From romunov at gmail.com  Tue Oct  1 12:04:52 2013
From: romunov at gmail.com (romunov)
Date: Tue, 1 Oct 2013 12:04:52 +0200
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <CAJkUqdEpuSKHOz88uS0bvKW3Egq-Dtok7R3XqC9Z5HcNFPOZEA@mail.gmail.com>
References: <CAJkUqdEpuSKHOz88uS0bvKW3Egq-Dtok7R3XqC9Z5HcNFPOZEA@mail.gmail.com>
Message-ID: <CAHT1vpiuaM06zGdUZ_KDMZj=En9s3Hw3aOKL0CcUW0xafiF1WQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131001/206fe985/attachment.pl>

From bbolker at gmail.com  Tue Oct  1 13:17:40 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 1 Oct 2013 11:17:40 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB
References: <CAJkUqdEpuSKHOz88uS0bvKW3Egq-Dtok7R3XqC9Z5HcNFPOZEA@mail.gmail.com>
	<CAHT1vpiuaM06zGdUZ_KDMZj=En9s3Hw3aOKL0CcUW0xafiF1WQ@mail.gmail.com>
Message-ID: <loom.20131001T131245-842@post.gmane.org>

romunov <romunov at ...> writes:

> 
> You can install the package via source (see
> http://glmmadmb.r-forge.r-project.org/), e.g.:
> 
> install.packages("glmmADMB",
>    repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>            getOption("repos")),type="source")
> 
> In order to do this, you will need a full R build toolchain to compile. If
> you're on linux based OS, you should be fine, but for windows,
>  you can grab
> it here:
> http://cran.r-project.org/bin/windows/Rtools/
> 
> That being said, I strongly recommend upgrading to a fairly recent version
> of R. In my experience, most packages catch on quick. You can always build
> some test units to check your work for backward compatibility.
> 
> Cheers,
> Roman

  At least part of the problem is in the detection/location of the
binary file . You can *try* downloading 
http://glmmadmb.r-forge.r-project.org/repos/bin/
  windows/contrib/3.0/glmmADMB_0.7.7.zip
[URL broken to make gmane happy, reassemble yourself]

  and see if it works.  But I have to agree with Roman that staying
on an old version of R is going to make things harder all around;
people are less likely to be willing to jump through hoops to help
you work with an old version (for example, I don't know if there
are Windows toolchain incompatibilities with old versions of R...)


From bbolker at gmail.com  Tue Oct  1 15:47:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 1 Oct 2013 13:47:41 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB
References: <CAJkUqdEpuSKHOz88uS0bvKW3Egq-Dtok7R3XqC9Z5HcNFPOZEA@mail.gmail.com>
	<CAHT1vpiuaM06zGdUZ_KDMZj=En9s3Hw3aOKL0CcUW0xafiF1WQ@mail.gmail.com>
	<loom.20131001T131245-842@post.gmane.org>
Message-ID: <loom.20131001T154609-102@post.gmane.org>

Ben Bolker <bbolker at ...> writes:


[snip]

>   At least part of the problem is in the detection/location of the
> binary file . You can *try* downloading 
> http://glmmadmb.r-forge.r-project.org/repos/bin/
>   windows/contrib/3.0/glmmADMB_0.7.7.zip
> [URL broken to make gmane happy, reassemble yourself]
> 
>   and see if it works.  But I have to agree with Roman that staying
> on an old version of R is going to make things harder all around;
> people are less likely to be willing to jump through hoops to help
> you work with an old version (for example, I don't know if there
> are Windows toolchain incompatibilities with old versions of R...)

  PS: glmmADMB uses 'paste0', which was added (I think) in R 2.14.0
or so.  You can work around this by defining

paste0 <- function(...) paste(...,sep="")

 (I should update the R dependency accordingly.) I don't know what
else might break ...


From bbolker at gmail.com  Tue Oct  1 16:28:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 01 Oct 2013 10:28:07 -0400
Subject: [R-sig-ME] mixed modelling with random effects with different
 correlation structures? GLMM/GEE mix
In-Reply-To: <3625_1380636326_r91E5OC3006707_7590d9e123ce1f.524af298@rug.nl>
References: <7740a86823fdf0.524aca33@rug.nl> <7590df0f23e954.524aca6f@rug.nl>
	<75e0b27123a26f.524acaae@rug.nl> <7610f72323c0a0.524acaeb@rug.nl>
	<759081d4239314.524acb28@rug.nl> <7590b07a23a6d6.524acb64@rug.nl>
	<75a0b21423b004.524acba1@rug.nl> <75d0cbcf23b655.524acbde@rug.nl>
	<7600b8d023ba43.524acc1b@rug.nl> <7720c90f23f960.524acc57@rug.nl>
	<7740fae423967c.524acd84@rug.nl> <75f0b62a23d3d0.524acdc3@rug.nl>
	<7600b57523af09.524aceb3@rug.nl> <7610bffa23c898.524acef2@rug.nl>
	<75e0e4a8238c9d.524acf2f@rug.nl> <7780b3fb23a0ee.524acf6c@rug.nl>
	<3625_1380636326_r91E5OC3006707_7590d9e123ce1f.524af298@rug.nl>
Message-ID: <524ADBF7.3060507@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 13-10-01 10:04 AM, R.Klink, van wrote:
> Dear Prof. Bolker
> 
> I write you on behalf of my colleagues working in the same
> project. We have a complicated study design, and as far as I have
> been able to tell, there are no published statistical packages that
> can deal with this design correctly.
> 
> We have a blocked design, of 3 blocks, with each 5 plots with each
> a different treatment. Each of these 15 plots has been sampled for 
> plant, insect and bird species richness during 4 consecutive years.
>  We would like to analyze all this in a mixed model where we
> include plot nested in block, and also the year effect as random
> factors. But this seems not to be possible, since the nested design
> has an "exchangeable correlation structure" (in GEE terms), or
> compound symmetry, whereas the time series is auto-regressive.
> Hence, we would like to construct a model that combines different
> correlation structures for the different random factors. My
> question to you is of course whether something like this is
> currently possible, if yes how? and if no, what would your advise
> be to analyze these data.
> 
> Feel free to post this question on one of the GLMM-fora
> 
> We hope you can give us some advice.
> 
> On behalf of me and my colleagues`

  Short answer: not that I know of (maybe AS-REML?)  You will probably
have to 'roll your own' with WinBUGS/JAGS, or AD Model Builder.  I
would also be quite concerned about fitting a model of this complexity
to a data set of this size -- it's going to be hard to estimate a year
effect with n=4, let alone an autoregressive correlation term.  I
would be inclined to fit a simpler model: year as a fixed effect --
and then test/examine the residuals for autocorrelation within plots.

  Hopefully others will come forward with different ideas.

 [cc'ing to r-sig-mixed-models]
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSStv3AAoJEOCV5YRblxUHzhAIALS/9jKqgjuJHFmBG3uibMyB
q+4W44WXR6tOSQYy0CSuLZHNdy+FfM2nXF7VDmyrwEZOfsx6s3S4jTEbxUauFxnG
oUacy1ZsXJyp59FWN8m0LKTUutsYPebZRRZ9I3S6WXLRHSG3uv1iL8/qRlEvG2ZA
oh/NK+1GP0UXgIYIdBgBwUmjc7hqCA4PGHxW7iDZ69dqpbZ306H8r2OuonzMvC8A
uVzjiAHXF789njVAiNN154wCOLHIHn/6IfcHLx04wRLEBMqGMMIsBs3UfhDBMbZL
NXIAq6ce5rvhpBWhQH8n94IwTTkc74WMmIZhaefkPbil97IzAEyeIgYYiP4DJV4=
=N+gU
-----END PGP SIGNATURE-----


From chris.brien at iinet.net.au  Wed Oct  2 02:14:10 2013
From: chris.brien at iinet.net.au (chris.brien at iinet.net.au)
Date: Wed, 02 Oct 2013 09:44:10 +0930
Subject: [R-sig-ME] mixed modelling with random effects with different
	correlation structures? GLMM/GEE mix
In-Reply-To: <524ADBF7.3060507@mcmaster.ca>
Message-ID: <5e3c9c5d901f878f2ed5527b56b3091f7f3ea925@webmail.iinet.net.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131002/82c1b6b0/attachment.pl>

From David.Duffy at qimr.edu.au  Wed Oct  2 14:02:13 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 2 Oct 2013 22:02:13 +1000
Subject: [R-sig-ME] mixed modelling with random effects with
 differentcorrelation structures? GLMM/GEE mix
In-Reply-To: <5e3c9c5d901f878f2ed5527b56b3091f7f3ea925@webmail.iinet.net.au>
References: <5e3c9c5d901f878f2ed5527b56b3091f7f3ea925@webmail.iinet.net.au>
Message-ID: <alpine.LMD.2.00.1310022158550.14553@orpheus.qimr.edu.au>

On Wed, 2 Oct 2013, chris.brien at iinet.net.au wrote:

> 	As Ben suggests it is possible to fit models with compound symmetry
> between plots within blocks and autocorrelation between times in
> asreml-r (and GenStat) However, these are commercial packages
> (http://www.vsni.co.uk/ [1]).

If you want R software, then as usual, this could be represented as a 
structural equation model, and run in openMx, sem or 
lavaan.


From henrik.singmann at psychologie.uni-freiburg.de  Wed Oct  2 16:09:26 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Wed, 02 Oct 2013 16:09:26 +0200
Subject: [R-sig-ME] Why does anova.merMod use refit?
Message-ID: <524C2916.3020506@psychologie.uni-freiburg.de>

Hi,

I stumbled upon something that surprised me in the anova method of lme4 (development version from github), namely that it always refits the model using refit.

This may lead to problems if the fitting algorithm doesn't converge with the default settings for refit (see below for an example) and diverges from the behavior of the anova method prior version 1.0 (which was consequently always very fast).

I would prefer if the refitting done by the anova method could be disabled or optional. Perhaps it would be the best if it gives a warning if models are not fit with REML = FALSE (I don't know what is the best way to find this out in the fitted object).

Usually one does not expect the anova method to be really time intensive, which with refit may well be the case for complex models fit without REML = FALSE.

Best,
Henrik


An example (data from http://stats.stackexchange.com/q/71172/442):

# preparation
require(lme4)
options(contrasts=c('contr.sum', 'contr.poly'))
dat <- read.table("http://pastebin.com/raw.php?i=MmNQigRv", colClasses = c(NA, rep("factor", 2), rep("numeric", 2)))
dat$pos.centered <- scale(dat$position, scale = FALSE)
dat$pos.centered.squared <- scale(dat$position^2, scale = FALSE)


# without REML = FALSE
m1 <- lmer(diff ~ cond.lag * (pos.centered + pos.centered.squared) + (cond.lag * (pos.centered + pos.centered.squared)|sub), dat, control = lmerControl(optCtrl = list(maxfun = 100000)))
m2 <- lmer(diff ~ cond.lag + pos.centered + pos.centered.squared + (cond.lag * (pos.centered + pos.centered.squared)|sub), dat)

anova(m1, m2)
## Data: dat
## Models:
## m2: diff ~ cond.lag + pos.centered + pos.centered.squared + (cond.lag *
## m2:     (pos.centered + pos.centered.squared) | sub)
## m1: diff ~ cond.lag * (pos.centered + pos.centered.squared) + (cond.lag *
## m1:     (pos.centered + pos.centered.squared) | sub)
##    Df    AIC    BIC logLik deviance Chisq Chi Df Pr(>Chisq)
## m2 26 -10924 -10763   5488   -10976
## m1 28 -10904 -10732   5480   -10960     0      2          1
## Warnmeldungen:
## 1: In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
##   convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
## 2: In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
##   convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded

# with REML = FALSE

m1r <- lmer(diff ~ cond.lag * (pos.centered + pos.centered.squared) + (cond.lag * (pos.centered + pos.centered.squared)|sub), dat, control = lmerControl(optCtrl = list(maxfun = 100000)), REML = FALSE)
m2r <- lmer(diff ~ cond.lag + pos.centered + pos.centered.squared + (cond.lag * (pos.centered + pos.centered.squared)|sub), dat, REML = FALSE)

anova(m1r, m2r)

## Data: dat
## Models:
## m2r: diff ~ cond.lag + pos.centered + pos.centered.squared + (cond.lag *
## m2r:     (pos.centered + pos.centered.squared) | sub)
## m1r: diff ~ cond.lag * (pos.centered + pos.centered.squared) + (cond.lag *
## m1r:     (pos.centered + pos.centered.squared) | sub)
##     Df    AIC    BIC logLik deviance Chisq Chi Df Pr(>Chisq)
## m2r 26 -10838 -10678   5445   -10890
## m1r 28 -10835 -10662   5445   -10891   0.3      2       0.86


-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From bates at stat.wisc.edu  Wed Oct  2 16:24:38 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Oct 2013 09:24:38 -0500
Subject: [R-sig-ME] Why does anova.merMod use refit?
In-Reply-To: <524C2916.3020506@psychologie.uni-freiburg.de>
References: <524C2916.3020506@psychologie.uni-freiburg.de>
Message-ID: <CAO7JsnREWsUn-SuwRt=Yy-fqX1iK2zty+neCge185nM+kMPK2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131002/1536bb9c/attachment.pl>

From henrik.singmann at psychologie.uni-freiburg.de  Wed Oct  2 17:04:53 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Wed, 02 Oct 2013 17:04:53 +0200
Subject: [R-sig-ME] Why does anova.merMod use refit?
In-Reply-To: <CAO7JsnREWsUn-SuwRt=Yy-fqX1iK2zty+neCge185nM+kMPK2w@mail.gmail.com>
References: <524C2916.3020506@psychologie.uni-freiburg.de>
	<CAO7JsnREWsUn-SuwRt=Yy-fqX1iK2zty+neCge185nM+kMPK2w@mail.gmail.com>
Message-ID: <524C3615.5030800@psychologie.uni-freiburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131002/f214cc71/attachment.pl>

From bbolker at gmail.com  Wed Oct  2 19:47:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Oct 2013 17:47:51 +0000 (UTC)
Subject: [R-sig-ME] Why does anova.merMod use refit?
References: <524C2916.3020506@psychologie.uni-freiburg.de>
	<CAO7JsnREWsUn-SuwRt=Yy-fqX1iK2zty+neCge185nM+kMPK2w@mail.gmail.com>
	<524C3615.5030800@psychologie.uni-freiburg.de>
Message-ID: <loom.20131002T194237-175@post.gmane.org>

Henrik Singmann <henrik.singmann at ...> writes:

 
> I am sorry for the misleading title of my mail. I didn't want to
> discuss the utility of having LRT tests done with REML versus not
> REML estimates, I think this doesn't deserve much discussion (i.e.,
> REML + LRT = bad).
 
> The point I wanted to make is just that it is relatively uncommon
> that an anova method is time consuming (which it may be in case of
> refit) and furthermore it is somewhat unsatisfactory that anova does
> not allow to pass the really nice control options to the
> optimizer. Obviously one can simply circumvent this issue by fitting
> the model directly with lmer and REML = FALSE and pass the correct
> optimizer arguments and then use this model as argument to anova.
 
> However, the optimization envoked by refit may also fail to converge
> in the number of default maxfun steps simply if there are many
> observations. This does not need to be due to a misspecified
> model. In fact in my real data, the warning message said exactly
> this (and came through anova): "maxfun < 10 * length(par)^2 is not
> recommended". And there is no way to change maxfun if refit is
> envoked.
 
> Hence my pledge for a warning instead of calling refit automatically.
> 
> Best,
> Henrik
 
> PS: I realize that this problem only appeared because I stupidly
> tried to compare to REML LMMs with anova which I shouldn't have
> done...

  I think there are some reasonable design considerations here,
not obvious what the best answer(s) is/are.

1. one way or the other we should prevent users from running
anova() on REML-fitted models *with different fixed effects* (arguably
there is a sensible use case for using anova() on models that
differ only in their random effects
  1a. should we try to do this automatically or should we throw
an error and hint to them how best to achieve their goal?

2 refit should allow appropriate optimization control parameters to be set
  2a a model refit should always inherit the optimization control parameters
from its parent model

3 we should try not to make too many backward-incompatible changes
(i.e. even if the current behaviour is weird we should make changes
carefully/gradually so as not to disturb users who have adapted to it)

  Point #2 is especially relevant; the design goal is to have #2a
be true, but it might not be.  Examples of where it is false, especially
minimalistic ones that can be run and tested as part of unit tests,
are especially welcome.

  Ben Bolker


From bbolker at gmail.com  Wed Oct  2 19:54:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Oct 2013 17:54:04 +0000 (UTC)
Subject: [R-sig-ME] Why does anova.merMod use refit?
References: <524C2916.3020506@psychologie.uni-freiburg.de>
	<CAO7JsnREWsUn-SuwRt=Yy-fqX1iK2zty+neCge185nM+kMPK2w@mail.gmail.com>
	<524C3615.5030800@psychologie.uni-freiburg.de>
	<loom.20131002T194237-175@post.gmane.org>
Message-ID: <loom.20131002T195227-514@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

>   I think there are some reasonable design considerations here,
> not obvious what the best answer(s) is/are.
> 
> 1. one way or the other we should prevent users from running
> anova() on REML-fitted models *with different fixed effects* (arguably
> there is a sensible use case for using anova() on models that
> differ only in their random effects
>   1a. should we try to do this automatically or should we throw
> an error and hint to them how best to achieve their goal?
> 
> 2 refit should allow appropriate optimization control parameters to be set
>   2a a model refit should always inherit the optimization control parameters
> from its parent model
> 
> 3 we should try not to make too many backward-incompatible changes
> (i.e. even if the current behaviour is weird we should make changes
> carefully/gradually so as not to disturb users who have adapted to it)
> 

  [snip snip snip]

  PS: I think opening an issue at http://github.com/lme4/lme4/issues
would be appropriate -- you can briefly summarize/refer to this discussion.
(I might add one myself, but someone else might get around to it first.)


From dominique.carval at cirad.fr  Thu Oct  3 18:10:20 2013
From: dominique.carval at cirad.fr (Dominique CARVAL)
Date: Thu, 3 Oct 2013 12:10:20 -0400 (AST)
Subject: [R-sig-ME] interpretation of an individual-level random effect
Message-ID: <08664fa3.000062cc.00000048@CARVAL_DOM-M067>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131003/32163376/attachment.pl>

From drmccloy at uw.edu  Thu Oct  3 18:43:35 2013
From: drmccloy at uw.edu (Dan McCloy)
Date: Thu, 3 Oct 2013 09:43:35 -0700
Subject: [R-sig-ME] errors compiling minqa during lme4 install
Message-ID: <CAOE0pYmq=oZSHfdtS1-MOBBA7UYsEHe6JX=MS-TpoomadM29hA@mail.gmail.com>

I tried to install lme4 on a new laptop today, and got the following
error during the installation of the dependency "minqa":

-L/home/dan/R/x86_64-pc-linux-gnu-library/3.0/Rcpp/lib: No such file
or directory
make: *** [minqa.so] Error 1
ERROR: compilation failed for package ?minqa?

I checked, and Rcpp is installed (version 0.10.5), and the folder in
question does exist, and contains two files: libRcpp.a and libRcpp.so

Any suggestions / advice?  Either my google skills are terrible, or
nobody else is having this problem.


From John.Morrongiello at csiro.au  Fri Oct  4 07:03:27 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Fri, 4 Oct 2013 05:03:27 +0000
Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept and
	slope model
Message-ID: <2547E22D246F3945BB491BDD8257C2E77DABBC4D@exmbx06-cdc.nexus.csiro.au>

Hi all

I was wondering if someone could show me how to calculate the intra-class correlation coefficient for a model with random intercepts and slopes in lmer? Should I even be calculating these, and instead draw inference from intercept only models? I've had a good look online and come across a few comments like (http://www.bristol.ac.uk/cmm/learning/videos/random-slopes.html):
 "For a random slopes model, the intraclass correlation is not equal to the variance partitioning coefficient because the intraclass correlation will depend on the value of x1 for each of the two elements in question.  The variance partitioning coefficient just depended on one value of x1 but if two different people each have a different value of x1, both those values are going to go into the formula for the intraclass correlation.  The exact expression for the intraclass correlation is quite complicated; we're not going to give it here because the important thing is simply to note that the intraclass correlation will depend on the two values of x1 as well as ?2u1, ?2u0 and ?u01". 

So I guess the ICC is contingent on a given value of X. I assume this is preferably an X value that all individuals share?

I can see that for a straight random intercept model (please correct if I'm wrong) 
M1<-y~x+(1|ID)
ICC(ID) = var(ID)/(var(ID)+var(residual) 
## correlation between measurements from two individuals

For a nested random effect model:
M2<-y~x+(1|site/ID)
ICC(ID) = var(ID)/(var(ID)+var(site)+var(residual)
##correlation between two measurements from same individual (how similar individuals are to themselves)

ICC(site) = var(site)/(var(ID)+var(site)+var(residual)
## correlation between two measurements from the same site

ICC(ID:site) = var(ID)+var(site)/(var(ID)+var(site)+var(residual)
## correlation between two measurements from the same individual at the same site

For a crossed random effect model:
M3<-y~x+(1|ID)+(1|year)
ICC(ID) = var(ID)/(var(ID)+var(residual)
ICC(year) = var(year)/(var(year)+var(residual)

What about for the random slope model:
M4<-y~x+(x|ID)
ICC(ID) = ???
e.g. (I'm tipping ICCs are going to be low)
Random effects:
 Groups   Name         Variance Std.Dev. Corr
 FishID   (Intercept)  0.011445 0.10698      
          c.(log(Age)) 0.037444 0.19350  0.25
 Residual              0.004595 0.06778      
Number of obs: 640, groups: FishID, 498

or even crossed random intercept and random slope model:
M5<-y~x+(x|ID)+(x|year)
ICC(ID) = ???
ICC(year) = ???

e.g.
Random effects:
 Groups   Name         Variance  Std.Dev. Corr 
 FishID   (Intercept)  0.0103597 0.10178       
          c.(log(Age)) 0.0393865 0.19846  0.21 
 fYear    (Intercept)  0.0007723 0.02779       
          c.(log(Age)) 0.0147014 0.12125  -0.36
 Residual              0.0044479 0.06669       
Number of obs: 640, groups: FishID, 498; fYear, 6

How would I report such ICCs- do I state that they were calculated over a given range of X (in this case Age e.g. at age=2, ICC(ID)=...)?

Regards

John


From jake987722 at hotmail.com  Fri Oct  4 08:41:56 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 4 Oct 2013 00:41:56 -0600
Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept
 and slope model
In-Reply-To: <2547E22D246F3945BB491BDD8257C2E77DABBC4D@exmbx06-cdc.nexus.csiro.au>
References: <2547E22D246F3945BB491BDD8257C2E77DABBC4D@exmbx06-cdc.nexus.csiro.au>
Message-ID: <BAY172-W2265CECF70C7EB85059F93CB100@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131004/4b1b811a/attachment.pl>

From bbolker at gmail.com  Fri Oct  4 15:06:30 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 Oct 2013 13:06:30 +0000 (UTC)
Subject: [R-sig-ME] errors compiling minqa during lme4 install
References: <CAOE0pYmq=oZSHfdtS1-MOBBA7UYsEHe6JX=MS-TpoomadM29hA@mail.gmail.com>
Message-ID: <loom.20131004T145919-554@post.gmane.org>

Dan McCloy <drmccloy at ...> writes:

> 
> I tried to install lme4 on a new laptop today, and got the following
> error during the installation of the dependency "minqa":
> 
> -L/home/dan/R/x86_64-pc-linux-gnu-library/3.0/Rcpp/lib: No such file
> or directory
> make: *** [minqa.so] Error 1
> ERROR: compilation failed for package ?minqa?
> 
> I checked, and Rcpp is installed (version 0.10.5), and the folder in
> question does exist, and contains two files: libRcpp.a and libRcpp.so
> 
> Any suggestions / advice?  Either my google skills are terrible, or
> nobody else is having this problem.


  Nothing springs to mind, sorry. Have you tried removing/reinstalling
Rcpp before (re)installing minqa?

http://www.youtube.com/watch?v=p85xwZ_OLX0


From bbolker at gmail.com  Fri Oct  4 15:11:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 Oct 2013 13:11:36 +0000 (UTC)
Subject: [R-sig-ME] interpretation of an individual-level random effect
References: <08664fa3.000062cc.00000048@CARVAL_DOM-M067>
Message-ID: <loom.20131004T150653-668@post.gmane.org>

Dominique CARVAL <dominique.carval at ...> writes:

> This is my first post to r-sig-mixed-models project and I hope I am
> sending my message to the appropriate place.
> 
> I have used a binomial GLMM with a logit link function to assess possible
> significant effect of variables (fixed effects: patch density, sex ratio,
> ) on the probability for a weevil to move from its local patch to a
> neighboring patch.
> 
> I have repeated measures (of the same individuals) of the binary response
> of the weevils (to move or not to move) to variations in the local
> conditions of patches.
> 
> To take into account the individual variation (the propensity of a
> particular individuals to respond 1 or 0), I added an individual-level
> random term (the Id of the individuals) to my model. If I have weel
> understood, it is also a way to deal with overdispersion in the data.
> 
> In the summary of GLMM (I used the glmer function of the lme4 package), I
> found the estimate of the variance of the individual-level random term.
> 
> My questions are : Can I interpret this variance as an (real) estimation
> of the variability between individuals in the response (the dispersal
> decision) ?  Can I use this value to simulate individual variability in an
> Individual-Based Model ?

  This all seems quite reasonable.

  You are of course making the assumption that the among-individual
variability is normally distributed on the logit scale.

  If you're going to build an individual-based model anyway you could
use it to test your assumption: specify a particular logit-Normal
distribution of among-individual variation in propensity to disperse,
run the model, simulate an observation process, and see whether running
the statistical model gives you a decent estimate.  (You might want
to do this many times to get a sense of the bias and variance.)

  You could also run the IBM with non-logit-Normal variation
(e.g. several discrete classes of individuals) and see how well
or poorly the glmer fit performs -- does it get the fixed effect
right?  What does it say about the variability?  etc.


From drmccloy at uw.edu  Sat Oct  5 12:50:37 2013
From: drmccloy at uw.edu (Dan McCloy)
Date: Sat, 5 Oct 2013 03:50:37 -0700
Subject: [R-sig-ME]  errors compiling minqa during lme4 install
Message-ID: <CAOE0pYnmounC4Sej3YjcNZhMSna=WTiZdxKpx-it-=mgoSk5jQ@mail.gmail.com>

Yes, I tried removing / reinstalling Rcpp.  No change.  Installing
RcppEigen fails with the same error as minqa, though I doubt that is
helpfully informative.  I don't know much about C(++) or make, but it
looks to me like there's no space between the -L and the library path.
 I assume that's normal?
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington


From kalakouentin at gmail.com  Sat Oct  5 18:32:18 2013
From: kalakouentin at gmail.com (Pantelis Z. Hadjipantelis)
Date: Sat, 05 Oct 2013 17:32:18 +0100
Subject: [R-sig-ME] errors compiling minqa during lme4 install
In-Reply-To: <CAOE0pYnmounC4Sej3YjcNZhMSna=WTiZdxKpx-it-=mgoSk5jQ@mail.gmail.com>
References: <CAOE0pYnmounC4Sej3YjcNZhMSna=WTiZdxKpx-it-=mgoSk5jQ@mail.gmail.com>
Message-ID: <52503F12.9070806@gmail.com>

On 05/10/13 11:50, Dan McCloy wrote:
> removing / reinstalling Rcpp.  No change.  Installing
> RcppEigen fails with the same error as minqa, though I doubt that is
> helpfully informative.  I don't know much about C(++) or make, but it
> looks to me like there's no space between the -L and the library path.
>   I assume that's normal?
Yes, it is normal. It is standard gcc syntax.

It is actually helpful to know that the same error exists. Given that 
both packages try to compile certain C++ files it means that most 
probably your C++ installation is the issue.

What version of gcc do you have by the way? Maybe running an update on 
it could be helpful.

Also out of curiosity : Do you have libc-dev-bin and libc6-dev 
installed? I vaguely remember that the first ever time I tried to 
install minqa I ran to some problems but then I went ahead installed a 
couple of *-dev files and ever since everything has been fine (sorry it 
has been about two years ago, I can't recall what exactly I installed.)

*/Rcpp/lib in my system also contains just:  libRcpp.a and libRcpp.so, 
so don't worry, you aren't missing something there.

For the record my installation is R 3.0.2, RcppEigen_0.3.1.2.1, 
Rcpp_0.10.3, lme4_1.0-4 and minqa_1.2.1.

Pantelis.


From baud-bovy.gabriel at hsr.it  Sun Oct  6 02:53:47 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Sun, 06 Oct 2013 02:53:47 +0200
Subject: [R-sig-ME] lmer specification for maximal random effects structure
 and one-between and two within-subject factors
Message-ID: <5250B49B.2000100@hsr.it>

Hi r-sig-me,

I am analyzing the results of an experiment with one between-subject 
factor (group, 3 levels: yo, yf, ef)
and two within-subject factors (vf, 2 levels: vf and novf, and task, 3 
levels: stand, ltstat, ltmov).
Each group includes uniquely identified 15 subjects. All factors are 
coded with sum contrasts (contr.sum).

Barr et al. 2013 advise to keep the random effects structure maximal. 
Moreover, they write
that "In general, within-unit treatments require both the by-unit 
intercepts and slopes in the
random effects specification, whereas between-unit treatments require 
only the by-unit
random intercepts."

Barr et al. (2013) Random effects structure for confirmatory hypothesis 
testing:
Keep it maximal. Journal of Memory and Language 68, 255?278

I have two questions:

First, how would you specify the model if you were trying to follow Barr 
et al.
(2013) advice to have a maximal random effect covariance structure 
(granted that it still has
to be identifiable) for such a design.

Second, I could not find a discussion discussing design matrix for 
random effects corresponding
to two or more within-subject factors. It seems that it would make sense 
in cases like that
to define one intercept for each subject plus one random effect for each 
treatment relative
to the baseline but the syntax to achieve it is ackward. It seems that 
the default leads
to design matrices with two many random effects. See the examples below.

Following Barr, my initial attempt was:

 > fit<-lmer(log(e.area)~group*task*vf + (1|su0) + (task|su0) + 
(vf|su0), CP0vf)
In checkZrank(reTrms$Zt, n = n, control, nonSmall = 1e+06) :
number of observations <= rank(Z); variance-covariance matrix will be 
unidentifiable.
 > VarCorr(fit)
Groups Name Std.Dev. Corr
su0 (Intercept) 0.21461
su0.1 (Intercept) 0.36124
taskltstat-stand 0.16478 0.501
taskltdyn-stand 0.12364 -0.949 -0.676
su0.2 (Intercept) 0.19043
vfnovf-vf 0.10934 -0.224
Residual 0.17567

This model yields a warning message and includes more random effects 
that I wanted (three "intercepts" !)

My first attempt to remove intercept to simplify the covariance 
structure was not successful

 > fit<-lmer(log(e.area)~group*task*vf + (1|su0) + (task-1|su0) + 
(vf-1|su0),CP0vf)
which yielded the warning message In checkZrank(reTrms$Zt, n = n, 
control, nonSmall = 1e+06) :
number of observations <= rank(Z); variance-covariance matrix will be 
unidentifiable.
 > VarCorr(fit)
Groups Name Std.Dev. Corr
su0 (Intercept) 0.30722
su0.1 taskstand 0.38166
taskltstat 0.43823 0.804
taskltdyn 0.22527 0.949 0.888
su0.2 vfVF 0.11602
vfnoVF 0.10147 -1.000
Residual 0.17508

This yields the same error message and looking at the structure of the 
covariance matrix
I see that the number of random effects has not changed (only that now 
the coding is
made with a dummy matrix instead of the contrasts).

The following model however does not give any warning message

 > fit<-lmer(log(e.area)~group*task*vf + (task|su0) + (vf|su0),CP0vf)
 > VarCorr(fit)
Groups Name Std.Dev. Corr
su0 (Intercept) 0.39050
taskltstat-stand 0.16468 0.492
taskltdyn-stand 0.12581 -0.891 -0.659
su0.1 (Intercept) 0.27859
vfnovf-vf 0.11002 -0.129
Residual 0.17198

However, I find difficult to interpret the fact that there are "two 
intercept".
Any suggestion would be appreciated.

It seems to me that a model with one random intercept for
the subject + one random effects for each treatment relative to the
baseline is easire to interpret. The syntax to get it is however not
straightforward and requires coding dummy variables by hand.

 > tmp<-CP0vf
 > tmp$vf.novf<-ifelse(tmp$vf=="noVF",1,0)
 > tmp$task.ltstat<-ifelse(tmp$task=="ltstat",1,0)
 > tmp$task.ltmov<-ifelse(tmp$task=="ltsmov",1,0)
 > fit<-lmer(log(e.area)~group*task*vf + (1|su0) + (task.ltstat-1|su0) + 
(task.ltmov-1|su0) + (vf.novf-1|su0),tmp)
 > VarCorr(fit)
Groups Name Std.Dev.
su0 (Intercept) 0.43475
su0.1 task.ltstat 0.23228
su0.2 task.ltmov 0.37742
su0.3 vf.novf 0.19578
Residual 0.20493

or, to allow for some correlations,

 > fit<-lmer(log(e.area)~group*task*vf + (task.ltstat-1|su0) + 
(task.ltmov-1|su0) + (vf|su0),tmp)
 > VarCorr(fit)
Groups Name Std.Dev. Corr
su0 task.ltstat 0.23284
su0.1 task.ltmov 0.20882
su0.2 (Intercept) 0.43813
vfnovf-vf 0.10022 0.090
Residual 0.20410

 > fit<-lmer(log(e.area)~group*task*vf + (task|su0) + (vf.novf-1|su0), tmp)
 > VarCorr(fit)
Groups Name Std.Dev. Corr
su0 (Intercept) 0.45837
taskltstat-stand 0.16109 0.413
taskltdyn-stand 0.12072 -0.698 -0.674
su0.1 vf.novf 0.20669
Residual 0.17932

I am a bit confused about how to reason about these different 
possibilities and
I wonder what to do in the spirit of Barr et al. (2013) who suggest not 
to try
to model the random structure but to keep it maximal. To quote them:

"The generalization performance of LMEMs including data-driven random 
effects structures
strongly depends upon modeling criteria and sample size, yielding 
reasonable results on
moderately-sized samples when conservative criteria are used, but with 
little or no power
advantage over maximal models."

Gabriel




-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From bbolker at gmail.com  Sun Oct  6 03:50:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 05 Oct 2013 21:50:57 -0400
Subject: [R-sig-ME] errors compiling minqa during lme4 install
In-Reply-To: <CAOE0pYnmounC4Sej3YjcNZhMSna=WTiZdxKpx-it-=mgoSk5jQ@mail.gmail.com>
References: <CAOE0pYnmounC4Sej3YjcNZhMSna=WTiZdxKpx-it-=mgoSk5jQ@mail.gmail.com>
Message-ID: <5250C201.9050401@gmail.com>

On 13-10-05 06:50 AM, Dan McCloy wrote:
> Yes, I tried removing / reinstalling Rcpp.  No change.  Installing
> RcppEigen fails with the same error as minqa, though I doubt that is
> helpfully informative.  I don't know much about C(++) or make, but it
> looks to me like there's no space between the -L and the library path.
>  I assume that's normal?
> -- dan
> 
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Fellow
> Institute for Learning and Brain Sciences
> University of Washington


  This is what my linking statement looks like, in case that's useful:

g++ -shared -L/usr/local/lib -o minqa.so altmov.o bigden.o biglag.o
bobyqa.o bobyqb.o lagmax.o minqa.o newuoa.o newuob.o prelim.o rescue.o
trsapp.o trsbox.o trstep.o uobyqa.o uobyqb.o update.o updatebobyqa.o
-L/mnt/hgfs/bolker/Documents/LOCAL/lib/R/site-library/Rcpp/lib -lRcpp
-Wl,-rpath,/mnt/hgfs/bolker/Documents/LOCAL/lib/R/site-library/Rcpp/lib
-lgfortran -lm -lquadmath -L/usr/local/lib/R/lib -lR

  The only other thing I can think of is checking permissions?


From tobias.heed at uni-hamburg.de  Sun Oct  6 10:18:16 2013
From: tobias.heed at uni-hamburg.de (Tobias Heed)
Date: Sun, 6 Oct 2013 10:18:16 +0200
Subject: [R-sig-ME] lmer specification for maximal random effects
	structure and one-between and two within-subject factors
In-Reply-To: <5250B49B.2000100@hsr.it>
References: <5250B49B.2000100@hsr.it>
Message-ID: <0CBF6BB4-6964-4D59-831F-0295609D1032@uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131006/8dc98fb5/attachment.pl>

From baud-bovy.gabriel at hsr.it  Sun Oct  6 15:15:50 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Sun, 06 Oct 2013 15:15:50 +0200
Subject: [R-sig-ME] lmer specification for maximal random effects
 structure and one-between and two within-subject factors
In-Reply-To: <0CBF6BB4-6964-4D59-831F-0295609D1032@uni-hamburg.de>
References: <5250B49B.2000100@hsr.it>
	<0CBF6BB4-6964-4D59-831F-0295609D1032@uni-hamburg.de>
Message-ID: <52516286.2030601@hsr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131006/a716506c/attachment.pl>

From drmccloy at uw.edu  Mon Oct  7 02:40:08 2013
From: drmccloy at uw.edu (Dan McCloy)
Date: Sun, 6 Oct 2013 17:40:08 -0700
Subject: [R-sig-ME] errors compiling minqa during lme4 install
Message-ID: <CAOE0pYmUmPiUA1mz1kruyvk0XcXRtSuBKVDCCzMbA1sty2fioA@mail.gmail.com>

Hi Pantelis,
My version of gcc is 4.7.3-1, and I did already have libc6-dev and
libc-dev-bin installed.  I poked around for other likely-looking *-dev
files that weren't installed, but didn't find any.  Strangely, I can
get Rcpp to install just fine, so I'm actually not certain that the
C++ installation is the problem.  My versions are R 3.0.2,  Rcpp
0.10.5.  I've put the full installation output in a Gist, in case
anyone notices something I'm missing:
https://gist.github.com/drammock/6860963


From kalakouentin at gmail.com  Mon Oct  7 05:44:38 2013
From: kalakouentin at gmail.com (Pantelis Z. Hadjipantelis)
Date: Mon, 07 Oct 2013 04:44:38 +0100
Subject: [R-sig-ME] errors compiling minqa during lme4 install
In-Reply-To: <CAOE0pYmUmPiUA1mz1kruyvk0XcXRtSuBKVDCCzMbA1sty2fioA@mail.gmail.com>
References: <CAOE0pYmUmPiUA1mz1kruyvk0XcXRtSuBKVDCCzMbA1sty2fioA@mail.gmail.com>
Message-ID: <52522E26.1010904@gmail.com>

On 07/10/13 01:40, Dan McCloy wrote:
> Hi Pantelis,
> My version of gcc is 4.7.3-1, and I did already have libc6-dev and
> libc-dev-bin installed.  I poked around for other likely-looking *-dev
> files that weren't installed, but didn't find any.  Strangely, I can
> get Rcpp to install just fine, so I'm actually not certain that the
> C++ installation is the problem.  My versions are R 3.0.2,  Rcpp
> 0.10.5.  I've put the full installation output in a Gist, in case
> anyone notices something I'm missing:
> https://gist.github.com/drammock/6860963

Hmm... Assuming that permissions are not an issue either I don't have an 
obvious answer (It doesn't seem like you are doing some odd like having 
spaces in the file path anyway).
Do you have a working Rcpp installation (not just successful library 
load)? For example, if you execute in the R-terminal <code> evalCpp('2 * 
M_PI') <\code> do you get back 6.283185? It's a long shot but maybe the 
problem has to with your Rcpp setup.

Have you tried asking in StackOverflow? Rcpp/RcppEigen's developers and 
maintainers appear to frequently answer questions there. You might get 
lucky.


From John.Morrongiello at csiro.au  Mon Oct  7 06:00:24 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Mon, 7 Oct 2013 04:00:24 +0000
Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept and
In-Reply-To: <mailman.5.1380880802.17398.r-sig-mixed-models@r-project.org>
References: <mailman.5.1380880802.17398.r-sig-mixed-models@r-project.org>
Message-ID: <2547E22D246F3945BB491BDD8257C2E77DABBE35@exmbx06-cdc.nexus.csiro.au>

Hi Jake

Thanks very much for your helpful response. I like your advice regarding not to present some of these ICCs- I must admit framing the language around them was getting a little confusing. The Goldstein reference provides the formula I was after (just after model 2 in refer for others). Whilst a mouthful, for interests sake I'll give it a go on a simple random slopes model. Finally, I got those ICC formulas for a crossed random effect model from a couple of papers I've recently read. I'd just like to confirm that for a crossed random effect model:
M3<-y~x+(1|ID)+(1|year)

ICC(ID) does not equal 
(1) var(ID)/(var(ID)+var(residual), 
but rather 
(2) var(ID)/(var(ID)+var(year)+var(residual)


Cheers John

Date: Fri, 4 Oct 2013 00:41:56 -0600
From: Jake Westfall <jake987722 at hotmail.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] intraclass correlation (ICC) for random
	intercept and slope model

Hi John,

Various intra-class correlation coefficients can certainly be computed for models with random slopes (which may or may not also have a crossed random structure), and they are kind of interesting to think about, but they do not end up being very useful as simple summaries of the data in these cases, partly because they cannot be understood simply as proportions of variance, and partly because, like you said, they are different for different values of the predictors. There are generally no clear guides about which values of the predictors are the ones you want to compute the ICC at.

Goldstein et al. (2002), in one of the earlier sections of the paper, discuss an ICC for a normal model with one random intercept and one random slope, possibly correlated:

http://www.bristol.ac.uk/cmm/research/pvmm.pdf

I think the ICCs that you wrote for the crossed random effects models without random slopes are not quite right. Both denominators should be the same and should contain all 3 variance components (ID, year, and residual). They differ only in the numerators.

ICCs for a crossed random intercept model with random slopes look like basically the one given above by Goldstein, except there is even more stuff in the denominator, reflecting variance due to both random grouping factors. And of course you have separate ICCs for the two grouping factors.

And there are even other, more exotic ICCs that we could talk about. What about, in the crossed models with IDs and years, the ICC for ID-by-year? This would be the expected correlation between different observations from the same ID and the same year. There are many different potential levels of replication in these higher models, and hence many ICCs that we could talk about.


As for how to report these... maybe don't? Like I said, they don't end up being very useful as simple summaries in these cases. Depending on what you're trying to convey, it might be more useful just to talk about the standard deviations of the random effects.

Jake

> From: John.Morrongiello at csiro.au
> To: r-sig-mixed-models at r-project.org
> Date: Fri, 4 Oct 2013 05:03:27 +0000
> Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept and	slope model
> 
> Hi all
> 
> I was wondering if someone could show me how to calculate the intra-class correlation coefficient for a model with random intercepts and slopes in lmer? Should I even be calculating these, and instead draw inference from intercept only models? I've had a good look online and come across a few comments like (http://www.bristol.ac.uk/cmm/learning/videos/random-slopes.html):
>  "For a random slopes model, the intraclass correlation is not equal to the variance partitioning coefficient because the intraclass correlation will depend on the value of x1 for each of the two elements in question.  The variance partitioning coefficient just depended on one value of x1 but if two different people each have a different value of x1, both those values are going to go into the formula for the intraclass correlation.  The exact expression for the intraclass correlation is quite complicated; we're not going to give it here because the important thing is simply to note that the intraclass correlation will depend on the two values of x1 as well as ?2u1, ?2u0 and ?u01". 
> 
> So I guess the ICC is contingent on a given value of X. I assume this is preferably an X value that all individuals share?
> 
> I can see that for a straight random intercept model (please correct 
> if I'm wrong)
> M1<-y~x+(1|ID)
> ICC(ID) = var(ID)/(var(ID)+var(residual) ## correlation between 
> measurements from two individuals
> 
> For a nested random effect model:
> M2<-y~x+(1|site/ID)
> ICC(ID) = var(ID)/(var(ID)+var(site)+var(residual)
> ##correlation between two measurements from same individual (how 
> similar individuals are to themselves)
> 
> ICC(site) = var(site)/(var(ID)+var(site)+var(residual)
> ## correlation between two measurements from the same site
> 
> ICC(ID:site) = var(ID)+var(site)/(var(ID)+var(site)+var(residual)
> ## correlation between two measurements from the same individual at 
> the same site
> 
> For a crossed random effect model:
> M3<-y~x+(1|ID)+(1|year)
> ICC(ID) = var(ID)/(var(ID)+var(residual)
> ICC(year) = var(year)/(var(year)+var(residual)
> 
> What about for the random slope model:
> M4<-y~x+(x|ID)
> ICC(ID) = ???
> e.g. (I'm tipping ICCs are going to be low) Random effects:
>  Groups   Name         Variance Std.Dev. Corr
>  FishID   (Intercept)  0.011445 0.10698      
>           c.(log(Age)) 0.037444 0.19350  0.25
>  Residual              0.004595 0.06778      
> Number of obs: 640, groups: FishID, 498
> 
> or even crossed random intercept and random slope model:
> M5<-y~x+(x|ID)+(x|year)
> ICC(ID) = ???
> ICC(year) = ???
> 
> e.g.
> Random effects:
>  Groups   Name         Variance  Std.Dev. Corr 
>  FishID   (Intercept)  0.0103597 0.10178       
>           c.(log(Age)) 0.0393865 0.19846  0.21 
>  fYear    (Intercept)  0.0007723 0.02779       
>           c.(log(Age)) 0.0147014 0.12125  -0.36
>  Residual              0.0044479 0.06669       
> Number of obs: 640, groups: FishID, 498; fYear, 6
> 
> How would I report such ICCs- do I state that they were calculated over a given range of X (in this case Age e.g. at age=2, ICC(ID)=...)?
> 
> Regards
> 
> John


From jake987722 at hotmail.com  Mon Oct  7 07:41:14 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sun, 6 Oct 2013 23:41:14 -0600
Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept and
In-Reply-To: <2547E22D246F3945BB491BDD8257C2E77DABBE35@exmbx06-cdc.nexus.csiro.au>
References: <mailman.5.1380880802.17398.r-sig-mixed-models@r-project.org>,
	<2547E22D246F3945BB491BDD8257C2E77DABBE35@exmbx06-cdc.nexus.csiro.au>
Message-ID: <BAY172-W20A214ACB34C45F2638B12CB130@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131006/9739df09/attachment.pl>

From bbolker at gmail.com  Mon Oct  7 16:42:50 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 Oct 2013 14:42:50 +0000 (UTC)
Subject: [R-sig-ME] errors compiling minqa during lme4 install
References: <CAOE0pYmUmPiUA1mz1kruyvk0XcXRtSuBKVDCCzMbA1sty2fioA@mail.gmail.com>
Message-ID: <loom.20131007T163915-349@post.gmane.org>

Dan McCloy <drmccloy at ...> writes:

> 
> Hi Pantelis,
> My version of gcc is 4.7.3-1, and I did already have libc6-dev and
> libc-dev-bin installed.  I poked around for other likely-looking *-dev
> files that weren't installed, but didn't find any.  Strangely, I can
> get Rcpp to install just fine, so I'm actually not certain that the
> C++ installation is the problem.  My versions are R 3.0.2,  Rcpp
> 0.10.5.  I've put the full installation output in a Gist, in case
> anyone notices something I'm missing:
> https://gist.github.com/drammock/6860963
> 
> 


  This is a bit of a long shot, but I wonder if for some reason there's
a bogus line break being introduced in to the g++ call.  The reason I
say this is that 

-L/home/dan/R/x86_64-pc-linux-gnu-library/3.0/Rcpp/lib: 
No such file or directory

  looks like a standard attempt to execute that file rather than an
error from trying to link to a nonexistent library.

  Can you try setting up a minimal g++ example and linking it
with a bogus library directory to see if you get the same error?


From keepauboon at hotmail.com  Sat Oct  5 23:41:52 2013
From: keepauboon at hotmail.com (Pau Boon Kee)
Date: Sat, 5 Oct 2013 21:41:52 +0000 (UTC)
Subject: [R-sig-ME] stability of glmmADMB
Message-ID: <loom.20131005T233314-978@post.gmane.org>

Dear all

I have an enquiry on the stability of the glmm AD model builder package in R.

I wonder if anyone can shed some light on the possible reasons as to 
why the results, estimated coefficients, 
generated by two different operating systems, window 7 and OS X, 
are different to a certain extent.

To a certain extent I meant, the directions of correlation are still the same, 
but the figures can be quite significantly different.

The following are my results:

windows 7:

intercept: -2.245552***
link_DIS_mm: -0.021536
landlock: 1.294218*** 


OS X:

intercept: -2.103106**
link_DIS_MM: -0.029175
landlock: 1.195673**

Your help will be very much appreciated.

Best Regards
Boon


From lupp at uchicago.edu  Mon Oct  7 21:01:49 2013
From: lupp at uchicago.edu (Stuart Luppescu)
Date: Mon, 07 Oct 2013 14:01:49 -0500
Subject: [R-sig-ME] mer summary not an S4 object??
Message-ID: <1381172509.3119.8.camel@musuko.uchicago.edu>

Hello, I've been using code like this for a while with no problems:

total.var7 <- sum(as.numeric(summary(lme7)@REmat[,3]))

but recently when I try this I get this message:

Error: trying to get slot "REmat" from an object (class
"summary.merMod") that is not an S4 object

Can someone tell me why this doesn't work anymore?

I have figured out a way to get around this, but it's semi-clumsy; I
much prefer the original. 

Thanks.
-- 
Stuart Luppescu -=-=- slu <AT> ccsr <DOT> uchicago <DOT> edu
CCSR at U of C ,.;-*^*-;.,  ccsr.uchicago.edu
     (^_^)/    ????????
[Crash programs] fail because they are based on the theory that, 
with nine women pregnant, you can get a baby a month.
                -- Wernher von Braun


From maiski at maiski.net  Mon Oct  7 14:52:06 2013
From: maiski at maiski.net (Maya)
Date: Mon, 7 Oct 2013 12:52:06 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm random intercept/slope model and credible
	intervals
Message-ID: <loom.20131007T144006-569@post.gmane.org>

Hello all,

i have the following problem. 
I want to fit a GLMM with a numerical fixed effect, a factorial random
effect, containing subject ids and a binary outcome. My code is:

fam='categorical'

priors1<-list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V = diag(2),
nu = 6)))

modelGlmm1<- MCMCglmm(toModel ~ fixedEffect,
random=~us(1+fixedEffect):randomEffect, data=data, verbose=FALSE,
family=fam, pr=TRUE, pl=TRUE, nitt=nittM, thin=thinM, burnin=burninM,
prior=priors1)

mp1 = predict(modelGlmm1, interval = 'confidence')


But as I try to get the credible intervals I get the following error:
Error in M[, which(rm.v), ] <- 0 : incorrect number of subscripts.

Could anybody give me some hints or enlighten me on the subject? I cannot
figure it out by myself :/

I have also another question: How are the credible intervals constructed:
pointwise or simultaniously?

Thanks in advance! 

Greets,

Maya


From bates at stat.wisc.edu  Mon Oct  7 22:29:03 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 7 Oct 2013 15:29:03 -0500
Subject: [R-sig-ME] mer summary not an S4 object??
In-Reply-To: <1381172509.3119.8.camel@musuko.uchicago.edu>
References: <1381172509.3119.8.camel@musuko.uchicago.edu>
Message-ID: <CAO7JsnQJDGY2CE3bCjkx_31kOiA_CV2e9b=tPiL7pUfQ57unXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131007/ca865b04/attachment.pl>

From baud-bovy.gabriel at hsr.it  Mon Oct  7 23:03:40 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Mon, 07 Oct 2013 23:03:40 +0200
Subject: [R-sig-ME] lmer specification for random effects with several
 within-subject factors
In-Reply-To: <52516286.2030601@hsr.it>
References: <5250B49B.2000100@hsr.it>
	<0CBF6BB4-6964-4D59-831F-0295609D1032@uni-hamburg.de>
	<52516286.2030601@hsr.it>
Message-ID: <525321AC.5030100@hsr.it>

Hi,

In my previous post lmer specification for maximal random effects 
structure and one-between and two within-subject factors), I had 
actually two quite different questions, which is not a very good idea. 
Thanks to Tobias, I got an answer to my first question. To restate the 
second question, I'll use  a repeated-measure design with two crossed 
within subject factors (A: 3 levels and B:2 levels) and replications as  
an imaginery example. I assume that A and B are coded with sum contrasts.

I found many instances where one is told to use (1|S) +  (0+A|S) or 
(1|S) + (A-1|S) to simplify the correlation structure (I have done it 
myself) but I am not actually sure to fully understand what is 
happening.  More precisely, while the random effects specified by the 
formula (A*B|S) yields the results that I intuitively expected, I find 
the results obtained with (1|S) + (A-1|S)  + (B-1|S)  + (A:B-1|S) or 
(1|S) + (A-1|S)  + (B-1|S)  + (A:B-1|S) confusing. In these cases, I  am 
actually not sure how to interpet the random effects yielded by lmer.  
Also, the design matrix is redundant and this redundancy makes these 
models more difficult to fit, which is somewhat paradoxical since the 
intention is to simplify the correlation structure.

I think that I understand how the design matrix Z is produced (i.e., by 
binding together the terms that are specifed between parenthesis)  even 
though
there are some cases  where I am not sure because the results for fixed 
and random effects are different (see the example with the interaction 
below).

My question is whether the design matrix  Z specified by these formulae 
make sense in this context and how to interpret the results if it does?

I could not find any discussion of these issues behond the simple case 
of  removing correlation betweenintercept and slope  of a continuous 
covariate.

As I said above, fitting a model maximal random effect structure with  
Y~A*B+(A*B|S) yields the expected variance-covariance matrix

Groups   Name        Std.Dev. Corr
  S        (Intercept) 1.90664
           A1          0.71938 0.710
           A2          0.63624  -1.000 -0.727
           B1          0.38072  -0.613 -0.992 0.632
           A1:B1       0.51257  -0.394 -0.927  0.416 0.968
           A2:B1       0.62905  -0.972 -0.855  0.978 0.781  0.598
  Residual             2.07002

The corresponding design matrix Z for one subject is

       (Intercept) A1 A2 B1 A1:B1 A2:B1
  [1,]           1  1  .  1     1     .
  [2,]           1  1  .  1     1     .
  [3,]           1  1  . -1    -1     .
  [4,]           1  1  . -1    -1     .
  [5,]           1  .  1  1     .     1
  [6,]           1  .  1  1     .     1
  [7,]           1  .  1 -1     .    -1
  [8,]           1  .  1 -1     .    -1
  [9,]           1 -1 -1  1    -1    -1
[10,]           1 -1 -1  1    -1    -1
[11,]           1 -1 -1 -1     1     1
[12,]           1 -1 -1 -1     1     1

where columns A1, A2 and B1 corresponds to the expected sum contrasts. 
This matrix is the same as the design matrix for the fixed effects.

To  remove correlations between the intercept A, B and A:B interaction 
terms, I tried    Y~A*B+(1|S) + (A|S)  + (B|S)  + (A:B|S).

Groups   Name        Std.Dev. Corr
  S        (Intercept) 2.5421e-08
  S.1      (Intercept) 2.1751e-07
           A1          9.1658e-08 0.992
           A2          3.1944e-07 -0.991 -0.970
  S.2      (Intercept) 6.5355e-08
           B1          1.2692e-07 1.000
  S.3      (Intercept) 1.8430e+00
           A1:B1       1.8613e-01 0.828
           A2:B1       1.4158e+00 -0.959 -0.802
           A3:B1       7.9928e-01  0.957  0.901 -0.981
           A1:B2       1.8497e+00  0.433  0.457 -0.668 0.640
           A2:B2       7.5347e-01  0.252  0.347 -0.509 0.491  0.980
           A3:B2       6.7337e-01 -0.439 -0.353  0.674 -0.610 -0.981 -0.947
  Residual             2.0700e+00           1.8845e+00

I did not get the expected results. This removed correlation between the 
terms but also additional  (redundant) intercepts terms.  Moreover, the 
interaction terms includes not only an intercept but also every 
combination between the factor A and B. The design matrix is

       (Intercept) (Intercept) A1 A2 (Intercept) B1 (Intercept) A1:B1 
A2:B1 A3:B1 A1:B2 A2:B2 A3:B2
  [1,]           1           1  1  .           1 1           1     1     
.     .     .     .     .
  [2,]           1           1  1  .           1 1           1     1     
.     .     .     .     .
  [3,]           1           1  1  .           1 -1           1     
.     .     .     1     .     .
  [4,]           1           1  1  .           1 -1           1     
.     .     .     1     .     .
  [5,]           1           1  .  1           1 1           1     .     
1     .     .     .     .
  [6,]           1           1  .  1           1 1           1     .     
1     .     .     .     .
  [7,]           1           1  .  1           1 -1           1     
.     .     .     .     1     .
  [8,]           1           1  .  1           1 -1           1     
.     .     .     .     1     .
  [9,]           1           1 -1 -1           1 1           1     .     
.     1     .     .     .
[10,]           1           1 -1 -1           1 1           1     .     
.     1     .     .     .
[11,]           1           1 -1 -1           1 -1           1     .     
.     .     .     .     .
[12,]           1           1 -1 -1           1 -1           1     .     
.     .     .     .     .

Note that column A1, B2, B1 correspond to the contrasts. For the 
intercation term, a different coding (dummy variables)
is used and an intercept term is added (this is quite surprising since 
A:B for fixed effect yields a different matrix).

If this matrix makes sense, how should I interpret the variance estimate 
associated with the intercept? Should simply
consider the sum as the estimate of the between subject variability? Is 
the split between the different terms
well defined ?

To  remove intercepts, I tried    Y~A*B+(1|S) + (A-1|S)  + (B-1|S)  + 
(A:B-1|S).  This yields

  Groups   Name        Std.Dev.   Corr
  S        (Intercept) 3.2644e-07
  S.1      A1 0.0000e+00
           A2          1.0269e-07 0.992
           A3          2.6214e-07 -0.9920.366
  S.2      B1 0.0000e+00
           B2          5.2044e-08 0.992
  S.3      A1:B1 1.9998e+00
           A2:B1       6.2886e-01 0.768
           A3:B1       2.6180e+00 0.998 0.724
           A1:B2       3.1261e+00 0.850 0.316 0.883
           A2:B2       2.1594e+00 0.944 0.516 0.964 0.976
           A3:B2       1.6618e+00 0.930 0.949 0.904 0.598 0.758
  Residual             2.0700e+00

and
       (Intercept) A1 A2 A3 B1 B2 A1:B1 A2:B1 A3:B1 A1:B2 A2:B2 A3:B2
  [1,]           1  1  .  .  1  .     1     .     . .     .     .
  [2,]           1  1  .  .  1  .     1     .     . .     .     .
  [3,]           1  1  .  .  .  1     .     .     . 1     .     .
  [4,]           1  1  .  .  .  1     .     .     . 1     .     .
  [5,]           1  .  1  .  1  .     .     1     . .     .     .
  [6,]           1  .  1  .  1  .     .     1     . .     .     .
  [7,]           1  .  1  .  .  1     .     .     . .     1     .
  [8,]           1  .  1  .  .  1     .     .     . .     1     .
  [9,]           1  .  .  1  1  .     .     .     1 .     .     .
[10,]           1  .  .  1  1  .     .     .     1 .     .     .
[11,]           1  .  .  1  .  1     .     .     . .     .     1
[12,]           1  .  .  1  .  1     .     .     . .     .     1

The intercept are indeed removed but each factor is dummy coded. 
Contrasts are not used anymore. This matrix is still rank deficient
and this model is still more difficult to fit than the original (A*B|S) 
model.

To summarize, I find the random effects of lmer difficult to interpret 
when using the formula (1|S) + (A-1|S)  + (B-1|S)  + (A:B-1|S) or (1|S) 
+ (A|S)  + (B|S)  + (A:B|S) . Moreover, their redundancy make them more 
difficult to fit than the (A*B|S).

I expected that (1|S) + (A-1|S)  + (B-1|S)  + (A:B-1|S) would all yield 
random effect structure that correspond to the fixed effects like when 
using (A*B|S) (see above) with a correlation structure like

  Groups   Name        Std.Dev.   Corr
  S        (Intercept) 3.2644e-07
  S.1      A1 0.0000e+00
           A2          1.0269e-07 0.992
  S.2      B1 0.0000e+00
  S.3      A1:B1 1.9998e+00
           A2:B1       6.2886e-01 0.768
  Residual             2.0700e+00

I was not sure what I was expecting with   (A|S)  + (B|S)  + (A:B|S) but 
it would be nice if there was a way to specificy a covariance

Groups   Name        Std.Dev.   Corr
  S        (Intercept) 3.2644e-07
A1          1.0269e-07 0.992
           A2          2.6214e-07 -0.9920.366
  S.1 B1          5.2044e-08 0.992
  S.2    A1:B1       6.2886e-01 0.768
           A2:B1       2.6180e+00 0.998 0.724
Residual             2.0700e+00

This would allow one to specify correlated random effects between the 
subject intercept and the various conditions while excluding
correlated random effects between the conditions (this appear quite fare 
from what is possible to do with lmer syntax(.

Best,

Gabriel

-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From John.Morrongiello at csiro.au  Tue Oct  8 00:41:23 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Mon, 7 Oct 2013 22:41:23 +0000
Subject: [R-sig-ME] intraclass correlation (ICC) for random intercept
 and slope model
Message-ID: <2547E22D246F3945BB491BDD8257C2E77DABBF25@exmbx06-cdc.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131007/9742579b/attachment.pl>

From drmccloy at uw.edu  Tue Oct  8 01:46:00 2013
From: drmccloy at uw.edu (Dan McCloy)
Date: Mon, 7 Oct 2013 16:46:00 -0700
Subject: [R-sig-ME] errors compiling minqa during lme4 install
Message-ID: <CAOE0pYkCPonsdCoysGZLNqnHTourC6JTG9tU-ny4u9i+8he6nw@mail.gmail.com>

You nailed it Ben!  I think lines 22 and 24 of the gist
(https://gist.github.com/drammock/6860963) ought to be all one line,
and same for lines 46 and 48.  If I manually combine them and run them
in bash myself, I don't get an error.  I have no idea how the extra
line breaks are getting introduced, but I'll send mail to minqa and
RcppEigen maintainers.  Thanks all for your help.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington


From j.hadfield at ed.ac.uk  Tue Oct  8 12:23:22 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 08 Oct 2013 11:23:22 +0100
Subject: [R-sig-ME] MCMCglmm random intercept/slope model and credible
 intervals
In-Reply-To: <loom.20131007T144006-569@post.gmane.org>
References: <loom.20131007T144006-569@post.gmane.org>
Message-ID: <20131008112322.10614wisq3r0w84k@www.staffmail.ed.ac.uk>

Hi,

There is a bug in predict.MCMCglmm for random regression models. I've  
corrected it in the unreleased version, but you can change it easy  
enough:

Change

M[,which(rm.v),]<-0

on L65 to

M[,which(rm.v)]<-0


Also, this model will not give sensible results. You need to use  
something like:

R = list(V = 1, fix=1)

in the prior for the residual variance (it cannot be estimated from  
the data with categorical data)

Also,

G = list(G1 = list(V = diag(2), nu = 6)))

is pretty informative, unless you have a lot of data and replication  
at the right level.

Cheers,

Jarrod


Quoting Maya <maiski at maiski.net> on Mon, 7 Oct 2013 12:52:06 +0000 (UTC):

> Hello all,
>
> i have the following problem.
> I want to fit a GLMM with a numerical fixed effect, a factorial random
> effect, containing subject ids and a binary outcome. My code is:
>
> fam='categorical'
>
> priors1<-list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V = diag(2),
> nu = 6)))
>
> modelGlmm1<- MCMCglmm(toModel ~ fixedEffect,
> random=~us(1+fixedEffect):randomEffect, data=data, verbose=FALSE,
> family=fam, pr=TRUE, pl=TRUE, nitt=nittM, thin=thinM, burnin=burninM,
> prior=priors1)
>
> mp1 = predict(modelGlmm1, interval = 'confidence')
>
>
> But as I try to get the credible intervals I get the following error:
> Error in M[, which(rm.v), ] <- 0 : incorrect number of subscripts.
>
> Could anybody give me some hints or enlighten me on the subject? I cannot
> figure it out by myself :/
>
> I have also another question: How are the credible intervals constructed:
> pointwise or simultaniously?
>
> Thanks in advance!
>
> Greets,
>
> Maya
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Adrien.Combaz at med.kuleuven.be  Tue Oct  8 14:06:19 2013
From: Adrien.Combaz at med.kuleuven.be (Adrien Combaz)
Date: Tue, 8 Oct 2013 12:06:19 +0000
Subject: [R-sig-ME] model for clustered longitudinal binary data
Message-ID: <224EC811FF648D4A808A1381957BEBF3106A9A4E@ICTS-S-MBX5.luna.kuleuven.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131008/6812b7f5/attachment.pl>

From bbolker at gmail.com  Tue Oct  8 15:31:49 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Oct 2013 13:31:49 +0000 (UTC)
Subject: [R-sig-ME] stability of glmmADMB
References: <loom.20131005T233314-978@post.gmane.org>
Message-ID: <loom.20131008T003135-871@post.gmane.org>

Pau Boon Kee <keepauboon at ...> writes:

> 
> Dear all
> 
> I have an enquiry on the stability of the glmm AD model builder package in R.
> 
> I wonder if anyone can shed some light on the possible reasons as to 
> why the results, estimated coefficients, 
> generated by two different operating systems, window 7 and OS X, 
> are different to a certain extent.
> 
> To a certain extent I meant, the directions
>  of correlation are still the same, 
> but the figures can be quite significantly different.
> 
> The following are my results:
> 
> windows 7:
> 
> intercept: -2.245552***
> link_DIS_mm: -0.021536
> landlock: 1.294218*** 
> 
> OS X:
> 
> intercept: -2.103106**
> link_DIS_MM: -0.029175
> landlock: 1.195673**
> 

  It's hard to say in general.  I agree that these
differences are a bit too big to be ascribed to 
numerical 'fuzz' alone, but they don't look big
enough to cause big differences in the interpretation;
what does "quite significantly different" mean?
How big are the estimated standard errors of these
estimates? How big are the differences in the 
maximum log-likelihoods between the two different
fits?


From bbolker at gmail.com  Wed Oct  9 03:04:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 01:04:23 +0000 (UTC)
Subject: [R-sig-ME] model for clustered longitudinal binary data
References: <224EC811FF648D4A808A1381957BEBF3106A9A4E@ICTS-S-MBX5.luna.kuleuven.be>
Message-ID: <loom.20131009T025751-477@post.gmane.org>

Adrien Combaz <Adrien.Combaz at ...> writes:

> 
> Dear list members,


[snip]

> I measure a longitudinal binary outcome (correctness of detection,
> 0: incorrect, 1: correct) with respect to 5 different experimental
> conditions (1 baseline and 4 treatments). The outcome is always
> measured at the same 10 time points. Each of the 9 subjects
> participated in all 5 conditions.  Additionally, for each subject
> and condition, the experiment was replicated 36 times. I therefore
> end up with 9*5*36=1620 binary longitudinal series (= trials of 10
> points each).
 
> My aim is to assess the influence of the experimental condition on
> my binary outcome. I need to build a model that would take into
> consideration the correlation along time for a given trial and the
> correlation among trials for a given subject.

  Correlation among trials for a given subject should be straightforward,
correlation along time for a given trial may be difficult (see below).
 
> I am considering a 3 levels logistic models where 10 consecutive
> binary measurements (level 1) are obtained on replicates (level 2)
> which are clustered into subjects (level 3). My only level 1
> covariate would be the time of measurement (ordinal factor, T = 1,
> ..., 10) and as level 2 covariate, I consider the experimental
> condition. I don't consider any level 3 covariate per se, but still
> want the model to account for between-subject variability.

This all seems reasonable.  If you really want time to be treated
as ordinal, you'll want to look at the clmm function from the 'ordinal'
package.  In most R modeling packages you don't need to state
explicitly which levels the covariates are measured at (but keeping
track of it is of course useful for thinking about issues of
identifiability, etc.)

A simple model would be something like

 response ~ time + expcond + (1|rep/sub)

As a more complete model you could consider

 response ~ time + expcond + (time|rep/sub) + (expcond|sub)


From John.Morrongiello at csiro.au  Wed Oct  9 05:20:17 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Wed, 9 Oct 2013 03:20:17 +0000
Subject: [R-sig-ME] plot log transformed variable with Effects package
Message-ID: <2547E22D246F3945BB491BDD8257C2E77DAC43B1@exmbx03-cdc.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131009/6c75775d/attachment.pl>

From alku at dtu.dk  Wed Oct  9 10:44:10 2013
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Wed, 9 Oct 2013 08:44:10 +0000
Subject: [R-sig-ME] bug in refit function?
Message-ID: <0566E17B6DEC62459078112371B7508E0E3024@ait-pex02mbx05.win.dtu.dk>


Hi all,

If I apply update function on the refit function, then the refitted model becomes the initial model. The example:

> set.seed(101)
> Y <- matrix(rnorm(1000),ncol=2)
> d <- data.frame(y1=Y[,1],  x=rnorm(100), f=rep(1:10,10))
> fit1 <- lmer(y1 ~ x+(1|f),data=d)
> fit2 <- refit(fit1, newresp = Y[,2])
> all.equal(fit1, update(fit2))
[1] TRUE

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252    LC_MONETARY=Danish_Denmark.1252
[4] LC_NUMERIC=C                    LC_TIME=Danish_Denmark.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_1.0-4      Matrix_1.0-12   lattice_0.20-15

loaded via a namespace (and not attached):
[1] grid_3.0.1    MASS_7.3-26   minqa_1.2.1   nlme_3.1-109  splines_3.0.1 tools_3.0.1  


Probably this is a bug?

Alexandra

From Adrien.Combaz at med.kuleuven.be  Wed Oct  9 16:00:14 2013
From: Adrien.Combaz at med.kuleuven.be (Adrien Combaz)
Date: Wed, 9 Oct 2013 14:00:14 +0000
Subject: [R-sig-ME] model for clustered longitudinal binary data
In-Reply-To: <loom.20131009T025751-477@post.gmane.org>
References: <224EC811FF648D4A808A1381957BEBF3106A9A4E@ICTS-S-MBX5.luna.kuleuven.be>
	<loom.20131009T025751-477@post.gmane.org>
Message-ID: <224EC811FF648D4A808A1381957BEBF3106A9B27@ICTS-S-MBX5.luna.kuleuven.be>


Thanks Ben for your reply,

> >
> > Dear list members,
> 
> 
> [snip]
> 
> > I measure a longitudinal binary outcome (correctness of detection,
> > 0: incorrect, 1: correct) with respect to 5 different experimental
> > conditions (1 baseline and 4 treatments). The outcome is always
> > measured at the same 10 time points. Each of the 9 subjects
> > participated in all 5 conditions.  Additionally, for each subject and
> > condition, the experiment was replicated 36 times. I therefore end up
> > with 9*5*36=1620 binary longitudinal series (= trials of 10 points
> > each).
> 
> > My aim is to assess the influence of the experimental condition on my
> > binary outcome. I need to build a model that would take into
> > consideration the correlation along time for a given trial and the
> > correlation among trials for a given subject.
> 
>   Correlation among trials for a given subject should be straightforward,
> correlation along time for a given trial may be difficult (see below).

Yes, this is my main issue.

> 
> > I am considering a 3 levels logistic models where 10 consecutive
> > binary measurements (level 1) are obtained on replicates (level 2)
> > which are clustered into subjects (level 3). My only level 1 covariate
> > would be the time of measurement (ordinal factor, T = 1, ..., 10) and
> > as level 2 covariate, I consider the experimental condition. I don't
> > consider any level 3 covariate per se, but still want the model to
> > account for between-subject variability.
> 
> This all seems reasonable.  If you really want time to be treated as ordinal,
> you'll want to look at the clmm function from the 'ordinal'
> package.  In most R modeling packages you don't need to state explicitly
> which levels the covariates are measured at (but keeping track of it is of
> course useful for thinking about issues of identifiability, etc.)

I am not sure to understand how I can use the clmm function, I am not familiar with it but from what I could read, it is used to fit cumulative link models for an ordinal response variable, while in my case time is not the response variable but a factor (and my response variable is binary).

I preferred to treat time as discrete factor rather than a continuous variable for 2 reasons:
1) it represents a number of cycles which is discrete and ordered by nature
2) on average, the correctness (logit) increases with time, but the relationship is nonlinear. It means that, if I use the time as a continuous variable, I should choose an adequate transformation to obtain a linear relationship, which can be very subjective. Since my main objective is to study the influence of the experimental condition, I didn't really want to go there.

> 
> A simple model would be something like
> 
>  response ~ time + expcond + (1|rep/sub)

I tried something like that with the lmer function, only difference is that I had as random effect (1|sub/rep). I thought that it was the proper syntax for replicates nested within subjects, giving a random intercept for each subject and for each replicate within subject. Am I missing something?

> 
> As a more complete model you could consider
> 
>  response ~ time + expcond + (time|rep/sub) + (expcond|sub)

With such a model where expcond is also used to define the random effect structure, can I use the anova function to compare it to the following "null model":
response ~ time + (time|rep/sub) + (expcond|sub)
and make a statement on the significance of the effect of the experiment condition?

> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Oct  9 19:45:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 17:45:19 +0000 (UTC)
Subject: [R-sig-ME] plot log transformed variable with Effects package
References: <2547E22D246F3945BB491BDD8257C2E77DAC43B1@exmbx03-cdc.nexus.csiro.au>
Message-ID: <loom.20131009T191009-198@post.gmane.org>

 <John.Morrongiello at ...> writes:

> 
> Hi list
> 
> I'm having trouble plotting a mixed model that includes log transformed
(or any transformed) terms.
> 
library(lme4)
library(effects)
data(cake, package="lme4")
> 
> ###this works
fm1 <- lmer(angle ~ recipe * temperature
 + (1|recipe:replicate), 
  cake, REML = FALSE)

plot(Effect(c('recipe','temperature'), fm1))
##but this doesn't (log transformed angle)

fm2 <- lmer(log(angle) ~ recipe * temperature + (1|recipe:replicate), 
 cake, REML = FALSE)

plot(Effect(c('recipe','temperature'), fm2))
> 
> ###returns the error:
 
> Error in plot(Effect(c("recipe", "temperature"), fm2)) :
> 
> error in evaluating the argument 'x' in selecting a method for function
> 'plot': Error in eval(expr, envir,
> enclos) : object 'angle' not found
> 
> However, including log-transformed terms works for a simple linear model
> 
> mod <- lm(log(prestige) ~ income*type, data=Prestige)
> 
> plot(Effect(c("income","type"), mod))
 
> Including a function in a model (e.g. fm2) used to work in an older
> version of the 'effects' package (sorry can't version) but obviously
> not anymore. Any thoughts on how to get fm2 to work without having
> to transform variables beforehand, if it is indeed still possible?

  This is probably something to take up with the maintainer of
the 'effects' package, who in turn might have to consult the lme4
maintainers.  The proximal problem occurs in 

  plot -> Effect -> Effect.merMod -> Effect.mer -> Effect ->
mer.to.glm

  There is a 'data' object that appears to be coming from the
model.frame() of the original object, but I haven't tracked its
source down yet -- but the problem is that it has log(angle) rather
than angle as a column ...


From bbolker at gmail.com  Wed Oct  9 19:47:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 17:47:53 +0000 (UTC)
Subject: [R-sig-ME] bug in refit function?
References: <0566E17B6DEC62459078112371B7508E0E3024@ait-pex02mbx05.win.dtu.dk>
Message-ID: <loom.20131009T194714-554@post.gmane.org>

Alexandra Kuznetsova <alku at ...> writes:

> 
> 
> Hi all,
> 
> If I apply update function on the refit function, then the refitted model
becomes the initial model. The example:
> 
> > set.seed(101)
> > Y <- matrix(rnorm(1000),ncol=2)
> > d <- data.frame(y1=Y[,1],  x=rnorm(100), f=rep(1:10,10))
> > fit1 <- lmer(y1 ~ x+(1|f),data=d)
> > fit2 <- refit(fit1, newresp = Y[,2])
> > all.equal(fit1, update(fit2))
> [1] TRUE
> 

  Thanks.  The problem is that update() works by evaluating
the @call slot, which doesn't get updated by refit.  We'll work
on this.

  Ben Bolker


From bayes.student at gmail.com  Wed Oct  9 21:45:02 2013
From: bayes.student at gmail.com (Bayes Student)
Date: Wed, 9 Oct 2013 15:45:02 -0400
Subject: [R-sig-ME] random slopes and intercepts using glmmadmb - negative
	binomial
Message-ID: <CAHNXKh5BK4X82v5jyO2=9v+R1mVE-4PM12gq2g0zGzo4byQ6pw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131009/66f17968/attachment.pl>

From bbolker at gmail.com  Wed Oct  9 23:46:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 21:46:19 +0000 (UTC)
Subject: [R-sig-ME] model for clustered longitudinal binary data
References: <224EC811FF648D4A808A1381957BEBF3106A9A4E@ICTS-S-MBX5.luna.kuleuven.be>
	<loom.20131009T025751-477@post.gmane.org>
	<224EC811FF648D4A808A1381957BEBF3106A9B27@ICTS-S-MBX5.luna.kuleuven.be>
Message-ID: <loom.20131009T234119-79@post.gmane.org>

Adrien Combaz <Adrien.Combaz at ...> writes:


[snip]

> > > I measure a longitudinal binary outcome (correctness of detection,
> > > 0: incorrect, 1: correct) with respect to 5 different experimental
> > > conditions (1 baseline and 4 treatments). The outcome is always
> > > measured at the same 10 time points. Each of the 9 subjects
> > > participated in all 5 conditions.  Additionally, for each subject and
> > > condition, the experiment was replicated 36 times. I therefore end up
> > > with 9*5*36=1620 binary longitudinal series (= trials of 10 points
> > > each).

[snip]

> >   Correlation among trials for a given subject 
> should be straightforward,
> > correlation along time for a given trial may be difficult (see below).
> 
> Yes, this is my main issue.

  I forgot to say that unless you are explicitly interested
in the estimated correlation structure, you could hope to get
around this by fitting the model without correlation and then
showing that the temporal autocorrelation in the residuals is
negligible ....


> > > I am considering a 3 levels logistic models where 10 consecutive
> > > binary measurements (level 1) are obtained on replicates (level 2)
> >> which are clustered into subjects (level 3). My only level 1 covariate
> > > would be the time of measurement (ordinal factor, T = 1, ..., 10) and
> > > as level 2 covariate, I consider the experimental condition. I don't
> > > consider any level 3 covariate per se, but still want the model to
> > > account for between-subject variability.

> > This all seems reasonable.  If you really want time to be treated
> > as ordinal, you'll want to look at the clmm function from the
> > 'ordinal' package.   

[snip]

> I am not sure to understand how I can use the clmm function, I am
> not familiar with it but from what I could read, it is used to fit
> cumulative link models for an ordinal response variable, while in my
> case time is not the response variable but a factor (and my response
> variable is binary).

 You're right, my bad.  The only difference between ordered and
unordered factors in the standard R approach to model-fitting is
that by default, treatment contrasts are used for unordered and
orthogonal polynomial contrasts are used for ordered factors.  Another
perhaps underused option is to specify successive-differences
contrasts, using the contr.sdif() function in the MASS package.
None of these will make a difference in the overall complexity or
fit of the model, just in the interpretation of the parameters.

> I preferred to treat time as discrete factor rather than a
> continuous variable for 2 reasons: 1) it represents a number of
> cycles which is discrete and ordered by nature 2) on average, the
> correctness (logit) increases with time, but the relationship is
> nonlinear. It means that, if I use the time as a continuous
> variable, I should choose an adequate transformation to obtain a
> linear relationship, which can be very subjective. Since my main
> objective is to study the influence of the experimental condition, I
> didn't really want to go there.

> > A simple model would be something like
> > 
> >  response ~ time + expcond + (1|rep/sub)

> I tried something like that with the lmer function, only difference
> is that I had as random effect (1|sub/rep). I thought that it was
> the proper syntax for replicates nested within subjects, giving a
> random intercept for each subject and for each replicate within
> subject. Am I missing something?

  No, my bad again.  it should be sub/rep

> 
> > 
> > As a more complete model you could consider
> > 
> >  response ~ time + expcond + (time|rep/sub) + (expcond|sub)

> With such a model where expcond is also used to define the random
> effect structure, can I use the anova function to compare it to the
> following "null model": response ~ time + (time|rep/sub) +
> (expcond|sub) and make a statement on the significance of the effect
> of the experiment condition? 

  Yes.


From bbolker at gmail.com  Wed Oct  9 23:50:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 21:50:41 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?random_slopes_and_intercepts_using_glmmadmb_?=
	=?utf-8?q?-_negative=09binomial?=
References: <CAHNXKh5BK4X82v5jyO2=9v+R1mVE-4PM12gq2g0zGzo4byQ6pw@mail.gmail.com>
Message-ID: <loom.20131009T234706-470@post.gmane.org>

Bayes Student <bayes.student at ...> writes:

> 
> Hello,
> I am new to mixed modeling and using the glmmadmb package. I am interested
> in using glmmadmb to model count data with a negative binomial
> distribution, using year and site sampled as my random
>  effect variables, as
> both should be allowed to vary independently. I would like to consider
> random intercepts for both factors, but also random
>  slopes for sites across
> all years. I am not sure how to code this in R, and have tried several
> different ways. Usually R just takes a super long time and
>  does not seem to
> complete the computation - which leads me to think my syntax is incorrect.
> Any suggestions/ thoughts would be greatly appreciated! 
> I'm using Windows 7
> with RStudio v.0.98.312.

  The version of R and glmmADMB are more relevant than the version of
RStudio, for what it's worth.


> 
> Here is what works - random intercepts model:
> 
>        mod <- glmmadmb(species~(1|year)+(1|site),data=cs,
>        family="nbinom2",link="log")
> 
> Here are some iterations I have tried which did not seem to work:
> 
>       mod <- glmmadmb(species~(1+site|year)+(1|site),data=cs,...)
>       mod <- glmmadmb(species~(site|year)+(1|site),data=cs,...)
>       mod <- glmmadmb(species~(1|year)+(1|site)+(0|site),data=cs,...)
> 

  [snip]

I think you're looking for species ~ year + (1|year) + (year|site) ,
equivalent to species ~ year + (1|year) + (1+year|site)

In the syntax (A|B), B is the *grouping variable* and A represents
the factor or factors that vary among groups.  The slight oddity
of this model is that year appears three times, once as a main effect
(the overall log-linear effect of year), once as a grouping variable
(the year-by-year variation across all sites around the log-linear
trend) and once as a random effect (the random variation of log-linear
trend among sites).


From bbolker at gmail.com  Thu Oct 10 00:16:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Oct 2013 22:16:43 +0000 (UTC)
Subject: [R-sig-ME] plot log transformed variable with Effects package
References: <2547E22D246F3945BB491BDD8257C2E77DAC43B1@exmbx03-cdc.nexus.csiro.au>
	<loom.20131009T191009-198@post.gmane.org>
Message-ID: <loom.20131010T001609-902@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
>  <John.Morrongiello <at> ...> writes:
> 
> > 
> > Hi list
> > 
> > I'm having trouble plotting a mixed model that includes log transformed
> (or any transformed) terms.
> > 
> library(lme4)
> library(effects)
> data(cake, package="lme4")
> > 
> > ###this works
> fm1 <- lmer(angle ~ recipe * temperature
>  + (1|recipe:replicate), 
>   cake, REML = FALSE)
> 
> plot(Effect(c('recipe','temperature'), fm1))
> ##but this doesn't (log transformed angle)
> 
> fm2 <- lmer(log(angle) ~ recipe * temperature + (1|recipe:replicate), 
>  cake, REML = FALSE)
> 
> plot(Effect(c('recipe','temperature'), fm2))
>   This is probably something to take up with the maintainer of
> the 'effects' package, who in turn might have to consult the lme4
> maintainers.  The proximal problem occurs in 
> 
>   plot -> Effect -> Effect.merMod -> Effect.mer -> Effect ->
> mer.to.glm
> 
>   There is a 'data' object that appears to be coming from the
> model.frame() of the original object, but I haven't tracked its
> source down yet -- but the problem is that it has log(angle) rather
> than angle as a column ...
> 
> 

  with a bit more work, I have come up with a way to
hack the effects package to make this work.  The function below
needs to be defined, then the arguments of the effects:::mer.to.glm
function have to be changed from

function(mod, data=model.frame(mod))

to

function(mod, data=xdata(mod))

You can hack the package yourself and/or request the maintainer
to add this capability ...
                                    
## modeled after stats::expand.model.frame
## expand the model frame to include any variables present
## in the original 'data' object but missing from the model frame
## potentially fragile:
##  * depends on 'data' still being present in the original environment
##  * doesn't check for any potential mishaps
xdata <- function(model, envir=environment(formula(model))) {
    fr <- model.frame(model)
    data <- eval(getCall(model)$data,envir)
    ## find missing variables
    newvars <- setdiff(all.vars(formula(model)),names(fr))
    if (length(newvars)>0) {
        fr <- data.frame(fr,data[newvars],check.names=FALSE)
    }
    fr
}


From zhangyf at affrc.go.jp  Thu Oct 10 02:06:36 2013
From: zhangyf at affrc.go.jp (Tetsuya Michinaka)
Date: Thu, 10 Oct 2013 09:06:36 +0900
Subject: [R-sig-ME] How to explain the difference of variables in random
	effects component
In-Reply-To: <mailman.2889.1381355718.4612.r-sig-mixed-models@r-project.org>
References: <mailman.2889.1381355718.4612.r-sig-mixed-models@r-project.org>
Message-ID: <5255EF8C.2030203@affrc.go.jp>

Hi all,

I am fitting a very simple linear mixed model by using lme4. It is like 
this:
ModelA<-lmer(TF~ P*A + (1| DistrictID),data, REML=TRUE)
ModelB<-lmer(TF~ P*A + (1+AREA| DistrictID),data, REML=TRUE)
ModelC<-lmer(TF~ P*A + (1+Distance| DistrictID),data, REML=TRUE)

By checking AIC and BIC, it is found that ModelB seems to be the best. 
Could you please tell me how to explain the the impacts of AREA and 
Distance?
The objective is to know the impacts of P and A on TF. AREA and Distance 
are characteristics of the district, therefore, they are added in the 
random effects component.
I am new for mixed model. Could you please help me?

Thanks.

Tetsuya


From jfox at mcmaster.ca  Thu Oct 10 05:01:24 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 09 Oct 2013 23:01:24 -0400
Subject: [R-sig-ME] plot log transformed variable with Effects package
In-Reply-To: <loom.20131010T001609-902@post.gmane.org>
References: <2547E22D246F3945BB491BDD8257C2E77DAC43B1@exmbx03-cdc.nexus.csiro.au>
	<loom.20131009T191009-198@post.gmane.org>
	<loom.20131010T001609-902@post.gmane.org>
Message-ID: <web-477900353@cgpsrv2.cis.mcmaster.ca>

Dear Ben,

This problem is already fixed in the development version of the effects package on R-Forge. We expect to move this version to CRAN soon, but in the interim, it can be installed via install.packages("effects", repos="http://R-Forge.R-project.org").

I hope this helps,
 John

On Wed, 9 Oct 2013 22:16:43 +0000 (UTC)
 Ben Bolker <bbolker at gmail.com> wrote:
> Ben Bolker <bbolker at ...> writes:
> 
> > 
> >  <John.Morrongiello <at> ...> writes:
> > 
> > > 
> > > Hi list
> > > 
> > > I'm having trouble plotting a mixed model that includes log transformed
> > (or any transformed) terms.
> > > 
> > library(lme4)
> > library(effects)
> > data(cake, package="lme4")
> > > 
> > > ###this works
> > fm1 <- lmer(angle ~ recipe * temperature
> >  + (1|recipe:replicate), 
> >   cake, REML = FALSE)
> > 
> > plot(Effect(c('recipe','temperature'), fm1))
> > ##but this doesn't (log transformed angle)
> > 
> > fm2 <- lmer(log(angle) ~ recipe * temperature + (1|recipe:replicate), 
> >  cake, REML = FALSE)
> > 
> > plot(Effect(c('recipe','temperature'), fm2))
> >   This is probably something to take up with the maintainer of
> > the 'effects' package, who in turn might have to consult the lme4
> > maintainers.  The proximal problem occurs in 
> > 
> >   plot -> Effect -> Effect.merMod -> Effect.mer -> Effect ->
> > mer.to.glm
> > 
> >   There is a 'data' object that appears to be coming from the
> > model.frame() of the original object, but I haven't tracked its
> > source down yet -- but the problem is that it has log(angle) rather
> > than angle as a column ...
> > 
> > 
> 
>   with a bit more work, I have come up with a way to
> hack the effects package to make this work.  The function below
> needs to be defined, then the arguments of the effects:::mer.to.glm
> function have to be changed from
> 
> function(mod, data=model.frame(mod))
> 
> to
> 
> function(mod, data=xdata(mod))
> 
> You can hack the package yourself and/or request the maintainer
> to add this capability ...
>                                     
> ## modeled after stats::expand.model.frame
> ## expand the model frame to include any variables present
> ## in the original 'data' object but missing from the model frame
> ## potentially fragile:
> ##  * depends on 'data' still being present in the original environment
> ##  * doesn't check for any potential mishaps
> xdata <- function(model, envir=environment(formula(model))) {
>     fr <- model.frame(model)
>     data <- eval(getCall(model)$data,envir)
>     ## find missing variables
>     newvars <- setdiff(all.vars(formula(model)),names(fr))
>     if (length(newvars)>0) {
>         fr <- data.frame(fr,data[newvars],check.names=FALSE)
>     }
>     fr
> }
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From chevillot.xavier at live.fr  Thu Oct 10 10:21:58 2013
From: chevillot.xavier at live.fr (xavier chevillot)
Date: Thu, 10 Oct 2013 10:21:58 +0200
Subject: [R-sig-ME] Help with Delta-gamma Glmm
In-Reply-To: <DUB115-W36E7326929697C30EA5E94831E0@phx.gbl>
References: <DUB115-W36E7326929697C30EA5E94831E0@phx.gbl>
Message-ID: <DUB115-W45784E6B52451958600F34831E0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131010/09368faa/attachment.pl>

From mhnunes at fc.ul.pt  Thu Oct 10 12:39:32 2013
From: mhnunes at fc.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Thu, 10 Oct 2013 11:39:32 +0100
Subject: [R-sig-ME] Random intercepts and/or slopes
Message-ID: <CE9565EEC2A21641A7FF431FBCB78892BE816674D1@FC-MBXCLUSTER.fc.ul.pt>

Dear all,

I?m new to mixed models, and I?m analysing a patients? data set whose response variable is adherence/no adherence to medication (binary variable, 0/1). For each patient there are different types of independent variables: sociodemographic; clinical; blood pressure control; etc. Additionally, patients are grouped (nested) within doctors. Due to the sampling design, I only have one replicate for each patient.

I want to study the impact of the independent variables on the adherence/no adherence to medication.  I?m not interested in studying the patients by themselves.
My question is: should I consider the simplest model     response  ~  Indep. Variables +  (1|Doctor),
or  should I explicitly introduce the nested structure of patient within doctor,   response ~ Indep. Variables + (Patient|Doctor) ?


Thanks in advanced!

Best regards,
Helena.


From baud-bovy.gabriel at hsr.it  Thu Oct 10 13:47:56 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Thu, 10 Oct 2013 13:47:56 +0200
Subject: [R-sig-ME] Random intercepts and/or slopes
In-Reply-To: <CE9565EEC2A21641A7FF431FBCB78892BE816674D1@FC-MBXCLUSTER.fc.ul.pt>
References: <CE9565EEC2A21641A7FF431FBCB78892BE816674D1@FC-MBXCLUSTER.fc.ul.pt>
Message-ID: <525693EC.30806@hsr.it>

On 10/10/2013 12:39 PM, Maria Helena Mourino Silva Nunes wrote:
> Dear all,
>
> I?m new to mixed models, and I?m analysing a patients? data set whose response variable is adherence/no adherence to medication (binary variable, 0/1). For each patient there are different types of independent variables: sociodemographic; clinical; blood pressure control; etc. Additionally, patients are grouped (nested) within doctors. Due to the sampling design, I only have one replicate for each patient.
>
> I want to study the impact of the independent variables on the adherence/no adherence to medication.  I?m not interested in studying the patients by themselves.
> My question is: should I consider the simplest model     response  ~  Indep. Variables +  (1|Doctor),
> or  should I explicitly introduce the nested structure of patient within doctor,   response ~ Indep. Variables + (Patient|Doctor) ?

Hi Helena,

Here a some syntax for your random effects assuming that all IV are
between-subject factors

  response  ~  Indep. Variables +   (1|Patient)

response ~ Indep. Variables + (1|Doctor) + (1|Patient)

The last one allow to define random effects for differences
across doctors as well as patients (with lmer, patients need to be uniquely
identified)

If you have repeated-measure (within-subject factors), then
things become more complex as the effect of some factor might
also be different across patients.  With lme, one advise in this
case is to include a maximal random structures (Barr et al., 2012, 2013)

(all within subject factor |Patient)

it one is interested only in fixed effects. However, other expert
recommend introducing random effects only for factors with a sufficient
large number of levels because variance estimates might not be
reliable. In any case, the situation with binomial model might be
different.

As you will see, there is not (yet) a generally agreed methodology
with mixed-effect models, the way you have it with old-fashioned ANOVA.
It takes a deep understanding of the methods and your data to
decide exactly what to do. There are now quite a bit of books and
papers on GLMM that might help to learn more on this topic.

Best,

Gabriel


>
>
> Thanks in advanced!
>
> Best regards,
> Helena.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Oct 10 14:21:59 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 10 Oct 2013 14:21:59 +0200
Subject: [R-sig-ME] Random intercepts and/or slopes
In-Reply-To: <525693EC.30806@hsr.it>
References: <CE9565EEC2A21641A7FF431FBCB78892BE816674D1@FC-MBXCLUSTER.fc.ul.pt>
	<525693EC.30806@hsr.it>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D8A0A01BA@UM-MAIL4112.unimaas.nl>

Since there is only a single replicate per patient, it is not possible to estimate the patient-level variance in these models:

response ~ Indep. Variables + (1|Patient)
response ~ Indep. Variables + (1|Doctor) + (1|Patient)

So, the only model that is really applicable here is:

response ~ Indep. Variables + (1|Doctor)

This model accounts for the nesting of patients within doctors.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Gabriel Baud-Bovy
> Sent: Thursday, October 10, 2013 13:48
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Random intercepts and/or slopes
> 
> On 10/10/2013 12:39 PM, Maria Helena Mourino Silva Nunes wrote:
> > Dear all,
> >
> > I'm new to mixed models, and I'm analysing a patients' data set whose
> response variable is adherence/no adherence to medication (binary
> variable, 0/1). For each patient there are different types of independent
> variables: sociodemographic; clinical; blood pressure control; etc.
> Additionally, patients are grouped (nested) within doctors. Due to the
> sampling design, I only have one replicate for each patient.
> >
> > I want to study the impact of the independent variables on the
> adherence/no adherence to medication.  I'm not interested in studying the
> patients by themselves.
> > My question is: should I consider the simplest model     response  ~
> Indep. Variables +  (1|Doctor),
> > or  should I explicitly introduce the nested structure of patient within
> doctor,   response ~ Indep. Variables + (Patient|Doctor) ?
> 
> Hi Helena,
> 
> Here a some syntax for your random effects assuming that all IV are
> between-subject factors
> 
>   response  ~  Indep. Variables +   (1|Patient)
> 
> response ~ Indep. Variables + (1|Doctor) + (1|Patient)
> 
> The last one allow to define random effects for differences
> across doctors as well as patients (with lmer, patients need to be
> uniquely
> identified)
> 
> If you have repeated-measure (within-subject factors), then
> things become more complex as the effect of some factor might
> also be different across patients.  With lme, one advise in this
> case is to include a maximal random structures (Barr et al., 2012, 2013)
> 
> (all within subject factor |Patient)
> 
> it one is interested only in fixed effects. However, other expert
> recommend introducing random effects only for factors with a sufficient
> large number of levels because variance estimates might not be
> reliable. In any case, the situation with binomial model might be
> different.
> 
> As you will see, there is not (yet) a generally agreed methodology
> with mixed-effect models, the way you have it with old-fashioned ANOVA.
> It takes a deep understanding of the methods and your data to
> decide exactly what to do. There are now quite a bit of books and
> papers on GLMM that might help to learn more on this topic.
> 
> Best,
> 
> Gabriel


From bbolker at gmail.com  Thu Oct 10 18:51:42 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 10 Oct 2013 16:51:42 +0000 (UTC)
Subject: [R-sig-ME] bug in refit function?
References: <0566E17B6DEC62459078112371B7508E0E3024@ait-pex02mbx05.win.dtu.dk>
	<loom.20131009T194714-554@post.gmane.org>
Message-ID: <loom.20131010T185048-302@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Alexandra Kuznetsova <alku <at> ...> writes:
> 
> > 
> > 
> > Hi all,
> > 
> > If I apply update function on the refit function, 
> then the refitted model
> becomes the initial model. The example:
> > 
> > > set.seed(101)
> > > Y <- matrix(rnorm(1000),ncol=2)
> > > d <- data.frame(y1=Y[,1],  x=rnorm(100), f=rep(1:10,10))
> > > fit1 <- lmer(y1 ~ x+(1|f),data=d)
> > > fit2 <- refit(fit1, newresp = Y[,2])
> > > all.equal(fit1, update(fit2))
> > [1] TRUE
> > 
> 
>   Thanks.  The problem is that update() works by evaluating
> the  <at> call slot, which doesn't get updated by refit.  We'll work
> on this.
> 

  Conversation continues at https://github.com/lme4/lme4/issues/142

My last update on the subject:

This is a little trickier than I thought. It's easy enough to update
the response column in the internal model frame slot, but the question
is whether one should try to update all references to y1 (in the
example above) to Y[,2] -- this is necessary if we want the results to
work with update(), which just goes to the environment (not to the
stored model frame) to re-evaluate the whole model ... otherwise, we
can replace the relevant slot in the model matrix, but unless we
update the formula to Y[,2] ~ ..., updating will just re-evaluate the
whole model, pulling y1 from d (where it hasn't changed, and where we
wouldn't want to change it!) and hence getting the old value, rather
than from model.frame(fit2)


From Ariel.Muldoon at oregonstate.edu  Thu Oct 10 20:53:14 2013
From: Ariel.Muldoon at oregonstate.edu (Muldoon, Ariel)
Date: Thu, 10 Oct 2013 18:53:14 +0000
Subject: [R-sig-ME] implications fitting random-only slopes
Message-ID: <6057235ECEA65D4DBC2696B69BA378A6013CE746@EX3.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131010/c8dd7fd6/attachment.pl>

From John.Morrongiello at csiro.au  Fri Oct 11 00:46:12 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 10 Oct 2013 22:46:12 +0000
Subject: [R-sig-ME] plot log transformed variable with Effects
Message-ID: <2547E22D246F3945BB491BDD8257C2E77F01BBA8@exmbx06-cdc.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131010/83234dd7/attachment.pl>

From Adrien.Combaz at med.kuleuven.be  Fri Oct 11 10:08:13 2013
From: Adrien.Combaz at med.kuleuven.be (Adrien Combaz)
Date: Fri, 11 Oct 2013 08:08:13 +0000
Subject: [R-sig-ME] model for clustered longitudinal binary data
In-Reply-To: <loom.20131009T234119-79@post.gmane.org>
References: <224EC811FF648D4A808A1381957BEBF3106A9A4E@ICTS-S-MBX5.luna.kuleuven.be>
	<loom.20131009T025751-477@post.gmane.org>
	<224EC811FF648D4A808A1381957BEBF3106A9B27@ICTS-S-MBX5.luna.kuleuven.be>
	<loom.20131009T234119-79@post.gmane.org>
Message-ID: <224EC811FF648D4A808A1381957BEBF3106ABE9B@ICTS-S-MBX5.luna.kuleuven.be>

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Wednesday, October 09, 2013 11:46 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] model for clustered longitudinal binary data
> 
> Adrien Combaz <Adrien.Combaz at ...> writes:
> 
> 
> [snip]
> 
> > > > I measure a longitudinal binary outcome (correctness of detection,
> > > > 0: incorrect, 1: correct) with respect to 5 different experimental
> > > > conditions (1 baseline and 4 treatments). The outcome is always
> > > > measured at the same 10 time points. Each of the 9 subjects
> > > > participated in all 5 conditions.  Additionally, for each subject
> > > > and condition, the experiment was replicated 36 times. I therefore
> > > > end up with 9*5*36=1620 binary longitudinal series (= trials of 10
> > > > points each).
> 
> [snip]
> 
> > >   Correlation among trials for a given subject
> > should be straightforward,
> > > correlation along time for a given trial may be difficult (see below).
> >
> > Yes, this is my main issue.
> 
>   I forgot to say that unless you are explicitly interested in the estimated
> correlation structure, you could hope to get around this by fitting the model
> without correlation and then showing that the temporal autocorrelation in
> the residuals is negligible ....
> 

That would indeed be nice.
Although, I was advised to avoid looking at residuals when doing logistic mixed models on binary data. I'm actually not sure about what they represent. When doing a normal mixed model, I'm able to retrieve my observed data by adding up fitted values and residuals, but it's not the case with logistic regression.
Therefore I'm wondering what they really represent and if looking at their autocorrelation will give me the information I expect.


> 
> > > > I am considering a 3 levels logistic models where 10 consecutive
> > > > binary measurements (level 1) are obtained on replicates (level 2)
> > >> which are clustered into subjects (level 3). My only level 1
> > >> covariate
> > > > would be the time of measurement (ordinal factor, T = 1, ..., 10)
> > > > and as level 2 covariate, I consider the experimental condition. I
> > > > don't consider any level 3 covariate per se, but still want the
> > > > model to account for between-subject variability.
> 
> > > This all seems reasonable.  If you really want time to be treated as
> > > ordinal, you'll want to look at the clmm function from the
> > > 'ordinal' package.
> 
> [snip]
> 
> > I am not sure to understand how I can use the clmm function, I am not
> > familiar with it but from what I could read, it is used to fit
> > cumulative link models for an ordinal response variable, while in my
> > case time is not the response variable but a factor (and my response
> > variable is binary).
> 
>  You're right, my bad.  The only difference between ordered and unordered
> factors in the standard R approach to model-fitting is that by default,
> treatment contrasts are used for unordered and orthogonal polynomial
> contrasts are used for ordered factors.  Another perhaps underused option is
> to specify successive-differences contrasts, using the contr.sdif() function in
> the MASS package.
> None of these will make a difference in the overall complexity or fit of the
> model, just in the interpretation of the parameters.
> 
> > I preferred to treat time as discrete factor rather than a continuous
> > variable for 2 reasons: 1) it represents a number of cycles which is
> > discrete and ordered by nature 2) on average, the correctness (logit)
> > increases with time, but the relationship is nonlinear. It means that,
> > if I use the time as a continuous variable, I should choose an
> > adequate transformation to obtain a linear relationship, which can be
> > very subjective. Since my main objective is to study the influence of
> > the experimental condition, I didn't really want to go there.
> 
> > > A simple model would be something like
> > >
> > >  response ~ time + expcond + (1|rep/sub)
> 
> > I tried something like that with the lmer function, only difference is
> > that I had as random effect (1|sub/rep). I thought that it was the
> > proper syntax for replicates nested within subjects, giving a random
> > intercept for each subject and for each replicate within subject. Am I
> > missing something?
> 
>   No, my bad again.  it should be sub/rep
> 
> >
> > >
> > > As a more complete model you could consider
> > >
> > >  response ~ time + expcond + (time|rep/sub) + (expcond|sub)
> 
> > With such a model where expcond is also used to define the random
> > effect structure, can I use the anova function to compare it to the
> > following "null model": response ~ time + (time|rep/sub) +
> > (expcond|sub) and make a statement on the significance of the effect
> > of the experiment condition?
> 
>   Yes.

Although this model seems nice, I'm reaching the maximum number of iterations without getting convergence, so I'll probably have to go for something a bit simpler.

> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mhnunes at fc.ul.pt  Fri Oct 11 13:08:31 2013
From: mhnunes at fc.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Fri, 11 Oct 2013 12:08:31 +0100
Subject: [R-sig-ME] Random intercepts and/or slopes
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730D8A0A01BA@UM-MAIL4112.unimaas.nl>
References: <CE9565EEC2A21641A7FF431FBCB78892BE816674D1@FC-MBXCLUSTER.fc.ul.pt>
	<525693EC.30806@hsr.it>,
	<077E31A57DA26E46AB0D493C9966AC730D8A0A01BA@UM-MAIL4112.unimaas.nl>
Message-ID: <CE9565EEC2A21641A7FF431FBCB78892BE816674E6@FC-MBXCLUSTER.fc.ul.pt>

Dear list members
Dear Wolfgang, Gabriel and Hans,

thanks a lot for your suggestions! It has been very useful.

I will use the model   response ~ Indep. Variables + (1|Doctor)   because I only have one set of observations for each patient (response variable + independent variables).


Best regards,
Helena.

________________________________________
De: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] Em Nome De Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Enviado: quinta-feira, 10 de Outubro de 2013 13:21
Para: r-sig-mixed-models at r-project.org
Assunto: Re: [R-sig-ME] Random intercepts and/or slopes

Since there is only a single replicate per patient, it is not possible to estimate the patient-level variance in these models:

response ~ Indep. Variables + (1|Patient)
response ~ Indep. Variables + (1|Doctor) + (1|Patient)

So, the only model that is really applicable here is:

response ~ Indep. Variables + (1|Doctor)

This model accounts for the nesting of patients within doctors.

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 | http://www.wvbauer.com

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Gabriel Baud-Bovy
> Sent: Thursday, October 10, 2013 13:48
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Random intercepts and/or slopes
>
> On 10/10/2013 12:39 PM, Maria Helena Mourino Silva Nunes wrote:
> > Dear all,
> >
> > I'm new to mixed models, and I'm analysing a patients' data set whose
> response variable is adherence/no adherence to medication (binary
> variable, 0/1). For each patient there are different types of independent
> variables: sociodemographic; clinical; blood pressure control; etc.
> Additionally, patients are grouped (nested) within doctors. Due to the
> sampling design, I only have one replicate for each patient.
> >
> > I want to study the impact of the independent variables on the
> adherence/no adherence to medication.  I'm not interested in studying the
> patients by themselves.
> > My question is: should I consider the simplest model     response  ~
> Indep. Variables +  (1|Doctor),
> > or  should I explicitly introduce the nested structure of patient within
> doctor,   response ~ Indep. Variables + (Patient|Doctor) ?
>
> Hi Helena,
>
> Here a some syntax for your random effects assuming that all IV are
> between-subject factors
>
>   response  ~  Indep. Variables +   (1|Patient)
>
> response ~ Indep. Variables + (1|Doctor) + (1|Patient)
>
> The last one allow to define random effects for differences
> across doctors as well as patients (with lmer, patients need to be
> uniquely
> identified)
>
> If you have repeated-measure (within-subject factors), then
> things become more complex as the effect of some factor might
> also be different across patients.  With lme, one advise in this
> case is to include a maximal random structures (Barr et al., 2012, 2013)
>
> (all within subject factor |Patient)
>
> it one is interested only in fixed effects. However, other expert
> recommend introducing random effects only for factors with a sufficient
> large number of levels because variance estimates might not be
> reliable. In any case, the situation with binomial model might be
> different.
>
> As you will see, there is not (yet) a generally agreed methodology
> with mixed-effect models, the way you have it with old-fashioned ANOVA.
> It takes a deep understanding of the methods and your data to
> decide exactly what to do. There are now quite a bit of books and
> papers on GLMM that might help to learn more on this topic.
>
> Best,
>
> Gabriel

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From Geraldine.Mabille at nina.no  Fri Oct 11 15:26:50 2013
From: Geraldine.Mabille at nina.no (Mabille, Geraldine)
Date: Fri, 11 Oct 2013 13:26:50 +0000
Subject: [R-sig-ME] glmmadmb- problems with explanatory variable with a lot
	of zeros?
Message-ID: <8CE1729E87FB844DA7A496C2ACCEE2657EBCEBE5@NINSRV05.nina.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131011/87d39407/attachment.pl>

From Geraldine.Mabille at nina.no  Fri Oct 11 16:06:12 2013
From: Geraldine.Mabille at nina.no (Mabille, Geraldine)
Date: Fri, 11 Oct 2013 14:06:12 +0000
Subject: [R-sig-ME] glmmadmb- problems with explanatory variable with a
 lot of zeros?
Message-ID: <8CE1729E87FB844DA7A496C2ACCEE2657EBCEC1B@NINSRV05.nina.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131011/fd7c0bda/attachment.pl>

From tobias.heed at uni-hamburg.de  Fri Oct 11 17:01:47 2013
From: tobias.heed at uni-hamburg.de (Tobias Heed)
Date: Fri, 11 Oct 2013 17:01:47 +0200
Subject: [R-sig-ME] implications fitting random-only slopes
In-Reply-To: <6057235ECEA65D4DBC2696B69BA378A6013CE746@EX3.oregonstate.edu>
References: <6057235ECEA65D4DBC2696B69BA378A6013CE746@EX3.oregonstate.edu>
Message-ID: <AF9970C7-F8EE-40AC-A8D7-48A0A6A5996C@uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131011/cf218c5a/attachment.pl>

From laetitia.etienne at cirad.fr  Fri Oct 11 18:59:49 2013
From: laetitia.etienne at cirad.fr (Laetitia ETIENNE)
Date: Fri, 11 Oct 2013 12:59:49 -0400 (AST)
Subject: [R-sig-ME] Calcul of confidence intervals of estimate coefficient
 by a logistic regression with random effect
Message-ID: <109385940.157332.1381510789467.JavaMail.root@cirad.fr>

Hello,

I would like to know how can i calculate confidence intervals of coefficients estimate with a logistic regression with random effect (i use the lme4 package for my glmm) ?

Example:

> y<-cbind(total-morts,morts)
			
> library(lme4)			
> modF<-glmer(y~sppNB+Fmyc+(1|Bloc),family=binomial(link="logit"))			
> drop1(modF,test="Chisq")			
Single term deletions			
Model:			
y ~ sppNB + Fmyc + (1 | Bloc)			
       Df    AIC     LRT  Pr(Chi)   			
<none>    66.680                    			
sppNB   4 73.721 15.0409 0.004617 **			
Fmyc    1 68.943  4.2636 0.038937 * 			
			
			
> summary(modF)			
Generalized linear mixed model fit by the Laplace approximation 			
Formula: y ~ sppNB + Fmyc + (1 | Bloc) 			
   AIC   BIC logLik deviance			
 66.68 71.64 -26.34    52.68			
Random effects:			
 Groups Name        Variance Std.Dev.			
 Bloc   (Intercept) 0.31936  0.56512 			
Number of obs: 15, groups: Bloc, 3			
			
Fixed effects:			
            Estimate Std. Error z value Pr(>|z|)   			
(Intercept) -4.11405    1.85861  -2.213  0.02686 * 			
sppNBjuncea  1.89728    1.11708   1.698  0.08943 . 			
sppNBMucuna  2.65001    1.87301   1.415  0.15712   			
sppNBspecta  2.72581    1.01592   2.683  0.00729 **			
sppNBVigna   1.90306    1.17422   1.621  0.10508   			
Fmyc         0.04048    0.01990   2.034  0.04192 * 	

I would like to know the confidence interval of the estimate coefficent of "Fmyc".		



thanks,

Laetitia Etienne


From bbolker at gmail.com  Fri Oct 11 22:18:31 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Oct 2013 20:18:31 +0000 (UTC)
Subject: [R-sig-ME] Calcul of confidence intervals of estimate
	coefficient by a logistic regression with random effect
References: <109385940.157332.1381510789467.JavaMail.root@cirad.fr>
Message-ID: <loom.20131011T220942-377@post.gmane.org>

Laetitia ETIENNE <laetitia.etienne at ...> writes:

> 
> Hello,
 
> I would like to know how can i calculate confidence intervals of
> coefficients estimate with a logistic regression with random effect
> (i use the lme4 package for my glmm) ?
 
> Example:
> 
> > y<-cbind(total-morts,morts)
> 			
> > library(lme4)			
> > modF<-glmer(y~sppNB+Fmyc+(1|Bloc),family=binomial(link="logit"))		
> > drop1(modF,test="Chisq")			

[snip]
> > summary(modF)			
>  Bloc   (Intercept) 0.31936  0.56512 			
> Number of obs: 15, groups: Bloc, 3			


[snip]
 			
> I would like to know the confidence interval of the estimate coefficent 
>  of "Fmyc".		


  If you're using the current (1.0-4) version of lme4, then
the answer is "?confint.merMod"; that gives you options of
profile confidence intervals (default: possibly slow but
fairly accurate); Wald intervals (fastest and least accurate);
or parametric bootstrap intervals (slowest and most accurate).

  You can speed things up a bit by specifying the 'which' argument
so that you only profile the parameters you actually care about,
but you need to know the position in the complete parameter
vector (including random effect parameters) -- this is something
we should improve in the future. I think in this case it would
be which(names(fixef(modF))=="Fmyc")+1 since there is one
random effects parameter.

  By the way, I worry that your model is overparameterized --
15 observations is very few to estimate 5 fixed effect parameters and 
1 random effect parameter, and 3 levels is very few for estimating
 a random effect.  Rules of thumb are >=5 levels for estimating a
random effect, and 10-20 observations per parameter ...


From bbolker at gmail.com  Fri Oct 11 22:29:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Oct 2013 20:29:55 +0000 (UTC)
Subject: [R-sig-ME] glmmadmb- problems with explanatory variable with a
	lot of zeros?
References: <8CE1729E87FB844DA7A496C2ACCEE2657EBCEC1B@NINSRV05.nina.no>
Message-ID: <loom.20131011T222018-142@post.gmane.org>

Mabille, Geraldine <Geraldine.Mabille at ...> writes:


> Edit...I have just understood the "problem" with the residuals that
> were different even though they had the same number of Lamb Killed
> and the same Dens_Lynx. It is only that they come from different
> municipalities!  The rest of the problem, with log likelihood
> behaving weirdly is still their though...

[snip]

> I'm just starting to use glmmadmb to try to model the number of
> lambs killed by lynx (Killed_Lamb) in each Norwegian
> municipality. We have repeated data over 11 years so I use
> municipality as a random effect in the analysis. The data contains a
> lot of zeros (403 over a total of 2151 lines) and evidence for
> overdispersion (tested using the overdisp_fun() after fitting of a
> poisson model in lme4, ratio obtained=23.8). I therefore decided to
> try using a negative binomial distribution with zero inflation.


> I first modeled the number of killed lambs as a function of the
> density of lynx (Dens_Lynx) in the municipality. We also have a lot
> of zero in Dens_Lynx (1518 over a total of 2151 lines).

> Mod1 <-glmmadmb(Killed_Lamb ~I(scale(Dens_Lynx)), random=~ 1|KOM, 
> data=DATA,zeroInflation=TRUE,family="nbinom")
> I obtain the following summary for Mod 1:
> Call:
> glmmadmb(formula = Killed_Lamb ~ I(scale(Dens_Lynx)), data = DATA,
>     family = "nbinom", random = ~1 | KOM, zeroInflation = TRUE)
 

[snip]
 
> Number of observations: total=2151, KOM=257
> Random effect variance(s):
> Group=KOM
>             Variance StdDev
> (Intercept)    4.053  2.013
> 
> Negative binomial dispersion parameter: 1.7665 (std. err.: 0.075737)
> Zero-inflation: 0.090062  (std. err.:  0.0083659 )
> 
> Log-likelihood: -9856.38
 
> I then tried to compare AIC for Mod1, with AIC for a base model
>  containing only an intercept as fixed effect:

> Mod0 <-glmmadmb(Killed_Lamb ~1, random=~ 1|KOM, 
> data=DATA,zeroInflation=TRUE,family="nbinom")
> anova(Mod0,Mod1).

> I get the following result and a warning because the more complex model 
> (Mod1) has a lower log-likelihood
> than the base model (Mod0)
> 
> Analysis of Deviance Table
> 
> Model 1: Killed_Lamb ~ 1
> 
> Model 2: Killed_Lamb ~ I(scale(Dens_Lynx))
> 
>   NoPar  LogLik Df Deviance Pr(>Chi)
> 
> 1     4 -9849.6
> 
> 2     5 -9856.4  1   -13.56        1
> 


  I don't know exactly what's going on here, but I agree it's weird.
Some suggestions:

 * try fitting the more and less complex models with starting
values set to the parameters of the other model (i.e. fit the 
more complex model starting at the reduced model, and the reduced
model starting at the estimate of the full model [forcing the
slope variable to zero])

* see whether adding a binary lynx present/absent variable helps
(this would add flexibility in the lynx density variable -- you
could also add a spline based on the lynx density; e.g. library(splines),
response ~ ns(Dens_Lynx,3); when
you plot the data, do the fitted parameters seem reasonable?)

* you can try a zero-inflated model via expectation-maximization 
with lme4:

https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/
    WRITEUP/owls.Rnw
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/R/
  owls_R_funs.R


From yulya258 at yahoo.com  Sat Oct 12 13:11:24 2013
From: yulya258 at yahoo.com (Yla Savh)
Date: Sat, 12 Oct 2013 04:11:24 -0700 (PDT)
Subject: [R-sig-ME] Issue with experimental design?
Message-ID: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131012/05ed5fd4/attachment.pl>

From cewright at uci.edu  Sat Oct 12 14:50:51 2013
From: cewright at uci.edu (Ted Wright)
Date: Sat, 12 Oct 2013 05:50:51 -0700
Subject: [R-sig-ME] Issue with experimental design?
In-Reply-To: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
References: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
Message-ID: <02c801cec749$afb8b1a0$0f2a14e0$@uci.edu>

You should treat this as a 3-group design. There is no nesting or crossing,
but you can still compare the outcomes for the three groups.

Ted Wright

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Yla Savh
Sent: Saturday, October 12, 2013 4:11 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Issue with experimental design?

Dear forum members, Could you please help me confirm if there is a problem
with the experimental design? There are two initial groups (vitamin D
deficient and normal group). Then, the D deficient group has two treatments
(with a low D dosage and a high D dosage), while the normal group has only
one treatment (maintenance therapy). 
Initially, I thought it might be a nested design (treatment nested within
groups, where the treatment is a fixed effect, and groups and treatment
nested in groups are random effects. However, I do not think it is a correct
design as the groups did not include the same treatments. Am I correct?
I see only one solution where we will have only one or two groups and the
same treatments should apply to each of them. Are there other
solutions?Thanks,Julia

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jkhartshorne at gmail.com  Sat Oct 12 22:01:27 2013
From: jkhartshorne at gmail.com (Joshua Hartshorne)
Date: Sat, 12 Oct 2013 16:01:27 -0400
Subject: [R-sig-ME] effect sizes in lmer
Message-ID: <CA+3amhezLfn=dyPJyAXeiJwYpPRDWhiMg7quXiHAiy9n6Rh0fA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131012/63002c21/attachment.pl>

From jwiley.psych at gmail.com  Sat Oct 12 22:14:35 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 12 Oct 2013 13:14:35 -0700
Subject: [R-sig-ME] Issue with experimental design?
In-Reply-To: <02c801cec749$afb8b1a0$0f2a14e0$@uci.edu>
References: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
	<02c801cec749$afb8b1a0$0f2a14e0$@uci.edu>
Message-ID: <CANz9Z_KwWGxy5ZhJhiZOT16o=gOnaacgQYJJext7jvE=kdjNTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131012/4e54b8cc/attachment.pl>

From dwinsemius at comcast.net  Sat Oct 12 23:27:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 12 Oct 2013 14:27:20 -0700
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <CA+3amhezLfn=dyPJyAXeiJwYpPRDWhiMg7quXiHAiy9n6Rh0fA@mail.gmail.com>
References: <CA+3amhezLfn=dyPJyAXeiJwYpPRDWhiMg7quXiHAiy9n6Rh0fA@mail.gmail.com>
Message-ID: <D56F9EFE-327B-41BB-8F92-EA51450E0059@comcast.net>


On Oct 12, 2013, at 1:01 PM, Joshua Hartshorne wrote:

> Are there any good methods for determining effect size for lmer? I am using
> anova(mod1,mod2) for my test statistics, so it would be great to get effect
> sizes out of that. In a 2011 discussion here, it was suggested that the
> log-likelihood ratio test is superior to effect size measures, so maybe
> even just a citation that makes that point would work?

You should read that discussion again to see if you can discern what was the point under discussion especially seeing it you can determine: superior with respect to what purpose?

> Your suggestions would be greatly appreciated. I'm under re-review at a
> journal that requires effect size measures.

The journal's purpose of requiring effect sizes is to prevent authors from focussing solely getting p-values, and then failing to explain the implications of model estimates. Don't you have access to the fixef and ranef functions?

-- 

David Winsemius
Alameda, CA, USA


From jkhartshorne at gmail.com  Sun Oct 13 00:03:53 2013
From: jkhartshorne at gmail.com (Joshua Hartshorne)
Date: Sat, 12 Oct 2013 18:03:53 -0400
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <D56F9EFE-327B-41BB-8F92-EA51450E0059@comcast.net>
References: <CA+3amhezLfn=dyPJyAXeiJwYpPRDWhiMg7quXiHAiy9n6Rh0fA@mail.gmail.com>
	<D56F9EFE-327B-41BB-8F92-EA51450E0059@comcast.net>
Message-ID: <CA+3amhcOx+5CFSdsFmvjd9UrkVrcris9OJ4Unc_zxbEYD469Gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131012/85ff69f1/attachment.pl>

From henrik.singmann at psychologie.uni-freiburg.de  Sun Oct 13 14:19:07 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Sun, 13 Oct 2013 14:19:07 +0200
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <CA+3amhcOx+5CFSdsFmvjd9UrkVrcris9OJ4Unc_zxbEYD469Gw@mail.gmail.com>
References: <CA+3amhezLfn=dyPJyAXeiJwYpPRDWhiMg7quXiHAiy9n6Rh0fA@mail.gmail.com>
	<D56F9EFE-327B-41BB-8F92-EA51450E0059@comcast.net>
	<CA+3amhcOx+5CFSdsFmvjd9UrkVrcris9OJ4Unc_zxbEYD469Gw@mail.gmail.com>
Message-ID: <525A8FBB.8040107@psychologie.uni-freiburg.de>

Do you want the effect size of single parameters? Then the friendly hint of David Winsemius (fixef or ranef) is the way to go (i.e., reporting the size of the parameters).

If you are interested in a value for the whole model, you could have a look at the different alternatives of R? discussed on the faq: http://glmm.wikidot.com/faq#mcmcsamp_status (scroll down a little).

I tend to like Omega?_0 which is given by the following for a model m:
1-var(residuals(m))/(var(model.response(model.frame(m)))

See: Xu, R. 2003. Measuring explained variation in linear mixed effects models. Statist. Med. 22:3527-3541. doi:10.1002/sim.1572

Hope that helps,
Henrik


Am 13.10.2013 00:03, schrieb Joshua Hartshorne:
> On Sat, Oct 12, 2013 at 5:27 PM, David Winsemius <dwinsemius at comcast.net>wrote:
>
>>
>>> Your suggestions would be greatly appreciated. I'm under re-review at a
>>> journal that requires effect size measures.
>>
>> The journal's purpose of requiring effect sizes is to prevent authors from
>> focussing solely getting p-values, and then failing to explain the
>> implications of model estimates. Don't you have access to the fixef and
>> ranef functions?
>>
>
> I doubt that's the purpose for this journal. In my field, researchers are
> pretty much only interested in interpreting the implications of the model
> estimates, and frankly I'm not sure what the alternative is. Quite frankly,
> most researchers in my field don't care about effect size one way or
> another, and those that do are mainly using it in conjunction with
> p-values, etc., to determine the likelihood the null hypothesis is true.
>
> I'm working with a 4x3x2 design. Let's call them factors A, B, and C. What
> I need to report is the size of the effect of A, B, C, and their
> interactions, which I won't get from fixef (so far as I know). I would just
> use an ANOVA but I have an unbalanced design.
>
> (Even if the estimates for the individual fixed effects in the regression
> were theoretically interesting -- they aren't -- large regression tables
> simply aren't published in my field, and it would be a long, probably
> unsuccessful slog trying to get one published.)
>
> 	[[alternative HTML version deleted]]
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From bbolker at gmail.com  Sun Oct 13 15:10:12 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 13 Oct 2013 13:10:12 +0000 (UTC)
Subject: [R-sig-ME] Issue with experimental design?
References: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
	<02c801cec749$afb8b1a0$0f2a14e0$@uci.edu>
Message-ID: <loom.20131013T151010-895@post.gmane.org>

Ted Wright <cewright at ...> writes:

> 
> You should treat this as a 3-group design. There is no nesting 
> or crossing,
> but you can still compare the outcomes for the three groups.
> 
> Ted Wright

  I agree. The way to make the distinction(s) you are interested
in (normal vs. treatment, or normal vs. low vs. treatment) is
by setting the contrasts of your fixed effects appropriately.
(You can see ?contrasts ; unfortunately setting custom contrasts
is a little bit opaque, although in your case the contr.sdif()
function from the MASS package might be helpful.)

> -----Original Message-----
> From: r-sig-mixed-models-bounces at ...
> [mailto:r-sig-mixed-models-bounces at ...] On Behalf Of Yla Savh
> Sent: Saturday, October 12, 2013 4:11 AM
> To: r-sig-mixed-models at ...
> Subject: [R-sig-ME] Issue with experimental design?
> 
> Dear forum members, Could you please help me confirm if there is a problem
> with the experimental design? There are two initial groups (vitamin D
> deficient and normal group). Then, the D deficient group has
>  two treatments
> (with a low D dosage and a high D dosage), while the normal group has only
> one treatment (maintenance therapy). 
> Initially, I thought it might be a nested design (treatment nested within
> groups, where the treatment is a fixed effect, and groups and treatment
> nested in groups are random effects. However, I do not think it is a correct
> design as the groups did not include the same treatments. Am I correct?
> I see only one solution where we will have only one or two groups and the
> same treatments should apply to each of them. Are there other
> solutions?Thanks,Julia


From jkhartshorne at gmail.com  Sun Oct 13 15:31:43 2013
From: jkhartshorne at gmail.com (Joshua Hartshorne)
Date: Sun, 13 Oct 2013 09:31:43 -0400
Subject: [R-sig-ME] effect sizes in lmer
Message-ID: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131013/585891de/attachment.pl>

From dwinsemius at comcast.net  Sun Oct 13 17:41:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 13 Oct 2013 08:41:05 -0700
Subject: [R-sig-ME] Issue with experimental design?
In-Reply-To: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
References: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
Message-ID: <841C38C6-A4A3-49B7-A33F-55F330DBBB39@comcast.net>


On Oct 12, 2013, at 4:11 AM, Yla Savh wrote:

> Dear forum members, Could you please help me confirm if there is a problem with
> the experimental design? There are two initial groups (vitamin D deficient and
> normal group). Then, the D deficient group has two treatments (with a low D dosage
> and a high D dosage), while the normal group has only one treatment (maintenance
> therapy). 
> Initially, I thought it might be a nested design (treatment
> nested within groups, where the treatment is a fixed effect, and groups and treatment
> nested in groups are random effects. However, I do not think it is a correct
> design as the groups did not include the same treatments. Am I correct?
> I see only one solution where we will have only one or two
> groups and the same treatments should apply to each of them. Are there other
> solutions?Thanks,Julia
> 

Perhaps a different opinion: You are really only "experimenting" with the "vitamin D deficient" group. There is no design basis for including the "normal" group in any inferential analysis. I suppose you can construct plots to look at descriptive comparisons but I see little valididity to including the structurally different (different by design) normal group in any analysis where you would be constructing effect measures. I suppose it might give you some estimate of variability and you would be able to describe differences, but you wouldn't have a solid basis for making inferences in that analysis because the range of initial vitamin-D values would be of necessity disjoint.


> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From henrik.singmann at psychologie.uni-freiburg.de  Sun Oct 13 19:12:11 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Sun, 13 Oct 2013 19:12:11 +0200
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>
References: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>
Message-ID: <525AD46B.60000@psychologie.uni-freiburg.de>

Dear Josh,

I don't know of a measure that serves this purpose. You could implement 
something like change in AIC or Omega? but if this is reasonable, others 
with a stronger statistical background will have to decide.

Cheers,
Henrik

Joshua Hartshorne schrieb:
> Hi Henrik,
>
> I'm not sure if I follow your reply. Using fixef will give me 24 effects,
> including the intercept. An ANOVA would give 7. What I need to report are
> the 7 ANOVA-style effects, not the 24 me-style ones.
>
> To make this more concrete, I have 4 types of stimuli, two different types
> of tests, and 3 conditions. What the readers are going to want to know is
> whether there is an omnibus interaction. Fixef reports 6 omnibus
> interactions -- one for every level of the interaction. I will also need to
> report the lower-level interactions and main effects. (Doesn't matter
> whether these are truly interpretable in the face of a significant
> higher-order interaction: It's standard practice to report them.)
>
> I can measure the significance of the ANOVA-style omnibus interaction by
> using model comparison. But that doesn't give me an effect size exactly.
> (One suggestion I heard recently was to use the change in AIC as an effect
> size.)
>
> Any ideas?
>
> Josh
>
> 	[[alternative HTML version deleted]]
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From bbolker at gmail.com  Mon Oct 14 03:37:42 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Oct 2013 01:37:42 +0000 (UTC)
Subject: [R-sig-ME] effect sizes in lmer
References: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>
Message-ID: <loom.20131014T033528-29@post.gmane.org>

Joshua Hartshorne <jkhartshorne at ...> writes:

> 
> Hi Henrik,
> 
> I'm not sure if I follow your reply. Using fixef will give me 24 effects,
> including the intercept. An ANOVA would give 7. What I need to report are
> the 7 ANOVA-style effects, not the 24 me-style ones.
> 
> To make this more concrete, I have 4 types of stimuli, two different types
> of tests, and 3 conditions. What the readers are going to want to know is
> whether there is an omnibus interaction. Fixef reports 6 omnibus
> interactions -- one for every level of the interaction. 
>I will also need to
> report the lower-level interactions and main effects. (Doesn't matter
> whether these are truly interpretable in the face of a significant
> higher-order interaction: It's standard practice to report them.)

  I sympathize with this point of view but it also worries me ("oh,
this doesn't make sense, but in my field we do it anyway ...")
 
> I can measure the significance of the ANOVA-style omnibus interaction by
> using model comparison. But that doesn't give me an effect size exactly.
> (One suggestion I heard recently was to use the change in AIC as an effect
> size.)

  I would go ahead and use -2*log-likelihood difference (deviance 
difference). This is
asymptotically chi-squared distributed, and is the analogue of the
F statistic in an ANOVA table, so if the F-statistic is what you 
define as "the effect size" in an ANOVA context then by extension
it makes sense to use the log-likelihood diff.


From jake987722 at hotmail.com  Mon Oct 14 04:51:47 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sun, 13 Oct 2013 20:51:47 -0600
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <loom.20131014T033528-29@post.gmane.org>
References: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>,
	<loom.20131014T033528-29@post.gmane.org>
Message-ID: <BAY172-W1078DACE4F35DF765E3E2ACB1A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131013/90101b36/attachment.pl>

From pierces1 at msu.edu  Mon Oct 14 14:21:37 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Mon, 14 Oct 2013 08:21:37 -0400
Subject: [R-sig-ME] effect sizes in lmer
In-Reply-To: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>
References: <CA+3amhcO8bTMTKUgejMYOYizr=xMqewMjJEpOqgobsYGLk63Dg@mail.gmail.com>
Message-ID: <000b01cec8d7$ee4ef980$caecec80$@msu.edu>

Josh,

Check out the following paper in addition to the other suggestions folks
here are making. Baguley provides a useful critique of standardized effect
sizes. If your variables are measured in inherently meaningful units, there
is utility in understanding what the parameter estimates actually tell you
in terms of simple effect size. 

Baguley, T. (2009). Standardized or simple effect size: What should be
reported? British Journal of Psychology, 100(3), 603-617. doi:
10.1348/000712608X377117

As an additional thought, an interaction is just a situation where the
effect size of one bivariate relationship (say slope of x as predictor of y)
depends on some other variable (for example z). Consider reporting all the
conditional effect sizes that describe the set of relationships rather than
some overall effect size. For example, what is the effect of x on y when z =
1, when z = 2, etc. Interpreting those conditional effects would be more
scientifically informative about the phenomenon under study than an overall
effect size, which is often too abstract a quantity for people to actually
understand. I suspect there are in fact situations where the same value for
the overall effect size could have drastically different implications
depending on what is happening with the various conditional effects. 


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
E-mail: pierces1 at msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Joshua Hartshorne [mailto:jkhartshorne at gmail.com] 
Sent: Sunday, October 13, 2013 9:32 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] effect sizes in lmer

Hi Henrik,

I'm not sure if I follow your reply. Using fixef will give me 24 effects,
including the intercept. An ANOVA would give 7. What I need to report are
the 7 ANOVA-style effects, not the 24 me-style ones.

To make this more concrete, I have 4 types of stimuli, two different types
of tests, and 3 conditions. What the readers are going to want to know is
whether there is an omnibus interaction. Fixef reports 6 omnibus
interactions -- one for every level of the interaction. I will also need to
report the lower-level interactions and main effects. (Doesn't matter
whether these are truly interpretable in the face of a significant
higher-order interaction: It's standard practice to report them.)

I can measure the significance of the ANOVA-style omnibus interaction by
using model comparison. But that doesn't give me an effect size exactly.
(One suggestion I heard recently was to use the change in AIC as an effect
size.)

Any ideas?

Josh

	[[alternative HTML version deleted]]


From Ariel.Muldoon at oregonstate.edu  Mon Oct 14 20:22:57 2013
From: Ariel.Muldoon at oregonstate.edu (Muldoon, Ariel)
Date: Mon, 14 Oct 2013 18:22:57 +0000
Subject: [R-sig-ME] implications fitting random-only slopes
In-Reply-To: <AF9970C7-F8EE-40AC-A8D7-48A0A6A5996C@uni-hamburg.de>
References: <6057235ECEA65D4DBC2696B69BA378A6013CE746@EX3.oregonstate.edu>
	<AF9970C7-F8EE-40AC-A8D7-48A0A6A5996C@uni-hamburg.de>
Message-ID: <6057235ECEA65D4DBC2696B69BA378A6013CEB1B@EX3.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131014/fcb9b0e5/attachment.pl>

From highstat at highstat.com  Mon Oct 14 22:08:23 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 14 Oct 2013 22:08:23 +0200
Subject: [R-sig-ME] Call of interest: mixed modelling course in Quebec City
Message-ID: <525C4F37.4020301@highstat.com>

This is a call of interest for: "Introduction to linear mixed effects 
modelling and GLMM course"

Where: Quebec City, Canada
When: 24 - 28 March 2014

Flyer: http://www.highstat.com/Courses/Flyer2014_03Quebec.pdf
General info: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From petemeyer at google.com  Tue Oct 15 00:51:03 2013
From: petemeyer at google.com (Pete Meyer)
Date: Mon, 14 Oct 2013 15:51:03 -0700
Subject: [R-sig-ME] When is sparseX implementation expected?
Message-ID: <CAAjm_vqXZOYp+-Nhh_derWO=dJL+U9L_m-1yECHAuWb51b+HUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131014/aedda951/attachment.pl>

From yulya258 at yahoo.com  Tue Oct 15 01:33:28 2013
From: yulya258 at yahoo.com (Yla Savh)
Date: Mon, 14 Oct 2013 16:33:28 -0700 (PDT)
Subject: [R-sig-ME] Issue with experimental design?
In-Reply-To: <841C38C6-A4A3-49B7-A33F-55F330DBBB39@comcast.net>
References: <1381576284.18635.YahooMailNeo@web162704.mail.bf1.yahoo.com>
	<841C38C6-A4A3-49B7-A33F-55F330DBBB39@comcast.net>
Message-ID: <1381793608.40635.YahooMailNeo@web162703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131014/c6bbb94d/attachment.pl>

From marvs at umich.edu  Tue Oct 15 01:55:45 2013
From: marvs at umich.edu (Dave Marvin)
Date: Mon, 14 Oct 2013 19:55:45 -0400
Subject: [R-sig-ME] Unrealistic fixed effect coefficients
Message-ID: <853B812E-C02B-4B02-922C-04D3A85246FA@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131014/5ecbdaf9/attachment.pl>

From jake987722 at hotmail.com  Tue Oct 15 02:40:19 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Mon, 14 Oct 2013 18:40:19 -0600
Subject: [R-sig-ME] Unrealistic fixed effect coefficients
In-Reply-To: <853B812E-C02B-4B02-922C-04D3A85246FA@umich.edu>
References: <853B812E-C02B-4B02-922C-04D3A85246FA@umich.edu>
Message-ID: <BAY172-W109C59E3B59CF8BF24B0B4CB1B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131014/c8a53df9/attachment.pl>

From jake987722 at hotmail.com  Tue Oct 15 10:08:58 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 15 Oct 2013 02:08:58 -0600
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random terms
Message-ID: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131015/0cf62618/attachment.pl>

From jake987722 at hotmail.com  Tue Oct 15 10:25:29 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 15 Oct 2013 02:25:29 -0600
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
Message-ID: <BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131015/50bc0960/attachment.pl>

From Geraldine.Mabille at nina.no  Tue Oct 15 14:33:32 2013
From: Geraldine.Mabille at nina.no (Mabille, Geraldine)
Date: Tue, 15 Oct 2013 12:33:32 +0000
Subject: [R-sig-ME] glmmadmb- problems with explanatory variable with a
 lot of zeros?
Message-ID: <8CE1729E87FB844DA7A496C2ACCEE2657EBCEDAE@NINSRV05.nina.no>

Thanks heaps to Ben Bolker and Dave Fournier for their answers and suggestions!
I have tried several of the suggestions made by Ben Bolker and here is what I get:
1) Using the zipme function, I get the following error message
zipme(cformula=Killed_Lamb~Dens_Lynx+(1|KOM),zformula=z~1,data=DATA,maxitr=20,tol=1e-6,verbose=FALSE,cfamily=poisson)
Error in lmerFrames(mc, formula, contrasts) :   negative weights or weights of zero are not allowed

2) Trying to add a binary variable Lynx_Bin into the model:
DATA$Lynx_Bin<-ifelse(DATA$Dens_Lynx>0,1,0)
Mod1a <-glmmadmb(Killed_Lamb~I(scale(Dens_Lynx))+Lynx_Bin, random=~ 1|KOM, data=DATA,zeroInflation=TRUE,family="nbinom")
I get the following error messages:
Parameters were estimated, but not standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Killed_Lamb ~ I(scale(Dens_Lynx)) + Lynx_Bin, random = ~1 |  : 
  The function maximizer failed (couldn't find STD file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl'
In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c "C:/Myname/R-2.15.2/library/glmmADMB/bin/windows64/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess' had status 1

3) Trying to fit Dens_Lynx as a spline:
library(splines)
Mod1b <-glmmadmb(Killed_Lamb~ns(Dens_Lynx,3), random=~ 1|KOM, data=DATA,zeroInflation=TRUE,family="nbinom")
Warning message:
In glmmadmb(Killed_Lamb ~ ns(Dens_Lynx, 3), random = ~1 | KOM, data = DATA,  :
  Convergence failed:log-likelihood of gradient= -510.054
summary(Mod1b)
Call:
glmmadmb(formula = Killed_Lamb ~ ns(Dens_Lynx, 3), data = DATA, 
    family = "nbinom", random = ~1 | KOM, zeroInflation = TRUE)
AIC: 29691.4 
Coefficients:
                               Estimate   Std. Error z value Pr(>|z|)
(Intercept)        7.13e+12   1.09e+14    0.07     0.95
ns(Dens_Lynx, 3)1  1.31e+13   1.82e+14    0.07     0.94
ns(Dens_Lynx, 3)2 -2.83e+13   2.17e+14   -0.13     0.90
ns(Dens_Lynx, 3)3  2.79e+11   6.93e+13    0.00     1.00
Number of observations: total=2151, KOM=257 
Random effect variance(s):
Group=KOM
                     Variance StdDev
(Intercept)    9.115  3.019
Negative binomial dispersion parameter: 0.90085 (std. err.: 0.076799)
Zero-inflation: 0.034505  (std. err.:  0.01553 )
Log-likelihood: -14838.7

4)Trying to specify my starting values (I'm not sure I understood Ben's suggestion properly here: specify starting values for the fixed effects only?  And not sure either if I implemented that properly). Here is what I tried
Mod1c<-glmmadmb(Killed_Lamb~I(scale(Dens_Lynx)), random=~ 1|KOM, data=DATA,zeroInflation=TRUE,family="nbinom",start=list(fixed=c(Mod0$b,0)))
summary(Mod1c)    ####### IS THE SAME AS summary(Mod1)
Call:
glmmadmb(formula = Killed_Lamb ~ I(scale(Dens_Lynx)), data = DATA, 
    family = "nbinom", start = list(fixed = c(Mod0$b, 0)), random = ~1 | 
        KOM, zeroInflation = TRUE)
AIC: 19722.8 
Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)           2.9544     0.1374    21.5  < 2e-16 ***
I(scale(Dens_Lynx))   0.1122     0.0229     4.9  9.5e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Number of observations: total=2151, KOM=257 
Random effect variance(s):
Group=KOM
            Variance StdDev
(Intercept)    4.053  2.013
Negative binomial dispersion parameter: 1.7665 (std. err.: 0.075737)
Zero-inflation: 0.090062  (std. err.:  0.0083659 )
Log-likelihood: -9856.38

Mod0c<-glmmadmb(Killed_Lamb~1, random=~ 1|KOM, data=DATA,zeroInflation=TRUE,family="nbinom",start=list(fixed=Mod1$b[1]))
Parameters were estimated, but not standard errors were not: the most likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Killed_Lamb ~ 1, random = ~1 | KOM, data = DATA, zeroInflation = TRUE,  : 
The function maximizer failed (couldn't find STD file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl'
In addition: Warning message: running command
 'C:\Windows\system32\cmd.exe /c "C:/Myname/R-2.15.2/library/glmmADMB/bin/windows64/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess' had status 1

5) Finally, I also tried fitting the same models as Mod0 and Mod1, but without zero inflation. This time the log likelihood behaves normally and AIC decreases when I add the Dens_Lynx variable in the model (Mod1d compared to Mod0d). However, if I test for the existence of zero-inflation by comparing AIC of Mod1 with AIC of Mod1d (or Mod0 with Mod0d) , I see that there seems to be strong evidence for existence of zero-inflation. Should I just forget about zero-inflation and fit the model with glmmadmb and no zero-inflation? I don't know how to interpret values for zero-inflation parameter we get from Mod0 and Mod1. Is there also strong evidence for zero-inflation according to those parameters?

Mod0d <-glmmadmb(Killed_Lamb~1, random=~ 1|KOM, data=DATA,family="nbinom")
Call: glmmadmb(formula = Killed_Lamb ~ 1, data = DATA, family = "nbinom",  random = ~1 | KOM, save.dir = "M:/Geraldine/Sheep/Results/Folder")
AIC: 19888.8 
Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    2.900      0.135    21.4   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Number of observations: total=2151, KOM=257 
Random effect variance(s):
Group=KOM
            Variance StdDev
(Intercept)    4.187  2.046
Negative binomial dispersion parameter: 1.0361 (std. err.: 0.038589)
Log-likelihood: -9941.4

Mod1d <-glmmadmb(Killed_Lamb~I(scale(Dens_Lynx)), random=~ 1|KOM, data=DATA,family="nbinom")
summary(Mod1d)
Call: glmmadmb(formula = Killed_Lamb ~ I(scale(Dens_Lynx)), data = DATA,  family = "nbinom", random = ~1 | KOM)
AIC: 19871.8 
Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)           2.9085     0.1326   21.93  < 2e-16 ***
I(scale(Dens_Lynx))   0.1259     0.0292    4.32  1.6e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Number of observations: total=2151, KOM=257 
Random effect variance(s):
Group=KOM
            Variance StdDev
(Intercept)    4.009  2.002
Negative binomial dispersion parameter: 1.0432 (std. err.: 0.038955)
Log-likelihood: -9931.89

Thanks again with any help on those issues,
Cheers,
Geraldine


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: 11. oktober 2013 22:30
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmadmb- problems with explanatory variable with a lot of zeros?

Mabille, Geraldine <Geraldine.Mabille at ...> writes:


> Edit...I have just understood the "problem" with the residuals that 
> were different even though they had the same number of Lamb Killed and 
> the same Dens_Lynx. It is only that they come from different 
> municipalities!  The rest of the problem, with log likelihood behaving 
> weirdly is still their though...

[snip]

> I'm just starting to use glmmadmb to try to model the number of lambs 
> killed by lynx (Killed_Lamb) in each Norwegian municipality. We have 
> repeated data over 11 years so I use municipality as a random effect 
> in the analysis. The data contains a lot of zeros (403 over a total of 
> 2151 lines) and evidence for overdispersion (tested using the 
> overdisp_fun() after fitting of a poisson model in lme4, ratio 
> obtained=23.8). I therefore decided to try using a negative binomial 
> distribution with zero inflation.


> I first modeled the number of killed lambs as a function of the 
> density of lynx (Dens_Lynx) in the municipality. We also have a lot of 
> zero in Dens_Lynx (1518 over a total of 2151 lines).

> Mod1 <-glmmadmb(Killed_Lamb ~I(scale(Dens_Lynx)), random=~ 1|KOM,
> data=DATA,zeroInflation=TRUE,family="nbinom")
> I obtain the following summary for Mod 1:
> Call:
> glmmadmb(formula = Killed_Lamb ~ I(scale(Dens_Lynx)), data = DATA,
>     family = "nbinom", random = ~1 | KOM, zeroInflation = TRUE)
 

[snip]
 
> Number of observations: total=2151, KOM=257
> Random effect variance(s):
> Group=KOM
>             Variance StdDev
> (Intercept)    4.053  2.013
> 
> Negative binomial dispersion parameter: 1.7665 (std. err.: 0.075737)
> Zero-inflation: 0.090062  (std. err.:  0.0083659 )
> 
> Log-likelihood: -9856.38
 
> I then tried to compare AIC for Mod1, with AIC for a base model
>  containing only an intercept as fixed effect:

> Mod0 <-glmmadmb(Killed_Lamb ~1, random=~ 1|KOM, 
> data=DATA,zeroInflation=TRUE,family="nbinom")
> anova(Mod0,Mod1).

> I get the following result and a warning because the more complex model 
> (Mod1) has a lower log-likelihood
> than the base model (Mod0)
> 
> Analysis of Deviance Table
> 
> Model 1: Killed_Lamb ~ 1
> 
> Model 2: Killed_Lamb ~ I(scale(Dens_Lynx))
> 
>   NoPar  LogLik Df Deviance Pr(>Chi)
> 
> 1     4 -9849.6
> 
> 2     5 -9856.4  1   -13.56        1
> 


  I don't know exactly what's going on here, but I agree it's weird.
Some suggestions:

 * try fitting the more and less complex models with starting
values set to the parameters of the other model (i.e. fit the 
more complex model starting at the reduced model, and the reduced
model starting at the estimate of the full model [forcing the
slope variable to zero])

* see whether adding a binary lynx present/absent variable helps
(this would add flexibility in the lynx density variable -- you
could also add a spline based on the lynx density; e.g. library(splines),
response ~ ns(Dens_Lynx,3); when
you plot the data, do the fitted parameters seem reasonable?)

* you can try a zero-inflated model via expectation-maximization 
with lme4:

https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/
    WRITEUP/owls.Rnw
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/R/
  owls_R_funs.R

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From marvs at umich.edu  Tue Oct 15 15:05:46 2013
From: marvs at umich.edu (Dave Marvin)
Date: Tue, 15 Oct 2013 09:05:46 -0400
Subject: [R-sig-ME] Unrealistic fixed effect coefficients
In-Reply-To: <BAY172-W109C59E3B59CF8BF24B0B4CB1B0@phx.gbl>
References: <853B812E-C02B-4B02-922C-04D3A85246FA@umich.edu>
	<BAY172-W109C59E3B59CF8BF24B0B4CB1B0@phx.gbl>
Message-ID: <CB36486B-A30F-48BB-BE40-DFD850A7D821@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131015/8d4962c6/attachment.pl>

From bbolker at gmail.com  Tue Oct 15 15:05:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Oct 2013 13:05:58 +0000 (UTC)
Subject: [R-sig-ME] When is sparseX implementation expected?
References: <CAAjm_vqXZOYp+-Nhh_derWO=dJL+U9L_m-1yECHAuWb51b+HUQ@mail.gmail.com>
Message-ID: <loom.20131015T145915-963@post.gmane.org>

Pete Meyer <petemeyer at ...> writes:

> 
> For some of our large models (>= 5k factor levels) I found that sparseX in
> lme4a (under R 2.14.2) made a big difference in compute time.  I see that
> it isn't yet implemented for this update to lme4.  Any idea how long it
> will be until it is available again?
> 

  It has not been near the top of the priority list.  We have looked
at it and thought (more or less) "oh, that shouldn't be *too hard*,
but it looks somewhat annoying" -- see https://github.com/lme4/lme4/issues/6
If you want to chime in on the issues list that might help push the
priority up slightly.

  cheers
    Ben Bolker


From HDoran at air.org  Tue Oct 15 15:34:33 2013
From: HDoran at air.org (Doran, Harold)
Date: Tue, 15 Oct 2013 13:34:33 +0000
Subject: [R-sig-ME] When is sparseX implementation expected?
In-Reply-To: <loom.20131015T145915-963@post.gmane.org>
References: <CAAjm_vqXZOYp+-Nhh_derWO=dJL+U9L_m-1yECHAuWb51b+HUQ@mail.gmail.com>
	<loom.20131015T145915-963@post.gmane.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68664407BD5@DC1VEX10MB001.air.org>

Curiously, though, how much of a need is there for sparseX? The model matrix for the random effects can often involve thousands of columns (sometimes even per level), and thousands of rows. Clearly, if the pattern of non-zeroes is large, there is a significant benefit.

But, the dimensions of the model matrix for the fixed effects are typically very small relative to the model matrix for the random effects, often involving only a handful of columns. 

One of the major benefits of the sparse storage for the random effect matrices are the methods that benefit, such as Cholesky(). In an iterative process, it only updates the numeric factorization at each iteration as it has already identified the symbolic representation in the first iteration. 

One thing I can imagine is if the number of rows of X is, say millions, and still involve only a handful of columns and suppose many of those rows are zeros. Then perhaps it could be useful? But even still when doing X'X on that matrix, its dimensions are (in theory) usually small and so doing things on that small p x p matrix is not too expensive.

On the other hand, if one has an X matrix with thousands of columns, I would question what the underlying statistical issue is and if the model is even good.

 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Tuesday, October 15, 2013 9:06 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] When is sparseX implementation expected?

Pete Meyer <petemeyer at ...> writes:

> 
> For some of our large models (>= 5k factor levels) I found that 
> sparseX in lme4a (under R 2.14.2) made a big difference in compute 
> time.  I see that it isn't yet implemented for this update to lme4.  
> Any idea how long it will be until it is available again?
> 

  It has not been near the top of the priority list.  We have looked at it and thought (more or less) "oh, that shouldn't be *too hard*, but it looks somewhat annoying" -- see https://github.com/lme4/lme4/issues/6
If you want to chime in on the issues list that might help push the priority up slightly.

  cheers
    Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From seth at swbigelow.net  Tue Oct 15 16:02:11 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Tue, 15 Oct 2013 10:02:11 -0400
Subject: [R-sig-ME] FW:  Unrealistic fixed effect coefficients
Message-ID: <002001cec9af$26a217e0$73e647a0$@net>

Dave, 

Perhaps you should go back to a simple model and build up from there,
examining residuals at each step as outlined in, e.g., Pinheiro & Bates
Chapter 1, or Simon Wood's GAM book (Chap. 6, Mixed models and GAMMS's is
great). 

My first cut at a simple model for your situation would be to ignore
chambers, specify random effects with species nested within functional
types, and use a likelihood ratio test to compare models with interaction
vs. no interaction of main effects, as in
M1 <- Lmer(response ~ CO2 + FT + (1|FT/spp))
M2 <- Lmer(response ~ CO2*FT +  (1|FT/spp))
anova(M1,M2)

...analogous to the 'machines' example in section 1.3 of Pinheiro & Bates.
Then, if this makes sense and the residual errors make sense, move
(incrementally) to a model that incorporates the chamber effect, using,
e.g., Jake's suggestions. 
-Seth


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dave Marvin
Sent: Tuesday, October 15, 2013 9:06 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Unrealistic fixed effect coefficients

Thank you for the clarification Jake. 

Your assumptions were correct in that a single Species can only be one
Functional Type (in this experiment at least), and a single Chamber will
only have one CO2 level. The model output with this random effects structure
is below, and gives much more realistic estimates of the fixed effects. 

However, this brings up a second issue (which maybe belongs in a new post?).
The standard errors of the estimated fixed effects are huge -- 3 to 9 times
as large as in the raw data. Is this to be interpreted as just having very
poor explanatory variables? Why, then, would my standard errors not be at
least in the same ballpark when just looking at the raw data group SEs? 



> Linear mixed model fit by REML
> Formula: HtChg ~ CO2 * FT + (FT | Chamber) + (CO2 | Spp) 
>    Data: striAseasonal 
>   AIC  BIC logLik deviance REMLdev
>  2744 2784  -1361     2750    2722
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr   
>  Chamber  (Intercept)  236.215 15.3693         
>           FTT           81.171  9.0095  -1.000 
>  Spp      (Intercept) 2995.561 54.7317         
>           CO2E           5.195  2.2793  -0.261 
>  Residual              828.383 28.7816         
> Number of obs: 281, groups: Chamber, 36; Spp, 8
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   68.911     27.819   2.477
> CO2E           7.429      7.138   1.041
> FTT          -43.882     39.065  -1.123
> CO2E:FTT      -7.214      7.675  -0.940
> 
> Correlation of Fixed Effects:
>          (Intr) CO2E   FTT   
> CO2E     -0.167              
> FTT      -0.707  0.100       
> CO2E:FTT  0.130 -0.732 -0.149




On Oct 14, 2013, at 8:40 PM, Jake Westfall wrote:

> Hi Dave,
> 
> Your random effects specification doesn't make sense.  You say that you
have 8 random Species, each of which are observed in a number of random
Chambers. So Species and Chamber are crossed. So a preliminary model would
look like this:
> 
> response ~ CO2 * FT + (1|Chamber) + (1|Spp)
> 
> Now, Species are nested under Functional Type, meaning each Species is of
one and only one FT (right??), so we cannot estimate a random FT slope
across Species. But each species *is* observed under both levels of CO2. So
we can modify the Spp random effects thusly:
> 
> response ~ CO2 * FT + (1|Chamber) + (CO2|Spp)
> 
> I assume that growth Chambers are nested under CO2 level (so that a single
Chamber can't have both CO2 levels). So we can't estimate a random CO2 slope
across Chambers.  But each Chamber *does* contain Species of both Functional
Types, right? So our final model, if I have understood the experimental
design correctly, should look like this:
> 
> response ~ CO2 * FT + (FT|Chamber) + (CO2|Spp)
> 
> Hope this helps,
> Jake
>> From: marvs at umich.edu
>> Date: Mon, 14 Oct 2013 19:55:45 -0400
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Unrealistic fixed effect coefficients
>> 
>> I am analyzing the growth response of two plant types (vines vs. trees)
to different CO2 levels, for a mix of species of each plant type in plant
growth chambers. I am fitting a mixed model with lmer using the following
fixed and random effects structures:
>> 
>> response ~ CO2 * FT + (1 + Spp | Chamber)
>> 
>> CO2 and FT are categorical predictors, each with two levels
(elevated/ambient CO2, vine/tree plant Functional Types). Each growth
chamber had the same mix of 8 species (Spp), so I would like to include both
species and chamber as random effects. With this random effects structure,
and please correct me if I am wrong, I believe I am modeling the variation
of each species among the growth chambers independent of the CO2 treatment
each chamber received. I would like to use this approach since each growth
chamber differs slightly in its microsite environment, and want to account
for species variation due to microsite (chamber) differences as a random
effect.  
>> 
>> However, the result of the model for most of my response variables (e.g.,
plant height below) give completely unrealistic fixed effect coefficients
(i.e., the plant height is never going to be negative, and the intercept
isn't even close to either of the group means from the raw data). Response
variables are untransformed and unstandardized. 
>> 
>> Am I specifying my random effects incorrectly? Or is there another
problem I am not seeing/addressing? Thank you. 
>> 
>>> Linear mixed model fit by REML
>>> Formula: HtChg ~ CO2 * FT + (1 + Spp | Chamber) 
>>>   Data: striAseasonal
>>>  AIC  BIC logLik deviance REMLdev
>>> 2640 2789  -1279     2571    2558
>>> Random effects:
>>> Groups   Name        Variance  Std.Dev. Corr

>>> Chamber  (Intercept)   613.032  24.7595

>>>          SppCLIJAV    6680.902  81.7368  0.747

>>>          SppCONN      1046.801  32.3543 -0.987 -0.773

>>>          SppCORALL    1479.760  38.4676  0.565  0.619 -0.630

>>>          SppPHRCO      461.740  21.4881 -0.995 -0.772  0.989 -0.597

>>>          SppSTIHY    19240.737 138.7110  0.799  0.762 -0.878  0.777
-0.809               
>>>          SppTABRO      690.773  26.2826 -0.095 -0.348  0.027  0.144
0.043  0.027        
>>>          SppTERAM      211.084  14.5287 -0.752 -0.291  0.679 -0.126
0.699 -0.348  0.136 
>>> Residual                91.938   9.5884

>>> Number of obs: 281, groups: Chamber, 36
>>> 
>>> Fixed effects:
>>>            Estimate Std. Error t value
>>> (Intercept)   13.459      1.629   8.260
>>> CO2E           3.216      2.276   1.413
>>> FTT          -15.751      2.498  -6.305
>>> CO2E:FTT      -2.251      3.538  -0.636
>>> 
>>> Correlation of Fixed Effects:
>>>         (Intr) CO2E   FTT   
>>> CO2E     -0.716              
>>> FTT      -0.518  0.371       
>>> CO2E:FTT  0.366 -0.512 -0.706
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Oct 15 17:12:15 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Oct 2013 11:12:15 -0400
Subject: [R-sig-ME] [Lme4-authors] AIC calculation
In-Reply-To: <525D59E1.1080603@gmail.com>
References: <525D59E1.1080603@gmail.com>
Message-ID: <525D5B4F.8080504@gmail.com>


   [forwarding to r-sig-mixed-models]

On 13-10-15 04:44 AM, Miguel Boubeta Mart?nez wrote:
> Hello,
> The lastest versions were 0.999999-2 and 1.0-4. I fit a GLMM, as
>   glmm=glmer(y~ x + (1|dd),family=poisson())
> where 'y' is the response, 'x' is the covariate and 'dd' is the
> area. With these options, the AIC results were different. Could you give
> me the reference of the calculation of AIC used in lme4?
> Sincerely,z``
>   Miguel.


  From the NEWS file for lme4, e.g.

> news(grepl("consistent",Text) & Version=="1.0-0",package="lme4")


: As another side effect of matching glm behaviour, reported
log-likelihoods from glmer models are no longer consistent with those
from pre-1.0 lme4, but _are_ consistent with glm; see glmer examples.

  The AIC calculation (given the log-likelihood) is completely standard:
it's the log-likelihood calculation you have to be careful about -- see
lme4:::logLik.merMod (which also specifies the computation of the number
of parameters).

  Ben Bolker




z``>
> ------------------------------------------------------------------------
> *De:* lme4 maintainer <bbolker at gmail.com>
> *Para:* Miguel Boubeta Mart?nez <miguel.boubeta at yahoo.es>;
> "lme4-authors at lists.r-forge.r-project.org"
> <lme4-authors at lists.r-forge.r-project.org>
> *Enviado:* Martes 15 de octubre de 2013 5:03
> *Asunto:* Re: [Lme4-authors] AIC calculation
> 
>   Certainly not without a reproducible example, or at least a lot more
> details (what were the "latest versions", i.e. are you referring to
> versions 0.999x and 1.0x , or 1.0-4 and 1.1-0 ?)  Was there anything
> else different about the fits (parameter values, log-likelihood)? Was
> this a GLMM or a LMM? etc etc etc.
> 
>   Our recommended advice is to send general questions first to
> r-sig-mixed-models at r-project.org
> <mailto:r-sig-mixed-models at r-project.org> , where someone else may be
> able to
> answer.  Please read http://tinyurl.com/reproducible-000 on how to
> create good reproducible examples, and the posting guide for the R
> lists, first (google "R mailing list posting guide")
> 
>   sincerely
>     Ben Bolker
> 
> 
> 
>


From raorben at gmail.com  Fri Oct 11 01:15:29 2013
From: raorben at gmail.com (Rachael Orben)
Date: Thu, 10 Oct 2013 23:15:29 +0000 (UTC)
Subject: [R-sig-ME] pwrssUpdate Error with new version of lme4
References: <CABsGe_yaPWEy10E4_5ofh8GhJ5f+UXCmk+MhCw3Q4pBPJL7aEA@mail.gmail.com>
Message-ID: <loom.20131011T000336-135@post.gmane.org>

Hi,

I am also getting the Error: pwrssUpdate did not 
converge in 30 iterations when 
running a binomial model in lme4 with glmer.  
I updated to R 3.0.2 & lme4 due 
to other errors. 

I am running everything on a Mac.

I am at the beginning stages of this analysis, 
so the problem could partly be my 
data set which has very few individuals with 
the condition 0. The error seems to 
be more likely to occur if I include 3 or 4 random 
effects.  Since I have few '0' individuals there 
may only be one or two of them in each of 
the groups modeled by the random effects. 
I have tried incorporating the term control = 
glmerControl(tolPwrss=1e-3), and that 
doesn't always help.

Any ideas what might be causing this error?
Thanks,
Rachael


From bates at stat.wisc.edu  Tue Oct 15 21:09:53 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 15 Oct 2013 14:09:53 -0500
Subject: [R-sig-ME] When is sparseX implementation expected?
In-Reply-To: <CAAjm_vqXZOYp+-Nhh_derWO=dJL+U9L_m-1yECHAuWb51b+HUQ@mail.gmail.com>
References: <CAAjm_vqXZOYp+-Nhh_derWO=dJL+U9L_m-1yECHAuWb51b+HUQ@mail.gmail.com>
Message-ID: <CAO7JsnSA+g49vf+vH4gjDhAcwgZ16pfJhy23M4ikbVZieMb97g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131015/adcb0d99/attachment.pl>

From bbolker at gmail.com  Tue Oct 15 17:06:09 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Oct 2013 11:06:09 -0400
Subject: [R-sig-ME] [Lme4-authors] AIC calculation
In-Reply-To: <1381826669.41799.YahooMailNeo@web171505.mail.ir2.yahoo.com>
References: <1381741941.61948.YahooMailNeo@web171506.mail.ir2.yahoo.com>
	<525CB084.8050803@lists.r-forge.r-project.org>
	<1381826669.41799.YahooMailNeo@web171505.mail.ir2.yahoo.com>
Message-ID: <525D59E1.1080603@gmail.com>

   [forwarding to r-sig-mixed-models]

On 13-10-15 04:44 AM, Miguel Boubeta Mart?nez wrote:
> Hello,
> The lastest versions were 0.999999-2 and 1.0-4. I fit a GLMM, as
>   glmm=glmer(y~ x + (1|dd),family=poisson())
> where 'y' is the response, 'x' is the covariate and 'dd' is the
> area. With these options, the AIC results were different. Could you give
> me the reference of the calculation of AIC used in lme4?
> Sincerely,z``
>   Miguel.


  From the NEWS file for lme4, e.g.

> news(grepl("consistent",Text) & Version=="1.0-0",package="lme4")


: As another side effect of matching glm behaviour, reported
log-likelihoods from glmer models are no longer consistent with those
from pre-1.0 lme4, but _are_ consistent with glm; see glmer examples.

  The AIC calculation (given the log-likelihood) is completely standard:
it's the log-likelihood calculation you have to be careful about -- see
lme4:::logLik.merMod (which also specifies the computation of the number
of parameters).

  Ben Bolker




z``>
> ------------------------------------------------------------------------
> *De:* lme4 maintainer <bbolker at gmail.com>
> *Para:* Miguel Boubeta Mart?nez <miguel.boubeta at yahoo.es>;
> "lme4-authors at lists.r-forge.r-project.org"
> <lme4-authors at lists.r-forge.r-project.org>
> *Enviado:* Martes 15 de octubre de 2013 5:03
> *Asunto:* Re: [Lme4-authors] AIC calculation
> 
>   Certainly not without a reproducible example, or at least a lot more
> details (what were the "latest versions", i.e. are you referring to
> versions 0.999x and 1.0x , or 1.0-4 and 1.1-0 ?)  Was there anything
> else different about the fits (parameter values, log-likelihood)? Was
> this a GLMM or a LMM? etc etc etc.
> 
>   Our recommended advice is to send general questions first to
> r-sig-mixed-models at r-project.org
> <mailto:r-sig-mixed-models at r-project.org> , where someone else may be
> able to
> answer.  Please read http://tinyurl.com/reproducible-000 on how to
> create good reproducible examples, and the posting guide for the R
> lists, first (google "R mailing list posting guide")
> 
>   sincerely
>     Ben Bolker
> 
> 
> 
>


From chris at trickysolutions.com.au  Wed Oct 16 00:44:30 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Wed, 16 Oct 2013 09:44:30 +1100
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
Message-ID: <-870254483034385012@unknownmsgid>

Could it be that lower order effects usually represent larger
differences between groups while interactions tend to 'tweak' things.

For example say we were predicting weight using gender and height.
Then height and gender would explain most of whats going on. But there
might be a very small gender*weight interaction.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

> On 15 Oct 2013, at 19:11, Jake Westfall <jake987722 at hotmail.com> wrote:
>
> Hi everyone,
>
> **TL, DR summary:**
> Is there any theoretical or empirical basis to support the following statement being true as a general rule of thumb?
> "When estimating a mixed model, typically the estimated variances/standard deviations of random effects associated with 'higher-order' terms (e.g., random effects of two-way, three-way, and beyond interaction terms) turn out to be *smaller* than the estimated variances/standard deviations of random effects associated with 'lower-order' terms (e.g., the residual variance, variances associated with simple effects of grouping factors)."
>
> The source of this claim is me. ;)
>
> ****
>
> Okay, now for the longer version...
>
> Typically when I sit down to start analyzing a new dataset which I know will call for a mixed model, one of the first models that I fit (after the statistical foreplay of looking through the observations in the dataset, plotting various things, cross-tabulating different factors, etc.) is one that is pretty close to the "maximal" random effects specification, where every random effect that is in-principle possible to estimate from the data, is estimated.
>
> Naturally, it is not uncommon that this nearly-maximal model will have some computational problems (convergence errors, or wacky variance/covariance estimates, or etc.) and that I have to trim back this model to find one that my data can more easily support. Fine.
>
> In these situations, the method I have come to prefer for trimming random terms is not to rely on significance tests or likelihood ratios, but rather to just identify the random effects that seem to have the smallest standard deviations (which can admittedly be a little tricky when predictors are on very different scales, but I try to take account of this in my appraisal) and remove these terms first, sequentially in an iterative process. The idea being that I want to alter the predictions of the model as little as possible while still reducing the complexity of the model.
>
> One pattern that I seem to have noticed after a pretty good amount of time spent doing this is that following this method very often leads me to trim random effects associated with higher-order terms (as defined above) of the model first. This is not always true, and occasionally some of the higher-order terms explain a lot of variance, but this doesn't seem to be the general pattern. In sharp contrast, I usually find that lower-order random terms -- particularly those associated with simple effects of the grouping factors -- explain a pretty good amount of variance and are fairly essential to the model. At the extreme, the residual term commonly accounts for close to the most variance, although of course removing this term wouldn't be sensible.
>
> This entirely informal observation leads me to form the hypothesis that I stated at the beginning of this email.
>
> If it is true, then it constitutes a useful piece of advice that might be passed down to people who are less experience with this kind of model selection process. But before I begin doing so, I want to check with other, more experienced users about their reactions to this observation. Does it seem more or less true to you? Is it roughly consistent with your experience fitting many different mixed models to many different datasets? Do you know of any sensible, theoretical reasons why we might actually *expect* this to be true in a lot of cases? Or does it just seem like bullshit?
>
> One possible answer here is that it is not true even in my own case, and I have simply deceived myself. Certainly a possibility that I am open to.
>
> Another possibility is that it might be true in my own case, but that this could simply be a kind of coincidence having to do with the kinds of datasets that I tend to work with routinely (which, FYI, are datasets in psychological / social sciences, a slight majority being experimental in origin, but also a fair proportion of non-experimental stuff). If this is the case then there is probably no good reason for expecting my observations to hold in general in other fields that handle very different kinds of data. Still, if there is a coherent non-coincidental reason for why this might be expected to be true, even if only for these particular kinds of datasets, I would love to hear it.
>
> And of course another possibility is that others *have* noticed similar patterns in their own data, and that it represents some kind of general rule of thumb that people find useful to keep in mind as they fit mixed models to various different data. If this is the case then it seems like there must be some compelling statistical-theoretical reason for why this pattern arises. But I really don't know what that reason would look like.
>
> I welcome anyone's thoughts and opinions about this. Totally legitimate responses to this might be as simple as comments like "Yeah I have noticed something similar in the data I've worked with, but I have no idea why it should be true" or conversely "I have noticed nothing like this in the data I've worked with." Of course I also welcome longer and more involved discussions...
>
> FULL DISCLOSURE: I think I am probably also going to post this question to stats.stackexchange.com. If/when I do, I will send along the link to that question thread.
>
> Jake
>
>
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Wed Oct 16 14:54:16 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 16 Oct 2013 07:54:16 -0500
Subject: [R-sig-ME] nlme
In-Reply-To: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
Message-ID: <CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/511fedc8/attachment.pl>

From andy_liaw at merck.com  Wed Oct 16 14:57:38 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 16 Oct 2013 08:57:38 -0400
Subject: [R-sig-ME] nlme
In-Reply-To: <CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
Message-ID: <D5FA03935F7418419332B61CA255F65F9FB973594D@USCTMXP51012.merck.com>

I believe that's an alternative name for least squares means.

Best,
Andy

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas Bates
Sent: Wednesday, October 16, 2013 8:54 AM
To: Catherine Bois
Cc: R-mixed models mailing list
Subject: Re: [R-sig-ME] nlme

On Wed, Oct 16, 2013 at 4:13 AM, Catherine Bois <C.Bois at sms.ed.ac.uk> wrote:

> Hi,
>
> I am currently using nlme to fit a mixed model. However, I was wondering
> if there is a function to extract model adjusted means derived from an nlme
> object, in order to subsequently plot in another programme?
>

I can't answer your question because I don't know what adjusted means are.
 I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
reply in case someone reading that list can help you.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From kw.stat at gmail.com  Wed Oct 16 15:07:33 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 16 Oct 2013 08:07:33 -0500
Subject: [R-sig-ME] nlme
In-Reply-To: <CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
Message-ID: <CAKFxdiRfx-jHE3Y=PN-xhDdG+rNc8GP2tO2_X1_oqPYSfp6FGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/818f2665/attachment.pl>

From bates at stat.wisc.edu  Wed Oct 16 15:08:29 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 16 Oct 2013 08:08:29 -0500
Subject: [R-sig-ME] nlme
In-Reply-To: <D5FA03935F7418419332B61CA255F65F9FB973594D@USCTMXP51012.merck.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
	<D5FA03935F7418419332B61CA255F65F9FB973594D@USCTMXP51012.merck.com>
Message-ID: <CAO7JsnSurRXqC_gRVO-u+Q1Ja2j=sBC+TNzHLVmb-A9JLNdYxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/961cf0e8/attachment.pl>

From marvs at umich.edu  Wed Oct 16 15:14:30 2013
From: marvs at umich.edu (Dave Marvin)
Date: Wed, 16 Oct 2013 09:14:30 -0400
Subject: [R-sig-ME] nlme
In-Reply-To: <CAKFxdiRfx-jHE3Y=PN-xhDdG+rNc8GP2tO2_X1_oqPYSfp6FGQ@mail.gmail.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
	<CAKFxdiRfx-jHE3Y=PN-xhDdG+rNc8GP2tO2_X1_oqPYSfp6FGQ@mail.gmail.com>
Message-ID: <B6BE2C81-653E-4B63-9A85-A9445106EA40@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/d4e1b777/attachment.pl>

From jfox at mcmaster.ca  Wed Oct 16 15:28:01 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 16 Oct 2013 09:28:01 -0400
Subject: [R-sig-ME] nlme
In-Reply-To: <CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
Message-ID: <web-478696237@cgpsrv2.cis.mcmaster.ca>

Dear Doug and Catherine,

The effects package will produce adjusted means (and other fits) for the fixed effects in models fit by lme() in the nlme package and by lmer() and glmer() in the lme4 package.

Best,
 John

On Wed, 16 Oct 2013 07:54:16 -0500
 Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Oct 16, 2013 at 4:13 AM, Catherine Bois <C.Bois at sms.ed.ac.uk> wrote:
> 
> > Hi,
> >
> > I am currently using nlme to fit a mixed model. However, I was wondering
> > if there is a function to extract model adjusted means derived from an nlme
> > object, in order to subsequently plot in another programme?
> >
> 
> I can't answer your question because I don't know what adjusted means are.
>  I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
> reply in case someone reading that list can help you.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From C.Bois at sms.ed.ac.uk  Wed Oct 16 16:13:43 2013
From: C.Bois at sms.ed.ac.uk (Catherine Bois)
Date: Wed, 16 Oct 2013 15:13:43 +0100
Subject: [R-sig-ME] nlme
In-Reply-To: <CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
Message-ID: <20131016151343.10034gmh4rdocb28@www.staffmail.ed.ac.uk>

Thanks guys. I am using lsmeans, however the problem is that I am  
interested in a categorical:continuous predictor interaction so I have  
two problems

1. lsmeans seems to take one value of the continuous predictor and  
compare the categorical predictors in relation to the outcome variable  
on this one value, as opposed to comparing slopes of the variable; I  
therefore wanted to graph this interaction somehow with the adjusted  
means

2. This means that I would need to somehow extract all the model  
adjusted values for these interaction terms and "build my own graph",  
outside of lsmeans capabilities, if that makes sense.

Sorry if this sounds unclear!


Quoting Douglas Bates <bates at stat.wisc.edu> on Wed, 16 Oct 2013  
07:54:16 -0500:

> On Wed, Oct 16, 2013 at 4:13 AM, Catherine Bois <C.Bois at sms.ed.ac.uk> wrote:
>
>> Hi,
>>
>> I am currently using nlme to fit a mixed model. However, I was wondering
>> if there is a function to extract model adjusted means derived from an nlme
>> object, in order to subsequently plot in another programme?
>>
>
> I can't answer your question because I don't know what adjusted means are.
>  I am cc:ing the R-SIG-Mixed-Models at R-project.org mailing list on this
> reply in case someone reading that list can help you.
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From lbp at njau.edu.cn  Wed Oct 16 05:22:07 2013
From: lbp at njau.edu.cn (lbp)
Date: Wed, 16 Oct 2013 11:22:07 +0800
Subject: [R-sig-ME] how to get confidence intervals in using glmer in lme4
	package?
Message-ID: <201310161122074066841@njau.edu.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/88207011/attachment.pl>

From leena.hamberg at metla.fi  Wed Oct 16 13:25:18 2013
From: leena.hamberg at metla.fi (Hamberg Leena (METLA))
Date: Wed, 16 Oct 2013 11:25:18 +0000
Subject: [R-sig-ME] GLMM question
Message-ID: <C475CA93BE409E4FB58AA4BDE4EBF347CC86A1@FITLK-EXMBX02.msvyvi.vaha.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/f46f8172/attachment.pl>

From kw.stat at gmail.com  Wed Oct 16 21:37:14 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 16 Oct 2013 14:37:14 -0500
Subject: [R-sig-ME] nlme
In-Reply-To: <20131016151343.10034gmh4rdocb28@www.staffmail.ed.ac.uk>
References: <20131016101344.18452qyjnetlqy80@www.staffmail.ed.ac.uk>
	<CAO7JsnT3WdGWvhd1gsH6sjiwX1HiE-nnzWRCFneR2DpPda0rkA@mail.gmail.com>
	<20131016151343.10034gmh4rdocb28@www.staffmail.ed.ac.uk>
Message-ID: <CAKFxdiSJeipx8BefVc71=aKPO26_Jirg9pp=RkON8Nc4yfcfRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/d4c0c1bd/attachment.pl>

From jake987722 at hotmail.com  Wed Oct 16 21:43:56 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 16 Oct 2013 13:43:56 -0600
Subject: [R-sig-ME] GLMM question
In-Reply-To: <C475CA93BE409E4FB58AA4BDE4EBF347CC86A1@FITLK-EXMBX02.msvyvi.vaha.local>
References: <C475CA93BE409E4FB58AA4BDE4EBF347CC86A1@FITLK-EXMBX02.msvyvi.vaha.local>
Message-ID: <BAY172-W112D5158B38C614A0BFB36CB040@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/94466374/attachment.pl>

From bbolker at gmail.com  Wed Oct 16 22:58:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Oct 2013 20:58:19 +0000 (UTC)
Subject: [R-sig-ME] GLMM question
References: <C475CA93BE409E4FB58AA4BDE4EBF347CC86A1@FITLK-EXMBX02.msvyvi.vaha.local>
	<BAY172-W112D5158B38C614A0BFB36CB040@phx.gbl>
Message-ID: <loom.20131016T224924-411@post.gmane.org>

Jake Westfall <jake987722 at ...> writes:

> 
> Hi Leena,
 
> Yes, p-values for tests of fixed effects can be found in various
>  ways. See the FAQ here:
 
> http://glmm.wikidot.com/faq
 
> In particular see the sections "What is the best way to test
> hypotheses on effects in GLMMs?" and "Why doesn't lme4 display
> denominator degrees of freedom/p values? What other options do I
> have?"
 
> Note that most of these methods of obtaining p-values will *not*
> also come with an estimated degrees of freedom. My guess is that
> just having the p-value will satisfy the editor and the absence of
> DFs will not be a big deal. But if you decide that you do also want
> the degrees of freedom, you can use the Kenward-Roger procedure
> implemented in the pbkrtest package.

  The situation is a little different for LMMs and GLMMs. You can only
use KRmodcomp() for linear mixed models.  You can use parametric 
bootstrap via PBmodcomp() in pbkrtest, or via bootMer in lme4 proper.

  GLMMs generally assume the data set is large (asymptotic tests),
so they give you p-values (but no dfs).  This is spelled out in
more detail in the FAQ referenced by Jake.  If the editor really
wants dfs for GLMMs, they're going to be disappointed.  
If they want p-values
that take finite-size corrections into account, you will need
parametric bootstrapping or some similar approach.
 
> Jake
> 
> From: leena.hamberg at ...

 [snip]
 
> I would like to ask a question relating to generalized linear mixed
> models. I have used package lme4, function glmer to estimate my
> models (logit link for occurrences, log for counts and identity for
> height models). I presented the results of my models in our
> manuscript (coefficients with SE - significant ones
> highlighted). However, the editor asked me to add p-values, df:s,
> and test statistics to the result section every time I am presenting
> significant or insignificant results. I did as was asked and
> explained that degrees of freedom were not available for these
> models and that when normality was assumed (i.e., in the case of t
> statistics) p-values were not available. However, the editor
> answered as follows:

  You should probably use lmer instead of glmer for your height models.
For completeness you really need to specify the family as well as the
link (I assume binomial for occurrences, Poisson for counts, and
Gaussian for height).  

Out of curiosity: how do you know whether the parameters are
statistically significant or not (at
some unspecified alpha level, probably 0.05) if you don't know the
p-values?
 
> "In my previous e-mail I've requested you to add details of the
> statistical results in your MS (e.g., results of the GLM you've
> done, F-values, Chi2-values, df, P-values, etc.)... ...You did not
> take this comment fully into account and I disagree with your answer
> to this request. On the contrary to what you answered me, R (since
> you used R) provides all the detailed results you are requested to
> provide...
 
> ...Also, even if p-values, df and statistics are tightly
> interrelated, this does to prevent you to give the corresponding
> information in your published work, at least to help potential
> readers to verify what you wanted to say. P-values are always
> available in R - or can easily be found - for Gaussian or not
> normally distributed traits. So, you have to provide all the needed
> information is you MS. For example, every single t-test has to come
> with its df and P-value. If really you are not able to find this in
> R, then you have to use another program..."
 
>  
> So how to proceed? Can df:s and p-values be found in any way 
> using the R? If yes, how this can be done?
> Unfortunately I couldn't solve this problem by myself.
> 
> Here is an example of GLMMs estimated:
> 
> tyvivmaxp10P=glmer(Tkvmaxpit~k?sittely+tyvilpm+m3haYHT+saastotKAIK+
> TKvHirvi+(1|ruutu),family=gaussian(link ="identity"), data=pihlajatE10)
> 
> summary(tyvivmaxp10P)
> 
> Linear mixed model fit by REML
> Formula: Tkvmaxpit ~ k?sittely + tyvilpm + m3haYHT + 
>   saastotKAIK + TKvHirvi + (1 | ruutu)
>    Data: pihlajatE10
>    AIC  BIC logLik deviance REMLdev
> 994.5 1015 -489.3    999.5   978.5
> Random effects:
> Groups   Name        Variance Std.Dev.
> ruutu    (Intercept)  207.25  14.396
>  Residual             1255.73  35.436
> Number of obs: 100, groups: ruutu, 8
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  80.71047   17.52630   4.605
> k?sittely2  -45.79590   13.98636  -3.274
> tyvilpm      22.06164    6.23251   3.540
> m3haYHT       0.11672    0.31592   0.369
> saastotKAIK   0.09566    0.11513   0.831
> TKvHirvi1    12.77524    8.55455   1.493

 [snip]


From bbolker at gmail.com  Wed Oct 16 22:59:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Oct 2013 20:59:04 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?how_to_get_confidence_intervals_in_using_glm?=
	=?utf-8?q?er_in_lme4=09package=3F?=
References: <201310161122074066841@njau.edu.cn>
Message-ID: <loom.20131016T225840-180@post.gmane.org>

lbp <lbp at ...> writes:

> 
> 
> Baoping LI, PhD,Prof.
> Department of Entomology
> Nanjing Agricultural University
> PR CHINA

 See ?confint.merMod , if you're using a recent version of lme4.

  Ben Bolker


From russell-lenth at uiowa.edu  Wed Oct 16 23:30:17 2013
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 16 Oct 2013 21:30:17 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 82, Issue 25
In-Reply-To: <mailman.3478.1381951330.4612.r-sig-mixed-models@r-project.org>
References: <mailman.3478.1381951330.4612.r-sig-mixed-models@r-project.org>
Message-ID: <5B2C404D-CA68-4587-AB3C-F2216502CA2B@uiowa.edu>

If I understand this correctly, I think you can use the 'trend' argument in lsmeans to get what you want. See the man page for lsmeans and the examples near the end.

Russ Lenth

Sent from my iPad

> On Oct 16, 2013, at 2:27 PM, "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org> wrote:
> 
> Thanks guys. I am using lsmeans, however the problem is that I am  
> interested in a categorical:continuous predictor interaction so I have  
> two problems
> 
> 1. lsmeans seems to take one value of the continuous predictor and  
> compare the categorical predictors in relation to the outcome variable  
> on this one value, as opposed to comparing slopes of the variable; I  
> therefore wanted to graph this interaction somehow with the adjusted  
> means


From maustin at amgen.com  Thu Oct 17 01:00:04 2013
From: maustin at amgen.com (Austin, Matt)
Date: Wed, 16 Oct 2013 23:00:04 +0000
Subject: [R-sig-ME] GLMM question
In-Reply-To: <BAY172-W112D5158B38C614A0BFB36CB040@phx.gbl>
Message-ID: <726DB167C5D40941817D45228973780B1DE45FA6@usso-pmsg-mbx02.am.corp.amgen.com>

Thanks!

On 10/16/13 12:43 PM, "Jake Westfall" <jake987722 at hotmail.com> wrote:

>Hi Leena,
>
>Yes, p-values for tests of fixed effects can be found in various ways.
>See the FAQ here:
>
>http://glmm.wikidot.com/faq
>
>In particular see the sections "What is the best way to test hypotheses
>on effects in GLMMs?" and "Why doesn't lme4 display denominator degrees
>of freedom/p values? What other options do I have?"
>
>Note that most of these methods of obtaining p-values will *not* also
>come with an estimated degrees of freedom. My guess is that just having
>the p-value will satisfy the editor and the absence of DFs will not be a
>big deal. But if you decide that you do also want the degrees of freedom,
>you can use the Kenward-Roger procedure implemented in the pbkrtest
>package.
>
>Jake
>
>From: leena.hamberg at metla.fi
>To: r-sig-mixed-models at r-project.org
>Date: Wed, 16 Oct 2013 11:25:18 +0000
>Subject: [R-sig-ME] GLMM question
>
>Dear list members,
> 
>I would like to ask a question relating to generalized linear mixed
>models. I have used package lme4, function glmer to estimate my models
>(logit link for occurrences, log for counts and identity for height
>models). I presented the results of my models in our manuscript
>(coefficients with SE - significant ones highlighted). However, the
>editor asked me to add p-values, df:s, and test statistics to the result
>section every time I am presenting significant or insignificant results.
>I did as was asked and explained that degrees of freedom were not
>available for these models and that when normality was assumed (i.e., in
>the case of t statistics) p-values were not available. However, the
>editor answered as follows:
> 
>"In my previous e-mail I've requested you to add details of the
>statistical results in your MS (e.g., results of the GLM you've done,
>F-values, Chi2-values, df, P-values, etc.)... ...You did not take this
>comment fully into account and I disagree with your answer to this
>request. On the contrary to what you answered me, R (since you used R)
>provides all the detailed results you are requested to provide...
> 
>...Also, even if p-values, df and statistics are tightly interrelated,
>this does to prevent you to give the corresponding information in your
>published work, at least to help potential readers to verify what you
>wanted to say. P-values are always available in R - or can easily be
>found - for Gaussian or not normally distributed traits. So, you have to
>provide all the needed information is you MS. For example, every single
>t-test has to come with its df and P-value. If really you are not able to
>find this in R, then you have to use another program..."
> 
> 
>So how to proceed? Can df:s and p-values be found in any way using the R?
>If yes, how this can be done? Unfortunately I couldn't solve this problem
>by myself.
> 
>Here is an example of GLMMs estimated:
> 
>tyvivmaxp10P=glmer(Tkvmaxpit~k?sittely+tyvilpm+m3haYHT+saastotKAIK+
>TKvHirvi+(1|ruutu),family=gaussian(link ="identity"), data=pihlajatE10)
> 
>summary(tyvivmaxp10P)
> 
>Linear mixed model fit by REML
>Formula: Tkvmaxpit ~ k?sittely + tyvilpm + m3haYHT + saastotKAIK +
>TKvHirvi + (1 | ruutu)
>   Data: pihlajatE10
>   AIC  BIC logLik deviance REMLdev
>994.5 1015 -489.3    999.5   978.5
>Random effects:
>Groups   Name        Variance Std.Dev.
>ruutu    (Intercept)  207.25  14.396
> Residual             1255.73  35.436
>Number of obs: 100, groups: ruutu, 8
> 
>Fixed effects:
>             Estimate Std. Error t value
>(Intercept)  80.71047   17.52630   4.605
>k?sittely2  -45.79590   13.98636  -3.274
>tyvilpm      22.06164    6.23251   3.540
>m3haYHT       0.11672    0.31592   0.369
>saastotKAIK   0.09566    0.11513   0.831
>TKvHirvi1    12.77524    8.55455   1.493
> 
>Correlation of Fixed Effects:
>            (Intr) ksttl2 tyvlpm m3hYHT ssKAIK
>k?sittely2  -0.588
>tyvilpm     -0.662  0.126
>m3haYHT     -0.292  0.223  0.210
>saastotKAIK -0.408  0.199 -0.027 -0.192
>TKvHirvi1   -0.064 -0.124 -0.127 -0.029  0.006
> 
> 
> 
>Kind regards,
> 
>Leena Hamberg
> 
> 
>	[[alternative HTML version deleted]]
> 
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 		 	   		
>	[[alternative HTML version deleted]]
>


From marvs at umich.edu  Thu Oct 17 02:41:47 2013
From: marvs at umich.edu (Dave Marvin)
Date: Wed, 16 Oct 2013 20:41:47 -0400
Subject: [R-sig-ME] Very large standard errors in lmer
Message-ID: <999134EA-0DD5-405C-B9C0-C302EC3BE2E0@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131016/3c18de94/attachment.pl>

From seth at swbigelow.net  Thu Oct 17 04:15:40 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Wed, 16 Oct 2013 22:15:40 -0400
Subject: [R-sig-ME] Very large standard errors in lmer
In-Reply-To: <999134EA-0DD5-405C-B9C0-C302EC3BE2E0@umich.edu>
References: <999134EA-0DD5-405C-B9C0-C302EC3BE2E0@umich.edu>
Message-ID: <000901cecade$c80da150$5828e3f0$@net>

Well, if you don't include species as a random effect, then standard error
is greatly reduced because n is greatly increased (from 4 to 36 x 4, no?)and
standard error = sqrt (variance)/sqrt(n). But, as you've observed, this is
the wrong way to go about this analysis because species is the basic unit of
replication for the FT treatment. 

--Seth




-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dave Marvin
Sent: Wednesday, October 16, 2013 8:42 PM
To: R-mixed models mailing list
Subject: [R-sig-ME] Very large standard errors in lmer

I am starting a new thread on a topic arising from here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021114.html, the
relevant background is:

> I am analyzing the growth response of two plant types (vines vs. trees) to
different CO2 levels, for a mix of species of each plant type in plant
growth chambers. I am fitting a mixed model with lmer using the following
fixed and random effects structures...

> CO2 and FT are categorical predictors, each with two levels
(elevated/ambient CO2, vine/tree plant Functional Types). Each growth
chamber had the same mix of 8 species (Spp), so I would like to include both
species and chamber as random effects...

Given the question I am asking with the data from the experiment ("Do
functional types (FT) have a different relative response to CO2 level?"),
the simplest starting model that makes biological sense is:

response ~ CO2*FT + (1|Spp)

The interaction term needs to be included as part of the fixed effects (see
above question), and species needs to be included as a random effect because
there are 4 species at each of the two levels of FT. I cannot really justify
ignoring the variation inherent in the group of 8 species that I used --
plus I and others (i.e., reviewers) are interested in quantifying that
species variation while still answering the main question at the functional
type level. (It should be noted that the sample size at each level of the
predictors is n=72, and there are n=36 individuals of each species). 

It seems that a mixed model is exactly the type of model for this particular
design and question. However, it was my understanding that by including a
random effect you should be reducing the overall variation of your fixed
effects estimates. In this case it is increasing them drastically (see
example outputs below) for every response variable that I measured.
Suggestions from previous responses to center my predictors, add/remove
chamber as a random effect, and nesting species by CO2 -- i.e., (1+CO2|Spp)
-- had little effect on the SE. 

What would be causing the standard errors to increase with just the
inclusion of species as a random effect?

data fit in lm():

> Call:
> lm(formula = HtChg ~ CO2 * FT, data = striAseasonal)
> 
> Residuals:
>    Min     1Q Median     3Q    Max 
> -74.34 -44.84 -12.64  23.46 140.66 
> 
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)    
> (Intercept)   71.814      6.835  10.506  < 2e-16 ***
> CO2E           4.526      9.599   0.471    0.638    
> FTT          -46.671      9.667  -4.828 2.28e-06 ***
> CO2E:FTT      -4.133     13.648  -0.303    0.762    
> ---
> Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 
> 
> Residual standard error: 57.19 on 277 degrees of freedom
>   (7 observations deleted due to missingness)
> Multiple R-squared: 0.1563,	Adjusted R-squared: 0.1471 
> F-statistic:  17.1 on 3 and 277 DF,  p-value: 3.218e-10 



data fit in lmer() with species as random effect:

> Linear mixed model fit by REML 
> Formula: HtChg ~ CO2 * FT + (1 | Spp) 
>    Data: striAseasonal 
>   AIC  BIC logLik deviance REMLdev
>  2747 2769  -1367     2762    2735
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Spp      (Intercept) 2950.78  54.321  
>  Residual              965.36  31.070  
> Number of obs: 281, groups: Spp, 8
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   69.319     27.408   2.529
> CO2E           7.022      5.218   1.346
> FTT          -44.221     38.760  -1.141
> CO2E:FTT      -6.808      7.419  -0.918
> 
> Correlation of Fixed Effects:
>          (Intr) CO2E   FTT   
> CO2E     -0.097              
> FTT      -0.707  0.068       
> CO2E:FTT  0.068 -0.703 -0.096

	[[alternative HTML version deleted]]


From anders.tisell at liu.se  Thu Oct 17 11:34:39 2013
From: anders.tisell at liu.se (Anders Tisell)
Date: Thu, 17 Oct 2013 09:34:39 +0000
Subject: [R-sig-ME] Save estimates as CSV
Message-ID: <73DBCD6D-7E61-444D-95F0-90EF5D590405@liu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/aaa7d37a/attachment.pl>

From baud-bovy.gabriel at hsr.it  Thu Oct 17 13:07:53 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Thu, 17 Oct 2013 13:07:53 +0200
Subject: [R-sig-ME] Save estimates as CSV
In-Reply-To: <73DBCD6D-7E61-444D-95F0-90EF5D590405@liu.se>
References: <73DBCD6D-7E61-444D-95F0-90EF5D590405@liu.se>
Message-ID: <525FC509.9030408@hsr.it>

Hi Anders,

You should use

print(summary(model))

in the loop.

Note that there are many functions to extract information
from a fitted model (e.g. coef, getME,  VarCorr, ...) beside summary.

To save your results, it is best to define an empty structure (list, 
array or data
frame) before running your loop and store your
results in it as you proceed. See also the plyr package.

There are many ways of computing the mean, interval of
confidence, SD, etc. in R.  I suggest that you find a good
book on R as your question appears to me much more
R programming than to mixed effect models.

Best,

Gabriel


On 17/10/2013 11:34 AM, Anders Tisell wrote:
> Hi,
>
> I have measured a variable called R1 now I what to create a mixed linear model describing the variable R1, with the fixed effect Group which have 2 levels, and two random effects, called fpIDX and VOIidx.
>
> I want to calculate this model for a number of data sets therefore I tried to write a script with a for loop running over all data sets. When the loop is running I want to print the summery of the model. However, when I use the summary() function in the script there is no output, and I instead used the print() function (When I do it line by line in the console the summary() function works fine).
>
> Then, I also what to calculate the mean and standard deviation of the estimated R1 for each group,  calculate 95% confidence the mean difference between the two groups, and calculate a post hoc t-test for the difference. Finally, I want to save the values of mean, SD of each group, the 95% conf.int. and the significance level to the t test in to a CSV file.
>
> The for loop now looks like the following:
> *** snip ***
>
> for(i in 1:length(FileList)){
>
>
>
>      # Read the dataset into object data
>      data <- read.csv(FileList[i])
>
>      # display the data
>
>
>
>      str(data)
>
>      # Calculate a mixed linear model with Group as fixed effect, VOIidx and fpIDX as random effects
>      model <- lmer(R1 ~ 1 + Group + ( 1  | fpIDX ) + ( 1 | VOIidx), data)
>      print(model)
>
>      summary(model)    # this command do not yield any out put when I use it in the script file
>
>
>
>   # Calculate mean R1 and SD for each Group
>
>      #???
>
>   # Calculate 95% of mean difference between Groups
>      #???
>
>   # Calculate post-hoc test between Groups
>      #???
>
>      # Save data to a result file
>
>      # ???? How could I save the data
>
>
> }
>
> *** snip ***
>
> I would be glad for help in both my questions:
>
> 1. How do I get the information presented with the summary command for a lmer model when I am using a script?
>
> 2. How do I calculate and save estimates of mean, confint, test, etc of a lmer model?
>
> I'm using the R GUI for Mac OS version R 3.0.1 GUI 1.61 Snow Leopard build (6492)
>
> Best regards
> Anders
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From jkamienk at gmail.com  Thu Oct 17 16:06:57 2013
From: jkamienk at gmail.com (Juan Kamienkowski)
Date: Thu, 17 Oct 2013 11:06:57 -0300
Subject: [R-sig-ME] Warning in rankMatrix(X)
Message-ID: <CAARjoQTYrhbzBoZF87qbtb_E463CqeZmNptesvXfLuL_GXtzcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/0f4f39be/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Oct 17 16:07:37 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 17 Oct 2013 16:07:37 +0200
Subject: [R-sig-ME] Update to 'metafor' Package
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D8A1EF8DA@UM-MAIL4112.unimaas.nl>

Dear "Mixed Modelers",

I am usually not too crazy about posts regarding package updates (those who use certain packages find out about those updates anyway), but once in a while this can be useful when those updates are of a more substantive nature than some bug fixes and slight improvements and when those updates may be of interest to a larger audience. With that in mind, I wanted to let the group know that I recently updated the 'metafor' package (a package for conducting meta-analyses with R). Since the usual meta-analytic models are in fact mixed-effects models, I figured that this may be of interest to at least some readers.

In the recent update, I added functionality for fitting multilevel/multivariate meta-analytic models. This was on my to-do list for longer than I like to admit, and the code for this had been sitting around for a long time, but it took quite some effort to properly test and document it. By the way, during that process, I gained entirely new levels of appreciation for packages like 'nlme' and 'lme4', which are in a league of their own, given their capabilities, flexibility, and stableness.

At any rate, this functionality is finally available, which makes it possible to fit a wide variety of rather complex meta-analytic models. This includes multivariate models for dependent outcomes (e.g., resulting from multiple assessments of the same response variable with different instruments, multiple assessments of different response variables, or multiple assessments of the response variable over time), models for network meta-analyses (also called multitreatment comparison meta-analyses), phylogenetic meta-analyses (i.e., meta-analyses that account for the shared phylogenetic history among the organisms studied), and in general models that account for correlation in outcomes induced by a multilevel structure in the data (e.g., multiple effects derived from the same paper, lab, research group, or species may be more similar to each other than effects derived from different papers, labs, research groups, or species).

In principle, one can also (ab)use this functionality for fitting mixed-effects model to primary data using two-step procedures. I'll give a simple example using the Orthodont data:

library(nlme)
library(metafor)
library(Matrix)

data(Orthodont)

### "center" the age variable
Orthodont$age <- Orthodont$age - 8

### standard random intercepts and slopes mixed-effects model
res1 <- lme(distance ~ age, random = ~ age | Subject, data=Orthodont)

### fit regression model per person
res.list <- lmList(distance ~ age, data=Orthodont)

### obtain coefficients and var-cov matrices thereof
b <- lapply(res.list, coef)
V <- lapply(res.list, vcov)

### dummy for coefficients and subject id variable
x    <- rep(c("Int","Slope"), length(b))
subj <- rep(names(b), each=2)

### create one long vector with the coefficients and corresponding var-cov matrix
b <- unlist(b)
V <- as.matrix(bdiag(V))

### now conduct a meta-analysis with the coefficients using an unstructed var-cov matrix for the true outcomes (i.e., coefficients)
res2 <- rma.mv(b ~ x - 1, V, random = ~ x | subj, struct="UN")

summary(res1)
summary(res2)

The results are quite similar. I would not recommend to do something like that in general, but it nicely illustrates how such a two-stage procedure (fit the "level 1 model" per person, then aggregate the coefficients) is quite similar to what the mixed-effects model does. In teaching about mixed-effects models, I have found it helpful to show this correspondence. I should point out though that I wrote rma.mv() for meta-analytic applications, where the total number of observed outcomes is typically quite small. I therefore spent little (read: no) effort on making it efficient for large sample sizes. So, if you feed 1000s of effects to it, you can make a pot of coffee (and probably consume it) while you wait for the model to converge.

You can read more about the metafor package on the package website at:

http://www.metafor-project.org/

On the website, I also provide some analysis examples, illustrating how various methods and models described in the meta-analytic literature can be replicated using the package:

http://www.metafor-project.org/doku.php/analyses

I'll keep expanding on this as I find the time. For the ecologists on this list -- I'll add a phylogenetic meta-analysis example as soon as I get my hands on an illustrative dataset. The package will also get another update in the near future, allowing for autoregressive structures in the true effects (useful when there are multiple assessments of an effect over time).

Anyway, I hope this was of interest to at least some readers. Now back to your regular scheduled program on mixed-effects models ...

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


From gd339 at cam.ac.uk  Thu Oct 17 15:01:56 2013
From: gd339 at cam.ac.uk (Gabrielle Davidson)
Date: Thu, 17 Oct 2013 14:01:56 +0100
Subject: [R-sig-ME] Error in glmmadmb: could not find function "paste0"
Message-ID: <CANEya6gvwsKcG9Sm+mv43gJdfUpUSN79V689ZpgYsW1EN0F74A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/7981556b/attachment.pl>

From bbolker at gmail.com  Thu Oct 17 16:38:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Oct 2013 14:38:19 +0000 (UTC)
Subject: [R-sig-ME] Error in glmmadmb: could not find function
References: <CANEya6gvwsKcG9Sm+mv43gJdfUpUSN79V689ZpgYsW1EN0F74A@mail.gmail.com>
Message-ID: <loom.20131017T163724-55@post.gmane.org>

Gabrielle Davidson <gd339 at ...> writes:

> 
> Hi,
> 
> I'm trying to run a glmm fit to a negative binomial and am using glmmADMB.
> I'm not sure why I keep getting an error message.
> 

 [snip]

> 
> Error in glmmadmb(allVisits ~ Species + Treatment + Species * Treatment +
>  :
>   could not find function "paste0"
> 
> I'd be so grateful if someone could shed some light on this for me!
> 
> Thanks!
> 

  You have an older version of R.  I should update the glmmADMB
package to explicitly require newer versions ... but you can work
around this by defining

paste0 <- function(...) paste(...,sep="")


From bbolker at gmail.com  Thu Oct 17 16:40:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Oct 2013 14:40:28 +0000 (UTC)
Subject: [R-sig-ME] Warning in rankMatrix(X)
References: <CAARjoQTYrhbzBoZF87qbtb_E463CqeZmNptesvXfLuL_GXtzcw@mail.gmail.com>
Message-ID: <loom.20131017T163851-964@post.gmane.org>

Juan Kamienkowski <jkamienk at ...> writes:

> 
> Hi,
> 
> I moved to lmer 1.0-4 and R 3.0.2. Now lmer() and glmer() functions are
> working much slower than before, and I get the following warning message,
> which I suspect is related to that.
> 
> Warning in rankMatrix(X) :
>   rankMatrix(<large sparse Matrix>, method = 'tolNorm2') coerces to dense
> matrix.
>   Probably should rather use  method = 'qrLINPACK' !?
> 
> Do you have any advice on this? Where can I change the method of the
> rankMatrix()?
> 


  This is a known bug, actually in Matrix: we hope to fix it soon,
but it will require a coordinated release of Matrix, RcppEigen,
and lme4.  You can ignore it for now, or use suppressWarnings() if
it's really annoying you (although that will suppress *all* warnings,
so it may not be a good idea).

  Sorry about things slowing down: can you tell us more about your
use case?  Have you tried switching from the default Nelder_Mead to
the (sometimes faster) bobyqa setting?  (see ?lmerControl)

  Ben Bolker


From marvs at umich.edu  Thu Oct 17 16:48:15 2013
From: marvs at umich.edu (Dave Marvin)
Date: Thu, 17 Oct 2013 10:48:15 -0400
Subject: [R-sig-ME] Zero random effect variance?
Message-ID: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu>

For the following dataset (described at the bottom of this email), a boxplot of the data by chamber

> height=read.table("height.txt",header=TRUE)
> boxplot(HtChg~Chamber,data=height)

shows there is clearly a lot of chamber-to-chamber variation in the response variable. However, if I run a random intercept-only model:

> lmer(HtChg~1+(1|Chamber),data=height)

I get 0 variance for the random intercept. Same is true if I then include any categorical fixed effects. Does this seem correct, and if so why? 
-Dave


> I am analyzing the growth response (Height Change) of two plant types (vines vs. trees) to different CO2 levels, for a mix of species of each plant type in plant growth chambers (Chamber). CO2 and FT are categorical predictors, each with two levels (elevated/ambient CO2, vine/tree plant Functional Types). Each growth chamber had the same mix of 8 species (Spp).


From kw.stat at gmail.com  Thu Oct 17 18:03:53 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 17 Oct 2013 11:03:53 -0500
Subject: [R-sig-ME] Error in glmmadmb: could not find function "paste0"
In-Reply-To: <CANEya6gvwsKcG9Sm+mv43gJdfUpUSN79V689ZpgYsW1EN0F74A@mail.gmail.com>
References: <CANEya6gvwsKcG9Sm+mv43gJdfUpUSN79V689ZpgYsW1EN0F74A@mail.gmail.com>
Message-ID: <CAKFxdiSGC+0saYZHFEFrZkww-QnK9sMiKaX_do4eR3a-guPEpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/eb189c39/attachment.pl>

From gd339 at cam.ac.uk  Thu Oct 17 21:26:13 2013
From: gd339 at cam.ac.uk (Gabrielle Davidson)
Date: Thu, 17 Oct 2013 20:26:13 +0100
Subject: [R-sig-ME] Error in glmmadmb: could not find function "paste0"
In-Reply-To: <CAKFxdiSGC+0saYZHFEFrZkww-QnK9sMiKaX_do4eR3a-guPEpg@mail.gmail.com>
References: <CANEya6gvwsKcG9Sm+mv43gJdfUpUSN79V689ZpgYsW1EN0F74A@mail.gmail.com>
	<CAKFxdiSGC+0saYZHFEFrZkww-QnK9sMiKaX_do4eR3a-guPEpg@mail.gmail.com>
Message-ID: <CANEya6jD-hAy482JSFvOCH1=zyhTB_2=E6P8TFoWnMojy7dEDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/8bd03748/attachment.pl>

From bbolker at gmail.com  Fri Oct 18 02:16:52 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 18 Oct 2013 00:16:52 +0000 (UTC)
Subject: [R-sig-ME] Zero random effect variance?
References: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu>
Message-ID: <loom.20131018T021649-517@post.gmane.org>

Dave Marvin <marvs at ...> writes:

> 
> For the following dataset (described at the bottom of this email), 

  Did you mean to include an actual data set, or just the text description?
Without the data set itself, we can't do better than guessing.

> a boxplot of the data by chamber
> 
> > height=read.table("height.txt",header=TRUE)
> > boxplot(HtChg~Chamber,data=height)
 
> shows there is clearly a lot of chamber-to-chamber variation in the
> response variable. However, if I run a random intercept-only model:
 
> > lmer(HtChg~1+(1|Chamber),data=height)
> 
> I get 0 variance for the random intercept. Same is true if I then 
> include any categorical fixed effects. Does
> this seem correct, and if so why? 
> -Dave
 
> > I am analyzing the growth response (Height Change) of two plant
>  types (vines vs. trees) to different CO2 levels, for a mix of
>  species of each plant type in plant growth chambers (Chamber). CO2
>  and FT are categorical predictors, each with two levels
>  (elevated/ambient CO2, vine/tree plant Functional Types). Each
>  growth chamber had the same mix of 8 species (Spp).

  Presumably the within-chamber variation is large enough that
it adequately accounts for the among-chamber variation?
Again, hard to say without seeing the data ... you could do the 
math yourself (e.g. is variance among >= (variance within)/(n within)?),
or simulate some representative examples ...


From marvs at umich.edu  Fri Oct 18 02:28:29 2013
From: marvs at umich.edu (Dave Marvin)
Date: Thu, 17 Oct 2013 20:28:29 -0400
Subject: [R-sig-ME] Zero random effect variance?
In-Reply-To: <loom.20131018T021649-517@post.gmane.org>
References: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu>
	<loom.20131018T021649-517@post.gmane.org>
Message-ID: <550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>

Sorry, I included it as a text file attachment. Guessing the list-serv strips attachments... Here is a link to the text file: http://goo.gl/e5q2hO

If that is the issue (which after looking back at my boxplot is probably the case) should I still expect literally zero variance attributed to the chambers?


On Oct 17, 2013, at 8:16 PM, Ben Bolker wrote:

> Dave Marvin <marvs at ...> writes:
> 
>> 
>> For the following dataset (described at the bottom of this email), 
> 
>  Did you mean to include an actual data set, or just the text description?
> Without the data set itself, we can't do better than guessing.
> 
>> a boxplot of the data by chamber
>> 
>>> height=read.table("height.txt",header=TRUE)
>>> boxplot(HtChg~Chamber,data=height)
> 
>> shows there is clearly a lot of chamber-to-chamber variation in the
>> response variable. However, if I run a random intercept-only model:
> 
>>> lmer(HtChg~1+(1|Chamber),data=height)
>> 
>> I get 0 variance for the random intercept. Same is true if I then 
>> include any categorical fixed effects. Does
>> this seem correct, and if so why? 
>> -Dave
> 
>>> I am analyzing the growth response (Height Change) of two plant
>> types (vines vs. trees) to different CO2 levels, for a mix of
>> species of each plant type in plant growth chambers (Chamber). CO2
>> and FT are categorical predictors, each with two levels
>> (elevated/ambient CO2, vine/tree plant Functional Types). Each
>> growth chamber had the same mix of 8 species (Spp).
> 
>  Presumably the within-chamber variation is large enough that
> it adequately accounts for the among-chamber variation?
> Again, hard to say without seeing the data ... you could do the 
> math yourself (e.g. is variance among >= (variance within)/(n within)?),
> or simulate some representative examples ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From David.Duffy at qimr.edu.au  Fri Oct 18 03:04:01 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 18 Oct 2013 11:04:01 +1000
Subject: [R-sig-ME] Zero random effect variance?
In-Reply-To: <550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>
References: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu><loom.20131018T021649-517@post.gmane.org>
	<550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>
Message-ID: <alpine.LMD.2.00.1310181100050.20417@orpheus.qimr.edu.au>

On Fri, 18 Oct 2013, Dave Marvin wrote:

> If that is the issue (which after looking back at my boxplot is probably 
> the case) should I still expect literally zero variance attributed to 
> the chambers?

Yes. The within-chamber intraclass correlation is -0.0835  (SE=0.0309) 
using the pairwise estimator.

| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bbolker at gmail.com  Fri Oct 18 05:05:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Oct 2013 23:05:57 -0400
Subject: [R-sig-ME] Zero random effect variance?
In-Reply-To: <550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>
References: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu>
	<loom.20131018T021649-517@post.gmane.org>
	<550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>
Message-ID: <5260A595.5080803@gmail.com>

On 13-10-17 08:28 PM, Dave Marvin wrote:
> Sorry, I included it as a text file attachment. Guessing the
> list-serv strips attachments... Here is a link to the text file:
> http://goo.gl/e5q2hO
> 
> If that is the issue (which after looking back at my boxplot is
> probably the case) should I still expect literally zero variance
> attributed to the chambers?

  Yes.  This is a case, I think (referred to from time to time in
threads on this list), where the classical method of moments estimates
would give a negative among-group variance, or a compound symmetry model
would give negative within-group correlations; the framework used in
lme4 can't do either of those things easily.  (It would be entertaining
but totally impractical to try to figure out what kind of imaginary- or
complex-valued values one would need in the computations to get this to
work out).

  Ben Bolker

> 
> 
> On Oct 17, 2013, at 8:16 PM, Ben Bolker wrote:
> 
>> Dave Marvin <marvs at ...> writes:
>> 
>>> 
>>> For the following dataset (described at the bottom of this
>>> email),
>> 
>> Did you mean to include an actual data set, or just the text
>> description? Without the data set itself, we can't do better than
>> guessing.
>> 
>>> a boxplot of the data by chamber
>>> 
>>>> height=read.table("height.txt",header=TRUE) 
>>>> boxplot(HtChg~Chamber,data=height)
>> 
>>> shows there is clearly a lot of chamber-to-chamber variation in
>>> the response variable. However, if I run a random intercept-only
>>> model:
>> 
>>>> lmer(HtChg~1+(1|Chamber),data=height)
>>> 
>>> I get 0 variance for the random intercept. Same is true if I then
>>>  include any categorical fixed effects. Does this seem correct,
>>> and if so why? -Dave
>> 
>>>> I am analyzing the growth response (Height Change) of two
>>>> plant
>>> types (vines vs. trees) to different CO2 levels, for a mix of 
>>> species of each plant type in plant growth chambers (Chamber).
>>> CO2 and FT are categorical predictors, each with two levels 
>>> (elevated/ambient CO2, vine/tree plant Functional Types). Each 
>>> growth chamber had the same mix of 8 species (Spp).
>> 
>> Presumably the within-chamber variation is large enough that it
>> adequately accounts for the among-chamber variation? Again, hard to
>> say without seeing the data ... you could do the math yourself
>> (e.g. is variance among >= (variance within)/(n within)?), or
>> simulate some representative examples ...
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From marvs at umich.edu  Fri Oct 18 05:14:42 2013
From: marvs at umich.edu (Dave Marvin)
Date: Thu, 17 Oct 2013 23:14:42 -0400
Subject: [R-sig-ME] Zero random effect variance?
In-Reply-To: <5260A595.5080803@gmail.com>
References: <491D697C-8C57-41F6-9C90-F65EA4AFD8B0@umich.edu>
	<loom.20131018T021649-517@post.gmane.org>
	<550F3E1A-4131-484B-AE3D-FDCD17716D13@umich.edu>
	<5260A595.5080803@gmail.com>
Message-ID: <CBF1D025-45B4-4A9C-9386-4093090C5BF1@umich.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131017/2ad76fcd/attachment.pl>

From jkamienk at gmail.com  Fri Oct 18 14:34:25 2013
From: jkamienk at gmail.com (Juan Kamienkowski)
Date: Fri, 18 Oct 2013 09:34:25 -0300
Subject: [R-sig-ME] Warning in rankMatrix(X)
In-Reply-To: <loom.20131017T163851-964@post.gmane.org>
References: <CAARjoQTYrhbzBoZF87qbtb_E463CqeZmNptesvXfLuL_GXtzcw@mail.gmail.com>
	<loom.20131017T163851-964@post.gmane.org>
Message-ID: <CAARjoQT2krt1SO9SHaQhzjG7gjB64TeJxHuCt_jjWOQZUH=7ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131018/1de419e3/attachment.pl>

From johannesradinger at gmail.com  Fri Oct 18 14:38:34 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Fri, 18 Oct 2013 14:38:34 +0200
Subject: [R-sig-ME] pwrssUpdate Error with new version of lme4
Message-ID: <CABsGe_yc0ZYxO8ZwHmDYb4_=iJNcqi8J3uT1ZVvYeNW+jmBduA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131018/7347da9d/attachment.pl>

From jlaurenceau at psych.udel.edu  Mon Oct 21 03:52:20 2013
From: jlaurenceau at psych.udel.edu (Jean-Philippe Laurenceau)
Date: Sun, 20 Oct 2013 21:52:20 -0400
Subject: [R-sig-ME] equality constraints in lmer/lme4
Message-ID: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131020/d55c2417/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Oct 21 04:54:54 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 21 Oct 2013 12:54:54 +1000
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
Message-ID: <alpine.LMD.2.00.1310211247410.30743@orpheus.qimr.edu.au>

On Mon, 21 Oct 2013, Jean-Philippe Laurenceau wrote:

> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>
> My question: is there a way to ask lme4 to re-estimate this model but 
> set an equality constraint on the effects of X1 and X2, such that their 
> estimates would be equal to each other?

Create the appropriate composite dummy variable (lmer doesn't offer LISREL 
style constraints). For instance, if X1, X2 are categorical then X1=A 
X2=A -> dummy.A=2, dummy.B=0...

Cheers, David Duffy.


From lamprianou at yahoo.com  Mon Oct 21 12:19:35 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 21 Oct 2013 03:19:35 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 82, Issue 31
In-Reply-To: <mailman.3.1382349602.25802.r-sig-mixed-models@r-project.org>
References: <mailman.3.1382349602.25802.r-sig-mixed-models@r-project.org>
Message-ID: <1382350775.3402.YahooMailNeo@web160104.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131021/20a6afd3/attachment.pl>

From tim.cole at ucl.ac.uk  Mon Oct 21 13:25:59 2013
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Mon, 21 Oct 2013 11:25:59 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 82, Issue 31
In-Reply-To: <mailman.3.1382349602.25802.r-sig-mixed-models@r-project.org>
Message-ID: <CE8ACB9B.271FB%tim.cole@ucl.ac.uk>

Probably easier, if X1 and X2 are continuous, would be

fm <- lmer ( Outcome ~ I(X1 + X2) + ( 1 | Subject ), data = mydata)

Best wishes,
Tim Cole

On Mon, 21 Oct 2013, David Duffy wrote:

>On Mon, 21 Oct 2013, Jean-Philippe Laurenceau wrote:
>
>>fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>>
>>My question: is there a way to ask lme4 to re-estimate this model but
>>set an equality constraint on the effects of X1 and X2, such that their
>>estimates would be equal to each other?
>
>Create the appropriate composite dummy variable (lmer doesn't offer LISREL
>style constraints). For instance, if X1, X2 are categorical then X1=A
>X2=A -> dummy.A=2, dummy.B=0...
>
>Cheers, David Duffy.
-- 

Tim.Cole at ucl.ac.uk <mailto:Tim.Cole at ich.ucl.ac.uk> Phone +44(0)20 7905
2666 Fax +44(0)20 7905 2381
MRC Centre of Epidemiology for Child Health
<http://www.ucl.ac.uk/ich/research-ich/mrc-cech>
UCL Institute of Child Health, London WC1N 1EH, UK
** PLEASE- NOTE NEW EMAIL ADDRESS **


From sharon.graham at pg.canterbury.ac.nz  Mon Oct 21 13:45:13 2013
From: sharon.graham at pg.canterbury.ac.nz (Elizabeth Graham)
Date: Mon, 21 Oct 2013 11:45:13 +0000
Subject: [R-sig-ME] Error structure for split-split plot with treatment
	across blocks
Message-ID: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131021/9b860319/attachment.pl>

From pearman at wsl.ch  Mon Oct 21 14:37:37 2013
From: pearman at wsl.ch (Peter B. Pearman)
Date: Mon, 21 Oct 2013 14:37:37 +0200
Subject: [R-sig-ME] MCMCglmm model and prior specification-incomplete
	sampling of blocks
Message-ID: <52652011.4000401@wsl.ch>

Hello MCMCglmm users,

I'm new to mixed models in MCMCglmm and have been trying to get up to
speed by reading in the Course Notes, Overview, Tutorial and items on
this list. I'm hoping that someone would comment on the specification of
the model I'm contemplating. I'm having trouble deciding on the
appropriate specification of the random effects (among other things),
in part because I don't know how to account for potential
non-independence among blocks and sites within block, given that only
one block has been sampled each year.

Some background:
As a preliminary to a study on the power of a monitoring project, I'm
interested in modeling trends in count data (numbers of species) over a
sequence of years, and identifying important sources of variation.
There are 5 blocks of sample sites, with about 60 sites in each block.
The blocks are not geographically distinct, meaning that all the sites
in all blocks are distributed throughout the same area.  Sites are
identified by 'coordID' and are classified by a factor, land.use, with 4
levels.  Each block has been sampled every 5 years in a rotation,
meaning that for each year there are response data for just one block of
sites. Three blocks have been sampled 4 times and two blocks only 3 times.

I have organized the data so that for each year the response,
'richness', has positive integer values for the sites in the block that
was sampled.  For all sites in other blocks that were not sampled in a
year, richness is NA.

Questions and model:
I'd like to know whether the among-site correlations (or covariances)
within blocks are greater than 0. It seems reasonable that values for
sites within a block may be more strongly correlated than values for
sites in different blocks. How I can incorporate and test for
non-independence of sites within block?

Also, how could I incorporate and test for non-zero co-variances among
blocks?  This might be a problem since block and year are confounded.
I should be able to determine whether among-block covariance is
important and should be included, or not, right? Or is this not possible
given this design?

I suggest the following prior:

prior.1 <- list(R = list(V = 1, nu = 0.002), G = list(G1 = list(V = 1,
nu = 0.002)))

(questions: Other priors to consider?  How can I determine whether a
prior is uninformative or not?)

and the following model, to start, realizing that the random
specification could be complete nonsense (large number off-diagonal terms?):

m1 <- MCMCglmm(richness ~ year:land.use -1,
                               random = ~ us(block):coordID,
                               family = "poisson",
                               data = x.3,
                               prior = prior.1,
                               nitt = 100000,
                               thin=  100,
                               burnin = 4000,
                               verbose = FALSE)

Any additional aspects I should consider? Have neglected? Alternatives?

Thank you in advance for any information that might alleviate my confusion.

Peter


From chevillot.xavier at live.fr  Mon Oct 21 14:53:34 2013
From: chevillot.xavier at live.fr (xavier chevillot)
Date: Mon, 21 Oct 2013 14:53:34 +0200
Subject: [R-sig-ME] select glmm r function
Message-ID: <DUB115-W5683757582B255C57C2AAF83010@phx.gbl>

Hello ,
I have to make a choice to compute a
delta-Glmm and i would like to have your comments.
I must to make a delta-glmm (binomial/gamma) with
an ARMA correlation.
I think that i must choose the glmmPQL function but i
have few questions.
(1)PQL is realy good for the binomial model (Breslow,2003)?
(2)Can i compute a CorStruct whit an other R function (
glmer? visibly not (Package comparisonin wikidot) )?
(3)If i use GlmmPQL ,how to select the significants variables and
their orders whitout AIC or BIC?
Thank you for your time
.Xavier.C
 		 	   		  

From bbolker at gmail.com  Mon Oct 21 15:14:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Oct 2013 13:14:58 +0000 (UTC)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 82, Issue 31
References: <mailman.3.1382349602.25802.r-sig-mixed-models@r-project.org>
	<1382350775.3402.YahooMailNeo@web160104.mail.bf1.yahoo.com>
Message-ID: <loom.20131021T143928-645@post.gmane.org>

Iasonas Lamprianou <lamprianou at ...> writes:

 
> Dear all, I have recently faced a problem where lme4 seems to be
> broken on R version 3.0.2 for 64 bits. I run a model which was
> always OK, and I get this message:
 
> m1.4.1 <- glmer(value ~ 1 + Specialist + Qualification + Experience
> + (1 | Writer) + (1 + Gender | Rule), writers.long , binomial,
> verbose = TRUE) Warning in rankMatrix(X) : rankMatrix(<large sparse
> Matrix>, method = 'tolNorm2') coerces to dense matrix. Probably
> should rather use method = 'qrLINPACK' !?

    This is a known false positive warning that actually
emanates from the Matrix package.  Fixing this will require a coordinated
release of a new Matrix, new RcppEigen, and new lme4 package.  You
can feel free to ignore it, though.

> Has anyone seen this message before? Has anyone noticed lme4
> behaving strangely these days after an update. I also get messages
> regarding Cholemsky function and not enough memory, on models which
> used to run very happily. Any help will be appreciated.

  Can't say much about these latter cases without specific examples,
although we would certainly be interested to find out more about
such cases.

  Ben Bolker


From bbolker at gmail.com  Mon Oct 21 15:38:01 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Oct 2013 13:38:01 +0000 (UTC)
Subject: [R-sig-ME] pwrssUpdate Error with new version of lme4
References: <CABsGe_yc0ZYxO8ZwHmDYb4_=iJNcqi8J3uT1ZVvYeNW+jmBduA@mail.gmail.com>
Message-ID: <loom.20131021T152542-449@post.gmane.org>

Johannes Radinger <johannesradinger at ...> writes:

> Hi all,
> 
> I'd like to follow up an issue which had already been discussed some weeks
> ago
> about the pwrss error in the new version of lme4:
> https://github.com/lme4/lme4/issues/134
> Thanks to Ben Bolker who had worked to solve that problem and implemented
> solutions in the release branch in github.
> 
> I tried that version from github (lme4_1.0-5) but run again/still in
> problems (which I didn't have with the older lm4 version). Again, I can
> provide some data (see below) to reproduce following error:
> Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> 
> The error occurs only when I include both predictors and all species:
> mod <- glmer(presabs~pred1+pred2+(1|species),family=binomial,data=mydf)
> 
> Models with single predictors work:
> mod1 <- glmer(presabs~pred1+(1|species),family=binomial,data=mydf)
> mod2 <- glmer(presabs~pred2+(1|species),family=binomial,data=mydf)
> 
> when I remove species "Rutiilus" the model also works:
> mod3 <-
> glmer(presabs~pred1+pred2+(1|species),family=binomial,
>   data=mydf[mydf$species!="Rutiilus",])
> 
> So there seems and issue with the combinations of that single species and
> the two predictors.
> However that was working in lme4_0.999999-2 (except for warnings: "glm.fit:
> fitted probabilities numerically 0 or 1 occurred ").
> 

 [snip snip snip ]

  In our defense, these are awfully messy data -- most of the predictor
values are concentrated very near zero, with a few values that are
many orders of magnitude larger ... and there seems to be an issue
of complete separation/large parameter values.  The proximal problem
was another underflow issue, which I have fixed in the development
branch on github.  The change also (mostly) fixes the other examples
reported at https://github.com/lme4/lme4/issues/138 , although they
still take a long time to run and end with a warning about the maximum
number of function evaluations being exceeded ...
  (This example no longer gives a warning with glmer: I'm not sure
whether it should or not)


From stevedrd at yahoo.com  Mon Oct 21 16:45:45 2013
From: stevedrd at yahoo.com (Steve Denham)
Date: Mon, 21 Oct 2013 07:45:45 -0700 (PDT)
Subject: [R-sig-ME] Error structure for split-split plot with
	treatment	across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <1382366745.96544.YahooMailNeo@web140606.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131021/b352aa41/attachment.pl>

From S.Ellison at LGCGroup.com  Mon Oct 21 18:00:21 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 21 Oct 2013 17:00:21 +0100
Subject: [R-sig-ME] Error structure for split-split plot with
	treatment	across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Elizabeth Graham
> Sent: 21 October 2013 12:45
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Error structure for split-split plot with treatment
> across blocks
> 
> Hello,
> 
> I am trying to create a LME model for a split-split-plot experiment.
> 
> My current model is as follows, based on the split-plot design outlined
> in Pinheiro and Bates 2000:
> 
> model<-lme(log(density)~Treatment*Shade*Leaves,
>                        random=~1|Stream/Treatment/Shade/Leaves)
> 

Question: Do you really want Treatment in the random-effects structure? 
The main reason for asking is that in principle it is a two-level fixed effect of interest, so it's a bit surprising to see it over on the right at all. Further, from your data you have your streams nested in Treatment which makes me wonder how it can be sensible to have a random-effects spec that puts treatment nested in stream.

Given that you probably want Treatment tested against the Stream-level random effect that is essentially the replication level per treatment, I'd have expected something like 
m2<-lme(log(density)~Treatment*Shade*Leaves,
                        random=~1|Stream/Shade/Leaves) 

That structure also works in aov: 

> summary(aov(log(density)~Treatment*Shade*Leaves+Error(Stream/Shade/Leaves), data))

testing Treatment against the random Stream effect and other effects, but unsurprisingly returns a singular model (killing the Stream/Treatment level of analysis) when adding Treatment in the Error term. 

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From 538280 at gmail.com  Mon Oct 21 19:44:05 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 21 Oct 2013 11:44:05 -0600
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
Message-ID: <CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>

If X1 and X2 are both numeric variables then

Outcome ~ I( X1 + X2 ) + (1|Subject)

should give you what you need.

If both are categorical, then you need to create a set of variables
that represent the combination (make sure that you understand what
that combination represents).

On Sun, Oct 20, 2013 at 7:52 PM, Jean-Philippe Laurenceau
<jlaurenceau at psych.udel.edu> wrote:
> Dear R-sig-ME list--
>
> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
>
> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>
> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
>
> Thanks for your time, J-P
>
> Jean-Philippe Laurenceau, Ph.D.
> Department of Psychology
> University of Delaware
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dmf34 at cam.ac.uk  Mon Oct 21 20:59:21 2013
From: dmf34 at cam.ac.uk (Daniel Fountain)
Date: Mon, 21 Oct 2013 19:59:21 +0100
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by simulation
 and confidence intervals - A request to check the approach
Message-ID: <CAFGyF8ygFdyXPvLv=YNOmtxc6WWvJif_BhrwBXO7F-s6a2FMrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131021/49b7b6cc/attachment.pl>

From sharon.graham at pg.canterbury.ac.nz  Mon Oct 21 21:26:58 2013
From: sharon.graham at pg.canterbury.ac.nz (Elizabeth Graham)
Date: Mon, 21 Oct 2013 19:26:58 +0000
Subject: [R-sig-ME] Error structure for split-split plot with treatment
 across blocks
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>
Message-ID: <4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>

Thanks for those prompt replies! 

m2<-lme(log(density)~Treatment*Shade*Leaves,
                        random=~1|Stream/Shade/Leaves)

was actually my original model structure, but has the same incongruity between model results and interaction plots - try interaction.plot(Shade, Treatment, density) for an example - the treatment and control lines do not intersect at all, and standard error bars do not overlap.  Thus I thought adding Treatment to the nesting structure might be necessary, as there seems to be a possible masking of a treatment effect with the random stream effect.

Thanks again S Ellison and Steve Denham, I will keep your advice in mind also.  Do people agree that the model structure above fits my experimental design?  And is there any way to investigate the treatment effect evident in the interaction plots?

Regards, 
Elizabeth
________________________________________
From: S Ellison [S.Ellison at LGCGroup.com]
Sent: Tuesday, October 22, 2013 5:00 AM
To: Elizabeth Graham; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Error structure for split-split plot with treatment across blocks

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Elizabeth Graham
> Sent: 21 October 2013 12:45
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Error structure for split-split plot with treatment
> across blocks
>
> Hello,
>
> I am trying to create a LME model for a split-split-plot experiment.
>
> My current model is as follows, based on the split-plot design outlined
> in Pinheiro and Bates 2000:
>
> model<-lme(log(density)~Treatment*Shade*Leaves,
>                        random=~1|Stream/Treatment/Shade/Leaves)
>

Question: Do you really want Treatment in the random-effects structure?
The main reason for asking is that in principle it is a two-level fixed effect of interest, so it's a bit surprising to see it over on the right at all. Further, from your data you have your streams nested in Treatment which makes me wonder how it can be sensible to have a random-effects spec that puts treatment nested in stream.

Given that you probably want Treatment tested against the Stream-level random effect that is essentially the replication level per treatment, I'd have expected something like
m2<-lme(log(density)~Treatment*Shade*Leaves,
                        random=~1|Stream/Shade/Leaves)

That structure also works in aov:

> summary(aov(log(density)~Treatment*Shade*Leaves+Error(Stream/Shade/Leaves), data))

testing Treatment against the random Stream effect and other effects, but unsurprisingly returns a singular model (killing the Stream/Treatment level of analysis) when adding Treatment in the Error term.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:17}}


From dwinsemius at comcast.net  Mon Oct 21 21:46:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Oct 2013 12:46:19 -0700
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
	<CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>
Message-ID: <447AE406-9974-489D-B006-4AD1DA239CB3@comcast.net>


On Oct 21, 2013, at 10:44 AM, Greg Snow wrote:

> If X1 and X2 are both numeric variables then
> 
> Outcome ~ I( X1 + X2 ) + (1|Subject)

Would that be:

Outcome ~ I( (X1 + X2)/2 ) + (1|Subject)  # ?

-- 
David.


> 
> should give you what you need.
> 
> If both are categorical, then you need to create a set of variables
> that represent the combination (make sure that you understand what
> that combination represents).
> 
> On Sun, Oct 20, 2013 at 7:52 PM, Jean-Philippe Laurenceau
> <jlaurenceau at psych.udel.edu> wrote:
>> Dear R-sig-ME list--
>> 
>> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
>> 
>> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>> 
>> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
>> 
>> Thanks for your time, J-P
>> 
>> Jean-Philippe Laurenceau, Ph.D.
>> Department of Psychology
>> University of Delaware
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From 538280 at gmail.com  Mon Oct 21 22:58:59 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 21 Oct 2013 14:58:59 -0600
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <447AE406-9974-489D-B006-4AD1DA239CB3@comcast.net>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
	<CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>
	<447AE406-9974-489D-B006-4AD1DA239CB3@comcast.net>
Message-ID: <CAFEqCdwTfondiz-4pXz2dREeW3acZ7=Ry3NAxtFE8m4Y41fTcw@mail.gmail.com>

No, think about the algebra, if we start with:

y = b0 + b1*x1 + b2*x2 + ...

then the constraint that b1 = b2 gives us:

y = b0 + b1*x1 + b1*x2 + ...

then factoring:

y = b0 + b1*(x1 + x2) + ...

Or we can demonstrate with a basic simulation example (here the true
common slope is 2):

> x1 <- rnorm(100, 10, 3)
> x2 <- rnorm(100, 100, 5)
> y <- 2*x1 + 2*x2 + rnorm(100,0,1)
> lm(y ~ x1 + x2)

Call:
lm(formula = y ~ x1 + x2)

Coefficients:
(Intercept)           x1           x2
     -1.862        2.034        2.015

> lm( y ~ I(x1+x2) )

Call:
lm(formula = y ~ I(x1 + x2))

Coefficients:
(Intercept)   I(x1 + x2)
     -2.282        2.021

> lm( y ~ I( (x1+x2)/2 ) )

Call:
lm(formula = y ~ I((x1 + x2)/2))

Coefficients:
   (Intercept)  I((x1 + x2)/2)
        -2.282           4.041

So you can see the averaging is not needed (or you could average, but
then you would need to multiply by 2 because we are going to make
predictions based on b1*x1+b1*x2, so the 2's would cancel).

This is just linear regression, but the concept should hold for lme as
well (if you want more convincing, simulate an lme style problem and
try it).

On Mon, Oct 21, 2013 at 1:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 21, 2013, at 10:44 AM, Greg Snow wrote:
>
>> If X1 and X2 are both numeric variables then
>>
>> Outcome ~ I( X1 + X2 ) + (1|Subject)
>
> Would that be:
>
> Outcome ~ I( (X1 + X2)/2 ) + (1|Subject)  # ?
>
> --
> David.
>
>
>>
>> should give you what you need.
>>
>> If both are categorical, then you need to create a set of variables
>> that represent the combination (make sure that you understand what
>> that combination represents).
>>
>> On Sun, Oct 20, 2013 at 7:52 PM, Jean-Philippe Laurenceau
>> <jlaurenceau at psych.udel.edu> wrote:
>>> Dear R-sig-ME list--
>>>
>>> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
>>>
>>> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>>>
>>> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
>>>
>>> Thanks for your time, J-P
>>>
>>> Jean-Philippe Laurenceau, Ph.D.
>>> Department of Psychology
>>> University of Delaware
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> David Winsemius
> Alameda, CA, USA
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From chris.brien at iinet.net.au  Mon Oct 21 23:18:12 2013
From: chris.brien at iinet.net.au (chris.brien at iinet.net.au)
Date: Tue, 22 Oct 2013 07:48:12 +1030
Subject: [R-sig-ME] Error structure for split-split plot with treatment
	across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <7d62ab23f757107a60d88edb741deb3a47d63a00@webmail.iinet.net.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/d313e256/attachment.pl>

From dwinsemius at comcast.net  Mon Oct 21 23:21:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 21 Oct 2013 14:21:35 -0700
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <CAFEqCdwTfondiz-4pXz2dREeW3acZ7=Ry3NAxtFE8m4Y41fTcw@mail.gmail.com>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
	<CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>
	<447AE406-9974-489D-B006-4AD1DA239CB3@comcast.net>
	<CAFEqCdwTfondiz-4pXz2dREeW3acZ7=Ry3NAxtFE8m4Y41fTcw@mail.gmail.com>
Message-ID: <2CECE021-1C58-4CB5-A292-DB8FCE82C844@comcast.net>


On Oct 21, 2013, at 1:58 PM, Greg Snow wrote:

> No, think about the algebra, if we start with:
> 
> y = b0 + b1*x1 + b2*x2 + ...
> 
> then the constraint that b1 = b2 gives us:
> 
> y = b0 + b1*x1 + b1*x2 + ...
> 
> then factoring:
> 
> y = b0 + b1*(x1 + x2) + ...
> 
> Or we can demonstrate with a basic simulation example (here the true
> common slope is 2):
> 
>> x1 <- rnorm(100, 10, 3)
>> x2 <- rnorm(100, 100, 5)
>> y <- 2*x1 + 2*x2 + rnorm(100,0,1)
>> lm(y ~ x1 + x2)
> 

Thanks, Greg. I get it.

I guess I'm more concrete in my thinking. I needed to see it prove experimentally. I just wasn't willing to accept it on the basis of "factoring" a formula, since there are some rather non-mathematical evaluation steps involved in the interpretation of "*" in R formulas.

-- 
David.

> Call:
> lm(formula = y ~ x1 + x2)
> 
> Coefficients:
> (Intercept)           x1           x2
>     -1.862        2.034        2.015
> 
>> lm( y ~ I(x1+x2) )
> 
> Call:
> lm(formula = y ~ I(x1 + x2))
> 
> Coefficients:
> (Intercept)   I(x1 + x2)
>     -2.282        2.021
> 
>> lm( y ~ I( (x1+x2)/2 ) )
> 
> Call:
> lm(formula = y ~ I((x1 + x2)/2))
> 
> Coefficients:
>   (Intercept)  I((x1 + x2)/2)
>        -2.282           4.041
> 
> So you can see the averaging is not needed (or you could average, but
> then you would need to multiply by 2 because we are going to make
> predictions based on b1*x1+b1*x2, so the 2's would cancel).
> 
> This is just linear regression, but the concept should hold for lme as
> well (if you want more convincing, simulate an lme style problem and
> try it).
> 
> On Mon, Oct 21, 2013 at 1:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Oct 21, 2013, at 10:44 AM, Greg Snow wrote:
>> 
>>> If X1 and X2 are both numeric variables then
>>> 
>>> Outcome ~ I( X1 + X2 ) + (1|Subject)
>> 
>> Would that be:
>> 
>> Outcome ~ I( (X1 + X2)/2 ) + (1|Subject)  # ?
>> 
>> --
>> David.
>> 
>> 
>>> 
>>> should give you what you need.
>>> 
>>> If both are categorical, then you need to create a set of variables
>>> that represent the combination (make sure that you understand what
>>> that combination represents).
>>> 
>>> On Sun, Oct 20, 2013 at 7:52 PM, Jean-Philippe Laurenceau
>>> <jlaurenceau at psych.udel.edu> wrote:
>>>> Dear R-sig-ME list--
>>>> 
>>>> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
>>>> 
>>>> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>>>> 
>>>> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
>>>> 
>>>> Thanks for your time, J-P
>>>> 
>>>> Jean-Philippe Laurenceau, Ph.D.
>>>> Department of Psychology
>>>> University of Delaware
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> 538280 at gmail.com
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com

David Winsemius
Alameda, CA, USA


From chris.brien at iinet.net.au  Mon Oct 21 23:25:12 2013
From: chris.brien at iinet.net.au (chris.brien at iinet.net.au)
Date: Tue, 22 Oct 2013 07:55:12 +1030
Subject: [R-sig-ME] Error structure for split-split plot with treatment
	across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <2c9e6989fa5cebe78cb9e1650ae8ee0d055360e0@webmail.iinet.net.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/834df8ef/attachment.pl>

From jlaurenceau at psych.udel.edu  Tue Oct 22 07:01:43 2013
From: jlaurenceau at psych.udel.edu (Jean-Philippe Laurenceau)
Date: Tue, 22 Oct 2013 01:01:43 -0400
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <CAFEqCdwTfondiz-4pXz2dREeW3acZ7=Ry3NAxtFE8m4Y41fTcw@mail.gmail.com>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
	<CAFEqCdywJDhnk3y7ggu++AMpOMeY_2Y83D6KpEtrY_ha8rnj0g@mail.gmail.com>
	<447AE406-9974-489D-B006-4AD1DA239CB3@comcast.net>
	<CAFEqCdwTfondiz-4pXz2dREeW3acZ7=Ry3NAxtFE8m4Y41fTcw@mail.gmail.com>
Message-ID: <0478721FB7E8994C9425EEC863C8EC66012803EB859D@razor.psych.udel.edu>

Dear Ewart, David D., David W., and Greg--Thanks a lot for your helpful responses. I now see that the solution is crystal clear, especially with Greg's algebra showing how constraining the coefficients of two numeric predictors in a lm or lme to be the same as entering the sum of the two predictors. And, since it appears that these two models are nested, I can also test whether this equality constraint is tenable by examining a difference in the model deviances. 

One more follow-up if I may...I presume this approach would also hold for a binary or count outcome? J-P

Jean-Philippe Laurenceau, Ph.D.
Department of Psychology
University of Delaware

-----Original Message-----
From: Greg Snow [mailto:538280 at gmail.com] 
Sent: Monday, October 21, 2013 4:59 PM
To: David Winsemius
Cc: Jean-Philippe Laurenceau; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] equality constraints in lmer/lme4

No, think about the algebra, if we start with:

y = b0 + b1*x1 + b2*x2 + ...

then the constraint that b1 = b2 gives us:

y = b0 + b1*x1 + b1*x2 + ...

then factoring:

y = b0 + b1*(x1 + x2) + ...

Or we can demonstrate with a basic simulation example (here the true common slope is 2):

> x1 <- rnorm(100, 10, 3)
> x2 <- rnorm(100, 100, 5)
> y <- 2*x1 + 2*x2 + rnorm(100,0,1)
> lm(y ~ x1 + x2)

Call:
lm(formula = y ~ x1 + x2)

Coefficients:
(Intercept)           x1           x2
     -1.862        2.034        2.015

> lm( y ~ I(x1+x2) )

Call:
lm(formula = y ~ I(x1 + x2))

Coefficients:
(Intercept)   I(x1 + x2)
     -2.282        2.021

> lm( y ~ I( (x1+x2)/2 ) )

Call:
lm(formula = y ~ I((x1 + x2)/2))

Coefficients:
   (Intercept)  I((x1 + x2)/2)
        -2.282           4.041

So you can see the averaging is not needed (or you could average, but then you would need to multiply by 2 because we are going to make predictions based on b1*x1+b1*x2, so the 2's would cancel).

This is just linear regression, but the concept should hold for lme as well (if you want more convincing, simulate an lme style problem and try it).

On Mon, Oct 21, 2013 at 1:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 21, 2013, at 10:44 AM, Greg Snow wrote:
>
>> If X1 and X2 are both numeric variables then
>>
>> Outcome ~ I( X1 + X2 ) + (1|Subject)
>
> Would that be:
>
> Outcome ~ I( (X1 + X2)/2 ) + (1|Subject)  # ?
>
> --
> David.
>
>
>>
>> should give you what you need.
>>
>> If both are categorical, then you need to create a set of variables 
>> that represent the combination (make sure that you understand what 
>> that combination represents).
>>
>> On Sun, Oct 20, 2013 at 7:52 PM, Jean-Philippe Laurenceau 
>> <jlaurenceau at psych.udel.edu> wrote:
>>> Dear R-sig-ME list--
>>>
>>> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
>>>
>>> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
>>>
>>> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
>>>
>>> Thanks for your time, J-P
>>>
>>> Jean-Philippe Laurenceau, Ph.D.
>>> Department of Psychology
>>> University of Delaware
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> David Winsemius
> Alameda, CA, USA
>



--
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bbolker at gmail.com  Tue Oct 22 15:25:10 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Oct 2013 09:25:10 -0400
Subject: [R-sig-ME] Fwd: What does "number of groups < 50"
In-Reply-To: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
Message-ID: <52667CB6.7070809@mcmaster.ca>


[forwarding to r-sig-mixed models]

-------- Original Message --------
Subject: What does "number of groups < 50"
Resent-Date: Tue, 22 Oct 2013 07:42:08 -0400
Date: Tue, 22 Oct 2013 11:41:04 +0000
From: Maria Paola Bissiri <Maria_Paola.Bissiri at tu-dresden.de>
To: bolker at mcmaster.ca

Dear Prof. Bolker,
I am carrying out an analysis of my data fitting a GLMM with glmer()
(from lme4), family binomial.

In the chapter "pvalues" in the manual (page 59)
http://cran.r-project.org/web/packages/lme4/lme4.pdf
you recommend the starred (*) methods "when the number of groups is < 50".

What is meant exactly with "number of groups"?

I have in total 1548 observations and four groups of perception
experiment participants: German, Chinese, Swedish and English natives
(language is a predictor in the model), with a maximum of 30
participants per language.

Using the starred (*) methods for GLMMs means bootstrapping, but I am
experiencing problems with that (e.g. too long calculation time), so I
would prefer to use Likelihood Ratio Tests.
However, I am not sure if this method is suitable. I am not sure if my
data fulfill the criterium of a number of group > 50, since I do not
know what it means.
=============

      It's not 100% clear since I don't know the structure of your
model exactly (presumably it's something like response ~ [fixed
effects] + (1|participant), or response ~ [fixed effects] +
(?|participant), i.e. you are using participant as a random effect),
but the 'number of groups' is the number of levels of the
random-effects grouping variable, i.e. probably the total number of
participants in your experiment (which sounds like it is probably >
50). These numbers are reported in the output of glmer, in your case
it would look something like "Number of obs: 1548, groups: participant, ??


From S.Ellison at lgcgroup.com  Tue Oct 22 15:25:36 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 22 Oct 2013 14:25:36 +0100
Subject: [R-sig-ME] Error structure for split-split plot with treatment
 across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>
	<4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554B3A451@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: Elizabeth Graham [mailto:sharon.graham at pg.canterbury.ac.nz]
> Sent: 21 October 2013 20:27
> m2<-lme(log(density)~Treatment*Shade*Leaves,
>                         random=~1|Stream/Shade/Leaves)
> 
> was actually my original model structure, but has the same incongruity
> between model results and interaction plots - try
> interaction.plot(Shade, Treatment, density) for an example - the
> treatment and control lines do not intersect at all, and standard error
> bars do not overlap.  

The default interaction.plot doesn't use the Stream random effect in its error bars; it's using the group means and standard errors based on assumed simple independent replication. Those 'replicates' aren't independent. That will tend to give underestimated standard errors compared to a correct nested random effects structure, as the Stream effect is quite big. 

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From russell-lenth at uiowa.edu  Tue Oct 22 15:35:29 2013
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Tue, 22 Oct 2013 13:35:29 +0000
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by
	simulation ...
Message-ID: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>

The reviewers were NOT correct in questioning whether you had sufficient power. Power is the probability of rejecting a null hypothesis. You have the data, you did your analysis, so you know which hypotheses were rejected (retrospectively, the power of those is 1) and those you did not (retrospective power of 0). There is no more information about power to be gleaned with respect to those data and analyses. You can use power calculations to decide sample size for a future study only.

Russ

-- 
Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Dept office (319)335-0712  -  FAX (319)335-3017   
russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/ 

...
The paper was accepted with revisions which is where we are now. The
reviewers correctly questioned to what extent we had sufficient power to
come to the conclusions we did. I do not want to perform a post-hoc power
analysis because from what I have read and seen on R discussions it is
discouraged.
...


From smilodon2000 at hotmail.com  Tue Oct 22 18:24:03 2013
From: smilodon2000 at hotmail.com (john benson)
Date: Tue, 22 Oct 2013 16:24:03 +0000
Subject: [R-sig-ME] MCMCglmm 3 way interaction
Message-ID: <BAY173-W54EE678649F3AEF2833DBDC020@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/bd94a380/attachment.pl>

From dwinsemius at comcast.net  Tue Oct 22 19:45:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 22 Oct 2013 10:45:59 -0700
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by
	simulation ...
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>
Message-ID: <9A347082-65A3-4FBE-8D14-3F775E6EC7C8@comcast.net>


On Oct 22, 2013, at 6:35 AM, Lenth, Russell V wrote:

> The reviewers were NOT correct in questioning whether you had sufficient power. Power is the probability of rejecting a null hypothesis. You have the data, you did your analysis, so you know which hypotheses were rejected (retrospectively, the power of those is 1) and those you did not (retrospective power of 0). There is no more information about power to be gleaned with respect to those data and analyses. You can use power calculations to decide sample size for a future study only.

Don't we need to know what conclusions were being questioned when we say this? I don't disagree about the vacuity of doing post-hoc power analyses, especially when the study of a rare condition will effectively place a hard limit on sample size. However, if conclusions were being submitted about "no difference" for the features that were "not significant", isn't it possible that questions about power would have validity?


> 
> Russ
> 
> -- 
> Russell V. Lenth  -  Professor Emeritus
> Department of Statistics and Actuarial Science   
> The University of Iowa  -  Iowa City, IA 52242  USA   
> Dept office (319)335-0712  -  FAX (319)335-3017   
> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/ 
> 
> ...
> The paper was accepted with revisions which is where we are now. The
> reviewers correctly questioned to what extent we had sufficient power to
> come to the conclusions we did. I do not want to perform a post-hoc power
> analysis because from what I have read and seen on R discussions it is
> discouraged.
> ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From kevin.thorpe at utoronto.ca  Tue Oct 22 19:51:29 2013
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 22 Oct 2013 13:51:29 -0400
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by
 simulation ...
In-Reply-To: <9A347082-65A3-4FBE-8D14-3F775E6EC7C8@comcast.net>
References: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>
	<9A347082-65A3-4FBE-8D14-3F775E6EC7C8@comcast.net>
Message-ID: <5266BB21.7060602@utoronto.ca>

On 10/22/2013 01:45 PM, David Winsemius wrote:
>
> On Oct 22, 2013, at 6:35 AM, Lenth, Russell V wrote:
>
>> The reviewers were NOT correct in questioning whether you had
>> sufficient power. Power is the probability of rejecting a null
>> hypothesis. You have the data, you did your analysis, so you know
>> which hypotheses were rejected (retrospectively, the power of those
>> is 1) and those you did not (retrospective power of 0). There is no
>> more information about power to be gleaned with respect to those
>> data and analyses. You can use power calculations to decide sample
>> size for a future study only.
>
> Don't we need to know what conclusions were being questioned when we
> say this? I don't disagree about the vacuity of doing post-hoc power
> analyses, especially when the study of a rare condition will
> effectively place a hard limit on sample size. However, if
> conclusions were being submitted about "no difference" for the
> features that were "not significant", isn't it possible that
> questions about power would have validity?

I guess the obvious response to this is "power for what?"  In such 
situations, I think a careful consideration of confidence intervals in 
the context of clinical significance is far more helpful.

Kevin

>
>>
>> Russ
>>
>> -- Russell V. Lenth  -  Professor Emeritus Department of Statistics
>> and Actuarial Science The University of Iowa  -  Iowa City, IA
>> 52242  USA Dept office (319)335-0712  -  FAX (319)335-3017
>> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
>>
>> ... The paper was accepted with revisions which is where we are
>> now. The reviewers correctly questioned to what extent we had
>> sufficient power to come to the conclusions we did. I do not want
>> to perform a post-hoc power analysis because from what I have read
>> and seen on R discussions it is discouraged. ...
>>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From solcita85 at hotmail.com  Tue Oct 22 19:51:27 2013
From: solcita85 at hotmail.com (Sol Lago)
Date: Tue, 22 Oct 2013 13:51:27 -0400
Subject: [R-sig-ME] warning computing profile confidence intervals with
	confint()
Message-ID: <BLU0-SMTP424673C11E93AFFF925CBA7AD020@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/fc1a20f2/attachment.pl>

From ethomas at stanford.edu  Mon Oct 21 03:57:09 2013
From: ethomas at stanford.edu (Ewart Thomas)
Date: Sun, 20 Oct 2013 18:57:09 -0700
Subject: [R-sig-ME] equality constraints in lmer/lme4
In-Reply-To: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
References: <0478721FB7E8994C9425EEC863C8EC66012803EB84F9@razor.psych.udel.edu>
Message-ID: <1C1C880F-E010-4149-9F63-37EF7180FAD0@stanford.edu>

j-p, if the constrained model you want is really 

fm <- lmer ( Outcome ~ Xt  + ( 1 | Subject ), data = mydata),

where Xt = X1 + X2, then why not define Xt as such and take it from there.
ewart

On Oct 20, 2013, at 6:52 PM, Jean-Philippe Laurenceau wrote:

> Dear R-sig-ME list--
> 
> When specifying the following lmer model, I get intercept fixed and random effects, a fixed effect for the X1 predictor, and a fixed effect for the X2 predictor.
> 
> fm <- lmer ( Outcome ~ X1 + X2 + ( 1 | Subject ), data = mydata)
> 
> My question: is there a way to ask lme4 to re-estimate this model but set an equality constraint on the effects of X1 and X2, such that their estimates would be equal to each other?
> 
> Thanks for your time, J-P
> 
> Jean-Philippe Laurenceau, Ph.D.
> Department of Psychology
> University of Delaware
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jlaurenceau at psych.udel.edu  Mon Oct 21 03:43:00 2013
From: jlaurenceau at psych.udel.edu (Jean-Philippe Laurenceau)
Date: Sun, 20 Oct 2013 21:43:00 -0400
Subject: [R-sig-ME] equality constraints in lmer/lme4
Message-ID: <0478721FB7E8994C9425EEC863C8EC66012803EB84F7@razor.psych.udel.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131020/f1f0fbc1/attachment.pl>

From solcita.lago at gmail.com  Sat Oct 19 20:02:11 2013
From: solcita.lago at gmail.com (Sol Lago)
Date: Sat, 19 Oct 2013 14:02:11 -0400
Subject: [R-sig-ME] confidence intervals from lmer() with random correlation
	parameters
Message-ID: <FE40BAC1-DB42-4435-9A24-8F022F7FB2D4@hotmail.com>

Hi there,

Lately I keep encountering the same problem and I'm wondering whether other people have been able to get around it. I'm running a mixed effects model using lmer(). My model has by-subject and by-item intercepts and slopes, and random correlation parameters between them. Since the current version of lmer() does not have MCMC sampling implemented, I cannot use pvals.fnc(). I get this message:

> Error in pvals.fnc(m, withMCMC = T) : MCMC sampling is not implemented in recent versions of lme4 for models with random correlation parameters

pvals.fnc() is also the function I always use to get confidence intervals (HPD95lower and HPD95upper were two columns in the pvals.fnc output). Does anyone know of an alternative way of getting confidence intervals for the fixed effects estimates in the model? Or does using models with random correlations means that we can no longer get CIs from R?

Thanks!

--Sol


From solcita.lago at gmail.com  Tue Oct 22 19:48:54 2013
From: solcita.lago at gmail.com (Sol Lago)
Date: Tue, 22 Oct 2013 13:48:54 -0400
Subject: [R-sig-ME] warning computing profile confidence intervals with
	confint()
Message-ID: <9E4EAB58-06E8-4D62-B9F5-29A07F6AFA18@hotmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/493fc8b4/attachment.pl>

From steve.walker at utoronto.ca  Tue Oct 22 20:03:56 2013
From: steve.walker at utoronto.ca (Steve Walker)
Date: Tue, 22 Oct 2013 14:03:56 -0400
Subject: [R-sig-ME] confidence intervals from lmer() with random
 correlation parameters
In-Reply-To: <FE40BAC1-DB42-4435-9A24-8F022F7FB2D4@hotmail.com>
References: <FE40BAC1-DB42-4435-9A24-8F022F7FB2D4@hotmail.com>
Message-ID: <5266BE0C.20705@utoronto.ca>

Hi Sol,

Ben Bolker has put together a help file (?pvalues) for reference about 
p-values and confidence intervals in the new lme4.

Hope this helps,
Steve

On 2013-10-19 2:02 PM, Sol Lago wrote:
> Hi there,
>
> Lately I keep encountering the same problem and I'm wondering whether other people have been able to get around it. I'm running a mixed effects model using lmer(). My model has by-subject and by-item intercepts and slopes, and random correlation parameters between them. Since the current version of lmer() does not have MCMC sampling implemented, I cannot use pvals.fnc(). I get this message:
>
>> Error in pvals.fnc(m, withMCMC = T) : MCMC sampling is not implemented in recent versions of lme4 for models with random correlation parameters
>
> pvals.fnc() is also the function I always use to get confidence intervals (HPD95lower and HPD95upper were two columns in the pvals.fnc output). Does anyone know of an alternative way of getting confidence intervals for the fixed effects estimates in the model? Or does using models with random correlations means that we can no longer get CIs from R?
>
> Thanks!
>
> --Sol
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From smckinney at bccrc.ca  Tue Oct 22 21:44:44 2013
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 22 Oct 2013 12:44:44 -0700
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by
 simulation ...
In-Reply-To: <5266BB21.7060602@utoronto.ca>
References: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>
	<9A347082-65A3-4FBE-8D14-3F775E6EC7C8@comcast.net>
	<5266BB21.7060602@utoronto.ca>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CB926E121@crcmail4.BCCRC.CA>




> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Kevin E. Thorpe
> Sent: October-22-13 10:51 AM
> To: David Winsemius
> Cc: Lenth, Russell V; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme4 sanple size analysis / power analysis by
> simulation ...
> 
> On 10/22/2013 01:45 PM, David Winsemius wrote:
> >
> > On Oct 22, 2013, at 6:35 AM, Lenth, Russell V wrote:
> >
> >> The reviewers were NOT correct in questioning whether you had
> >> sufficient power. Power is the probability of rejecting a null
> >> hypothesis. You have the data, you did your analysis, so you know
> >> which hypotheses were rejected (retrospectively, the power of those
> >> is 1) and those you did not (retrospective power of 0). There is no
> >> more information about power to be gleaned with respect to those
> >> data and analyses. You can use power calculations to decide sample
> >> size for a future study only.
> >
> > Don't we need to know what conclusions were being questioned when we
> > say this? I don't disagree about the vacuity of doing post-hoc power
> > analyses, especially when the study of a rare condition will
> > effectively place a hard limit on sample size. However, if
> > conclusions were being submitted about "no difference" for the
> > features that were "not significant", isn't it possible that
> > questions about power would have validity?
> 
> I guess the obvious response to this is "power for what?"  In such
> situations, I think a careful consideration of confidence intervals in
> the context of clinical significance is far more helpful.
> 
> Kevin


If the study found differences with small p-values, there's no
power question to ask.  Confidence intervals will not cover values
such as 0 or 1 that indicate no difference between/among groups.
A definitive assertion of a diference can be made, subject to the
error rate inherent in the specified type I error rate (often labeled
alpha, and often set to 0.05).

The only legitimate power question the reviewers can ask is in the
case that p-values were large, and corresponding confidence intervals
covered values indicating no difference.  In that case the question is

"Did you specify a difference of scientific interest that you wanted to detect,
and did you do a power analysis with data at hand prior to this study, to determine
a minimum sample size to yield sufficient power to detect such a difference of
scientific interest?"

If the answer is yes, then a null finding can be definitively declared to be a
sound finding of no difference of scientific interest.

If the answer is no, then the authors can only conclude "We fail to reject
the null hypothesis", not "we accept the null hypothesis".  This is the reason
statisticians came up with this oddly phrased expression - because failing
to reject is not equivalent to accepting the null hypothesis if a-priori
power calculations were not undertaken to ensure a large enough sample
to detect a difference of scientific interest with sufficiently high coverage
probability (power, or 1 - type II error rate).



Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre




> 
> >
> >>
> >> Russ
> >>
> >> -- Russell V. Lenth  -  Professor Emeritus Department of Statistics
> >> and Actuarial Science The University of Iowa  -  Iowa City, IA
> >> 52242  USA Dept office (319)335-0712  -  FAX (319)335-3017
> >> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
> >>
> >> ... The paper was accepted with revisions which is where we are
> >> now. The reviewers correctly questioned to what extent we had
> >> sufficient power to come to the conclusions we did. I do not want
> >> to perform a post-hoc power analysis because from what I have read
> >> and seen on R discussions it is discouraged. ...
> >>
> 
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From russell-lenth at uiowa.edu  Tue Oct 22 22:30:55 2013
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Tue, 22 Oct 2013 20:30:55 +0000
Subject: [R-sig-ME] lme4 sanple size analysis / power analysis by
 simulation ...
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0CB926E121@crcmail4.BCCRC.CA>
References: <51F0C7C54B032A42A23B74A088E7141C1EC737F2@itsnt443.iowa.uiowa.edu>
	<9A347082-65A3-4FBE-8D14-3F775E6EC7C8@comcast.net>
	<5266BB21.7060602@utoronto.ca>,
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926E121@crcmail4.BCCRC.CA>
Message-ID: <62022E85-846A-4A88-A9D9-D5D686BCF9A6@uiowa.edu>

Re David's response, I don't think the question of post hoc power hinges on the outcome of the test. If it was "no significance", then obviously the power was too low to detect the observed effect, because it in fact was not detected. It is important to answer the right questions, rather than to try to come up with an exacting way to answer the wrong question. And power isn't the right question here. 

One right question is this: what did you observe, and was it meaningful in any practical way? If two groups have average IQ scores that differ by, say, 0.45, and this result isn't significant, then the question isn't whether the power was too low, but that there is no practical difference between the two populations. On the other hand, if the difference is 19 IQ points, then that would be regarded as a meaningful difference. If the test was significant, then the test was powerful enough; and otherwise it wasn't powerful enough. But that judgment isn't based on a calculation, it's based on looking at -- and actually thinking about -- the observed results. 

For that reason, I am in closer agreement with Kevin and Steven's comments. However, the correct way to judge whether a difference is smaller than a threshold is to do an equivalence test, not a power calculation. See the Hoenig and Heisey reference in the original post.

I apologize if this discussion is viewed as inappropriate for this forum. The original question came up in the context of a technicality related to interpreting a mixed-model analysis, and I do realize we have wandered away from that emphasis. Perhaps we should move this elsewhere if there is further comment?

Russ

Sent from my iPad

> On Oct 22, 2013, at 2:44 PM, "Steven McKinney" <smckinney at bccrc.ca> wrote:
> 
> 
> 
> 
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
>> bounces at r-project.org] On Behalf Of Kevin E. Thorpe
>> Sent: October-22-13 10:51 AM
>> To: David Winsemius
>> Cc: Lenth, Russell V; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lme4 sanple size analysis / power analysis by
>> simulation ...
>> 
>>> On 10/22/2013 01:45 PM, David Winsemius wrote:
>>> 
>>>> On Oct 22, 2013, at 6:35 AM, Lenth, Russell V wrote:
>>>> 
>>>> The reviewers were NOT correct in questioning whether you had
>>>> sufficient power. Power is the probability of rejecting a null
>>>> hypothesis. You have the data, you did your analysis, so you know
>>>> which hypotheses were rejected (retrospectively, the power of those
>>>> is 1) and those you did not (retrospective power of 0). There is no
>>>> more information about power to be gleaned with respect to those
>>>> data and analyses. You can use power calculations to decide sample
>>>> size for a future study only.
>>> 
>>> Don't we need to know what conclusions were being questioned when we
>>> say this? I don't disagree about the vacuity of doing post-hoc power
>>> analyses, especially when the study of a rare condition will
>>> effectively place a hard limit on sample size. However, if
>>> conclusions were being submitted about "no difference" for the
>>> features that were "not significant", isn't it possible that
>>> questions about power would have validity?
>> 
>> I guess the obvious response to this is "power for what?"  In such
>> situations, I think a careful consideration of confidence intervals in
>> the context of clinical significance is far more helpful.
>> 
>> Kevin
> 
> 
> If the study found differences with small p-values, there's no
> power question to ask.  Confidence intervals will not cover values
> such as 0 or 1 that indicate no difference between/among groups.
> A definitive assertion of a diference can be made, subject to the
> error rate inherent in the specified type I error rate (often labeled
> alpha, and often set to 0.05).
> 
> The only legitimate power question the reviewers can ask is in the
> case that p-values were large, and corresponding confidence intervals
> covered values indicating no difference.  In that case the question is
> 
> "Did you specify a difference of scientific interest that you wanted to detect,
> and did you do a power analysis with data at hand prior to this study, to determine
> a minimum sample size to yield sufficient power to detect such a difference of
> scientific interest?"
> 
> If the answer is yes, then a null finding can be definitively declared to be a
> sound finding of no difference of scientific interest.
> 
> If the answer is no, then the authors can only conclude "We fail to reject
> the null hypothesis", not "we accept the null hypothesis".  This is the reason
> statisticians came up with this oddly phrased expression - because failing
> to reject is not equivalent to accepting the null hypothesis if a-priori
> power calculations were not undertaken to ensure a large enough sample
> to detect a difference of scientific interest with sufficiently high coverage
> probability (power, or 1 - type II error rate).
> 
> 
> 
> Steven McKinney, Ph.D.
> 
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
> 
> 
> 
> 
>> 
>>> 
>>>> 
>>>> Russ
>>>> 
>>>> -- Russell V. Lenth  -  Professor Emeritus Department of Statistics
>>>> and Actuarial Science The University of Iowa  -  Iowa City, IA
>>>> 52242  USA Dept office (319)335-0712  -  FAX (319)335-3017
>>>> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
>>>> 
>>>> ... The paper was accepted with revisions which is where we are
>>>> now. The reviewers correctly questioned to what extent we had
>>>> sufficient power to come to the conclusions we did. I do not want
>>>> to perform a post-hoc power analysis because from what I have read
>>>> and seen on R discussions it is discouraged. ...
>> 
>> 
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sharon.graham at pg.canterbury.ac.nz  Tue Oct 22 23:11:45 2013
From: sharon.graham at pg.canterbury.ac.nz (Elizabeth Graham)
Date: Tue, 22 Oct 2013 21:11:45 +0000
Subject: [R-sig-ME] Error structure for split-split plot with treatment
 across blocks
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5554B3A451@GOLD.corp.lgc-group.com>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>
	<4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A451@GOLD.corp.lgc-group.com>
Message-ID: <4F88CD2FCBB7464BBED9431A08B79084022EEA@UCEXMBX01-D.canterbury.ac.nz>

Yes, good point, thank you!  That was explained to me by someone else as well, who recommended that I make my plots based on the coefficients of the model instead... do you, or anyone else reading this, know how to do that?  I think I will need to somehow combine or group coefficients by experimental level, for example, to make a Treatment-Shade interaction plot I will need a coefficient value for treatment-shaded, treatment-unshaded, control-shaded, and control-unshaded. 

Thanks again for your input, much appreciated.

Elizabeth
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of S Ellison [S.Ellison at lgcgroup.com]
Sent: Wednesday, October 23, 2013 2:25 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Error structure for split-split plot with treatment across blocks

> -----Original Message-----
> From: Elizabeth Graham [mailto:sharon.graham at pg.canterbury.ac.nz]
> Sent: 21 October 2013 20:27
> m2<-lme(log(density)~Treatment*Shade*Leaves,
>                         random=~1|Stream/Shade/Leaves)
>
> was actually my original model structure, but has the same incongruity
> between model results and interaction plots - try
> interaction.plot(Shade, Treatment, density) for an example - the
> treatment and control lines do not intersect at all, and standard error
> bars do not overlap.

The default interaction.plot doesn't use the Stream random effect in its error bars; it's using the group means and standard errors based on assumed simple independent replication. Those 'replicates' aren't independent. That will tend to give underestimated standard errors compared to a correct nested random effects structure, as the Stream effect is quite big.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:15}}


From bbolker at gmail.com  Wed Oct 23 00:49:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Oct 2013 22:49:23 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?warning_computing_profile_confidence_interva?=
	=?utf-8?q?ls_with=09confint=28=29?=
References: <BLU0-SMTP424673C11E93AFFF925CBA7AD020@phx.gbl>
Message-ID: <loom.20131023T003807-908@post.gmane.org>

Sol Lago <solcita85 at ...> writes:

> Hi everyone,

> I am using a mixed effect model and I would like to 
> provide profile confidence intervals, which were
> suggested in the lme4 documentation as an alternative to
>  traditional pvalues. Below are my model and the
> command I use to generate the confidence intervals:

> m <- lmer(residRT ~ Gram*Number + (0+Gram+Number|Subject) + (1|Subject)  + 
>   (1|Item), data= data)  #model
> confint(m, method="profile", oldNames=FALSE)  #profile CIs
 
> However, when I run confint () I always get this warning: "In
> cov2cor(m) : diag(.) had 0 or NA entries; non-finite result is
> doubtful" (I get it 13 times, one for each parameter in the model).

  This is quite possibly a false positive -- it sounds vaguely
familiar but I don't have a working example (otherwise it would
be listed as an issue on github and I would be trying to fix it)
If you can come up with a small/minimal reproducible example,
or if someone else has one, could you (1) post it here or (2) send
it via e-mail or (3) post it to https://github.com/lme4/lme4/issues
(at the very least, we could use a more informative error message)
 
> My questions are:
 
> (1) How worried should I be? Would you advice not to report the CIs
> given the warning? When I compute normal CIs intead (same command,
> just method="Wald) I get values that very similar to the profile
> confidence intervals. I wonder if I should report normal CIs
> instead: the upshot is that they can be always computed, but I worry
> they are less related to the way the mixed-effects model was
> computed, so it might be conceptually confusing.

  If the Wald and likelihood profiles are similar that's a pretty
good sign.  If the Wald intervals *are* similar, and familiar to
your audience, you might be right that reporting them would be
best (although as far as I know profile CIs are always more accurate
than Wald CIs, so familiarity and computational convenience would
be the only reason to prefer Wald CIs).
 
> (2) If I were to report the profile CIs, which are the standard
> references I should give in the paper? I don't think profile CIs are
> known in my field, so I think I should point people to whichever are
> the standard references for this.

  I don't know about the "standard": most theoretical statistics
textbooks should mention it at least in passing. In ecology you could quote
Bolker 2008 _Ecological Models and Data in R_, or Mangel and Hilborn's
1998 _Ecological Detective_  ...


From tobias.heed at uni-hamburg.de  Wed Oct 23 08:54:03 2013
From: tobias.heed at uni-hamburg.de (Tobias Heed)
Date: Wed, 23 Oct 2013 08:54:03 +0200
Subject: [R-sig-ME] Error structure for split-split plot with treatment
	across blocks
In-Reply-To: <4F88CD2FCBB7464BBED9431A08B79084022EEA@UCEXMBX01-D.canterbury.ac.nz>
References: <4F88CD2FCBB7464BBED9431A08B790840226FB@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A0AA@GOLD.corp.lgc-group.com>
	<4F88CD2FCBB7464BBED9431A08B7908402277E@UCEXMBX01-D.canterbury.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED5554B3A451@GOLD.corp.lgc-group.com>
	<4F88CD2FCBB7464BBED9431A08B79084022EEA@UCEXMBX01-D.canterbury.ac.nz>
Message-ID: <9FFF71D6-BE12-4A74-AF07-249627B2D515@uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131023/a8ba145e/attachment.pl>

From sreckojoksimovic at gmail.com  Wed Oct 23 08:35:29 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Tue, 22 Oct 2013 23:35:29 -0700
Subject: [R-sig-ME] multilevel linear models
Message-ID: <CAM8BP_=msWb9Y5CjOPaeD1c+VD6NYj2Skn2P0vRGevoiwFS3RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131022/33caa7e1/attachment.pl>

From stefan.ferger at yahoo.de  Wed Oct 23 16:48:42 2013
From: stefan.ferger at yahoo.de (Stefan Ferger)
Date: Wed, 23 Oct 2013 15:48:42 +0100 (BST)
Subject: [R-sig-ME] Zero-inflated binomial (ZIB) models in glmmADMB:
	warnings and errors
Message-ID: <1382539722.1360.YahooMailNeo@web171701.mail.ir2.yahoo.com>

Dear list members,

I have two problems with fitting a zero-inflated glmm with a binomial distribution (ZIB). None of both seems to be new, but the suggestions I found in the mailing list so far didn't help me to solve the problems.


I briefly try to describe my experimental design, so that you know what it is about:
I have 13 plots; each plot has 10 subplots (called clusters here); within each cluster are 20 fruits of 3 colors each. The whole experiment was replicated in 2 seasons. The response variable are fruits that are pecked vs. not pecked, i.e. the number of success vs. the number of failures per cluster (within plot) and color and season, i.e. a binomial response.


The success-part of this binomial response is strongly, but quite evenly zero-inflated, i.e. there is no obvious pattern in the distribution of zeros in successes between seasons or colors:
> table(fruits$pecks, fruits$color, fruits$season) , ,  = cold black red violet 0     86  90     95 1     23  18     17 2     10  11      6 3      7   3      3 4      3   3      3 5      0   2      4 6      1   3      1 7      0   0      0 9      0   0      0 11     0   0      1 , ,  = hot black red violet 0    100  99     91 1     11  13     18 2     12   6      8 3      5   3      6 4      2   4      3 5      0   1      1 6      0   1      0 7      0   1      3 9      0   1      0 11     0   1      0


Although not new (see for example Daniel Hall's paper: http://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2000.01030.x/full), it seems that modeling a binomial response variable with a very low frequency of success in a ZIB is still quite unusual....as Ben Bolker wrote: [...] using a binomial family with zeroInflation=TRUE.  If your response is a matrix of successes and failures, that's unusual but plausible [...] (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017903.html)

I found five R packages that are apparently able to deal with zero-inflation: glmmADMB, MCMCglmm, pscl, VGAM, R-INLA.
As clusters are nested within plots and the experiment is replicated in 2 seasons, I would like to include a random effect of "cluster nested in plot". pscl and VGAM seem not to support random effects. glmmADMB, MCMCglmm and R-INLA apparently do. As I have been working with lme4 previously, I decided to try glmmADMB first, as the model specification is very similar in both packages.

Testing the effect of season and color on the number of pecked fruits SEPARATELY works well, when I use the follwing models (although the SEs are comparatively large [on the logit-scale]):
---------------------------------------------------------------------------------------------------------------------------

Call: glmmadmb(formula = fruits.bin ~ season + (1 | plotID/clusterID) +  (1 | color), data = fruits.av, family = "binomial", zeroInflation = TRUE) AIC: 1543.8  Coefficients: Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -3.5364     0.3059   -11.6   <2e-16 *** seasonhot    -0.0469     0.1184    -0.4     0.69    
--- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Number of observations: total=780, plotID=13, plotID:clusterID=130, color=3 
Random effect variance(s):
Group=plotID Variance StdDev
(Intercept)   0.7154 0.8458
Group=plotID:clusterID Variance StdDev
(Intercept)   0.9076 0.9527
Group=color Variance StdDev
(Intercept)  0.03397 0.1843 Zero-inflation: 0.40874  (std. err.:  0.04368 ) Log-likelihood: -765.91

[The function overdisp_fun from http://glmm.wikidot.com/faq gives a ratio of 1.40 (pearsonchisq/rdf)].

--------------------------------------------------------------------------------

Call: glmmadmb(formula = fruits.bin ~ color + (1 | plotID/clusterID),  data = fruits.av, family = "binomial", zeroInflation = TRUE) AIC: 1538.4  Coefficients: Estimate Std. Error z value Pr(>|z|)    
(Intercept)   -3.807      0.292  -13.02   <2e-16 *** colorred       0.396      0.137    2.88   0.0039 ** colorviolet    0.367      0.138    2.66   0.0079 ** 
--- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Number of observations: total=780, plotID=13, plotID:clusterID=130 
Random effect variance(s):
Group=plotID Variance StdDev
(Intercept)   0.7011 0.8373
Group=plotID:clusterID Variance StdDev
(Intercept)   0.9091 0.9534 Zero-inflation: 0.41143  (std. err.:  0.043531 ) Log-likelihood: -763.194 


[The function overdisp_fun from http://glmm.wikidot.com/faq gives a ratio of 1.42 (pearsonchisq/rdf)]
-------------------------------------------------------------------------------


-----------------------------
1st problem

-----------------------------

However, when I test both season and color TOGETHER plus their interaction, I get a warning (see the summary below for the model specification):
---------------------------------------------------------------------------------------------------------------------------------

GLMM's in R powered by AD Model Builder: Family: binom  link = logit  Zero inflation: p = 0.40831  Fixed effects: Log-likelihood: -778.26 AIC: 1574.52  Formula: fruits.bin ~ season * color + (1 | plotID/clusterID)  (Intercept) seasonhotcolorredcolorvioletseasonhot:colorred  -2.7569960            -0.9638953            -0.2266267            -0.2346871             0.8357870 seasonhot:colorviolet  0.8964410  Random effects:
Structure: Diagonal matrix
Group=plotID Variance StdDev
(Intercept)    2.242  1.497
Group=plotID:clusterID Variance StdDev
(Intercept)   0.9694 0.9846 Number of observations: total=780, plotID=13, plotID:clusterID=130 Warning message: In print.glmmadmb(list(n = 780L, q = c(13L, 130L), formula = fruits.bin ~  : Object has a large gradient component

Here is the summary:

-------------------------------------------------------------------------------------------------------------------------------

Call: glmmadmb(formula = fruits.bin ~ season * color + (1 | plotID/clusterID),  data = fruits.av, family = "binomial", zeroInflation = TRUE) AIC: 1574.5  Coefficients: Estimate Std. Error z value Pr(>|z|)    
(Intercept)             -2.757      0.620   -4.44  8.8e-06 *** seasonhot               -0.964      0.204   -4.73  2.2e-06 *** colorred                -0.227      0.174   -1.30   0.1931 colorviolet             -0.235      0.181   -1.29   0.1957 seasonhot:colorred       0.836      0.283    2.96   0.0031 ** seasonhot:colorviolet    0.896      0.279    3.21   0.0013 ** 
--- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Number of observations: total=780, plotID=13, plotID:clusterID=130 
Random effect variance(s):
Group=plotID Variance StdDev
(Intercept)    2.242  1.497
Group=plotID:clusterID Variance StdDev
(Intercept)   0.9694 0.9846 Zero-inflation: 0.40831  (std. err.:  0.044651 ) Log-likelihood: -778.26 Warning message: In glmmadmb(fruits.bin ~ season * color + (1 | plotID/clusterID),  : Convergence failed:log-likelihood of gradient= -85.777

[The function overdisp_fun from http://glmm.wikidot.com/faq gives a ratio of 1.88 (pearsonchisq/rdf)]


----------------------------------------------------------------------------------------------------------------------


I tried to work on this, guided by the recommendations Ben Bolker gave here: 

http://lists.admb-project.org/pipermail/users/2012-February/001695.html 

>> setting verbose=T does not provide any additional information (to me)
>> setting the maximum number of iterations larger does not change anything (I set maxfn=10000)
>> I plotted the raw data, the model predictions of the zero-inflated model and the predictions of a "normal" mixed model (glmer, i.e. without controlling for zero-inflation); I attach them to this email (if this doesn't work with the mailing list, I can also send them to whomever likes to have a look). The predictions of the glmm look quite good. The predictions of the ziglmm lack variation within groups, i.e. there is only one value for all replicates of each combination of season and color; and they seem to be slightly to large - but both could probably be related to the warning message!?

Is it likely that the stronger overdispersion is responsible for this and would it make sense to control for it with an additional observation-level random effect? (I tried it > it didn't work...).


-----------------------------
2nd problem

-----------------------------

In another model, in which I try to investigate on the effect of elevation on the number of pecks on fruits, I get another error message: 

> summary(pecks.zibin <- glmmadmb(fruits.bin ~ alt + (1|plotID/clusterID) + (1|color), zeroInflation=TRUE, family="binomial", data=fruits.av)) Parameters were estimated, but not standard errors were not: the most likely problem is that the curvature at MLE was zero or negative Warning message: running command 'C:\Windows\system32\cmd.exe /c "D:/Sonstiges/R_library/glmmADMB/bin/windows64/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess' had status 42 Error in summary(pecks.zibin <- glmmadmb(fruits.bin ~ alt + (1 | plotID/clusterID) +  : FehlerbeiderAuswertungdesArgumentes 'object' beiderMethodenauswahlf?rFunktion 'summary': Error in glmmadmb(fruits.bin ~ alt + (1 | plotID/clusterID) + (1 | color),  :  The function maximizer failed (couldn't find STD file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl'


Again I tried to work on this, guided by the trouble shooting steps provided in ?admbControl
and by Ben Bolkers comments here:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q2/018545.html
>> setting noinit=F and/or shess=F does not change anything, nor do changes on the other run parameters

>> the output files do not provide any information to me, as I do not know how to open them and what to look for



1) None of the models shown above produces any warnings or errors when I run them with glmer (and thus ignore the zero-inflation).
2) When I sum all pecks on plot level and leave out cluster completely, I get much less zeros (but also much less replicates). When again modeled in glmer without controlling for zero-inflation the results are qualitatively the same as in 1), but the overdispersion is becoming much stronger (ratio ~ 3.5). Correcting for this by incorporating an observation-level random effect, however, leads to strong underdispersion (ratio ~ 0.3) and differing results.

3) I nevertheless think that the model structure should be determined by the design and therefore I would like to go for the version that appreciates the clusters, which means that I have to deal with these zeros.

Does anybody know what I could do to fit these models in glmmADMBsuccessfully? Do I actually need to account for this zero-inflation, the consensus seems to be that one should do so if there are "over-proportionally" many zeros - but when is this threshold passed?

As fitting the models successfully in glmmADMB might be tricky, does anybody know how the model structure should look like in one of the other packages, i.e. MCMCglmm (I found the model specification very tricky here) or R-INLA?


Thank you for your help,
Stefan

?
-- 
Stefan Ferger 
Biodiversity and Climate Research Centre (BiK-F) 
Project Area B: Biodiversity Dynamics and Climate 
Senckenberganlage 25 
D-60325 Frankfurt am Main 
phone: +49 69 7542 1871 
fax:   +49 69 7542 1800 
e-mail: stefan.ferger at senckenberg.de 
homepage: www.bik-f.de/root/index.php?page_id=433 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ziglmm-predicted pecks per cluster_original.png
Type: image/png
Size: 3875 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131023/87310332/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: glmm-predicted pecks per cluster_zoomed in.png
Type: image/png
Size: 5040 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131023/87310332/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pecks per cluster_zoomed in.png
Type: image/png
Size: 4581 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131023/87310332/attachment-0005.png>

From highstat at highstat.com  Wed Oct 23 18:20:17 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 23 Oct 2013 17:20:17 +0100
Subject: [R-sig-ME] Zero-inflated binomial (ZIB) models in glmmADMB:,
 warnings and errors
In-Reply-To: <mailman.4062.1382539739.4612.r-sig-mixed-models@r-project.org>
References: <mailman.4062.1382539739.4612.r-sig-mixed-models@r-project.org>
Message-ID: <5267F741.60706@highstat.com>




> ------------------------------
>
> Message: 2
> Date: Wed, 23 Oct 2013 15:48:42 +0100 (BST)
> From: Stefan Ferger <stefan.ferger at yahoo.de>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Zero-inflated binomial (ZIB) models in glmmADMB:
> 	warnings and errors
> Message-ID:
> 	<1382539722.1360.YahooMailNeo at web171701.mail.ir2.yahoo.com>
> Content-Type: text/plain; charset="utf-8"
>
>


> 1) None of the models shown above produces any warnings or errors when I run them with glmer (and thus ignore the zero-inflation).
> 2) When I sum all pecks on plot level and leave out cluster completely, I get much less zeros (but also much less replicates). When again modeled in glmer without controlling for zero-inflation the results are qualitatively the same as in 1), but the overdispersion is becoming much stronger (ratio ~ 3.5). Correcting for this by incorporating an observation-level random effect, however, leads to strong underdispersion (ratio ~ 0.3) and differing results.
>
> 3) I nevertheless think that the model structure should be determined by the design and therefore I would like to go for the version that appreciates the clusters, which means that I have to deal with these zeros.
>
> Does anybody know what I could do to fit these models in glmmADMBsuccessfully? Do I actually need to account for this zero-inflation, the consensus seems to be that one should do so if there are "over-proportionally" many zeros - but when is this threshold passed?
>
> As fitting the models successfully in glmmADMB might be tricky, does anybody know how the model structure should look like in one of the other packages, i.e. MCMCglmm (I found the model specification very tricky here) or R-INLA?
>
>
> Thank you for your help,
> Stefan



I would certainly include the plot effect, and cluster effect within plot. .....it imposes a correlation structure on your data.
Not sure whether I understand the color thing though.

If your binomial GLMM is overdispersed then you should try to figure out why this is. Common causes are:

1. Outliers
2. Non-linear patterns
3. Wrong link function
4. Wrong distribution
5. Too many zeros
6. Dependency structure that has not been included...or included in the wrong way.

For 2...plot your residuals vs each continuous covariate. If 5 is the cause, then yes...a zero inflated binomial is an option.
For 4 you may want to consider the beta-binomial distribution, see for example the book from Ben Bolker, or our 'Beginner's Guide to GLM & GLMM'; it
contains code to fit a beta-binomial GLMM in JAGS. A zero inflated version of a beta-binomial GLMM/GAMM requires similar code.


As to your question how many zeros means zero inflated models.....it all depends. I have data sets with 70% of zeros...and a
Poisson/NB GLM still do the job...and I have data sets where 25% of zeros already means ZIP. Same holds for ZIB.


I would strongly suggest to do this in JAGS.

Have fun

Alain








-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From bbolker at gmail.com  Wed Oct 23 18:51:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Oct 2013 12:51:00 -0400
Subject: [R-sig-ME] lme4 and confidence intervals
In-Reply-To: <CAJ4s-a4q7y3y_YooYp5iWaUnVDhJEBm-xDR-yGhhybpJf5wyTA@mail.gmail.com>
References: <CAJ4s-a4q7y3y_YooYp5iWaUnVDhJEBm-xDR-yGhhybpJf5wyTA@mail.gmail.com>
Message-ID: <5267FE74.8000902@gmail.com>

 [cc'ing to r-sig-mixed models]

  This doesn't happen for me: I would need a reproducible example in
order to be able to see what's going on.

   sincerely
   Ben Bolker


On 13-10-23 12:31 PM, Nicholas Mitsakakis wrote:
> Hello Bob,
> 
> I want to get the (or some) confidence intervals for the coefficients
> from a mixed effects model fitted by the lmer function. I noticed in the
> lme4 documentation that confint function can do this but it does not
> work for me giving errors messages:
> 
> Error: $ operator not defined for this S4 class
> 
> I have installed the most recent version of lme4 from CRAN.
> 
> Am I missing something?
> 
> I would appreciate it if you could let me know.
> 
> Regards,
> nicholas
> 
> -- 
> Nicholas Mitsakakis, MSc, PhD
> Biostatistician
> Toronto Health Economics and Technology Assessment (THETA) Collaborative
> Assistant Professor
> Leslie Dan Faculty of Pharmacy, University of Toronto
> 6th Floor, Room 641
> 144 College Street
> Toronto ON, M5S 3M2
> e: n.mitsakakis at theta.utoronto.ca <mailto:n.mitsakakis at theta.utoronto.ca>
> t: (416) 946 - 3700
> f: (416) 946 - 3719
> w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>


From bbolker at gmail.com  Wed Oct 23 21:04:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Oct 2013 15:04:28 -0400
Subject: [R-sig-ME] lme4 and confidence intervals
In-Reply-To: <CAJ4s-a4pJkPauCL5sA11vOpwt208mMSWz6PVVA=H8x5ufkoe0w@mail.gmail.com>
References: <CAJ4s-a4q7y3y_YooYp5iWaUnVDhJEBm-xDR-yGhhybpJf5wyTA@mail.gmail.com>	<5267FE74.8000902@gmail.com>
	<CAJ4s-a4pJkPauCL5sA11vOpwt208mMSWz6PVVA=H8x5ufkoe0w@mail.gmail.com>
Message-ID: <52681DBC.4070807@gmail.com>

   This works for me with the development version of lme4 (although I do
get some warnings about cov2cor() that have been referenced on another
recent thread, and the confidence intervals for the Insitution RE are
not getting calculated).  I strongly suspect it will also work with the
release version, although I haven't tested it.

  Can you start with a clean session and give the results of
sessionInfo() ??


On 13-10-23 01:03 PM, Nicholas Mitsakakis wrote:
> Hi Ben,
> 
> I am attaching a dataset, brazil. The code I used is
> 
> I <- which(as.numeric(brazil$state) == 1 & as.numeric(brazil$drug) == 1)
> modref2 <- lmer(log.Std.Unit.Price ~ 1 + (1|Institution) + (1|supplier)
> + log(Quantity) + as.numeric(Date), brazil, subset = I)
> confint(modref2)
> 
> 
> Please let me know if you are getting the same problem.
> 
> Thanks a lot,
> Nicholas
> 
> 
> 
> 
> On Wed, Oct 23, 2013 at 12:51 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>      [cc'ing to r-sig-mixed models]
> 
>       This doesn't happen for me: I would need a reproducible example in
>     order to be able to see what's going on.
> 
>        sincerely
>        Ben Bolker
> 
> 
>     On 13-10-23 12 <tel:13-10-23%2012>:31 PM, Nicholas Mitsakakis wrote:
>     > Hello Bob,
>     >
>     > I want to get the (or some) confidence intervals for the coefficients
>     > from a mixed effects model fitted by the lmer function. I noticed
>     in the
>     > lme4 documentation that confint function can do this but it does not
>     > work for me giving errors messages:
>     >
>     > Error: $ operator not defined for this S4 class
>     >
>     > I have installed the most recent version of lme4 from CRAN.
>     >
>     > Am I missing something?
>     >
>     > I would appreciate it if you could let me know.
>     >
>     > Regards,
>     > nicholas
>     >
>     > --
>     > Nicholas Mitsakakis, MSc, PhD
>     > Biostatistician
>     > Toronto Health Economics and Technology Assessment (THETA)
>     Collaborative
>     > Assistant Professor
>     > Leslie Dan Faculty of Pharmacy, University of Toronto
>     > 6th Floor, Room 641
>     > 144 College Street
>     > Toronto ON, M5S 3M2
>     > e: n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>
>     <mailto:n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>>
>     > t: (416) 946 - 3700 <tel:%28416%29%20946%20-%203700>
>     > f: (416) 946 - 3719 <tel:%28416%29%20946%20-%203719>
>     > w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>
>     <http://www.theta.utoronto.ca>
> 
> 
> 
> 
> -- 
> Nicholas Mitsakakis, MSc, PhD
> Biostatistician
> Toronto Health Economics and Technology Assessment (THETA) Collaborative
> Assistant Professor
> Leslie Dan Faculty of Pharmacy, University of Toronto
> 6th Floor, Room 641
> 144 College Street
> Toronto ON, M5S 3M2
> e: n.mitsakakis at theta.utoronto.ca <mailto:n.mitsakakis at theta.utoronto.ca>
> t: (416) 946 - 3700
> f: (416) 946 - 3719
> w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>


From bbolker at gmail.com  Wed Oct 23 23:20:06 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Oct 2013 17:20:06 -0400
Subject: [R-sig-ME] lme4 and confidence intervals
In-Reply-To: <CAJ4s-a7qCoyqxHVuOtZ-BnvGKYHCR_qrupQWJ0YnCoNu--QjMA@mail.gmail.com>
References: <CAJ4s-a4q7y3y_YooYp5iWaUnVDhJEBm-xDR-yGhhybpJf5wyTA@mail.gmail.com>	<5267FE74.8000902@gmail.com>	<CAJ4s-a4pJkPauCL5sA11vOpwt208mMSWz6PVVA=H8x5ufkoe0w@mail.gmail.com>	<52681DBC.4070807@gmail.com>
	<CAJ4s-a7qCoyqxHVuOtZ-BnvGKYHCR_qrupQWJ0YnCoNu--QjMA@mail.gmail.com>
Message-ID: <52683D86.50609@gmail.com>

  The problem is that your version of R is sufficiently old (version
2.15, the next major release, was released about 18 months ago, which in
R time is "old") that you are picking up a version of lme4 that doesn't
implement confint().
  The easiest thing (at least from my point of view) would be to upgrade
your version of R, but if you are constrained to 2.14 for other reasons
you *might* be able to install a more recent version by downloading it
manually from CRAN or http://lme4.r-forge.r-project.org/repos and
installing locally.  You're liable to run into minor, and possibly
major, hassles this way because of various changes/incompatibilities
between R versions. (For example, I know we use paste0() internally -- I
think it was introduced in 2.15 -- that one is easy to work around, but
there are probably other compatibility problems ...)

  Ben Bolker


On 13-10-23 03:18 PM, Nicholas Mitsakakis wrote:
> Hi Ben,
> 
> here is what I get:
> 
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252  
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                  
> [5] LC_TIME=English_Canada.1252   
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base    
> 
> other attached packages:
> [1] lme4_0.999999-0 Matrix_1.0-1    lattice_0.20-0
> 
> loaded via a namespace (and not attached):
> [1] grid_2.14.0   nlme_3.1-102  stats4_2.14.0
> 
> 
> Does the problem have anything to do with the fact I am using 64-bit?
> 
> Any way to by pass this problem?
> 
> Thanks a lot for your help.
> Nicholas
> 
> 
> On Wed, Oct 23, 2013 at 3:04 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>        This works for me with the development version of lme4 (although I do
>     get some warnings about cov2cor() that have been referenced on another
>     recent thread, and the confidence intervals for the Insitution RE are
>     not getting calculated).  I strongly suspect it will also work with the
>     release version, although I haven't tested it.
> 
>       Can you start with a clean session and give the results of
>     sessionInfo() ??
> 
> 
>     On 13-10-23 01 <tel:13-10-23%2001>:03 PM, Nicholas Mitsakakis wrote:
>     > Hi Ben,
>     >
>     > I am attaching a dataset, brazil. The code I used is
>     >
>     > I <- which(as.numeric(brazil$state) == 1 & as.numeric(brazil$drug)
>     == 1)
>     > modref2 <- lmer(log.Std.Unit.Price ~ 1 + (1|Institution) +
>     (1|supplier)
>     > + log(Quantity) + as.numeric(Date), brazil, subset = I)
>     > confint(modref2)
>     >
>     >
>     > Please let me know if you are getting the same problem.
>     >
>     > Thanks a lot,
>     > Nicholas
>     >
>     >
>     >
>     >
>     > On Wed, Oct 23, 2013 at 12:51 PM, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>
>     > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> wrote:
>     >
>     >      [cc'ing to r-sig-mixed models]
>     >
>     >       This doesn't happen for me: I would need a reproducible
>     example in
>     >     order to be able to see what's going on.
>     >
>     >        sincerely
>     >        Ben Bolker
>     >
>     >
>     >     On 13-10-23 12 <tel:13-10-23%2012> <tel:13-10-23%2012>:31 PM,
>     Nicholas Mitsakakis wrote:
>     >     > Hello Bob,
>     >     >
>     >     > I want to get the (or some) confidence intervals for the
>     coefficients
>     >     > from a mixed effects model fitted by the lmer function. I
>     noticed
>     >     in the
>     >     > lme4 documentation that confint function can do this but it
>     does not
>     >     > work for me giving errors messages:
>     >     >
>     >     > Error: $ operator not defined for this S4 class
>     >     >
>     >     > I have installed the most recent version of lme4 from CRAN.
>     >     >
>     >     > Am I missing something?
>     >     >
>     >     > I would appreciate it if you could let me know.
>     >     >
>     >     > Regards,
>     >     > nicholas
>     >     >
>     >     > --
>     >     > Nicholas Mitsakakis, MSc, PhD
>     >     > Biostatistician
>     >     > Toronto Health Economics and Technology Assessment (THETA)
>     >     Collaborative
>     >     > Assistant Professor
>     >     > Leslie Dan Faculty of Pharmacy, University of Toronto
>     >     > 6th Floor, Room 641
>     >     > 144 College Street
>     >     > Toronto ON, M5S 3M2
>     >     > e: n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>
>     >     <mailto:n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>>
>     >     <mailto:n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>
>     >     <mailto:n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>>>
>     >     > t: (416) 946 - 3700 <tel:%28416%29%20946%20-%203700>
>     <tel:%28416%29%20946%20-%203700>
>     >     > f: (416) 946 - 3719 <tel:%28416%29%20946%20-%203719>
>     <tel:%28416%29%20946%20-%203719>
>     >     > w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>
>     <http://www.theta.utoronto.ca>
>     >     <http://www.theta.utoronto.ca>
>     >
>     >
>     >
>     >
>     > --
>     > Nicholas Mitsakakis, MSc, PhD
>     > Biostatistician
>     > Toronto Health Economics and Technology Assessment (THETA)
>     Collaborative
>     > Assistant Professor
>     > Leslie Dan Faculty of Pharmacy, University of Toronto
>     > 6th Floor, Room 641
>     > 144 College Street
>     > Toronto ON, M5S 3M2
>     > e: n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>
>     <mailto:n.mitsakakis at theta.utoronto.ca
>     <mailto:n.mitsakakis at theta.utoronto.ca>>
>     > t: (416) 946 - 3700 <tel:%28416%29%20946%20-%203700>
>     > f: (416) 946 - 3719 <tel:%28416%29%20946%20-%203719>
>     > w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>
>     <http://www.theta.utoronto.ca>
> 
> 
> 
> 
> -- 
> Nicholas Mitsakakis, MSc, PhD
> Biostatistician
> Toronto Health Economics and Technology Assessment (THETA) Collaborative
> Assistant Professor
> Leslie Dan Faculty of Pharmacy, University of Toronto
> 6th Floor, Room 641
> 144 College Street
> Toronto ON, M5S 3M2
> e: n.mitsakakis at theta.utoronto.ca <mailto:n.mitsakakis at theta.utoronto.ca>
> t: (416) 946 - 3700
> f: (416) 946 - 3719
> w: www.theta.utoronto.ca <http://www.theta.utoronto.ca>


From highstat at highstat.com  Thu Oct 24 10:34:36 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 24 Oct 2013 09:34:36 +0100
Subject: [R-sig-ME] Course: Mixed modelling  (with intro MCMC)
Message-ID: <5268DB9C.4080708@highstat.com>

We would like to announce the following stats course;

Course: Introduction to MCMC, Linear mixed effects models and GLMM with R
When: 20-24 January, 2014
Where: Bangor University, UK
Info: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyer2014_02Bangor.pdf

Kind regards,

Alain

-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From stefan.ferger at yahoo.de  Thu Oct 24 13:02:27 2013
From: stefan.ferger at yahoo.de (Stefan Ferger)
Date: Thu, 24 Oct 2013 12:02:27 +0100 (BST)
Subject: [R-sig-ME] Zero-inflated binomial (ZIB) models in glmmADMB:
	warnings and errors
Message-ID: <1382612547.36250.YahooMailNeo@web171705.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131024/9341b55e/attachment.pl>

From saba.ghotbi at gmail.com  Thu Oct 24 10:51:23 2013
From: saba.ghotbi at gmail.com (saba)
Date: Thu, 24 Oct 2013 12:21:23 +0330
Subject: [R-sig-ME] GAMM4: In mer_finalize(ans) : false convergence (8)
Message-ID: <000001ced096$3c0f23a0$b42d6ae0$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131024/71c63514/attachment.pl>

From Maria_Paola.Bissiri at tu-dresden.de  Thu Oct 24 21:34:52 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Thu, 24 Oct 2013 19:34:52 +0000
Subject: [R-sig-ME] What does "number of groups < 50"
In-Reply-To: <52667CB6.7070809@mcmaster.ca>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
Message-ID: <20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>

Dear Prof. Bolker,
thank you very much for your answer. Yes, in my model the random  
effects are the experiment participants:
(1 + predictor | participant).
There are 86 participants.

My question is if likelihood ratio tests are reliable for calculating  
p-values for the parameters of my glmer model (family=binomial).
I am trying parametric bootstrapping with bootMer and confint, but  
those scripts have been running since more than 1700 minutes (is it  
normal that it takes so long?). So I would prefer to use the LRT  
method, provided that it gives reliable results.

How can I find out if LRT is suitable for my model? Is a number of  
groups > 50 sufficient?
What is meant with "finite-size cases" in this Faq?  
http://glmm.wikidot.com/faq#toc5
For using LRT, are there requirements also regarding the total number  
of samples and of parameters?

Below I copy information about my model and the fitting.
I would be thankful for any suggestion you could give me.
Kind regards,
Maria Paola

> fallmid.glmer6
Generalized linear mixed model fit by maximum likelihood ['glmerMod']
  Family: binomial ( logit )
Formula: resp_X ~ lang * ini_pch + lang * manner + lang * fin_B + (1 +  
      fin_B | subj_ID)
    Data: fallmid
       AIC       BIC    logLik  deviance
1731.5874 1875.8948 -838.7937 1677.5874
Random effects:
  Groups  Name        Std.Dev. Corr
  subj_ID (Intercept) 1.242
          fin_Bm      1.956    -0.72
Number of obs: 1548, groups: subj_ID, 86
Fixed Effects:
     (Intercept)           langde           langen           langsw     
      ini_pchm         ini_pchr         mannerla         mannerna       
      fin_Bm
        -1.76590          0.71972          0.14369          0.49608     
       0.25780         -0.02228          0.02569         -0.24087       
     2.13501
langde:ini_pchm  langen:ini_pchm  langsw:ini_pchm  langde:ini_pchr   
langen:ini_pchr  langsw:ini_pchr  langde:mannerla  langen:mannerla   
langsw:mannerla
        -0.52407          0.11792          0.26505         -0.73270     
      -1.01174         -0.03017         -0.19740         -0.48532       
     0.49438
langde:mannerna  langen:mannerna  langsw:mannerna    langde:fin_Bm     
langen:fin_Bm    langsw:fin_Bm
         0.41269          0.65082          0.61956         -1.57816     
      -1.17330         -2.32019

> probs.fallmid.glmer6 = 1/(1+exp(-fitted(fallmid.glmer6)))
> probs.fallmid.glmer6 = binomial()$linkinv(fitted(fallmid.glmer6))
> library(Hmisc)
> fit.probs.fallmid.glmer6 = somers2(probs.fallmid.glmer6,  
> as.numeric(fallmid$resp_X)-1)
> fit.probs.fallmid.glmer6
            C          Dxy            n      Missing
    0.8606880    0.7213759 1548.0000000    0.0000000



Zitat von Ben Bolker <bbolker at gmail.com>:

> [forwarding to r-sig-mixed models]
>
> -------- Original Message --------
> Subject: What does "number of groups < 50"
> Resent-Date: Tue, 22 Oct 2013 07:42:08 -0400
> Date: Tue, 22 Oct 2013 11:41:04 +0000
> From: Maria Paola
> To: bolker at mcmaster.ca
>
> Dear Prof. Bolker,
> I am carrying out an analysis of my data fitting a GLMM with glmer()
> (from lme4), family binomial.
>
> In the chapter "pvalues" in the manual (page 59)
> http://cran.r-project.org/web/packages/lme4/lme4.pdf
> you recommend the starred (*) methods "when the number of groups is < 50".
>
> What is meant exactly with "number of groups"?
>
> I have in total 1548 observations and four groups of perception
> experiment participants: German, Chinese, Swedish and English natives
> (language is a predictor in the model), with a maximum of 30
> participants per language.
>
> Using the starred (*) methods for GLMMs means bootstrapping, but I am
> experiencing problems with that (e.g. too long calculation time), so I
> would prefer to use Likelihood Ratio Tests.
> However, I am not sure if this method is suitable. I am not sure if my
> data fulfill the criterium of a number of group > 50, since I do not
> know what it means.
> =============
>
>       It's not 100% clear since I don't know the structure of your
> model exactly (presumably it's something like response ~ [fixed
> effects] + (1|participant), or response ~ [fixed effects] +
> (?|participant), i.e. you are using participant as a random effect),
> but the 'number of groups' is the number of levels of the
> random-effects grouping variable, i.e. probably the total number of
> participants in your experiment (which sounds like it is probably >
> 50). These numbers are reported in the output of glmer, in your case
> it would look something like "Number of obs: 1548, groups: participant, ??

-- 
Dr. Maria Paola Bissiri

TU Dresden
Fakult?t Elektrotechnik und Informationstechnik
Institut f?r Akustik und Sprachkommunikation
01062 Dresden

Barkhausen-Bau, Raum S54
Helmholtzstra?e 18

Tel: +49 (0)351 463-34283
Fax: +49 (0)351 463-37781
E-Mail: Maria_Paola.Bissiri at tu-dresden.de
http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm


From bbolker at gmail.com  Thu Oct 24 23:52:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Oct 2013 17:52:25 -0400
Subject: [R-sig-ME] What does "number of groups < 50"
In-Reply-To: <20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
Message-ID: <52699699.8040509@gmail.com>

  There is very little established theory giving error bounds for
different ways of approximating p-values (someone can please pop up and
correct me if they know of some!  Even better, they can edit
http://glmm.wikidot.com/faq and add them.).  In general, the ordering is

  parametric bootstrap > likelihood profile > Wald

in terms of computational effort, and the reverse order in terms of
accuracy/required sample size.

  There are rules of thumb about total number of observations (N), ratio
of observations to parameters (N/k), residual degrees of freedom (N-k),
number of groups (n), etc., but I can't give you an authoritative
reference.  The number of grouping levels is often the most limiting
factor, so that's what I've quoted.  In my opinion (for whatever it's
worth), you should probably be OK with LRTs (you appear to have N=1548,
k=26, n=86, although I might have miscounted; N-k is large (>100), and
N/k is reasonably large (approx. 60)).  In general, what we mean by
"large" is that the distribution of the sum of N objects converges
reasonably well to a Normal (or the scaled distribution of the sum of
squares converges to a chi^2 distribution); for N>50 this should be
reasonable unless the underlying distribution is really pathological, or
you're trying to do tests on the extreme tails of the distributions ...

  The only way to be sure is to calculate PB confidence intervals for
your model (or for some subset), and compare them with the LRT intervals.

  Ben Bolker

On 13-10-24 03:34 PM, Maria Paola Bissiri wrote:
> Dear Prof. Bolker,
> thank you very much for your answer. Yes, in my model the random effects
> are the experiment participants:
> (1 + predictor | participant).
> There are 86 participants.
> 
> My question is if likelihood ratio tests are reliable for calculating
> p-values for the parameters of my glmer model (family=binomial).
> I am trying parametric bootstrapping with bootMer and confint, but those
> scripts have been running since more than 1700 minutes (is it normal
> that it takes so long?). So I would prefer to use the LRT method,
> provided that it gives reliable results.
> 
> How can I find out if LRT is suitable for my model? Is a number of
> groups > 50 sufficient?
> What is meant with "finite-size cases" in this Faq?
> http://glmm.wikidot.com/faq#toc5
> For using LRT, are there requirements also regarding the total number of
> samples and of parameters?
> 
> Below I copy information about my model and the fitting.
> I would be thankful for any suggestion you could give me.
> Kind regards,
> Maria Paola
> 
>> fallmid.glmer6
> Generalized linear mixed model fit by maximum likelihood ['glmerMod']
>  Family: binomial ( logit )
> Formula: resp_X ~ lang * ini_pch + lang * manner + lang * fin_B + (1 +
>      fin_B | subj_ID)
>    Data: fallmid
>       AIC       BIC    logLik  deviance
> 1731.5874 1875.8948 -838.7937 1677.5874
> Random effects:
>  Groups  Name        Std.Dev. Corr
>  subj_ID (Intercept) 1.242
>          fin_Bm      1.956    -0.72
> Number of obs: 1548, groups: subj_ID, 86
> Fixed Effects:
>     (Intercept)           langde           langen           langsw   
>      ini_pchm         ini_pchr         mannerla         mannerna     
>      fin_Bm
>        -1.76590          0.71972          0.14369          0.49608   
>       0.25780         -0.02228          0.02569         -0.24087     
>     2.13501
> langde:ini_pchm  langen:ini_pchm  langsw:ini_pchm  langde:ini_pchr 
> langen:ini_pchr  langsw:ini_pchr  langde:mannerla  langen:mannerla 
> langsw:mannerla
>        -0.52407          0.11792          0.26505         -0.73270   
>      -1.01174         -0.03017         -0.19740         -0.48532     
>     0.49438
> langde:mannerna  langen:mannerna  langsw:mannerna    langde:fin_Bm   
> langen:fin_Bm    langsw:fin_Bm
>         0.41269          0.65082          0.61956         -1.57816   
>      -1.17330         -2.32019
> 
>> probs.fallmid.glmer6 = 1/(1+exp(-fitted(fallmid.glmer6)))
>> probs.fallmid.glmer6 = binomial()$linkinv(fitted(fallmid.glmer6))
>> library(Hmisc)
>> fit.probs.fallmid.glmer6 = somers2(probs.fallmid.glmer6,
>> as.numeric(fallmid$resp_X)-1)
>> fit.probs.fallmid.glmer6
>            C          Dxy            n      Missing
>    0.8606880    0.7213759 1548.0000000    0.0000000
> 
> 
> 
> Zitat von Ben Bolker <bbolker at gmail.com>:
> 
>> [forwarding to r-sig-mixed models]
>>
>> -------- Original Message --------
>> Subject: What does "number of groups < 50"
>> Resent-Date: Tue, 22 Oct 2013 07:42:08 -0400
>> Date: Tue, 22 Oct 2013 11:41:04 +0000
>> From: Maria Paola
>> To: bolker at mcmaster.ca
>>
>> Dear Prof. Bolker,
>> I am carrying out an analysis of my data fitting a GLMM with glmer()
>> (from lme4), family binomial.
>>
>> In the chapter "pvalues" in the manual (page 59)
>> http://cran.r-project.org/web/packages/lme4/lme4.pdf
>> you recommend the starred (*) methods "when the number of groups is <
>> 50".
>>
>> What is meant exactly with "number of groups"?
>>
>> I have in total 1548 observations and four groups of perception
>> experiment participants: German, Chinese, Swedish and English natives
>> (language is a predictor in the model), with a maximum of 30
>> participants per language.
>>
>> Using the starred (*) methods for GLMMs means bootstrapping, but I am
>> experiencing problems with that (e.g. too long calculation time), so I
>> would prefer to use Likelihood Ratio Tests.
>> However, I am not sure if this method is suitable. I am not sure if my
>> data fulfill the criterium of a number of group > 50, since I do not
>> know what it means.
>> =============
>>
>>       It's not 100% clear since I don't know the structure of your
>> model exactly (presumably it's something like response ~ [fixed
>> effects] + (1|participant), or response ~ [fixed effects] +
>> (?|participant), i.e. you are using participant as a random effect),
>> but the 'number of groups' is the number of levels of the
>> random-effects grouping variable, i.e. probably the total number of
>> participants in your experiment (which sounds like it is probably >
>> 50). These numbers are reported in the output of glmer, in your case
>> it would look something like "Number of obs: 1548, groups:
>> participant, ??
>


From bbolker at gmail.com  Fri Oct 25 00:14:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Oct 2013 22:14:28 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?GAMM4=3A_In_mer=5Ffinalize=28ans=29_=3A_fals?=
	=?utf-8?q?e_convergence_=288=29?=
References: <000001ced096$3c0f23a0$b42d6ae0$@gmail.com>
Message-ID: <loom.20131025T001100-599@post.gmane.org>

saba <saba.ghotbi at ...> writes:

> 
> Hi
> 
> I have read your comment on ( In mer_finalize(ans)), and some questions
> raised for me. It would be your kind if advise me about all 
> or some of them:

  I'm not sure who you're addressing (this is a mailing list), but I'll
try.

> 
> In introducing the random effect is it important that
>  repeated measurements
> exist per individuals? And why?

  It depends on the model.  If the dispersion parameter is estimated
(as in a linear mixed model fitted with lmer or a Gamma or Gaussian
model fitted with glmer), then a one-measurement-per-individual
experimental design will probably end up confounding the dispersion
parameter (or residual variance in the case of lmer fits) with the
random effect.  Hopefully you'll get an error or a warning message in
this case, but it is possible to trick lme4.
  If the dispersion parameter is fixed (binomial/Poisson GLMMs) then
an observation-level random effect is a useful way to model overdispersion.
See http://glmm.wikidot.com/faq 

> 
> Does R consider the repeated values in a group and calculate
>  the variances?

  Not sure what you mean here.  You may want to read e.g. 
Pinheiro and Bates 2000, or some other text on mixed models, for
the basic theory of what mixed-model software is estimating.

> 
> Best regards
> 
> saba


From dieter.menne at menne-biomed.de  Fri Oct 25 10:59:08 2013
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 25 Oct 2013 08:59:08 +0000 (UTC)
Subject: [R-sig-ME] lme: predictions variance collapses when one more level
	is added
Message-ID: <loom.20131025T105037-32@post.gmane.org>

I have a simple mixed-model, with predictive factor treat (levels M1,M2,M3,
M4), continuous par, and a grouping variable subj from a cross-over experiment.

Everything works as expected when I only use M1, M2, M3; see subset.lme
below. The residuals are well distributed; resid(.,type="p")~fitted(.)|treat

When I add level M4 (all.lme below), the variance of the predictions shrinks
to almost zero. I know that level M4 adds heteroscedasticity, so I tried
with varPower(); this corrects for the residual, but the fitted() appear
nonsensical. 


d = structure(list(subj = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 14L, 
14L, 14L, 14L, 15L, 15L, 15L, 15L, 16L, 17L, 17L, 17L, 17L), .Label = c("1", 
"3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", 
"15", "16", "17", "18"), class = "factor"), treat = structure(c(4L, 
1L, 3L, 2L, 2L, 3L, 1L, 4L, 3L, 2L, 4L, 1L, 4L, 3L, 2L, 3L, 4L, 
2L, 1L, 1L, 4L, 2L, 3L, 4L, 3L, 1L, 2L, 1L, 4L, 3L, 2L, 2L, 3L, 
4L, 1L, 2L, 4L, 3L, 4L, 3L, 1L, 2L, 2L, 3L, 4L, 1L, 2L, 1L, 3L, 
4L, 4L, 1L, 3L, 2L, 1L, 2L, 4L, 3L, 1L, 3L, 2L, 4L, 1L), .Label = c("M1", 
"M2", "M3", "M4"), class = "factor"), par = c(162.1, 105.2, 146.1, 
119.7, 129.9, 152.2, 156.8, 235.4, 122.6, 107.6, 199, 82.5, 165.8, 
115.3, 128.4, 96.8, 334.3, 67.9, 84.3, 152.3, 63.7, 103.6, 97.7, 
335.2, 130.5, 113.6, 123.9, 79.7, 172.1, 94.7, 97, 101.9, 125.4, 
177.1, 96, 90.9, 174.2, 96.3, 343.6, 106.3, 94.9, 112.5, 111.6, 
110.4, 197.9, 116, 93, 85.1, 123.1, 222, 28.4, 123.3, 111.6, 
106.3, 81.8, 101.5, 301.1, 102, 59.8, 131.1, 99.2, 104.6, 107.9
)), .Names = c("subj", "treat", "par"), row.names = c(1L, 2L, 
3L, 5L, 7L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 18L, 19L, 
20L, 21L, 22L, 23L, 25L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 35L, 
36L, 38L, 39L, 40L, 42L, 43L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 
52L, 54L, 55L, 57L, 58L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 68L, 
70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 79L), class = "data.frame")

library(nlme)
str(d)
# Drop one level first to see reasonable result
subset.lme = lme(par~treat,random=~1|subj,data=d[d$treat!="M4",])
# This plot looks good (scaling chosen for comparison below)
plot(subset.lme,  resid(.,type="p")~fitted(.)|treat,pch=16,xlim=c(70,250))
summary(subset.lme)

# Use all levels: variance of predictions per group shrinks to nothing
all.lme = lme(par~treat,random=~1|subj,data=d)
plot(all.lme,  resid(.,type="p")~fitted(.)|treat,pch=16,xlim=c(70,250))
summary(all.lme)

# Taking into account heteroscedastic M4 does not change the picture
allpower.lme = lme(par~treat,random=~1|subj,data=d,weights=varPower())
plot(allpower.lme,  resid(.,type="p")~fitted(.)|treat,pch=16,xlim=c(70,250))
summary(allpower.lme)


sessionInfo()


#R version 3.0.2 (2013-09-25)
#Platform: i386-w64-mingw32/i386 (32-bit)

#locale:
#  [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
LC_MONETARY=German_Germany.1252
#[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    
#
#attached base packages:
#  [1] stats     graphics  grDevices utils     datasets  methods   base     

#other attached packages:
#  [1] nlme_3.1-111

...


From b.pelzer at maw.ru.nl  Fri Oct 25 11:27:13 2013
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 25 Oct 2013 11:27:13 +0200
Subject: [R-sig-ME] warning glmer
In-Reply-To: <52699699.8040509@gmail.com>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
	<52699699.8040509@gmail.com>
Message-ID: <526A3971.8040302@maw.ru.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131025/5d364523/attachment.pl>

From steve.walker at utoronto.ca  Fri Oct 25 11:37:27 2013
From: steve.walker at utoronto.ca (Steve Walker)
Date: Fri, 25 Oct 2013 05:37:27 -0400
Subject: [R-sig-ME] warning glmer
In-Reply-To: <526A3971.8040302@maw.ru.nl>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
	<52699699.8040509@gmail.com> <526A3971.8040302@maw.ru.nl>
Message-ID: <526A3BD7.7000607@utoronto.ca>

Hi Ben,

I think you should be fine.  Please see here for details:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021151.html

Cheers,
Steve

On 2013-10-25 5:27 AM, Ben Pelzer wrote:
> Dear list,
>
> When running glmer I got a warning message:
>
> Warning in rankMatrix(X) :
>     rankMatrix(<large sparse Matrix>, method = 'tolNorm2') coerces to
> dense matrix.
>     Probably should rather use  method = 'qrLINPACK' !?
>
> With verbose=TRUE, the following output is produced:
>
> (NM) 20: f = 1.42942e+006 at    0.119639     0.45168 -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116 -2.7772 -0.00823687
> 0.0111525 0.000371882 0.000425201 2.08593   -0.804334   -0.597046
> -1.23742   0.0721005 -0.00524431  -0.0777254  -0.0455618   0.0182222
> 0.00949421 0.0178676  -0.0760966  -0.0310283  -0.0179217
> (NM) 40: f = 1.42942e+006 at    0.119639     0.45168  -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116     -2.7772
> -0.00823687   0.0111525 0.000371882 0.000425201     2.08593 -0.804334
> -0.597046    -1.23742   0.0721005 -0.00524431 -0.0777254  -0.0455618
> 0.0182222  0.00949421   0.0178676 -0.0760966  -0.0310283  -0.0179217
> (NM) 60: f = 1.42942e+006 at    0.119639     0.45168  -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116     -2.7772
> -0.00823687   0.0111525 0.000371882 0.000425201     2.08593 -0.804334
> -0.597046    -1.23742   0.0721005 -0.00524431 -0.0777254  -0.0455618
> 0.0182222  0.00949421   0.0178676 -0.0760966  -0.0310283  -0.0179217
> (NM) 80: f = 1.42942e+006 at    0.119639     0.45168  -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116     -2.7772
> -0.00823687   0.0111525 0.000371882 0.000425201     2.08593 -0.804334
> -0.597046    -1.23742   0.0721005 -0.00524431 -0.0777254  -0.0455618
> 0.0182222  0.00949421   0.0178676 -0.0760966  -0.0310283  -0.0179217
> (NM) 100: f = 1.42942e+006 at    0.119639     0.45168  -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116     -2.7772
> -0.00823687   0.0111525 0.000371882 0.000425201     2.08593 -0.804334
> -0.597046    -1.23742   0.0721005 -0.00524431 -0.0777254  -0.0455618
> 0.0182222  0.00949421   0.0178676 -0.0760966  -0.0310283  -0.0179217
> (NM) 120: f = 1.42942e+006 at    0.119639     0.45168  -0.0183788
> -0.00152183   0.0246831  -0.0123731   0.0524116     -2.7772
> -0.00823687   0.0111525 0.000371882 0.000425201
>
> The estimates of fixed and random effects look "normal", no unreasonable
> results. However, should I still be worried about the estimates found,
> given this warning message and verbose results?
>
> I updated package lme4 recently, using "Update packages" in the main
> menu. My R version is 3.0.2. Thanks for any help! Regards,
>
> Ben.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mtoncic at ffri.hr  Fri Oct 25 12:12:02 2013
From: mtoncic at ffri.hr (marKo)
Date: Fri, 25 Oct 2013 12:12:02 +0200
Subject: [R-sig-ME] multilevel linear models
In-Reply-To: <CAM8BP_=msWb9Y5CjOPaeD1c+VD6NYj2Skn2P0vRGevoiwFS3RA@mail.gmail.com>
References: <CAM8BP_=msWb9Y5CjOPaeD1c+VD6NYj2Skn2P0vRGevoiwFS3RA@mail.gmail.com>
Message-ID: <526A43F2.8020806@ffri.hr>

On 23.10.2013 08:35, srecko joksimovic wrote:
> Hi,
> just recently I started my research on MLM, but now I'm little bit
> confused... I tried to build a model, but now I'm not quite sure what's the
> right thing I'm trying to do. The point is that I have a dataset with
> counts and time of users activity. For example, it looks something like
> this:
> userID, group, department, organizationalUnit, activityCount, activityTime,
> totalPoints
> 112,     g1,      d1,              o1                        232
>      45,4              45
> 122,     g3,      d2,              o1                        323
>      25,6              25
> 892,     g1,      d1,              o1                        98
>      56,3              99
> 313,     g2,      d1,              o2                        332
>      41,5              67
> 763,     g3,      d2,              o2                        555
>      89.7              23
>
> maybe the example itself it's not that important at this point, but I could
> provide more data if that is needed. However, the original idea was to use
> activitycount, totalpoints, organizationalUnit and department as a fixed
> variables, as well as interactions between organizationalUnits vs. count
> and time and, department vs. count and time. Random variables are usedId
> and group\department. The problem occurs when I add department as a fixed
> and/or random part, because of the following error:
> Error in lme4::lFormula(formula = totalPoints~ activityCount  +
> activityTime  + ...: rank of X = 38 < ncol(X) = 39.
>
> I decided to remove group\department as a random effect, but that might not
> be good, because I need group nested under department. I also tried to add
> another random variable group\organizationalUnit | userID, which (I hope)
> means that user varies across groups which are nested under the
> organizational units. And I'm not sure about that part. In lmer (lmerTest)
> documentation, I found several examples, which translated to this one could
> be written like this:
> group:organizationalUnit | userID
> group\organizationalUnit | userID
> group+organizationalUnit | userID
>
> could someone please explain how those models are different, and what they
> mean? I tried to run all of them but I run out of memory. I know that 8GB
> of RAM is not too much, but it was enough for most of my tests. Should I
> look for more RAM or should I correct my model? :)
>
> thanks,
> Srecko
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
At first it seems odd to me to estimate the same effect as fixed and 
random. Maybe I'm wrong but I think it doesn't make sense (I guess that 
it might be sound in some circumstances but I cannot think of one). 
Check if your categorical variables are defined as factors. As concerns 
the random parameter distinction in definition it should result as 
generally in linear model definition.
A:B ? only the interaction term
A*B ? main effects and interaction
A+B ? only main effects
In the random part you estimate the intercept if you specify as you have 
(if you do not want to, you should state it explicitly by (0+A+B|ID).
I think that RAM is not the problem. I have fitted models to large data 
setts with less RAM without problems.
Hope it helps.

Marko


From bbolker at gmail.com  Sat Oct 26 00:48:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 25 Oct 2013 22:48:23 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme=3A_predictions_variance_collapses_when_o?=
	=?utf-8?q?ne_more_level=09is_added?=
References: <loom.20131025T105037-32@post.gmane.org>
Message-ID: <loom.20131026T004319-638@post.gmane.org>

Dieter Menne <dieter.menne at ...> writes:

> 
> I have a simple mixed-model, with predictive factor treat (levels M1,M2,M3,
> M4), continuous par, and a grouping variable subj from a cross-over 
> experiment.
> 
> Everything works as expected when I only use M1, M2, M3; see subset.lme
> below. The residuals are well distributed; 
> resid(.,type="p")~fitted(.)|treat
> 
> When I add level M4 (all.lme below), the variance of the 
> predictions shrinks
> to almost zero. I know that level M4 adds heteroscedasticity, so I tried
> with varPower(); this corrects for the residual, but the fitted() appear
> nonsensical. 

  Sorry for snipping context here (I'm posting via gmane, which doesn't
like that).  If I use  weights=varIdent(form=~1|treat)) rather than
weights=varPower() (i.e. residual variance varies by treatment group,
rather than as a power function of the estimated mean), I get what
seem (at least at a quick glance) to be reasonable results.


From i.m.s.white at ed.ac.uk  Sat Oct 26 15:39:59 2013
From: i.m.s.white at ed.ac.uk (ian m s white)
Date: Sat, 26 Oct 2013 14:39:59 +0100
Subject: [R-sig-ME] lme: predictions variance collapses when one more
	level	is added
In-Reply-To: <loom.20131026T004319-638@post.gmane.org>
References: <loom.20131025T105037-32@post.gmane.org>
	<loom.20131026T004319-638@post.gmane.org>
Message-ID: <AFBDF5E0-6760-4C28-87EB-2B9B27EF4411@ed.ac.uk>

There is another way of looking at this. The data comprise a sample of size 17 from a multivariate (normal) distribution. The sample mean vector (4x1) and covariance matrix (4x4) can be calculated, and hypothesis tests about the population mean vector  constructed (e.g. see text by Mardia, Kent and Bibby, or similar). I'm not sure whether this easily fits into the mixed model framework. Especially lme(r), which insist on having a single residual term added to everything.
  
On 25 Oct 2013, at 23:48, Ben Bolker <bbolker at gmail.com> wrote:

> Dieter Menne <dieter.menne at ...> writes:
> 
>> 
>> I have a simple mixed-model, with predictive factor treat (levels M1,M2,M3,
>> M4), continuous par, and a grouping variable subj from a cross-over 
>> experiment.
>> 
>> Everything works as expected when I only use M1, M2, M3; see subset.lme
>> below. The residuals are well distributed; 
>> resid(.,type="p")~fitted(.)|treat
>> 
>> When I add level M4 (all.lme below), the variance of the 
>> predictions shrinks
>> to almost zero. I know that level M4 adds heteroscedasticity, so I tried
>> with varPower(); this corrects for the residual, but the fitted() appear
>> nonsensical. 
> 
>  Sorry for snipping context here (I'm posting via gmane, which doesn't
> like that).  If I use  weights=varIdent(form=~1|treat)) rather than
> weights=varPower() (i.e. residual variance varies by treatment group,
> rather than as a power function of the estimated mean), I get what
> seem (at least at a quick glance) to be reasonable results.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From sharon.graham at pg.canterbury.ac.nz  Sun Oct 27 01:41:11 2013
From: sharon.graham at pg.canterbury.ac.nz (Elizabeth Graham)
Date: Sat, 26 Oct 2013 23:41:11 +0000
Subject: [R-sig-ME] confidence intervals on predictions from lme
Message-ID: <4F88CD2FCBB7464BBED9431A08B790840230FF@UCEXMBX01-D.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131026/9fd569b6/attachment.pl>

From dieter.menne at menne-biomed.de  Sun Oct 27 11:10:30 2013
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 27 Oct 2013 10:10:30 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme=3A_predictions_variance_collapses_when_o?=
	=?utf-8?q?ne_more_level=09is_added?=
References: <loom.20131025T105037-32@post.gmane.org>
	<loom.20131026T004319-638@post.gmane.org>
Message-ID: <loom.20131027T105643-458@post.gmane.org>

Ben Bolker commented:

>   Sorry for snipping context here (I'm posting via gmane, which doesn't
> like that).  If I use  weights=varIdent(form=~1|treat)) rather than
> weights=varPower() (i.e. residual variance varies by treatment group,
> rather than as a power function of the estimated mean), I get what
> seem (at least at a quick glance) to be reasonable results.

You are right; I received a similar comment from Ariel Muldoon off-list. I
admit that I have tried it, but most have done some stupid syntax mistake so
it go away unnoticed.

While it is a solution, I still do not understand what really happens with
the prediction. And, assuming I am using lmer, what should I do? I noted the
same collapsing effect.


Dieter


From bbolker at gmail.com  Mon Oct 28 03:43:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 28 Oct 2013 02:43:41 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme=3A_predictions_variance_collapses_when_o?=
	=?utf-8?q?ne_more_level=09is_added?=
References: <loom.20131025T105037-32@post.gmane.org>
	<loom.20131026T004319-638@post.gmane.org>
	<loom.20131027T105643-458@post.gmane.org>
Message-ID: <loom.20131028T033747-706@post.gmane.org>

Dieter Menne <dieter.menne at ...> writes:

> 
> Ben Bolker commented:
> 
> >   Sorry for snipping context here (I'm posting via gmane, which doesn't
> > like that).  If I use  weights=varIdent(form=~1|treat)) rather than
> > weights=varPower() (i.e. residual variance varies by treatment group,
> > rather than as a power function of the estimated mean), I get what
> > seem (at least at a quick glance) to be reasonable results.
> 
> You are right; I received a similar comment from Ariel Muldoon off-list. I
> admit that I have tried it, but most have done some stupid syntax mistake so
> it go away unnoticed.
> 
> While it is a solution, I still do not understand what really happens with
> the prediction. And, assuming I am using lmer, what should I do? I noted the
> same collapsing effect.
> 
> Dieter
> 

  I assume that what's going on is just the fairly frequently observed
situation that when the fourth group is included (without invoking
heteroscedasticity), the among-group variation is actually less than
expected from the within-group variation (i.e. less than 
var(within)/(n per group)), implying a negative within-group correlation ...

  I don't think transforming will help here ... David Afshartous
had some postings on allowing different random-effect variances
by treatment groups, but that's not what you need.  We have talked
some about how to implement heteroscedasticity models in lme4, but it's a lot
of work/more or less just a gleam in our eye at this point ...

  Which aspects of lmer are essential in this analysis 
(e.g. profiling, speed, consistency with other analyses, ...?)

  Ben Bolker


From dieter.menne at menne-biomed.de  Mon Oct 28 07:59:28 2013
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 28 Oct 2013 06:59:28 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme=3A_predictions_variance_collapses_when_o?=
	=?utf-8?q?ne_more_level=09is_added?=
References: <loom.20131025T105037-32@post.gmane.org>
	<loom.20131026T004319-638@post.gmane.org>
	<loom.20131027T105643-458@post.gmane.org>
	<loom.20131028T033747-706@post.gmane.org>
Message-ID: <loom.20131028T075839-892@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

>   Which aspects of lmer are essential in this analysis 
> (e.g. profiling, speed, consistency with other analyses, ...?)
> 

Just my own curiosity... No need to dig further. Thanks, Ben.

Dieter


From Maria_Paola.Bissiri at tu-dresden.de  Mon Oct 28 19:43:58 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Mon, 28 Oct 2013 18:43:58 +0000
Subject: [R-sig-ME] What does "number of groups < 50"
In-Reply-To: <52699699.8040509@gmail.com>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
	<52699699.8040509@gmail.com>
Message-ID: <20131028184358.Horde.7A-9onh1HzqxorYMmGapBg1@mail.zih.tu-dresden.de>

Dear Prof. Bolker,
thank you very much for your answer.

My bootMer script completed the 1000 iterations calculating confidence  
intervals at the levels 0.95, 0.99 and 0.999 using the methods "norm",  
"basic" and "perc", but gave the following warnings for each fixed  
effect:
Warning : Basic Intervals used Extreme Quantiles
Some basic intervals may be unstable
Warning : Percentile Intervals used Extreme Quantiles
Some percentile intervals may be unstable

Can I then use the intervals calculated by means of the "normal"  
method? Is such method based on an assumption of normality that should  
be tested?
As my response variable is dichotomous, I am not sure what I should  
test for normality and how.
I wonder if in my case the number of groups (86) is sufficient and  
maybe the test for normality is not necessary.

I copy below the bootMer script and the output for one of the fixed  
effects as example.
Kind regards,
Maria Paola Bissiri


Script:
-------

FUN <- function(fallmid.glmer6) {
      return(fixef(fallmid.glmer6))
}

# nsim = number of iterations
fm.glmer6.bM <- bootMer(fallmid.glmer6, FUN, nsim = 1000)

require("boot")

for (n in 1:length(fixef(fallmid.glmer6))){
    print(fixef(fallmid.glmer6)[n])
    (bMCI <- boot.ci(fm.glmer6.bM, conf = c(0.95, 0.99, 0.999),  
index=n, type=c("norm", "basic", "perc")))
    print(bMCI)
}


Example of output:
------------------

langen:ini_pchr
        -1.009678
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL :
boot.ci(boot.out = fm.glmer6.bM, conf = c(0.95, 0.99, 0.999),
      type = c("norm", "basic", "perc"), index = n)

Intervals :
Level      Normal              Basic              Percentile
95%   (-1.986,  0.032 )   (-1.981,  0.088 )   (-2.107, -0.038 )
99%   (-2.303,  0.349 )   (-2.242,  0.376 )   (-2.395,  0.223 )
99.9%   (-2.670,  0.717 )   (-2.471,  0.581 )   (-2.600,  0.451 )
Calculations and Intervals on Original Scale
Warning : Basic Intervals used Extreme Quantiles
Some basic intervals may be unstable
Warning : Percentile Intervals used Extreme Quantiles
Some percentile intervals may be unstable




Zitat von Ben Bolker <bbolker at gmail.com>:

> There is very little established theory giving error bounds for
> different ways of approximating p-values (someone can please pop up and
> correct me if they know of some!  Even better, they can edit
> http://glmm.wikidot.com/faq and add them.).  In general, the ordering is
>
>   parametric bootstrap > likelihood profile > Wald
>
> in terms of computational effort, and the reverse order in terms of
> accuracy/required sample size.
>
>   There are rules of thumb about total number of observations (N), ratio
> of observations to parameters (N/k), residual degrees of freedom (N-k),
> number of groups (n), etc., but I can't give you an authoritative
> reference.  The number of grouping levels is often the most limiting
> factor, so that's what I've quoted.  In my opinion (for whatever it's
> worth), you should probably be OK with LRTs (you appear to have N=1548,
> k=26, n=86, although I might have miscounted; N-k is large (>100), and
> N/k is reasonably large (approx. 60)).  In general, what we mean by
> "large" is that the distribution of the sum of N objects converges
> reasonably well to a Normal (or the scaled distribution of the sum of
> squares converges to a chi^2 distribution); for N>50 this should be
> reasonable unless the underlying distribution is really pathological, or
> you're trying to do tests on the extreme tails of the distributions ...
>
>   The only way to be sure is to calculate PB confidence intervals for
> your model (or for some subset), and compare them with the LRT intervals.
>
>   Ben Bolker
>
> On 13-10-24 03:34 PM, Maria Paola Bissiri wrote:
>> Dear Prof. Bolker,
>> thank you very much for your answer. Yes, in my model the random effects
>> are the experiment participants:
>> (1 + predictor | participant).
>> There are 86 participants.
>>
>> My question is if likelihood ratio tests are reliable for calculating
>> p-values for the parameters of my glmer model (family=binomial).
>> I am trying parametric bootstrapping with bootMer and confint, but those
>> scripts have been running since more than 1700 minutes (is it normal
>> that it takes so long?). So I would prefer to use the LRT method,
>> provided that it gives reliable results.
>>
>> How can I find out if LRT is suitable for my model? Is a number of
>> groups > 50 sufficient?
>> What is meant with "finite-size cases" in this Faq?
>> http://glmm.wikidot.com/faq#toc5
>> For using LRT, are there requirements also regarding the total number of
>> samples and of parameters?
>>
>> Below I copy information about my model and the fitting.
>> I would be thankful for any suggestion you could give me.
>> Kind regards,
>> Maria Paola
>>
>>> fallmid.glmer6
>> Generalized linear mixed model fit by maximum likelihood ['glmerMod']
>>  Family: binomial ( logit )
>> Formula: resp_X ~ lang * ini_pch + lang * manner + lang * fin_B + (1 +
>>      fin_B | subj_ID)
>>    Data: fallmid
>>       AIC       BIC    logLik  deviance
>> 1731.5874 1875.8948 -838.7937 1677.5874
>> Random effects:
>>  Groups  Name        Std.Dev. Corr
>>  subj_ID (Intercept) 1.242
>>          fin_Bm      1.956    -0.72
>> Number of obs: 1548, groups: subj_ID, 86
>> Fixed Effects:
>>     (Intercept)           langde           langen           langsw
>>      ini_pchm         ini_pchr         mannerla         mannerna
>>      fin_Bm
>>        -1.76590          0.71972          0.14369          0.49608
>>       0.25780         -0.02228          0.02569         -0.24087
>>     2.13501
>> langde:ini_pchm  langen:ini_pchm  langsw:ini_pchm  langde:ini_pchr
>> langen:ini_pchr  langsw:ini_pchr  langde:mannerla  langen:mannerla
>> langsw:mannerla
>>        -0.52407          0.11792          0.26505         -0.73270
>>      -1.01174         -0.03017         -0.19740         -0.48532
>>     0.49438
>> langde:mannerna  langen:mannerna  langsw:mannerna    langde:fin_Bm
>> langen:fin_Bm    langsw:fin_Bm
>>         0.41269          0.65082          0.61956         -1.57816
>>      -1.17330         -2.32019
>>
>>> probs.fallmid.glmer6 = 1/(1+exp(-fitted(fallmid.glmer6)))
>>> probs.fallmid.glmer6 = binomial()$linkinv(fitted(fallmid.glmer6))
>>> library(Hmisc)
>>> fit.probs.fallmid.glmer6 = somers2(probs.fallmid.glmer6,
>>> as.numeric(fallmid$resp_X)-1)
>>> fit.probs.fallmid.glmer6
>>            C          Dxy            n      Missing
>>    0.8606880    0.7213759 1548.0000000    0.0000000
>>
>>
>>
>> Zitat von Ben Bolker <bbolker at gmail.com>:
>>
>>> [forwarding to r-sig-mixed models]
>>>
>>> -------- Original Message --------
>>> Subject: What does "number of groups < 50"
>>> Resent-Date: Tue, 22 Oct 2013 07:42:08 -0400
>>> Date: Tue, 22 Oct 2013 11:41:04 +0000
>>> From: Maria Paola
>>> To: bolker at mcmaster.ca
>>>
>>> Dear Prof. Bolker,
>>> I am carrying out an analysis of my data fitting a GLMM with glmer()
>>> (from lme4), family binomial.
>>>
>>> In the chapter "pvalues" in the manual (page 59)
>>> http://cran.r-project.org/web/packages/lme4/lme4.pdf
>>> you recommend the starred (*) methods "when the number of groups is <
>>> 50".
>>>
>>> What is meant exactly with "number of groups"?
>>>
>>> I have in total 1548 observations and four groups of perception
>>> experiment participants: German, Chinese, Swedish and English natives
>>> (language is a predictor in the model), with a maximum of 30
>>> participants per language.
>>>
>>> Using the starred (*) methods for GLMMs means bootstrapping, but I am
>>> experiencing problems with that (e.g. too long calculation time), so I
>>> would prefer to use Likelihood Ratio Tests.
>>> However, I am not sure if this method is suitable. I am not sure if my
>>> data fulfill the criterium of a number of group > 50, since I do not
>>> know what it means.
>>> =============
>>>
>>>       It's not 100% clear since I don't know the structure of your
>>> model exactly (presumably it's something like response ~ [fixed
>>> effects] + (1|participant), or response ~ [fixed effects] +
>>> (?|participant), i.e. you are using participant as a random effect),
>>> but the 'number of groups' is the number of levels of the
>>> random-effects grouping variable, i.e. probably the total number of
>>> participants in your experiment (which sounds like it is probably >
>>> 50). These numbers are reported in the output of glmer, in your case
>>> it would look something like "Number of obs: 1548, groups:
>>> participant, ??
>>

-- 
Dr. Maria Paola Bissiri

TU Dresden
Fakult?t Elektrotechnik und Informationstechnik
Institut f?r Akustik und Sprachkommunikation
01062 Dresden

Barkhausen-Bau, Raum S54
Helmholtzstra?e 18

Tel: +49 (0)351 463-34283
Fax: +49 (0)351 463-37781
E-Mail: Maria_Paola.Bissiri at tu-dresden.de
http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm


From andreas.nord at biol.lu.se  Mon Oct 28 09:43:14 2013
From: andreas.nord at biol.lu.se (Andreas Nord)
Date: Mon, 28 Oct 2013 08:43:14 +0000
Subject: [R-sig-ME] Problems with lme random slope+intercept model
Message-ID: <504BD08817485B49A9AB0ED11F217112720755F3@UWMBX04.uw.lu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131028/afa79aa2/attachment.pl>

From bbolker at gmail.com  Mon Oct 28 21:40:38 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 28 Oct 2013 20:40:38 +0000 (UTC)
Subject: [R-sig-ME] Problems with lme random slope+intercept model
References: <504BD08817485B49A9AB0ED11F217112720755F3@UWMBX04.uw.lu.se>
Message-ID: <loom.20131028T213352-378@post.gmane.org>

Andreas Nord <andreas.nord at ...> writes:


> Dear all,

> I'm trying to fit a model on ecological data in which I have
> measured a few biotic and abiotic factors over the course of a few
> days in several individuals. Specifically, I'm interested in
> modelling y ~ x1, with x2, x3, and 'factor' as independent
> variables. Because data suggests both slope and intercept (for y
> ~x1) might differ between individuals, I'd want to compare model fit
> for a saturated model with random intercept only, against that of a
> model with random slope + intercept. Data are available in full from
> this link: https://www.dropbox.com/s/mzk8utvgkzp4rtr/data.txt
 
> The random intercept model seems to function appropriately:
> data<-subset(data,data$id!='id225' & data$id!='id237' & data$id!='id233')
> m1.lme<-with(data,lme(y~x1+x2+x3+factor,random=~1|id,na.action=na.omit))
 
> However, fitting the random slope+intercept model produces an error message
>  I can't quite make sense of.
> m2.lme<-with(data,lme(y~x1+x2+x3+factor,random=~1+y|id,na.action=na.omit))
> #Error in chol.default((value + t(value))/2) :
> #  the leading minor of order 2 is not positive definite

  It doesn't really make any sense to use the *response* variable y
as the random-effects response.  It's the effect of the *predictor*
variable that will vary across individuals, so you should try writing it as

m2.lme<- lme(y~x1+x2+x3+factor,random=~1+x1|id,
             data=data,na.action=na.omit)

It's also better/more coherent to include 'data' as an argument
rather than to use with() in this case.

You can also use random=~x1|id since the intercept is included
implicitly (opinions differ about whether it is better to be compact
or explicit).

  Ben Bolker


From emmanuel.curis at parisdescartes.fr  Tue Oct 29 09:19:16 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 29 Oct 2013 09:19:16 +0100
Subject: [R-sig-ME] What does "number of groups < 50"
In-Reply-To: <20131028184358.Horde.7A-9onh1HzqxorYMmGapBg1@mail.zih.tu-dresden.de>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
	<52699699.8040509@gmail.com>
	<20131028184358.Horde.7A-9onh1HzqxorYMmGapBg1@mail.zih.tu-dresden.de>
Message-ID: <20131029081916.GA30283@info124.pharmacie.univ-paris5.fr>

Hello,

I'm not a specialist of bootstrap, hence will not give advice about
using normal approximation for bootstrap confidence interval; however,
I guess your warnings come from the fact that trying to obtain the
bilateral 99.9 % confidence interval using percentiles of a n = 1000
sample (as done with your 1000 bootstrap "iterations") roughly means
leave one value out (either min or max) and use all remaining values
as the confidence interval. Hence, either min or max (depending on the
one that was rejected) is used, leading to using the extreme values as
quantiles...

In other words, it simply suggests that 1000 iterations gives a too
small sample to have a good approximation of the 99.9 % confidence
interval, you should use more bootstrap replications. However, it
should be ok for the 95 % one, unless may be you have a lot of ties.

Hope this helps,

Emmanuel Curis

On Mon, Oct 28, 2013 at 06:43:58PM +0000, Maria Paola Bissiri wrote:
? My bootMer script completed the 1000 iterations calculating
? confidence intervals at the levels 0.95, 0.99 and 0.999 using the
? methods "norm", "basic" and "perc", but gave the following warnings
? for each fixed effect:
? Warning : Basic Intervals used Extreme Quantiles
? Some basic intervals may be unstable
? Warning : Percentile Intervals used Extreme Quantiles
? Some percentile intervals may be unstable

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From dieter.menne at menne-biomed.de  Tue Oct 29 12:18:40 2013
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 29 Oct 2013 11:18:40 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?lme=3A_predictions_variance_collapses_when_o?=
	=?utf-8?q?ne_more_level=09is_added?=
References: <loom.20131025T105037-32@post.gmane.org>
	<loom.20131026T004319-638@post.gmane.org>
	<loom.20131027T105643-458@post.gmane.org>
	<loom.20131028T033747-706@post.gmane.org>
Message-ID: <loom.20131029T121437-505@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

>   I assume that what's going on is just the fairly frequently observed
> situation that when the fourth group is included (without invoking
> heteroscedasticity), the among-group variation is actually less than
> expected from the within-group variation (i.e. less than 
> var(within)/(n per group)), implying a negative within-group correlation ...
> 

Dominik Grathwohl has sent me a simulation shown below with his permissin
that shows that heteroscedasticity is just a distraction, and that the
negative within-group correlation is the source of the problem. Note the
very small variance of the random intercept

Random effects: (for negative within-group correlation)
 Formula: ~1 | id
        (Intercept) Residual
StdDev:    7.93e-05     1.88


# Dominik Grathwohl's example on negative correlation
# leading to a collapse of prediction variance
library(nlme)
library(mvtnorm)
library(lattice)
# positive correlation
set.seed(171109)
N <- 20
(sigma <- matrix(c(4,2,2,3), ncol=2))
x <- rmvnorm(n=N, mean=c(1,2), sigma=sigma)
dim(x)
colMeans(x)
sd(x)
cov(x)
sqrt(cov(x)[2,1]) # between subject sd
(sd.w <- sd(x[,1]-x[,2])/sqrt(2)) # within subject sd 
# check with mixed model 
df <- data.frame(id=rep(1:N,2), trt=gl(2,N), y=c(x[,1],x[,2])) 
sp <- list(superpose.symbol = list(pch=rep(16,7))) 
xyplot(y~trt, groups=factor(id), data=subset(df, id < 101), 
       type=c("g", "p", "l"), xlab="trt", ylab="y", par.settings=sp)
summary(m1 <- lme(y ~ trt, data=df, random=~1|id)) 
plot(m1,  resid(.,type="p")~fitted(.)|trt,pch=16)

# negative correlation
set.seed(171109)
N <- 20
(sigma <- matrix(c(4,-2,-2,3), ncol=2))
x <- rmvnorm(n=N, mean=c(1,2), sigma=sigma)
dim(x)
colMeans(x)
sd(x)
cov(x)
sqrt(cov(x)[2,1]) # between subject sd
(sd.w <- sd(x[,1]-x[,2])/sqrt(2)) # within subject sd 
# check with mixed model 
df <- data.frame(id=rep(1:N,2), trt=gl(2,N), y=c(x[,1],x[,2]))
sp <- list(superpose.symbol = list(pch=rep(16,7))) 
xyplot(y~trt, groups=factor(id), data=subset(df, id < 101), 
       type=c("g", "p", "l"), xlab="trt", ylab="y", par.settings=sp) 
summary(m1<-lme(y ~ trt, data=df, random=~1|id)) 
plot(m1,  resid(.,type="p")~fitted(.)|trt,pch=16)


From dave.kane at gmail.com  Tue Oct 29 21:01:02 2013
From: dave.kane at gmail.com (David Kane)
Date: Tue, 29 Oct 2013 16:01:02 -0400
Subject: [R-sig-ME] behavior of na.action = na.exclude using lmer in lme4
 1.0-5 inconsistent with lm and with older versions of lme4
Message-ID: <CAG6L79ndcbxObgWRkiQsqdo5=rgSw7t3f5Z2h0ZpE+1vF3U2ZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131029/04333e4a/attachment.pl>

From bbolker at gmail.com  Wed Oct 30 19:50:48 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 30 Oct 2013 18:50:48 +0000 (UTC)
Subject: [R-sig-ME] behavior of na.action = na.exclude using lmer in
	lme4 1.0-5 inconsistent with lm and with older versions of lme4
References: <CAG6L79ndcbxObgWRkiQsqdo5=rgSw7t3f5Z2h0ZpE+1vF3U2ZQ@mail.gmail.com>
Message-ID: <loom.20131030T194900-348@post.gmane.org>

David Kane <dave.kane at ...> writes:

> 
> Consider a simple example:
> 
> > set.seed(1)> df <- data.frame(x = c(rnorm(7), NA),
>  y = rep(c("A", "B"), 4))> length(fitted(lm(data =
> df, x ~ y, na.action = na.exclude)))[1] 8
> 
> This behaves as I would expect. Although there is no fitted value for
> the 8th observation, because x is NA for that row, the fitted values
> are "padded" with NA so that they are the same length as the number of
> rows in the input data frame df, which is very handy. But calling
> na.action = na.exclude no longer has the same effect in lme4.
> 
> > length(fitted(lmer(data = df, x ~ (1 | y), 
> na.action = na.exclude)))[1] 7
> 
> I am fairly certain that, in older versions of lme4, the length would
> be 8, with the last value being NA, just as it is with lm().
> 
> How can I get lmer to behave in the same way as lm --- padding the fitted
> vector with NAs (in the appropriate locations) so that it is the same
> length as the number of rows in the input data frame.

  Just for the record: as stated at

http://stackoverflow.com/questions/19668783/
  behavior-of-na-action-na-exclude-using-lmer-in-lme4-1-0-5-
    inconsistent-with-lm/19668855#19668855

(broken URL to make Gmane happy), you can just use predict(model)
rather than fitted(model).

  This is fixed in the Github development (1.1-1) version, may
get pulled into the patched (1.0-6) branch, but seems low priority
since the fix is so easy ...


  Ben Bolker


From yulya258 at yahoo.com  Thu Oct 31 12:44:57 2013
From: yulya258 at yahoo.com (Yla Savh)
Date: Thu, 31 Oct 2013 04:44:57 -0700 (PDT)
Subject: [R-sig-ME] How to compute a correlation between two time ranges?
Message-ID: <1383219897.32413.YahooMailNeo@web162706.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131031/0c95066b/attachment.pl>

From bbolker at gmail.com  Thu Oct 31 13:53:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 31 Oct 2013 12:53:55 +0000 (UTC)
Subject: [R-sig-ME] How to compute a correlation between two time ranges?
References: <1383219897.32413.YahooMailNeo@web162706.mail.bf1.yahoo.com>
Message-ID: <loom.20131031T135034-169@post.gmane.org>

Yla Savh <yulya258 at ...> writes:

> 
> 
> Dear forum members:
> ?
> I have two series of times to compare. Additionally, I have
> to allow for a buffer before and after the times so that they can
> be within 20
> seconds of each other and not seem discordant. 

  [snip]

 This is the wrong list for your question; you might try
r-help at r-project.org or Stack Overflow.  Furthermore, your
question isn't very precisely posed as a statistical
question -- you might take a look at cross-correlation analysis
(?ccf)

  good luck
    Ben Bolker


From tobias.heed at uni-hamburg.de  Thu Oct 31 18:08:36 2013
From: tobias.heed at uni-hamburg.de (Tobias Heed)
Date: Thu, 31 Oct 2013 18:08:36 +0100
Subject: [R-sig-ME] r-sig-models@r-project.org
Message-ID: <F9B03440-8024-499E-B8CC-6F170A657869@uni-hamburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131031/ef034886/attachment.pl>

From tobias.heed at uni-hamburg.de  Thu Oct 31 18:11:45 2013
From: tobias.heed at uni-hamburg.de (Tobias Heed)
Date: Thu, 31 Oct 2013 18:11:45 +0100
Subject: [R-sig-ME] wrong post
Message-ID: <4D7145FB-F7D9-49A9-B4A4-F931DFEC86A9@uni-hamburg.de>

Apologies for the accidental post in German from just a few seconds ago. Just delete.
Tobias


From haldre1 at gmail.com  Thu Oct 31 18:26:18 2013
From: haldre1 at gmail.com (Haldre Rogers)
Date: Thu, 31 Oct 2013 12:26:18 -0500
Subject: [R-sig-ME] contrasts and interactions with multi-level factors in
	glmer
Message-ID: <527292BA.5010301@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131031/9b111c0f/attachment.pl>

From Martin.Leclerc2 at USherbrooke.ca  Fri Nov  1 02:30:45 2013
From: Martin.Leclerc2 at USherbrooke.ca (Martin Leclerc)
Date: Thu, 31 Oct 2013 21:30:45 -0400
Subject: [R-sig-ME] ICC on random slopes in mixed logistic regression
Message-ID: <20131031213045.145917xvss5kkcis@www.usherbrooke.ca>

Hi everyone,

I wanted to know if someone knows how to calculate repeatability on a  
random slope of a mixed logistic regression with a nested intercept. I  
want to evaluate the repeatability of the variable X. The function  
glmer in the lme4 package doesn?t give me an estimate of the residual  
variance and I am not sure if ICC is calculated the same way in mixed  
linear and logistic regressions (and with nested intercept). Here is  
what the model looks like:

reg = glmer ( Y ~ X + (X | ID / IDyear), family = binomial)

Where Y = dichotomous dependent variable, ID = factor of 34 levels,  
IDyear = factor of 93 levels.

The output is the following:

Random effects:

  Groups            Name         Variance     Std.Dev.    Corr
  IDyear : ID      (Intercept)   0.0056611    0.075241
                    X            0.0898307    0.299718    0.670

  ID               (Intercept)   0.0331178    0.181983
                    X            0.0699248    0.264433    0.564

Number of obs: 76740, groups: bearyear:bearID, 93; bearID, 34

Even though I am not familiar with other package, I have also tried  
with the glmmPQL function. Here is the model (Is it normal that this  
function is really much faster to converge? From 25 min. to 4 min.):

reg2 = glmmPQL ( Y ~ X, random = ~ X | ID / IDyear), family= binomial )

Here is the output:

Random effects:

Formula: ~ X | ID
  Structure: General positive-definite, Log-Cholesky parametrization

                   StdDev      Corr
(Intercept)       0.3067025    (Intr)
X                 1.4141289    -0.943


Formula: ~ X | IDyear  %in%  ID
  Structure: General positive-definite, Log-Cholesky parametrization

                    StdDev         Corr
(Intercept)        0.2676970    (Intr)
X                  1.6009115    -0.965
Residual           0.9964824


Is there a way to calculate an ICC on each random slopes and intercept  
or the ICC needs to be calculated at each level of my nested intercept  
(i.e. one ICC for ID and one ICC for IDyear). The way I see it, is  
that my random ID variance (intercept + slope) is my intergroup  
variance and my IDyear variance (intercept + slope) is my intragroup  
variance. Therefore, I would just evaluate the repeatability as:

random variance of ID / random variance of ID + random variance of IDyear

Thanks a lot for your comments and your help,

Martin
-----------------------------------------------------
Martin Leclerc, biol. M.Sc.,
Candidat Ph.D.
Labo de d?mographie ?volutive et conservation

D?partement de biologie, Universit? de Sherbrooke
Sherbrooke, Qu?bec, Canada, J1K 2R1
Tel: 1-(819)-821-8000 #63020
Sans frais: 1-800-267-8337
Fax: (819)-821-8049


From jake987722 at hotmail.com  Fri Nov  1 02:54:48 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Thu, 31 Oct 2013 19:54:48 -0600
Subject: [R-sig-ME] ICC on random slopes in mixed logistic regression
In-Reply-To: <20131031213045.145917xvss5kkcis@www.usherbrooke.ca>
References: <20131031213045.145917xvss5kkcis@www.usherbrooke.ca>
Message-ID: <BAY172-W3790FB8C52FD7EB983C29BCBF50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131031/cd6c221d/attachment.pl>

From a.hayward at sheffield.ac.uk  Fri Nov  1 16:47:02 2013
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Fri, 1 Nov 2013 15:47:02 +0000
Subject: [R-sig-ME] Manipulating matrices from MCMCglmm
Message-ID: <CALQiR09QgmLp9xNHwtm82ZB+r-QESXZHG_enVnz_LHrioqgERg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131101/905b668c/attachment.pl>

From Maria_Paola.Bissiri at tu-dresden.de  Fri Nov  1 16:44:25 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Fri, 01 Nov 2013 15:44:25 +0000
Subject: [R-sig-ME] What does "number of groups < 50"
In-Reply-To: <20131029081916.GA30283@info124.pharmacie.univ-paris5.fr>
References: <32720_1382442140_r9MBgH5b022693_20131022114104.Horde.zR890vd4KYb2FKtjGvwWng8@mail.zih.tu-dresden.de>
	<52667CB6.7070809@mcmaster.ca>
	<20131024193452.Horde.sjRY6Ev5qc7wcGTy0LWP_Q1@mail.zih.tu-dresden.de>
	<52699699.8040509@gmail.com>
	<20131028184358.Horde.7A-9onh1HzqxorYMmGapBg1@mail.zih.tu-dresden.de>
	<20131029081916.GA30283@info124.pharmacie.univ-paris5.fr>
Message-ID: <20131101154425.Horde.YrTEyCGNBQ-vEX62Y2CmMQ2@mail.zih.tu-dresden.de>

Dear Dr. Curis,
thank you very much. I will run the bootstrap with a higher number of  
simulations.

Unfortunately there is another major problem now. When I try to  
generate the glmer model on Linux again, it does not converge anymore.
I get this error message, which I did not get before:
In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
   failure to converge in 10000 evaluations
The other two models, for which I need to run the bootstrap on Linux,  
too, do not converge on Linux either. All three models still converge  
on Windows.

This happened after our system administrator installed R on two more  
Linux machines upon my request, although I don't see any connection  
with this, the glmer model does not converge on any Linux machine. On  
all four Linux machines and on Windows the versions of R, lme4, Matrix  
and lattice have the same number.
I would be thankful for any suggestion to solve the problem.
I copy sessionInfo() information below.
Kind regards,
Maria Paola

Windows:

R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] phia_0.1-5      car_2.0-19      lme4_1.0-4      Matrix_1.0-14
[5] lattice_0.20-23 Hmisc_3.12-2    Formula_1.1-1   survival_2.37-4

loaded via a namespace (and not attached):
[1] cluster_1.14.4 grid_3.0.2     MASS_7.3-29    minqa_1.2.1    nlme_3.1-111
[6] nnet_7.3-7     rpart_4.1-3


Linux:

R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8
  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8
  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.0-4      Matrix_1.0-14   lattice_0.20-23

loaded via a namespace (and not attached):
  [1] afex_0.6-82       car_2.0-19        coin_1.0-23       grid_3.0.2
  [5] MASS_7.3-29       minqa_1.2.1       modeltools_0.2-21 mvtnorm_0.9-9996
  [9] nlme_3.1-111      nnet_7.3-7        pbkrtest_0.3-7    plyr_1.8
[13] reshape2_1.2.2    splines_3.0.2     stats4_3.0.2      stringr_0.6.2
[17] survival_2.37-4




Zitat von Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:

> Hello,
>
> I'm not a specialist of bootstrap, hence will not give advice about
> using normal approximation for bootstrap confidence interval; however,
> I guess your warnings come from the fact that trying to obtain the
> bilateral 99.9 % confidence interval using percentiles of a n = 1000
> sample (as done with your 1000 bootstrap "iterations") roughly means
> leave one value out (either min or max) and use all remaining values
> as the confidence interval. Hence, either min or max (depending on the
> one that was rejected) is used, leading to using the extreme values as
> quantiles...
>
> In other words, it simply suggests that 1000 iterations gives a too
> small sample to have a good approximation of the 99.9 % confidence
> interval, you should use more bootstrap replications. However, it
> should be ok for the 95 % one, unless may be you have a lot of ties.
>
> Hope this helps,
>
> Emmanuel Curis
>
> On Mon, Oct 28, 2013 at 06:43:58PM +0000, Maria Paola Bissiri wrote:
> ? My bootMer script completed the 1000 iterations calculating
> ? confidence intervals at the levels 0.95, 0.99 and 0.999 using the
> ? methods "norm", "basic" and "perc", but gave the following warnings
> ? for each fixed effect:
> ? Warning : Basic Intervals used Extreme Quantiles
> ? Some basic intervals may be unstable
> ? Warning : Percentile Intervals used Extreme Quantiles
> ? Some percentile intervals may be unstable
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
Dr. Maria Paola Bissiri

TU Dresden
Fakult?t Elektrotechnik und Informationstechnik
Institut f?r Akustik und Sprachkommunikation
01062 Dresden

Barkhausen-Bau, Raum S54
Helmholtzstra?e 18

Tel: +49 (0)351 463-34283
Fax: +49 (0)351 463-37781
E-Mail: Maria_Paola.Bissiri at tu-dresden.de
http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm


From j.hadfield at ed.ac.uk  Fri Nov  1 17:01:07 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 01 Nov 2013 16:01:07 +0000
Subject: [R-sig-ME] Manipulating matrices from MCMCglmm
In-Reply-To: <CALQiR09QgmLp9xNHwtm82ZB+r-QESXZHG_enVnz_LHrioqgERg@mail.gmail.com>
References: <CALQiR09QgmLp9xNHwtm82ZB+r-QESXZHG_enVnz_LHrioqgERg@mail.gmail.com>
Message-ID: <20131101160107.156176g5q9vxzhgk@www.staffmail.ed.ac.uk>

Hi Adam,

Try this:

beta<-function(x, dimension=4, response=1){
V<-matrix(x,dimension, dimension)
solve(V[-response,-response],V[-response,response])
}

post.beta<-apply(m1$VCV[,1:16] 1, beta)

# you have to change 1:16 to the appropriate indices.

This has also been done in:  Phillimore, A. B., S. St?lhandske, R. J.  
Smithers, and R. Bernard. 2012. Dissecting the contributions of  
plasticity and local adaptation to the phenology of a butterfly and  
its host plants. American Naturalist 180: 655-670

Cheers,

Jarrod

Quoting Adam Hayward <a.hayward at sheffield.ac.uk> on Fri, 1 Nov 2013  
15:47:02 +0000:

> Hi all,
>
> I'mm running a 4-trait model in MCMCglmm in order to estimate selection on
> three traits (the first trait being lifetime reproductive success). The
> model gives me 1000 estimates of each of the variance components. I'm
> primarily interested in the first 16 components, which make up the 4x4
> individual-level VCV matrix, but there are other variance components, some
> of which are not fitted to all traits. model$VCV spits this out as an
> object with dimensions of 1000xN, where N is the number of VCV components.
> Primarily, I would like to convert this into the thousand estimates of my
> 4x4 individual-level matrix, which I should then be able to use to
> calculate selection gradients accounting for correlated selection and have
> some measure of error around these estimates. For example, on a single
> estimate of a 4x4 VCV matrix:
>
> # matrix of VCV estimates
>> I<-as.matrix(cbind(
> + c(1, 1, 0.1, 0.5),
> + c(1, 1, 0.1, 0.1),
> + c(0.1, 0.1, 1, 0.1),
> + c(0.5, 0.1, 0.1, 1)))
>
> # get matrix, minus the trait we're estimating selection through, i.e. LRS
>> Ipred<-I[2:4,2:4]
>> Ipred
>      [,1] [,2] [,3]
> [1,]  1.0  0.1  0.1
> [2,]  0.1  1.0  0.1
> [3,]  0.1  0.1  1.0
>
> # get a vector of covariances between predictors and fitness
>> COV<-(I[1,])[2:4]
>
> # calculate selection gradients
>> Beta<-ginv(Ipred)%*%COV
>> Beta
>             [,1]
> [1,] -0.03703704
> [2,]  0.40740741
> [3,]  0.96296296
>
> An added complication is that two of these "traits" are random slopes, but
> that will probably have to wait. I think for now my question is a
> *relatively* straightforward one- how would I go about obtaining my 1000
> 4x4 matrices to plug into the above formulas in order to get selection
> coefficients with some measure of error? I'd be very grateful if anyone has
> any advice.
>
> Best wishes,
> Adam
>
>
>
> --
> Adam Hayward
> Post-Doctoral Research Associate
> Department of Animal and Plant Sciences
> Alfred Denny Building
> University of Sheffield
> Western Bank
> Sheffield S10 2TN
> UK
> http://www.huli.group.shef.ac.uk/adam-personal.html
> http://adhayward.wordpress.com/
> https://twitter.com/adhayward18
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From a.hayward at sheffield.ac.uk  Fri Nov  1 18:02:58 2013
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Fri, 1 Nov 2013 17:02:58 +0000
Subject: [R-sig-ME] Manipulating matrices from MCMCglmm
In-Reply-To: <20131101160107.156176g5q9vxzhgk@www.staffmail.ed.ac.uk>
References: <CALQiR09QgmLp9xNHwtm82ZB+r-QESXZHG_enVnz_LHrioqgERg@mail.gmail.com>
	<20131101160107.156176g5q9vxzhgk@www.staffmail.ed.ac.uk>
Message-ID: <CALQiR09-6FAwthdeDuL_+TJhzY2SWWdEjuoZo1ZBhMKvug0vpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131101/df963441/attachment.pl>

From kevinmgould at gmail.com  Tue Nov  5 02:39:40 2013
From: kevinmgould at gmail.com (Kevin Gould)
Date: Mon, 4 Nov 2013 18:39:40 -0700
Subject: [R-sig-ME] KRmodcomp issues
Message-ID: <CADm7UQFjrnpdZ4p+v=9XLtR8Y0w467L3Lutc38z+cueHAQ_pxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131104/8942a1cc/attachment.pl>

From henrik.singmann at psychologie.uni-freiburg.de  Tue Nov  5 16:18:51 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Tue, 05 Nov 2013 16:18:51 +0100
Subject: [R-sig-ME] KRmodcomp issues
In-Reply-To: <CADm7UQFjrnpdZ4p+v=9XLtR8Y0w467L3Lutc38z+cueHAQ_pxA@mail.gmail.com>
References: <CADm7UQFjrnpdZ4p+v=9XLtR8Y0w467L3Lutc38z+cueHAQ_pxA@mail.gmail.com>
Message-ID: <52790C5B.7020304@psychologie.uni-freiburg.de>

Hi Kevin,

Your problem will most likely disappear if you install the development version of pbkrtest (v 0.3-7) from here:
http://people.math.aau.dk/~sorenh/software/pbkrtest/devel/

If not, you have to contact the maintainer of pbkrtest as described on their website with a reproducibel example. See under section "Reporting unexpected behaviours (bugs)" here:
http://people.math.aau.dk/~sorenh/software/pbkrtest/

I hope this helps,
Henrik


Am 05.11.2013 02:39, schrieb Kevin Gould:
> Hi all!  This is my first time posting to the forum.  I am, admittedly, an
> R novice (and statistical almost-novice) with little experience with mixed
> models analysis.  However, I was referred here by someone who is an R whiz,
> if that counts for anything.  Today I was attempting to use KRmodcomp and
> got the following (rather confusing) output:
>
> F-test with Kenward-Roger approximation; computing time: 2.10 sec.
> large : Time ~ Grammar + Syllables + Order + (Grammar + Syllables + Order |
>      Subject)
> small : Time ~ Syllables + Order + (Grammar + Syllables + Order | Subject)
>           stat     ndf     ddf F.scaling p.value
> Ftest -25.141   1.000  39.975         1       1
>
> Any idea what could be causing this?  Here's the summary for ModelA, if
> that helps:
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: Time ~ Grammar + Syllables + Order + (Grammar + Syllables + Order
> |      Subject)
>     Data: data1
>
> REML criterion at convergence: 317.5946
>
> Random effects:
>   Groups   Name              Variance Std.Dev. Corr
>   Subject  (Intercept)       0.021865 0.14787
>            Grammarspeed_slow 0.004639 0.06811  -0.78
>            Syllables         0.000408 0.02020   0.10 -0.69
>            OrderB            0.061705 0.24841  -0.58  0.66 -0.30
>   Residual                   0.085452 0.29232
> Number of obs: 571, groups: Subject, 41
>
> Fixed effects:
>                     Estimate Std. Error t value
> (Intercept)        1.510485   0.122052  12.376
> Grammarspeed_slow -0.123387   0.027608  -4.469
> Syllables          0.033882   0.016742   2.024
> OrderB            -0.003791   0.064584  -0.059
>
> Correlation of Fixed Effects:
>              (Intr) Grmmr_ Syllbl
> Grmmrspd_sl  0.096
> Syllables   -0.923 -0.302
> OrderB      -0.209  0.152 -0.034
>
> The t-value of -4.47 seems promising, so any help you could give me would
> be greatly appreciated!
>
> Again, I'm a novice.  If there's any other information that you require
> from me here, please don't hesitate to ask!
>
> Thanks very much!
>
> -Kevin
>
> 	[[alternative HTML version deleted]]
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From fbromano at sabanciuniv.edu  Tue Nov  5 16:56:08 2013
From: fbromano at sabanciuniv.edu (Francesco)
Date: Tue, 05 Nov 2013 17:56:08 +0200
Subject: [R-sig-ME] Plotting residuals for GLMER model and zero counts
In-Reply-To: <527911A1.5070008@sabanciuniv.edu>
References: <527911A1.5070008@sabanciuniv.edu>
Message-ID: <52791518.106@sabanciuniv.edu>



Dear R-ers,

although a number of options exist out there to plot logit models, I
can't seem
to find one that works for glmer. What I would like to do is, in light of
having found no interaction between the two fixed effects (which answers my
research question), look at a plot to tell how well the model fits the data.

The package LMERconveniencefunctions ver 2.0
has a nice plot for lmer but this won't work on my model because R
automatically
asks me to use glmer. It has a factor DV (Correct), two fixed factor IVs
(Group and Syntax),
and two random effect (ID and item).

Here's the output of calling:

model<- glmer(Correct ~ Group * Syntax + (Syntax + 1 | ID) + (Group + 1
| item), data=...., family=binomial)

#Generalized linear mixed model fit by maximum likelihood ['glmerMod']
Family: binomial ( logit )
Formula: Correct ~ Group * Syntax + (Syntax + 1 | ID) + (Group + 1 | item)
Data: .....

AIC BIC logLik deviance
235.4060 276.5207 -107.7030 215.4060

Random effects:
Groups Name Variance Std.Dev. Corr
ID (Intercept) 44.919 6.702
Syntaxof 45.850 6.771 -0.99
item (Intercept) 6.282 2.506
Groupns 38.105 6.173 -0.63
Number of obs: 451, groups: ID, 38; item, 16

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -9.236 2.192 -4.214 2.51e-05
Groupns -2.815 4.743 -0.594 0.5528
Syntax of 5.546 2.458 2.256 0.0241
Groupns:Syntax of -1.457 6.405 -0.228 0.8200

(Intercept) ***
Groupns
Syntaxof *
Groupns:Syntaxof
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
(Intr) Gropns Syntxf
Groupns -0.499
Syntaxof -0.892 0.445
Grpns:Syntx 0.370 -0.741 -0.443

I have tried messing around with Mosaic but here I keep running into the
error
>Error: length(dim(observed)) == 2 is not TRUE

which I suspect is due to one cell in the 2x2x2 crosstab of results below being
lower than 2 (please correct me here if I'm mistaken):


Group Syntax Cor InC
nns	's 118 14
nns	of 128 19
ns	's 62 6
ns	of 53 1

I've tried using xtabs and formulae as the x argument for the mosaic function but neither seems to work.

On a side note, how do I cope with cases where participants produced 0 counts to a cell?
I understand Chi-square does not cope well with these. Should I leave them as is, or turn these
into NAs, or eliminate as outliers?

Thank you in advance for reading.

Francesco


From bbolker at gmail.com  Tue Nov  5 23:30:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Nov 2013 22:30:00 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?contrasts_and_interactions_with_multi-level_?=
	=?utf-8?q?factors_in=09glmer?=
References: <527292BA.5010301@gmail.com>
Message-ID: <loom.20131105T231455-883@post.gmane.org>

Haldre Rogers <haldre1 at ...> writes:

> 
> Hello-


Just a quick follow-up so that the list isn't *completely* silent
on the topic.  I think the main reason you're not getting any answers
is (1) your question is complex (speaking just for myself, I look
at it and think "oh, that's kind of hairy -- maybe I'll have a chance
to look at that tomorrow ...") (2) I'm pretty sure that your questions
are more general linear-model-parameterization questions than specifically
(G)LMM questions, so people not be jumping in on the list.
 
> I conducted a field experiment where I added seedlings near and far from 
> conspecific trees at multiple plots at multiple sites on multiple 
> islands and recorded survival, among other things. Here, I'm trying to 
> determine the overall effect of distance (near vs far) on the proportion 
> of seeds that survived in each plot (site is a random effect). I'd also 
> like to determine whether the effect of distance varies by canopy 
> openness. Finally, I would like to test whether the effect of distance 
> differs between islands. I'm confused about how to set up the right 
> contrasts given the interactions, and how to interpret the output. 
> Treatment contrasts use a reference level, which is fine for distance 
> where 'near' is a meaningful reference level, but for 'island', the 
> reference level is not meaningful (i.e. it doesn't make sense to compare 
> each island to one arbitrarily chosen island). A link to my data, and 
> output from an example are below. This is for one species, but I have 
> data for six species total, and ideally, I'd like to compare these 
> effects between species (see question 2 below). I have three specific 
> questions at the bottom.

The quick answer is that you can use sum-to-zero contrasts
(contr.sum) for island, if you want, which will make the main effect
of distance be the (unweighted) average effect across islands.

> 
> Here's a link to the data: 
> https://www.dropbox.com/s/fregbu154zw7whz/aglaifen.csv
> 
>  > aglaiafen<-read.csv("aglaifen.csv")
>  > aglaiafen$dist<-factor(aglaiafen$dist, levels=c("near", "far"))
>  >
>  > #response is cbind(number of seedlings that survived/number of 
> seedlings that died), family = binomial
>  > #Three predictors- island, distance, and canopy openness
>  > #island has 4 levels (A, B, C, D). Island A is reference level by 
> default, but is not really meaningful as reference level.
>  > #dist has 2 levels, near and far, with near set as reference level.
>  > #centavgopen is centered at the mean canopy openness.
>  > #site is a random effect (3-5 sites per island, 4 islands). There are 
> usually 4 near plots and 4 far plots per site.
>  >
>  > #Here are three approaches to analysis that give qualitatively 
> similar answers, but I'm not sure which (if any) is the best approach.
>  >

  Sorry, I don't have time to dig through all of this ...
> 
> *Questions: *
>  > # 1) Is one of these methods (or some other method) best for testing 
> the effect of distance on survival relative to canopy openness and 
> island? Can I conclude that, for this species, there is not a distance 
> effect for island A, B or D, there isn't an interaction between distance 
> and openness, but that there was lower seedling survival in far plots on 
> island C? Is that lower relative only to near plots on islandC? Why 
> don't the coefficients for the interactions change when contrasts are 
> changed?
> 
>  > # 2) I have similar data for five other species, and I'd like to 
> compare the magnitude of the distance effect between species. Would 
> adding a species to the model (by adding species*island*distance and 
> species*openness*distance) be advisable, or is it better to just analyze 
> each species separately to avoid the challenges with interpreting 
> three-way interactions, especially in glmer's where options for 
> hypothesis testing are more limited than lm's or glm's? Again, I don't 
> really want to know the effect of one species relative to a reference 
> species, but simply compare the magnitude of the distance effect between 
> species- how do I set up my model to do that? I can share the full 
> dataset offline if that would help.

   Well, the three-way interaction *is* the magnitude of the
difference among species.  You could use drop1() to test the overall
effect of the interaction (i.e., the overall magnitude of among-island
differences in the island*distance and openness*distance effects)

>  > # 3) Is the use of confint(model, method="Wald") acceptable for 
> testing this? I tried using bootMer a few different ways (e.g. 
> bootMer(survm1, nsim=1000), using a couple different functions), but all 
> bootstrap runs fail each time I've tried. Likelihood ratio tests can 
> tell me whether a factor should be included in a model, but not 
> differences between levels of factors (e.g. islands or species). In 
> addition, results from LRT's are similar to those obtained using 
> confint. Setting up the glht (multcomp package) for this, given all of 
> the interactions and the continuous openness variable seems a bit 
> overwhelming.

   If confint() results are similar to *summary()* results then
confint(model,method="Wald") is OK ...  results from LRTs and
those using confint(model,method="profile") (i.e. the default)
*should* be identical ...


From chawlaak at stt.msu.edu  Wed Nov  6 18:33:03 2013
From: chawlaak at stt.msu.edu (Akshita Chawla)
Date: Wed, 6 Nov 2013 17:33:03 +0000
Subject: [R-sig-ME] cox reid likelihood in R
In-Reply-To: <F9000793-FA15-4C51-9810-32BA05895682@stt.msu.edu>
References: <F9000793-FA15-4C51-9810-32BA05895682@stt.msu.edu>
Message-ID: <EF5EBB697547A6499E735E41D1606E301B27BEE4@STTEx1.sttwin.stt.msu.edu>



Dear all

I am trying to compute the Cox reid adjusted likelihood ratio test for mixed models in r. The adjustment needs the information matrix. Is there a package/function in R that runs the test or is there a way to extract the information matrix from an lme object?

Thanks
Akshita


From chawlaak at stt.msu.edu  Wed Nov  6 18:19:32 2013
From: chawlaak at stt.msu.edu (Akshita Chawla)
Date: Wed, 6 Nov 2013 17:19:32 +0000
Subject: [R-sig-ME] cox reid likelihood in R
Message-ID: <F9000793-FA15-4C51-9810-32BA05895682@stt.msu.edu>

Dear all

I am trying to compute the Cox reid adjusted likelihood ratio test for mixed models in r. The adjustment needs the information matrix. Is there a package/function in R that runs the test or is there a way to extract the information matrix from an lme object?

Thanks
Akshita

From bbolker at gmail.com  Wed Nov  6 19:35:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Nov 2013 18:35:28 +0000 (UTC)
Subject: [R-sig-ME] cox reid likelihood in R
References: <F9000793-FA15-4C51-9810-32BA05895682@stt.msu.edu>
	<EF5EBB697547A6499E735E41D1606E301B27BEE4@STTEx1.sttwin.stt.msu.edu>
Message-ID: <loom.20131106T192827-859@post.gmane.org>

Akshita Chawla <chawlaak at ...> writes:

> 
> 
> Dear all
> 
> I am trying to compute the Cox reid adjusted likelihood ratio
> test for mixed models in r. The adjustment
> needs the information matrix. Is there a package/function in R
> that runs the test or is there a way to
> extract the information matrix from an lme object?
> 
> Thanks
> Akshita
> 
> 


  Which information matrix?

  Within a merMod object, the "RX" component (getME(model,"RX"))
gives the (unscaled) Cholesky factor of the fixed-effects information
matrix (there's also an "RXi" component which has the inverse,
i.e. the Cholesky factor of the fixed-effects variance-covariance
matrix).  You can take the cross-product of this element to get
the information matrix, scaling by sigma^2 if necessary.  (See
https://github.com/lme4/lme4/issues/47 for some related discussion.)

  However, this is the information matrix *conditional on the
theta (random-effects) parameters*.  A full information matrix including
the uncertainty in the theta parameters is trickier ...

  Ben Bolker


From bbolker at gmail.com  Wed Nov  6 22:33:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Nov 2013 21:33:20 +0000 (UTC)
Subject: [R-sig-ME] Plotting residuals for GLMER model and zero counts
References: <527911A1.5070008@sabanciuniv.edu> <52791518.106@sabanciuniv.edu>
Message-ID: <loom.20131106T221303-818@post.gmane.org>

Francesco <fbromano at ...> writes:

> Dear R-ers,
> 
> although a number of options exist out there to plot logit models, I
> can't seem
> to find one that works for glmer. What I would like to do is, in light of
> having found no interaction between the two fixed effects (which answers my
> research question), look at a plot to tell how well the model fits the data.
> 
> The package LMERconveniencefunctions ver 2.0
> has a nice plot for lmer but this won't work on my model because R
> automatically
> asks me to use glmer. It has a factor DV (Correct), two fixed factor IVs
> (Group and Syntax),
> and two random effect (ID and item).
> 
> Here's the output of calling:
> 
> model<- glmer(Correct ~ Group * Syntax + (Syntax + 1 | ID) + (Group + 1
> | item), data=...., family=binomial)

I was going to ask you to please generate a (small) reproducible example
(e.g. see http://tinyurl.com/reproducible-000 ), but I couldn't resist
the urge to show off a new feature of the development branch of lme4,
which is that you can use simulate() with a regular (g)lmer formula
to simulate data corresponding to a given mixed model ...

library(lme4)
set.seed(101)
## generate factorial combinations
d <- expand.grid(Group=c("ns","nns"),Syntax=c("'s","of"),
      ID =factor(1:38),item=factor(1:16))
## subsample randomly down to actual data size
d <- d[sample(nrow(d),size=451),]
## check ...
with(d,table(interaction(Group,Syntax)))
## parameters (approximated from your output)
params <- list(fixef=c(-9,-2,5,-1.5),theta=c(7,-1,7,3,-0.5,6))
form <- Correct ~ Group * Syntax + (Syntax + 1 | ID) + (Group + 1| item)
s <- simulate(form[-2],  ## use one-sided formula
    newdata=d,
    newparams=params,
    family=binomial)
## turn response into a factor
d$Correct <- factor(s[[1]],labels=c("InC","Cor"))
fit1 <- glmer(Correct ~ Group * Syntax +
    (Syntax + 1 | ID) + (Group + 1| item),
    data=d,
    family=binomial)
dAug <- data.frame(d,res=residuals(fit1,"pearson"))
library(lattice)
plot(fit1)  ## the default plot is not too useful
## or
bwplot(res~Group:Syntax,data=dAug)
plot(fit1,Group:Syntax~resid(.))
## how bad does the fit get if we leave out the interaction?
fit2 <- update(fit1,.~.-Group:Syntax)
plot(fit2,Group:Syntax~resid(.))
anova(fit1,fit2)
## you can also separate by item etc. pretty easily ...
plot(fit2,Group:Syntax~resid(.)|item)

> On a side note, how do I cope with cases where participants produced
> 0 counts to a cell?  I understand Chi-square does not cope well with
> these. Should I leave them as is, or turn these into NAs, or
> eliminate as outliers?

  Leave them alone.  You may be misunderstanding the framework of
GLMMs, which does *not* require a balanced design (although some
'structural' kinds of missingness, such as missing combinations
of interactions of *fixed* factors, will cause trouble) -- and
it's not based on a decomposition of a Pearson chi-squared table,
if that's what you're thinking ...


From john.hodsoll at kcl.ac.uk  Thu Nov  7 16:26:06 2013
From: john.hodsoll at kcl.ac.uk (Hodsoll, John)
Date: Thu, 7 Nov 2013 15:26:06 +0000
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
Message-ID: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131107/72d66ea5/attachment.pl>

From johannesradinger at gmail.com  Thu Nov  7 17:31:41 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Thu, 7 Nov 2013 17:31:41 +0100
Subject: [R-sig-ME] getME function crashes
Message-ID: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131107/6cc818d2/attachment.pl>

From renaud.lancelot at cirad.fr  Thu Nov  7 17:43:42 2013
From: renaud.lancelot at cirad.fr (lancelot)
Date: Thu, 07 Nov 2013 17:43:42 +0100
Subject: [R-sig-ME] getME function crashes
In-Reply-To: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
References: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
Message-ID: <527BC33E.5040901@cirad.fr>

everything's fine for me with the development version of lme4 (github)

 > library(arm)
Le chargement a n?cessit? le package : MASS
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : lme4
Le chargement a n?cessit? le package : lattice

arm (Version 1.6-09, built: 2013-9-23)

Working directory is D:/Analyses

 > library(lme4)
 > set.seed (1)
 > J <- 15
 > n <- J*(J+1)/2
 > group <- rep (1:J, 1:J)
 > mu.a <- 5
 > sigma.a <- 2
 > a <- rnorm (J, mu.a, sigma.a)
 > b <- -3
 > x <- rnorm (n, 2, 1)
 > y <- rbinom (n, 1, invlogit (a[group] + b*x))
 > mod <- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
 > getME(mod, "L")
'MatrixFactorization' of Formal class 'dCHMsimpl' [package "Matrix"] 
with 10 slots
   ..@ x       : num [1:15] 1.22 1.22 1.1 1.44 1.74 ...
   ..@ p       : int [1:16] 0 1 2 3 4 5 6 7 8 9 ...
   ..@ i       : int [1:15] 0 1 2 3 4 5 6 7 8 9 ...
   ..@ nz      : int [1:15] 1 1 1 1 1 1 1 1 1 1 ...
   ..@ nxt     : int [1:17] 1 2 3 4 5 6 7 8 9 10 ...
   ..@ prv     : int [1:17] 16 0 1 2 3 4 5 6 7 8 ...
   ..@ colcount: int [1:15] 1 1 1 1 1 1 1 1 1 1 ...
   ..@ perm    : int [1:15] 0 1 2 3 4 5 6 7 8 9 ...
   ..@ type    : int [1:4] 2 1 0 1
   ..@ Dim     : int [1:2] 15 15
 > sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] arm_1.6-09      lme4_1.1-1      lattice_0.20-25 Matrix_1.1-0 
MASS_7.3-29

loaded via a namespace (and not attached):
[1] abind_1.4-1    coda_0.16-1    fortunes_1.5-1 grid_3.0.2 
minqa_1.2.1    nlme_3.1-111
[7] splines_3.0.2  tools_3.0.2


Idem with the 64-bit version of R

Renaud




Le 07/11/2013 17:31, Johannes Radinger a ?crit :
> Hi,
>
> Actually I tried to use the sim function from the package "arm" to get
> posterior simulations of beta from a merMod.
> But somehow this function crashed and I could trace the problem back to the
> function getME(model,"L") which is
> the cause for the crash.
> For example here an example dataset for a binomial model (glmer) from the
> sim function in the 'arm'-package:
>
> set.seed (1)
> J<- 15
> n<- J*(J+1)/2
> group<- rep (1:J, 1:J)
> mu.a<- 5
> sigma.a<- 2
> a<- rnorm (J, mu.a, sigma.a)
> b<- -3
> x<- rnorm (n, 2, 1)
> y<- rbinom (n, 1, invlogit (a[group] + b*x))
>
> mod<- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
>
> When I now run getME(mod, "L") my R session completely crashes with
> following error:
> *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Traceback:
>   1: .Call(merPredDL, ptr())
>   2: PR$L()
>   3: getME(mod, "L")
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
> I am running following setup:
>
> R version 3.0.2 (2013-09-25)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] arm_1.6-09      lme4_1.0-5      lattice_0.20-24 Matrix_1.1-0
> MASS_7.3-29
>
> loaded via a namespace (and not attached):
> [1] abind_1.4-0   coda_0.16-1   grid_3.0.2    minqa_1.2.1   nlme_3.1-111
> splines_3.0.2 tools_3.0.2
>
> Can anyone reproduce this problem?
>
> /Johannes
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
Renaud Lancelot
Directeur adjoint / Deputy director
http://umr-cmaee.cirad.fr/
http://formation-elevage-suds.cirad.fr/
CIRAD, UMR CMAEE, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Head of epidemiology team
EDENext Project, coordinator: http://www.edenext.eu/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 98
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From steve.walker at utoronto.ca  Thu Nov  7 17:46:59 2013
From: steve.walker at utoronto.ca (Steve Walker)
Date: Thu, 07 Nov 2013 11:46:59 -0500
Subject: [R-sig-ME] getME function crashes
In-Reply-To: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
References: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
Message-ID: <527BC403.3080906@utoronto.ca>

I couldn't reproduce, but that is not entirely surprising with memory 
bugs. Apart from changing invlogit to plogis, I successfully ran your 
example with the following session info.  The difference could be that I 
was using a development version of lme4, but I doubt that would make a 
difference...checking...no, the cran version works for me too.

Steve

 > sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-1   Matrix_1.1-0

loaded via a namespace (and not attached):
[1] MASS_7.3-29     grid_3.0.2      lattice_0.20-23 minqa_1.2.1
[5] nlme_3.1-111    splines_3.0.2
 >

On 11/7/2013, 11:31 AM, Johannes Radinger wrote:
> Hi,
>
> Actually I tried to use the sim function from the package "arm" to get
> posterior simulations of beta from a merMod.
> But somehow this function crashed and I could trace the problem back to the
> function getME(model,"L") which is
> the cause for the crash.
> For example here an example dataset for a binomial model (glmer) from the
> sim function in the 'arm'-package:
>
> set.seed (1)
> J <- 15
> n <- J*(J+1)/2
> group <- rep (1:J, 1:J)
> mu.a <- 5
> sigma.a <- 2
> a <- rnorm (J, mu.a, sigma.a)
> b <- -3
> x <- rnorm (n, 2, 1)
> y <- rbinom (n, 1, invlogit (a[group] + b*x))
>
> mod <- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
>
> When I now run getME(mod, "L") my R session completely crashes with
> following error:
> *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Traceback:
>   1: .Call(merPredDL, ptr())
>   2: PR$L()
>   3: getME(mod, "L")
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
> I am running following setup:
>
> R version 3.0.2 (2013-09-25)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] arm_1.6-09      lme4_1.0-5      lattice_0.20-24 Matrix_1.1-0
> MASS_7.3-29
>
> loaded via a namespace (and not attached):
> [1] abind_1.4-0   coda_0.16-1   grid_3.0.2    minqa_1.2.1   nlme_3.1-111
> splines_3.0.2 tools_3.0.2
>
> Can anyone reproduce this problem?
>
> /Johannes
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From Hugo.Mildenberger at web.de  Thu Nov  7 18:26:20 2013
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Thu, 7 Nov 2013 18:26:20 +0100
Subject: [R-sig-ME] getME function crashes
In-Reply-To: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
References: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
Message-ID: <20131107182620.6e7c0ee606a85017f016c999@zotac.lan>

Johannes,

on Linux-64, with the same version of R and the same version of 
all loaded packages, your example code runs fine. Apart from 
Windows-32, the only difference I've spotted is  that a module 
named "tools_3.0.2" does not appear in my sessionInfo(), but 
that might be platform dependant.

Hugo




On Thu, 7 Nov 2013 17:31:41 +0100
Johannes Radinger <johannesradinger at gmail.com> wrote:

> Hi,
> 
> Actually I tried to use the sim function from the package "arm" to get
> posterior simulations of beta from a merMod.
> But somehow this function crashed and I could trace the problem back to the
> function getME(model,"L") which is
> the cause for the crash.
> For example here an example dataset for a binomial model (glmer) from the
> sim function in the 'arm'-package:
> 
> set.seed (1)
> J <- 15
> n <- J*(J+1)/2
> group <- rep (1:J, 1:J)
> mu.a <- 5
> sigma.a <- 2
> a <- rnorm (J, mu.a, sigma.a)
> b <- -3
> x <- rnorm (n, 2, 1)
> y <- rbinom (n, 1, invlogit (a[group] + b*x))
> 
> mod <- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
> 
> When I now run getME(mod, "L") my R session completely crashes with
> following error:
> *** caught segfault ***
> address (nil), cause 'memory not mapped'
> 
> Traceback:
>  1: .Call(merPredDL, ptr())
>  2: PR$L()
>  3: getME(mod, "L")
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> 
> I am running following setup:
> 
> R version 3.0.2 (2013-09-25)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] arm_1.6-09      lme4_1.0-5      lattice_0.20-24 Matrix_1.1-0
> MASS_7.3-29
> 
> loaded via a namespace (and not attached):
> [1] abind_1.4-0   coda_0.16-1   grid_3.0.2    minqa_1.2.1   nlme_3.1-111
> splines_3.0.2 tools_3.0.2
> 
> Can anyone reproduce this problem?
> 
> /Johannes
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--


From bbolker at gmail.com  Thu Nov  7 18:32:40 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 07 Nov 2013 12:32:40 -0500
Subject: [R-sig-ME] getME function crashes
In-Reply-To: <527BC33E.5040901@cirad.fr>
References: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
	<527BC33E.5040901@cirad.fr>
Message-ID: <527BCEB8.90104@gmail.com>

  This are the exact symptoms of having a mismatch between your Matrix,
RcppEigen, and lme4 versions ... try reinstalling them in that order.

  Ben Bolker

On 13-11-07 11:43 AM, lancelot wrote:
> everything's fine for me with the development version of lme4 (github)
> 
>> library(arm)
> Le chargement a n?cessit? le package : MASS
> Le chargement a n?cessit? le package : Matrix
> Le chargement a n?cessit? le package : lme4
> Le chargement a n?cessit? le package : lattice
> 
> arm (Version 1.6-09, built: 2013-9-23)
> 
> Working directory is D:/Analyses
> 
>> library(lme4)
>> set.seed (1)
>> J <- 15
>> n <- J*(J+1)/2
>> group <- rep (1:J, 1:J)
>> mu.a <- 5
>> sigma.a <- 2
>> a <- rnorm (J, mu.a, sigma.a)
>> b <- -3
>> x <- rnorm (n, 2, 1)
>> y <- rbinom (n, 1, invlogit (a[group] + b*x))
>> mod <- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
>> getME(mod, "L")
> 'MatrixFactorization' of Formal class 'dCHMsimpl' [package "Matrix"]
> with 10 slots
>   ..@ x       : num [1:15] 1.22 1.22 1.1 1.44 1.74 ...
>   ..@ p       : int [1:16] 0 1 2 3 4 5 6 7 8 9 ...
>   ..@ i       : int [1:15] 0 1 2 3 4 5 6 7 8 9 ...
>   ..@ nz      : int [1:15] 1 1 1 1 1 1 1 1 1 1 ...
>   ..@ nxt     : int [1:17] 1 2 3 4 5 6 7 8 9 10 ...
>   ..@ prv     : int [1:17] 16 0 1 2 3 4 5 6 7 8 ...
>   ..@ colcount: int [1:15] 1 1 1 1 1 1 1 1 1 1 ...
>   ..@ perm    : int [1:15] 0 1 2 3 4 5 6 7 8 9 ...
>   ..@ type    : int [1:4] 2 1 0 1
>   ..@ Dim     : int [1:2] 15 15
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> [3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
> [5] LC_TIME=French_France.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] arm_1.6-09      lme4_1.1-1      lattice_0.20-25 Matrix_1.1-0
> MASS_7.3-29
> 
> loaded via a namespace (and not attached):
> [1] abind_1.4-1    coda_0.16-1    fortunes_1.5-1 grid_3.0.2
> minqa_1.2.1    nlme_3.1-111
> [7] splines_3.0.2  tools_3.0.2
> 
> 
> Idem with the 64-bit version of R
> 
> Renaud
> 
> 
> 
> 
> Le 07/11/2013 17:31, Johannes Radinger a ?crit :
>> Hi,
>>
>> Actually I tried to use the sim function from the package "arm" to get
>> posterior simulations of beta from a merMod.
>> But somehow this function crashed and I could trace the problem back
>> to the
>> function getME(model,"L") which is
>> the cause for the crash.
>> For example here an example dataset for a binomial model (glmer) from the
>> sim function in the 'arm'-package:
>>
>> set.seed (1)
>> J<- 15
>> n<- J*(J+1)/2
>> group<- rep (1:J, 1:J)
>> mu.a<- 5
>> sigma.a<- 2
>> a<- rnorm (J, mu.a, sigma.a)
>> b<- -3
>> x<- rnorm (n, 2, 1)
>> y<- rbinom (n, 1, invlogit (a[group] + b*x))
>>
>> mod<- glmer (y ~ x + (1 | group), family=binomial(link="logit"))
>>
>> When I now run getME(mod, "L") my R session completely crashes with
>> following error:
>> *** caught segfault ***
>> address (nil), cause 'memory not mapped'
>>
>> Traceback:
>>   1: .Call(merPredDL, ptr())
>>   2: PR$L()
>>   3: getME(mod, "L")
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>>
>> I am running following setup:
>>
>> R version 3.0.2 (2013-09-25)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] arm_1.6-09      lme4_1.0-5      lattice_0.20-24 Matrix_1.1-0
>> MASS_7.3-29
>>
>> loaded via a namespace (and not attached):
>> [1] abind_1.4-0   coda_0.16-1   grid_3.0.2    minqa_1.2.1   nlme_3.1-111
>> splines_3.0.2 tools_3.0.2
>>
>> Can anyone reproduce this problem?
>>
>> /Johannes
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>


From j.hadfield at ed.ac.uk  Thu Nov  7 21:01:25 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 07 Nov 2013 20:01:25 +0000
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
In-Reply-To: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
References: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
Message-ID: <20131107200125.1675524aymyntf8c@www.staffmail.ed.ac.uk>

Hi John,

Your interpretation of the model is correct. However, I'm not sure  
about the random terms  - just to be sure, there are multiple  
observations per wardn?  With a typical zero-altered model the random  
term would be trait:wardn which assumes the between ward variance is  
the same for both processes and the correlation between them is 1.  
Your model (which is equivalent to idh(trait):units) assumes a  
correlation of 0 and different variances. Reality probably lies  
somewhere between these two extremes. You might want to see if the  
fixed effect coefficients are sensitive to this, and perhaps even  
estimate all relevant parameters (us(trait):wardn) if you have a lot  
of data. Perhaps try that and report back?

Cheers,

Jarrod



Quoting "Hodsoll, John" <john.hodsoll at kcl.ac.uk> on Thu, 7 Nov 2013  
15:26:06 +0000:

> Dear all
>
>
>
> I am wondering if anyone can help me in interpreting a zero added  
> model using MCMCglmm. I am analysing a clinical trial for counts of  
> incidents on a psychiatric ward (per work shift).  The data has a  
> surfeit of zeros and so I am using zero inflated models. The problem  
> I have is trying to understand what zero added models is telling me  
> about the zero inflation. I've looked through the excellent course  
> notes from Jarrod Hadfield but am a bit unsure as to the take home  
> message as this is the first time I've attempted to use these models.
>
>
>
> Model background: Outcome data is collected at the ward level (i.e.  
> not individual patient) and so a hurdle model seemed the most  
> appropriate, i.e. each ward has the potential to generate an  
> incident on any given shift. I have used the zero altered models to  
> test for inflation as on p109 of the course notes. In this  
> (simplified analysis with just a quick test run) I have included all  
> factors as predictors for both parts of the model;  trial phase:  
> period.x (baseline vs outcome) and experimental condition expconr  
> (control vs test). Here is my model specification
>
>  cf.za.1 <- MCMCglmm(totflct ~ -1 + trait*(expcon.r*period.x),
>
>                       data = sw.df, family = "zapoisson",
>
>                       random = ~idh(at.level(trait,2)):wardn +  
> idh(at.level(trait,1)):wardn,
>
>                      rcov = ~ trait:units,
>
>                       #prior = zza.prior,
>
>                       #nitt = 250000, burnin = 50000, thin = 500,
>
>                       verbose = TRUE, pr = TRUE, pl = FALSE, saveXL = TRUE)
>
>
>
> The outcome I'm interested in is the change between control and  
> treatment from baseline to outcome, highlighted as the interaction  
> term in the model below. For shifts with events there is a reduction  
> in the rate of events for the intervention versus control shown by  
> the negative coefficient for the expcon.r  x period.x. However, for  
> the zero inflation test this co-efficient is positive. Just to  
> confirm, does this mean I have zero deflation for the test condition  
> in the outcome phase relative to the control condition, i.e. more  
> shifts with incidents.
>
>
>
> post.mean l-95% CI u-95% CI eff.samp
>
> trait:units    0.4641   0.4317   0.4947    116.3
>
>
>
> Location effects: totflct ~ -1 + trait * (expcon.r * period.x)
>
>
>
>                                               post.mean  l-95% CI   
> u-95% CI eff.samp  pMCMC
>
> traittotflct                                  1.395460  1.195803   
> 1.602353   1000.0 <0.001 ***
>
> traitza_totflct                               1.012971  0.742179   
> 1.318166    468.3 <0.001 ***
>
> expcon.rtest                                  0.052641 -0.210311   
> 0.327396    894.5  0.690
>
> period.xoutcome                              -0.170481 -0.251931  
> -0.103334    567.0 <0.001 ***
>
> expcon.rtest:period.xoutcome                 -0.157615 -0.269555  
> -0.051604    513.6  0.004 **
>
> traitza_totflct:expcon.rtest                 -0.316590 -0.762917   
> 0.150063    748.1  0.174
>
> traitza_totflct:period.xoutcome              -0.189739 -0.345773  
> -0.059751    162.4  0.008 **
>
> traitza_totflct:expcon.rtest:period.xoutcome  0.237426  0.001023   
> 0.450208    166.0  0.034 *
>
>
>
> I find this a bit odd, but then you would expect more zeros for a  
> condition with a lower mean count in 1 condition relative to the  
> other so that would reduce zero inflation? If anyone has any insight  
> it would be much appreciated.
>
>
>
> Thanks
>
> John
>
>
>
> ====================================
>
>
>
> John Hodsoll
>
> Institute of Psychiatry
>
> Kings College London
>
> London
>
> SE5 8AF
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Nov  8 10:17:50 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 08 Nov 2013 09:17:50 +0000
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
In-Reply-To: <20131107200125.1675524aymyntf8c@www.staffmail.ed.ac.uk>
References: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
	<20131107200125.1675524aymyntf8c@www.staffmail.ed.ac.uk>
Message-ID: <20131108091750.20107d377hq0rl8o@www.staffmail.ed.ac.uk>

Hi John,

Sorry, I made a mistake. ~wardn assumes equal variances and a  
correlation of 1. ~trait:wardn assumes equal variances and a  
correlation of 0.

Cheers,

Jarrod


Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Thu, 07 Nov 2013  
20:01:25 +0000:

> Hi John,
>
> Your interpretation of the model is correct. However, I'm not sure  
> about the random terms  - just to be sure, there are multiple  
> observations per wardn?  With a typical zero-altered model the  
> random term would be trait:wardn which assumes the between ward  
> variance is the same for both processes and the correlation between  
> them is 1. Your model (which is equivalent to idh(trait):units)  
> assumes a correlation of 0 and different variances. Reality probably  
> lies somewhere between these two extremes. You might want to see if  
> the fixed effect coefficients are sensitive to this, and perhaps  
> even estimate all relevant parameters (us(trait):wardn) if you have  
> a lot of data. Perhaps try that and report back?
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting "Hodsoll, John" <john.hodsoll at kcl.ac.uk> on Thu, 7 Nov 2013  
> 15:26:06 +0000:
>
>> Dear all
>>
>>
>>
>> I am wondering if anyone can help me in interpreting a zero added  
>> model using MCMCglmm. I am analysing a clinical trial for counts of  
>> incidents on a psychiatric ward (per work shift).  The data has a  
>> surfeit of zeros and so I am using zero inflated models. The  
>> problem I have is trying to understand what zero added models is  
>> telling me about the zero inflation. I've looked through the  
>> excellent course notes from Jarrod Hadfield but am a bit unsure as  
>> to the take home message as this is the first time I've attempted  
>> to use these models.
>>
>>
>>
>> Model background: Outcome data is collected at the ward level (i.e.  
>> not individual patient) and so a hurdle model seemed the most  
>> appropriate, i.e. each ward has the potential to generate an  
>> incident on any given shift. I have used the zero altered models to  
>> test for inflation as on p109 of the course notes. In this  
>> (simplified analysis with just a quick test run) I have included  
>> all factors as predictors for both parts of the model;  trial  
>> phase: period.x (baseline vs outcome) and experimental condition  
>> expconr (control vs test). Here is my model specification
>>
>> cf.za.1 <- MCMCglmm(totflct ~ -1 + trait*(expcon.r*period.x),
>>
>>                      data = sw.df, family = "zapoisson",
>>
>>                      random = ~idh(at.level(trait,2)):wardn +  
>> idh(at.level(trait,1)):wardn,
>>
>>                     rcov = ~ trait:units,
>>
>>                      #prior = zza.prior,
>>
>>                      #nitt = 250000, burnin = 50000, thin = 500,
>>
>>                      verbose = TRUE, pr = TRUE, pl = FALSE, saveXL = TRUE)
>>
>>
>>
>> The outcome I'm interested in is the change between control and  
>> treatment from baseline to outcome, highlighted as the interaction  
>> term in the model below. For shifts with events there is a  
>> reduction in the rate of events for the intervention versus control  
>> shown by the negative coefficient for the expcon.r  x period.x.  
>> However, for the zero inflation test this co-efficient is positive.  
>> Just to confirm, does this mean I have zero deflation for the test  
>> condition in the outcome phase relative to the control condition,  
>> i.e. more shifts with incidents.
>>
>>
>>
>> post.mean l-95% CI u-95% CI eff.samp
>>
>> trait:units    0.4641   0.4317   0.4947    116.3
>>
>>
>>
>> Location effects: totflct ~ -1 + trait * (expcon.r * period.x)
>>
>>
>>
>>                                              post.mean  l-95% CI   
>> u-95% CI eff.samp  pMCMC
>>
>> traittotflct                                  1.395460  1.195803   
>> 1.602353   1000.0 <0.001 ***
>>
>> traitza_totflct                               1.012971  0.742179   
>> 1.318166    468.3 <0.001 ***
>>
>> expcon.rtest                                  0.052641 -0.210311   
>> 0.327396    894.5  0.690
>>
>> period.xoutcome                              -0.170481 -0.251931  
>> -0.103334    567.0 <0.001 ***
>>
>> expcon.rtest:period.xoutcome                 -0.157615 -0.269555  
>> -0.051604    513.6  0.004 **
>>
>> traitza_totflct:expcon.rtest                 -0.316590 -0.762917   
>> 0.150063    748.1  0.174
>>
>> traitza_totflct:period.xoutcome              -0.189739 -0.345773  
>> -0.059751    162.4  0.008 **
>>
>> traitza_totflct:expcon.rtest:period.xoutcome  0.237426  0.001023   
>> 0.450208    166.0  0.034 *
>>
>>
>>
>> I find this a bit odd, but then you would expect more zeros for a  
>> condition with a lower mean count in 1 condition relative to the  
>> other so that would reduce zero inflation? If anyone has any  
>> insight it would be much appreciated.
>>
>>
>>
>> Thanks
>>
>> John
>>
>>
>>
>> ====================================
>>
>>
>>
>> John Hodsoll
>>
>> Institute of Psychiatry
>>
>> Kings College London
>>
>> London
>>
>> SE5 8AF
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From johannesradinger at gmail.com  Fri Nov  8 11:08:00 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Fri, 8 Nov 2013 11:08:00 +0100
Subject: [R-sig-ME] getME function crashes
In-Reply-To: <527BCEB8.90104@gmail.com>
References: <CABsGe_xhyL8=7F6rQqmDuiuB-ZiES7h3UXgfPqwoMCfdta=Hrw@mail.gmail.com>
	<527BC33E.5040901@cirad.fr> <527BCEB8.90104@gmail.com>
Message-ID: <CABsGe_yH_PGAobxy1Ud8W6-cKrnCv_6N_CJxH-2+eNWWcYLQmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131108/8316a83d/attachment.pl>

From datkins at u.washington.edu  Fri Nov  8 15:57:37 2013
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 08 Nov 2013 06:57:37 -0800
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
In-Reply-To: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
References: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
Message-ID: <527CFBE1.3080703@u.washington.edu>


John--

In addition to Jarrod's specific suggestions, you might give a look at 
an article we wrote describing GLMM for count data (including 
zero-inflated / hurdle models), which also has accompanying R code, 
focused in large part on MCMCglmm:

Atkins, D. C., Baldwin, S., Zheng, C., Gallop, R. J., & Neighbors, C. 
(2013). A tutorial on count regression and zero-altered count models for 
longitudinal substance use data.  Psychology of Addictive Behaviors, 27, 
166-177. doi: 10.1037/a0029508 PMCID: PMC3513584.

MS, data, code can be found from link at:

http://depts.washington.edu/cshrb/statistical-resources-tutorial-link/

Hope that helps and best wishes with your analyses.

cheers, Dave

-- 
Dave Atkins, PhD

Research Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu
http://depts.washington.edu/cshrb/david-atkins/#more-48

"The combination of some data and an aching desire for an answer does 
not ensure that a reasonable answer can be extracted from a given body 
of data." -- John Tukey


From jake987722 at hotmail.com  Fri Nov  8 19:15:16 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 8 Nov 2013 11:15:16 -0700
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>,
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
Message-ID: <BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131108/5da8c127/attachment.pl>

From reinhold.kliegl at gmail.com  Fri Nov  8 19:49:50 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 8 Nov 2013 19:49:50 +0100
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>
Message-ID: <CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131108/602a439d/attachment.pl>

From jake987722 at hotmail.com  Fri Nov  8 21:42:02 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 8 Nov 2013 13:42:02 -0700
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
 terms
In-Reply-To: <CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>,
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>,
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>,
	<CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
Message-ID: <BAY172-W140EECBA4876C490FD9F03CBF20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131108/7e3a1e00/attachment.pl>

From pdalgd at gmail.com  Sat Nov  9 10:37:14 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 9 Nov 2013 10:37:14 +0100
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>
	<CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
Message-ID: <543FFDC4-1C84-4135-B3DA-C165D135360B@gmail.com>


On 08 Nov 2013, at 19:49 , Reinhold Kliegl <reinhold.kliegl at gmail.com> wrote:

> If I understand your question correctly, I think there is one exception.
> Whenever you are dealing with balanced 2 x 2 x 2 x ... design all main
> effects and interactions have equal statistical power.

Say what? A main effect in that case is a difference between two averages. A (1st order) interaction effect is a difference between two differences of means, each based on half as many observations. So the standard error in the latter case is twice that of the former. Of course, you can scale the interaction so that the s.e. is the same as that of the main effects, but it is then not clear that similarly sized effects are equal in importance. At the very least, you need to be very specific about what you mean by "equal power".



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From reinhold.kliegl at gmail.com  Sat Nov  9 11:05:49 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 9 Nov 2013 11:05:49 +0100
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <543FFDC4-1C84-4135-B3DA-C165D135360B@gmail.com>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>
	<CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
	<543FFDC4-1C84-4135-B3DA-C165D135360B@gmail.com>
Message-ID: <CAG+WrEzScV9CoZRNUpSoDzTneW19-PP65F-ABaZOE9fO1dgH8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131109/23909e80/attachment.pl>

From reinhold.kliegl at gmail.com  Sat Nov  9 17:18:41 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 9 Nov 2013 17:18:41 +0100
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
	terms
In-Reply-To: <BAY172-W140EECBA4876C490FD9F03CBF20@phx.gbl>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>
	<CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>
	<BAY172-W140EECBA4876C490FD9F03CBF20@phx.gbl>
Message-ID: <CAG+WrExMXk6CvrzzMTROriJqaRxuTfeaOfb=ts+QSJCFxP4shg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131109/00993720/attachment.pl>

From jake987722 at hotmail.com  Sat Nov  9 20:40:43 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sat, 9 Nov 2013 12:40:43 -0700
Subject: [R-sig-ME] Variances of higher-order vs. lower-order random
 terms
In-Reply-To: <CAG+WrExMXk6CvrzzMTROriJqaRxuTfeaOfb=ts+QSJCFxP4shg@mail.gmail.com>
References: <BAY172-W32B0A07F07F281A1B801F4CB1B0@phx.gbl>,
	<BAY172-W36B4CC67CE61BA9E596F3ACB1B0@phx.gbl>,
	<BAY172-W370F52BD2A8C89052A2380CBF20@phx.gbl>,
	<CAG+WrEy9AMgHNFX2hQ4CDX1SLdOySDs4WH-Z548_mjc1Q5dEcg@mail.gmail.com>,
	<BAY172-W140EECBA4876C490FD9F03CBF20@phx.gbl>,
	<CAG+WrExMXk6CvrzzMTROriJqaRxuTfeaOfb=ts+QSJCFxP4shg@mail.gmail.com>
Message-ID: <BAY172-W4381FD9B397595AC5FBB1CBFD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131109/ed59dd69/attachment.pl>

From v_coudrain at voila.fr  Mon Nov 11 13:45:23 2013
From: v_coudrain at voila.fr (V. Coudrain)
Date: Mon, 11 Nov 2013 13:45:23 +0100 (CET)
Subject: [R-sig-ME] Doubt about including random effects or not
Message-ID: <724230362.39761384173923481.JavaMail.www@wwinf7125>

Dear all,

I collected insects in 30 sites, 15 sites each with a level of isolation and all 30 sites are arranged along a gradient of habitat amount. Each insect species has a 
specialization value. I would like to test if specialization increases along the gradient of habitat and differs between isolation level. The number of insect species and 
individuals differ largely between sites. I have two doubts: should I specify site as a random variable? Should I specify insect abundance as an offset?

The model I thought about: lme(specialization~Isolation*habitat amount + offset(insect abundance) , random~1|Site)

However I am not sure about using site as a random effect and specifically if it makes sense to mix offset and random effect.

Thank you!

Val?rie Coudrain
___________________________________________________________
Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html


From s.dryhurst at gmail.com  Mon Nov 11 14:36:54 2013
From: s.dryhurst at gmail.com (Sarah Dryhurst)
Date: Mon, 11 Nov 2013 13:36:54 +0000
Subject: [R-sig-ME] p-value calculation in binomial models
Message-ID: <CAAvYmYMxxXdzcdaXXEV4Eaq3jNWo08FCZ5NN-wvtx=-g5fvpXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131111/e2f2ddd5/attachment.pl>

From s.dryhurst at gmail.com  Mon Nov 11 15:14:46 2013
From: s.dryhurst at gmail.com (Sarah Dryhurst)
Date: Mon, 11 Nov 2013 14:14:46 +0000
Subject: [R-sig-ME] p-value calculation in binomial models
In-Reply-To: <CAAvYmYMxxXdzcdaXXEV4Eaq3jNWo08FCZ5NN-wvtx=-g5fvpXA@mail.gmail.com>
References: <CAAvYmYMxxXdzcdaXXEV4Eaq3jNWo08FCZ5NN-wvtx=-g5fvpXA@mail.gmail.com>
Message-ID: <CAAvYmYO=mu4j6meXv0kYxLG6H7nujMEtr3GrEUPzPej_iJfxjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131111/53290a56/attachment.pl>

From john.hodsoll at kcl.ac.uk  Mon Nov 11 19:00:59 2013
From: john.hodsoll at kcl.ac.uk (Hodsoll, John)
Date: Mon, 11 Nov 2013 18:00:59 +0000
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
In-Reply-To: <20131108091750.20107d377hq0rl8o@www.staffmail.ed.ac.uk>
References: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
	<20131107200125.1675524aymyntf8c@www.staffmail.ed.ac.uk>
	<20131108091750.20107d377hq0rl8o@www.staffmail.ed.ac.uk>
Message-ID: <f34849af72cd4b238a7d88b56450978e@DBXPR03MB239.eurprd03.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131111/95f16b3e/attachment.pl>

From f.calboli at imperial.ac.uk  Mon Nov 11 21:02:12 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 11 Nov 2013 20:02:12 +0000
Subject: [R-sig-ME] adding a kinship matrix as a random covariate
Message-ID: <86DC121F-84E0-4776-B208-A9CDA7BD69BD@imperial.ac.uk>

[This email might, or might have not, bounced, so I'm sending it a second time.  Apologies if you receive multiple copies]

Hi All,

I am possibly not up to date on using R mixed models when my random covariate is a Kinship matrix (from genetic data, not pedigree).

I have a data frame (called my.data), with m rows and 126 columns.  The columns are the phenotypes (quantitative) and a number of covariates, plus the genotype (coded as x/y, where y and y are microsatellite lengths).  Independently I have a m by m matrix of kinship values, derived from the genetic data.

All looks like:

> my.data

  id temp     bw    bl dt        rbw       rbl  sex  MSA  MSB  MSC  MSD  MDE  MSF  MSG  MSH
1   1   16 0.8707 16.66 54 0.01612407 0.3085185    m 240/256 162/166 256/256 123/123    <NA> 120/156 331/335 115/115
2   2   16 0.8644 16.91 54 0.01600741 0.3131481    m 268/270 162/162 256/256 123/123 361/373 120/156    <NA> 115/119
3   3   16 0.8464 17.25 54 0.01567407 0.3194444    m 240/268 162/162 272/272 123/123 353/361 120/120    <NA> 115/115
4   4   16 0.9077 18.16 54 0.01680926 0.3362963 <NA> 256/270 162/162    <NA> 123/123 353/361 120/120    <NA> 115/119
5   5   16 0.9075 18.05 53 0.01712264 0.3405660    f    <NA>    <NA>    <NA> 111/115 353/361 120/120    <NA> 115/115
6   6   16 0.8296 17.36 53 0.01565283 0.3275472    f 268/270 162/162    <NA> 111/123 353/361 120/156    <NA> 115/119
7   7   16 0.8354 17.74 51 0.01638039 0.3478431    f    <NA>    <NA>    <NA> 115/123    <NA> 120/156    <NA> 115/119
8   8   16 0.8614 16.84 53 0.01625283 0.3177358    f    <NA> 162/162 256/256 123/123    <NA> 120/156    <NA> 115/119
9   9   16 0.7756 18.22 54 0.01436296 0.3374074    f 268/270    <NA> 272/272 115/123    <NA> 120/120    <NA> 115/115
10 10   16 0.8076 16.37 53 0.01523774 0.3088679    f    <NA> 162/172    <NA> 115/123 361/373 120/120    <NA> 115/115

and the kinship matrix:

> Kinship[1:6, 1:6]
         [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
[1,] 0.5438596 0.4035088 0.3750000 0.3618421 0.3728070 0.3771930
[2,] 0.4035088 0.5614035 0.3903509 0.4298246 0.3925439 0.3925439
[3,] 0.3750000 0.3903509 0.5438596 0.3399123 0.3179825 0.3991228
[4,] 0.3618421 0.4298246 0.3399123 0.5219298 0.3771930 0.3662281
[5,] 0.3728070 0.3925439 0.3179825 0.3771930 0.5175439 0.3662281
[6,] 0.3771930 0.3925439 0.3991228 0.3662281 0.3662281 0.5833333

I tried in lme4 the following:

lmer(all$bw ~ all$MSA + all$temp + all$sex + all$dt + (1|Kinship))

returns

Error in `[[<-.data.frame`(`*tmp*`, i, value = c(233L, 174L, 161L, 162L,  : 
 replacement has 384120 rows, data has 485


I tried in nlme this:

lme(all$bw ~ all$MSA + all$temp + all$sex + all$dt, random = ~ 1|Kinship, na.action = na.omit)
Error in eval(expr, envir, enclos) : object 'bw' not found

If I put the kinship in my.data

> my.data$K = Kinship

lme(bw ~ MSA + temp + sex + dt, random = ~ 1|K, data = my.data, na.action =  na.omit)
Error in `row.names<-.data.frame`(`*tmp*`, value = origOrder) : 
 invalid 'row.names' length

Obviously using a m by m matrix is not a good way of specifying a random effect.  Given my data, which is not going to change, is there a way of using the K matrix as a random covariate?  alternatively, which packages would allow me to do so?  Finally, I will admit it openly, from the start.  I am after a p-value, ideally from an anova, to see if the different genotypes at each locus have an effect or not.  

Best

F


From bbolker at gmail.com  Mon Nov 11 22:29:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Nov 2013 16:29:18 -0500
Subject: [R-sig-ME] Doubt about including random effects or not
In-Reply-To: <724230362.39761384173923481.JavaMail.www@wwinf7125>
References: <724230362.39761384173923481.JavaMail.www@wwinf7125>
Message-ID: <52814C2E.40900@gmail.com>

On 13-11-11 07:45 AM, V. Coudrain wrote:
> Dear all,
> 
> I collected insects in 30 sites, 15 sites each with a level of
> isolation and all 30 sites are arranged along a gradient of habitat
> amount. Each insect species has a specialization value. I would like
> to test if specialization increases along the gradient of habitat and
> differs between isolation level. The number of insect species and 
> individuals differ largely between sites. I have two doubts: should I
> specify site as a random variable? Should I specify insect abundance
> as an offset?
> 
> The model I thought about: lme(specialization~Isolation*habitat
> amount + offset(insect abundance) , random~1|Site)
> 
> However I am not sure about using site as a random effect and
> specifically if it makes sense to mix offset and random effect.
> 
> Thank you!
> 
> Val?rie Coudrain 

  You can mix offsets and random effects: see e.g. the Owls example at
https://groups.nceas.ucsb.edu/non-linear-modeling/projects (although
this is also zero-inflated, which adds an additional level of complexity
you don't need).  A couple of comments though:

 * I don't quite understand why you don't just calculate average
specialization per site; presumably Isolation and habitat amount are
site-level covariates?  If you have different sample sizes per site, you
could calculate the mean and std. dev. of specialization and use the
weights= argument to inverse-variance weight ... (see Murtaugh 2007
_Ecology_ for arguments in favor of aggregating when analyzing nested
designs). (It's possible that one of your covariates varies within site,
which would make this aggregation infeasible.)
 * I also don't quite understand why you expect specialization to be
directly proportional to abundance?  Is abundance a species:site-level
covariate, or an overall (site-level) covariate (I think the latter)?  I
would consider just putting insect abundance in as a covariate (i.e.
allow for some dependence, don't require direct proportionality)... ?

  Ben Bolker


From bbolker at gmail.com  Mon Nov 11 22:45:31 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Nov 2013 16:45:31 -0500
Subject: [R-sig-ME] adding a kinship matrix as a random covariate
In-Reply-To: <86DC121F-84E0-4776-B208-A9CDA7BD69BD@imperial.ac.uk>
References: <86DC121F-84E0-4776-B208-A9CDA7BD69BD@imperial.ac.uk>
Message-ID: <52814FFB.10703@gmail.com>

On 13-11-11 03:02 PM, Federico Calboli wrote:
> [This email might, or might have not, bounced, so I'm sending it a
> second time.  Apologies if you receive multiple copies]
> 
> Hi All,
> 
> I am possibly not up to date on using R mixed models when my random
> covariate is a Kinship matrix (from genetic data, not pedigree).
> 
> I have a data frame (called my.data), with m rows and 126 columns.
> The columns are the phenotypes (quantitative) and a number of
> covariates, plus the genotype (coded as x/y, where y and y are
> microsatellite lengths).  Independently I have a m by m matrix of
> kinship values, derived from the genetic data.
> 
> All looks like:
> 
>> my.data
> 
> id temp     bw    bl dt        rbw       rbl  sex  MSA  MSB  MSC  MSD
> MDE  MSF  MSG  MSH 1   1   16 0.8707 16.66 54 0.01612407 0.3085185
> m 240/256 162/166 256/256 123/123    <NA> 120/156 331/335 115/115 2
> 2   16 0.8644 16.91 54 0.01600741 0.3131481    m 268/270 162/162
> 256/256 123/123 361/373 120/156    <NA> 115/119 3   3   16 0.8464
> 17.25 54 0.01567407 0.3194444    m 240/268 162/162 272/272 123/123
> 353/361 120/120    <NA> 115/115 4   4   16 0.9077 18.16 54 0.01680926
> 0.3362963 <NA> 256/270 162/162    <NA> 123/123 353/361 120/120
> <NA> 115/119 5   5   16 0.9075 18.05 53 0.01712264 0.3405660    f
> <NA>    <NA>    <NA> 111/115 353/361 120/120    <NA> 115/115 6   6
> 16 0.8296 17.36 53 0.01565283 0.3275472    f 268/270 162/162    <NA>
> 111/123 353/361 120/156    <NA> 115/119 7   7   16 0.8354 17.74 51
> 0.01638039 0.3478431    f    <NA>    <NA>    <NA> 115/123    <NA>
> 120/156    <NA> 115/119 8   8   16 0.8614 16.84 53 0.01625283
> 0.3177358    f    <NA> 162/162 256/256 123/123    <NA> 120/156
> <NA> 115/119 9   9   16 0.7756 18.22 54 0.01436296 0.3374074    f
> 268/270    <NA> 272/272 115/123    <NA> 120/120    <NA> 115/115 10 10
> 16 0.8076 16.37 53 0.01523774 0.3088679    f    <NA> 162/172    <NA>
> 115/123 361/373 120/120    <NA> 115/115
> 
> and the kinship matrix:
> 
>> Kinship[1:6, 1:6]
> [,1]      [,2]      [,3]      [,4]      [,5]      [,6] [1,] 0.5438596
> 0.4035088 0.3750000 0.3618421 0.3728070 0.3771930 [2,] 0.4035088
> 0.5614035 0.3903509 0.4298246 0.3925439 0.3925439 [3,] 0.3750000
> 0.3903509 0.5438596 0.3399123 0.3179825 0.3991228 [4,] 0.3618421
> 0.4298246 0.3399123 0.5219298 0.3771930 0.3662281 [5,] 0.3728070
> 0.3925439 0.3179825 0.3771930 0.5175439 0.3662281 [6,] 0.3771930
> 0.3925439 0.3991228 0.3662281 0.3662281 0.5833333
> 
> I tried in lme4 the following:
> 
> lmer(all$bw ~ all$MSA + all$temp + all$sex + all$dt + (1|Kinship))
> 
> returns
> 
> Error in `[[<-.data.frame`(`*tmp*`, i, value = c(233L, 174L, 161L,
> 162L,  : replacement has 384120 rows, data has 485
> 
> 
> I tried in nlme this:
> 
> lme(all$bw ~ all$MSA + all$temp + all$sex + all$dt, random = ~
> 1|Kinship, na.action = na.omit) Error in eval(expr, envir, enclos) :
> object 'bw' not found
> 
> If I put the kinship in my.data
> 
>> my.data$K = Kinship
> 
> lme(bw ~ MSA + temp + sex + dt, random = ~ 1|K, data = my.data,
> na.action =  na.omit) Error in `row.names<-.data.frame`(`*tmp*`,
> value = origOrder) : invalid 'row.names' length
> 
> Obviously using a m by m matrix is not a good way of specifying a
> random effect.  Given my data, which is not going to change, is there
> a way of using the K matrix as a random covariate?  alternatively,
> which packages would allow me to do so?  Finally, I will admit it
> openly, from the start.  I am after a p-value, ideally from an anova,
> to see if the different genotypes at each locus have an effect or
> not.
> 

Are any of these StackOverflow answers relevant/useful?


http://stackoverflow.com/questions/8245132/single-level-variables-in-mixed-model-lme4-error-in-r/8247412#8247412

http://stackoverflow.com/questions/19327088/reproducing-results-from-previous-answer-is-not-working-due-to-using-new-version/19382162#19382162

http://stackoverflow.com/questions/19104475/how-to-modify-slots-lme4-1-0/19106863#19106863

 I would also look at the results of library("sos"); findFn("kinship") ,
although there's a fair amount to sort through there ...  Perhaps in
conjunction with the reverse depends/reverse suggests of nlme and lme4 ... ?


From a.reynaldi at student.unsw.edu.au  Tue Nov 12 05:42:35 2013
From: a.reynaldi at student.unsw.edu.au (Arnold Reynaldi)
Date: Tue, 12 Nov 2013 04:42:35 +0000
Subject: [R-sig-ME] Nonlinear mixed effect with nlme
Message-ID: <62FF4C4E32840642930D994866A29105932EE8@INFPWXM002.ad.unsw.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131112/2bc26612/attachment.pl>

From v_coudrain at voila.fr  Tue Nov 12 09:00:54 2013
From: v_coudrain at voila.fr (V. Coudrain)
Date: Tue, 12 Nov 2013 09:00:54 +0100 (CET)
Subject: [R-sig-ME] Doubt about including random effects or not
In-Reply-To: <52814C2E.40900@gmail.com>
Message-ID: <264177899.147451384243254168.JavaMail.www@wwinf7125>

Dear Ben Bolker,

Thank you very much for your help.

> * I don't quite understand why you don't just calculate average
> specialization per site; presumably Isolation and habitat amount are
> site-level covariates? If you have different sample sizes per site, you
> could calculate the mean and std. dev. of specialization and use the
> weights= argument to inverse-variance weight ... (see Murtaugh 2007
> _Ecology_ for arguments in favor of aggregating when analyzing nested
> designs). (It's possible that one of your covariates varies within site,
> which would make this aggregation infeasible.)

Just to avoid confusion: isolation is a factor with two levels: isolated or not isolated (15 sites each), and habitat amount has a single value pro site. These two 
variables have limited collinearity.

I thought about using the mean, but what I am really interested in is to know is the distribution of specialization index, i.e., if species with high specialization occur 
mostly in connected sites compared to isolated sites, or if their abundance increases with increasing habitat amount. Just taking the mean won't show me this. 
However by reading you I think that looking at the spread (variance) of the specialization index may be a solution. Increasing variance should indicate the 
presence of species with more extreme specialization values. But I am not sure how to test for this, and if I can specify a one-tailed test (if variance towards 
higher specialization values is related to the isolation and habitat amount covariates).

> * I also don't quite understand why you expect specialization to be
> directly proportional to abundance? Is abundance a species:site-level
> covariate, or an overall (site-level) covariate (I think the latter)? I
> would consider just putting insect abundance in as a covariate (i.e.
> allow for some dependence, don't require direct proportionality)... ?
> 

No I think, this s an error from my side. Anyway think I misunderstood offset, which should anyway be used for a response variable that is a count (not the fact 
in my case. As you suggest it, it is certainly more appropriate to put insect abundance as a covariate.

Val?rie


___________________________________________________________
Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Nov 12 09:54:39 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 12 Nov 2013 09:54:39 +0100
Subject: [R-sig-ME] lmList from lme4 on grouped data objects
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D91FE4BD8@UM-MAIL4112.unimaas.nl>

Dear lme4-Maintainers,

As far as I can tell, lmList() from lme4 does not play nicely with grouped data objects from the nlme package. Example:

library(lme4)
data(Orthodont, package="nlme")

class(Orthodont)

### [1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"

res <- lmList(distance ~ age | Subject, data=Orthodont)

### Error in eval(expr, envir, enclos) : object 'Subject' not found
### In addition: Warning message:
### In Ops.ordered(age, Subject) : '|' is not meaningful for ordered factors

Orthodont <- as.data.frame(Orthodont)

res <- lmList(distance ~ age | Subject, data=Orthodont)

### works

This had me stumped for a while, so I figured I would note this here (in case anybody else runs into this issue). After googling a bit, I found:

https://github.com/lme4/lme4/blob/master/tests/lmList.R

so nothing really new here. But maybe add a check to lmList() whether somebody specifies a grouped data object and turn it into a regular data frame?

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


From john.hodsoll at kcl.ac.uk  Tue Nov 12 13:07:15 2013
From: john.hodsoll at kcl.ac.uk (Hodsoll, John)
Date: Tue, 12 Nov 2013 12:07:15 +0000
Subject: [R-sig-ME] Interpreting Zero altered models in MCMCglmm
In-Reply-To: <527CFBE1.3080703@u.washington.edu>
References: <6daaa3ff74c84327bd6db89f9bf8bdb3@DBXPR03MB239.eurprd03.prod.outlook.com>
	<527CFBE1.3080703@u.washington.edu>
Message-ID: <af2d5d25d48e4e9abe7a0f8d2a620bec@DBXPR03MB239.eurprd03.prod.outlook.com>

Hi David

Thanks for your note. Really useful paper and code which I've used quite extensively. One point of interest, I understand from your code how estimated means are generated for observations with events. But how would you recommend combining this with the estimates for zero inflation to get an overall mean? In general when we present this to clinicians they would want to get an overall estimate of reduction of violent incidents. 

Thanks and again, great paper.

John

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of David Atkins
Sent: 08 November 2013 14:58
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Interpreting Zero altered models in MCMCglmm


John--

In addition to Jarrod's specific suggestions, you might give a look at an article we wrote describing GLMM for count data (including zero-inflated / hurdle models), which also has accompanying R code, focused in large part on MCMCglmm:

Atkins, D. C., Baldwin, S., Zheng, C., Gallop, R. J., & Neighbors, C. 
(2013). A tutorial on count regression and zero-altered count models for longitudinal substance use data.  Psychology of Addictive Behaviors, 27, 166-177. doi: 10.1037/a0029508 PMCID: PMC3513584.

MS, data, code can be found from link at:

http://depts.washington.edu/cshrb/statistical-resources-tutorial-link/

Hope that helps and best wishes with your analyses.

cheers, Dave

--
Dave Atkins, PhD

Research Professor
Department of Psychiatry and Behavioral Science University of Washington datkins at u.washington.edu
http://depts.washington.edu/cshrb/david-atkins/#more-48

"The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data." -- John Tukey

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From nad34 at cam.ac.uk  Tue Nov 12 13:50:44 2013
From: nad34 at cam.ac.uk (Nick Donnelly)
Date: Tue, 12 Nov 2013 12:50:44 +0000 (UTC)
Subject: [R-sig-ME] Error with predict.merMod and random slopes
Message-ID: <loom.20131112T133254-675@post.gmane.org>

Hello All,

This is my first time posting, and I'm not a very experienced user of R and
lme4, so I apologise in advance if I've missed something important or this
issue has been addressed previously.

I'm trying to use a binomial mixed model to predict whether subjects make a
certain type of response in trials in a behavioural task. I've been fitting
a binomial mixed model using lme4, and have been using the ID of my subjects
as a random intercept, and using the predict.merMod method to predict the
outcome of new trial data, which has been working. 

However, having recently read Barr et al 2013
(http://idiom.ucsd.edu/~rlevy/papers/barr-etal-2013-jml.pdf) I've been
trying to make my models maximal by adding random slopes for my
within-subjects factors. When I add random slopes to my models and use
predict.merMod I now get an error:

"Error: sum(nb) == q is not TRUE"

Here is the code, and a link to the data I am working with, which is
hopefully fully self-contained and working:

library(lme4)

latencyData <-
read.csv("https://dl.dropboxusercontent.com/s/uhn86f5nae662i6
/latencyDataTest.dat",header = TRUE)

#latencyData$prem is the outcome of each behavioural trial (premature or
#not premature) - the dependent variable
#latencyData$group is a between subjects factor 
#latencyData$latency is a reaction time that is measured as part of each
#trial
#latencyData$PO is the outcome of the previous trial
#latencyData$subjectID is a code for the subject which made each trial

#take the full dataset apart from one trial, which I will use for
#prediction later
x <- 1
ix <- 1:dim(latencyData)[1] != x

dataTrain <- latencyData[ix,]
dataTest  <- latencyData[x ,]


#fit a logistic regression model with the subject ID as random intercept
m1 <- glmer(prem ~ group*latency*PO + (1|subjectID),data = dataTrain, 
family = binomial)

#fit a logistic regression model that attempts to be "maximal" after Barr
#et al 2013, including random slopes for the subject's latency, the
#previous trial outcome, and their interaction(the highest order
within-#subjects factors)

m2 <- glmer(prem ~ group*latency*PO + (latency:PO|subjectID),
data = dataTrain, family = binomial)

#Try a model with just 1 random slope
m3 <- glmer(prem ~ group*latency*PO + (PO|subjectID),
data = dataTrain,family = binomial)


#try and predict the left out trial with the random intercept only model-
#gives a result
predict(m1,dataTest,REform = NULL,type = "response")

#try and predict the left out trial with the random intercepts and slopes 
#model
predict(m2,dataTest,REform = NULL,type = "response")

#this gives an error:"Error: sum(nb) == q is not TRUE"

#try and predict the left out trial with the random intercepts and single
#random slope model
predict(m3,dataTest,REform = NULL,type = "response")

#this gives the same error:"Error: sum(nb) == q is not TRUE"

#If I remove the RE from the prediction, I can get a result rather than an
#error
predict(m3,dataTest,REform = NA,type = "response")

However, I would like to be able to make predictions using the maximal model
and the random effects structure. Is there anything anyone can suggest I can
do to get this working, or is it not yet an available feature in lme4 (I
know the predict.merMod method is new)?


From youngjo at snu.ac.kr  Thu Nov  7 04:54:48 2013
From: youngjo at snu.ac.kr (Youngjo Lee)
Date: Thu, 7 Nov 2013 12:54:48 +0900
Subject: [R-sig-ME] the cox-reid adjusted likelihood for linear mixed models
	in R
Message-ID: <CAGBsDtRdc_CQs7KNSrKhgHhdiCHQCS8hx=ASEmodToxxr0gt7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131107/38093a50/attachment.pl>

From Maria_Paola.Bissiri at tu-dresden.de  Tue Nov 12 20:14:41 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Tue, 12 Nov 2013 19:14:41 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
Message-ID: <20131112191441.Horde.wscwT2XY_yYaLz4XReEVwA7@mail.zih.tu-dresden.de>

Dear list members,
how should I define the prior for my MCMCglmm model with random =  
~us(1+subj_ID):fin_B?
fin_B is dichotomous, subj_ID has 86 levels (the experiment participants).
The response variable resp_X ist dichotomous.

When I run for instance the following ...
(an attempt inspired by  
http://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/)

k <- length(levels(fallmid$resp_X))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
prior = list(R = list(fix=1, V=0.5 * (I + J), n = 4),
              G = list(
                  G1 = list(V = diag(1), n = 2),
                  G2 = list(V = diag(1), n = 2)))

fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +  
lang * fin_B,
                              random = ~us(1+subj_ID):fin_B,  
family="categorical", data=fallmid,
                              prior=prior
                              )

.... I get the following error message.

Error in MCMCglmm(resp_X ~ lang * ini_pch + lang * manner + lang * fin_B,  :
   prior$G has the wrong number of structures

How should I define G? Is R fine as it is?
I researched everywhere in Internet and asked people about it, but I  
don't understand how V and n should be indicated. I would be grateful  
if you could help.

Kind regards,
Maria Paola



-- 
Dr. Maria Paola Bissiri

TU Dresden
Fakult?t Elektrotechnik und Informationstechnik
Institut f?r Akustik und Sprachkommunikation
01062 Dresden

Barkhausen-Bau, Raum S54
Helmholtzstra?e 18

Tel: +49 (0)351 463-34283
Fax: +49 (0)351 463-37781
E-Mail: Maria_Paola.Bissiri at tu-dresden.de
http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm


From aline.frank at wsl.ch  Tue Nov 12 20:40:38 2013
From: aline.frank at wsl.ch (aline.frank at wsl.ch)
Date: Tue, 12 Nov 2013 20:40:38 +0100
Subject: [R-sig-ME] Looking for residuals in clmm summary output
Message-ID: <OF9269AB78.4657A5AB-ONC1257C21.006C174A-C1257C21.006C1750@wsl.ch>

Hello

I am working with ordinal data using the clmm() mixed models approach of the R package "ordinal". My interest is in analyzing the random effects of my model, inclusive the residual term. However, the summary of my model does not inlude the residuals. Does this mean that my residuals are "hidden" in one of the random effects, or is there a way to get the residuals anyway? Below you see my model summary output.

Thanks for every hint!

Aline



model <- clmm(trait~1+(1|Block_Nr)+(1|Pop_Nr)+(1|Fam_Nr)+(1|Block_Nr:Pop_Nr),data=dat)

Data: frost damage on the plants in levels 0-5

Output R:

Cumulative Link Mixed Model fitted with the Laplace approximation

formula: trait ~ 1 + (1 | Block_Nr) + (1 | Pop_Nr) + (1 | Fam_Nr) + (1 |      Block_Nr:Pop_Nr)
data:    dat

 link  threshold nobs logLik   AIC     niter     max.grad cond.H
 logit flexible  4018 -2015.57 4047.14 660(2644) 2.93e-03 3.6e+01

Random effects:
 Groups          Name        Variance Std.Dev.
 Block_Nr:Pop_Nr (Intercept) 0.0000   0.0000  
 Fam_Nr          (Intercept) 0.1085   0.3294  
 Pop_Nr          (Intercept) 0.2694   0.5191  
 Block_Nr        (Intercept) 0.1351   0.3675  
Number of groups:  Block_Nr:Pop_Nr 1435,  Fam_Nr 258,  Pop_Nr 90,  Block_Nr 16

No Coefficients

Threshold coefficients:
    Estimate Std. Error z value
0|1   1.9701     0.1221   16.14
1|2   3.7404     0.1488   25.13
2|3   4.5441     0.1791   25.37
3|4   5.3417     0.2322   23.00
(103 observations deleted due to missingness)


From bbolker at gmail.com  Tue Nov 12 23:41:24 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Nov 2013 17:41:24 -0500
Subject: [R-sig-ME] Error with predict.merMod and random slopes
In-Reply-To: <loom.20131112T133254-675@post.gmane.org>
References: <loom.20131112T133254-675@post.gmane.org>
Message-ID: <5282AE94.9080204@gmail.com>

On 13-11-12 07:50 AM, Nick Donnelly wrote:
> Hello All,
> 
> This is my first time posting, and I'm not a very experienced user of R and
> lme4, so I apologise in advance if I've missed something important or this
> issue has been addressed previously.
> 
> I'm trying to use a binomial mixed model to predict whether subjects make a
> certain type of response in trials in a behavioural task. I've been fitting
> a binomial mixed model using lme4, and have been using the ID of my subjects
> as a random intercept, and using the predict.merMod method to predict the
> outcome of new trial data, which has been working. 
> 
> However, having recently read Barr et al 2013
> (http://idiom.ucsd.edu/~rlevy/papers/barr-etal-2013-jml.pdf) I've been
> trying to make my models maximal by adding random slopes for my
> within-subjects factors. When I add random slopes to my models and use
> predict.merMod I now get an error:
> 
> "Error: sum(nb) == q is not TRUE"
> 
> Here is the code, and a link to the data I am working with, which is
> hopefully fully self-contained and working:
> 
> library(lme4)
> 
> latencyData <-
> read.csv("https://dl.dropboxusercontent.com/s/uhn86f5nae662i6
> /latencyDataTest.dat",header = TRUE)
> 
> #latencyData$prem is the outcome of each behavioural trial (premature or
> #not premature) - the dependent variable
> #latencyData$group is a between subjects factor 
> #latencyData$latency is a reaction time that is measured as part of each
> #trial
> #latencyData$PO is the outcome of the previous trial
> #latencyData$subjectID is a code for the subject which made each trial
> 
> #take the full dataset apart from one trial, which I will use for
> #prediction later
> x <- 1
> ix <- 1:dim(latencyData)[1] != x
> 
> dataTrain <- latencyData[ix,]
> dataTest  <- latencyData[x ,]
> 
> 
> #fit a logistic regression model with the subject ID as random intercept
> m1 <- glmer(prem ~ group*latency*PO + (1|subjectID),data = dataTrain, 
> family = binomial)
> 
> #fit a logistic regression model that attempts to be "maximal" after Barr
> #et al 2013, including random slopes for the subject's latency, the
> #previous trial outcome, and their interaction(the highest order
> within-#subjects factors)
> 
> m2 <- glmer(prem ~ group*latency*PO + (latency:PO|subjectID),
> data = dataTrain, family = binomial)
> 
> #Try a model with just 1 random slope
> m3 <- glmer(prem ~ group*latency*PO + (PO|subjectID),
> data = dataTrain,family = binomial)
> 
> 
> #try and predict the left out trial with the random intercept only model-
> #gives a result
> predict(m1,dataTest,REform = NULL,type = "response")
> 
> #try and predict the left out trial with the random intercepts and slopes 
> #model
> predict(m2,dataTest,REform = NULL,type = "response")
> 
> #this gives an error:"Error: sum(nb) == q is not TRUE"
> 
> #try and predict the left out trial with the random intercepts and single
> #random slope model
> predict(m3,dataTest,REform = NULL,type = "response")
> 
> #this gives the same error:"Error: sum(nb) == q is not TRUE"
> 
> #If I remove the RE from the prediction, I can get a result rather than an
> #error
> predict(m3,dataTest,REform = NA,type = "response")
> 
> However, I would like to be able to make predictions using the maximal model
> and the random effects structure. Is there anything anyone can suggest I can
> do to get this working, or is it not yet an available feature in lme4 (I
> know the predict.merMod method is new)?


  Thanks for the very detailed report.  This *should* work, the fact
that it doesn't constitutes a bug.

  I'm guessing that you might be able to work around the problems by
defining the interactions up front, e.g.

transform(dataTrain,latencyPO=interaction(latency,PO))

and then using (latencyPO|subjectID) as the random effect.

  I will take a closer look (maybe with a smaller example so that it
runs faster ...)

  Ben Bolker


From bbolker at gmail.com  Tue Nov 12 23:49:05 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Nov 2013 17:49:05 -0500
Subject: [R-sig-ME] Looking for residuals in clmm summary output
In-Reply-To: <OF9269AB78.4657A5AB-ONC1257C21.006C174A-C1257C21.006C1750@wsl.ch>
References: <OF9269AB78.4657A5AB-ONC1257C21.006C174A-C1257C21.006C1750@wsl.ch>
Message-ID: <5282B061.7020206@gmail.com>

On 13-11-12 02:40 PM, aline.frank at wsl.ch wrote:
> Hello
> 
> I am working with ordinal data using the clmm() mixed models approach
> of the R package "ordinal". My interest is in analyzing the random
> effects of my model, inclusive the residual term. However, the
> summary of my model does not inlude the residuals. Does this mean
> that my residuals are "hidden" in one of the random effects, or is
> there a way to get the residuals anyway? Below you see my model
> summary output.
> 
> Thanks for every hint!
> 
> Aline

My first thought is that since fitted(model) works, you might be able to
used fitted(model)-observed, but on second thought, you're going to have
to figure out what scale the 'fitted' value is on and how it relates to
the predicted value of the response ...






> 
> 
> 
> model <-
> clmm(trait~1+(1|Block_Nr)+(1|Pop_Nr)+(1|Fam_Nr)+(1|Block_Nr:Pop_Nr),data=dat)
>
>  Data: frost damage on the plants in levels 0-5
> 
> Output R:
> 
> Cumulative Link Mixed Model fitted with the Laplace approximation
> 
> formula: trait ~ 1 + (1 | Block_Nr) + (1 | Pop_Nr) + (1 | Fam_Nr) +
> (1 |      Block_Nr:Pop_Nr) data:    dat
> 
> link  threshold nobs logLik   AIC     niter     max.grad cond.H logit
> flexible  4018 -2015.57 4047.14 660(2644) 2.93e-03 3.6e+01
> 
> Random effects: Groups          Name        Variance Std.Dev. 
> Block_Nr:Pop_Nr (Intercept) 0.0000   0.0000 Fam_Nr
> (Intercept) 0.1085   0.3294 Pop_Nr          (Intercept) 0.2694
> 0.5191 Block_Nr        (Intercept) 0.1351   0.3675 Number of groups:
> Block_Nr:Pop_Nr 1435,  Fam_Nr 258,  Pop_Nr 90,  Block_Nr 16
> 
> No Coefficients
> 
> Threshold coefficients: Estimate Std. Error z value 0|1   1.9701
> 0.1221   16.14 1|2   3.7404     0.1488   25.13 2|3   4.5441
> 0.1791   25.37 3|4   5.3417     0.2322   23.00 (103 observations
> deleted due to missingness)
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From rune.haubo at gmail.com  Wed Nov 13 10:35:48 2013
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 13 Nov 2013 10:35:48 +0100
Subject: [R-sig-ME] Looking for residuals in clmm summary output
In-Reply-To: <OF9269AB78.4657A5AB-ONC1257C21.006C174A-C1257C21.006C1750@wsl.ch>
References: <OF9269AB78.4657A5AB-ONC1257C21.006C174A-C1257C21.006C1750@wsl.ch>
Message-ID: <CAG_uk90SnAkmzemv9iG0eJrm_h8neneyb7moqH3ZLo1+GFb-Uw@mail.gmail.com>

Dear Aline,

You are not alone in being surprised of the absence of residuals; I
meet that question on a regular basis. And I would be delighted to
implement residuals for CLMs and CLMMs in ordinal, its only that I
have never seen a relevant definition of such residuals or been able
to come up with one myself. One of the problems is that we are really
taking about a vector-valued response (multinomially distributed), and
so we might be able to define vector-valued residuals. But what would
you use such a residual vector for? Graphing it is not as easy as with
univariate responses, and even if that succeeds, which structures
should you look for?

Here is a possible definition of 'raw' residuals for CLMs (non-random):
## Residuals for CLMs:
library(ordinal)
fm1 <-  clm(rating ~ temp + contact, data=wine)
summary(fm1)
pred <- predict(fm1, newdata=wine[, c("contact", "temp")])$fit
Y <- matrix(0, nrow=nrow(wine), ncol=nlevels(wine$rating))
Y <- 1 * (col(Y) == wine$rating)
head(Y) ## multinomial response
head(pred) ## fitted values for multinomial response
raw.resid <- Y - pred
head(raw.resid)

The last lines give:

> head(Y)
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    1    0    0    0
[2,]    0    0    1    0    0
[3,]    0    0    1    0    0
[4,]    0    0    0    1    0
[5,]    0    0    0    1    0
[6,]    0    0    0    1    0
> head(pred)
           1         2         3          4          5
1 0.20679013 0.5706497 0.1922909 0.02361882 0.00665041
2 0.20679013 0.5706497 0.1922909 0.02361882 0.00665041
3 0.05354601 0.3776461 0.4430599 0.09582084 0.02992711
4 0.05354601 0.3776461 0.4430599 0.09582084 0.02992711
5 0.02088771 0.2014157 0.5015755 0.20049402 0.07562701
6 0.02088771 0.2014157 0.5015755 0.20049402 0.07562701
> raw.resid <- Y - pred
> head(raw.resid)
            1          2          3           4           5
1 -0.20679013  0.4293503 -0.1922909 -0.02361882 -0.00665041
2 -0.20679013 -0.5706497  0.8077091 -0.02361882 -0.00665041
3 -0.05354601 -0.3776461  0.5569401 -0.09582084 -0.02992711
4 -0.05354601 -0.3776461 -0.4430599  0.90417916 -0.02992711
5 -0.02088771 -0.2014157 -0.5015755  0.79950598 -0.07562701
6 -0.02088771 -0.2014157 -0.5015755  0.79950598 -0.07562701

There is at present no predict method for clmm objects, so here you
have another challenge.  However, as I indicated above, the real
challenge is to figure out what to do with such residuals. Note that
the elements of the  i'th predicted probability vector are correlated
as it necessarily sums to 1:
> unique(rowSums(pred))
[1] 1

Cheers,
Rune


On 12 November 2013 20:40,  <aline.frank at wsl.ch> wrote:
> Hello
>
> I am working with ordinal data using the clmm() mixed models approach of the R package "ordinal". My interest is in analyzing the random effects of my model, inclusive the residual term. However, the summary of my model does not inlude the residuals. Does this mean that my residuals are "hidden" in one of the random effects, or is there a way to get the residuals anyway? Below you see my model summary output.
>
> Thanks for every hint!
>
> Aline
>
>
>
> model <- clmm(trait~1+(1|Block_Nr)+(1|Pop_Nr)+(1|Fam_Nr)+(1|Block_Nr:Pop_Nr),data=dat)
>
> Data: frost damage on the plants in levels 0-5
>
> Output R:
>
> Cumulative Link Mixed Model fitted with the Laplace approximation
>
> formula: trait ~ 1 + (1 | Block_Nr) + (1 | Pop_Nr) + (1 | Fam_Nr) + (1 |      Block_Nr:Pop_Nr)
> data:    dat
>
>  link  threshold nobs logLik   AIC     niter     max.grad cond.H
>  logit flexible  4018 -2015.57 4047.14 660(2644) 2.93e-03 3.6e+01
>
> Random effects:
>  Groups          Name        Variance Std.Dev.
>  Block_Nr:Pop_Nr (Intercept) 0.0000   0.0000
>  Fam_Nr          (Intercept) 0.1085   0.3294
>  Pop_Nr          (Intercept) 0.2694   0.5191
>  Block_Nr        (Intercept) 0.1351   0.3675
> Number of groups:  Block_Nr:Pop_Nr 1435,  Fam_Nr 258,  Pop_Nr 90,  Block_Nr 16
>
> No Coefficients
>
> Threshold coefficients:
>     Estimate Std. Error z value
> 0|1   1.9701     0.1221   16.14
> 1|2   3.7404     0.1488   25.13
> 2|3   4.5441     0.1791   25.37
> 3|4   5.3417     0.2322   23.00
> (103 observations deleted due to missingness)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From geralttee at gmail.com  Wed Nov 13 15:32:54 2013
From: geralttee at gmail.com (Szymek Drobniak)
Date: Wed, 13 Nov 2013 15:32:54 +0100
Subject: [R-sig-ME] Define prior in MCMCglmm
Message-ID: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131113/22b457da/attachment.pl>

From bbolker at gmail.com  Wed Nov 13 16:19:03 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Nov 2013 15:19:03 +0000 (UTC)
Subject: [R-sig-ME] lmList from lme4 on grouped data objects
References: <077E31A57DA26E46AB0D493C9966AC730D91FE4BD8@UM-MAIL4112.unimaas.nl>
Message-ID: <loom.20131113T161338-709@post.gmane.org>

Viechtbauer Wolfgang (STAT <wolfgang.viechtbauer at ...> writes:

> 
> Dear lme4-Maintainers,
> 
> As far as I can tell, lmList() from lme4 does not 
> play nicely with grouped data objects from the nlme package. Example:
> 
> library(lme4)
> data(Orthodont, package="nlme")
> 
> class(Orthodont)
> 
> ### [1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"
> 
> res <- lmList(distance ~ age | Subject, data=Orthodont)
> 
> ### Error in eval(expr, envir, enclos) : object 'Subject' not found
> ### In addition: Warning message:
> ### In Ops.ordered(age, Subject) : '|' is not 
> meaningful for ordered factors
> 
> Orthodont <- as.data.frame(Orthodont)
> 
> res <- lmList(distance ~ age | Subject, data=Orthodont)
> 
> ### works
> 
> This had me stumped for a while, so I figured I would note this here (in
case anybody else runs into this
> issue). After googling a bit, I found:
> 
> https://github.com/lme4/lme4/blob/master/tests/lmList.R
> 
> so nothing really new here. But maybe add a check
>  to lmList() whether somebody specifies a grouped data
> object and turn it into a regular data frame?


  This is a good point. The code of lmList actually has a
line converting the 'data' argument via 'as.data.frame', but
it doesn't work! The reason is a bit subtle -- lmList constructs
its model frame by modifying the call and evaluating it in the
parent frame, so that modifications to 'data' within the function
itself get lost ...  I'm not currently sure of the best way to
fix this, so in the meantime I'm adding a comment to the documentation.

There are still some open issues with lmList: in particular, it
doesn't play nicely with the nlme accessor methods:

https://github.com/lme4/lme4/issues/26


From bbolker at gmail.com  Wed Nov 13 16:40:10 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Nov 2013 10:40:10 -0500
Subject: [R-sig-ME] Error with predict.merMod and random slopes
In-Reply-To: <loom.20131112T133254-675@post.gmane.org>
References: <loom.20131112T133254-675@post.gmane.org>
Message-ID: <52839D5A.8000707@gmail.com>

On 13-11-12 07:50 AM, Nick Donnelly wrote:
> Hello All,
> 
> This is my first time posting, and I'm not a very experienced user of R and
> lme4, so I apologise in advance if I've missed something important or this
> issue has been addressed previously.
> 
> I'm trying to use a binomial mixed model to predict whether subjects make a
> certain type of response in trials in a behavioural task. I've been fitting
> a binomial mixed model using lme4, and have been using the ID of my subjects
> as a random intercept, and using the predict.merMod method to predict the
> outcome of new trial data, which has been working. 
> 
> However, having recently read Barr et al 2013
> (http://idiom.ucsd.edu/~rlevy/papers/barr-etal-2013-jml.pdf) I've been
> trying to make my models maximal by adding random slopes for my
> within-subjects factors. When I add random slopes to my models and use
> predict.merMod I now get an error:
> 
> "Error: sum(nb) == q is not TRUE"
> 
> Here is the code, and a link to the data I am working with, which is
> hopefully fully self-contained and working:
> 
> library(lme4)
> 
> latencyData <-
> read.csv("https://dl.dropboxusercontent.com/s/uhn86f5nae662i6
> /latencyDataTest.dat",header = TRUE)
> 
> #latencyData$prem is the outcome of each behavioural trial (premature or
> #not premature) - the dependent variable
> #latencyData$group is a between subjects factor 
> #latencyData$latency is a reaction time that is measured as part of each
> #trial
> #latencyData$PO is the outcome of the previous trial
> #latencyData$subjectID is a code for the subject which made each trial
> 
> #take the full dataset apart from one trial, which I will use for
> #prediction later
> x <- 1
> ix <- 1:dim(latencyData)[1] != x
> 
> dataTrain <- latencyData[ix,]
> dataTest  <- latencyData[x ,]
> 
> 
> #fit a logistic regression model with the subject ID as random intercept
> m1 <- glmer(prem ~ group*latency*PO + (1|subjectID),data = dataTrain, 
> family = binomial)
> 
> #fit a logistic regression model that attempts to be "maximal" after Barr
> #et al 2013, including random slopes for the subject's latency, the
> #previous trial outcome, and their interaction(the highest order
> within-#subjects factors)
> 
> m2 <- glmer(prem ~ group*latency*PO + (latency:PO|subjectID),
> data = dataTrain, family = binomial)
> 
> #Try a model with just 1 random slope
> m3 <- glmer(prem ~ group*latency*PO + (PO|subjectID),
> data = dataTrain,family = binomial)
> 
> 
> #try and predict the left out trial with the random intercept only model-
> #gives a result
> predict(m1,dataTest,REform = NULL,type = "response")
> 
> #try and predict the left out trial with the random intercepts and slopes 
> #model
> predict(m2,dataTest,REform = NULL,type = "response")
> 
> #this gives an error:"Error: sum(nb) == q is not TRUE"
> 
> #try and predict the left out trial with the random intercepts and single
> #random slope model
> predict(m3,dataTest,REform = NULL,type = "response")
> 
> #this gives the same error:"Error: sum(nb) == q is not TRUE"
> 
> #If I remove the RE from the prediction, I can get a result rather than an
> #error
> predict(m3,dataTest,REform = NA,type = "response")
> 
> However, I would like to be able to make predictions using the maximal model
> and the random effects structure. Is there anything anyone can suggest I can
> do to get this working, or is it not yet an available feature in lme4 (I
> know the predict.merMod method is new)?
> 
  I lied in my previous message: I don't think interaction(latency,PO)
is the right thing to do at all (it would work for two categorical
variables, but not for a continuous + categorical) variable...)

I've added this as  https://github.com/lme4/lme4/issues/153


From juan.santos at ti.bund.de  Thu Nov 14 14:48:31 2013
From: juan.santos at ti.bund.de (Juan Santos)
Date: Thu, 14 Nov 2013 14:48:31 +0100
Subject: [R-sig-ME] Non linear mixed models on binomial distributed data
Message-ID: <5284D4AF.5070605@ti.bund.de>

Dear list members,

I frecuently use this model:

p(l)=\frac{s\times r(l)}{(1-s)+s\times r(l)} (1)

To estimate the expected catch rates in a selective fishing gear (the 
test gear) , which has been fishing in paralel with a non selective gear 
(the control gear) . p(l) depends on:

s=the split parameter: defining the probability of a fish to enter in 
the test gear (s) or the control gear (1-s)
r(l)= the likelihood of fish retention in the test trawl. This 
likelihood is conditioned to fish body length, and describes the test 
gear size selection.

the relationship between the retention likelihood and the fish length 
r(l) is used to be defined as a logit link function:

r(l)=\frac{exp(\beta_1+\beta_2\times l )}{1+exp(\beta_1+\beta_2\times l 
)} (2)


In overall, there is a total of three parameters to be estimated: s, 
\beta_1, \beta_2. I use a non linear approach to estimate such 
parameters, by maximizing the binomial log-likelihood function:

\sum_l{N_{l}^T\times \log{p(l)}+N_{l}^C\times \log{1-p(l)}} (3)

where N_{l}^T is the number of fishes per length-class caught in the 
test gear, and N_{l}^C is the numbers caught in the control codend.


for a given Test gear, we use to perform several hauls, showing in many 
cases a high variation of the estimated p(l) between hauls. To account 
for such variation I use the bootstrap (with resampling scheme based on 
resampling between hauls and fishes within hauls) to estimate the error 
of the mean curve (estimated using the data after pooling the different 
hauls).

I ?m wondering if I can shift to a non linear mixed modeling approach, 
where the hauls are considered as a random component. At the moment I 
only could find such approach but using leats squares as minimization 
criteria. But I could not find a way to keep using the equation (3) as 
target criteria.


All the best,

Juan Santos


From Maria_Paola.Bissiri at tu-dresden.de  Thu Nov 14 16:06:26 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Thu, 14 Nov 2013 15:06:26 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
Message-ID: <20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>

Dear Szymek,
thank you very much for your answer.

Yes, the random effects were indicated wrongly in MCMCglmm! My  
intention is of course to look at variance associated with subjects  
(subj_ID).
I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID  
+ us(fin_B):subj_ID.
Please, correct me if I am wrong.

So the model runs with:
k <- length(levels(fallmid$resp_X))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
prior <- list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
                  G = list(G1 = list(V = diag(1), n = 2), G2 = list(V  
= diag(2), n = 2)))

fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +  
lang * fin_B,
                              random = ~us(1):subj_ID + us(fin_B):subj_ID,
                              family="categorical", data=fallmid,
                              prior=prior
                              )

In your suggestion you indicate nu=2.002. What does "nu" mean? What is  
the difference between nu and n? In the MCMCglmm manual and in the  
tutorial they are both defined as "degrees of belief". What does this  
mean?

Kind regards,
Maria Paola







Zitat von Szymek Drobniak <geralttee at gmail.com>:

> Dear Maria,
>
> I'm not sure what exactly you're trying to test with your model, but to
> start with - your prior specification assumes 2 random effects, and your
> model has only one (a structured covariance matrix with fin_B defined as a
> random effect). This specification you've provided is similar to a random
> intercept/slope model - but I can't see why you would like to fit it (most
> importantly, you assumed that fin_B is both a fixed and random effect). If
> your intention was to look at variance associated with subjects (subj_ID),
> and you'd like to see if this variance is heterogeneous for different
> levels of fin_B - you could fit:
>
> MCMCglmm(your_fixed_formula_here, random=~us(fin_B):subj_ID, ...)
>
> and the prior would be (assuming fin_B has 2 levels as you've said)
>
> list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2),nu=2.002)))
>
> that's for start, then have a look at mcmc-series plots to see if it mixes
> well and tweak your model further if necessary.
>
> Cheer
> szymek

-- 
Dr. Maria Paola Bissiri

TU Dresden
Fakult?t Elektrotechnik und Informationstechnik
Institut f?r Akustik und Sprachkommunikation
01062 Dresden

Barkhausen-Bau, Raum S54
Helmholtzstra?e 18

Tel: +49 (0)351 463-34283
Fax: +49 (0)351 463-37781
E-Mail: Maria_Paola.Bissiri at tu-dresden.de
http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm


From j.hadfield at ed.ac.uk  Thu Nov 14 18:23:37 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 14 Nov 2013 17:23:37 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
Message-ID: <20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>

Hi Maria,

random = ~us(1):subj_ID + us(fin_B):subj_ID  is the same as  
idh(1+finB):subj_ID and is not the same as (1 + fin_B|subj_ID) in lmer  
because the idh fixes the covariance between and intercepts and slopes  
to zero.  us(1+finB):subj_ID is equivalent to the lmer code.

Also, a prior of nu=2 (or nu=2.002) could have quite an influence on  
your posterior. V=diag(2) and nu=1.002 for the 2x2 case gives a  
marginal prior on the variances that is equivalent to an inverse gamma  
with shape and scale equal to 0.001. This prior used to be used a lot,  
but has some bad properties when values close to zero have support. I  
often use the parameter expanded prior:

list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)

where a is something large.

There is no difference between nu and n.

Cheers,

Jarrod

I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
> And this should be indicated in MCMCglmm() as random =  
> ~us(1):subj_ID + us(fin_B):subj_ID.


  Quoting Maria Paola Bissiri <Maria_Paola.Bissiri at tu-dresden.de> on  
Thu, 14 Nov 2013 15:06:26 +0000:

> Dear Szymek,
> thank you very much for your answer.
>
> Yes, the random effects were indicated wrongly in MCMCglmm! My  
> intention is of course to look at variance associated with subjects  
> (subj_ID).
> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
> And this should be indicated in MCMCglmm() as random =  
> ~us(1):subj_ID + us(fin_B):subj_ID.
> Please, correct me if I am wrong.
>
> So the model runs with:
> k <- length(levels(fallmid$resp_X))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> prior <- list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
>                  G = list(G1 = list(V = diag(1), n = 2), G2 = list(V  
> = diag(2), n = 2)))
>
> fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner  
> + lang * fin_B,
>                              random = ~us(1):subj_ID + us(fin_B):subj_ID,
>                              family="categorical", data=fallmid,
>                              prior=prior
>                              )
>
> In your suggestion you indicate nu=2.002. What does "nu" mean? What  
> is the difference between nu and n? In the MCMCglmm manual and in  
> the tutorial they are both defined as "degrees of belief". What does  
> this mean?
>
> Kind regards,
> Maria Paola
>
>
>
>
>
>
>
> Zitat von Szymek Drobniak <geralttee at gmail.com>:
>
>> Dear Maria,
>>
>> I'm not sure what exactly you're trying to test with your model, but to
>> start with - your prior specification assumes 2 random effects, and your
>> model has only one (a structured covariance matrix with fin_B defined as a
>> random effect). This specification you've provided is similar to a random
>> intercept/slope model - but I can't see why you would like to fit it (most
>> importantly, you assumed that fin_B is both a fixed and random effect). If
>> your intention was to look at variance associated with subjects (subj_ID),
>> and you'd like to see if this variance is heterogeneous for different
>> levels of fin_B - you could fit:
>>
>> MCMCglmm(your_fixed_formula_here, random=~us(fin_B):subj_ID, ...)
>>
>> and the prior would be (assuming fin_B has 2 levels as you've said)
>>
>> list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2),nu=2.002)))
>>
>> that's for start, then have a look at mcmc-series plots to see if it mixes
>> well and tweak your model further if necessary.
>>
>> Cheer
>> szymek
>
> -- 
> Dr. Maria Paola Bissiri
>
> TU Dresden
> Fakult?t Elektrotechnik und Informationstechnik
> Institut f?r Akustik und Sprachkommunikation
> 01062 Dresden
>
> Barkhausen-Bau, Raum S54
> Helmholtzstra?e 18
>
> Tel: +49 (0)351 463-34283
> Fax: +49 (0)351 463-37781
> E-Mail: Maria_Paola.Bissiri at tu-dresden.de
> http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From M.Fairbrother at bristol.ac.uk  Thu Nov 14 20:30:42 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 14 Nov 2013 19:30:42 +0000
Subject: [R-sig-ME] Plotting residuals for GLMER model and zero counts
Message-ID: <CAAH-yP8-moCAF-HXV85fQVWLsCsJtwy_UdQsOJ0tOrT-co3JMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131114/bb85ff5d/attachment.pl>

From bbolker at gmail.com  Thu Nov 14 20:37:17 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Nov 2013 14:37:17 -0500
Subject: [R-sig-ME] Plotting residuals for GLMER model and zero counts
In-Reply-To: <CAAH-yP8-moCAF-HXV85fQVWLsCsJtwy_UdQsOJ0tOrT-co3JMA@mail.gmail.com>
References: <CAAH-yP8-moCAF-HXV85fQVWLsCsJtwy_UdQsOJ0tOrT-co3JMA@mail.gmail.com>
Message-ID: <5285266D.3080106@gmail.com>

  At present this is only in the development (1.1-1) version, which is
on Github.  If you have development tools (compiler etc.) installed, then

library(devtools)
install_packages("lme4",user="lme4")

  If not, there may be binaries at
http://lme4.r-forge.r-project.org/repos (I don't remember ...)

  cheers
    Ben


On 13-11-14 02:30 PM, Malcolm Fairbrother wrote:
> Dear Ben,
> 
> I was looking at the nifty code you sent around on 6 Nov (see below),
> but on my system I'm getting stuck at:
> 
>> s <- simulate(form[-2],  ## use one-sided formula
> +     newdata=d,
> +     newparams=params,
> +     family=binomial)
> Error in UseMethod("simulate") : 
>   no applicable method for 'simulate' applied to an object of class
> "formula"
> 
> I just checked, and I think I've got the latest version of lme4
> (lme4_1.0-5, right?). I presume I'm missing something simple...?
> 
> Thanks,
> Malcolm
> 
> 
> 
> 
> 
>     Date: Wed, 6 Nov 2013 21:33:20 +0000 (UTC)
>     From: Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>
>     To: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     Subject: Re: [R-sig-ME] Plotting residuals for GLMER model and zero
>             counts
>     Message-ID: <loom.20131106T221303-818 at post.gmane.org
>     <mailto:loom.20131106T221303-818 at post.gmane.org>>
>     Content-Type: text/plain; charset=us-ascii
> 
>     Francesco <fbromano at ...> writes:
> 
>     > Dear R-ers,
>     >
>     > although a number of options exist out there to plot logit models, I
>     > can't seem
>     > to find one that works for glmer. What I would like to do is, in
>     light of
>     > having found no interaction between the two fixed effects (which
>     answers my
>     > research question), look at a plot to tell how well the model fits
>     the data.
>     >
>     > The package LMERconveniencefunctions ver 2.0
>     > has a nice plot for lmer but this won't work on my model because R
>     > automatically
>     > asks me to use glmer. It has a factor DV (Correct), two fixed
>     factor IVs
>     > (Group and Syntax),
>     > and two random effect (ID and item).
>     >
>     > Here's the output of calling:
>     >
>     > model<- glmer(Correct ~ Group * Syntax + (Syntax + 1 | ID) +
>     (Group + 1
>     > | item), data=...., family=binomial)
> 
>     I was going to ask you to please generate a (small) reproducible example
>     (e.g. see http://tinyurl.com/reproducible-000 ), but I couldn't resist
>     the urge to show off a new feature of the development branch of lme4,
>     which is that you can use simulate() with a regular (g)lmer formula
>     to simulate data corresponding to a given mixed model ...
> 
>     library(lme4)
>     set.seed(101)
>     ## generate factorial combinations
>     d <- expand.grid(Group=c("ns","nns"),Syntax=c("'s","of"),
>           ID =factor(1:38),item=factor(1:16))
>     ## subsample randomly down to actual data size
>     d <- d[sample(nrow(d),size=451),]
>     ## check ...
>     with(d,table(interaction(Group,Syntax)))
>     ## parameters (approximated from your output)
>     params <- list(fixef=c(-9,-2,5,-1.5),theta=c(7,-1,7,3,-0.5,6))
>     form <- Correct ~ Group * Syntax + (Syntax + 1 | ID) + (Group + 1| item)
>     s <- simulate(form[-2],  ## use one-sided formula
>         newdata=d,
>         newparams=params,
>         family=binomial)
>     ## turn response into a factor
>     d$Correct <- factor(s[[1]],labels=c("InC","Cor"))
>     fit1 <- glmer(Correct ~ Group * Syntax +
>         (Syntax + 1 | ID) + (Group + 1| item),
>         data=d,
>         family=binomial)
>     dAug <- data.frame(d,res=residuals(fit1,"pearson"))
>     library(lattice)
>     plot(fit1)  ## the default plot is not too useful
>     ## or
>     bwplot(res~Group:Syntax,data=dAug)
>     plot(fit1,Group:Syntax~resid(.))
>     ## how bad does the fit get if we leave out the interaction?
>     fit2 <- update(fit1,.~.-Group:Syntax)
>     plot(fit2,Group:Syntax~resid(.))
>     anova(fit1,fit2)
>     ## you can also separate by item etc. pretty easily ...
>     plot(fit2,Group:Syntax~resid(.)|item)
>


From T.Pennell at sussex.ac.uk  Fri Nov 15 11:06:23 2013
From: T.Pennell at sussex.ac.uk (Tanya Pennell)
Date: Fri, 15 Nov 2013 10:06:23 +0000
Subject: [R-sig-ME] MCMCglmm - Random effect prior specification
Message-ID: <B42E84E7-4638-42CC-B074-B338DA3BB881@sussex.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131115/b1a0650b/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Nov 15 20:29:37 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 15 Nov 2013 20:29:37 +0100
Subject: [R-sig-ME] lmList from lme4 on grouped data objects
In-Reply-To: <loom.20131113T161338-709@post.gmane.org>
References: <077E31A57DA26E46AB0D493C9966AC730D91FE4BD8@UM-MAIL4112.unimaas.nl>
	<loom.20131113T161338-709@post.gmane.org>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D9215A2A9@UM-MAIL4112.unimaas.nl>

Ah, did not realize that (in principle) it is already doing as.data.frame(). Unfortunately, I don't have a solution to the issue mentioned. But a note in the docs is certainly useful.

Best,
Wolfgang

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Wednesday, November 13, 2013 16:19
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lmList from lme4 on grouped data objects
> 
> Viechtbauer Wolfgang (STAT <wolfgang.viechtbauer at ...> writes:
> 
> >
> > Dear lme4-Maintainers,
> >
> > As far as I can tell, lmList() from lme4 does not
> > play nicely with grouped data objects from the nlme package. Example:
> >
> > library(lme4)
> > data(Orthodont, package="nlme")
> >
> > class(Orthodont)
> >
> > ### [1] "nfnGroupedData" "nfGroupedData"  "groupedData"    "data.frame"
> >
> > res <- lmList(distance ~ age | Subject, data=Orthodont)
> >
> > ### Error in eval(expr, envir, enclos) : object 'Subject' not found
> > ### In addition: Warning message:
> > ### In Ops.ordered(age, Subject) : '|' is not
> > meaningful for ordered factors
> >
> > Orthodont <- as.data.frame(Orthodont)
> >
> > res <- lmList(distance ~ age | Subject, data=Orthodont)
> >
> > ### works
> >
> > This had me stumped for a while, so I figured I would note this here (in
> case anybody else runs into this
> > issue). After googling a bit, I found:
> >
> > https://github.com/lme4/lme4/blob/master/tests/lmList.R
> >
> > so nothing really new here. But maybe add a check
> >  to lmList() whether somebody specifies a grouped data
> > object and turn it into a regular data frame?
> 
> 
>   This is a good point. The code of lmList actually has a
> line converting the 'data' argument via 'as.data.frame', but
> it doesn't work! The reason is a bit subtle -- lmList constructs
> its model frame by modifying the call and evaluating it in the
> parent frame, so that modifications to 'data' within the function
> itself get lost ...  I'm not currently sure of the best way to
> fix this, so in the meantime I'm adding a comment to the documentation.
> 
> There are still some open issues with lmList: in particular, it
> doesn't play nicely with the nlme accessor methods:
> 
> https://github.com/lme4/lme4/issues/26
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From geralttee at gmail.com  Fri Nov 15 21:47:35 2013
From: geralttee at gmail.com (Szymek Drobniak)
Date: Fri, 15 Nov 2013 21:47:35 +0100
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
Message-ID: <CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131115/99c44607/attachment.pl>

From jake987722 at hotmail.com  Sat Nov 16 00:49:27 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 15 Nov 2013 16:49:27 -0700
Subject: [R-sig-ME] reference for standard error of estimated variance
	components
In-Reply-To: <CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>,
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>,
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>,
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
Message-ID: <BAY172-W226F5A9F20AF21B1BAC31ECBFB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131115/6e49e9c2/attachment.pl>

From john.maindonald at anu.edu.au  Sat Nov 16 02:10:45 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 16 Nov 2013 01:10:45 +0000
Subject: [R-sig-ME] reference for standard error of estimated
	variance	components
In-Reply-To: <BAY172-W226F5A9F20AF21B1BAC31ECBFB0@phx.gbl>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>,
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>, 
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>,
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
	<BAY172-W226F5A9F20AF21B1BAC31ECBFB0@phx.gbl>
Message-ID: <0065DF1E-2882-4EB3-975E-D08641F77760@anu.edu.au>

See help(mcmcsamp), which tells you that mcmcsamp() is no
longer available, but gives a number of other recourses. For
example:

> library(DAAG)
> science1.lmer <- lmer(like ~ sex + PrivPub + (1:school:class), data=science, na.action=na.exclude)
> confint(science1.lmer)
Computing profile confidence intervals ...
> round(confint(science1.lmer), 2)
Computing profile confidence intervals ...
              2.5 % 97.5 %
.sig01         0.42   0.71
.sigma         1.68   1.82
(Intercept)    4.40   5.04
sexm          -0.01   0.37
PrivPubpublic  0.05   0.78

These are in the same ballpark as the estimates we gave in
'Data Analysis & Graphics Using R', CUP, 3rd edn 2010, p.316,
using mcmcsamp():

Compare
> round(confint(science1.lmer)[1:2,]^2, 2)  ## Convert to variances
Computing profile confidence intervals ...
       2.5 % 97.5 %
.sig01  0.18   0.51
.sigma  2.83   3.30

with mcmcsamp(), from a pre-1.0 version of lme4    
   0.148 0.43
   2.84   3.28

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 16/11/2013, at 10:49 AM, Jake Westfall <jake987722 at hotmail.com> wrote:

> Hi all,
> 
> Wondering if anyone knew off the top of their head, or could very quickly locate, a reference describing how to compute the variance/standard error of a variance component as, e.g., estimated by lmer(). I am fully aware that this might not be a very sensible thing to do because we strongly expect for the distribution of these estimates to be asymmetric and etc. Let me explain my motivation.
> 
> I am interested in these standard errors for purely for troubleshooting purposes; specifically, helping diagnose situations where we have a bad model specification given the data at hand. I find that in many situations, particularly those involving crossed random effects, lmer() happily provides estimates for models that include certain variance components that we know are in-principle inestimable given the structure of the dataset.
> 
> For example, random factors A and B are crossed, but there is only 1 observation at each level of the crossing, so the A*B variance is confounded with the residual variance, yet lmer() lists distinct estimates for A*B variance and residual variance. Another example: random A and random B are crossed, but B is nested in fixed X, yet somehow lmer() will provide estimates for both the random A*X interaction (which can be estimated fine) and also a random B*X interaction (which cannot be). 
> 
> Furthermore, there is no error message indicating that anything fishy is going on in these cases, and the estimated variances even look rather sensible (I suspect it is doing something like double-counting random terms that are confounded and thus providing similar but non-identical estimates for the two confounded variances, but I don't know). So a less experienced user may never get any clue that the model does not make sense given the data. (FYI, I report this behavior using lme4 version < 1.0, and have not yet verified on version > 1.0, but my understanding is that if anything the newer lme4 functions tend to provide *fewer* warnings and errors rather than more, so I would be pretty surprised if everything blows up the way it really ought to with these models in the newest versions.)
> 
> My suspicion is that if one were to compute the standard errors of the confounded variance components, they would be unreasonably large, and this might serve as the only obvious clue to many users that all is not well. So I want to try this to see if it works as a reasonably informative indicator of model misspecification.
> 
> I was sure I would be able to find the variance formula I needed from Littell et al. "SAS System for Mixed Models," but no luck so far. Googling has also not turned it up yet, although some searching remains to be done. So I thought I would ask here to see if any of you had leads. 
> 
> Jake 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From bbolker at gmail.com  Sat Nov 16 02:43:32 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 15 Nov 2013 20:43:32 -0500
Subject: [R-sig-ME] reference for standard error of estimated variance
 components
In-Reply-To: <0065DF1E-2882-4EB3-975E-D08641F77760@anu.edu.au>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>,
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>,
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>,
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>	<BAY172-W226F5A9F20AF21B1BAC31ECBFB0@phx.gbl>
	<0065DF1E-2882-4EB3-975E-D08641F77760@anu.edu.au>
Message-ID: <5286CDC4.30008@gmail.com>


  Another option for diagnosing problems with the fit is to
compute the Hessian of the variance-covariance parameters, which
are fitted with a Cholesky-factor parameterization ... this
doesn't actually get you the uncertainty of the variance-covariance
matrices, but it gives something that is arguably more useful.
https://github.com/lme4/lme4/issues/120 has some useful machinery
written by Rune Haubo which we eventually hope to integrate into
the package.

  This should be a lot cheaper than likelihood profiling too
(takes only O(p^2) function evaluations where p is the number
of model parameters)

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
dd <- update(fm1,devFunOnly=TRUE)
library(numDeriv)
h <- hessian(dd,getME(fm1,"theta"))

Various diagnostics:

rcond(h)
diag(solve(h))

On 13-11-15 08:10 PM, John Maindonald wrote:
> See help(mcmcsamp), which tells you that mcmcsamp() is no longer
> available, but gives a number of other recourses. For example:
> 
>> library(DAAG) science1.lmer <- lmer(like ~ sex + PrivPub +
>> (1:school:class), data=science, na.action=na.exclude) 
>> confint(science1.lmer)
> Computing profile confidence intervals ...
>> round(confint(science1.lmer), 2)
> Computing profile confidence intervals ... 2.5 % 97.5 % .sig01
> 0.42   0.71 .sigma         1.68   1.82 (Intercept)    4.40   5.04 
> sexm          -0.01   0.37 PrivPubpublic  0.05   0.78
> 
> These are in the same ballpark as the estimates we gave in 'Data
> Analysis & Graphics Using R', CUP, 3rd edn 2010, p.316, using
> mcmcsamp():
> 
> Compare
>> round(confint(science1.lmer)[1:2,]^2, 2)  ## Convert to variances
> Computing profile confidence intervals ... 2.5 % 97.5 % .sig01  0.18
> 0.51 .sigma  2.83   3.30
> 
> with mcmcsamp(), from a pre-1.0 version of lme4 0.148 0.43 2.84
> 3.28
> 
> John Maindonald             email: john.maindonald at anu.edu.au phone :
> +61 2 (6125)3473    fax  : +61 2(6125)5549 Centre for Mathematics &
> Its Applications, Room 1194, John Dedman Mathematical Sciences
> Building (Building 27) Australian National University, Canberra ACT
> 0200.
> 
> 
> On 16/11/2013, at 10:49 AM, Jake Westfall <jake987722 at hotmail.com>
> wrote:
> 
>> Hi all,
>> 
>> Wondering if anyone knew off the top of their head, or could very
>> quickly locate, a reference describing how to compute the
>> variance/standard error of a variance component as, e.g., estimated
>> by lmer(). I am fully aware that this might not be a very sensible
>> thing to do because we strongly expect for the distribution of
>> these estimates to be asymmetric and etc. Let me explain my
>> motivation.
>> 
>> I am interested in these standard errors for purely for
>> troubleshooting purposes; specifically, helping diagnose situations
>> where we have a bad model specification given the data at hand. I
>> find that in many situations, particularly those involving crossed
>> random effects, lmer() happily provides estimates for models that
>> include certain variance components that we know are in-principle
>> inestimable given the structure of the dataset.
>> 
>> For example, random factors A and B are crossed, but there is only
>> 1 observation at each level of the crossing, so the A*B variance is
>> confounded with the residual variance, yet lmer() lists distinct
>> estimates for A*B variance and residual variance. Another example:
>> random A and random B are crossed, but B is nested in fixed X, yet
>> somehow lmer() will provide estimates for both the random A*X
>> interaction (which can be estimated fine) and also a random B*X
>> interaction (which cannot be).
>> 
>> Furthermore, there is no error message indicating that anything
>> fishy is going on in these cases, and the estimated variances even
>> look rather sensible (I suspect it is doing something like
>> double-counting random terms that are confounded and thus providing
>> similar but non-identical estimates for the two confounded
>> variances, but I don't know). So a less experienced user may never
>> get any clue that the model does not make sense given the data.
>> (FYI, I report this behavior using lme4 version < 1.0, and have not
>> yet verified on version > 1.0, but my understanding is that if
>> anything the newer lme4 functions tend to provide *fewer* warnings
>> and errors rather than more, so I would be pretty surprised if
>> everything blows up the way it really ought to with these models in
>> the newest versions.)
>> 
>> My suspicion is that if one were to compute the standard errors of
>> the confounded variance components, they would be unreasonably
>> large, and this might serve as the only obvious clue to many users
>> that all is not well. So I want to try this to see if it works as a
>> reasonably informative indicator of model misspecification.
>> 
>> I was sure I would be able to find the variance formula I needed
>> from Littell et al. "SAS System for Mixed Models," but no luck so
>> far. Googling has also not turned it up yet, although some
>> searching remains to be done. So I thought I would ask here to see
>> if any of you had leads.
>> 
>> Jake [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From stgries at gmail.com  Sat Nov 16 03:30:26 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Fri, 15 Nov 2013 18:30:26 -0800
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and different
	AIC-values
Message-ID: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>

Hi

I am trying to do a mixed-effects model analysis on data that were
published with a repeated-measures ANOVA as follows:

summary(aov(OVERLAParcsine ~ USED*SAMPLE + Error(NAME/(USED*SAMPLE))))

In order to first determine the required random-effects structure, I
created the following two models:

m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
(USED*SAMPLE|NAME), REML=TRUE)
m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
(USED+SAMPLE|NAME), REML=TRUE)

The problems begin when I try to find out which model accounts for the
data better:
> anova(m.01a.reml, m.01b.reml, test="F")
Data:
Models:
m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
           Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
m.01b.reml 13 -144.74 -115.139 85.368  -170.74
m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
Warning message:
In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded

So, there are negative AIC values. Ok, according to
<http://r.789695.n4.nabble.com/Negative-AIC-td899943.html> and
<http://emdbolker.wikidot.com/faq> this may not be real problematic so
I would go with m.01b.reml because its AIC value is smaller. But the
remaining values are of course also strange, with Chisq=0 because of
the negative difference of the deviance values.

Now, I also used AIC on the models and get results that are different
from the anova comparison above:

> AIC(m.01b.reml)
[1] -120.4052
> AIC(m.01a.reml)
[1] 20.96197

So, two questions:

(i) which AIC-values are correct - anova or AIC?
(ii) so I can't do a p-value based test on which model to use?

Thanks,
STG
--
Stefan Th. Gries
-----------------------------------------------
University of California, Santa Barbara
http://www.linguistics.ucsb.edu/faculty/stgries


From j.hadfield at ed.ac.uk  Sat Nov 16 08:50:12 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 16 Nov 2013 07:50:12 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
Message-ID: <20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>

Hi Szymek,

Whoops  - I forgot it was dichotomous. idh(X):Y is probably more  
appropriate. (1+x) fits two effects; a) Y effects for the first level  
of X and b) the difference between Y effects between the two levels.   
If X was continous it would make more sense because it would be  
intercept and slope.

Cheers,

Jarrod


Quoting Szymek Drobniak <geralttee at gmail.com> on Fri, 15 Nov 2013  
21:47:35 +0100:

> Hello,
>
> thank you Jarrod for clarifying things, I obviously made a mistake with the
> nu value. I was also wondering - what is the interpretation of idh(1+X):Y
> in case X is a dichotomous variable?
>
> Cheers,
> sz.
>
>
> On 14 November 2013 18:23, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Maria,
>>
>> random = ~us(1):subj_ID + us(fin_B):subj_ID  is the same as
>> idh(1+finB):subj_ID and is not the same as (1 + fin_B|subj_ID) in lmer
>> because the idh fixes the covariance between and intercepts and slopes to
>> zero.  us(1+finB):subj_ID is equivalent to the lmer code.
>>
>> Also, a prior of nu=2 (or nu=2.002) could have quite an influence on your
>> posterior. V=diag(2) and nu=1.002 for the 2x2 case gives a marginal prior
>> on the variances that is equivalent to an inverse gamma with shape and
>> scale equal to 0.001. This prior used to be used a lot, but has some bad
>> properties when values close to zero have support. I often use the
>> parameter expanded prior:
>>
>> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)
>>
>> where a is something large.
>>
>> There is no difference between nu and n.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>
>>> And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>> us(fin_B):subj_ID.
>>>
>>
>>
>>  Quoting Maria Paola Bissiri <Maria_Paola.Bissiri at tu-dresden.de> on Thu,
>> 14 Nov 2013 15:06:26 +0000:
>>
>>  Dear Szymek,
>>> thank you very much for your answer.
>>>
>>> Yes, the random effects were indicated wrongly in MCMCglmm! My intention
>>> is of course to look at variance associated with subjects (subj_ID).
>>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>> And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>> us(fin_B):subj_ID.
>>> Please, correct me if I am wrong.
>>>
>>> So the model runs with:
>>> k <- length(levels(fallmid$resp_X))
>>> I <- diag(k-1)
>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>> prior <- list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
>>>                  G = list(G1 = list(V = diag(1), n = 2), G2 = list(V =
>>> diag(2), n = 2)))
>>>
>>> fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +
>>> lang * fin_B,
>>>                              random = ~us(1):subj_ID + us(fin_B):subj_ID,
>>>                              family="categorical", data=fallmid,
>>>                              prior=prior
>>>                              )
>>>
>>> In your suggestion you indicate nu=2.002. What does "nu" mean? What is
>>> the difference between nu and n? In the MCMCglmm manual and in the tutorial
>>> they are both defined as "degrees of belief". What does this mean?
>>>
>>> Kind regards,
>>> Maria Paola
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Zitat von Szymek Drobniak <geralttee at gmail.com>:
>>>
>>>  Dear Maria,
>>>>
>>>> I'm not sure what exactly you're trying to test with your model, but to
>>>> start with - your prior specification assumes 2 random effects, and your
>>>> model has only one (a structured covariance matrix with fin_B defined as
>>>> a
>>>> random effect). This specification you've provided is similar to a random
>>>> intercept/slope model - but I can't see why you would like to fit it
>>>> (most
>>>> importantly, you assumed that fin_B is both a fixed and random effect).
>>>> If
>>>> your intention was to look at variance associated with subjects
>>>> (subj_ID),
>>>> and you'd like to see if this variance is heterogeneous for different
>>>> levels of fin_B - you could fit:
>>>>
>>>> MCMCglmm(your_fixed_formula_here, random=~us(fin_B):subj_ID, ...)
>>>>
>>>> and the prior would be (assuming fin_B has 2 levels as you've said)
>>>>
>>>> list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2),nu=2.002)))
>>>>
>>>> that's for start, then have a look at mcmc-series plots to see if it
>>>> mixes
>>>> well and tweak your model further if necessary.
>>>>
>>>> Cheer
>>>> szymek
>>>>
>>>
>>> --
>>> Dr. Maria Paola Bissiri
>>>
>>> TU Dresden
>>> Fakult?t Elektrotechnik und Informationstechnik
>>> Institut f?r Akustik und Sprachkommunikation
>>> 01062 Dresden
>>>
>>> Barkhausen-Bau, Raum S54
>>> Helmholtzstra?e 18
>>>
>>> Tel: +49 (0)351 463-34283
>>> Fax: +49 (0)351 463-37781
>>> E-Mail: Maria_Paola.Bissiri at tu-dresden.de
>>> http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Szymon Drobniak, PhD. || Population Ecology Group
> Institute of Environmental Sciences, Jagiellonian University
> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
> szymek.drobniak at uj.edu.pl
> www.eko.uj.edu.pl/drobniak
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Nov 16 09:08:48 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 16 Nov 2013 08:08:48 +0000
Subject: [R-sig-ME] MCMCglmm - Random effect prior specification
In-Reply-To: <B42E84E7-4638-42CC-B074-B338DA3BB881@sussex.ac.uk>
References: <B42E84E7-4638-42CC-B074-B338DA3BB881@sussex.ac.uk>
Message-ID: <20131116080848.15975styuqhjvvgg@www.staffmail.ed.ac.uk>

Hi Tanya,

The warning is because MCMCglmm augments the data set with missing  
data for missing combinations of rep/sex. This is just an algorithmic  
trick to keep the effects balanced and therefore easier to Gibbs  
sample. It is not an warning the user really has to worry about.

However, if the rep 1 in males and females have no connection, except  
by name, do you really expect their to be a between-sex covariance in  
their effects. If not, probably better to use idh(sex):rep.

However, with so few reps it will not be possible to get precise  
estimates of the variance of their effects, and the posterior will be  
sensitive to alternate prior specifications. That being said, if the  
rep effects are not of immediate interest this might not impact on the  
rest of the analysis. You could also fit them as fixed effects.


Autocorrelation is not an issue per se, it just means you have to  
collect more samples to get the same reduction in Monte Carlo error.  
You should focus on the effective sample size and aim to get something  
in the region of 1-2 thousand effective samples.

Cheers,

Jarrod



Quoting Tanya Pennell <T.Pennell at sussex.ac.uk> on Fri, 15 Nov 2013  
10:06:23 +0000:

> Hi,
>
> I'm currently running an MCMCglmm for a data set of male and female  
> fitness within 100 genetic fly lines.
>
> For each line, I have 4 female data points and 6 male data points.
>
> Each data point represents the average fitness of that sex in each  
> replicate (note that reps are labelled 1-4 for females and 1-6 for  
> males, and each rep for the sexes was carried out at different times  
> - i.e. rep 1 female was done at a different time to rep 1 male).
>
> For the model, I therefore need to incorporate replicate by sex as a  
> random effect:
>
> prior.model.2<-list(R=list(V=matrix(c(400,0,0,600),2,2),  
> nu=0.01),G=list (G1=list(V=matrix(c(400,0,0,600),2,2), nu=2,  
> alpha.mu=c(0,0), alpha.V=matrix(c(400,0,0,600),2,2),  
> G2=list(V=matrix(c(400,0,0,600),2,2), nu=2, alpha.mu=c(0,0),  
> alpha.V=matrix(c(400,0,0,600),2,2))))
>
>
> model.2 <- MCMCglmm(S_relative_fec ~ sex-1, random=~us(sex):line +  
> us(sex):rep,rcov=~idh(sex):units, family="gaussian", nitt = 100000,  
> burnin = 30000, thin=30, data = h100newdata, prior = prior.model.2,  
> verbose = FALSE)
>
>
> However, when I run this model I get the following warning message:  
> 'some combinations in us(sex):rep do not exist and 2 missing records  
> have been generated'
>
> The autocorrelation for female rep and units is also very high
>
> Does anyone know how I can correct the model or prior to change this?
>
> Many thanks,
> Tanya
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From webbe at ufl.edu  Sat Nov 16 16:23:03 2013
From: webbe at ufl.edu (Elizabeth Webb)
Date: Sat, 16 Nov 2013 10:23:03 -0500
Subject: [R-sig-ME] lognormal bias correction with nested random effects
Message-ID: <CAJ4DX-uzg6UtHUbzo_DJ_pCyM=ZYQdd2jqvkLnDnwc6MsjXK4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131116/8d705c89/attachment.pl>

From bbolker at gmail.com  Sat Nov 16 18:36:01 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Nov 2013 12:36:01 -0500
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
 different AIC-values
In-Reply-To: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
Message-ID: <5287AD01.5040904@gmail.com>

On 13-11-15 09:30 PM, Stefan Th. Gries wrote:
> Hi
> 
> I am trying to do a mixed-effects model analysis on data that were
> published with a repeated-measures ANOVA as follows:
> 
> summary(aov(OVERLAParcsine ~ USED*SAMPLE + Error(NAME/(USED*SAMPLE))))
> 
> In order to first determine the required random-effects structure, I
> created the following two models:
> 
> m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
> (USED*SAMPLE|NAME), REML=TRUE)
> m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
> (USED+SAMPLE|NAME), REML=TRUE)
> 
> The problems begin when I try to find out which model accounts for the
> data better:
>> anova(m.01a.reml, m.01b.reml, test="F")
> Data:
> Models:
> m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
> m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
>            Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> m.01b.reml 13 -144.74 -115.139 85.368  -170.74
> m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
> Warning message:
> In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 
> So, there are negative AIC values. Ok, according to
> <http://r.789695.n4.nabble.com/Negative-AIC-td899943.html> and
> <http://emdbolker.wikidot.com/faq> this may not be real problematic so
> I would go with m.01b.reml because its AIC value is smaller. But the
> remaining values are of course also strange, with Chisq=0 because of
> the negative difference of the deviance values.

  I'm not sure about that, it looks like it *might* be a glitch in the
display.  Do the results of anova(m.01b.reml, m.01a.reml) look more
sensible?

> 
> Now, I also used AIC on the models and get results that are different
> from the anova comparison above:
> 
>> AIC(m.01b.reml)
> [1] -120.4052
>> AIC(m.01a.reml)
> [1] 20.96197
> 
> So, two questions:
> 
> (i) which AIC-values are correct - anova or AIC?

see http://glmm.wikidot.com/faq#error_anova_lmer_AIC:

As pointed out by several users (here, here, and here, for example), the
AICs computed for lmer models in summary and anova are different;
summary uses the REML specification as specified when fitting the model,
while anova always uses REML=FALSE (to safeguard users against
incorrectly using restricted MLs to compare models with different fixed
effect components). (This behavior is slightly overzealous since users
might conceivably be using anova to compare models with different random
effects [although this also subject to boundary effects as described
elsewhere in this document ?])

  Note that the AIC differences are almost identical (140)



> (ii) so I can't do a p-value based test on which model to use?

 Well, anova() gave you a likelihood ratio test (based on a ML
refitting, which is not necessarily what you want: see
https://github.com/lme4/lme4/issues/141 ).

  I would say that the bottom line here is that since the more complex
model m.01b.reml is about 60 log-likelihood units (or "REML criterion
units") better, it doesn't really matter what test you do -- the more
complex model is overwhelmingly better.

> 
> Thanks,
> STG
> --
> Stefan Th. Gries
> -----------------------------------------------
> University of California, Santa Barbara
> http://www.linguistics.ucsb.edu/faculty/stgries
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From stgries at gmail.com  Sat Nov 16 18:52:37 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sat, 16 Nov 2013 09:52:37 -0800
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
	different AIC-values
In-Reply-To: <5287AD01.5040904@gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
Message-ID: <CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>

Hi

BB> I'm not sure about that, it looks like it *might* be a glitch in
the display.  Do the results of anova(m.01b.reml, m.01a.reml) look
more sensible?
The results of the two anova functions are the same (and come with warnings):

> anova(m.01a.reml, m.01b.reml) # one order
Data:
Models:
m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
           Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
m.01b.reml 13 -144.74 -115.139 85.368  -170.74
m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
Warning message:
In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded

> anova(m.01b.reml, m.01a.reml) # other order
Data:
Models:
m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
           Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
m.01b.reml 13 -144.74 -115.139 85.368  -170.74
m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
Warning message:
In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function
evaluations exceeded

BB> As pointed out by several users (here, here, and here, for
example), the AICs computed for lmer models in summary and anova are
different; summary uses the REML specification as specified when
fitting the model, while anova always uses REML=FALSE
Ah ok, I did not know that. I do not get any AIC-values though from
the summary output:

> summary(m.01a.reml) # one model
Linear mixed model fit by REML ['lmerMod']
Formula: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)

REML criterion at convergence: -13.038

Random effects:
 Groups   Name           Variance Std.Dev. Corr
 NAME     (Intercept)    0.011097 0.10534
          USEDyes        0.026935 0.16412   0.56
          SAMPLE         0.000392 0.01980   0.80  0.17
          USEDyes:SAMPLE 0.005344 0.07310  -0.80 -0.17 -1.00
 Residual                0.003081 0.05551
Number of obs: 72, groups: NAME, 12

Fixed effects:
                         Estimate Std. Error t value
(Intercept)               0.11711    1.54844   0.076
USEDyes                   0.33570    5.61965   0.060
poly(SAMPLE, 2)1          0.41849    8.24332   0.051
poly(SAMPLE, 2)2         -0.03079    0.07850  -0.392
USEDyes:poly(SAMPLE, 2)1  0.55875   30.43556   0.018
USEDyes:poly(SAMPLE, 2)2 -0.25532    0.11102  -2.300

Correlation of Fixed Effects:
                 (Intr) USEDys p(SAMPLE,2)1 p(SAMPLE,2)2 USED:(SAMPLE,2)1
USEDyes          -1.000
p(SAMPLE,2)1      1.000 -1.000
p(SAMPLE,2)2      0.000  0.000  0.000
USED:(SAMPLE,2)1 -1.000  1.000 -1.000        0.000
USED:(SAMPLE,2)2  0.000  0.000  0.000       -0.707        0.000

> summary(m.01b.reml) # other model
Linear mixed model fit by REML ['lmerMod']
Formula: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)

REML criterion at convergence: -146.4052

Random effects:
 Groups   Name        Variance  Std.Dev.  Corr
 NAME     (Intercept) 1.500e-28 1.225e-14
          USEDyes     8.008e-02 2.830e-01 0.42
          SAMPLE      3.362e-09 5.798e-05 0.42 1.00
 Residual             2.777e-03 5.270e-02
Number of obs: 72, groups: NAME, 12

Fixed effects:
                          Estimate Std. Error t value
(Intercept)               0.117109   0.009852  11.887
USEDyes                   0.335704   0.082629   4.063
poly(SAMPLE, 2)1          0.418488   0.078339   5.342
poly(SAMPLE, 2)2         -0.030790   0.074527  -0.413
USEDyes:poly(SAMPLE, 2)1  0.558745   0.105396   5.301
USEDyes:poly(SAMPLE, 2)2 -0.255317   0.105396  -2.422

Correlation of Fixed Effects:
                 (Intr) USEDys p(SAMPLE,2)1 p(SAMPLE,2)2 USED:(SAMPLE,2)1
USEDyes           0.353
p(SAMPLE,2)1      0.140  0.305
p(SAMPLE,2)2      0.000  0.000  0.000
USED:(SAMPLE,2)1  0.000  0.000 -0.673        0.000
USED:(SAMPLE,2)2  0.000  0.000  0.000       -0.707        0.000

BB> (This behavior is slightly overzealous since users might
conceivably be using anova to compare models with different random
effects [although this also subject to boundary effects as described
elsewhere in this document ?])
Yes, that's what I was trying to do, following some advice in the
literature (I think the Zuur et al. books)

BB> Note that the AIC differences are almost identical (140)
True, the anova one is 123, the separate AIC ones are 140.

BB>  Well, anova() gave you a likelihood ratio test (based on a ML
refitting, which is not necessarily what you want: see
https://github.com/lme4/lme4/issues/141 ).
Ok, I get that now, thanks.

BB> I would say that the bottom line here is that since the more
complex model m.01b.reml is about 60 log-likelihood units (or "REML
criterion units") better, it doesn't really matter what test you do --
the more complex model is overwhelmingly better.
Ok, just to clarify: m.01b.reml is the more complex one:

m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
(USED*SAMPLE|NAME), REML=TRUE)
m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
(USED+SAMPLE|NAME), REML=TRUE)

but so you're saying I should go with m.01a.reml because ... do you
get to the 60 LL units because of

- the REML criterion at convergence: (-13.038 for m.01a.reml and
-146.4052 for m.01b.reml), or
- because of the logLik diff in the anova output?

Thanks so much,
STG
--
Stefan Th. Gries
-----------------------------------------------
University of California, Santa Barbara
http://www.linguistics.ucsb.edu/faculty/stgries


From bbolker at gmail.com  Sat Nov 16 19:10:10 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Nov 2013 13:10:10 -0500
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
 different AIC-values
In-Reply-To: <CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
Message-ID: <5287B502.8070609@gmail.com>

On 13-11-16 12:52 PM, Stefan Th. Gries wrote:
> Hi
> 
> BB> I'm not sure about that, it looks like it *might* be a glitch in
> the display.  Do the results of anova(m.01b.reml, m.01a.reml) look
> more sensible?
> The results of the two anova functions are the same (and come with warnings):
> 
>> anova(m.01a.reml, m.01b.reml) # one order
> Data:
> Models:
> m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
> m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
>            Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> m.01b.reml 13 -144.74 -115.139 85.368  -170.74
> m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
> Warning message:
> In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 
>> anova(m.01b.reml, m.01a.reml) # other order
> Data:
> Models:
> m.01b.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
> m.01a.reml: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
>            Df     AIC      BIC logLik deviance Chisq Chi Df Pr(>Chisq)
> m.01b.reml 13 -144.74 -115.139 85.368  -170.74
> m.01a.reml 17  -21.20   17.503 27.600   -55.20     0      4          1
> Warning message:
> In optwrap(optimizer, devfun, x at theta, lower = x at lower) :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 

  The warnings are unrelated to the anova display; they come from the
ML-refitting done by anova.merMod.

> BB> As pointed out by several users (here, here, and here, for
> example), the AICs computed for lmer models in summary and anova are
> different; summary uses the REML specification as specified when
> fitting the model, while anova always uses REML=FALSE
> Ah ok, I did not know that. I do not get any AIC-values though from
> the summary output:
> 
>> summary(m.01a.reml) # one model
> Linear mixed model fit by REML ['lmerMod']
> Formula: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED * SAMPLE | NAME)
> 
> REML criterion at convergence: -13.038
> 
> Random effects:
>  Groups   Name           Variance Std.Dev. Corr
>  NAME     (Intercept)    0.011097 0.10534
>           USEDyes        0.026935 0.16412   0.56
>           SAMPLE         0.000392 0.01980   0.80  0.17
>           USEDyes:SAMPLE 0.005344 0.07310  -0.80 -0.17 -1.00
>  Residual                0.003081 0.05551
> Number of obs: 72, groups: NAME, 12
> 
> Fixed effects:
>                          Estimate Std. Error t value
> (Intercept)               0.11711    1.54844   0.076
> USEDyes                   0.33570    5.61965   0.060
> poly(SAMPLE, 2)1          0.41849    8.24332   0.051
> poly(SAMPLE, 2)2         -0.03079    0.07850  -0.392
> USEDyes:poly(SAMPLE, 2)1  0.55875   30.43556   0.018
> USEDyes:poly(SAMPLE, 2)2 -0.25532    0.11102  -2.300
> 
> Correlation of Fixed Effects:
>                  (Intr) USEDys p(SAMPLE,2)1 p(SAMPLE,2)2 USED:(SAMPLE,2)1
> USEDyes          -1.000
> p(SAMPLE,2)1      1.000 -1.000
> p(SAMPLE,2)2      0.000  0.000  0.000
> USED:(SAMPLE,2)1 -1.000  1.000 -1.000        0.000
> USED:(SAMPLE,2)2  0.000  0.000  0.000       -0.707        0.000
> 
>> summary(m.01b.reml) # other model
> Linear mixed model fit by REML ['lmerMod']
> Formula: OVERLAParcsine ~ USED * poly(SAMPLE, 2) + (USED + SAMPLE | NAME)
> 
> REML criterion at convergence: -146.4052
> 
> Random effects:
>  Groups   Name        Variance  Std.Dev.  Corr
>  NAME     (Intercept) 1.500e-28 1.225e-14
>           USEDyes     8.008e-02 2.830e-01 0.42
>           SAMPLE      3.362e-09 5.798e-05 0.42 1.00
>  Residual             2.777e-03 5.270e-02
> Number of obs: 72, groups: NAME, 12
> 
> Fixed effects:
>                           Estimate Std. Error t value
> (Intercept)               0.117109   0.009852  11.887
> USEDyes                   0.335704   0.082629   4.063
> poly(SAMPLE, 2)1          0.418488   0.078339   5.342
> poly(SAMPLE, 2)2         -0.030790   0.074527  -0.413
> USEDyes:poly(SAMPLE, 2)1  0.558745   0.105396   5.301
> USEDyes:poly(SAMPLE, 2)2 -0.255317   0.105396  -2.422
> 
> Correlation of Fixed Effects:
>                  (Intr) USEDys p(SAMPLE,2)1 p(SAMPLE,2)2 USED:(SAMPLE,2)1
> USEDyes           0.353
> p(SAMPLE,2)1      0.140  0.305
> p(SAMPLE,2)2      0.000  0.000  0.000
> USED:(SAMPLE,2)1  0.000  0.000 -0.673        0.000
> USED:(SAMPLE,2)2  0.000  0.000  0.000       -0.707        0.000

  Yes, but [I think] AIC() gives you the 'AIC' based on the REML
criterion: -2*(REML criterion)+2*(# parameters) rather than (we can
argue about what it really means)

fm1 <- lmer(Reaction~Days+(Days|Subject),sleepstudy,REML=TRUE)
fm2 <- update(fm1,.~Days+(1|Subject),REML=TRUE)
fm3 <- update(fm1,REML=FALSE)
fm4 <- update(fm2,REML=FALSE)

 AIC(fm1,fm2,fm3,fm4)
    df      AIC
fm1  6 1755.628
fm2  4 1794.465
fm3  6 1763.939
fm4  4 1802.079

I confirm that anova(fm1,fm2); anova(fm2,fm1); anova(fm3,fm4); and
anova(fm4,fm3) all give results that differ only in their labels (all
the numerical values are the same).


> BB> (This behavior is slightly overzealous since users might
> conceivably be using anova to compare models with different random
> effects [although this also subject to boundary effects as described
> elsewhere in this document ?])
> Yes, that's what I was trying to do, following some advice in the
> literature (I think the Zuur et al. books)
> 
> BB> Note that the AIC differences are almost identical (140)
> True, the anova one is 123, the separate AIC ones are 140.
> 
> BB>  Well, anova() gave you a likelihood ratio test (based on a ML
> refitting, which is not necessarily what you want: see
> https://github.com/lme4/lme4/issues/141 ).
> Ok, I get that now, thanks.
> 
> BB> I would say that the bottom line here is that since the more
> complex model m.01b.reml is about 60 log-likelihood units (or "REML
> criterion units") better, it doesn't really matter what test you do --
> the more complex model is overwhelmingly better.
> Ok, just to clarify: m.01b.reml is the more complex one:

  Yes, that's what I said ("the more complex model m.01b.reml is ... 60
log-likelihood units ... better")

> 
> m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
> (USED*SAMPLE|NAME), REML=TRUE)
> m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) +
> (USED+SAMPLE|NAME), REML=TRUE)
> 
> but so you're saying I should go with m.01a.reml because ... do you
> get to the 60 LL units because of

  No, I'm saying you should go with m.01b.reml, because it fits much
better.  The REML criterion (analogous to twice the negative
log-likelihood [or deviance], essentially the "negative restricted
maximum likelihood") is smaller.  The log-likelihood is larger.
> 
> - the REML criterion at convergence: (-13.038 for m.01a.reml and
> -146.4052 for m.01b.reml), or
> - because of the logLik diff in the anova output?
> 
> Thanks so much,
> STG
> --
> Stefan Th. Gries
> -----------------------------------------------
> University of California, Santa Barbara
> http://www.linguistics.ucsb.edu/faculty/stgries
> -----------------------------------------------
>


From stgries at gmail.com  Sat Nov 16 19:12:53 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sat, 16 Nov 2013 10:12:53 -0800
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
	different AIC-values
In-Reply-To: <5287B502.8070609@gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
	<5287B502.8070609@gmail.com>
Message-ID: <CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>

Darn, I made a typo:

> m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) + (USED*SAMPLE|NAME), REML=TRUE)
> m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) + (USED+SAMPLE|NAME), REML=TRUE)

m.01a.reml is the more complex one: both have the same fixed-effects
structure, but the a model has the more complex random-effects
structure. (Reading rest now ...)


From bbolker at gmail.com  Sat Nov 16 19:15:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Nov 2013 13:15:41 -0500
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
 different AIC-values
In-Reply-To: <CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
	<5287B502.8070609@gmail.com>
	<CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>
Message-ID: <5287B64D.9080206@gmail.com>

On 13-11-16 01:12 PM, Stefan Th. Gries wrote:
> Darn, I made a typo:
> 
>> m.01a.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) + (USED*SAMPLE|NAME), REML=TRUE)
>> m.01b.reml <- lmer(OVERLAParcsine ~ USED*poly(SAMPLE, 2) + (USED+SAMPLE|NAME), REML=TRUE)
> 
> m.01a.reml is the more complex one: both have the same fixed-effects
> structure, but the a model has the more complex random-effects
> structure. (Reading rest now ...)
> 

  OK, sorry about the confusion.  It looks like something is wrong with
the optimization of m.01a.reml, since it should always have a higher
likelihood/lower negative log-likelihood than m.01b.reml.  Can you (1) try

  control=lmerControl(optCtrl=list(maxfun=1e5))

and (2) consider sending or posting data?

  Ben


From stgries at gmail.com  Sat Nov 16 19:21:16 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sat, 16 Nov 2013 10:21:16 -0800
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
	different AIC-values
In-Reply-To: <5287B64D.9080206@gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
	<5287B502.8070609@gmail.com>
	<CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>
	<5287B64D.9080206@gmail.com>
Message-ID: <CAFrBz2=hPAMbdZ+JHfn2u0+4FvVHwmUo4LaUmkBUCXLLXKjmbQ@mail.gmail.com>

I am attaching the data and the code separately, trying the code you sent now.
STG

From bbolker at gmail.com  Sun Nov 17 18:36:06 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 17 Nov 2013 12:36:06 -0500
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
 different AIC-values
In-Reply-To: <CAFrBz2=hPAMbdZ+JHfn2u0+4FvVHwmUo4LaUmkBUCXLLXKjmbQ@mail.gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
	<5287B502.8070609@gmail.com>
	<CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>
	<5287B64D.9080206@gmail.com>
	<CAFrBz2=hPAMbdZ+JHfn2u0+4FvVHwmUo4LaUmkBUCXLLXKjmbQ@mail.gmail.com>
Message-ID: <5288FE86.1010606@gmail.com>

On 13-11-16 01:21 PM, Stefan Th. Gries wrote:
> I am attaching the data and the code separately, 
> trying the code you sent now.
> STG
> 

TL;DR It's pretty clear that the full model you're trying to fit is too
complicated, and weird, but it *ought* to fit or at least warn you that
it can't. I will try to work with it a bit and see if we can use it as a
test case for detecting badly fitted models/figure out what's going wrong.

================
  As a start, this model is attempting to fit 10 variance-covariance
parameters to only 72 observations; while I don't know a great rule of
thumb for how big a data set one should have for N var-cov parameters,
it should definitely be *more* conservative than the "10-20 observations
per parameter" rule of thumb (e.g. see Harrell _Regression Modeling
Strategies_) -- var-cov parameters are harder to estimate than location
(fixed-effect) parameters.

  A few other comments:

* using a quadratic effect poly(SAMPLE,2) for a variable with only three
levels (100, 200, 500) seems a bit odd, although I guess the model has
the same number of parameters as if you had just treated SAMPLE as a
factor in the first place (if you treat it as an *ordered* factor then
you will get orthogonal polynomial contrasts by default anyway).

* in general, if you want to correspond to a traditional aov()-style
analysis, you want to use a random effect of the form (1|A/B) rather
than (B|A); if A and B are both categorical, then the first (an
intercept effect at grouping levels A and B-within-A) is different from,
and more parsimonious than, the second (random effects of levels B
across grouping variables A) -- in particular, the latter includes all
the covariances between effects of B.

* the original aov()-style analysis has no room left for residual error:
since the experimental design has a single observation per
NAME:USED:SAMPLE combination (i.e. an unreplicated randomized block
design), using Error(NAME/(USED*SAMPLE)) gives one error value for each
observation -- so when you try to replicate this via

m.01c.reml <- lmer(OVERLAParcsine ~ USED*SAMPLE+
                   (1|NAME/(USED:SAMPLE)),
                   REML=TRUE,data=x)

you get

Error in checkNlevels(reTrms$flist, n = n, control) :
  number of levels of each grouping factor must be < number of observations

This seems to be OK and probably the closest in spirit to the original
aov() analysis.

lmer(OVERLAParcsine ~ USED*SAMPLE+
		   (1|NAME)+(1|NAME:USED)+(1|NAME:SAMPLE),
                   REML=TRUE,data=x,
                   control=lmerControl(check.nobs.vs.rankZ="ignore"))

(I don't know why the rank-Z testing check is giving an error here --
false positive, or this model is really *not* OK but I haven't figured
that out)

  Finally, if possible (i.e. if the denominator of the 'OVERLAP'
variable is known), I would consider a binomial GLMM rather than
trying to transform (e.g. see e.g. Warton and Hui "The arcsine is
asinine" Ecology 2011) ...


From stgries at gmail.com  Sun Nov 17 18:49:14 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sun, 17 Nov 2013 09:49:14 -0800
Subject: [R-sig-ME] Model comparison with anova and AIC: p=0 and
	different AIC-values
In-Reply-To: <5288FE86.1010606@gmail.com>
References: <CAFrBz2mk9z89BsimCFY9Nti9HZPMajOQsBVQBxPYFq94M8pkSQ@mail.gmail.com>
	<5287AD01.5040904@gmail.com>
	<CAFrBz2=PTeBKVCLOYc+vfK+f9Ea+HymWyfT9UPKyh=rP3S9HLQ@mail.gmail.com>
	<5287B502.8070609@gmail.com>
	<CAFrBz2k676ZtOXuCii7MU4JNKy8tG+6BsVdaJy2WADoSpr=MPg@mail.gmail.com>
	<5287B64D.9080206@gmail.com>
	<CAFrBz2=hPAMbdZ+JHfn2u0+4FvVHwmUo4LaUmkBUCXLLXKjmbQ@mail.gmail.com>
	<5288FE86.1010606@gmail.com>
Message-ID: <CAFrBz2mQ-1L-d_USic+MSphSUpTZRwaNOZN+f-LAQnowummmRg@mail.gmail.com>

Thanks a lot for the detailed comments. Here are some first quick
responses before I look into them in more detail:

>   As a start, this model is attempting to fit 10 variance-covariance parameters to only 72 observations; while I don't know a great rule of thumb for how big a data set one should have for N var-cov parameters, it should definitely be *more* conservative than the "10-20 observations per parameter" rule of thumb (e.g. see Harrell _Regression Modeling Strategies_) -- var-cov parameters are harder to estimate than location (fixed-effect) parameters.
Yes, I am aware of Harrell's rule. This is not my data set, I am just
trying to check their aov analysis with lmer

Re polynomial/ordered contrast: yes, that's what I was thinking.
SAMPLE is numeric or at least ordinal so I am not really losing dfs
there, plus the way I understand their data the leveling off that is
shown in an effects plot, for instance, seems to make sense because it
would mean that increasing the sample sizes doesn't increase the dep
var. linearly and ad infinitum.

> * in general, if you want to correspond to a traditional aov()-style analysis, you want to use a random effect of the form (1|A/B) rather than (B|A)
Ok, THAT I will need to read up on, at present that is over my head.

> * the original aov()-style analysis has no room left for residual error: since the experimental design has a single observation per NAME:USED:SAMPLE
Yes, of course.

>   Finally, if possible (i.e. if the denominator of the 'OVERLAP' variable is known), I would consider a binomial GLMM rather than trying to transform (e.g. see e.g. Warton and Hui "The arcsine is asinine" Ecology 2011) ...
Agreed, they could have done a binomial one but they don't report the
data necessary for that. I only did the arcsine for comparability
because they did it. If any transformation, I'd probably have
preferred the logit, but sure, the binomial one would have been best

Again, thanks a lot!
STG
--
Stefan Th. Gries
-----------------------------------------------
University of California, Santa Barbara
http://www.linguistics.ucsb.edu/faculty/stgries


From stgries at gmail.com  Mon Nov 18 03:24:24 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sun, 17 Nov 2013 18:24:24 -0800
Subject: [R-sig-ME] Error with predict.merMod and random slopes
Message-ID: <CAFrBz2kNVbo4u8e3_OkgF2hYVeciCtKMs76anfPpq1CKs4JZYw@mail.gmail.com>

Just a quick follow-up on the thread of

- <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021275.html>
- <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021279.html>
- <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021284.html>

because I ran into the same problem with this:

library(lme4)
example <- read.table(text="
X3 Y3 SPEAKER3
0.00655882 0.004769464 1
0.06138487 0.156728480 1
0.11072831 0.324273036 1
0.16555435 0.550263367 1
0.20119128 0.694429613 1
0.25875863 0.900938019 1
0.30810207 1.049000649 1
0.38485854 1.259405441 1
0.45339109 1.407468071 1
0.50821714 1.497084927 1
0.25327603 -0.006919691 2
0.32454988 0.121661015 2
0.38759984 0.312583881 2
0.49451063 0.515195902 2
0.54933667 0.643776607 2
0.67269528 0.854181398 2
0.81250169 1.134721120 2
0.88103425 1.267198211 2
0.94682550 1.384089761 2
0.72478000 1.010037000 2
0.66995397 0.148935710 3
0.75493434 0.230759795 3
0.90296467 0.374926041 3
0.97697983 0.456750126 3
1.03180588 0.519092287 3
1.13323406 0.647672992 3
1.27578178 0.803528393 3
1.41284689 0.900938019 3
1.51153378 0.986658489 3
0.57949100 0.047629699 3", header=TRUE, sep="")

model.lmer.3c <- lmer(Y3~X3+(X3|SPEAKER3), data=example)
predict(model.lmer.3c, newdata=data.frame(SPEAKER3=3, X3=0.4),
REform=NA) # no problem
#         1
# 0.4808733
predict(model.lmer.3c, newdata=data.frame(SPEAKER3=3, X3=0.4),
REform=NULL) # problem
# Error: sum(nb) == q is not TRUE

HTH,
STG
--
Stefan Th. Gries
-----------------------------------------------
University of California, Santa Barbara
http://www.linguistics.ucsb.edu/faculty/stgries


From gustaf.granath at gmail.com  Mon Nov 18 20:50:25 2013
From: gustaf.granath at gmail.com (Gustaf Granath)
Date: Mon, 18 Nov 2013 14:50:25 -0500
Subject: [R-sig-ME] Set individual variance components to zero in lme
Message-ID: <528A6F81.5080003@gmail.com>

Hi,
Is it possible to set individual variance components in lme() to zero?

For example, say that you have 4 different locations and and you 
estimate individual variance components at each location + separate 
residual variances.

lme( y ~ location, random = ~ 0 + location|plot/plant, data = dat, 
weights = varIdent(form = ~1|location) )

Now I want to test if the plot variance component at location x is 
greater than zero. I can do this by fitting individual models.
lme( y ~ 1, random = ~ 1|plot/plant, data = dat, subset = location=="x" 
)  versus
lme( y ~ 1, random = ~ 1|plant, data = dat, subset = location=="x" )
using a LRT test. However, it would be convenient if it is possible to 
fix individual components to zero in the first model with all locations, 
like the G.param argument can do in asreml-r. It doesnt seem like there 
is an easy way with lme() but maybe someone has tried it?

Cheers

Gustaf

-- 
Gustaf Granath (PhD)
Post doc
McMaster University
School of Geography & Earth Sciences


From e.r.j.wubs at gmail.com  Tue Nov 19 08:50:18 2013
From: e.r.j.wubs at gmail.com (Jasper Wubs)
Date: Tue, 19 Nov 2013 08:50:18 +0100
Subject: [R-sig-ME] Heteroscedasticity and d.f.
Message-ID: <CAHPsBVqZk6t9V+zGw7fLJgOYE3bsd0kk5kf9bGLmLRsDD8tUYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131119/f7c16da2/attachment.pl>

From andrea.onofri at unipg.it  Tue Nov 19 09:39:35 2013
From: andrea.onofri at unipg.it (andrea.onofri at unipg.it)
Date: Tue, 19 Nov 2013 09:39:35 +0100
Subject: [R-sig-ME] non-nested effects in lme
Message-ID: <528b22df.02580e0a.43a3.184f@mx.google.com>

Dear all,

I am trying to fit a simple model, relating to a randomised block design where both blocks (A) and treatments (B) are random effects. Coding in lmer, this model would be: 

model <- lmer(Y ~ 1 + (1|A) + (1|B))

However, I would also like to be able to 'manipulate' the correlation structure and thus I assume I have to revert to the lme function in the nlme package. In other cases I have been able to fit non-nested effects in lme by appropriately using the pdMat construct, but, after several efforts, I do not seem to succeed in this simple case. I would greatly appreciate any hints that puts me in the right direction. I thank you very much in advance.

Regards

Andrea Onofri


From Friso.muijsers at uni-oldenburg.de  Tue Nov 19 10:48:55 2013
From: Friso.muijsers at uni-oldenburg.de (Friso Muijsers)
Date: Tue, 19 Nov 2013 10:48:55 +0100
Subject: [R-sig-ME] non-nested effects in lme
In-Reply-To: <528b22df.02580e0a.43a3.184f@mx.google.com>
References: <528b22df.02580e0a.43a3.184f@mx.google.com>
Message-ID: <528B3407.2050501@uni-oldenburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131119/7e690bb9/attachment.pl>

From AKunick at gmx.de  Tue Nov 19 12:56:20 2013
From: AKunick at gmx.de (Arndt Kunick)
Date: Tue, 19 Nov 2013 12:56:20 +0100 (CET)
Subject: [R-sig-ME] starter values
Message-ID: <trinity-2aad6184-f21b-4437-b415-15da28e6b0bd-1384862180056@3capp-gmx-bs33>

Dear R-user,
I want to fit a nonlinear mixed model with the following formula (see below)

fit1 <- nlmer(kosten ~ SSbiexp(hm, np, A1, lrc1,A2,lrc2) ~ 0 + A1 + lrc1 + A2 + lrc2 +
????????? (0+A1+lrc1+A2+lrc2|j) + (0+A1+lrc1+A2+lrc2|o), start = c(A1 = , lrc1 = , A2 = , lrc2 = ), d))

Thereby I have a problem with determine appropriate starter values for the parameters of the function SSbiexp.
Regarding SSbiexp my questions are:

What is the meaning of the parameters A1, lrc1, A2 and lrc2?
How can I deduce appropriate starter values?
Exists there documentation for self-starter functions in lme4?

I am looking forward to hear from you!

With kind regards,

Anton

?j o hm np kosten
2011 1 1210,9 26 6,5
2011 1 1206,4 7,8 17,3
2011 1 1194,8 3,7 13,7
2011 1 1222 36,5 20,8
2012 1 1210,9 26 9,2
2012 1 1206,4 7,8 22,2
2012 1 1194,8 3,7 18,2
2012 1 1222 36,5 21,3
2011 2 833,6 4 18,8
2011 2 1452,2 8,3 24,9
2011 2 1472,3 42,8 24,5
2011 2 973,4 7,1 25,4
2011 2 852,9 18,4 25,9
2011 2 891,9 20 32,3
2011 2 837 5,4 28,6
2011 2 1084,9 12,6 20,6
2011 2 1149,2 58,2 23,3
2011 2 1140,9 63,1 26,8
2011 2 1589 60,6 29,5
2011 2 1199,7 14,9 19
2012 2 833,6 4 36,3
2012 2 1452,2 8,3 25,2
2012 2 1472,3 42,8 21,9
2012 2 984,1 12,9 24,6
2012 2 852,9 18,4 30,4
2012 2 877,1 16,5 25,1
2012 2 837 5,4 36,4
2012 2 1084,3 13 12,1
2012 2 1149,2 58,2 49,1
2012 2 1136,5 64,3 6
2012 2 1597,7 60,5 49,8
2012 2 1199,7 14,9 18,9
2011 3 1231,3 39,8 24,9
2011 3 1254,7 27,9 37,8
2011 3 1261,3 19 44,8
2011 3 1257,5 14,5 25,1
2011 3 1263,3 29,1 33,3
2012 3 1231,3 39,8 30,3
2012 3 1254,1 28 47,1
2012 3 1261,3 19 41,6
2012 3 1257,5 14,5 29,2
2012 3 1263,3 29,1 34,4
2011 4 1392,8 19,6 8,6
2011 4 1732,4 40,7 39,6
2011 4 1783,9 47,2 54,7
2011 4 1403,1 14,3 19,6
2011 4 1399,5 19,8 16,4
2011 4 1430,1 16,7 16,3
2011 4 1441,4 59,9 55,5
2011 4 1699,6 18,1 56,2
2012 4 1732,4 40,7 95,4
2012 4 1783,9 47,2 91,4
2012 4 1699,6 18,1 65
2011 5 1506,9 33,3 31
2011 5 1539,2 44,6 48,9
2011 5 1529,2 43 29,6
2011 5 1466,3 56,1 44,6
2012 5 1506,9 33,3 31,5
2012 5 1539,2 44,6 61,3
2012 5 1529,9 42,8 40,6
2012 5 1466,3 56,1 48,6
2011 6 1215,6 8,5 14,3
2011 6 1512,5 48,6 34,3
2011 6 1491,5 18,6 12,6
2011 6 1235,7 9 14,8
2011 6 1275,3 40,8 20
2011 6 1344 38,7 25,5
2011 6 1270,6 48,3 31,9
2011 6 1269,9 29,8 21,7
2011 6 1294,4 49,6 36,7
2011 6 1418,4 26,2 27,1
2011 6 1389 39,2 35,8
2012 6 1215,6 8,5 16,8
2012 6 1512,5 48,6 33,3
2012 6 1491,5 18,6 33,3
2012 6 1235,7 9 17,4
2012 6 1275,3 40,8 16,9
2012 6 1344 38,7 19,1
2012 6 1270,6 48,3 23,7
2012 6 1269,9 29,8 19,6
2012 6 1294,4 49,6 24,9
2012 6 1418,4 26,2 22,6
2012 6 1389 39,2 31,2
2011 7 1437,4 65,2 84,2
2011 7 1497,1 76,4 87,2
2012 7 1437,4 65,2 85,3
2012 7 1496,5 75,7 48,7
2012 7 1420,1 62,4 71,8
2012 7 1420,4 75,9 49,9
2011 8 1537,5 3,4 30,9
2011 8 1677,5 29,6 42,1
2011 8 1672,3 28 25,2
2011 8 2071,2 42,3 116,6
2011 8 2079,7 33,1 62
2012 8 1537,5 3,4 28,8
2012 8 1677,5 29,6 50,6
2012 8 1672,3 28 24,5
2012 8 2071,2 42,3 168,1
2012 8 2079,7 33,1 57,9
2011 9 1192 14,3 13,2
2011 9 1195,7 13,6 14,6
2012 10 1385,4 21,4 36,2
2012 10 1608,2 33,3 44
2012 10 1607,8 37 52,4
2012 10 1611,3 41,3 57,9
2012 10 1607,6 46,8 43,3
2012 10 1601,6 33,1 52
2012 10 1741,5 26,2 65
2012 10 1355 24,4 29,7
2012 10 1578,3 31,3 27,9
2012 10 1539,9 37 27,4
2012 10 1567,8 20,3 22,2
2012 10 1585,7 25,8 27,7
2012 10 1560,8 20,1 22,5
2012 10 1617,3 40,3 25,9
2012 10 1578,9 26,8 24,9
2011 11 1443,2 23,9 45
2011 11 1476,4 49,4 47,5
2011 11 2057,4 29,1 135,5
2011 11 2083,8 87,5 338,8
2012 11 1445,7 26 40,7
2012 11 2056,1 26,6 108,7
2012 11 2077,4 73,7 136,4
2011 12 1212,1 51,3 67,4
2011 12 1151,1 63,3 93,3
2011 12 1268,2 44,4 59,9
2011 12 1024,9 60,7 83
2012 12 1212,1 51,3 83,4
2012 12 1151,1 63,3 78,6
2012 12 1268,2 44,4 78,4
2012 12 1024,9 60,7 60
2011 13 1306,2 61,5 34,5
2011 13 1339,2 69,1 52,3
2011 13 1341,4 71,9 66
2011 13 1373,4 71,4 27,6
2011 13 1381,2 65,5 51,2
2011 13 1323,7 65,6 82,9
2012 13 1306,2 61,5 55,6
2012 13 1339,2 69,1 36,4
2012 13 1341,4 71,9 60,4
2012 13 1373,4 71,4 52,3
2012 13 1381,2 65,5 73
2012 13 1323,7 65,6 57,1
2011 14 895,2 11,6 32,1
2011 14 914,9 17,7 27,4
2011 14 946,2 23,5 24,2
2011 14 959,1 28,5 25
2011 14 885,4 7,7 24,8
2011 14 911,2 6,5 18,8
2012 14 895,2 11,6 16,9
2012 14 914,1 17,4 20,7
2012 14 946,2 23,5 22,7
2012 14 959,1 28,5 34,8
2012 14 885,4 7,7 16,7
2012 14 911,2 6,5 15,7
2011 15 812,9 9,5 10,8
2011 16 836,7 30,1 32,5
2011 16 807,3 11,5 24,5
2011 16 823,4 23,6 28,8
2011 16 851,2 23,8 19,3
2011 16 860,6 31,7 28,1
2012 16 836,7 30,1 48,7
2012 16 807,3 11,5 23,8
2012 16 823,4 23,6 34,1
2012 16 851,2 23,8 19,2
2012 16 860,6 31,7 38,3
2011 17 967,6 54,2 36
2011 17 949,2 44,6 31,5
2011 17 942,1 30,3 19,8
2011 17 932,8 10,2 31,6
2011 17 942,4 31,8 36,2
2011 17 1558,8 60,9 99
2012 17 967,6 54,2 33,9
2012 17 949,2 44,6 26
2012 17 942,1 30,3 30,8
2012 17 931,6 11,9 31,4
2012 17 942,4 31,8 39,1
2012 17 1558,8 60,9 128,6
2011 18 1129,1 52,1 102,8
2011 18 1189,9 49,2 103,9
2011 18 1173,4 50,2 127,2
2012 18 1129,1 52,1 68,7
2012 18 1189,9 49,2 54,9
2012 18 1173,4 50,2 119,7
2011 19 1130,6 59,7 65,1
2011 19 1123,9 45,3 40,8
2011 19 1124,6 44,5 49
2011 19 1115,1 46,4 71,7
2011 19 1690,7 60,3 104
2012 19 1130,6 59,7 79
2012 19 1123,3 44,7 53,3
2012 19 1124,6 44,5 58,1
2012 19 1114,3 46,5 48,8
2012 19 1690,7 60,3 60
2011 20 1336,9 29,4 7,8
2011 20 1325,3 39,2 19,2
2011 20 1316,1 53,6 13,5
2011 20 1298 26,6 11
2011 20 1247,5 14,5 18,4
2011 20 1412,1 12,9 14,2
2011 20 1489,4 10,4 31,1
2012 20 1336,9 29,4 15,4
2012 20 1325,3 39,2 26,9
2012 20 1316,1 53,6 21,7
2012 20 1298 26,6 14,7
2012 20 1247,5 14,5 25,5
2012 20 1412,1 12,9 14,4
2012 20 1489,4 10,4 29
?


From a.reynaldi at student.unsw.edu.au  Tue Nov 19 14:15:50 2013
From: a.reynaldi at student.unsw.edu.au (Arnold Reynaldi)
Date: Tue, 19 Nov 2013 13:15:50 +0000
Subject: [R-sig-ME] starter values
In-Reply-To: <trinity-2aad6184-f21b-4437-b415-15da28e6b0bd-1384862180056@3capp-gmx-bs33>
References: <trinity-2aad6184-f21b-4437-b415-15da28e6b0bd-1384862180056@3capp-gmx-bs33>
Message-ID: <62FF4C4E32840642930D994866A29105933390@INFPWXM002.ad.unsw.edu.au>

Hi there,

The model is biexponential decay. So the assumption here is that in your data, you have 2 sub-populations that decay with different rate. A1 is the initial number of your first sub-population and it will decay with a rate of lrc1. On the other hand, A2 is your second initial number of your second sub-population with decay rate of lrc2.

As for the starting value, I believe that SSbiexp will determine the starting value automatically. Just use this code : 

fit1 <- nlmer(kosten ~ SSbiexp(hm, np, A1, lrc1,A2,lrc2) ~ 0 + A1 + lrc1 + A2 + lrc2 +
          (0+A1+lrc1+A2+lrc2|j) + (0+A1+lrc1+A2+lrc2|o), d))
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Arndt Kunick [AKunick at gmx.de]
Sent: Tuesday, November 19, 2013 10:56 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] starter values

Dear R-user,
I want to fit a nonlinear mixed model with the following formula (see below)

fit1 <- nlmer(kosten ~ SSbiexp(hm, np, A1, lrc1,A2,lrc2) ~ 0 + A1 + lrc1 + A2 + lrc2 +
          (0+A1+lrc1+A2+lrc2|j) + (0+A1+lrc1+A2+lrc2|o), start = c(A1 = , lrc1 = , A2 = , lrc2 = ), d))

Thereby I have a problem with determine appropriate starter values for the parameters of the function SSbiexp.
Regarding SSbiexp my questions are:

What is the meaning of the parameters A1, lrc1, A2 and lrc2?
How can I deduce appropriate starter values?
Exists there documentation for self-starter functions in lme4?

I am looking forward to hear from you!

With kind regards,

Anton

 j o hm np kosten
2011 1 1210,9 26 6,5
2011 1 1206,4 7,8 17,3
2011 1 1194,8 3,7 13,7
2011 1 1222 36,5 20,8
2012 1 1210,9 26 9,2
2012 1 1206,4 7,8 22,2
2012 1 1194,8 3,7 18,2
2012 1 1222 36,5 21,3
2011 2 833,6 4 18,8
2011 2 1452,2 8,3 24,9
2011 2 1472,3 42,8 24,5
2011 2 973,4 7,1 25,4
2011 2 852,9 18,4 25,9
2011 2 891,9 20 32,3
2011 2 837 5,4 28,6
2011 2 1084,9 12,6 20,6
2011 2 1149,2 58,2 23,3
2011 2 1140,9 63,1 26,8
2011 2 1589 60,6 29,5
2011 2 1199,7 14,9 19
2012 2 833,6 4 36,3
2012 2 1452,2 8,3 25,2
2012 2 1472,3 42,8 21,9
2012 2 984,1 12,9 24,6
2012 2 852,9 18,4 30,4
2012 2 877,1 16,5 25,1
2012 2 837 5,4 36,4
2012 2 1084,3 13 12,1
2012 2 1149,2 58,2 49,1
2012 2 1136,5 64,3 6
2012 2 1597,7 60,5 49,8
2012 2 1199,7 14,9 18,9
2011 3 1231,3 39,8 24,9
2011 3 1254,7 27,9 37,8
2011 3 1261,3 19 44,8
2011 3 1257,5 14,5 25,1
2011 3 1263,3 29,1 33,3
2012 3 1231,3 39,8 30,3
2012 3 1254,1 28 47,1
2012 3 1261,3 19 41,6
2012 3 1257,5 14,5 29,2
2012 3 1263,3 29,1 34,4
2011 4 1392,8 19,6 8,6
2011 4 1732,4 40,7 39,6
2011 4 1783,9 47,2 54,7
2011 4 1403,1 14,3 19,6
2011 4 1399,5 19,8 16,4
2011 4 1430,1 16,7 16,3
2011 4 1441,4 59,9 55,5
2011 4 1699,6 18,1 56,2
2012 4 1732,4 40,7 95,4
2012 4 1783,9 47,2 91,4
2012 4 1699,6 18,1 65
2011 5 1506,9 33,3 31
2011 5 1539,2 44,6 48,9
2011 5 1529,2 43 29,6
2011 5 1466,3 56,1 44,6
2012 5 1506,9 33,3 31,5
2012 5 1539,2 44,6 61,3
2012 5 1529,9 42,8 40,6
2012 5 1466,3 56,1 48,6
2011 6 1215,6 8,5 14,3
2011 6 1512,5 48,6 34,3
2011 6 1491,5 18,6 12,6
2011 6 1235,7 9 14,8
2011 6 1275,3 40,8 20
2011 6 1344 38,7 25,5
2011 6 1270,6 48,3 31,9
2011 6 1269,9 29,8 21,7
2011 6 1294,4 49,6 36,7
2011 6 1418,4 26,2 27,1
2011 6 1389 39,2 35,8
2012 6 1215,6 8,5 16,8
2012 6 1512,5 48,6 33,3
2012 6 1491,5 18,6 33,3
2012 6 1235,7 9 17,4
2012 6 1275,3 40,8 16,9
2012 6 1344 38,7 19,1
2012 6 1270,6 48,3 23,7
2012 6 1269,9 29,8 19,6
2012 6 1294,4 49,6 24,9
2012 6 1418,4 26,2 22,6
2012 6 1389 39,2 31,2
2011 7 1437,4 65,2 84,2
2011 7 1497,1 76,4 87,2
2012 7 1437,4 65,2 85,3
2012 7 1496,5 75,7 48,7
2012 7 1420,1 62,4 71,8
2012 7 1420,4 75,9 49,9
2011 8 1537,5 3,4 30,9
2011 8 1677,5 29,6 42,1
2011 8 1672,3 28 25,2
2011 8 2071,2 42,3 116,6
2011 8 2079,7 33,1 62
2012 8 1537,5 3,4 28,8
2012 8 1677,5 29,6 50,6
2012 8 1672,3 28 24,5
2012 8 2071,2 42,3 168,1
2012 8 2079,7 33,1 57,9
2011 9 1192 14,3 13,2
2011 9 1195,7 13,6 14,6
2012 10 1385,4 21,4 36,2
2012 10 1608,2 33,3 44
2012 10 1607,8 37 52,4
2012 10 1611,3 41,3 57,9
2012 10 1607,6 46,8 43,3
2012 10 1601,6 33,1 52
2012 10 1741,5 26,2 65
2012 10 1355 24,4 29,7
2012 10 1578,3 31,3 27,9
2012 10 1539,9 37 27,4
2012 10 1567,8 20,3 22,2
2012 10 1585,7 25,8 27,7
2012 10 1560,8 20,1 22,5
2012 10 1617,3 40,3 25,9
2012 10 1578,9 26,8 24,9
2011 11 1443,2 23,9 45
2011 11 1476,4 49,4 47,5
2011 11 2057,4 29,1 135,5
2011 11 2083,8 87,5 338,8
2012 11 1445,7 26 40,7
2012 11 2056,1 26,6 108,7
2012 11 2077,4 73,7 136,4
2011 12 1212,1 51,3 67,4
2011 12 1151,1 63,3 93,3
2011 12 1268,2 44,4 59,9
2011 12 1024,9 60,7 83
2012 12 1212,1 51,3 83,4
2012 12 1151,1 63,3 78,6
2012 12 1268,2 44,4 78,4
2012 12 1024,9 60,7 60
2011 13 1306,2 61,5 34,5
2011 13 1339,2 69,1 52,3
2011 13 1341,4 71,9 66
2011 13 1373,4 71,4 27,6
2011 13 1381,2 65,5 51,2
2011 13 1323,7 65,6 82,9
2012 13 1306,2 61,5 55,6
2012 13 1339,2 69,1 36,4
2012 13 1341,4 71,9 60,4
2012 13 1373,4 71,4 52,3
2012 13 1381,2 65,5 73
2012 13 1323,7 65,6 57,1
2011 14 895,2 11,6 32,1
2011 14 914,9 17,7 27,4
2011 14 946,2 23,5 24,2
2011 14 959,1 28,5 25
2011 14 885,4 7,7 24,8
2011 14 911,2 6,5 18,8
2012 14 895,2 11,6 16,9
2012 14 914,1 17,4 20,7
2012 14 946,2 23,5 22,7
2012 14 959,1 28,5 34,8
2012 14 885,4 7,7 16,7
2012 14 911,2 6,5 15,7
2011 15 812,9 9,5 10,8
2011 16 836,7 30,1 32,5
2011 16 807,3 11,5 24,5
2011 16 823,4 23,6 28,8
2011 16 851,2 23,8 19,3
2011 16 860,6 31,7 28,1
2012 16 836,7 30,1 48,7
2012 16 807,3 11,5 23,8
2012 16 823,4 23,6 34,1
2012 16 851,2 23,8 19,2
2012 16 860,6 31,7 38,3
2011 17 967,6 54,2 36
2011 17 949,2 44,6 31,5
2011 17 942,1 30,3 19,8
2011 17 932,8 10,2 31,6
2011 17 942,4 31,8 36,2
2011 17 1558,8 60,9 99
2012 17 967,6 54,2 33,9
2012 17 949,2 44,6 26
2012 17 942,1 30,3 30,8
2012 17 931,6 11,9 31,4
2012 17 942,4 31,8 39,1
2012 17 1558,8 60,9 128,6
2011 18 1129,1 52,1 102,8
2011 18 1189,9 49,2 103,9
2011 18 1173,4 50,2 127,2
2012 18 1129,1 52,1 68,7
2012 18 1189,9 49,2 54,9
2012 18 1173,4 50,2 119,7
2011 19 1130,6 59,7 65,1
2011 19 1123,9 45,3 40,8
2011 19 1124,6 44,5 49
2011 19 1115,1 46,4 71,7
2011 19 1690,7 60,3 104
2012 19 1130,6 59,7 79
2012 19 1123,3 44,7 53,3
2012 19 1124,6 44,5 58,1
2012 19 1114,3 46,5 48,8
2012 19 1690,7 60,3 60
2011 20 1336,9 29,4 7,8
2011 20 1325,3 39,2 19,2
2011 20 1316,1 53,6 13,5
2011 20 1298 26,6 11
2011 20 1247,5 14,5 18,4
2011 20 1412,1 12,9 14,2
2011 20 1489,4 10,4 31,1
2012 20 1336,9 29,4 15,4
2012 20 1325,3 39,2 26,9
2012 20 1316,1 53,6 21,7
2012 20 1298 26,6 14,7
2012 20 1247,5 14,5 25,5
2012 20 1412,1 12,9 14,4
2012 20 1489,4 10,4 29


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From andrea.onofri at unipg.it  Tue Nov 19 14:28:38 2013
From: andrea.onofri at unipg.it (Andrea Onofri)
Date: Tue, 19 Nov 2013 14:28:38 +0100
Subject: [R-sig-ME] non-nested effects in lme
In-Reply-To: <528B3407.2050501@uni-oldenburg.de>
References: <528b22df.02580e0a.43a3.184f@mx.google.com>
	<528B3407.2050501@uni-oldenburg.de>
Message-ID: <CAN=z4LOBM3e1sM4EfcqKc-OhHPgSKsOuBgj1jn9OtyoDGZz=qw@mail.gmail.com>

Hello Friso,

very many thanks for your answer. I think that the coding in
StatsExchange is equivalent to:

lme(Y~ 1, random=~1|A/B, data=X, weights=varIdent(form=~1|A))

which is actually different from what I am looking for.
Indeed:

Y <- c(1.6, 2.3, 2.25, 3, 1.6, 2.35, 1.5, 2.85, 1.45, 2.65, 1.95,
2.65, 1.1, 2.1, 0.7, 2.25, 1.15, 1.65, 0.8, 1.7, 0.95, 1.65,
0.75, 1.35, 1, 2.05, 0.8, 2, 0.75, 1.9, 0.65, 1.9, 1.4, 2.1,
1.6, 1.95, 1.05, 1.75, 0.85, 1.75, 1.3, 1.95, 0.95, 1.55, 1,
1.1, 0.65, 1.05, 1.3, 1.45, 1.05, 0.9, 0.8, 0.9, 0.65, 0.7)
A <- structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L,
4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L,
8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L, 11L, 11L,
11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L
), .Label = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J",
"K", "L", "M", "N"), class = "factor")
B <- structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), .Label = c("A",
"B", "C", "D"), class = "factor")

mod <- lmer(Y ~ 1 + (1|A) + (1|B))

Results in:
 ......
Linear mixed model fit by REML
Formula: Y ~ 1 + (1 | A) + (1 | B)
....
Random effects:
Groups Name Variance Std.Dev.
A (Intercept) 0.180203 0.42450
B (Intercept) 0.163587 0.40446
Residual 0.088169 0.29693
Number of obs: 56, groups: A, 14; B, 4

Fixed effects:
Estimate Std. Error t value
(Intercept) 1.4839 0.2352 6.308

While:

mod2 <- lme(Y ~ 1, random=list(A=~1, B=~1))

Results in:

Linear mixed-effects model fit by REML
.......
Random effects:
Formula: ~1 | A
(Intercept)
StdDev: 0.3732374

Formula: ~1 | B %in% A
(Intercept) Residual
StdDev: 0.4641765 0.1905162

Fixed effects: Y ~ 1
Value Std.Error DF t-value p-value
(Intercept) 1.483929 0.1201919 42 12.34633 0

It looks quite different, but perhaps I am missing something? Thank
you again very much

Andrea Onofri
Department of Agroenvironmental and Crop Sciences
University of Perugia
Italy


On 19 November 2013 10:48, Friso Muijsers
<Friso.muijsers at uni-oldenburg.de> wrote:
> Am 11/19/2013 9:39 AM, schrieb andrea.onofri at unipg.it:
>> Dear all,
>>
>> I am trying to fit a simple model, relating to a randomised block design where both blocks (A) and treatments (B) are random effects. Coding in lmer, this model would be:
>>
>> model <- lmer(Y ~ 1 + (1|A) + (1|B))
>>
>> However, I would also like to be able to 'manipulate' the correlation structure and thus I assume I have to revert to the lme function in the nlme package. In other cases I have been able to fit non-nested effects in lme by appropriately using the pdMat construct, but, after several efforts, I do not seem to succeed in this simple case. I would greatly appreciate any hints that puts me in the right direction. I thank you very much in advance.
>>
>> Regards
>>
>> Andrea Onofri
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Hello,
>
> if I understand correctly, you want to specifiy multiple but non-nested
> random effects? If so, I recently found a post on statsExchange where
> someone has found a solution. I didn't check it though, but perhaps it
> fits your needs:
>
> |fit<-  lme(Y~  time,  random=list(year=~1,  date=~time),  data=X,  weights=varIdent(form=~1|year))
>
> or adapted to your general lmer example
>
> ||fit<-  lme(Y~  1,  random=list(A=~1,  B=~1),  data=X,  weights=varIdent(form=~1|A))||
>
> You can read the details here:
>
> http://stats.stackexchange.com/questions/58669/specifying-multiple-separate-random-effects-in-lme
>
> Perhaps that works (didn't check it myself, yet)
>
> Greetings
> |
>
> --
> Friso Muijsers
>
> Institute for Chemistry and Biology of the Marine Environment (ICBM)
> Carl-von-Ossietzky University Oldenburg
> Schleusenstrasse 1
> 26382 Wilhemshaven
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Friso.muijsers at uni-oldenburg.de  Tue Nov 19 14:46:29 2013
From: Friso.muijsers at uni-oldenburg.de (Friso Muijsers)
Date: Tue, 19 Nov 2013 14:46:29 +0100
Subject: [R-sig-ME] non-nested effects in lme
In-Reply-To: <CAN=z4LOBM3e1sM4EfcqKc-OhHPgSKsOuBgj1jn9OtyoDGZz=qw@mail.gmail.com>
References: <528b22df.02580e0a.43a3.184f@mx.google.com>	<528B3407.2050501@uni-oldenburg.de>
	<CAN=z4LOBM3e1sM4EfcqKc-OhHPgSKsOuBgj1jn9OtyoDGZz=qw@mail.gmail.com>
Message-ID: <528B6BB5.8060200@uni-oldenburg.de>

Ok, I'm sorry for directing you into the wrong direction. Probably 
someone else has an idea?

Am 11/19/2013 2:28 PM, schrieb Andrea Onofri:
> Hello Friso,
>
> very many thanks for your answer. I think that the coding in
> StatsExchange is equivalent to:
>
> lme(Y~ 1, random=~1|A/B, data=X, weights=varIdent(form=~1|A))
>
> which is actually different from what I am looking for.
> Indeed:
>
> Y <- c(1.6, 2.3, 2.25, 3, 1.6, 2.35, 1.5, 2.85, 1.45, 2.65, 1.95,
> 2.65, 1.1, 2.1, 0.7, 2.25, 1.15, 1.65, 0.8, 1.7, 0.95, 1.65,
> 0.75, 1.35, 1, 2.05, 0.8, 2, 0.75, 1.9, 0.65, 1.9, 1.4, 2.1,
> 1.6, 1.95, 1.05, 1.75, 0.85, 1.75, 1.3, 1.95, 0.95, 1.55, 1,
> 1.1, 0.65, 1.05, 1.3, 1.45, 1.05, 0.9, 0.8, 0.9, 0.65, 0.7)
> A <- structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L,
> 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L
> ), .Label = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J",
> "K", "L", "M", "N"), class = "factor")
> B <- structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), .Label = c("A",
> "B", "C", "D"), class = "factor")
>
> mod <- lmer(Y ~ 1 + (1|A) + (1|B))
>
> Results in:
>   ......
> Linear mixed model fit by REML
> Formula: Y ~ 1 + (1 | A) + (1 | B)
> ....
> Random effects:
> Groups Name Variance Std.Dev.
> A (Intercept) 0.180203 0.42450
> B (Intercept) 0.163587 0.40446
> Residual 0.088169 0.29693
> Number of obs: 56, groups: A, 14; B, 4
>
> Fixed effects:
> Estimate Std. Error t value
> (Intercept) 1.4839 0.2352 6.308
>
> While:
>
> mod2 <- lme(Y ~ 1, random=list(A=~1, B=~1))
>
> Results in:
>
> Linear mixed-effects model fit by REML
> .......
> Random effects:
> Formula: ~1 | A
> (Intercept)
> StdDev: 0.3732374
>
> Formula: ~1 | B %in% A
> (Intercept) Residual
> StdDev: 0.4641765 0.1905162
>
> Fixed effects: Y ~ 1
> Value Std.Error DF t-value p-value
> (Intercept) 1.483929 0.1201919 42 12.34633 0
>
> It looks quite different, but perhaps I am missing something? Thank
> you again very much
>
> Andrea Onofri
> Department of Agroenvironmental and Crop Sciences
> University of Perugia
> Italy
>
>
> On 19 November 2013 10:48, Friso Muijsers
> <Friso.muijsers at uni-oldenburg.de> wrote:
>> Am 11/19/2013 9:39 AM, schrieb andrea.onofri at unipg.it:
>>> Dear all,
>>>
>>> I am trying to fit a simple model, relating to a randomised block design where both blocks (A) and treatments (B) are random effects. Coding in lmer, this model would be:
>>>
>>> model <- lmer(Y ~ 1 + (1|A) + (1|B))
>>>
>>> However, I would also like to be able to 'manipulate' the correlation structure and thus I assume I have to revert to the lme function in the nlme package. In other cases I have been able to fit non-nested effects in lme by appropriately using the pdMat construct, but, after several efforts, I do not seem to succeed in this simple case. I would greatly appreciate any hints that puts me in the right direction. I thank you very much in advance.
>>>
>>> Regards
>>>
>>> Andrea Onofri
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> Hello,
>>
>> if I understand correctly, you want to specifiy multiple but non-nested
>> random effects? If so, I recently found a post on statsExchange where
>> someone has found a solution. I didn't check it though, but perhaps it
>> fits your needs:
>>
>> |fit<-  lme(Y~  time,  random=list(year=~1,  date=~time),  data=X,  weights=varIdent(form=~1|year))
>>
>> or adapted to your general lmer example
>>
>> ||fit<-  lme(Y~  1,  random=list(A=~1,  B=~1),  data=X,  weights=varIdent(form=~1|A))||
>>
>> You can read the details here:
>>
>> http://stats.stackexchange.com/questions/58669/specifying-multiple-separate-random-effects-in-lme
>>
>> Perhaps that works (didn't check it myself, yet)
>>
>> Greetings
>> |
>>
>> --
>> Friso Muijsers
>>
>> Institute for Chemistry and Biology of the Marine Environment (ICBM)
>> Carl-von-Ossietzky University Oldenburg
>> Schleusenstrasse 1
>> 26382 Wilhemshaven
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Friso Muijsers

Institute for Chemistry and Biology of the Marine Environment (ICBM)
Carl-von-Ossietzky University Oldenburg
Schleusenstrasse 1
26382 Wilhemshaven


From fbromano at sabanciuniv.edu  Tue Nov 19 16:30:13 2013
From: fbromano at sabanciuniv.edu (Francesco)
Date: Tue, 19 Nov 2013 17:30:13 +0200
Subject: [R-sig-ME] Post-hoc comparison for incorrect responses in glmer
Message-ID: <528B8405.9050805@sabanciuniv.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131119/9146bec5/attachment.pl>

From maechler at stat.math.ethz.ch  Tue Nov 19 19:44:33 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 Nov 2013 19:44:33 +0100
Subject: [R-sig-ME] starter values
In-Reply-To: <62FF4C4E32840642930D994866A29105933390@INFPWXM002.ad.unsw.edu.au>
References: <trinity-2aad6184-f21b-4437-b415-15da28e6b0bd-1384862180056@3capp-gmx-bs33>
	<62FF4C4E32840642930D994866A29105933390@INFPWXM002.ad.unsw.edu.au>
Message-ID: <21131.45457.63328.278313@stat.math.ethz.ch>

>>>>> Arnold Reynaldi <a.reynaldi at student.unsw.edu.au>
>>>>>     on Tue, 19 Nov 2013 13:15:50 +0000 writes:

    > Hi there, The model is biexponential decay. So the
    > assumption here is that in your data, you have 2
    > sub-populations that decay with different rate. A1 is the
    > initial number of your first sub-population and it will
    > decay with a rate of lrc1. On the other hand, A2 is your
    > second initial number of your second sub-population with
    > decay rate of lrc2.

    > As for the starting value, I believe that SSbiexp will
    > determine the starting value automatically. Just use this
    > code :

    > fit1 <- nlmer(kosten ~ SSbiexp(hm, np, A1, lrc1,A2,lrc2) ~
    > 0 + A1 + lrc1 + A2 + lrc2 + (0+A1+lrc1+A2+lrc2|j) +
    > (0+A1+lrc1+A2+lrc2|o), d))

There's more to it:

First, SSbiexp  has 5, not 6 arguments, so you'd need
 SSbiexp(np, A1, lrc1,A2,lrc2) 
or
 SSbiexp(hm, A1, lrc1,A2,lrc2) 

or their sum; but the sum won't work directly, because currently nlmer()
has the restriction that the nonlinear formula part must -- when
evaluated -- not only give a numeric vector, but that vector
must have a "gradient" attribute, a matrix.

And then, your data is *increasing*, not decaying, as Arnold
nicely said,  so a SSbiexp() model will not work.

To the last question: *if* your data were decaying, then you
could use  getInitial() {found on the help page of SSbiexp() !!!}
as follows,

getInitial(kosten ~ SSbiexp(hm, A1, lrc1,A2,lrc2), data=d)

but indeed, this gives an error, because really
a *decaying* exponential model definitely does not fit your data:

plot(kosten ~hm, d)
plot(kosten ~np, d) # similar: exponential *growth* rather


Martin Maechler, ETH Zurich


    > ________________________________________ 

    >> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Arndt Kunick [AKunick at gmx.de]
    >> Sent: Tuesday, November 19, 2013 10:56 PM
    >> To: r-sig-mixed-models at r-project.org
    >> Subject: [R-sig-ME] starter values
    >> 
    >> Dear R-user,
    >> I want to fit a nonlinear mixed model with the following formula (see below)
    >> 
    >> fit1 <- nlmer(kosten ~ SSbiexp(hm, np, A1, lrc1,A2,lrc2) ~ 0 + A1 + lrc1 + A2 + lrc2 +
    >>           (0+A1+lrc1+A2+lrc2|j) + (0+A1+lrc1+A2+lrc2|o), start = c(A1 = , lrc1 = , A2 = , lrc2 = ), d))
    >> 
    >> Thereby I have a problem with determine appropriate starter values for the parameters of the function SSbiexp.
    >> Regarding SSbiexp my questions are:
    >> 
    >> What is the meaning of the parameters A1, lrc1, A2 and lrc2?
    >> How can I deduce appropriate starter values?
    >> Exists there documentation for self-starter functions in lme4?
    >> 
    >> I am looking forward to hear from you!
    >> 
    >> With kind regards,
    >> 
    >> Anton


From agalecki at umich.edu  Tue Nov 19 22:50:57 2013
From: agalecki at umich.edu (Andrzej Galecki)
Date: Tue, 19 Nov 2013 16:50:57 -0500
Subject: [R-sig-ME] non-nested effects in lme
In-Reply-To: <528B6BB5.8060200@uni-oldenburg.de>
References: <528b22df.02580e0a.43a3.184f@mx.google.com>
	<528B3407.2050501@uni-oldenburg.de>
	<CAN=z4LOBM3e1sM4EfcqKc-OhHPgSKsOuBgj1jn9OtyoDGZz=qw@mail.gmail.com>
	<528B6BB5.8060200@uni-oldenburg.de>
Message-ID: <CA+XOvOQZUWQ+YQXBbZZpbZWP27rmeMO9XmB-GwVUawK=ZU6Mmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131119/92a5d987/attachment.pl>

From andrea.onofri at unipg.it  Wed Nov 20 09:08:52 2013
From: andrea.onofri at unipg.it (Andrea Onofri)
Date: Wed, 20 Nov 2013 09:08:52 +0100
Subject: [R-sig-ME] non-nested effects in lme
In-Reply-To: <CA+XOvOQZUWQ+YQXBbZZpbZWP27rmeMO9XmB-GwVUawK=ZU6Mmw@mail.gmail.com>
References: <528b22df.02580e0a.43a3.184f@mx.google.com>
	<528B3407.2050501@uni-oldenburg.de>
	<CAN=z4LOBM3e1sM4EfcqKc-OhHPgSKsOuBgj1jn9OtyoDGZz=qw@mail.gmail.com>
	<528B6BB5.8060200@uni-oldenburg.de>
	<CA+XOvOQZUWQ+YQXBbZZpbZWP27rmeMO9XmB-GwVUawK=ZU6Mmw@mail.gmail.com>
Message-ID: <CAN=z4LPK1f8uRsE8+y5XtkJxKKCqq-Z+G1UaVzQdFxrwLE47JA@mail.gmail.com>

Dear Andrzej,
the use of the auxiliary variables makes the trick! Brilliant
solution! Very many thanks for this.
Regards
Andrea

----------
Andrea Onofri
Department of Agroenvironmental and Crop Sciences
University of Perugia
Italy

On 19 November 2013 22:50, Andrzej Galecki <agalecki at umich.edu> wrote:
> Hi Andrea,
>
> In  Chapter 19 of Galecki, Burzykowski  recent book titled "Linear
> Mixed-Effects Models Using R: Step-by-Step Approach" you will find an
> example of
> using lme() function for  amode with crossed random effects.  Related syntax
> (see below) is distributed with nlmeU package available from cran.  Note
> that execution time can be fairly long.
>
> Best,
>
> Andrzej
>
> PS.  Note the use of auxiliary variables named one1 and one2.
>
> library(lattice)
> data(fcat, package = "nlmeU")
>
> ## ---->>>> NOTE: Code used in Panels R19.1 - R19.7 is stored in Ch19mer.R
> file
>
>
> ###################################################
> ### code chunk: R19.8
> ###################################################
> library(nlme)
>
> fcat1 <- within(fcat, one1 <- one2 <- 1L)
> system.time(
>    fm19.2 <-
>       lme(scorec ~ 1,
>           random = list(
>           one1 = pdIdent(~target - 1),
>           one2 = pdIdent(~id - 1)),
>           data = fcat1))
> fm19.2                                          # M19.2: (19.2)
>
>
>
>
> On Tue, Nov 19, 2013 at 8:46 AM, Friso Muijsers
> <Friso.muijsers at uni-oldenburg.de> wrote:
>>
>> Ok, I'm sorry for directing you into the wrong direction. Probably someone
>> else has an idea?
>>
>> Am 11/19/2013 2:28 PM, schrieb Andrea Onofri:
>>
>>> Hello Friso,
>>>
>>> very many thanks for your answer. I think that the coding in
>>> StatsExchange is equivalent to:
>>>
>>> lme(Y~ 1, random=~1|A/B, data=X, weights=varIdent(form=~1|A))
>>>
>>> which is actually different from what I am looking for.
>>> Indeed:
>>>
>>> Y <- c(1.6, 2.3, 2.25, 3, 1.6, 2.35, 1.5, 2.85, 1.45, 2.65, 1.95,
>>> 2.65, 1.1, 2.1, 0.7, 2.25, 1.15, 1.65, 0.8, 1.7, 0.95, 1.65,
>>> 0.75, 1.35, 1, 2.05, 0.8, 2, 0.75, 1.9, 0.65, 1.9, 1.4, 2.1,
>>> 1.6, 1.95, 1.05, 1.75, 0.85, 1.75, 1.3, 1.95, 0.95, 1.55, 1,
>>> 1.1, 0.65, 1.05, 1.3, 1.45, 1.05, 0.9, 0.8, 0.9, 0.65, 0.7)
>>> A <- structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L,
>>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L,
>>> 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L, 11L, 11L,
>>> 11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L
>>> ), .Label = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J",
>>> "K", "L", "M", "N"), class = "factor")
>>> B <- structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
>>> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
>>> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L,
>>> 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), .Label = c("A",
>>> "B", "C", "D"), class = "factor")
>>>
>>> mod <- lmer(Y ~ 1 + (1|A) + (1|B))
>>>
>>> Results in:
>>>   ......
>>> Linear mixed model fit by REML
>>> Formula: Y ~ 1 + (1 | A) + (1 | B)
>>> ....
>>> Random effects:
>>> Groups Name Variance Std.Dev.
>>> A (Intercept) 0.180203 0.42450
>>> B (Intercept) 0.163587 0.40446
>>> Residual 0.088169 0.29693
>>> Number of obs: 56, groups: A, 14; B, 4
>>>
>>> Fixed effects:
>>> Estimate Std. Error t value
>>> (Intercept) 1.4839 0.2352 6.308
>>>
>>> While:
>>>
>>> mod2 <- lme(Y ~ 1, random=list(A=~1, B=~1))
>>>
>>> Results in:
>>>
>>> Linear mixed-effects model fit by REML
>>> .......
>>> Random effects:
>>> Formula: ~1 | A
>>> (Intercept)
>>> StdDev: 0.3732374
>>>
>>> Formula: ~1 | B %in% A
>>> (Intercept) Residual
>>> StdDev: 0.4641765 0.1905162
>>>
>>> Fixed effects: Y ~ 1
>>> Value Std.Error DF t-value p-value
>>> (Intercept) 1.483929 0.1201919 42 12.34633 0
>>>
>>> It looks quite different, but perhaps I am missing something? Thank
>>> you again very much
>>>
>>> Andrea Onofri
>>> Department of Agroenvironmental and Crop Sciences
>>> University of Perugia
>>> Italy
>>>
>>>
>>> On 19 November 2013 10:48, Friso Muijsers
>>> <Friso.muijsers at uni-oldenburg.de> wrote:
>>>>
>>>> Am 11/19/2013 9:39 AM, schrieb andrea.onofri at unipg.it:
>>>>>
>>>>> Dear all,
>>>>>
>>>>> I am trying to fit a simple model, relating to a randomised block
>>>>> design where both blocks (A) and treatments (B) are random effects. Coding
>>>>> in lmer, this model would be:
>>>>>
>>>>> model <- lmer(Y ~ 1 + (1|A) + (1|B))
>>>>>
>>>>> However, I would also like to be able to 'manipulate' the correlation
>>>>> structure and thus I assume I have to revert to the lme function in the nlme
>>>>> package. In other cases I have been able to fit non-nested effects in lme by
>>>>> appropriately using the pdMat construct, but, after several efforts, I do
>>>>> not seem to succeed in this simple case. I would greatly appreciate any
>>>>> hints that puts me in the right direction. I thank you very much in advance.
>>>>>
>>>>> Regards
>>>>>
>>>>> Andrea Onofri
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> Hello,
>>>>
>>>> if I understand correctly, you want to specifiy multiple but non-nested
>>>> random effects? If so, I recently found a post on statsExchange where
>>>> someone has found a solution. I didn't check it though, but perhaps it
>>>> fits your needs:
>>>>
>>>> |fit<-  lme(Y~  time,  random=list(year=~1,  date=~time),  data=X,
>>>> weights=varIdent(form=~1|year))
>>>>
>>>> or adapted to your general lmer example
>>>>
>>>> ||fit<-  lme(Y~  1,  random=list(A=~1,  B=~1),  data=X,
>>>> weights=varIdent(form=~1|A))||
>>>>
>>>> You can read the details here:
>>>>
>>>>
>>>> http://stats.stackexchange.com/questions/58669/specifying-multiple-separate-random-effects-in-lme
>>>>
>>>> Perhaps that works (didn't check it myself, yet)
>>>>
>>>> Greetings
>>>> |
>>>>
>>>> --
>>>> Friso Muijsers
>>>>
>>>> Institute for Chemistry and Biology of the Marine Environment (ICBM)
>>>> Carl-von-Ossietzky University Oldenburg
>>>> Schleusenstrasse 1
>>>> 26382 Wilhemshaven
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Friso Muijsers
>>
>> Institute for Chemistry and Biology of the Marine Environment (ICBM)
>> Carl-von-Ossietzky University Oldenburg
>> Schleusenstrasse 1
>> 26382 Wilhemshaven
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From AKunick at gmx.de  Wed Nov 20 17:45:49 2013
From: AKunick at gmx.de (Arndt Kunick)
Date: Wed, 20 Nov 2013 17:45:49 +0100 (CET)
Subject: [R-sig-ME] starter values
Message-ID: <trinity-dae4b2b8-518b-4fca-821f-b213ae7801b8-1384965949561@3capp-gmx-bs23>



Thank you for the explanation about SSbiexp!
?
Primarily I fitted the model in the form below:
?
fit3 <- lmer(kosten ~ hm + I(hm^2) + np + I(np^2) + (1|j) + (1|o) + (0 + hm*np|o),? d)
?
The problem was that the quadratic polynomial function for hm and np does not fit well.
?
It seems that a non-linear model is more suitable in this case.
Is it possible to design a non-linear mixed-effect-model for two fix effects (nlin for hm and np)?
If no, is there an alternative approach?
?
I would be grateful about every advice or professional knowledge.
?
A*


From Maria_Paola.Bissiri at tu-dresden.de  Wed Nov 20 20:50:30 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Wed, 20 Nov 2013 19:50:30 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
	<20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>
Message-ID: <20131120195030.Horde.-F0IZ62N73o2N7New1yl4Q6@mail.zih.tu-dresden.de>

Dear Jarrod, dear Szymek,
thank you for your answers, I made some progress, but I am not sure if  
I am on the right way.

Jarrod, you mean that the random effects (1 + fin_B|subj_ID) in glmer,  
corresponding to us(1+fin_B):subj_ID in MCMCglmm, are not appropriate  
because fin_B is binomial, right?
So, would you suggest random = ~us(fin_B):subj_ID in MCMCglmm?
Is (fin_B|subj_ID) the corresponding glmer notation for it?

Is "us" or "idh" more appropriate for my data in MCMCglmm? fin_B is  
dichotomous, a factor variable with two outcomes "f" or "m". subj_ID  
has 86 outcomes (the experiment participants).

>>> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)
>>> where a is something large.

Can you give me some hint how large "a" should be?
I tried the following:

a=1e+06
k <- length(levels(fallmid$resp_X))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
prior = list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
            G = list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
alpha.V=diag(2)*a)))

fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +  
lang * fin_B,
                               random = ~us(fin_B):subj_ID,
                               family="categorical", data=fallmid,
                               prior=prior
                               )


Then I checked
autocorr(fallmid.MCMCglmm$Sol)
and I saw that the model with the default parameters produced  
sometimes autocorrelation of 0.4 between successive stored iterations.
How should the parameters nitt, thin and burnin be set to improve  
this? Should I just increase all numbers in the same ratio as the  
default ones? Are there limits by increasing?

I rerun MCMCglmm indicating
nitt=150000, thin=100, burnin=37500
and could get autocorrelation < 0.1 for all fixed effects, except  
0.1043 for langen:ini_pchr

I copy below the autocorrelation output for VCV, in which I cannot  
understand titles as "f:f.subj_ID", and "m:f.subj_ID". "f" and "m" are  
the outcomes of the dichotomous variable fin_B.
And I copy also the summary of the model.
How does it look for you? Am I on the right way?

Kind regards,
Maria Paola

> autocorr(fallmid.MCMCglmm.tweak$VCV)
, , f:f.subj_ID

          f:f.subj_ID m:f.subj_ID f:m.subj_ID  m:m.subj_ID units
Lag 0     1.00000000 -0.18716407 -0.18716407 -0.002976274   NaN
Lag 100   0.28414235 -0.04901656 -0.04901656 -0.021149419   NaN
Lag 500   0.02436112 -0.01027021 -0.01027021 -0.027991234   NaN
Lag 1000 -0.01759353 -0.01638179 -0.01638179 -0.011795094   NaN
Lag 5000 -0.04787859  0.00763913  0.00763913  0.024799289   NaN

, , m:f.subj_ID

          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
Lag 0    -0.18716407 1.000000000 1.000000000 -0.17260855   NaN
Lag 100  -0.04912875 0.023138658 0.023138658 -0.05718198   NaN
Lag 500  -0.03577679 0.003964840 0.003964840 -0.05278701   NaN
Lag 1000  0.02771401 0.004615445 0.004615445  0.01383229   NaN
Lag 5000  0.01528668 0.001639329 0.001639329 -0.02532356   NaN

, , f:m.subj_ID

          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
Lag 0    -0.18716407 1.000000000 1.000000000 -0.17260855   NaN
Lag 100  -0.04912875 0.023138658 0.023138658 -0.05718198   NaN
Lag 500  -0.03577679 0.003964840 0.003964840 -0.05278701   NaN
Lag 1000  0.02771401 0.004615445 0.004615445  0.01383229   NaN
Lag 5000  0.01528668 0.001639329 0.001639329 -0.02532356   NaN

, , m:m.subj_ID

           f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
Lag 0    -0.002976274 -0.17260855 -0.17260855  1.00000000   NaN
Lag 100  -0.062222834 -0.04848553 -0.04848553  0.22828366   NaN
Lag 500   0.017753127 -0.01216755 -0.01216755  0.07778476   NaN
Lag 1000  0.020301781  0.03771063  0.03771063 -0.02781175   NaN
Lag 5000 -0.015825205 -0.05418101 -0.05418101  0.07003646   NaN

, , units

          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
Lag 0            NaN         NaN         NaN         NaN   NaN
Lag 100          NaN         NaN         NaN         NaN   NaN
Lag 500          NaN         NaN         NaN         NaN   NaN
Lag 1000         NaN         NaN         NaN         NaN   NaN
Lag 5000         NaN         NaN         NaN         NaN   NaN




> summary(fallmid.MCMCglmm.tweak)

  Iterations = 37501:149901
  Thinning interval  = 100
  Sample size  = 1125

  DIC: 1586.166

  G-structure:  ~us(fin_B):subj_ID

             post.mean l-95% CI u-95% CI eff.samp
f:f.subj_ID    2.8329    1.351   4.4789    626.6
m:f.subj_ID   -0.4024   -1.301   0.5999   1125.0
f:m.subj_ID   -0.4024   -1.301   0.5999   1125.0
m:m.subj_ID    3.3495    1.665   4.9086    481.2

  R-structure:  ~units

       post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

  Location effects: resp_X ~ lang * ini_pch + lang * manner + lang * fin_B

                 post.mean l-95% CI u-95% CI eff.samp   pMCMC
(Intercept)      -2.12231 -2.99651 -1.19650   1125.0 < 9e-04 ***
langde            0.86672 -0.33061  2.13741   1125.0 0.15467
langen            0.17379 -1.32158  1.96542   1021.4 0.83556
langsw            0.60668 -1.11771  2.00774   1125.0 0.44622
ini_pchm          0.31321 -0.36251  0.94373   1125.0 0.33956
ini_pchr         -0.01135 -0.61257  0.65751   1005.5 0.97600
mannerla          0.02540 -0.64462  0.60490   1125.0 0.93689
mannerna         -0.29521 -0.87690  0.37917   1125.0 0.38222
fin_Bm            2.57100  1.54529  3.81118   1019.3 < 9e-04 ***
langde:ini_pchm  -0.62639 -1.44799  0.26281   1026.4 0.14044
langen:ini_pchm   0.13596 -0.98973  1.23208    975.7 0.81244
langsw:ini_pchm   0.27390 -0.87134  1.31791   1125.0 0.63644
langde:ini_pchr  -0.89823 -1.79517 -0.03409   1256.7 0.05511 .
langen:ini_pchr  -1.30494 -2.58387 -0.09301    911.7 0.05333 .
langsw:ini_pchr  -0.08782 -1.13757  1.02182   1010.0 0.89422
langde:mannerla  -0.24312 -1.13861  0.63645   1125.0 0.59378
langen:mannerla  -0.58499 -1.78324  0.61955   1125.0 0.32000
langsw:mannerla   0.58872 -0.52892  1.64295   1125.0 0.27733
langde:mannerna   0.47920 -0.33966  1.37083   1125.0 0.30756
langen:mannerna   0.79813 -0.35619  1.89286   1125.0 0.19911
langsw:mannerna   0.72797 -0.29891  1.89281   1125.0 0.19911
langde:fin_Bm    -1.90047 -3.36978 -0.31952    997.2 0.00889 **
langen:fin_Bm    -1.44445 -3.59097  0.42764    964.4 0.15467
langsw:fin_Bm    -2.80490 -5.03965 -1.07777   1125.0 0.00533 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1





Zitat von Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi Szymek,
>
> Whoops  - I forgot it was dichotomous. idh(X):Y is probably more
> appropriate. (1+x) fits two effects; a) Y effects for the first
> level of X and b) the difference between Y effects between the two
> levels.  If X was continous it would make more sense because it
> would be intercept and slope.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Szymek Drobniak <geralttee at gmail.com> on Fri, 15 Nov 2013
> 21:47:35 +0100:
>
>> Hello,
>>
>> thank you Jarrod for clarifying things, I obviously made a mistake with the
>> nu value. I was also wondering - what is the interpretation of idh(1+X):Y
>> in case X is a dichotomous variable?
>>
>> Cheers,
>> sz.
>>
>>
>> On 14 November 2013 18:23, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>>> Hi Maria,
>>>
>>> random = ~us(1):subj_ID + us(fin_B):subj_ID  is the same as
>>> idh(1+finB):subj_ID and is not the same as (1 + fin_B|subj_ID) in lmer
>>> because the idh fixes the covariance between and intercepts and slopes to
>>> zero.  us(1+finB):subj_ID is equivalent to the lmer code.
>>>
>>> Also, a prior of nu=2 (or nu=2.002) could have quite an influence on your
>>> posterior. V=diag(2) and nu=1.002 for the 2x2 case gives a marginal prior
>>> on the variances that is equivalent to an inverse gamma with shape and
>>> scale equal to 0.001. This prior used to be used a lot, but has some bad
>>> properties when values close to zero have support. I often use the
>>> parameter expanded prior:
>>>
>>> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)
>>>
>>> where a is something large.
>>>
>>> There is no difference between nu and n.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>>
>>>> And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>>> us(fin_B):subj_ID.
>>>>
>>>
>>>
>>> Quoting Maria Paola Bissiri <Maria_Paola.Bissiri at tu-dresden.de> on Thu,
>>> 14 Nov 2013 15:06:26 +0000:
>>>
>>> Dear Szymek,
>>>> thank you very much for your answer.
>>>>
>>>> Yes, the random effects were indicated wrongly in MCMCglmm! My intention
>>>> is of course to look at variance associated with subjects (subj_ID).
>>>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>>> And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>>> us(fin_B):subj_ID.
>>>> Please, correct me if I am wrong.
>>>>
>>>> So the model runs with:
>>>> k <- length(levels(fallmid$resp_X))
>>>> I <- diag(k-1)
>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>> prior <- list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
>>>>                G = list(G1 = list(V = diag(1), n = 2), G2 = list(V =
>>>> diag(2), n = 2)))
>>>>
>>>> fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +
>>>> lang * fin_B,
>>>>                            random = ~us(1):subj_ID + us(fin_B):subj_ID,
>>>>                            family="categorical", data=fallmid,
>>>>                            prior=prior
>>>>                            )
>>>>
>>>> In your suggestion you indicate nu=2.002. What does "nu" mean? What is
>>>> the difference between nu and n? In the MCMCglmm manual and in
>>>> the tutorial
>>>> they are both defined as "degrees of belief". What does this mean?
>>>>
>>>> Kind regards,
>>>> Maria Paola
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Zitat von Szymek Drobniak <geralttee at gmail.com>:
>>>>
>>>> Dear Maria,
>>>>>
>>>>> I'm not sure what exactly you're trying to test with your model, but to
>>>>> start with - your prior specification assumes 2 random effects, and your
>>>>> model has only one (a structured covariance matrix with fin_B defined as
>>>>> a
>>>>> random effect). This specification you've provided is similar to a random
>>>>> intercept/slope model - but I can't see why you would like to fit it
>>>>> (most
>>>>> importantly, you assumed that fin_B is both a fixed and random effect).
>>>>> If
>>>>> your intention was to look at variance associated with subjects
>>>>> (subj_ID),
>>>>> and you'd like to see if this variance is heterogeneous for different
>>>>> levels of fin_B - you could fit:
>>>>>
>>>>> MCMCglmm(your_fixed_formula_here, random=~us(fin_B):subj_ID, ...)
>>>>>
>>>>> and the prior would be (assuming fin_B has 2 levels as you've said)
>>>>>
>>>>> list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2),nu=2.002)))
>>>>>
>>>>> that's for start, then have a look at mcmc-series plots to see if it
>>>>> mixes
>>>>> well and tweak your model further if necessary.
>>>>>
>>>>> Cheer
>>>>> szymek
>>>>>
>>>>
>>>> --
>>>> Dr. Maria Paola Bissiri
>>>>
>>>> TU Dresden
>>>> Fakult?t Elektrotechnik und Informationstechnik
>>>> Institut f?r Akustik und Sprachkommunikation
>>>> 01062 Dresden
>>>>
>>>> Barkhausen-Bau, Raum S54
>>>> Helmholtzstra?e 18
>>>>
>>>> Tel: +49 (0)351 463-34283
>>>> Fax: +49 (0)351 463-37781
>>>> E-Mail: Maria_Paola.Bissiri at tu-dresden.de
>>>> http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>
>>
>> --
>> Szymon Drobniak, PhD. || Population Ecology Group
>> Institute of Environmental Sciences, Jagiellonian University
>> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
>> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
>> szymek.drobniak at uj.edu.pl
>> www.eko.uj.edu.pl/drobniak
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


From geralttee at gmail.com  Wed Nov 20 21:20:49 2013
From: geralttee at gmail.com (Szymek Drobniak)
Date: Wed, 20 Nov 2013 21:20:49 +0100
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <20131120195030.Horde.-F0IZ62N73o2N7New1yl4Q6@mail.zih.tu-dresden.de>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
	<20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>
	<20131120195030.Horde.-F0IZ62N73o2N7New1yl4Q6@mail.zih.tu-dresden.de>
Message-ID: <CANXb-o61cA0AtbAPFXaD5a5rQm0fxBr+95j_y3ONQkk31OqFug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131120/a8b5f7b1/attachment.pl>

From jake987722 at hotmail.com  Wed Nov 20 23:27:51 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 20 Nov 2013 15:27:51 -0700
Subject: [R-sig-ME] extract DFs from summary.merModLmerTest
Message-ID: <BAY172-W1547588E854EB574C2113BCBE60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131120/7ac51337/attachment.pl>

From bbolker at gmail.com  Wed Nov 20 23:37:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Nov 2013 17:37:25 -0500
Subject: [R-sig-ME] extract DFs from summary.merModLmerTest
In-Reply-To: <BAY172-W1547588E854EB574C2113BCBE60@phx.gbl>
References: <BAY172-W1547588E854EB574C2113BCBE60@phx.gbl>
Message-ID: <528D39A5.1060609@gmail.com>

On 13-11-20 05:27 PM, Jake Westfall wrote:
> I see that package lmerTest will compute approximate degrees of
> freedom via the Satterthwaite method for test of fixed effects from
> merMod objects, and it uses these to provide some p-values. Great.
> But how do I extract the computed Satterthwaite degrees of freedom?
> They are not displayed in the default output of
> summary.merModLmerTest objects (which is a big "WTF" in itself, but
> nevermind), not discussed in the package documentation as far as I
> can tell, and studying str(summary(fittedModel)) has not given any
> clues about where they are stored... surely they must be saved
> somewhere, right??
> 

 They don't *have* to be stored (although I agree it would be a good
idea); they might be computed on the fly and used for computing the
p-values, or even printed out, but not stored in the summary object.
  You might have to start digging through

getMethod("summary","merModLmerTest") and
lmerTest:::totalAnovaRandLsmeans

but these are pretty scary pieces of code.  Maybe send a wishlist item
to the maintainer ... ?


From jake987722 at hotmail.com  Thu Nov 21 00:32:21 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 20 Nov 2013 16:32:21 -0700
Subject: [R-sig-ME] extract DFs from summary.merModLmerTest
In-Reply-To: <528D39A5.1060609@gmail.com>
References: <BAY172-W1547588E854EB574C2113BCBE60@phx.gbl>,
	<528D39A5.1060609@gmail.com>
Message-ID: <BAY172-W50D9775860C67881169619CBE60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131120/16143891/attachment.pl>

From segerfan83 at gmail.com  Thu Nov 21 02:45:08 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Wed, 20 Nov 2013 20:45:08 -0500
Subject: [R-sig-ME] Calculate Repeatability of Mixed Model Random Effects
Message-ID: <CAHe08SgFAD-4ii3cD600eCqn09oFihYYK4qniLL9UT-S8DAqMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131120/ced291a3/attachment.pl>

From highstat at highstat.com  Thu Nov 21 09:34:38 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 21 Nov 2013 08:34:38 +0000
Subject: [R-sig-ME] Course: Introduction to Linear mixed effects models,
 GLMM and MCMC with R
Message-ID: <528DC59E.7090701@highstat.com>

We would like to announce the following statistics course;

Course: Introduction to Linear mixed effects models, GLMM and MCMC with R
When: 10-14 February, 2014
Where: Pousada de juventude parque das nacoes. Rua de Moscavide, Lt 47 ? 
101, 1998- 011. Lisbon, Portugal
Info: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyer2014_02SIM_LisbonV2.pdf

Kind regards,

Alain


-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From Maria_Paola.Bissiri at tu-dresden.de  Thu Nov 21 20:19:35 2013
From: Maria_Paola.Bissiri at tu-dresden.de (Maria Paola Bissiri)
Date: Thu, 21 Nov 2013 19:19:35 +0000
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <CANXb-o61cA0AtbAPFXaD5a5rQm0fxBr+95j_y3ONQkk31OqFug@mail.gmail.com>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
	<20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>
	<20131120195030.Horde.-F0IZ62N73o2N7New1yl4Q6@mail.zih.tu-dresden.de>
	<CANXb-o61cA0AtbAPFXaD5a5rQm0fxBr+95j_y3ONQkk31OqFug@mail.gmail.com>
Message-ID: <20131121191935.Horde.HCkpUekS14113gGx2EuZww3@mail.zih.tu-dresden.de>

Hello Szymek,
thank you very much for your answer.

> if you have enough information in your data it's probably good to  
> explicitly model covariances not fixed at 0.

what would be enough information to choose "us" instead of "idh"?
I have to generate two models. One for 360 observations from 20  
subjects, and the other one for 1548 observations from 86 subjects.

> Be careful about prior - for the idh
> structure your prior (nu=1.002 would probably more informative than you
> want, please Jarrod correct me if I'm right).

In case of idh, which should be the "nu" value in the prior for R and for G?

> E.g. for your estimated variances you have around 600 and 400 which  
> is a bit to low - try running for longer, maybe increasing thin a bit.

So, if effectiveSize(model$VCV) is > 1000, it is okay, right?

> Fixed effects look ok to me - you have some interactions that  
> probably are not
> significant, so I'd try simplifying the model.

I read in the list that it is not recommended to do backward  
elimination of non significant terms in the model. E.g.:
http://article.gmane.org/gmane.comp.lang.r.lme4.devel/5713/
My objective is to test by means of GLMM the influence of the  
predictors in the model on the response variable. Not sure if I should  
simplify the model or not.

Kind regards,
Maria Paola


Zitat von Szymek Drobniak <geralttee at gmail.com>:

> Hello Maria,
>
> us and idh fit different kinds of covariance structures: in us all relevant
> parameters are estimated (both variances and covariances) - if you have
> enough information in your data it's probably good to explicitly model
> covariances not fixed at 0. In case of idh the covariance matrix is similar
> but the covariances are fixed at zero (so only variances - i.e. the
> off-diagonal elements) are estimated. Be careful about prior - for the idh
> structure your prior (nu=1.002 would probably more informative than you
> want, please Jarrod correct me if I'm right).
>
> As for the autocorrelations - I'd generally go as low as possible, usually
> I try to get values less than 0.05. You're mostly interested in
> autocorrelations for lags=thin - and mostly diagonal values so you'll have
> much clearer output by running
>
> diag(autocorr(model$VCV)[2,,])
>
> or just look at effectiveSize(model$VCV) which should be ideally around at
> least 1000. As far as I know there's no strict rule as to which values of
> nitt/thin/burnin to use - it depends on your data, how much information it
> contains and how many parameters you're trying to estimate. What you're
> trying to achieve is a well mixing chain with low-enough
> autocorrelations/large enough effective sample sizes. E.g. for your
> estimated variances you have around 600 and 400 which is a bit to low - try
> running for longer, maybe increasing thin a bit. Burnin seems enough, of
> course as far as I would set it. There's no limit for the number of
> iterations (beside, of course, your time and available computer memory ;))
>
> And about the labels in the output: if you fit us() covariance structure -
> you're output will contain m.m.subj_ID and f.f.subj_ID labeling estimated
> variances (off-diagonal elements of the co matrix) and
> m.f.subj_ID/f.m.subj_ID labeling covariances (the matrix is symmetrical so
> they're the same). If you fit idh() you'll have only m.m.subj_ID and
> f.f.subj_ID as covariance will be fixed at 0 and not estimated. Fixed
> effects look ok to me - you have some interactions that probably are not
> significant, so I'd try simplifying the model.
>
> Cheers
> sz.
>
>
>
> On 20 November 2013 20:50, Maria Paola Bissiri <
> Maria_Paola.Bissiri at tu-dresden.de> wrote:
>
>> Dear Jarrod, dear Szymek,
>> thank you for your answers, I made some progress, but I am not sure if I
>> am on the right way.
>>
>> Jarrod, you mean that the random effects (1 + fin_B|subj_ID) in glmer,
>> corresponding to us(1+fin_B):subj_ID in MCMCglmm, are not appropriate
>> because fin_B is binomial, right?
>> So, would you suggest random = ~us(fin_B):subj_ID in MCMCglmm?
>> Is (fin_B|subj_ID) the corresponding glmer notation for it?
>>
>> Is "us" or "idh" more appropriate for my data in MCMCglmm? fin_B is
>> dichotomous, a factor variable with two outcomes "f" or "m". subj_ID has 86
>> outcomes (the experiment participants).
>>
>>
>>  list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)
>>>>> where a is something large.
>>>>>
>>>>
>> Can you give me some hint how large "a" should be?
>> I tried the following:
>>
>> a=1e+06
>>
>> k <- length(levels(fallmid$resp_X))
>> I <- diag(k-1)
>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>> prior = list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
>>            G = list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),
>> alpha.V=diag(2)*a)))
>>
>>
>> fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +
>> lang * fin_B,
>>                               random = ~us(fin_B):subj_ID,
>>
>>                               family="categorical", data=fallmid,
>>                               prior=prior
>>                               )
>>
>>
>> Then I checked
>> autocorr(fallmid.MCMCglmm$Sol)
>> and I saw that the model with the default parameters produced sometimes
>> autocorrelation of 0.4 between successive stored iterations.
>> How should the parameters nitt, thin and burnin be set to improve this?
>> Should I just increase all numbers in the same ratio as the default ones?
>> Are there limits by increasing?
>>
>> I rerun MCMCglmm indicating
>> nitt=150000, thin=100, burnin=37500
>> and could get autocorrelation < 0.1 for all fixed effects, except 0.1043
>> for langen:ini_pchr
>>
>> I copy below the autocorrelation output for VCV, in which I cannot
>> understand titles as "f:f.subj_ID", and "m:f.subj_ID". "f" and "m" are the
>> outcomes of the dichotomous variable fin_B.
>> And I copy also the summary of the model.
>> How does it look for you? Am I on the right way?
>>
>> Kind regards,
>> Maria Paola
>>
>>  autocorr(fallmid.MCMCglmm.tweak$VCV)
>>>
>> , , f:f.subj_ID
>>
>>          f:f.subj_ID m:f.subj_ID f:m.subj_ID  m:m.subj_ID units
>> Lag 0     1.00000000 -0.18716407 -0.18716407 -0.002976274   NaN
>> Lag 100   0.28414235 -0.04901656 -0.04901656 -0.021149419   NaN
>> Lag 500   0.02436112 -0.01027021 -0.01027021 -0.027991234   NaN
>> Lag 1000 -0.01759353 -0.01638179 -0.01638179 -0.011795094   NaN
>> Lag 5000 -0.04787859  0.00763913  0.00763913  0.024799289   NaN
>>
>> , , m:f.subj_ID
>>
>>          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
>> Lag 0    -0.18716407 1.000000000 1.000000000 -0.17260855   NaN
>> Lag 100  -0.04912875 0.023138658 0.023138658 -0.05718198   NaN
>> Lag 500  -0.03577679 0.003964840 0.003964840 -0.05278701   NaN
>> Lag 1000  0.02771401 0.004615445 0.004615445  0.01383229   NaN
>> Lag 5000  0.01528668 0.001639329 0.001639329 -0.02532356   NaN
>>
>> , , f:m.subj_ID
>>
>>          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
>> Lag 0    -0.18716407 1.000000000 1.000000000 -0.17260855   NaN
>> Lag 100  -0.04912875 0.023138658 0.023138658 -0.05718198   NaN
>> Lag 500  -0.03577679 0.003964840 0.003964840 -0.05278701   NaN
>> Lag 1000  0.02771401 0.004615445 0.004615445  0.01383229   NaN
>> Lag 5000  0.01528668 0.001639329 0.001639329 -0.02532356   NaN
>>
>> , , m:m.subj_ID
>>
>>           f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
>> Lag 0    -0.002976274 -0.17260855 -0.17260855  1.00000000   NaN
>> Lag 100  -0.062222834 -0.04848553 -0.04848553  0.22828366   NaN
>> Lag 500   0.017753127 -0.01216755 -0.01216755  0.07778476   NaN
>> Lag 1000  0.020301781  0.03771063  0.03771063 -0.02781175   NaN
>> Lag 5000 -0.015825205 -0.05418101 -0.05418101  0.07003646   NaN
>>
>> , , units
>>
>>          f:f.subj_ID m:f.subj_ID f:m.subj_ID m:m.subj_ID units
>> Lag 0            NaN         NaN         NaN         NaN   NaN
>> Lag 100          NaN         NaN         NaN         NaN   NaN
>> Lag 500          NaN         NaN         NaN         NaN   NaN
>> Lag 1000         NaN         NaN         NaN         NaN   NaN
>> Lag 5000         NaN         NaN         NaN         NaN   NaN
>>
>>
>>
>>
>>  summary(fallmid.MCMCglmm.tweak)
>>>
>>
>>  Iterations = 37501:149901
>>  Thinning interval  = 100
>>  Sample size  = 1125
>>
>>  DIC: 1586.166
>>
>>  G-structure:  ~us(fin_B):subj_ID
>>
>>             post.mean l-95% CI u-95% CI eff.samp
>> f:f.subj_ID    2.8329    1.351   4.4789    626.6
>> m:f.subj_ID   -0.4024   -1.301   0.5999   1125.0
>> f:m.subj_ID   -0.4024   -1.301   0.5999   1125.0
>> m:m.subj_ID    3.3495    1.665   4.9086    481.2
>>
>>  R-structure:  ~units
>>
>>       post.mean l-95% CI u-95% CI eff.samp
>> units         1        1        1        0
>>
>>  Location effects: resp_X ~ lang * ini_pch + lang * manner + lang * fin_B
>>
>>                 post.mean l-95% CI u-95% CI eff.samp   pMCMC
>> (Intercept)      -2.12231 -2.99651 -1.19650   1125.0 < 9e-04 ***
>> langde            0.86672 -0.33061  2.13741   1125.0 0.15467
>> langen            0.17379 -1.32158  1.96542   1021.4 0.83556
>> langsw            0.60668 -1.11771  2.00774   1125.0 0.44622
>> ini_pchm          0.31321 -0.36251  0.94373   1125.0 0.33956
>> ini_pchr         -0.01135 -0.61257  0.65751   1005.5 0.97600
>> mannerla          0.02540 -0.64462  0.60490   1125.0 0.93689
>> mannerna         -0.29521 -0.87690  0.37917   1125.0 0.38222
>> fin_Bm            2.57100  1.54529  3.81118   1019.3 < 9e-04 ***
>> langde:ini_pchm  -0.62639 -1.44799  0.26281   1026.4 0.14044
>> langen:ini_pchm   0.13596 -0.98973  1.23208    975.7 0.81244
>> langsw:ini_pchm   0.27390 -0.87134  1.31791   1125.0 0.63644
>> langde:ini_pchr  -0.89823 -1.79517 -0.03409   1256.7 0.05511 .
>> langen:ini_pchr  -1.30494 -2.58387 -0.09301    911.7 0.05333 .
>> langsw:ini_pchr  -0.08782 -1.13757  1.02182   1010.0 0.89422
>> langde:mannerla  -0.24312 -1.13861  0.63645   1125.0 0.59378
>> langen:mannerla  -0.58499 -1.78324  0.61955   1125.0 0.32000
>> langsw:mannerla   0.58872 -0.52892  1.64295   1125.0 0.27733
>> langde:mannerna   0.47920 -0.33966  1.37083   1125.0 0.30756
>> langen:mannerna   0.79813 -0.35619  1.89286   1125.0 0.19911
>> langsw:mannerna   0.72797 -0.29891  1.89281   1125.0 0.19911
>> langde:fin_Bm    -1.90047 -3.36978 -0.31952    997.2 0.00889 **
>> langen:fin_Bm    -1.44445 -3.59097  0.42764    964.4 0.15467
>> langsw:fin_Bm    -2.80490 -5.03965 -1.07777   1125.0 0.00533 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>>
>>
>> Zitat von Jarrod Hadfield <j.hadfield at ed.ac.uk>:
>>
>>
>>  Hi Szymek,
>>>
>>> Whoops  - I forgot it was dichotomous. idh(X):Y is probably more
>>> appropriate. (1+x) fits two effects; a) Y effects for the first
>>> level of X and b) the difference between Y effects between the two
>>> levels.  If X was continous it would make more sense because it
>>> would be intercept and slope.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>> Quoting Szymek Drobniak <geralttee at gmail.com> on Fri, 15 Nov 2013
>>> 21:47:35 +0100:
>>>
>>>  Hello,
>>>>
>>>> thank you Jarrod for clarifying things, I obviously made a mistake with
>>>> the
>>>> nu value. I was also wondering - what is the interpretation of idh(1+X):Y
>>>> in case X is a dichotomous variable?
>>>>
>>>> Cheers,
>>>> sz.
>>>>
>>>>
>>>> On 14 November 2013 18:23, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>
>>>>  Hi Maria,
>>>>>
>>>>> random = ~us(1):subj_ID + us(fin_B):subj_ID  is the same as
>>>>> idh(1+finB):subj_ID and is not the same as (1 + fin_B|subj_ID) in lmer
>>>>> because the idh fixes the covariance between and intercepts and slopes
>>>>> to
>>>>> zero.  us(1+finB):subj_ID is equivalent to the lmer code.
>>>>>
>>>>> Also, a prior of nu=2 (or nu=2.002) could have quite an influence on
>>>>> your
>>>>> posterior. V=diag(2) and nu=1.002 for the 2x2 case gives a marginal
>>>>> prior
>>>>> on the variances that is equivalent to an inverse gamma with shape and
>>>>> scale equal to 0.001. This prior used to be used a lot, but has some bad
>>>>> properties when values close to zero have support. I often use the
>>>>> parameter expanded prior:
>>>>>
>>>>> list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a)
>>>>>
>>>>> where a is something large.
>>>>>
>>>>> There is no difference between nu and n.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>>>>
>>>>>  And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>>>>> us(fin_B):subj_ID.
>>>>>>
>>>>>>
>>>>>
>>>>> Quoting Maria Paola Bissiri <Maria_Paola.Bissiri at tu-dresden.de> on Thu,
>>>>> 14 Nov 2013 15:06:26 +0000:
>>>>>
>>>>> Dear Szymek,
>>>>>
>>>>>> thank you very much for your answer.
>>>>>>
>>>>>> Yes, the random effects were indicated wrongly in MCMCglmm! My
>>>>>> intention
>>>>>> is of course to look at variance associated with subjects (subj_ID).
>>>>>> I meant (1 + fin_B|subj_ID), as indicated in glmer() (lme4 package).
>>>>>> And this should be indicated in MCMCglmm() as random = ~us(1):subj_ID +
>>>>>> us(fin_B):subj_ID.
>>>>>> Please, correct me if I am wrong.
>>>>>>
>>>>>> So the model runs with:
>>>>>> k <- length(levels(fallmid$resp_X))
>>>>>> I <- diag(k-1)
>>>>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>>>> prior <- list(R = list(fix = 1, V = 0.5 * (I+J), n = 2),
>>>>>>                G = list(G1 = list(V = diag(1), n = 2), G2 = list(V =
>>>>>> diag(2), n = 2)))
>>>>>>
>>>>>> fallmid.MCMCglmm <- MCMCglmm(resp_X ~ lang * ini_pch + lang * manner +
>>>>>> lang * fin_B,
>>>>>>                            random = ~us(1):subj_ID + us(fin_B):subj_ID,
>>>>>>                            family="categorical", data=fallmid,
>>>>>>                            prior=prior
>>>>>>                            )
>>>>>>
>>>>>> In your suggestion you indicate nu=2.002. What does "nu" mean? What is
>>>>>> the difference between nu and n? In the MCMCglmm manual and in
>>>>>> the tutorial
>>>>>> they are both defined as "degrees of belief". What does this mean?
>>>>>>
>>>>>> Kind regards,
>>>>>> Maria Paola
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Zitat von Szymek Drobniak <geralttee at gmail.com>:
>>>>>>
>>>>>> Dear Maria,
>>>>>>
>>>>>>>
>>>>>>> I'm not sure what exactly you're trying to test with your model, but
>>>>>>> to
>>>>>>> start with - your prior specification assumes 2 random effects, and
>>>>>>> your
>>>>>>> model has only one (a structured covariance matrix with fin_B defined
>>>>>>> as
>>>>>>> a
>>>>>>> random effect). This specification you've provided is similar to a
>>>>>>> random
>>>>>>> intercept/slope model - but I can't see why you would like to fit it
>>>>>>> (most
>>>>>>> importantly, you assumed that fin_B is both a fixed and random
>>>>>>> effect).
>>>>>>> If
>>>>>>> your intention was to look at variance associated with subjects
>>>>>>> (subj_ID),
>>>>>>> and you'd like to see if this variance is heterogeneous for different
>>>>>>> levels of fin_B - you could fit:
>>>>>>>
>>>>>>> MCMCglmm(your_fixed_formula_here, random=~us(fin_B):subj_ID, ...)
>>>>>>>
>>>>>>> and the prior would be (assuming fin_B has 2 levels as you've said)
>>>>>>>
>>>>>>> list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2),nu=2.002)))
>>>>>>>
>>>>>>> that's for start, then have a look at mcmc-series plots to see if it
>>>>>>> mixes
>>>>>>> well and tweak your model further if necessary.
>>>>>>>
>>>>>>> Cheer
>>>>>>> szymek
>>>>>>>
>>>>>>>
>>>>>> --
>>>>>> Dr. Maria Paola Bissiri
>>>>>>
>>>>>> TU Dresden
>>>>>> Fakult?t Elektrotechnik und Informationstechnik
>>>>>> Institut f?r Akustik und Sprachkommunikation
>>>>>> 01062 Dresden
>>>>>>
>>>>>> Barkhausen-Bau, Raum S54
>>>>>> Helmholtzstra?e 18
>>>>>>
>>>>>> Tel: +49 (0)351 463-34283
>>>>>> Fax: +49 (0)351 463-37781
>>>>>> E-Mail: Maria_Paola.Bissiri at tu-dresden.de
>>>>>> http://wwwpub.zih.tu-dresden.de/~bissiri/index.htm
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Szymon Drobniak, PhD. || Population Ecology Group
>>>> Institute of Environmental Sciences, Jagiellonian University
>>>> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
>>>> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
>>>> szymek.drobniak at uj.edu.pl
>>>> www.eko.uj.edu.pl/drobniak
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>
>>
>
>
> --
> Szymon Drobniak, PhD. || Population Ecology Group
> Institute of Environmental Sciences, Jagiellonian University
> ul. Gronostajowa 7, 30-387 Krak?w, POLAND
> tel.: +48 12 664 51 79 fax: +48 12 664 69 12
> szymek.drobniak at uj.edu.pl
> www.eko.uj.edu.pl/drobniak


From segerfan83 at gmail.com  Thu Nov 21 20:47:41 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Thu, 21 Nov 2013 14:47:41 -0500
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
Message-ID: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131121/ed2e1ca7/attachment.pl>

From bbolker at gmail.com  Thu Nov 21 20:48:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Nov 2013 14:48:13 -0500
Subject: [R-sig-ME] lme4: constrain sigma to 0
In-Reply-To: <528E4605.5060607@uni-mannheim.de>
References: <528E4605.5060607@uni-mannheim.de>
Message-ID: <528E637D.2070302@gmail.com>

On 13-11-21 12:42 PM, Maya Machunsky wrote:
>  Dear Dr. Bolker,
> 
> I am using lmer to estimate fixed effects for exerimental data (in
> Psychology). At the moment I am trying to run a model in which the
> residual variance is fixed to 0 and I am wondering whether it is
> possible to run such a model with lmer. I found messages from 2011 (a
> discussion between you and Rolf Turner) according to which it was not
> possible to constrain sigma to 0. Now I am asking myself whether it is
> now with a new version of the lme4 package possible.
> 
> Thanks a lot in advance and
> best regards,
> Maya Machunsky

  No, still not possible (or at least not easy), because the
residual variance is profiled out, so it doesn't enter directly
into the calculations -- it's not a parameter you can set.

  You can sort of achieve this using blmer to set a 'point' prior
on sigma (i.e. fix it at a specific value) -- but you can't set the
residual variance to *exactly* zero.

library(lme4)
## fit model
fm0 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy)
library(blme)
fm1 <- blmer(Reaction ~ Days + (1 | Subject), sleepstudy,
       cov.prior=NULL,
       resid.prior=point(0.0001))

sumfun <- function(fm) {
    c(sd_Subject=unname(sqrt(unlist(VarCorr(fm)))),
      sd_Residual=sigma(fm),
      REMLdev=unname(deviance(fm)))

}
cfun <- function(sigma=1) {
    fm <- blmer(Reaction ~ Days + (1 | Subject), sleepstudy,
                cov.prior=NULL,
                resid.prior=point(sigma))
    sumfun(fm)
}
svec <- c(10^seq(-5,2,by=0.25),20:60)
sigmaprof <- rbind(sumfun(fm0),t(sapply(svec,cfun)))

sigmaprof <- as.data.frame(sigmaprof[order(sigmaprof[,"sd_Residual"]),])
par(las=1,bty="l")

## REML deviance vs. residual value -- LOG scale
plot(REMLdev~sd_Residual,data=sigmaprof,type="b",log="xy")
abline(v=sigma(fm0),col=2)
## leave out last point to improve scaling
plot(sd_Subject~sd_Residual,data=sigmaprof[-30,],type="b",log="x")
abline(v=sigma(fm0),col=2)

plot(REMLdev~sd_Residual,data=sigmaprof,
    subset=REMLdev-min(REMLdev)<30,type="b",log="xy")

Compare with the likelihood profile:

pp <- profile(fm1)
xyplot(pp)


There *might* also be a way to do this by digging into the
profiling machinery a bit more.

  As always, corrections and improvements are welcome.


From segerfan83 at gmail.com  Thu Nov 21 21:06:54 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Thu, 21 Nov 2013 15:06:54 -0500
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
	<CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>
Message-ID: <CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131121/2a0b183b/attachment.pl>

From bbolker at gmail.com  Thu Nov 21 21:10:44 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Nov 2013 15:10:44 -0500
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
Message-ID: <528E68C4.5030500@gmail.com>

On 13-11-21 02:47 PM, AvianResearchDivision wrote:
> Hi all,
> 
> I've read multiple times that using LRT to test the significance of random
> effects terms in mixed models yields conservative p-values and that one way
> to correct this is to divide the p value in half.  Is this a hard fast rule
> or is there a script for R that gives an actual corrected value?
> 
> Thank you,
> Jacob

  It's not hard and fast.  Fabian Scheipl's RLRsim package gives a fast
stochastic algorithm for getting the correct null distribution in these
cases, but it only works for a subset of models.  I *believe* (but may
misremember) that for the simple case of a single, scalar random effect
(i.e. a single blocking factor with an intercept effect only, ~ ... +
(1|block)) that the null distribution is provably 0.5*chi^2(0) +
0.5*chi^2(1) (i.e., you should divide by 2), but (1) this might only
hold for LMMs (not GLMMs) and (2) it might only hold asymptotically and
(3) it definitely doesn't hold for more complex random-effects models.
Pinheiro and Bates 2000 discuss this (as referenced in
http://glmm.wikidot.com/faq#random-sig ; I believe the ur-reference is
Stram and Lee (1994), it's also discussed briefly in Bolker (2008) p 250:

http://ms.mcmaster.ca/~bolker/misc/Bolker_2008_p250.pdf

P&B incorporated simulation machinery in nlme (?simulate.lme -- note
that simulate.lme *predates* the more general simulate() accessor in
base R, and works differently); this sort of functionality can be
replicated pretty easily with lme4, but it will be slow.


Stram, Daniel O, and Jae Won Lee. 1994. ?Variance Components Testing in
the Longitudinal Fixed E?ects Model.? Biometrics 50 (4): 1171?1177.
http://links.jstor.org/sici?sici=0006-341X%28199412%2950%3A4%3C1171%3AVCTITL%3E2.0.CO%3B2-H.


From Paul.Thompson at SanfordHealth.org  Thu Nov 21 21:21:42 2013
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Thu, 21 Nov 2013 20:21:42 +0000
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
	<CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>
	<CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>

I have never heard of a rule of "dividing the p values in half". There are corrections like Bonferroni but these depend on the number of tests. 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of AvianResearchDivision
Sent: Thursday, November 21, 2013 2:07 PM
To: Philippi, Tom; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Testing Random Effects--On the Boundary

Hi Tom,

I have read that page.  I see there are 6 options, but I am curious about using LRT in particular and using a corrected p value, rather than other options.  I see people floating around the suggestion to divide the p value in half, but there has to be a more exact calculation maybe?  Then again, maybe not because of the nature of the issue.

Jacob


On Thu, Nov 21, 2013 at 3:04 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:

> Jacob--
> Have you read the r-sig-mixed-models FAQ and the references it points to:
> http://glmm.wikidot.com/faq
>
> I don't know if you can do the parametric bootstrap tests for random 
> effects using PBmodcomp in package pbkrtest, as I only test for fixed 
> effects.
>
> I hope that this helps...
> Tom
>
>
> On Thu, Nov 21, 2013 at 11:47 AM, AvianResearchDivision < 
> segerfan83 at gmail.com> wrote:
>
>> Hi all,
>>
>> I've read multiple times that using LRT to test the significance of 
>> random effects terms in mixed models yields conservative p-values and 
>> that one way to correct this is to divide the p value in half.  Is 
>> this a hard fast rule or is there a script for R that gives an actual 
>> corrected value?
>>
>> Thank you,
>> Jacob
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> -------------------------------------------
> Tom Philippi, Ph.D.
> Quantitative Ecologist & Data Therapist Inventory and Monitoring 
> Program National Park Service
> (619) 523-4576
> Tom_Philippi at nps.gov
> http://science.nature.nps.gov/im/monitor
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.


From bbolker at gmail.com  Thu Nov 21 21:25:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Nov 2013 15:25:35 -0500
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>	<CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>	<CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <528E6C3F.4040706@gmail.com>

On 13-11-21 03:21 PM, Thompson,Paul wrote:
> I have never heard of a rule of "dividing the p values in half".
> There are corrections like Bonferroni but these depend on the number
> of tests.
> 

  See my answer to this question ...  The "divide by half rule" applies
when the null value of a single parameter in a linear mixed model is on
the boundary (i.e. H0: variance=0). It's not at all related to multiple
comparisons corrections, but to a modification of the sampling
distribution expected under the null hypothesis, from likelihood theory ...

  cheers
    Ben Bolker


From geralttee at gmail.com  Thu Nov 21 23:47:24 2013
From: geralttee at gmail.com (Szymek Drobniak)
Date: Thu, 21 Nov 2013 23:47:24 +0100
Subject: [R-sig-ME] Define prior in MCMCglmm
In-Reply-To: <20131121191935.Horde.HCkpUekS14113gGx2EuZww3@mail.zih.tu-dresden.de>
References: <CANXb-o7yPLmTtRs-cRWKQoy45Z_UWYC=RNZQmyea6m4sc6JRLg@mail.gmail.com>
	<20131114150626.Horde.miY2NM7OJp_3_42YHFMS9w1@mail.zih.tu-dresden.de>
	<20131114172337.87105zbwvxa1rako@www.staffmail.ed.ac.uk>
	<CANXb-o6uwsEkHADKEV_PF0-2VqHrTFA6iKd4b0VvKyirM4q+dw@mail.gmail.com>
	<20131116075012.187641thala2xbqc@www.staffmail.ed.ac.uk>
	<20131120195030.Horde.-F0IZ62N73o2N7New1yl4Q6@mail.zih.tu-dresden.de>
	<CANXb-o61cA0AtbAPFXaD5a5rQm0fxBr+95j_y3ONQkk31OqFug@mail.gmail.com>
	<20131121191935.Horde.HCkpUekS14113gGx2EuZww3@mail.zih.tu-dresden.de>
Message-ID: <CANXb-o4TBpg7DMYyC=KbRWjRDtct9XBL_AD17=pgCq-UnROhvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131121/aa31242f/attachment.pl>

From M.Fairbrother at bristol.ac.uk  Fri Nov 22 01:17:26 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 22 Nov 2013 00:17:26 +0000
Subject: [R-sig-ME] JOBS: 5 New Academic Posts in Quantitative Social
 Science at the University of Bristol
Message-ID: <CAAH-yP_AjTcPubyLjRz=QwTDsvW0=VDK6VFtuNYk9A1Km008cQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131122/27a9f575/attachment.pl>

From m.geraci at ucl.ac.uk  Fri Nov 22 09:30:29 2013
From: m.geraci at ucl.ac.uk (Geraci, Marco)
Date: Fri, 22 Nov 2013 08:30:29 +0000
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <528E68C4.5030500@gmail.com>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
	<528E68C4.5030500@gmail.com>
Message-ID: <18b7ebba5e6e4848b353bace39c8378e@AMXPR01MB087.eurprd01.prod.exchangelabs.com>

I believe Ben is referring to Self and Liang (1987) results. Alternatively, there is a score-type test (Biometrika, 2003, 90, pp 73-84) which performs quite well in LMMs. I applied it to semiparametric models (Statistics in Medicine, 2008, 27, pp 2902-2921). Let me know if that is something you want to try out. I have the code but will have to dig it out from an untidy collection of functions.

best wishes

Marco

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: 21 November 2013 20:11
To: AvianResearchDivision; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Testing Random Effects--On the Boundary

On 13-11-21 02:47 PM, AvianResearchDivision wrote:
> Hi all,
> 
> I've read multiple times that using LRT to test the significance of 
> random effects terms in mixed models yields conservative p-values and 
> that one way to correct this is to divide the p value in half.  Is 
> this a hard fast rule or is there a script for R that gives an actual corrected value?
> 
> Thank you,
> Jacob

  It's not hard and fast.  Fabian Scheipl's RLRsim package gives a fast stochastic algorithm for getting the correct null distribution in these cases, but it only works for a subset of models.  I *believe* (but may
misremember) that for the simple case of a single, scalar random effect (i.e. a single blocking factor with an intercept effect only, ~ ... +
(1|block)) that the null distribution is provably 0.5*chi^2(0) +
0.5*chi^2(1) (i.e., you should divide by 2), but (1) this might only hold for LMMs (not GLMMs) and (2) it might only hold asymptotically and
(3) it definitely doesn't hold for more complex random-effects models.
Pinheiro and Bates 2000 discuss this (as referenced in http://glmm.wikidot.com/faq#random-sig ; I believe the ur-reference is Stram and Lee (1994), it's also discussed briefly in Bolker (2008) p 250:

http://ms.mcmaster.ca/~bolker/misc/Bolker_2008_p250.pdf

P&B incorporated simulation machinery in nlme (?simulate.lme -- note that simulate.lme *predates* the more general simulate() accessor in base R, and works differently); this sort of functionality can be replicated pretty easily with lme4, but it will be slow.


Stram, Daniel O, and Jae Won Lee. 1994. ?Variance Components Testing in the Longitudinal Fixed E?ects Model.? Biometrics 50 (4): 1171?1177.
http://links.jstor.org/sici?sici=0006-341X%28199412%2950%3A4%3C1171%3AVCTITL%3E2.0.CO%3B2-H.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From James.Grecian at glasgow.ac.uk  Fri Nov 22 11:54:28 2013
From: James.Grecian at glasgow.ac.uk (James Grecian)
Date: Fri, 22 Nov 2013 10:54:28 +0000
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
	<CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>
	<CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <1E74325F1E320E4FAAEB051976822A0D3C085A2C7E@CMS03.campus.gla.ac.uk>

Hi all,

Have you tried Scheipl's RLRsim package? http://cran.r-project.org/web/packages/RLRsim/index.html

I found it really useful for testing the importance of random effects. It will simulate a p value based on LRT for you.

Best,

James


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thompson,Paul
Sent: 21 November 2013 20:22
To: AvianResearchDivision; Philippi, Tom; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Testing Random Effects--On the Boundary

I have never heard of a rule of "dividing the p values in half". There are corrections like Bonferroni but these depend on the number of tests. 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of AvianResearchDivision
Sent: Thursday, November 21, 2013 2:07 PM
To: Philippi, Tom; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Testing Random Effects--On the Boundary

Hi Tom,

I have read that page.  I see there are 6 options, but I am curious about using LRT in particular and using a corrected p value, rather than other options.  I see people floating around the suggestion to divide the p value in half, but there has to be a more exact calculation maybe?  Then again, maybe not because of the nature of the issue.

Jacob


On Thu, Nov 21, 2013 at 3:04 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:

> Jacob--
> Have you read the r-sig-mixed-models FAQ and the references it points to:
> http://glmm.wikidot.com/faq
>
> I don't know if you can do the parametric bootstrap tests for random 
> effects using PBmodcomp in package pbkrtest, as I only test for fixed 
> effects.
>
> I hope that this helps...
> Tom
>
>
> On Thu, Nov 21, 2013 at 11:47 AM, AvianResearchDivision < 
> segerfan83 at gmail.com> wrote:
>
>> Hi all,
>>
>> I've read multiple times that using LRT to test the significance of 
>> random effects terms in mixed models yields conservative p-values and 
>> that one way to correct this is to divide the p value in half.  Is 
>> this a hard fast rule or is there a script for R that gives an actual 
>> corrected value?
>>
>> Thank you,
>> Jacob
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> -------------------------------------------
> Tom Philippi, Ph.D.
> Quantitative Ecologist & Data Therapist Inventory and Monitoring 
> Program National Park Service
> (619) 523-4576
> Tom_Philippi at nps.gov
> http://science.nature.nps.gov/im/monitor
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including a...{{dropped:11}}


From fbromano at sabanciuniv.edu  Fri Nov 22 13:05:29 2013
From: fbromano at sabanciuniv.edu (Francesco)
Date: Fri, 22 Nov 2013 14:05:29 +0200
Subject: [R-sig-ME] Post-hoc comparison for incorrect responses in glmer
In-Reply-To: <528F4734.2040203@sabanciuniv.edu>
References: <528F4734.2040203@sabanciuniv.edu>
Message-ID: <528F4889.5090301@sabanciuniv.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131122/387176d2/attachment.pl>

From segerfan83 at gmail.com  Fri Nov 22 17:42:51 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Fri, 22 Nov 2013 11:42:51 -0500
Subject: [R-sig-ME] Testing Random Effects--On the Boundary
In-Reply-To: <1E74325F1E320E4FAAEB051976822A0D3C085A2C7E@CMS03.campus.gla.ac.uk>
References: <CAHe08Sh8mjdA8y5bJ9yCaP7s=raJtzmBnSzAw2z7p=w5A7M0jw@mail.gmail.com>
	<CAM9kYqjjUR9QN6MQnTShJGjus7q_Yg9mcUkFKVerVNPhtqZP0Q@mail.gmail.com>
	<CAHe08ShJJQNYJhvRoep81CUb78b9Dhm2BC2BMGYoxueKeQGqDw@mail.gmail.com>
	<9B75E7CF385CB94EAD6587DD96AC2D97D070A836@SFSMCEXMBX3.sanfordhealth.org>
	<1E74325F1E320E4FAAEB051976822A0D3C085A2C7E@CMS03.campus.gla.ac.uk>
Message-ID: <CAHe08SiexRmb+gyc=ikYULwbBEJGXmtycwb57yR+MGYkqB7oRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131122/5b82f58b/attachment.pl>

From fbromano at sabanciuniv.edu  Sat Nov 23 12:23:09 2013
From: fbromano at sabanciuniv.edu (Francesco)
Date: Sat, 23 Nov 2013 13:23:09 +0200
Subject: [R-sig-ME] Post-hoc comparison for incorrect responses in glmer
Message-ID: <5290901D.4010208@sabanciuniv.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131123/0b47851b/attachment.pl>

From fbromano at sabanciuniv.edu  Sat Nov 23 16:23:09 2013
From: fbromano at sabanciuniv.edu (Francesco)
Date: Sat, 23 Nov 2013 17:23:09 +0200
Subject: [R-sig-ME] Post-hoc comparison for incorrect responses in glmer
In-Reply-To: <5290901D.4010208@sabanciuniv.edu>
References: <5290901D.4010208@sabanciuniv.edu>
Message-ID: <5290C85D.2050202@sabanciuniv.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131123/01ee9410/attachment.pl>

From david at harsk.dk  Sun Nov 24 08:54:57 2013
From: david at harsk.dk (David Westergaard)
Date: Sun, 24 Nov 2013 15:54:57 +0800
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
	very few data points
Message-ID: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>

Hello everyone,

First off, I've posted a similar question to StackExchange
(http://stats.stackexchange.com/questions/76980/analysis-of-longitudinal-data-with-very-few-points),
but I received no answers.

To summarise the data: From 2 subjects, 8 response values were
measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
treatment. Subject 1 received no further treatment after T1.

I've reasoned that this is a repeated measures mixed model kind of
design, so I tried to fit a linear model with random effects, using
lme4:

lm1 <- lmer(Response ~ Treatment * Timepoint + (1|Subject),
data=my_data,REML=FALSE)

However, I am not sure if this model is "correct," I have entered time
points as factorial values, but I am ensure if they should instead be
numerical values. They are quite spread. On a side note, if I don't
set REML=FALSE, I get an error "Computed variance-covariance matrix is
not positive definite" when I try to run "summary(lm1)". I'm guessing
this may have something to do with my sample size.

I am a bit unsure of how to evaluate the model. The number of data
points is extremely low. My naive approach was to make an alternative
model, which does not include treatment:

lm2 <- lmer(Response ~  Timepoint + (1|subject_id), data=test,REML=FALSE)

And do an ANOVA to see which one fits the data better. This is the output:
anova(lm1,lm2)
        Df     AIC     BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
lm2  6   87.12   87.60 -37.561    75.12
lm1 10 -453.72 -452.93 236.860  -473.72 548.84      4  < 2.2e-16 ***

>From this, can I conclude that lm1 fits the data significantly better,
and is a reliable model?

What I'm trying to investigate, is:

1. Is there any observable effect after administering the drug (i.e.
is the difference between response values significantly greater than
zero)
2. If there is an effect, what is the effect size at each time point
(i.e. what is the difference between response values)
3. How does the effect vary over time
4. If there is an effect, is the effect observed from the drug at T1
still persistant at T3

Any help on this matter is much appreciated.

Regards,
David


From pierces1 at msu.edu  Sun Nov 24 15:41:52 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 24 Nov 2013 09:41:52 -0500
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data
	with	very few data points
In-Reply-To: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
Message-ID: <003301cee923$51098a70$f31c9f50$@msu.edu>

You probably need data from a lot more subjects to get good estimates of the
parameters in that model. 


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
E-mail: pierces1 at msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: David Westergaard [mailto:david at harsk.dk] 
Sent: Sunday, November 24, 2013 2:55 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
very few data points

Hello everyone,

First off, I've posted a similar question to StackExchange
(http://stats.stackexchange.com/questions/76980/analysis-of-longitudinal-dat
a-with-very-few-points),
but I received no answers.

To summarise the data: From 2 subjects, 8 response values were
measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
treatment. Subject 1 received no further treatment after T1.

I've reasoned that this is a repeated measures mixed model kind of
design, so I tried to fit a linear model with random effects, using
lme4:

lm1 <- lmer(Response ~ Treatment * Timepoint + (1|Subject),
data=my_data,REML=FALSE)

However, I am not sure if this model is "correct," I have entered time
points as factorial values, but I am ensure if they should instead be
numerical values. They are quite spread. On a side note, if I don't
set REML=FALSE, I get an error "Computed variance-covariance matrix is
not positive definite" when I try to run "summary(lm1)". I'm guessing
this may have something to do with my sample size.

I am a bit unsure of how to evaluate the model. The number of data
points is extremely low. My naive approach was to make an alternative
model, which does not include treatment:

lm2 <- lmer(Response ~  Timepoint + (1|subject_id), data=test,REML=FALSE)

And do an ANOVA to see which one fits the data better. This is the output:
anova(lm1,lm2)
        Df     AIC     BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
lm2  6   87.12   87.60 -37.561    75.12
lm1 10 -453.72 -452.93 236.860  -473.72 548.84      4  < 2.2e-16 ***

>From this, can I conclude that lm1 fits the data significantly better,
and is a reliable model?

What I'm trying to investigate, is:

1. Is there any observable effect after administering the drug (i.e.
is the difference between response values significantly greater than
zero)
2. If there is an effect, what is the effect size at each time point
(i.e. what is the difference between response values)
3. How does the effect vary over time
4. If there is an effect, is the effect observed from the drug at T1
still persistant at T3

Any help on this matter is much appreciated.

Regards,
David


From david at harsk.dk  Sun Nov 24 15:43:36 2013
From: david at harsk.dk (David Westergaard)
Date: Sun, 24 Nov 2013 22:43:36 +0800
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
 very few data points
In-Reply-To: <003301cee923$51098a70$f31c9f50$@msu.edu>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
	<003301cee923$51098a70$f31c9f50$@msu.edu>
Message-ID: <CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>

I agree, but I won't be getting any more data, so I'm trying to find
the least-worst solution, so to speak.

Any suggestions/ideas are most welcome.

Regards,
David

2013/11/24 Steven J. Pierce <pierces1 at msu.edu>:
> You probably need data from a lot more subjects to get good estimates of the
> parameters in that model.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: David Westergaard [mailto:david at harsk.dk]
> Sent: Sunday, November 24, 2013 2:55 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
> very few data points
>
> Hello everyone,
>
> First off, I've posted a similar question to StackExchange
> (http://stats.stackexchange.com/questions/76980/analysis-of-longitudinal-dat
> a-with-very-few-points),
> but I received no answers.
>
> To summarise the data: From 2 subjects, 8 response values were
> measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
> treatment. Subject 1 received no further treatment after T1.
>
> I've reasoned that this is a repeated measures mixed model kind of
> design, so I tried to fit a linear model with random effects, using
> lme4:
>
> lm1 <- lmer(Response ~ Treatment * Timepoint + (1|Subject),
> data=my_data,REML=FALSE)
>
> However, I am not sure if this model is "correct," I have entered time
> points as factorial values, but I am ensure if they should instead be
> numerical values. They are quite spread. On a side note, if I don't
> set REML=FALSE, I get an error "Computed variance-covariance matrix is
> not positive definite" when I try to run "summary(lm1)". I'm guessing
> this may have something to do with my sample size.
>
> I am a bit unsure of how to evaluate the model. The number of data
> points is extremely low. My naive approach was to make an alternative
> model, which does not include treatment:
>
> lm2 <- lmer(Response ~  Timepoint + (1|subject_id), data=test,REML=FALSE)
>
> And do an ANOVA to see which one fits the data better. This is the output:
> anova(lm1,lm2)
>         Df     AIC     BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> lm2  6   87.12   87.60 -37.561    75.12
> lm1 10 -453.72 -452.93 236.860  -473.72 548.84      4  < 2.2e-16 ***
>
> >From this, can I conclude that lm1 fits the data significantly better,
> and is a reliable model?
>
> What I'm trying to investigate, is:
>
> 1. Is there any observable effect after administering the drug (i.e.
> is the difference between response values significantly greater than
> zero)
> 2. If there is an effect, what is the effect size at each time point
> (i.e. what is the difference between response values)
> 3. How does the effect vary over time
> 4. If there is an effect, is the effect observed from the drug at T1
> still persistant at T3
>
> Any help on this matter is much appreciated.
>
> Regards,
> David
>
>
>


From pierces1 at msu.edu  Sun Nov 24 16:32:01 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 24 Nov 2013 10:32:01 -0500
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
	very few data points
In-Reply-To: <CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
	<003301cee923$51098a70$f31c9f50$@msu.edu>
	<CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
Message-ID: <003d01cee92a$522bbf20$f6833d60$@msu.edu>

I don't see any hope of drawing trustworthy conclusions from a dataset this
small given the complexity of the model you want to use and the long list of
things you want to know. 

Maybe the least-worst approach is to accept that this data should not be
analyzed and go search the literature for previously published evidence
pertaining to your question instead, or to advocate for obtaining the
resources required to plan a study with an appropriate sample size and
research design. 

For most of your questions (e.g., pairwise comparisons at each time point),
you have two relevant data points, one with and one without treatment. It
would take a pretty extraordinary set of circumstances to convince me that
this sample is the best evidence one can acquire to answer your questions.
Barring that, doing statistics on data this sparse and using them to support
any serious decision-making seems unethical to me.


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
E-mail: pierces1 at msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: David Westergaard [mailto:david at harsk.dk] 
Sent: Sunday, November 24, 2013 9:44 AM
To: Steven J. Pierce
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Fitting linear mixed model to longitudinal data with
very few data points

I agree, but I won't be getting any more data, so I'm trying to find
the least-worst solution, so to speak.

Any suggestions/ideas are most welcome.

Regards,
David

2013/11/24 Steven J. Pierce <pierces1 at msu.edu>:
> You probably need data from a lot more subjects to get good estimates of
the
> parameters in that model.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: David Westergaard [mailto:david at harsk.dk]
> Sent: Sunday, November 24, 2013 2:55 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
> very few data points
>
> Hello everyone,
>
> First off, I've posted a similar question to StackExchange
>
(http://stats.stackexchange.com/questions/76980/analysis-of-longitudinal-dat
> a-with-very-few-points),
> but I received no answers.
>
> To summarise the data: From 2 subjects, 8 response values were
> measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
> treatment. Subject 1 received no further treatment after T1.
>
> I've reasoned that this is a repeated measures mixed model kind of
> design, so I tried to fit a linear model with random effects, using
> lme4:
>
> lm1 <- lmer(Response ~ Treatment * Timepoint + (1|Subject),
> data=my_data,REML=FALSE)
>
> However, I am not sure if this model is "correct," I have entered time
> points as factorial values, but I am ensure if they should instead be
> numerical values. They are quite spread. On a side note, if I don't
> set REML=FALSE, I get an error "Computed variance-covariance matrix is
> not positive definite" when I try to run "summary(lm1)". I'm guessing
> this may have something to do with my sample size.
>
> I am a bit unsure of how to evaluate the model. The number of data
> points is extremely low. My naive approach was to make an alternative
> model, which does not include treatment:
>
> lm2 <- lmer(Response ~  Timepoint + (1|subject_id), data=test,REML=FALSE)
>
> And do an ANOVA to see which one fits the data better. This is the output:
> anova(lm1,lm2)
>         Df     AIC     BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> lm2  6   87.12   87.60 -37.561    75.12
> lm1 10 -453.72 -452.93 236.860  -473.72 548.84      4  < 2.2e-16 ***
>
> >From this, can I conclude that lm1 fits the data significantly better,
> and is a reliable model?
>
> What I'm trying to investigate, is:
>
> 1. Is there any observable effect after administering the drug (i.e.
> is the difference between response values significantly greater than
> zero)
> 2. If there is an effect, what is the effect size at each time point
> (i.e. what is the difference between response values)
> 3. How does the effect vary over time
> 4. If there is an effect, is the effect observed from the drug at T1
> still persistant at T3
>
> Any help on this matter is much appreciated.
>
> Regards,
> David
>
>
>


From bbolker at gmail.com  Sun Nov 24 18:15:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 24 Nov 2013 12:15:16 -0500
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
 very few data points
In-Reply-To: <CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>	<003301cee923$51098a70$f31c9f50$@msu.edu>
	<CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
Message-ID: <52923424.8090501@gmail.com>

On 13-11-24 09:43 AM, David Westergaard wrote:

> To summarise the data: From 2 subjects, 8 response values were
> measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
> treatment. Subject 1 received no further treatment after T1.

>> 1. Is there any observable effect after administering the drug (i.e.
>> is the difference between response values significantly greater than
>> zero)
>> 2. If there is an effect, what is the effect size at each time point
>> (i.e. what is the difference between response values)
>> 3. How does the effect vary over time
>> 4. If there is an effect, is the effect observed from the drug at T1
>> still persistant at T3


  So you have a total of 64 (2 subjects * 4 times * 8 obs) observations?
Overlooking the problem of extrapolating from two individuals to the
whole population that might get treated, it seems to me it would be
perfectly reasonable to treat this as a regular linear model problem --
specifically, ecologists would call this a "before-after-control-impact"
design.  If the individuals have different underlying time courses then
you won't be able to detect it -- it will be confounded with the
treatment effect.  Most of your questions can be set up as contrasts:
for example, the effect of the drug is represented by the interaction
between (subject) and (T0 vs. {T1,T2,T3}).  (The main effect of subject
gives the difference between subjects: the main effect of (T0 vs.
{T1,T2,T3}) gives the before-after difference for the untreated subject;
the interaction gives the estimated effect size.

  And so on.  (This is a reasonable question, but I don't think it can
be framed as a mixed model question with this design.)

  Ben Bolker


From Thierry.ONKELINX at inbo.be  Mon Nov 25 14:48:17 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 25 Nov 2013 13:48:17 +0000
Subject: [R-sig-ME] [R] lmer specification for random effects:
	contradictory reults
In-Reply-To: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
References: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>

Dear Benedetta,

I think you might want (1+T+Z|subject) as random effects  rather than (1+T|subject) + (1 + Z|subject). The latter has two random intercepts per subject: a recipe for disaster.

Follow-up posts should only go to the mixed models mailing list which I'm cc'ing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Benedetta Cesqui
Verzonden: maandag 25 november 2013 11:13
Aan: r-help at r-project.org
Onderwerp: [R] lmer specification for random effects: contradictory reults

Hi All,



I was wondering if someone could help me to solve this issue with lmer.
In order to understand the best mixed effects model to fit my data, I compared the following options according to the procedures specified in many papers (i.e. Baayen <http://www.google.it/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDsQFjAA
&url=http%3A%2F%2Fwww.ualberta.ca%2F~baayen%2Fpublications%2FbaayenDavidsonB
ates.pdf&ei=FhqTUoXuJKKV7Abds4GYBA&usg=AFQjCNFst7GT7mBX7w9lXItJTtELJSKWJg&si
g2=KGA5MHxOvEGwDxf-Gcqi6g&bvm>  R.H. et al 2008) Here, dT_purs is the response variable, T and Z are the fixed effects, and subject is the random effect. Random and fixed effects are crossed.:

mod0 <- lmer(dT_purs ~ T + Z + (1|subject), data = x)
mod1 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject), data = x)
mod2 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod3 <- lmer(dT_purs ~ T * Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod4 <- lmer(dT_purs ~ T * Z + (1| subject), data = x)


anova(mod0, mod1,mod2, mod3, mod4)



Data: x

Models:

mod0: dT_purs ~ T + Z + (1 | subject)

mod4: dT_purs ~ T * Z + (1 | subject )

mod1: dT_purs ~ T + Z + (1 + T| subject)

mod2: dT_purs ~ T + Z + (1 + T| subject ) + (1 + Z | subject)

mod3: dT_purs ~ T * Z + (1 + T| subject) + (1 + Z | subject)

     Df     AIC     BIC logLik deviance   Chisq Chi Df Pr(>Chisq)

mod0  5 -689.81 -669.46 349.91  -699.81

mod4  6 -689.57 -665.14 350.78  -701.57  1.7532      1   0.185473

mod1  7 -689.12 -660.62 351.56  -703.12  1.5504      1   0.213070

mod2 10 -695.67 -654.97 357.84  -715.67 12.5563      3   0.005701 **

mod3 11 -695.83 -651.05 358.92  -717.83  2.1580      1   0.141825

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





It turns out that mod2 has the right level of complexity for this dataset.

However when I looked at its summary, I got a correlation of -0.87 for the
random effects relative to the T effect and -1 for the random effects
relatively to the Z.





summary(mod2)

Linear mixed model fit by maximum likelihood ['lmerMod']

Formula: dT_purs ~T + Z + (1 + T | subject) + (1 + Z | subject)

   Data: x



      AIC       BIC    logLik  deviance

-695.6729 -654.9655  357.8364 -715.6729



Random effects:

Groups     Name        Variance  Std.Dev. Corr

 subject   (Intercept) 0.0032063 0.05662

            T       0.0117204 0.10826  -0.87

subject.1 (Intercept) 0.0005673 0.02382

            Z           0.0025859 0.05085  1.00

 Residual               0.0104551 0.10225

Number of obs: 433, groups: soggetto, 7



Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.02489    0.03833   0.650

T        0.52010    0.05905   8.808

Z           -0.09019    0.02199  -4.101



Correlation of Fixed Effects:

      (Intr) tempo

T -0.901

Z      0.218 -0.026





If I understand correctly what the correlation parameters reported in the
table are, the correlation of 1 means that, for the Z effects the random
intercept is perfectly collinear with the random slope. Thus, we fit the
wrong model. A random intercept only model would have sufficed.

Am I correct?



If so, should I take mod1 (mod1 <- dT_purs ~ T + Z + (1 + T | subject )
instead of mod2 to fit my data?

Why are these results contradictory?

Finally is a correlation value of -0.87 a too high or an acceptable value ?



Thanks for help me in advance!



Best



Benedetta





---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From webbe at ufl.edu  Tue Nov 26 03:32:51 2013
From: webbe at ufl.edu (Elizabeth Webb)
Date: Mon, 25 Nov 2013 21:32:51 -0500
Subject: [R-sig-ME] nlme repeated measures
Message-ID: <CAJ4DX-t651sMJZQgWqwen_MvG9+CB3beN=JL4RgX9TpztxX0-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131125/a87d7bb8/attachment.pl>

From bbolker at gmail.com  Tue Nov 26 03:38:48 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Nov 2013 21:38:48 -0500
Subject: [R-sig-ME] more worked GLMM examples
Message-ID: <529409B8.9040607@gmail.com>


  I have posted some new worked GLMM examples at
http://rpubs.com/bbolker/glmmchapter . They're still a bit under
construction, so I would welcome feedback.  (Most of the code is shown,
but some grubby bits relevant to making the plots are hidden -- e-mail
me if you want the full .rmd file.)

  Ben Bolker


From david at harsk.dk  Tue Nov 26 03:45:19 2013
From: david at harsk.dk (David Westergaard)
Date: Tue, 26 Nov 2013 10:45:19 +0800
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
 very few data points
In-Reply-To: <52923424.8090501@gmail.com>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
	<003301cee923$51098a70$f31c9f50$@msu.edu>
	<CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
	<52923424.8090501@gmail.com>
Message-ID: <CAGBW5sgnSUS-0x8PxwqPe0TizzC6VOTC3xG5V35GXOjcysEp2Q@mail.gmail.com>

Thank you both for your valuable input. Just to clarify, this is NOT a
clinical study. This is a first of its kind study, and we are
interested in generating hypothesis for further investigation and
experimental evaluation. We accept the limitations of our study, but
we have a need to estimate these things, given data. Especially
because the pattern that we observe makes absolutely perfect sense
biologically.

@Ben, you could put it like that, I guess. In truth, what we have
measured is the total gene abundance. We have then binned the
abundance of individual genes into categories, and its those
categories that we term Response values.

Are there any good introductions to working with contrasts in R? When
I search google, I just get hit by a massive amount of hits, and its a
bit overwhelming. Also, how would you suggest making the design?

Best,
David

2013/11/25 Ben Bolker <bbolker at gmail.com>:
> On 13-11-24 09:43 AM, David Westergaard wrote:
>
>> To summarise the data: From 2 subjects, 8 response values were
>> measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
>> treatment. Subject 1 received no further treatment after T1.
>
>>> 1. Is there any observable effect after administering the drug (i.e.
>>> is the difference between response values significantly greater than
>>> zero)
>>> 2. If there is an effect, what is the effect size at each time point
>>> (i.e. what is the difference between response values)
>>> 3. How does the effect vary over time
>>> 4. If there is an effect, is the effect observed from the drug at T1
>>> still persistant at T3
>
>
>   So you have a total of 64 (2 subjects * 4 times * 8 obs) observations?
> Overlooking the problem of extrapolating from two individuals to the
> whole population that might get treated, it seems to me it would be
> perfectly reasonable to treat this as a regular linear model problem --
> specifically, ecologists would call this a "before-after-control-impact"
> design.  If the individuals have different underlying time courses then
> you won't be able to detect it -- it will be confounded with the
> treatment effect.  Most of your questions can be set up as contrasts:
> for example, the effect of the drug is represented by the interaction
> between (subject) and (T0 vs. {T1,T2,T3}).  (The main effect of subject
> gives the difference between subjects: the main effect of (T0 vs.
> {T1,T2,T3}) gives the before-after difference for the untreated subject;
> the interaction gives the estimated effect size.
>
>   And so on.  (This is a reasonable question, but I don't think it can
> be framed as a mixed model question with this design.)
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Nov 26 04:29:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Nov 2013 22:29:13 -0500
Subject: [R-sig-ME] Fitting linear mixed model to longitudinal data with
 very few data points
In-Reply-To: <CAGBW5sgnSUS-0x8PxwqPe0TizzC6VOTC3xG5V35GXOjcysEp2Q@mail.gmail.com>
References: <CAGBW5sj_1BedgFYYDbd96LZQjCSxa1us3Bm5K2kgQ6psAD+A5w@mail.gmail.com>
	<003301cee923$51098a70$f31c9f50$@msu.edu>
	<CAGBW5sgPregQR=2F-xTWDriAW4M229nSrLG8DH=PdU3zoX1EUw@mail.gmail.com>
	<52923424.8090501@gmail.com>
	<CAGBW5sgnSUS-0x8PxwqPe0TizzC6VOTC3xG5V35GXOjcysEp2Q@mail.gmail.com>
Message-ID: <52941589.4070400@gmail.com>

On 13-11-25 09:45 PM, David Westergaard wrote:
> Thank you both for your valuable input. Just to clarify, this is NOT a
> clinical study. This is a first of its kind study, and we are
> interested in generating hypothesis for further investigation and
> experimental evaluation. We accept the limitations of our study, but
> we have a need to estimate these things, given data. Especially
> because the pattern that we observe makes absolutely perfect sense
> biologically.
> 
> @Ben, you could put it like that, I guess. In truth, what we have
> measured is the total gene abundance. We have then binned the
> abundance of individual genes into categories, and its those
> categories that we term Response values.
> 
> Are there any good introductions to working with contrasts in R? When
> I search google, I just get hit by a massive amount of hits, and its a
> bit overwhelming. Also, how would you suggest making the design?

Maybe

http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf

  (I'd welcome other suggestions from the list)

> 
> Best,
> David
> 
> 2013/11/25 Ben Bolker <bbolker at gmail.com>:
>> On 13-11-24 09:43 AM, David Westergaard wrote:
>>
>>> To summarise the data: From 2 subjects, 8 response values were
>>> measured at time points T0, T1, T2, T3. At T1, subject 1 underwent
>>> treatment. Subject 1 received no further treatment after T1.
>>
>>>> 1. Is there any observable effect after administering the drug (i.e.
>>>> is the difference between response values significantly greater than
>>>> zero)
>>>> 2. If there is an effect, what is the effect size at each time point
>>>> (i.e. what is the difference between response values)
>>>> 3. How does the effect vary over time
>>>> 4. If there is an effect, is the effect observed from the drug at T1
>>>> still persistant at T3
>>
>>
>>   So you have a total of 64 (2 subjects * 4 times * 8 obs) observations?
>> Overlooking the problem of extrapolating from two individuals to the
>> whole population that might get treated, it seems to me it would be
>> perfectly reasonable to treat this as a regular linear model problem --
>> specifically, ecologists would call this a "before-after-control-impact"
>> design.  If the individuals have different underlying time courses then
>> you won't be able to detect it -- it will be confounded with the
>> treatment effect.  Most of your questions can be set up as contrasts:
>> for example, the effect of the drug is represented by the interaction
>> between (subject) and (T0 vs. {T1,T2,T3}).  (The main effect of subject
>> gives the difference between subjects: the main effect of (T0 vs.
>> {T1,T2,T3}) gives the before-after difference for the untreated subject;
>> the interaction gives the estimated effect size.
>>
>>   And so on.  (This is a reasonable question, but I don't think it can
>> be framed as a mixed model question with this design.)
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Nov 26 04:23:44 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Nov 2013 22:23:44 -0500
Subject: [R-sig-ME] nlme repeated measures
In-Reply-To: <CAJ4DX-t651sMJZQgWqwen_MvG9+CB3beN=JL4RgX9TpztxX0-A@mail.gmail.com>
References: <CAJ4DX-t651sMJZQgWqwen_MvG9+CB3beN=JL4RgX9TpztxX0-A@mail.gmail.com>
Message-ID: <52941440.8010809@gmail.com>

On 13-11-25 09:32 PM, Elizabeth Webb wrote:
> Hi All-
> 
> I am trying to fit a light response curve (model photosynthesis based on
> photosynthetically active radiation) with measurements taken on the same
> plots over many days.  I can get the model to converge in nls but to take
> into account the repeated measures, I need to use nlme.  My code is here
> (where the starting values were taken from the nls output):
> 
> ww.light_grouped<-groupedData(gC~par|block/fence/plot,data=ww.light)
> 
> mixedWW<-nlme(model=gC~(alpha*par*Fmax)/(alpha*par+Fmax)+Rd,fixed=alpha+Fmax~1,start=c(alpha=-0.0001795,Fmax=-0.0092121),
>                data=ww.light_grouped,random=Rd~1|block/fence/plot)
> 
> When I run this, I get the following error:
> 
> Error in solve.default(estimates[dimE[1] - (p:1), dimE[2] - (p:1), drop =
> FALSE]) :
>   system is computationally singular: reciprocal condition number =
> 3.55879e-37
> 
> I know that I cannot be the first person to try to fit a repeated measures
> light response curve (most of the literature seems to be on coding in SAS
> though).  Any ideas on how to solve this error or other ways to fit this
> type of curve in R?
> 
> Thanks,
> Elizabeth

  Your main problem is that you also need 'Rd' in the model as a fixed
effect -- the random effects are defined to have mean zero.  (Note that
these data are sufficiently noisy that the block variance = residual
variance/100 (i.e. ratio of 10 in the standard deviations) and that the
other two variance terms are essentially zero ...)

ww.light_grouped<-groupedData(gC~par|block/fence/plot,data=ww.light)

nls0 <- nls(gC~alpha*par*Fmax/(alpha*par+Fmax)+Rd,
            start=c(alpha=-0.0001795,Fmax=-0.0092121,Rd=0),
            data=ww.light)
pframe <- data.frame(par=1:700)
pframe$gC <- predict(nls0,newdata=pframe)

ww.light <- transform(ww.light,
                      bfp=interaction(block,fence,plot))
library(ggplot2)
ggplot(ww.light,aes(x=par,y=gC)) +geom_point(aes(colour=bfp))+
    geom_line(aes(group=bfp,
                  colour=bfp))+
    geom_line(data=pframe,lwd=2,alpha=0.4)

library(mgcv)
ggplot(ww.light,aes(x=par,y=gC)) +geom_point(aes(colour=bfp))+
    geom_smooth(aes(group=interaction(block,fence,plot),
                  colour=interaction(block,fence,plot)),
                se=FALSE,method="gam")+
    geom_line(data=pframe,lwd=2,alpha=0.4)

ggplot(ww.light,aes(x=par,y=gC)) +geom_point(aes(colour=bfp))+
    geom_smooth(aes(group=bfp,
                  colour=bfp),se=FALSE)+
    coord_cartesian(ylim=c(-0.03,0.04))

mixedWW<-nlme(model=gC~(alpha*par*Fmax)/(alpha*par+Fmax)+Rd,

fixed=alpha+Fmax+Rd~1,start=c(alpha=-0.0001795,Fmax=-0.0092121,
                                 Rd=0.0139),
              data=ww.light,random=Rd~1|bfp)

mixedWW2<-nlme(model=gC~(alpha*par*Fmax)/(alpha*par+Fmax)+Rd,

fixed=alpha+Fmax+Rd~1,start=c(alpha=-0.0001795,Fmax=-0.0092121,
                                 Rd=0.0139),
              data=ww.light,random=Rd~1|block/fence/plot)


> 
> P.S. My data:
>> dput(ww.light)
> structure(list(par = c(212, 208, 503, 89, 61.9, 155, 49, 35,
> 641.5, 532.6, 345, 559, 80, 33, 21, 173, 750, 210, 151, 169,
> 334, 34, 17, 121, 689.5, 689.5, 140, 152, 116, 142, 183, 366,
> 24, 68, 119, 626, 603.9, 364, 194, 118, 185, 149, 45, 383, 83,
> 81, 141, 308.6, 300, 297, 500, 27, 25, 315, 97, 76, 165, 487.7,
> 453.2), gC = c(0.00823490377389, 0.001915093741032, -0.022289772410622,
> 0.0227122610049, 0.02557586905398, 0.02456920537407, 0.002374206642954,
> 0.013696390897218, 0.040337047839618, 0.009981229463982, -0.00674478119502,
> -0.001055959594434, 0.030835240675164, 0.006106703096412, 0.01421021063421,
> -0.000526876101036, 0.00202679213112, -0.000838672558272, 0.00509918585139,
> 0.006495516099864, 0.001626921909792, 0.006247252588266, 0.004622651392392,
> 0.00063338751144, 0.002997109554102, 0.010496218151088, 0.002770538321952,
> -0.003660578166654, -0.00229353987582, 0.004299458228208,
> 0.003570011155386,
> -0.004095960060402, 0.00200178972513, 0.007373300376096, 0.001331055108216,
> 0.009435928103748, 0.026637682283982, -0.006434379185256,
> -0.001959871385466,
> 0.010275562922436, -0.000594160634394, 0.015110760372264, 0.01182487186701,
> 0.004280099006556, 0.00569932660827, 0.00988832461734, 0.002471339105676,
> 0.020481226398234, 0.004056278470344, -0.00501195668094, -0.0063009487386,
> 0.00757298331279, 0.021282565362282, 0.006687425246994, 0.00579015733752,
> 0.010894561817346, 0.007070991129486, 0.020669872048848, 0.005616670768956
> ), block = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L), .Label = c("A", "B", "C"), class = "factor"), fence = c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), plot = structure(c(6L,
> 8L, 8L, 6L, 8L, 8L, 8L, 8L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 6L, 8L,
> 8L, 6L, 8L, 8L, 8L, 8L, 8L, 6L, 8L, 6L, 8L, 8L, 6L, 8L, 8L, 8L,
> 8L, 8L, 6L, 8L, 6L, 8L, 6L, 8L, 6L, 8L, 8L, 8L, 8L, 8L, 6L, 6L,
> 8L, 8L, 6L, 8L, 8L, 8L, 8L, 8L, 6L, 8L), .Label = c("1", "2",
> "3", "4", "5", "6", "7", "8", "A", "B", "C", "D"), class = "factor")),
> .Names = c("par",
> "gC", "block", "fence", "plot"), row.names = c(630L, 632L, 634L,
> 638L, 640L, 642L, 646L, 648L, 649L, 651L, 654L, 656L, 659L, 663L,
> 665L, 669L, 671L, 673L, 675L, 677L, 679L, 681L, 683L, 685L, 687L,
> 689L, 691L, 693L, 695L, 697L, 699L, 701L, 703L, 705L, 707L, 709L,
> 711L, 713L, 715L, 717L, 719L, 721L, 723L, 725L, 727L, 729L, 731L,
> 733L, 737L, 739L, 741L, 743L, 745L, 747L, 749L, 751L, 753L, 755L,
> 757L), class = "data.frame")
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Thierry.ONKELINX at inbo.be  Tue Nov 26 10:29:26 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 26 Nov 2013 09:29:26 +0000
Subject: [R-sig-ME] [R] lmer specification for random effects:
	contradictory reults
In-Reply-To: <000301cee9ed$02ef6f10$08ce4d30$@cesqui@hsantalucia.it>
References: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
	<AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>
	<000301cee9ed$02ef6f10$08ce4d30$@cesqui@hsantalucia.it>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB04E3C@inbomail.inbo.be>

IMHO, if your design requires a random effect, then you add it to the model. Significance is irrelevant in that case.

Comparing mod2.1 and mod2.4 is not testing for a random slope but for the fixed effect of Z. Instead you should compare a model with (1 + T + Z|subject) versus a model with (1 + T | subject). Note that a) you must use REML for that comparison and b) you are testing on the boundary.

Zuur et al (2009) has a nice introduction on model building for mixed models.

@BOOK{
  title = {{M}ixed {E}ffects {M}odels and {E}xtensions in {E}cology with {R}},
  publisher = {Springer New York},
  year = {2009},
  author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil J. and Saveliev,
        Anatoly A. and Smith, Graham M.},
  doi = {10.1007/978-0-387-87458-6}
}

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Benedetta Cesqui [mailto:b.cesqui at hsantalucia.it]
Verzonden: maandag 25 november 2013 15:46
Aan: ONKELINX, Thierry; r-help at r-project.org
CC: r-sig-mixed-models at r-project.org
Onderwerp: R: [R] lmer specification for random effects: contradictory reults

Dear Thierry,

thank you for the quick reply.
I have only one question about the approach you proposed.
As you suggested, imagine that the model we end up after the model selection procedure is:

mod2.1 <- lmer(dT_purs ~ T + Z + (1 +T+Z| subject), data =x, REML= FALSE)

According to the common procedures specified in many manuals and recent papers, if I want to compute the p_values relative to each term, I will perform a likelihood test, in which the deviance of the (-2LL) of a model containing the specific term is compared to another model without it.
In the case of the fixed effect terms I have no problem in the interpretation of the results. Each comparison returns a significance associated with the estimated coefficient of the term.
Thus in this case:

mod2.2 <- lmer(dT_purs ~ Z + (1 +T+Z|soggetto)  , data = x, REML = FALSE)
mod2.3 <- lmer(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x, REML = FALSE) anova(mod2.1, mod2.2) p_valueT = 3.203e-05 anova(mod2.1, mod2.3) p_valueZ = 0.001793

What about the p_value relative to the (1+T+Z|subject)?
One option is to compute:
mod2.4 <- lm(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x) and then execute the loklikelihood test as follows:

L0 <-logLik(mod2.4)
L1 <-logLik(mod2.1)
LR <--2*(L1-L0)
pv <- pchisq(LR,2,ncp = 0, lower.tai=FALSE,log.p = FALSE)

However, what can I conclude on the random slopeif it is significant?

With the previouse approach using the model:
mod2 <- lmer(dT_purs ~ T + Z + (1 +T| subject) + (1+ Z| subject), data =x)

The comparison among the models in which the different termd were included/excluded provided me the following results:
        p_valueT = 1.269e-07;
        p_valueZ =0.00322
        p_valueTS =  0.4277
        p_valueZS = 0.005701

I interpreted the ones relative to the random effects as if the subjects differed not only in their overall responses, but also in the nature of their response dT_purse values in the different T conditions, but not in the different Z conditions.

Benedetta


-----Messaggio originale-----
Da: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
Inviato: luned? 25 novembre 2013 14:48
A: Benedetta Cesqui; r-help at r-project.org
Cc: r-sig-mixed-models at r-project.org
Oggetto: RE: [R] lmer specification for random effects: contradictory reults

Dear Benedetta,

I think you might want (1+T+Z|subject) as random effects  rather than
(1+T|subject) + (1 + Z|subject). The latter has two random intercepts per
subject: a recipe for disaster.

Follow-up posts should only go to the mixed models mailing list which I'm cc'ing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
Namens Benedetta Cesqui
Verzonden: maandag 25 november 2013 11:13
Aan: r-help at r-project.org
Onderwerp: [R] lmer specification for random effects: contradictory reults

Hi All,



I was wondering if someone could help me to solve this issue with lmer.
In order to understand the best mixed effects model to fit my data, I compared the following options according to the procedures specified in many papers (i.e. Baayen <http://www.google.it/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDsQFjAA
&url=http%3A%2F%2Fwww.ualberta.ca%2F~baayen%2Fpublications%2FbaayenDavidsonB
ates.pdf&ei=FhqTUoXuJKKV7Abds4GYBA&usg=AFQjCNFst7GT7mBX7w9lXItJTtELJSKWJg&si
g2=KGA5MHxOvEGwDxf-Gcqi6g&bvm>  R.H. et al 2008) Here, dT_purs is the response variable, T and Z are the fixed effects, and subject is the random effect. Random and fixed effects are crossed.:

mod0 <- lmer(dT_purs ~ T + Z + (1|subject), data = x)
mod1 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject), data = x)
mod2 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod3 <- lmer(dT_purs ~ T * Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod4 <- lmer(dT_purs ~ T * Z + (1| subject), data = x)


anova(mod0, mod1,mod2, mod3, mod4)



Data: x

Models:

mod0: dT_purs ~ T + Z + (1 | subject)

mod4: dT_purs ~ T * Z + (1 | subject )

mod1: dT_purs ~ T + Z + (1 + T| subject)

mod2: dT_purs ~ T + Z + (1 + T| subject ) + (1 + Z | subject)

mod3: dT_purs ~ T * Z + (1 + T| subject) + (1 + Z | subject)

     Df     AIC     BIC logLik deviance   Chisq Chi Df Pr(>Chisq)

mod0  5 -689.81 -669.46 349.91  -699.81

mod4  6 -689.57 -665.14 350.78  -701.57  1.7532      1   0.185473

mod1  7 -689.12 -660.62 351.56  -703.12  1.5504      1   0.213070

mod2 10 -695.67 -654.97 357.84  -715.67 12.5563      3   0.005701 **

mod3 11 -695.83 -651.05 358.92  -717.83  2.1580      1   0.141825

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





It turns out that mod2 has the right level of complexity for this dataset.

However when I looked at its summary, I got a correlation of -0.87 for the random effects relative to the T effect and -1 for the random effects relatively to the Z.





summary(mod2)

Linear mixed model fit by maximum likelihood ['lmerMod']

Formula: dT_purs ~T + Z + (1 + T | subject) + (1 + Z | subject)

   Data: x



      AIC       BIC    logLik  deviance

-695.6729 -654.9655  357.8364 -715.6729



Random effects:

Groups     Name        Variance  Std.Dev. Corr

 subject   (Intercept) 0.0032063 0.05662

            T       0.0117204 0.10826  -0.87

subject.1 (Intercept) 0.0005673 0.02382

            Z           0.0025859 0.05085  1.00

 Residual               0.0104551 0.10225

Number of obs: 433, groups: soggetto, 7



Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.02489    0.03833   0.650

T        0.52010    0.05905   8.808

Z           -0.09019    0.02199  -4.101



Correlation of Fixed Effects:

      (Intr) tempo

T -0.901

Z      0.218 -0.026





If I understand correctly what the correlation parameters reported in the table are, the correlation of 1 means that, for the Z effects the random intercept is perfectly collinear with the random slope. Thus, we fit the wrong model. A random intercept only model would have sufficed.

Am I correct?



If so, should I take mod1 (mod1 <- dT_purs ~ T + Z + (1 + T | subject ) instead of mod2 to fit my data?

Why are these results contradictory?

Finally is a correlation value of -0.87 a too high or an acceptable value ?



Thanks for help me in advance!



Best



Benedetta





---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bbonit at tin.it  Tue Nov 26 11:28:46 2013
From: bbonit at tin.it (bbonit at tin.it)
Date: Tue, 26 Nov 2013 11:28:46 +0100 (CET)
Subject: [R-sig-ME] HELP gls
Message-ID: <14293f43e83.bbonit@tin.it>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131126/d78d9e83/attachment.pl>

From paul.johnson at glasgow.ac.uk  Tue Nov 26 13:05:52 2013
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 26 Nov 2013 12:05:52 +0000
Subject: [R-sig-ME] function for simulating from GLMM
In-Reply-To: <DAB55EFEBDAD1F4888EDB2E8F5180BC95E065070EF@CMS03.campus.gla.ac.uk>
References: <2E1FCBE7-BABC-446C-82BC-5C50E814BF1D@glasgow.ac.uk>
	<DAB55EFEBDAD1F4888EDB2E8F5180BC95E065070EF@CMS03.campus.gla.ac.uk>
Message-ID: <5716F8E2-6F88-40C2-B48A-A9B211617478@glasgow.ac.uk>

Hi, 

I've moved sim.glmm from Dropbox to github: 

https://github.com/pcdjohnson/sim.glmm.git

The dropbox copy will no longer be updated and may disappear at some point.

Paul



On 30 Sep 2013, at 13:11, Paul Johnson <Paul.Johnson at glasgow.ac.uk> wrote:

> Hi,
> 
> Thanks to those who emailed with feedback on the sim.glmm function. New version here:
> https://www.dropbox.com/s/41xeopjsxt3eerc/functions_for_glmm_power_simulations_v4.2_30September2013.R
> The main change is that I've fixed an error that occurred when supplying a single random effect variance as a vector. 
> 
> Paul
> 
> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Paul Johnson [paul.johnson at glasgow.ac.uk]
> Sent: 12 September 2013 16:44
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] function for simulating from GLMM
> 
> Dear R mixed modellers,
> 
> I've written a function, sim.glmm, to simulate from some GLMMs (Gaussian, binomial, Poisson and negative binomial). I've been using this function for a while, and thought some of you might be interested (I think there was a request for such a function recently). I've use for power analysis and to check bias, CI coverage, type I error, residuals distributions, etc.
> 
> The code is here:
> https://www.dropbox.com/s/b0h1cptgq3ummjq/functions_for_glmm_power_simulations_v4_16August2013_draft.R
> 
> I'm not aware of other R functions that do this, although I guess they must be out there (although I've recently learned that MLwiN can link with R to simulate from GLMMs - I haven't tried this). I'm aware that simulate-mer will simulate from fitted GLMMs, but not, afaik, from a set of parameter values.
> 
> Below is an example of how it works. Any comments or suggestions would be greatly appreciated.
> 
> Paul Johnson
> Glasgow
> 
>  # simulate counts of tick burden on grouse chicks in a single year from a Poisson-lognormal GLMM,
>  # loosely based on:
>  #   Elston et al. (2001).
>  #   Analysis of aggregation, a worked example: numbers of ticks on red grouse chicks. Parasitology, 122, 563?9.
>  #   http://abdn.ac.uk/lambin-group/Papers/Paper%2041%202001%20Elston%20Tick%20aggregation%20Parasitology.pdf
>  # chicks are nested within broods, and broods within locations
> 
>    # simulate data set that defines sampling of chicks within broods within locations,
>    # assuming 3 chicks per brood and 2 broods per location. N locations = 20.
> 
>      tickdata <- expand.grid(chick=1:3, brood=1:2, location=1:20)
> 
>    # make brood and chick ids unique (otherwise random effects will be simulated as crossed, not nested)
> 
>      tickdata$location <- factor(paste("loc", tickdata$location, sep=""))
>      tickdata$brood <- factor(paste(tickdata$location, "brd", tickdata$brood, sep=""))
>      tickdata$chick <- factor(paste(tickdata$brood, "chk", tickdata$chick, sep=""))
> 
>    # simulate tick counts with an average burden of 5 ticks per chick
>    # random effect variances are 2, 1 and 0.3 for location, brood and chick respectively
> 
>      tickdata<-
>        sim.glmm(design.data = tickdata,
>          fixed.eff = list(intercept = log(5)),
>          rand.V = c(location = 2, brood = 1, chick = 0.3),
>          distribution = 'poisson')
> 
>    # plot counts and fit GLMM
> 
>      plot(response~jitter(as.numeric(location),factor=0.5),pch=21,bg=as.numeric(brood),data=tickdata)
>      library(lme4)
>      glmer(response~(1|location)+(1|brood)+(1|chick),family='poisson',data=tickdata)
> 
>    # adding categorical or continuous fixed effects is straightforward, e.g
>    # if tickdata has altiude (in km and centred on zero) and sex:
>    # fixed.eff = list(intercept = log(5), altitude.km = log(2), sex=log(c(M = 1, F = 0.8)))
>    # random effects can have non-zero covariances if rand.V is supplied as a variance-covariance matrix
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.cesqui at hsantalucia.it  Tue Nov 26 15:47:40 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Tue, 26 Nov 2013 15:47:40 +0100
Subject: [R-sig-ME] lmer model design
Message-ID: <000b01ceeab6$7851fe70$68f5fb50$@cesqui@hsantalucia.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131126/ded62897/attachment.pl>

From b.cesqui at hsantalucia.it  Tue Nov 26 15:52:38 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Tue, 26 Nov 2013 15:52:38 +0100
Subject: [R-sig-ME] R:  lmer model design
In-Reply-To: <000b01ceeab6$7851fe70$68f5fb50$@cesqui@hsantalucia.it>
References: <000b01ceeab6$7851fe70$68f5fb50$@cesqui@hsantalucia.it>
Message-ID: <001001ceeab7$2a9fbef0$7fdf3cd0$@cesqui@hsantalucia.it>

Sorry,
in regards to the multcompare issue of my post, the error text I got is 

 Error in mcp2matrix(model, linfct = linfct) : 
  Variable(s) 'T' of class 'integer' is/are not contained as a factor in
'model'.


benedetta

-----Messaggio originale-----
Da: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Per conto di Benedetta
Cesqui
Inviato: marted? 26 novembre 2013 15:48
A: r-sig-mixed-models at r-project.org
Oggetto: [R-sig-ME] lmer model design

Hi all,

 

I am trying to determine the most appropriate way to run the following
analysis.

I asked 7  subjects to catch a ball launched with different initial
conditions. The system is calibrated to have a total of 4 time flight and 2
arrival height conditions.
 I tested different subjects of different skill level ( that is, different
final score percentage, i.e. number of ball caught/ total number of
launches), and measured a response variable (y, say something as the
reaction time, or the ability at tracking the ball with the eye). Those
variables are supposed to be correlated to the performance ( ability at
catching or not the ball).

The aims of my analysis is: 

1) test whether the responses are different for different score ( i.e. a
lower  value of the y response variable if the subject was not able to catch
the ball). The score is 1 if the subject caught the ball. The score was 0 if
the subject touched or missed the ball.

3) test whether the response variable are different for the different
experimental conditions.

 

I used two different approaches and get apparently different results:

 

In the first case, I run an LMM analysis and used the score as a dummy
variable:

 

mod0 <- lmer(y ~ T+ Z + (1|subject) + factor(score), data = x)

 

( this model is the result of a mixed model building process. I compared
several possible models of different random and fixed effect structures. For
brevity I only reported the one that gave me the best results according to
the outcomes of the likelihood test).

 

summary (mod0)

Linear mixed model fit by REML ['lmerMod']

Formula: y ~ T + Z + (1 | subject) + factor(score) 

   Data: x 

 

REML criterion at convergence: -642.0967 

 

Random effects:

Groups   Name        Variance Std.Dev.

subject (Intercept) 0.001681 0.04100 

 Residual             0.008938 0.09454 

Number of obs: 364, groups: subject, 7

 

Fixed effects:

                Estimate Std. Error t value

(Intercept)     0.232191   0.025870   8.975

T            0.034977   0.004951   7.064

Z           -0.046545   0.010017  -4.647

factor(score)1  0.047830   0.012407   3.855

 

Correlation of Fixed Effects:

            (Intr) T   Z  

T        -0.472              

Z        -0.580  0.024       

factr(scr)1 -0.139 -0.239  0.031

 

The comparison between mod0 and mod1 , defined as;

 

mod1 <- lmer(y ~ T+ Z + (1|subject) +, data = x),

 

returns me the significance of the factor(score)  term.

anova(mod0,mod1)

Data: x

Models:

mod1: y ~ T + Z + (1 | subject)

mod0: y ~ T + Z + (1 | subject) + factor(score)

     Df     AIC     BIC logLik deviance  Chisq Chi Df Pr(>Chisq)    

mod1  5 -647.01 -627.53 328.51  -657.01                             

mod0  6 -659.74 -636.36 335.87  -671.74 14.733      1  0.0001239 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 

It turns out that the score affects the y variable. In particular y is
higher for score =1. However, as the subjects were of different skill level,
I could also wander whether the random slopes associated with the score were
different across subjects. In other words I should   also be able to see
that skilled subjects ( that is, subjects with a higher number of caught
ball), should also present a higher y value.

 

I thus, consider the following model

 

mod2<-  lmer(y ~ T+ Z + (1+score|subject) +factor(score), data = x)

 

summary(mod2)

Linear mixed model fit by REML ['lmerMod']

Formula: y ~ T + Z + (1 + score | subject) + factor(score) 

   Data: x 

 

REML criterion at convergence: -646.0884 

 

Random effects:

Groups   Name        Variance Std.Dev. Corr

subject (Intercept) 0.001240 0.03521      

          score       0.001571 0.03963  0.55

Residual             0.008730 0.09344      

Number of obs: 364, groups: subject, 7

 

Fixed effects:

                Estimate Std. Error t value

(Intercept)     0.232614   0.024430   9.522

T            0.034213   0.004892   6.993

Z           -0.045544   0.009921  -4.591

factor(score)1  0.039768   0.020356   1.954

 

Correlation of Fixed Effects:

            (Intr) T   Z  

T        -0.496              

Z        -0.606  0.024       

factr(scr)1  0.132 -0.141  0.017

 

and get:

 

anova(mod0, mod2)

Data: x

Models:

mod0: y ~ T + Z + (1 | subject) + factor(score)

mod2: y ~ T + Z + (1 + score | subject) + factor(score)

     Df     AIC     BIC logLik deviance  Chisq Chi Df Pr(>Chisq)

mod0  6 -659.74 -636.36 335.87  -671.74                         

mod2  8 -659.01 -627.83 337.50  -675.01 3.2628      2     0.1957

 

If I interpret my results correctly, this means that overall  the y variable
is affected by the ability of the subjects to catch the ball or not.
However, a subject that has a lower score, doesn't necessary have also  a
lower y response variable.

 

Now, I decide to reverse the point of view and see whether the score ( i.e.
the performance of the subjects in the task) was affected by the response
variable. I run a GLMM analysis. To this aim I compared the following
models:

 

mod3 <- glmer(score ~ y + T+ Z + (1|subject) , data = x,
family=binomial(link = "logit"))

mod4 <- glmer(score ~ y+ T+ Z+ (1 +y|subject), data = x,
family=binomial(link = "logit"))

anova(mod3,mod4)

 

Models:

mod3: score ~ y + T + Z + (1 | subject)

mod9: score ~ y + T + Z + (1 + y | subject)

     Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)  

mod7  5 358.51 377.99 -174.25   348.51                           

mod9  7 355.27 382.55 -170.64   341.27 7.2348      2    0.02685 *

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 

Thus, mod4, better accounts for my data.

summary(mod4)

 

Generalized linear mixed model fit by maximum likelihood ['glmerMod']

Family: binomial ( logit )

Formula: score ~ y + T + Z + (1 + y | subject) 

   Data: x 

 

      AIC       BIC    logLik  deviance 

 355.2723  382.5524 -170.6362  341.2723 

 

Random effects:

Groups   Name        Variance  Std.Dev. Corr

subject (Intercept)  0.009295 0.09641      

          y     42.975699 6.55559  1.00

Number of obs: 364, groups: subject, 7

 

Fixed effects:

            Estimate Std. Error z value Pr(>|z|)    

(Intercept) -2.31323    0.68571  -3.373 0.000742 ***

y      2.97926    2.92840   1.017 0.308979    

T         0.42262    0.14305   2.954 0.003133 ** 

Z         0.08513    0.28984   0.294 0.768987    

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 

Correlation of Fixed Effects:

        (Intr) y T  

y -0.251              

T    -0.322 -0.159       

Z    -0.739  0.149 -0.084

 

This analysis retuns a p_value for the y response variable that is not
significant ( 0.3089), and instead returns me a significant value of the T
variable.

hence it suggests that the score depends on the T condition, and not on the
y variable. What the significance of the (1 + y | subject) term suggets?

What is the best approach to run this analysis?

 

Finally, I tried to run a Tukey test to study possible difference of the
score level depending on the T and Z conditions:

cont <- glht(mod9,  linfct = mcp( T = "Tukey"))

and got these error:

 

Error in mcp2matrix(model, linfct = linfct) : 

  Variable(s) 'Tcat' of class 'integer' is/are not contained as a factor in
'model'.

 

Does anyone know what I did wrong?

 

Sorry for the long post, but I am really stacked in this analysis and do not
know how to move on!

 

Many thanks

 

Benedetta

---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it

 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.cesqui at hsantalucia.it  Mon Nov 25 10:56:09 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Mon, 25 Nov 2013 10:56:09 +0100
Subject: [R-sig-ME] Contradictory results in lmer
Message-ID: <000f01cee9c4$90f525d0$b2df7170$@cesqui@hsantalucia.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131125/1b6c68dd/attachment.pl>

From b.cesqui at hsantalucia.it  Mon Nov 25 15:45:30 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Mon, 25 Nov 2013 15:45:30 +0100
Subject: [R-sig-ME] R: [R] lmer specification for random effects:
	contradictory reults
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>
References: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
	<AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>
Message-ID: <000301cee9ed$02ef6f10$08ce4d30$@cesqui@hsantalucia.it>

Dear Thierry,

thank you for the quick reply.
I have only one question about the approach you proposed.
As you suggested, imagine that the model we end up after the model selection
procedure is:

mod2.1 <- lmer(dT_purs ~ T + Z + (1 +T+Z| subject), data =x, REML= FALSE)

According to the common procedures specified in many manuals and recent
papers, if I want to compute the p_values relative to each term, I will
perform a likelihood test, in which the deviance of the (-2LL) of a model
containing the specific term is compared to another model without it.
In the case of the fixed effect terms I have no problem in the
interpretation of the results. Each comparison returns a significance
associated with the estimated coefficient of the term.
Thus in this case:

mod2.2 <- lmer(dT_purs ~ Z + (1 +T+Z|soggetto)  , data = x, REML = FALSE)
mod2.3 <- lmer(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x, REML = FALSE)
anova(mod2.1, mod2.2)
p_valueT = 3.203e-05
anova(mod2.1, mod2.3)
p_valueZ = 0.001793

What about the p_value relative to the (1+T+Z|subject)?
One option is to compute:
mod2.4 <- lm(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x)
and then execute the loklikelihood test as follows:

L0 <-logLik(mod2.4)
L1 <-logLik(mod2.1)
LR <--2*(L1-L0)
pv <- pchisq(LR,2,ncp = 0, lower.tai=FALSE,log.p = FALSE)

However, what can I conclude on the random slopeif it is significant? 

With the previouse approach using the model:
mod2 <- lmer(dT_purs ~ T + Z + (1 +T| subject) + (1+ Z| subject), data =x)

The comparison among the models in which the different termd were
included/excluded provided me the following results:
	p_valueT = 1.269e-07;
	p_valueZ =0.00322 
	p_valueTS =  0.4277
	p_valueZS = 0.005701

I interpreted the ones relative to the random effects as if the subjects
differed not only in their overall responses, but also in the nature of
their response dT_purse values in the different T conditions, but not in the
different Z conditions.

Benedetta


-----Messaggio originale-----
Da: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Inviato: luned? 25 novembre 2013 14:48
A: Benedetta Cesqui; r-help at r-project.org
Cc: r-sig-mixed-models at r-project.org
Oggetto: RE: [R] lmer specification for random effects: contradictory reults

Dear Benedetta,

I think you might want (1+T+Z|subject) as random effects  rather than
(1+T|subject) + (1 + Z|subject). The latter has two random intercepts per
subject: a recipe for disaster.

Follow-up posts should only go to the mixed models mailing list which I'm
cc'ing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than
asking him to perform a post-mortem examination: he may be able to say what
the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
Namens Benedetta Cesqui
Verzonden: maandag 25 november 2013 11:13
Aan: r-help at r-project.org
Onderwerp: [R] lmer specification for random effects: contradictory reults

Hi All,



I was wondering if someone could help me to solve this issue with lmer.
In order to understand the best mixed effects model to fit my data, I
compared the following options according to the procedures specified in many
papers (i.e. Baayen
<http://www.google.it/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDsQFjAA
&url=http%3A%2F%2Fwww.ualberta.ca%2F~baayen%2Fpublications%2FbaayenDavidsonB
ates.pdf&ei=FhqTUoXuJKKV7Abds4GYBA&usg=AFQjCNFst7GT7mBX7w9lXItJTtELJSKWJg&si
g2=KGA5MHxOvEGwDxf-Gcqi6g&bvm>  R.H. et al 2008) Here, dT_purs is the
response variable, T and Z are the fixed effects, and subject is the random
effect. Random and fixed effects are crossed.:

mod0 <- lmer(dT_purs ~ T + Z + (1|subject), data = x)
mod1 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject), data = x)
mod2 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod3 <- lmer(dT_purs ~ T * Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod4 <- lmer(dT_purs ~ T * Z + (1| subject), data = x)


anova(mod0, mod1,mod2, mod3, mod4)



Data: x

Models:

mod0: dT_purs ~ T + Z + (1 | subject)

mod4: dT_purs ~ T * Z + (1 | subject )

mod1: dT_purs ~ T + Z + (1 + T| subject)

mod2: dT_purs ~ T + Z + (1 + T| subject ) + (1 + Z | subject)

mod3: dT_purs ~ T * Z + (1 + T| subject) + (1 + Z | subject)

     Df     AIC     BIC logLik deviance   Chisq Chi Df Pr(>Chisq)

mod0  5 -689.81 -669.46 349.91  -699.81

mod4  6 -689.57 -665.14 350.78  -701.57  1.7532      1   0.185473

mod1  7 -689.12 -660.62 351.56  -703.12  1.5504      1   0.213070

mod2 10 -695.67 -654.97 357.84  -715.67 12.5563      3   0.005701 **

mod3 11 -695.83 -651.05 358.92  -717.83  2.1580      1   0.141825

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





It turns out that mod2 has the right level of complexity for this dataset.

However when I looked at its summary, I got a correlation of -0.87 for the
random effects relative to the T effect and -1 for the random effects
relatively to the Z.





summary(mod2)

Linear mixed model fit by maximum likelihood ['lmerMod']

Formula: dT_purs ~T + Z + (1 + T | subject) + (1 + Z | subject)

   Data: x



      AIC       BIC    logLik  deviance

-695.6729 -654.9655  357.8364 -715.6729



Random effects:

Groups     Name        Variance  Std.Dev. Corr

 subject   (Intercept) 0.0032063 0.05662

            T       0.0117204 0.10826  -0.87

subject.1 (Intercept) 0.0005673 0.02382

            Z           0.0025859 0.05085  1.00

 Residual               0.0104551 0.10225

Number of obs: 433, groups: soggetto, 7



Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.02489    0.03833   0.650

T        0.52010    0.05905   8.808

Z           -0.09019    0.02199  -4.101



Correlation of Fixed Effects:

      (Intr) tempo

T -0.901

Z      0.218 -0.026





If I understand correctly what the correlation parameters reported in the
table are, the correlation of 1 means that, for the Z effects the random
intercept is perfectly collinear with the random slope. Thus, we fit the
wrong model. A random intercept only model would have sufficed.

Am I correct?



If so, should I take mod1 (mod1 <- dT_purs ~ T + Z + (1 + T | subject )
instead of mod2 to fit my data?

Why are these results contradictory?

Finally is a correlation value of -0.87 a too high or an acceptable value ?



Thanks for help me in advance!



Best



Benedetta





---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit
bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en
binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd
is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the
writer and may not be regarded as stating an official position of INBO, as
long as the message is not confirmed by a duly signed document.


From nerutenbeck at gmail.com  Tue Nov 26 04:52:50 2013
From: nerutenbeck at gmail.com (Nathan E. Rutenbeck)
Date: Mon, 25 Nov 2013 22:52:50 -0500
Subject: [R-sig-ME] Predict method for lmer
Message-ID: <52941B12.3030906@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131125/6542a51c/attachment.pl>

From pradeep.babu at gmail.com  Sun Nov 24 16:41:22 2013
From: pradeep.babu at gmail.com (Pradeep Babu S.)
Date: Sun, 24 Nov 2013 21:11:22 +0530
Subject: [R-sig-ME] specifying partially crossed mixed effects
Message-ID: <CAJv2FdDk0cEnqMKLKU=0ih-4J4iBTZa_p0s+rnQKLFj_1OUfwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131124/b04e359d/attachment.pl>

From Rachel.Smith at glasgow.ac.uk  Sun Nov 24 01:50:58 2013
From: Rachel.Smith at glasgow.ac.uk (Rachel Smith)
Date: Sun, 24 Nov 2013 00:50:58 +0000
Subject: [R-sig-ME] =?windows-1252?q?=22invalid_class_=93mer=94_object=22_?=
 =?windows-1252?q?error_with_lme4_0=2E999375=2E42?=
Message-ID: <4D20AC12B0DD1B41B3901228D1C40C2D4911D126BE@CMS03.campus.gla.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131124/763bdc46/attachment.pl>

From bbolker at gmail.com  Tue Nov 26 18:00:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Nov 2013 12:00:20 -0500
Subject: [R-sig-ME]
 =?windows-1252?q?=22invalid_class_=93mer=94_object=22_?=
 =?windows-1252?q?error_with_lme4_0=2E999375=2E42?=
In-Reply-To: <4D20AC12B0DD1B41B3901228D1C40C2D4911D126BE@CMS03.campus.gla.ac.uk>
References: <4D20AC12B0DD1B41B3901228D1C40C2D4911D126BE@CMS03.campus.gla.ac.uk>
Message-ID: <5294D3A4.4070407@gmail.com>

On 13-11-23 07:50 PM, Rachel Smith wrote:
> Dear lme4-folks,
> 
> I wonder if you can help me with a query.
> 
> In our lab we are (not very advanced) users of lme4, who have until
> recently relied heavily on languageR. We are trying to adjust to lme4
> 3.0.1 and life without languageR/pvals.fnc.

  Sorry about that :-(

> As part of this process, to try to ensure continuity for our
> students, I recently asked our technical support to ensure that our
> lab machines are running the following: R 2.15.2 with lme4 version
> 0.999375.42, and languageR R 3.0.1 with lme4 version 1.0.5
> 
> I have tested the following simple bit of code under both of the
> above. junk = lmer(RTlexdec ~ WordCategory + (1|Word), data=english) 
> This works fine under R 3.0.1 with lme4 1.0.5.
> 
> But, under R 2.15.2 with lme4 0.999375.42, I get the following error
> message:
> 
> "Error in validObject(.Object) : invalid class ?mer? object: Slot L
> must be a monotonic LL' factorization of size dims['q']"
> 
> 
> 
> Do you have any idea where this problem could be originating? I'm
> wondering whether the versions of e.g. MASS or matrix that we have
> loaded, could be an issue here - might we have newer versions of
> these that aren't compatible with lme4 0.999375.42, or something like
> that?
> 

   Try re-installing lme4.0 *after* you have installed the new versions
of Matrix; if you switch Matrix versions "under" lme4.0 , it won't
detect that the binary interfaces have changed and that it should
therefore be re-installed ... (i.e. it's not technically that the newer
versions of Matrix are incompatible, but that lme4.0 needs to be
recompiled/reinstalled to work properly with the new version)

  Ben Bolker


From bbolker at gmail.com  Wed Nov 27 22:59:30 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 Nov 2013 21:59:30 +0000 (UTC)
Subject: [R-sig-ME] Predict method for lmer
References: <52941B12.3030906@gmail.com>
Message-ID: <loom.20131127T225716-717@post.gmane.org>

Nathan E. Rutenbeck <nerutenbeck at ...> writes:

> 
> Hi all,
> 
> I am struggling to use predict.merMod to generate predictions from a 
> relatively simple mixed model. 

 [snip snip snip]

> Example code follows:
> 
> mer0 <- lmer ( top ~ 1 + (1|stand), data=data)
> mer0.1 <- update( mer0, .~. + (1|species))

 [more snippage]
 
> mer2 <- update(mer1, .~. + (DBH|Species)
> predict(mer2, newdata=data, allow.new.levels=T) # This fails with the 
> following error:
> 
> Error in t(.Call(Csparse_dense_crossprod, y, t(x))) :
>    error in evaluating the argument 'x' in selecting a
>  method for function
> 't': Error: Cholmod error 'X and/or
> Y have wrong dimensions' at file ../MatrixOps/cholmod_sdmult.c, line 90
> 
> It seems that I am failing to provide the proper matrix format for the 
> newdata argument, but I don't necessarily see how to fix it.
> 
> Thanks in advance,
> 
> -Nathan Rutenbeck
> 

  This is probably a bug (i.e. not your fault), but possibly one that has
been fixed more recently. Can you please:

* try installing the development version, either from Github or via
install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
and see if that helps?
* send me a _small_ reproducible example?

  Ben Bolker


From holtermann at hwwi.org  Thu Nov 28 10:38:38 2013
From: holtermann at hwwi.org (Linus Holtermann)
Date: Thu, 28 Nov 2013 10:38:38 +0100
Subject: [R-sig-ME] Multilevel logit and sample size (mixed models)
Message-ID: <AD0050057515F54084E7D5B93478C848093C50AFE9@winxbede39.exchange.xchg>

Hello,

I want to estimate a complex hierarchical multilevel logit model with spatial structure.
The model is a two-level-model wtih random slopes for some variables and cross-level interaction effects (the excact form of the model is not yet specified). I have 20 regions (upper Level) which contain several districts (lower Level). The dependent variable is employment growth at district-level.
The multilevel logit model should include at least three variables at the upper Level and eight variables at the lower Level.
I am a little bit concerned that my sample size is too small to produce reliable Point estimates and Standard Errors for such a complex model.

There are two Options:

1.) Choosing larger district Areas for which more relevant data is avaidable, resulting in:
20 regions with number of districts per region varying from 3 to 40 (Average number of districts per Region: 13)

2.) Choosing smaller district Areas, resulting in:
20 regions with number of districts per region varying from 8 to 400 (Average number of districts per Region: 60)

I like to use larger districts, because more data are avaidable. Is the sample size too small for the multilevel model? In literature this topic is discussed controversially. Some authors say you need at least 50 Groups with an average number of 50 memebers per group in a multilevel model with dichotomous data. Ohter claim that at least 20 Groups with minimum 5 members per group are sufficient. Is there a test for minimum sample size for multilevel models in R? Would an MCMC-approach help me to produce more reliable estimates?


Off Topic: Has someone try to incorporate spatial effects (spatial lag or spatial error) in multilevel models? Is that possible?

Mit freundlichen Gr??en
 
 
Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
 
AmtsgerichtHamburg HRB 94303
Gesch?ftsf?hrer: Prof. Dr. Thomas Straubhaar, Gunnar Geyer
Umsatzsteuer-ID: DE 241849425

From f.vanlangendonck at fcdonders.ru.nl  Wed Nov 27 18:58:48 2013
From: f.vanlangendonck at fcdonders.ru.nl (Vanlangendonck, F. (Flora))
Date: Wed, 27 Nov 2013 18:58:48 +0100 (CET)
Subject: [R-sig-ME] Using mcp and glht for lmer model
In-Reply-To: <399082243.4066009.1385570965623.JavaMail.root@sculptor.zimbra.ru.nl>
Message-ID: <642659923.4066806.1385575128101.JavaMail.root@sculptor.zimbra.ru.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131127/398e2b8c/attachment.pl>

From bbonit at tin.it  Fri Nov 29 07:11:57 2013
From: bbonit at tin.it (bbonit at tin.it)
Date: Fri, 29 Nov 2013 07:11:57 +0100 (CET)
Subject: [R-sig-ME] simulate.lme for correlation  in repeated measure
Message-ID: <142a27c329e.bbonit@tin.it>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131129/9e506699/attachment.pl>

From Bjorn.Lindstrom at ki.se  Fri Nov 29 18:40:28 2013
From: Bjorn.Lindstrom at ki.se (=?iso-8859-1?Q?Bj=F6rn_Lindstr=F6m?=)
Date: Fri, 29 Nov 2013 17:40:28 +0000
Subject: [R-sig-ME] estimation of intercept in binomial glmer
Message-ID: <6A157C1E1256BB4C8AE38B529E908BF8B708640E@KIMSX04.user.ki.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131129/c37ae1fc/attachment.pl>

From bbolker at gmail.com  Fri Nov 29 19:04:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 Nov 2013 13:04:53 -0500
Subject: [R-sig-ME] simulate.lme for correlation  in repeated measure
In-Reply-To: <142a27c329e.bbonit@tin.it>
References: <142a27c329e.bbonit@tin.it>
Message-ID: <5298D745.1020902@gmail.com>

On 13-11-29 01:11 AM, bbonit at tin.it wrote:
> Dear list, good morning I would like to ask You (and in particular to
> professor Ben Bolker and Professor Bates) how i can silmulate dataset
> fittet with lme where there is specied correlation argument in lme
> function .  simulate.leme function give error and doesn' t allow this
> kind of operation Can someome prototipe an example how i can i do for
> solve this problem? Thank You so much in advance list ..sorry for
> noise Bonitta Gianluca

  I don't know of a canned solution.  You can simulate correlated
multivariate normal deviates using mvrnorm() from the MASS package, or
slightly more efficiently by using the machinery from the nlme package
to construct the Cholesky factors

library(nlme)
cs1 <- corAR1(form = ~1 | Subject, value=0.6)
cs1 <- Initialize(cs1, data = Orthodont)
## get Cholesky factor rather than correlation matrix
cm <- corMatrix(cs1,corr=FALSE)
library(Matrix)
mm <- bdiag(cm)
image(mm)

  That might get you started, but if you need a more canned solution I
hope someone else comes forward with one ...


From M.Fairbrother at bristol.ac.uk  Sun Dec  1 15:26:24 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 1 Dec 2013 14:26:24 +0000
Subject: [R-sig-ME] Multilevel logit and sample size (mixed models)
Message-ID: <CAAH-yP-N-5Dux4QGd=-GuiEihM_scZJb8M=rP=scuePan27YpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131201/fb5cd2a6/attachment.pl>

From sunilmundra at hotmail.com  Sun Dec  1 20:50:46 2013
From: sunilmundra at hotmail.com (Sunil Mundra)
Date: Mon, 2 Dec 2013 01:20:46 +0530
Subject: [R-sig-ME] Linear mixed model (estimated mean ploting)
Message-ID: <BLU182-W38FABC5B40BD37FFDE1F8AA3EB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131202/bd914cdc/attachment.pl>

From segerfan83 at gmail.com  Sun Dec  1 23:31:40 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Sun, 1 Dec 2013 17:31:40 -0500
Subject: [R-sig-ME] Always allow for correlation of random effects?
Message-ID: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131201/bb02dae4/attachment.pl>

From segerfan83 at gmail.com  Mon Dec  2 02:05:08 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Sun, 1 Dec 2013 20:05:08 -0500
Subject: [R-sig-ME] Extremely High Slope/Intercept Correlation
Message-ID: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131201/2bf0c38f/attachment.pl>

From bbonit at tin.it  Mon Dec  2 10:11:12 2013
From: bbonit at tin.it (bonitta gianluca)
Date: Mon, 2 Dec 2013 09:11:12 +0000 (UTC)
Subject: [R-sig-ME] simulate.lme for correlation  in repeated measure
References: <142a27c329e.bbonit@tin.it> <5298D745.1020902@gmail.com>
Message-ID: <loom.20131202T094529-417@post.gmane.org>

thank You so much for Your (soon) replay professor Ben 
I would like to post my idea  (following your suggestion) for simulate 
repeated measure dataset from fitted model..
let me write down the pseudo code

thank you again


From Thierry.ONKELINX at inbo.be  Mon Dec  2 10:20:12 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 2 Dec 2013 09:20:12 +0000
Subject: [R-sig-ME] Extremely High Slope/Intercept Correlation
In-Reply-To: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>
References: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB0629E@inbomail.inbo.be>

This can be caused by having more complexity than the data allows. Note that the variance of the random slope is small.

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens AvianResearchDivision
Verzonden: maandag 2 december 2013 2:05
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Extremely High Slope/Intercept Correlation

Hi all,

I came across extremely high slope/intercept correlation (-1.00) when running the following model:

model<-lmer(X~Y+(Y|Male))

summary(model)

Random effects:

 Groups             Name               Variance          Std.Dev.          Corr


 Male                (Intercept)          1.562e-01        0.3952284

                        Y                       7.581e-07       0.0008707
-1.00

                        Residual            2.661e-01        0.5158953

Number of obs: 879, groups: Male, 59


What is causing this?  This high of a correlation does not seem possible, especially in ecology.  Any suggestions moving forward?


Thank you,

Jacob

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Dec  2 10:35:58 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 2 Dec 2013 10:35:58 +0100
Subject: [R-sig-ME] Extremely High Slope/Intercept Correlation
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427DFB0629E@inbomail.inbo.be>
References: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427DFB0629E@inbomail.inbo.be>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99B0CDAA@UM-MAIL4112.unimaas.nl>

I assume 'Male' is dichotomous, so it has just two levels. Not likely that one can estimate any variance components based on that grouping variable with any degree of precision.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of ONKELINX, Thierry
> Sent: Monday, December 02, 2013 10:20
> To: AvianResearchDivision; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Extremely High Slope/Intercept Correlation
> 
> This can be caused by having more complexity than the data allows. Note
> that the variance of the random slope is small.
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] Namens AvianResearchDivision
> Verzonden: maandag 2 december 2013 2:05
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Extremely High Slope/Intercept Correlation
> 
> Hi all,
> 
> I came across extremely high slope/intercept correlation (-1.00) when
> running the following model:
> 
> model<-lmer(X~Y+(Y|Male))
> 
> summary(model)
> 
> Random effects:
> 
>  Groups             Name               Variance          Std.Dev.
> Corr
> 
> 
>  Male                (Intercept)          1.562e-01        0.3952284
> 
>                         Y                       7.581e-07       0.0008707
> -1.00
> 
>                         Residual            2.661e-01        0.5158953
> 
> Number of obs: 879, groups: Male, 59
> 
> 
> What is causing this?  This high of a correlation does not seem possible,
> especially in ecology.  Any suggestions moving forward?
> 
> 
> Thank you,
> 
> Jacob
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From segerfan83 at gmail.com  Mon Dec  2 13:43:01 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Mon, 2 Dec 2013 07:43:01 -0500
Subject: [R-sig-ME] Fwd:  Extremely High Slope/Intercept Correlation
In-Reply-To: <CAHe08Sjs97w4FGXObB3fj9W9LO5pyydOqSmv71XWttGk-EXH5A@mail.gmail.com>
References: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427DFB0629E@inbomail.inbo.be>
	<077E31A57DA26E46AB0D493C9966AC730D99B0CDAA@UM-MAIL4112.unimaas.nl>
	<CAHe08Sjs97w4FGXObB3fj9W9LO5pyydOqSmv71XWttGk-EXH5A@mail.gmail.com>
Message-ID: <CAHe08SgZDcap3yihDQAgoajEUawRpObFKOCkM1+mfOVkE5pMKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131202/66fadb0e/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Dec  2 14:04:55 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 2 Dec 2013 14:04:55 +0100
Subject: [R-sig-ME] Fwd:  Extremely High Slope/Intercept Correlation
In-Reply-To: <CAHe08SgZDcap3yihDQAgoajEUawRpObFKOCkM1+mfOVkE5pMKg@mail.gmail.com>
References: <CAHe08SjujR64yMH=so7YDQ6C996PX5w_uj4vmGvo9Mxfz852FA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427DFB0629E@inbomail.inbo.be>
	<077E31A57DA26E46AB0D493C9966AC730D99B0CDAA@UM-MAIL4112.unimaas.nl>
	<CAHe08Sjs97w4FGXObB3fj9W9LO5pyydOqSmv71XWttGk-EXH5A@mail.gmail.com>
	<CAHe08SgZDcap3yihDQAgoajEUawRpObFKOCkM1+mfOVkE5pMKg@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99B0CF40@UM-MAIL4112.unimaas.nl>

Ah okay, I misunderstood what 'Male' stood for.

To figure out what is going on, you could fit lm(Y ~ X) for each male separately (e.g., with the lmList function) and then examine a plot of the intercepts versus the slopes.

Best,
Wolfgang

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of AvianResearchDivision
> Sent: Monday, December 02, 2013 13:43
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fwd: Extremely High Slope/Intercept Correlation
> 
> ---------- Forwarded message ----------
> From: AvianResearchDivision <segerfan83 at gmail.com>
> Date: Mon, Dec 2, 2013 at 7:42 AM
> Subject: Re: [R-sig-ME] Extremely High Slope/Intercept Correlation
> To: "Viechtbauer Wolfgang (STAT)" <
> wolfgang.viechtbauer at maastrichtuniversity.nl>
> 
> 
> Male is not dichotomous, it has 59 levels for 59 different males.  I run
> this same model, but with a different dependent variables and I get much
> lower correlations.  Can someone please explain what "This can be caused
> by
> having more complexity than the data allows. Note that the variance of the
> random slope is small." means?
> 
> Thank you,
> Jacob
> 
> 
> On Mon, Dec 2, 2013 at 4:35 AM, Viechtbauer Wolfgang (STAT) <
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> 
> > I assume 'Male' is dichotomous, so it has just two levels. Not likely
> that
> > one can estimate any variance components based on that grouping variable
> > with any degree of precision.
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-
> > > bounces at r-project.org] On Behalf Of ONKELINX, Thierry
> > > Sent: Monday, December 02, 2013 10:20
> > > To: AvianResearchDivision; r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] Extremely High Slope/Intercept Correlation
> > >
> > > This can be caused by having more complexity than the data allows.
> Note
> > > that the variance of the random slope is small.
> > >
> > > -----Oorspronkelijk bericht-----
> > > Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> > r-sig-mixed-models-
> > > bounces at r-project.org] Namens AvianResearchDivision
> > > Verzonden: maandag 2 december 2013 2:05
> > > Aan: r-sig-mixed-models at r-project.org
> > > Onderwerp: [R-sig-ME] Extremely High Slope/Intercept Correlation
> > >
> > > Hi all,
> > >
> > > I came across extremely high slope/intercept correlation (-1.00) when
> > > running the following model:
> > >
> > > model<-lmer(X~Y+(Y|Male))
> > >
> > > summary(model)
> > >
> > > Random effects:
> > >
> > >  Groups             Name               Variance          Std.Dev.
> > > Corr
> > >
> > >
> > >  Male                (Intercept)          1.562e-01        0.3952284
> > >
> > >                         Y                       7.581e-07
> 0.0008707
> > > -1.00
> > >
> > >                         Residual            2.661e-01        0.5158953
> > >
> > > Number of obs: 879, groups: Male, 59
> > >
> > >
> > > What is causing this?  This high of a correlation does not seem
> possible,
> > > especially in ecology.  Any suggestions moving forward?
> > >
> > >
> > > Thank you,
> > >
> > > Jacob
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * *
> *
> > > Dit bericht en eventuele bijlagen geven enkel de visie van de
> schrijver
> > > weer en binden het INBO onder geen enkel beding, zolang dit bericht
> niet
> > > bevestigd is door een geldig ondertekend document.
> > > The views expressed in this message and any annex are purely those of
> the
> > > writer and may not be regarded as stating an official position of
> INBO,
> > as
> > > long as the message is not confirmed by a duly signed document.
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From nerutenbeck at gmail.com  Fri Nov 29 18:07:20 2013
From: nerutenbeck at gmail.com (Nathan E. Rutenbeck)
Date: Fri, 29 Nov 2013 12:07:20 -0500
Subject: [R-sig-ME] Predict method for lmer
In-Reply-To: <mailman.3.1385636401.30336.r-sig-mixed-models@r-project.org>
References: <mailman.3.1385636401.30336.r-sig-mixed-models@r-project.org>
Message-ID: <5298C9C8.4090604@gmail.com>


>> Hi all,
>>
>> I am struggling to use predict.merMod to generate predictions from a
>> relatively simple mixed model.
>   [snip snip snip]
>
>> Example code follows:
>>
>> mer0 <- lmer ( top ~ 1 + (1|stand), data=data)
>> mer0.1 <- update( mer0, .~. + (1|species))
>   [more snippage]
>   
>> mer2 <- update(mer1, .~. + (DBH|Species)
>> predict(mer2, newdata=data, allow.new.levels=T) # This fails with the
>> following error:
>>
>> Error in t(.Call(Csparse_dense_crossprod, y, t(x))) :
>>     error in evaluating the argument 'x' in selecting a
>>   method for function
>> 't': Error: Cholmod error 'X and/or
>> Y have wrong dimensions' at file ../MatrixOps/cholmod_sdmult.c, line 90
>>
>> It seems that I am failing to provide the proper matrix format for the
>> newdata argument, but I don't necessarily see how to fix it.
>>
>> Thanks in advance,
>>
>> -Nathan Rutenbeck
>>
>    This is probably a bug (i.e. not your fault), but possibly one that has
> been fixed more recently. Can you please:
>
> * try installing the development version, either from Github or via
> install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
> and see if that helps?
> * send me a _small_ reproducible example?
>
>    Ben Bolker
Hi Ben,

Thanks for the tip. I can report back that the development version of 
lme4 solved all my woes.

-Nathan


From bbolker at gmail.com  Mon Dec  2 23:40:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 02 Dec 2013 17:40:33 -0500
Subject: [R-sig-ME] Predict method for lmer
In-Reply-To: <5298C9C8.4090604@gmail.com>
References: <mailman.3.1385636401.30336.r-sig-mixed-models@r-project.org>
	<5298C9C8.4090604@gmail.com>
Message-ID: <529D0C61.7080302@gmail.com>

On 13-11-29 12:07 PM, Nathan E. Rutenbeck wrote:
> 
>>> Hi all,
>>>
>>> I am struggling to use predict.merMod to generate predictions from a
>>> relatively simple mixed model.
>>   [snip snip snip]
>>
>>> Example code follows:
>>>
>>> mer0 <- lmer ( top ~ 1 + (1|stand), data=data)
>>> mer0.1 <- update( mer0, .~. + (1|species))
>>   [more snippage]
>>  
>>> mer2 <- update(mer1, .~. + (DBH|Species)
>>> predict(mer2, newdata=data, allow.new.levels=T) # This fails with the
>>> following error:
>>>
>>> Error in t(.Call(Csparse_dense_crossprod, y, t(x))) :
>>>     error in evaluating the argument 'x' in selecting a
>>>   method for function
>>> 't': Error: Cholmod error 'X and/or
>>> Y have wrong dimensions' at file ../MatrixOps/cholmod_sdmult.c, line 90
>>>
>>> It seems that I am failing to provide the proper matrix format for the
>>> newdata argument, but I don't necessarily see how to fix it.
>>>
>>> Thanks in advance,
>>>
>>> -Nathan Rutenbeck
>>>
>>    This is probably a bug (i.e. not your fault), but possibly one that
>> has
>> been fixed more recently. Can you please:
>>
>> * try installing the development version, either from Github or via
>> install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
>> and see if that helps?
>> * send me a _small_ reproducible example?
>>
>>    Ben Bolker
> Hi Ben,
> 
> Thanks for the tip. I can report back that the development version of
> lme4 solved all my woes.
> 
> -Nathan

  Thanks for reporting back, and thank goodness your problem is already
resolved in the development version -- we're deep in petty bugs here at
lme4 central, we don't need any more (although that shouldn't discourage
people from reporting them if they're out there!)

  Ben Bolker


From mari.s.lyly at utu.fi  Tue Dec  3 08:42:51 2013
From: mari.s.lyly at utu.fi (Mari Lyly)
Date: Tue, 03 Dec 2013 07:42:51 +0000
Subject: [R-sig-ME] How to calculate proportion of deviance explained from
	GAMM?
Message-ID: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>

Hello all,

I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several fixed factors and smooth terms, and also a temporal structure. I have correlated main effect candidates, and I would like to compare their GAMMs to see, which one of the models best fits the data. The random structure is the same in all of the models.

I came across a thesis on Additive Mixed Models (http://eio.usc.es/pub/mte/descargas/ProyectosFinMaster/Proyecto_393.pdf). Following that example, I plan to use the proportion of deviance explained as a tool for model comparison and tuning the models in GAMM. The DE% is defined as:
(null deviance - residual deviance ) / null deviance

I have tried using the following script, but I end up having residual deviance (DR) slightly larger than the null deviance (DN):
DN <- deviance(gam(model0 ~ 1, data=data, family=poisson))
model1 <-gamm(response ~ s(cov1, by=factor1) + s(cov2) + s(cov3) + s(cov4) + cov5,
     random=list(factor2= ~ 1), correlation= corAR1(form= ~ factor3 | factor2), data=data, family=poisson)
DR <- sum(residuals(model1$gam, type="pearson")^2)

Would someone be able to tell if I am using the correct code to extract DN from the null model (GAM) and DR from the model to be compared (GAMM)? To my understanding, DR values should be clearly smaller than DN (unless it's overparameterization, which should not be the case here). If I'm not using the right functions, then please give advice on how to acquire the correct values.

With best regards,
   Mari Lyly
__________________________________
Mari Lyly, PhD student
University of Turku
e-mail: mari.s.lyly at utu.fi


From Julia.Sommerfeld at utas.edu.au  Tue Dec  3 10:47:31 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 3 Dec 2013 10:47:31 +0100
Subject: [R-sig-ME] Fwd: How to calculate proportion of deviance explained
 from GAMM?
In-Reply-To: <CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>
	<CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>
Message-ID: <CAOCHjhS4mSJr456DMDDpvGdb5wc-==YbthjESmaLEMkVNLUK6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/bc3d32c1/attachment.pl>

From mari.s.lyly at utu.fi  Tue Dec  3 12:09:36 2013
From: mari.s.lyly at utu.fi (Mari Lyly)
Date: Tue, 03 Dec 2013 11:09:36 +0000
Subject: [R-sig-ME] How to calculate proportion of deviance explained
 from GAMM?
In-Reply-To: <CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>
	<CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>
Message-ID: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DB43@exch-mbx-01.utu.fi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/c4d18994/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Tue Dec  3 13:58:00 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 3 Dec 2013 13:58:00 +0100
Subject: [R-sig-ME] How to calculate proportion of deviance explained
	from GAMM?
In-Reply-To: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DB43@exch-mbx-01.utu.fi>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>
	<CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>
	<3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DB43@exch-mbx-01.utu.fi>
Message-ID: <CAOCHjhRiRjxw89gqA-VO_eGui6-LdDxRTj+t26aQsVPW=jRRuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/9ba7deaa/attachment.pl>

From medo_botany at hotmail.com  Tue Dec  3 15:21:00 2013
From: medo_botany at hotmail.com (Hamada Elsayed Ali)
Date: Tue, 3 Dec 2013 14:21:00 +0000
Subject: [R-sig-ME] Problem with glmer
Message-ID: <DUB119-W36382E5DDB1D5501F5B5669CD50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/fdcd1edb/attachment.pl>

From bbolker at gmail.com  Tue Dec  3 15:26:03 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 03 Dec 2013 09:26:03 -0500
Subject: [R-sig-ME] Problem with glmer
In-Reply-To: <DUB119-W36382E5DDB1D5501F5B5669CD50@phx.gbl>
References: <DUB119-W36382E5DDB1D5501F5B5669CD50@phx.gbl>
Message-ID: <529DE9FB.2000007@gmail.com>

On 13-12-03 09:21 AM, Hamada Elsayed Ali wrote:
> Dear All,
> 
> I am trying to run glmer models to test the effect of noncrop % and
> management effect on P/A data with 27000 records. I used the
> following code:
> 
> glmer100<-glmer(Present~Management+NonCrop100+(1|Plot.No), 
> family=binomial, data=Presence)
> 
> and it works fine, but when I tried to add the species name as
> follows:
> 
> glmer100<-glmer(Present~Management+NonCrop100+Short.Name+(1|Plot.No),
>  family=binomial, data=Presence)
> 
> It gave me the following warning:
> 
> Warning in rankMatrix(X) : rankMatrix(<large sparse Matrix>, method =
> 'tolNorm2') coerces to dense matrix. Probably should rather use
> method = 'qrLINPACK' !? Can any one help me,

   This is a harmless warning that can be ignored (a false positive from
the Matrix package); it could be eliminated by upgrading your version of
the Matrix package, after which you should at least reinstall (and
possibly update) your version of lme4.

  Ben Bolker


From bbolker at gmail.com  Tue Dec  3 17:02:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 03 Dec 2013 11:02:57 -0500
Subject: [R-sig-ME] How to calculate proportion of deviance explained
 from GAMM?
In-Reply-To: <CAOCHjhRiRjxw89gqA-VO_eGui6-LdDxRTj+t26aQsVPW=jRRuQ@mail.gmail.com>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>	<CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>	<3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DB43@exch-mbx-01.utu.fi>
	<CAOCHjhRiRjxw89gqA-VO_eGui6-LdDxRTj+t26aQsVPW=jRRuQ@mail.gmail.com>
Message-ID: <529E00B1.1020000@gmail.com>

On 13-12-03 07:58 AM, Julia Sommerfeld wrote:
> Hi Mari,
> 
> 
> 2013/12/3 Mari Lyly <mari.s.lyly at utu.fi>
> 
>> Hi Julia,
>>
>> I too thought of using GAMM for getting the null deviance, but I cannot
>> use deviance() function on the $gam bit of the GAMM (it returns 'NULL'). I
>> wonder if the sum of squared residuals of the null GAMM would be the same
>> thing as the null deviance? That is, I fit a GAMM and then calculate the
>> sum of squared residuals, as follows:
>>
>> data$rand <- 1
>> model0 <-gamm(response ~ 1, random=list(rand= ~ 1), data=data,
>> family=poisson)
>> DN <- sum(residuals(model0$gam, type="pearson")^2)
>>
>> Would it be ok to use that to get the null deviance (and the DE%)?

  Well, I would use the sum of squares of the *deviance* residuals for
that, not the sum of squares of the Pearson residuals ...


From Julia.Sommerfeld at utas.edu.au  Tue Dec  3 17:46:50 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 3 Dec 2013 17:46:50 +0100
Subject: [R-sig-ME] How to calculate proportion of deviance explained
	from GAMM?
Message-ID: <CAOCHjhSLM=OtqF8Pn91mYYYx4k66cvx=hDbzN3TdRSZAguYuyw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/f4845da4/attachment.pl>

From rob.robinson at bto.org  Tue Dec  3 17:59:30 2013
From: rob.robinson at bto.org (Rob Robinson)
Date: Tue, 3 Dec 2013 16:59:30 +0000
Subject: [R-sig-ME] How to calculate proportion of deviance explained
	from GAMM?
In-Reply-To: <CAOCHjhSLM=OtqF8Pn91mYYYx4k66cvx=hDbzN3TdRSZAguYuyw@mail.gmail.com>
References: <CAOCHjhSLM=OtqF8Pn91mYYYx4k66cvx=hDbzN3TdRSZAguYuyw@mail.gmail.com>
Message-ID: <CAGcXcEbGsOvNnYR1m1cFjwuSdve192Wqd=KxUcpezc5e-YSafw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/3fe5ef24/attachment.pl>

From samora.andrew at umb.no  Tue Dec  3 09:44:41 2013
From: samora.andrew at umb.no (Samora Macrice Andrew)
Date: Tue, 3 Dec 2013 08:44:41 +0000
Subject: [R-sig-ME] help with installation of glmmADMB
Message-ID: <984A77FA9998EB4E901B9ABC3D7853DB3CEFFEEF@A-EXCH-MBX2.ans.umb.no>

Hi, i have nested data with zero inflation which I would like to analyze. I have downloaded glmmADMB but when I activate it I get this msg "Error: package 'glmmADMB' was built before R 2.10.0: please re-install it". I tried to update packages in R studio but in vain. I followed the explanations in http://glmmadmb.r-forge.r-project.org/glmmADMB.html and http://www.ats.ucla.edu/stat/r/faq/mepoisson.htm but i still get the same message!!

Can anyone help please!!

Thanks
Samora M. Andrew
PhD Student 
Ecology and Natural Resource Management
Norwegian University of Life Sciences
P.O. Box 5003, ?s, Norway 


From PaulW.Rasmussen at wisconsin.gov  Tue Dec  3 18:27:28 2013
From: PaulW.Rasmussen at wisconsin.gov (Rasmussen, Paul W - DNR)
Date: Tue, 3 Dec 2013 11:27:28 -0600
Subject: [R-sig-ME] extract phi parameter from lme model
Message-ID: <38E3F31A2DB41640951AE608DB95918209AE979B3D@MEWMAD0P1699.accounts.wistate.us>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/65e22b7b/attachment.pl>

From julia.somma at gmail.com  Tue Dec  3 10:45:08 2013
From: julia.somma at gmail.com (Julia Sommerfeld)
Date: Tue, 3 Dec 2013 10:45:08 +0100
Subject: [R-sig-ME] How to calculate proportion of deviance explained
	from GAMM?
In-Reply-To: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C4CB7DAD3@exch-mbx-01.utu.fi>
Message-ID: <CAOCHjhT6CdZi3e+RcP2AmHEumpYm47E7ZAGudTY0zv+3m2xpcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/0cb9f069/attachment.pl>

From bbolker at gmail.com  Tue Dec  3 21:56:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 03 Dec 2013 15:56:25 -0500
Subject: [R-sig-ME] extract phi parameter from lme model
In-Reply-To: <38E3F31A2DB41640951AE608DB95918209AE979B3D@MEWMAD0P1699.accounts.wistate.us>
References: <38E3F31A2DB41640951AE608DB95918209AE979B3D@MEWMAD0P1699.accounts.wistate.us>
Message-ID: <529E4579.9030404@gmail.com>

On 13-12-03 12:27 PM, Rasmussen, Paul W - DNR wrote:
> Hi,
> 
> Can anyone tell me how to extract an AR(1) parameter from an lme
> model?
> 
> Here is a summary of the model:
> 
>> summary(WAElme.modAR1)
> Linear mixed-effects model fit by maximum likelihood Data:
> WAElmeData AIC       BIC   logLik -103.6577 -83.43384 57.82883
> 
> Random effects: Formula: ~1 | WBIC (Intercept)  Residual StdDev:
> 0.08148838 0.2578487
> 
> Correlation Structure: ARMA(1,0) Formula: ~year | WBIC Parameter
> estimate(s): Phi1 0.7262637 Fixed effects: log10pe ~ year + area 
> Value  Std.Error  DF  t-value p-value (Intercept)  3.468126
> 0.08024473 203 43.21937  0.0000 year        -0.009656 0.00491928 203
> -1.96292  0.0510 area         0.276664 0.04673097   9  5.92035
> 0.0002 Correlation: (Intr) year year -0.823 area -0.034  0.065
> 
> Standardized Within-Group Residuals: Min           Q1          Med
> Q3          Max -3.182366526 -0.526080732 -0.002701109  0.573640884
> 2.406525772
> 
> Number of Observations: 215 Number of Groups: 11
> 
> I can print the value of the phi parameter as follows:
> 
>> WAElme.modAR1$modelStruct$corStruct
> Correlation structure of class corARMA representing Phi1 0.7262637
> 
> but I am not able to use this in further calculations.  Can anyone
> tell me how to extract this as a scalar for use in further
> calculations?
> 
> Thank you, Paul Rasmussen Wisconsin DNR
> 

A reproducible example is always nice ...

set.seed(101)
d <- data.frame(y=rnorm(100),x=rnorm(100),f=factor(rep(1:10,10)))
library(nlme)
m <- lme(y~x,random=~1|f,correlation=corAR1(),data=d)

cS
str(cS <- m$modelStruct$corStruct)
## ... something complicated
coef(cS)  ## not same as printed value
?coef.corStruct
coef(cS,unconstrained=FALSE)


From bbolker at gmail.com  Tue Dec  3 22:01:26 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 21:01:26 +0000 (UTC)
Subject: [R-sig-ME] help with installation of glmmADMB
References: <984A77FA9998EB4E901B9ABC3D7853DB3CEFFEEF@A-EXCH-MBX2.ans.umb.no>
Message-ID: <loom.20131203T215910-290@post.gmane.org>

Samora Macrice Andrew <samora.andrew at ...> writes:

> 
> Hi, i have nested data with zero inflation which I would like to
>  analyze. I have downloaded glmmADMB 

  from where? what is the name of your downloaded file?

> but when
> I activate it I get this msg "Error: package 'glmmADMB' was built
>  before R 2.10.0: please re-install it". I
> tried to update packages in R studio but in vain. 
> I followed the explanations in
> http://glmmadmb.r-forge.r-project.org/glmmADMB.html and
> http://www.ats.ucla.edu/stat/r/faq/mepoisson.htm but i 
> still get the same message!!
> 
> Can anyone help please!!

 Have you tried the instructions at 

http://glmmadmb.r-forge.r-project.org/

in particular #2,

If this fails (because you don't have the very latest version of R, or
because R-forge is having a bad day), try

install.packages("glmmADMB", 
   repos=c("http://glmmadmb.r-forge.r-project.org/repos",
           getOption("repos")),type="source")


  ??

> 
> Thanks
> Samora M. Andrew
> PhD Student 
> Ecology and Natural Resource Management
> Norwegian University of Life Sciences
> P.O. Box 5003, ?s, Norway 
> 
>


From bbolker at gmail.com  Tue Dec  3 22:03:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 21:03:07 +0000 (UTC)
Subject: [R-sig-ME] Linear mixed model (estimated mean ploting)
References: <BLU182-W38FABC5B40BD37FFDE1F8AA3EB0@phx.gbl>
Message-ID: <loom.20131203T220220-619@post.gmane.org>

Sunil Mundra <sunilmundra at ...> writes:

> 
> Hi all,I have two treatment, within one fixed effect. 
> i would like to plot estimated mean of the model for
> each treatment in the same line of the graph, how can i plot this? 
> I have many variable to test against fixed
> variable and want to plot using less space.anyone can help me?
> Many thanks in advance.RegardsSunil
> Mundra 		 	   	

  Please give us a small, simple reproducible example of what you
want.  http://tinyurl.com/reproducible-000 may be helpful.


From bbolker at gmail.com  Tue Dec  3 22:10:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 21:10:07 +0000 (UTC)
Subject: [R-sig-ME] Always allow for correlation of random effects?
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>
Message-ID: <loom.20131203T220519-969@post.gmane.org>

AvianResearchDivision <segerfan83 at ...> writes:

> 
> Hi all,
> 
> I am working with mixed models and have the following general model
> structure:
> 
> model<-lmer(X~Y*Z+(A|B), where Y is a continuous mean centered
> environmental variable, Z is Year (2012 or 2013).
> 
> Part of my interest in my study is to explore variation in plasticity
> between individuals, not just population level plasticity.  When settling
> on a final model, I first check for significance of random 
> effects and then
> I worry about the fixed effects structure.  For the random effects
> structure, even in there is not significant variation between individuals
> in their slope, I leave this term in the model because it is a primary
> interest of mine.  My question is, if I am leaving random slopes in all of
> final models along with random intercepts, should I also allow for the
> correlation of the random effects, i.e. (A|B) or should I not allow for
> this, i.e. (A+0|B) if there is no significant correlation when checked LRT
> fitted by REML?
> 
> I initially thought that I would remove the ability for correlated random
> effects if there was no significant correlation, but then I read the
> following: "In models with both individual-specifi?c 
> elevations and slopes we
> allowed for the potential correlation between these, to ensure that BLUP
> estimates produced by the models were not affected by the method used to
> centre covariates." from 'Phenotypic plasticity in a maternal trait in red
> deer" by Nussey et al. 2005.  Do you understand their reasoning?

  Very briefly (if Gmane lets me): if the correlation between slopes
and intercepts is suppressed, then you can change the results by
linear transformation of the 'A' variable (you didn't tell us what
it was -- it might be helpful); for example, if 'A' is a continuous
predictor, then centering it will change the answers.  If 'A' is
a categorical predictor, then changing the contrasts (e.g. from the
default treatment contrasts to sum-to-zero contrasts) will change the
answers.  If you allow for the correlations, then the results will be
invariant to linear transformations/combinations of the 'A' variable.
Rune Haubo has some nice little examples of this phenomenon suggesting
that the common practice of dropping the correlations for parsimony
can have misleading effects -- I don't know if they're publicly available
anywhere.

  By the way,
by dropping the correlations do you mean the difference between

(1|B) + (0+A|B)

and

(A|B)

?  This works for a continuous variable, but *not* for a categorical
variable -- at present if you want to do this for a categorical
variable you need to generate your own dummy variables (e.g. see
https://github.com/lme4/lme4/issues/139 )


From bbolker at gmail.com  Tue Dec  3 22:16:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Dec 2013 21:16:07 +0000 (UTC)
Subject: [R-sig-ME] estimation of intercept in binomial glmer
References: <6A157C1E1256BB4C8AE38B529E908BF8B708640E@KIMSX04.user.ki.se>
Message-ID: <loom.20131203T221041-744@post.gmane.org>

Bj?rn Lindstr?m <Bjorn.Lindstrom at ...> writes:

> 
> Dear all,
 
> I have a data set with 25 subjects, all with 20 binary responses
> (psychological learning task). Many subjects gave the 1 response
> (lets call this response A and the 0 response B) throughout the
> task.
 
> My goal is to estimate the Probability of A (P(A)), and if it is
> above chance (the latter is trivial in this data set, but I have
> several other similar sets where its more of an issue).
 
> If I calculate the proportion of A responses for each subject (mean,
> na.rm=T), the sample mean is 0.757 (the sample distribution of
> proportion A is very skewed toward 1, with a few all 0 respondents).
 
> If i instead use glmer:
> glmer(RespondA~1+(1|Subject),family=binomial,data=data),

> Fixed effects:
>       Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.660      1.143   3.201  0.00137 **
> 
> ,with an estimate that is far above 0.757. Plogis(3.66) = 0.974. 
> This estimate is close to the sample median
> (md =1), but does it make sense?
> 
> Ordinary glm, ignoring the Subject factor, gives an intercept closer to
>  the sample mean :
> 
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.1995     0.1073   11.18   <2e-16 ***
> 
> (plogis(1.1995) = 0.768)
 
> Can someone please illuminate whats happening here? Is it shrinkage
> in the GLMM? Seem a bit much for just the intercept right?
> Overdispersion (dont know much about that...)

  This is an interesting question; I find it hard to answer precisely
without seeing the original data, but it doesn't surprise me 
very much that in this kind of extreme situation (with complete
or near-complete separation for some of the respondents) the results
from naive averaging, GLM estimation (which should correspond to 
averaging on the logit scale), and GLMM estimation would differ
considerably.  The GLMM intercept represents (roughly) the population
average across individuals of the log-odds response, while the GLM
intercept represents the the population average across observations.
You might get some enlightenment out of the relevant section from
Agresti's _Categorical Data Analysis_ book (sorry, don't have it
with me) on marginal vs conditional estimates ...

 Ben Bolker


From jake987722 at hotmail.com  Tue Dec  3 22:32:39 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 3 Dec 2013 14:32:39 -0700
Subject: [R-sig-ME] Always allow for correlation of random effects?
In-Reply-To: <loom.20131203T220519-969@post.gmane.org>
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>,
	<loom.20131203T220519-969@post.gmane.org>
Message-ID: <BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/d1f7bea5/attachment.pl>

From gebregz at musc.edu  Tue Dec  3 22:35:07 2013
From: gebregz at musc.edu (Gebregziabher, Mulugeta)
Date: Tue, 3 Dec 2013 21:35:07 +0000
Subject: [R-sig-ME] estimation of intercept in binomial glmer
In-Reply-To: <loom.20131203T221041-744@post.gmane.org>
References: <6A157C1E1256BB4C8AE38B529E908BF8B708640E@KIMSX04.user.ki.se>
	<loom.20131203T221041-744@post.gmane.org>
Message-ID: <21B425F6A7950443A4DE2B335BC4CB441F623759@exg-mb11a.clinlan.local>

A helpful answer to this question is on page 363 of Fitzmaurice et al (2004): Applied longitudinal analysis. 
The approximate relationship between Beta_glm and Beta_glmm is given as:
Beta_glm=~Beta_glmm/sqrt(1+0.346*var(b_i))
Where b_i is the random intercept in the glmm.
Hope this helps!
--------------------------------
Mulugeta Gebregziabher, PhD
Associate Professor of Biostatistics
Department of Public Health Sciences
Medical University of South Carolina

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Tuesday, December 03, 2013 4:16 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] estimation of intercept in binomial glmer

Bj?rn Lindstr?m <Bjorn.Lindstrom at ...> writes:

> 
> Dear all,
 
> I have a data set with 25 subjects, all with 20 binary responses 
> (psychological learning task). Many subjects gave the 1 response (lets 
> call this response A and the 0 response B) throughout the task.
 
> My goal is to estimate the Probability of A (P(A)), and if it is above 
> chance (the latter is trivial in this data set, but I have several 
> other similar sets where its more of an issue).
 
> If I calculate the proportion of A responses for each subject (mean, 
> na.rm=T), the sample mean is 0.757 (the sample distribution of 
> proportion A is very skewed toward 1, with a few all 0 respondents).
 
> If i instead use glmer:
> glmer(RespondA~1+(1|Subject),family=binomial,data=data),

> Fixed effects:
>       Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.660      1.143   3.201  0.00137 **
> 
> ,with an estimate that is far above 0.757. Plogis(3.66) = 0.974. 
> This estimate is close to the sample median (md =1), but does it make 
> sense?
> 
> Ordinary glm, ignoring the Subject factor, gives an intercept closer 
> to  the sample mean :
> 
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.1995     0.1073   11.18   <2e-16 ***
> 
> (plogis(1.1995) = 0.768)
 
> Can someone please illuminate whats happening here? Is it shrinkage in 
> the GLMM? Seem a bit much for just the intercept right?
> Overdispersion (dont know much about that...)

  This is an interesting question; I find it hard to answer precisely without seeing the original data, but it doesn't surprise me very much that in this kind of extreme situation (with complete or near-complete separation for some of the respondents) the results from naive averaging, GLM estimation (which should correspond to averaging on the logit scale), and GLMM estimation would differ considerably.  The GLMM intercept represents (roughly) the population average across individuals of the log-odds response, while the GLM intercept represents the the population average across observations.
You might get some enlightenment out of the relevant section from Agresti's _Categorical Data Analysis_ book (sorry, don't have it with me) on marginal vs conditional estimates ...

 Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker at gmail.com  Tue Dec  3 22:58:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 03 Dec 2013 16:58:56 -0500
Subject: [R-sig-ME] estimation of intercept in binomial glmer
In-Reply-To: <21B425F6A7950443A4DE2B335BC4CB441F623759@exg-mb11a.clinlan.local>
References: <6A157C1E1256BB4C8AE38B529E908BF8B708640E@KIMSX04.user.ki.se>	<loom.20131203T221041-744@post.gmane.org>
	<21B425F6A7950443A4DE2B335BC4CB441F623759@exg-mb11a.clinlan.local>
Message-ID: <529E5420.30407@gmail.com>

On 13-12-03 04:35 PM, Gebregziabher, Mulugeta wrote:
> A helpful answer to this question is on page 363 of Fitzmaurice et al (2004): Applied longitudinal analysis. 
> The approximate relationship between Beta_glm and Beta_glmm is given as:
> Beta_glm=~Beta_glmm/sqrt(1+0.346*var(b_i))
> Where b_i is the random intercept in the glmm.
> Hope this helps!
> --------------------------------
> Mulugeta Gebregziabher, PhD
> Associate Professor of Biostatistics
> Department of Public Health Sciences
> Medical University of South Carolina

  Very useful. This Google books link:

http://books.google.ca/books?id=0exUN1yFBHEC&lpg=PA441&dq=fitzmaurice%20glm%20glmm&pg=PA477#v=snippet&q=attenuated&f=false

  gives the magic number as k^2=0.346 with k=16*sqrt(3)/(15*pi) ["The
derivation of this approximation is not important" (!!)]

> 256*3/(225*pi^2)
[1] 0.345843

I'm assuming we can get this from some kind of delta-method
approximation based on the logistic distribution (the logistic
distribution with scale parameter s has variance pi^2/3*s^2), but can't
produce it immediately without further work ...

 Section 12.2.2 of Agresti gives the marginal mean as logistic(c X beta)
where c = (1+0.6*sigma^2)^{-1/2}, referencing Zeger et al 1988

  Ben Bolker


From reinhold.kliegl at gmail.com  Tue Dec  3 23:39:50 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 3 Dec 2013 23:39:50 +0100
Subject: [R-sig-ME] Always allow for correlation of random effects?
In-Reply-To: <BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>
	<loom.20131203T220519-969@post.gmane.org>
	<BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>
Message-ID: <CAG+WrEyFx06yZrp_AAbL2LmFiqjPRXA=Ef6BrWU3nVyLmY6D6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131203/d02af0c3/attachment.pl>

From bbolker at gmail.com  Wed Dec  4 01:59:21 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Dec 2013 00:59:21 +0000 (UTC)
Subject: [R-sig-ME] Always allow for correlation of random effects?
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>
	<loom.20131203T220519-969@post.gmane.org>
	<BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>
	<CAG+WrEyFx06yZrp_AAbL2LmFiqjPRXA=Ef6BrWU3nVyLmY6D6g@mail.gmail.com>
Message-ID: <loom.20131204T015620-146@post.gmane.org>

Reinhold Kliegl <reinhold.kliegl at ...> writes:

> 
> Does the following relate to the issue you are discussing here?
> 
> # If a and b are intercept and slope, then the
> # offset for X to obtain a zero intercept-slope
> # correlation parameter is cov(a,b)/var(b).
> # (I saw this derivation, which also yields a minimum
> # variance estimate for the intercept, in a 2007 GLMM
> # handout by Ulrich  Halekoh.)
> 
> # An illustration with the sleepstudy data.
> library(lme4)
> summary(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> VarCorr(fm1)
> 
> ## Groups   Name        Std.Dev. Corr
> ## Subject  (Intercept) 24.7406
> ##          Days         5.9221  0.066
> ## Residual             25.5918
> 
> # Compute the offset and add it to Days
> # (i.e., a very specific, but linear transformation of Days)
> sleepstudy$DaysA <- sleepstudy$Days + (0.066*24.7405*5.9221)/35.072
> summary(fm3 <- lmer(Reaction ~ DaysA + (DaysA|Subject), sleepstudy))
> 
> VarCorr(fm3)
> ##Groups   Name        Std.Dev. Corr
> ##Subject  (Intercept) 24.6874
> ##         DaysA        5.9221  0.000
> ##Residual             25.5918
> 
> Reinhold Kliegl

  Yes, that's a large part of it.  There may have been some other
aspects to the example, but I think this illustrates the main point.
My interpretation is that unless the zero point of the continuous
covariate has strong theoretical meaning, so that a location shift
doesn't make sense, the hypothesis (correlation=0) is 
dubious.  This seems analogous to the old rule that one shouldn't
compare between-group (intercept) differences in an ANCOVA model
(one with an interaction between a continuous and a categorical 
predictor), because they can be made to match any arbitrary value
by shifting the location of the continuous predictor.


From segerfan83 at gmail.com  Wed Dec  4 14:44:50 2013
From: segerfan83 at gmail.com (AvianResearchDivision)
Date: Wed, 4 Dec 2013 08:44:50 -0500
Subject: [R-sig-ME] Always allow for correlation of random effects?
In-Reply-To: <loom.20131204T015620-146@post.gmane.org>
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>
	<loom.20131203T220519-969@post.gmane.org>
	<BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>
	<CAG+WrEyFx06yZrp_AAbL2LmFiqjPRXA=Ef6BrWU3nVyLmY6D6g@mail.gmail.com>
	<loom.20131204T015620-146@post.gmane.org>
Message-ID: <CAHe08SjQFduBLzqNJ6kCTfg+-buKuNku529r5vN=AsZBKBLS8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/8b97bd8a/attachment.pl>

From bbonit at tin.it  Wed Dec  4 16:32:31 2013
From: bbonit at tin.it (bbonit at tin.it)
Date: Wed, 4 Dec 2013 16:32:31 +0100 (CET)
Subject: [R-sig-ME] simulate lme function value
Message-ID: <142be3d3393.bbonit@tin.it>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/cd395e74/attachment.pl>

From sheryn.olson at maine.edu  Wed Dec  4 16:46:54 2013
From: sheryn.olson at maine.edu (Sheryn Olson)
Date: Wed, 4 Dec 2013 10:46:54 -0500
Subject: [R-sig-ME] glmmadmb nbinom model syntax correctly accounting for
	repeated measures?
Message-ID: <CAATUFeeryOvnx4N4vsLYMq0nkXy+=HfcKztew9pEgh8+CbP2=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/e5e27339/attachment.pl>

From F.Ingleby at sussex.ac.uk  Wed Dec  4 16:56:14 2013
From: F.Ingleby at sussex.ac.uk (Fiona Ingleby)
Date: Wed, 4 Dec 2013 15:56:14 +0000
Subject: [R-sig-ME] simulating datasets for mixed model analysis
Message-ID: <A6F63871-E59A-4118-A963-9375CB102CD1@sussex.ac.uk>

Dear list,

I am trying to simulate a dataset with a specific covariance matrix for analysis with a mixed model. To illustrate what I mean, I've used MCMCglmm (although a similar model could be done using lmer) to make a reproducible example:

# make a random dataset
data<-data.frame(x=rnorm(5000,0.1,0.1),y=rnorm(5000,0.5,0.2),z=rnorm(5000,0.4,0.1),group=factor(rep(seq(50),100)))
# analyse with MCMCglmm as if x, y and z are three response variables and group is a grouping factor
prior<-list(R=list(V=diag(3)/3,nu=0.05),G=list(G1=list(V=diag(3)/3,nu=0.05)))
model<-MCMCglmm(cbind(x,y,z)~trait-1,random=~us(trait):group,
              rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",3),
              nitt=20000,burnin=1000,thin=25)
# extract the group-level variance/covariance matrix:
varcov<-matrix(c(mean(model$VCV[,1]),mean(model$VCV[,2]),mean(model$VCV[,3]),mean(model$VCV[,4]),mean(model$VCV[,5]),mean(model$VCV[,6]),mean(model$VCV[,7]),mean(model$VCV[,8]),mean(model$VCV[,9])),3)

What I would like to do is start with a given matrix, and simulate a dataset around this matrix - so, something similar to the line of code above used to create the random dataset, but designed for a known var/cov structure.

I'd be really grateful if anyone could offer any help or point me in the right direction at all.

Thanks in advance,

Fiona

From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Dec  4 17:48:52 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 4 Dec 2013 17:48:52 +0100
Subject: [R-sig-ME] Always allow for correlation of random effects?
In-Reply-To: <CAHe08SjQFduBLzqNJ6kCTfg+-buKuNku529r5vN=AsZBKBLS8w@mail.gmail.com>
References: <CAHe08Sj39CQM=stWc0TtmKXDk4vA880D_T-MvqNfOvxp4xHwJQ@mail.gmail.com>
	<loom.20131203T220519-969@post.gmane.org>
	<BAY172-W39A186EB3F3B377969F974CBD50@phx.gbl>
	<CAG+WrEyFx06yZrp_AAbL2LmFiqjPRXA=Ef6BrWU3nVyLmY6D6g@mail.gmail.com>
	<loom.20131204T015620-146@post.gmane.org>
	<CAHe08SjQFduBLzqNJ6kCTfg+-buKuNku529r5vN=AsZBKBLS8w@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99B0D876@UM-MAIL4112.unimaas.nl>

This can happen when the model fitting routine is hitting boundaries of the parameter space. For example, suppose the slope variance of Y is so close to 0 as to be essentially indistinguishable numerically from 0. Whether rho is then -1, 0, +1, or any other value is essentially irrelevant then (since the covariance is then also essentially 0). The routine will give you *some* value (and different routines may give you rather different values), but that parameter is not really estimable. This is what Thierry was alluding to when he said:

> This can be caused by having more complexity than the data allows. Note that the variance of the random slope is small.

Thierry, please correct me if I am misinterpreting your statement.

The profiled log likelihood for parameters that are not identifiable is essentially flat. Roughly speaking, this translates into a large SE for the corresponding parameter estimate. So, even with an 'estimated' correlation of -1, the test of that correlation may not be significant.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of AvianResearchDivision
> Sent: Wednesday, December 04, 2013 14:45
> To: Ben Bolker; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Always allow for correlation of random effects?
> 
> Hi Ben,
> 
> Thank you for the response.  My model actually was this:
> model<-lmer(X~Y*Z+(Y|B), where Y is a continuous grand mean-centered
> environmental variable (where 0 in this case does not have a 'strong
> theoretical meaning' other than the average environment that males (B)
> experience) and B is a factor with 59 levels.  The interaction Y*Z (Z =
> year) is irrelevant I suppose for two reasons.  1.  It's not significant
> in
> all but one case (when tested in 5 different models) and 2.  The one case
> where it is significant, I analyze the two years separately, thus removing
> the interaction from the model.  In my model selection, I establish the
> random effects structure first and then establish the fixed effects
> structure.  If I understand what you and others have responded with, it
> seems that I should leave the possibility of correlations in all models,
> even if a LRT suggests that there is not a significant correlation between
> intercept and slope.  And yes, this amounts to my final random effects
> structure as (Y|B) instead of (Y+0|B)+(1|B).
> 
> The odd thing is, when I allow for correlations in one of my models, the
> R2
> value for my BLUP points (coef(model)) is -1.00, but when I don't allow
> correlations, the R2 value is 0.3857.  When testing for the significance
> of
> correlations with a LRT, the X2 value is 1.68 and p = 0.1946.  How can you
> have an R2 of -1.00, but a non-significant p value?  More importantly, how
> does one get a R2 of -1.00 when working with ecological data?  This seems
> incorrect.
> 
> Thank you again,
> Jacob
> 
> 
> On Tue, Dec 3, 2013 at 7:59 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> > Reinhold Kliegl <reinhold.kliegl at ...> writes:
> >
> > >
> > > Does the following relate to the issue you are discussing here?
> > >
> > > # If a and b are intercept and slope, then the
> > > # offset for X to obtain a zero intercept-slope
> > > # correlation parameter is cov(a,b)/var(b).
> > > # (I saw this derivation, which also yields a minimum
> > > # variance estimate for the intercept, in a 2007 GLMM
> > > # handout by Ulrich  Halekoh.)
> > >
> > > # An illustration with the sleepstudy data.
> > > library(lme4)
> > > summary(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> > > VarCorr(fm1)
> > >
> > > ## Groups   Name        Std.Dev. Corr
> > > ## Subject  (Intercept) 24.7406
> > > ##          Days         5.9221  0.066
> > > ## Residual             25.5918
> > >
> > > # Compute the offset and add it to Days
> > > # (i.e., a very specific, but linear transformation of Days)
> > > sleepstudy$DaysA <- sleepstudy$Days + (0.066*24.7405*5.9221)/35.072
> > > summary(fm3 <- lmer(Reaction ~ DaysA + (DaysA|Subject), sleepstudy))
> > >
> > > VarCorr(fm3)
> > > ##Groups   Name        Std.Dev. Corr
> > > ##Subject  (Intercept) 24.6874
> > > ##         DaysA        5.9221  0.000
> > > ##Residual             25.5918
> > >
> > > Reinhold Kliegl
> >
> >   Yes, that's a large part of it.  There may have been some other
> > aspects to the example, but I think this illustrates the main point.
> > My interpretation is that unless the zero point of the continuous
> > covariate has strong theoretical meaning, so that a location shift
> > doesn't make sense, the hypothesis (correlation=0) is
> > dubious.  This seems analogous to the old rule that one shouldn't
> > compare between-group (intercept) differences in an ANCOVA model
> > (one with an interaction between a continuous and a categorical
> > predictor), because they can be made to match any arbitrary value
> > by shifting the location of the continuous predictor.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From moskante at gmail.com  Wed Dec  4 18:12:24 2013
From: moskante at gmail.com (alessandro)
Date: Wed, 4 Dec 2013 18:12:24 +0100
Subject: [R-sig-ME] simulating datasets for mixed model analysis
In-Reply-To: <mailman.601.1386175735.4547.r-sig-mixed-models@r-project.org>
References: <mailman.601.1386175735.4547.r-sig-mixed-models@r-project.org>
Message-ID: <0CC4CBF8-4B9A-40A6-81BC-3B7B72E70FF7@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/e897e176/attachment.pl>

From kw.stat at gmail.com  Wed Dec  4 18:30:07 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 4 Dec 2013 11:30:07 -0600
Subject: [R-sig-ME] simulating datasets for mixed model analysis
In-Reply-To: <0CC4CBF8-4B9A-40A6-81BC-3B7B72E70FF7@gmail.com>
References: <mailman.601.1386175735.4547.r-sig-mixed-models@r-project.org>
	<0CC4CBF8-4B9A-40A6-81BC-3B7B72E70FF7@gmail.com>
Message-ID: <CAKFxdiQNN+VTaaGWfZwvUSgXkp4Pi8P6ACF=tEp0j0GKTdxtpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/2d7452de/attachment.pl>

From bbolker at gmail.com  Wed Dec  4 18:50:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Dec 2013 17:50:23 +0000 (UTC)
Subject: [R-sig-ME] simulate lme function value
References: <142be3d3393.bbonit@tin.it>
Message-ID: <loom.20131204T184708-467@post.gmane.org>

bbonit at ... <bbonit at ...> writes:

> 
>  Dear list i have a question :
> 
> how can i extract simulated value from simulate function in nlme ? (if it
is possible)
> thank You so much 
> sorry for noise
> Bonitta Gianluca 

  I think you may be out of luck -- that is, I don't think that
simulate.lme stores the simulated values.  If I run the example
in ?simulate.lme and examine the resulting object, I get:

str(orthSim)
List of 2
 $ null:List of 2
  ..$ ML  : num [1:1000, 1:2] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:1000] "1" "2" "3" "4" ...
  .. .. ..$ : chr [1:2] "info" "logLik"
  ..$ REML: num [1:1000, 1:2] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:1000] "1" "2" "3" "4" ...
  .. .. ..$ : chr [1:2] "info" "logLik"
 $ alt :List of 2
  ..$ ML  : num [1:1000, 1:2] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:1000] "1" "2" "3" "4" ...
  .. .. ..$ : chr [1:2] "info" "logLik"
  ..$ REML: num [1:1000, 1:2] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:1000] "1" "2" "3" "4" ...
  .. .. ..$ : chr [1:2] "info" "logLik"
 - attr(*, "call")= language simulate.lme(object = 
  list(fixed = distance ~ age, data = Orthodont,
   random = ~1 |      Subject), nsim = 1000, 
   m2 = list(random = ~age | Subject))
 - attr(*, "seed")= int 61390140
 - attr(*, "df")= num 2
 - attr(*, "useGen")= logi FALSE
 - attr(*, "class")= chr "simulate.lme"

In words -- the ML and REML criteria are stored for the reduced
and full models for each simulation, but not the values themselves.
You *might* be able to hack the function: the critical lines are

base2 <- base + rnorm(N, sd = sig)
        for (j in 1:Q) {
            base2 <- base2 + ((array(rnorm(ngrp[j] * qvec[j]), 
                c(ngrp[j], qvec[j]), list(1:ngrp[j], NULL)) %*% 
                DeltaInv[[j]])[ind[[j]], , drop = FALSE] * condL1$Xy[, 
                csq1[j]:csq2[j], drop = FALSE]) %*% rep(1, qvec[j])
        }


From s06mw3 at abdn.ac.uk  Wed Dec  4 19:15:48 2013
From: s06mw3 at abdn.ac.uk (matthew)
Date: Wed, 4 Dec 2013 18:15:48 +0000
Subject: [R-sig-ME]  simulating datasets for mixed model analysis
Message-ID: <529F7154.5010002@abdn.ac.uk>

Dear Fiona,

You can check out the course notes to the MCMCglmm package - there are
examples in there that simulate data.  Also, try the "grfx" and "drfx"
functions in the "nadiv" package.  Below is some code using your example
that does what I think you want.  Of course, there are probably other
(more elegant) options out there that can be accessed by a little
googling...

Sincerely,
Matthew

######## R CODE   ######
library(MCMCglmm)
library(nadiv)
# make a random dataset
data<-data.frame(group=factor(rep(seq(50),100)))
#define the mean for each trait
mus <- rnorm(3, 100, 20)
#define the desired variance-covariance matrix for the "groups"
vcov.in <- matrix(c(10,  5, 3,
                      5, 10, 8,
              3,  8, 10), nrow = 3, byrow = TRUE)
#define a residual variance-covariance matrix (here, residuals are
un-correlated among groups)
Rvcov <- diag(c(10, 20, 5))
#Create the random effects for the group variable
fx.out <- drfx(G = vcov.in, fac = "group", dataf = data)
#create the residuals
r.out <- grfx(n = 5000, G = Rvcov, incidence = NULL)
#create a trait value for each of the three traits
data$x <- mus[1] + fx.out$fx[, 1] + r.out[, 1]
data$y <- mus[2] + fx.out$fx[, 2] + r.out[, 2]
data$z <- mus[3] + fx.out$fx[, 3] + r.out[, 3]
# analyse with MCMCglmm as if x, y and z are three response variables
and group is a grouping factor
prior<-list(R=list(V=diag(3)/3,nu=0.05),G=list(G1=list(V=diag(3)/3,nu=0.05)))
model<-MCMCglmm(cbind(x,y,z)~trait-1,random=~us(trait):group,

rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",3),
               nitt=20000,burnin=1000,thin=25)
# extract the group-level variance/covariance matrix:
varcov<-matrix(c(mean(model$VCV[,1]),mean(model$VCV[,2]),mean(model$VCV[,3]),mean(model$VCV[,4]),mean(model$VCV[,5]),mean(model$VCV[,6]),mean(model$VCV[,7]),mean(model$VCV[,8]),mean(model$VCV[,9])),3)

#now compare the covariance matrix of generated random effects with the
estimated one from MCMCglmm
cov(fx.out$fx)
varcov



--
....................................................
Dr. Matthew E. Wolak
School of Biological Sciences
Zoology Building
University of Aberdeen
Tillydrone Avenue
Aberdeen AB24 2TZ
office phone: +44 (0)1224 273255




The University of Aberdeen is a charity registered in Scotland, No SC013683.


From agalecki at umich.edu  Wed Dec  4 19:33:35 2013
From: agalecki at umich.edu (Andrzej Galecki)
Date: Wed, 4 Dec 2013 13:33:35 -0500
Subject: [R-sig-ME] simulate lme function value
In-Reply-To: <loom.20131204T184708-467@post.gmane.org>
References: <142be3d3393.bbonit@tin.it>
	<loom.20131204T184708-467@post.gmane.org>
Message-ID: <CA+XOvORgnr7HQ0-E9r021NF=oAvinJXAML0Ou_MELjfBjPEmWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131204/68564e01/attachment.pl>

From bbolker at gmail.com  Wed Dec  4 19:46:08 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Dec 2013 18:46:08 +0000 (UTC)
Subject: [R-sig-ME] simulate lme function value
References: <142be3d3393.bbonit@tin.it>
	<loom.20131204T184708-467@post.gmane.org>
	<CA+XOvORgnr7HQ0-E9r021NF=oAvinJXAML0Ou_MELjfBjPEmWw@mail.gmail.com>
Message-ID: <loom.20131204T193802-955@post.gmane.org>

Andrzej Galecki <agalecki at ...> writes:

> 
> Hello Bonitta,
> 
> You may want to  try:
> 
> library(nlme)
> fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
> 
> library(nlmeU)
> simY <- simulateY(fm1, nsim =5)
> 
> Internallly, simulateY  employs  getVarCov.lme method  function from nlme
> package. For this reason it will not work for models with multiple levels
> of nesting.
> 
> More details about simulateY function in Section 20.4 of the  Galecki,
> Burzykowski book "Linear Mixed-Effects Models Using R: A step-by-step
> approach" (2013).

  For what it's worth, if you're willing to move to lme4 (and I
know there are reasons not to do this), simulate() works more as 
one would expect from the ?simulate help page (simulate.lme was
written *before* the generic simulate method was introduced into R),
and you can simulate either from a fitted model or from a one-sided
formula (with specified data and parameters).  Of course, you can't
simulate models with R-side effects such as correlation or
heteroscedasticity, but apparently these can't be simulated with 
simulate.lme either:

   if (length(fit1$modelStruct) > 1) {
        stop("models with \"corStruct\" and/or
     \"varFunc\" objects not allowed")
    }


e.g.

library(lme4)
data(Orthodont,package="nlme")
fm1 <- lmer(distance ~ age+(1|age), data = Orthodont)
ss <- simulate(fm1,nsim=5)

or

## this requires the development version of lme4 ...
ss2 <- simulate(~age+(1|age),
                newdata=Orthodont,
                family=gaussian,
                newparams=list(beta=c(1,1),theta=1,sigma=1),
                nsim=5)


From bbonit at tin.it  Wed Dec  4 20:50:01 2013
From: bbonit at tin.it (Bonitta gianluca)
Date: Wed, 4 Dec 2013 19:50:01 +0000 (UTC)
Subject: [R-sig-ME] simulate lme function value
References: <142be3d3393.bbonit@tin.it>
	<loom.20131204T184708-467@post.gmane.org>
Message-ID: <loom.20131204T203234-562@post.gmane.org>

thank you so  much i had seen base2 ...







but i must "hack? the functio and recompile pakage ..







return(base2)..







i not able to hack function directly from r .....























maby with fixInNamespace??







can you help me ...







thank you professor Ben 







thank You professor Galecki  (nice book ...maby i don' t  read with 
attention simulation in nlmU package



Oh yes is wonderful if  lme4 can implement a part for correlated errors 
linear mixed models  (for repeated maesure  ... but complimet  to all lme4 
dev team and all people who try to ipmrove  this package















SORRY FOR NOISE















thank You list















Bonitta Gianluca


From sunilmundra at hotmail.com  Wed Dec  4 23:09:03 2013
From: sunilmundra at hotmail.com (Sunil Mundra)
Date: Thu, 5 Dec 2013 03:39:03 +0530
Subject: [R-sig-ME] Prediction of modeled estimate and plot
In-Reply-To: <loom.20131204T184708-467@post.gmane.org>
References: <142be3d3393.bbonit@tin.it>,
	<loom.20131204T184708-467@post.gmane.org>
Message-ID: <BLU182-W30A1B5A231796B3AEEC89DA3D40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131205/c06cb168/attachment.pl>

From bbolker at gmail.com  Wed Dec  4 23:23:14 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 04 Dec 2013 17:23:14 -0500
Subject: [R-sig-ME] Prediction of modeled estimate and plot
In-Reply-To: <BLU182-W30A1B5A231796B3AEEC89DA3D40@phx.gbl>
References: <142be3d3393.bbonit@tin.it>,
	<loom.20131204T184708-467@post.gmane.org>
	<BLU182-W30A1B5A231796B3AEEC89DA3D40@phx.gbl>
Message-ID: <529FAB52.7040907@gmail.com>

On 13-12-04 05:09 PM, Sunil Mundra wrote:
> Hi allI am interested to see the effect of warming (a factor
> variable, with control set and experimental set due to snow
> accumulation), and vegetation (experiment is conducted in two
> different vegetation type), there is random effect of Block of Fence
> and individual fence within the vegetation type.I would like to
> predict modeled estimate of env var (here shown only moisture, I have
> total 15 env variable) at different warming treatment (a factor, with
> two treatment; Deep and Control) and at different Vegetation type
> (Heath and Meadow).I also want to plot these predicted values and
> also need to test their significance (I need help how to this after
> prediction)

  I don't know quite what you mean by the significance of a predicted
value.  Are you asking whether the confidence intervals on the predicted
values overlap zero?  You can compute confidence intervals on
predictions either via the recipe given at http://glmm.wikidot.com/faq
(which neglects uncertainty in the variance-covariance parameters), or
using parametric bootstrapping (bootMer)


Can any one help me in performing these function and
finishing the script. I am still getting error in predict
function


lmm.2 <- lmer(formula = Moisture ~ Warming + Vegetation +
 (1|Block/Fence), data = data)
summary(lmm.2)
simple.predict(lmm.2,
 Moisture ~ Warming + Vegetation, data.frame(Warming.F=c(Deep,
Control), Vegetation.F = c(Heath, Medow)))

As far as I can tell the 'simple.predict()' function is from the
multilevel package, but as far as I can tell it is also superseded by
predict() from newer version of lme4.

  You're going to have to tell us what's actually going wrong, and
probably provide a reproducible example.  Have you looked at
?predict.merMod in a recent version of lme4 ???

  Ben Bolker


From danielezrajohnson at gmail.com  Thu Dec  5 08:17:10 2013
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 5 Dec 2013 02:17:10 -0500
Subject: [R-sig-ME] order of terms affecting lme4 results (much more than
	lme4.0)
Message-ID: <CAABSvoUgN7-r_inAA1MBwUKkC7nWQ2prm3fSG0yeE0c=Oxv_vg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131205/6fcb6760/attachment.pl>

From danielezrajohnson at gmail.com  Thu Dec  5 13:04:53 2013
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 5 Dec 2013 07:04:53 -0500
Subject: [R-sig-ME] order of terms affecting lme4 results (much more
	than lme4.0)
In-Reply-To: <CAABSvoUgN7-r_inAA1MBwUKkC7nWQ2prm3fSG0yeE0c=Oxv_vg@mail.gmail.com>
References: <CAABSvoUgN7-r_inAA1MBwUKkC7nWQ2prm3fSG0yeE0c=Oxv_vg@mail.gmail.com>
Message-ID: <CAABSvoW--AD7RmOcSeRbk45WMeoJWSVCRobcn4_QZcTrhDPWqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131205/fdabe7f6/attachment.pl>

From rcorria at ipe.csic.es  Thu Dec  5 11:02:18 2013
From: rcorria at ipe.csic.es (CORRIA AINSLIE, ROBIN)
Date: Thu, 05 Dec 2013 11:02:18 +0100
Subject: [R-sig-ME] Model adequacy with glmmADMB
Message-ID: <20131205110218.Horde.AeWqSeC4m2bFhhtda_dJeQ2@webmail.csic.es>

Dear all,

I've been using the glmmADMB package to fit zero-inflated poisson
data and I wanted to know is there is an easy way to asses model adequacy
or goodnes of fit, for example a quantile-quantile plot as suggested
by Zuur (2009) or a pseudo-R2, like in "A general and simple
method for obtaining R2 from generalized linear mixed-effects models"
(Nakagawa & Schielzeth 2013).
I have tried to do the later with the function r.squaredGLMM on
package MuMIn but it?s not applicable to objects of class "glmmadmb".

Any suggestions?



Robin Corri? Ainslie
Instituto Pirenaico de Ecolog?a (IPE-CSIC)
Avda. Monta?ana, 1005. 50059 Zaragoza, Espa?a
Mail: rcorria at ipe.csic.es
Phone: (+34) 976-716031


From taylor.russ at gmail.com  Sun Dec  8 15:17:10 2013
From: taylor.russ at gmail.com (rt)
Date: Sun, 8 Dec 2013 08:17:10 -0600
Subject: [R-sig-ME] Citing LME4 and Bates' Springer book (2010)
Message-ID: <CAH6+39MY1Z-6UHjapn+-=P=by7TjnWb_XhnONRiBp7RSs-ecFA@mail.gmail.com>

What it the proper citation for the lme4 package and the Bates' book?
Also, can lme4 datasets (e.g., Pastes, ScotsSec, InstEval etc.) be
used for illustration in publications?  Can the authors grant
permission or is the permission from the source needed?

Many thanks for the package and the book.  When can I hold a
non-digital copy in my hands?

Thanks,

Russ


From mlgentes2 at yahoo.com  Mon Dec  9 01:24:42 2013
From: mlgentes2 at yahoo.com (marieline gentes)
Date: Sun, 8 Dec 2013 16:24:42 -0800 (PST)
Subject: [R-sig-ME] "whole factor" effects for categorical	variable (3
	levels) in glmmPQL ?
Message-ID: <1386548682.91918.YahooMailNeo@web160803.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131208/5c6de4c8/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Dec  9 05:09:14 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 9 Dec 2013 14:09:14 +1000
Subject: [R-sig-ME] "whole factor" effects for categorical	variable
 (3levels) in glmmPQL ?
In-Reply-To: <1386548682.91918.YahooMailNeo@web160803.mail.bf1.yahoo.com>
References: <1386548682.91918.YahooMailNeo@web160803.mail.bf1.yahoo.com>
Message-ID: <alpine.LMD.2.00.1312091407150.19721@orpheus.qimr.edu.au>

On Mon, 9 Dec 2013, marieline gentes wrote:

> I simply want to report the fact that year (categorical, three levels)
> What is the proper way to do this ? Should I not be using glmmPQL ?

You could use Anova() from John Fox's car package.


From egor.ananyev at gmail.com  Sun Dec  8 04:50:51 2013
From: egor.ananyev at gmail.com (Egor Ananyev)
Date: Sun, 8 Dec 2013 11:50:51 +0800
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
Message-ID: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131208/458cf61e/attachment.pl>

From bates at stat.wisc.edu  Mon Dec  9 18:56:37 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 9 Dec 2013 11:56:37 -0600
Subject: [R-sig-ME] Question on lme4 book
Message-ID: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131209/ec911711/attachment.pl>

From h.wickham at gmail.com  Mon Dec  9 20:35:52 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 9 Dec 2013 13:35:52 -0600
Subject: [R-sig-ME] [Rcpp-devel] Question on lme4 book
In-Reply-To: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
References: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
Message-ID: <CABdHhvG_nrbJ_BN2QzWQvsw0=5JqLKJ1yJXU3Ny8VwajbEgW9g@mail.gmail.com>

> Maintaining an Rcpp-based package on CRAN these days is a case of "no good
> deed shall go unpunished" and "the flogging will continue until morale
> improves".  I am the maintainer of the RcppEigen package which apparently
> also makes me the maintainer of an Eigen port to Solaris.  When compilers on
> Solaris report errors in code from Eigen I am supposed to fix them.  This is
> difficult in that I don't have access to any computers running Solaris,
> which is a proprietary operating system as far as I can tell, and Eigen is a
> complex code base using what is called "template meta-programming" in C++.
> Making modifications to such code can be difficult.  I can't claim to fully
> understand all the details in Eigen and in Rcpp.  I am a user of these code
> bases, not a developer. The Eigen authors themselves don't test their code
> under Solaris because they don't have access to Solaris systems either and
> they don't regard Solaris as an important platform for numerical computing.
> The CRAN maintainers feel differently, which puts me in a box.

It's not just packages that use Rcpp that suffer from this problem.
lubridate, which has extensive user tests, often fails on solaris
because it does something different to every other platform. While
this has uncovered a number of bugs and limitations in R's datetime
support, the only feedback we get from CRAN is extremely negative.

For lubridate, in the absence of any help from a solaris expert (and
no evidence that anyone on solaris uses lubridate), we have simply
told CRAN that it does not work on solaris. We continue to argue that
the CRAN policies only require that an R package need only work on two
major platforms to be distributed via CRAN, and while the CRAN
maintainers continue to push back at us, they are bound by their own
words.

(While a somewhat biased sample, we see very few solaris downloads
from the Rstudio cran mirror: since Jan 1, there were 845 packages
downloaded from solaris, 0.003% of the total)

> There are days when I am tempted to say, "okay, if RcppEigen is not suitable
> for CRAN then remove it" which would result in removal of all the packages
> that depend on it, including lme4.  That may seem childish of me but I
> really don't know what else to do.

I have been tempted to do this too, and for RcppEigen more than an
empty threat. Currently the complete reverse dependencies (Depends,
Imports, LinkingTo and Suggests) of RcppEigen includes 3626 packages,
almost three-quarters of CRAN. It would certainly create more work for
CRAN can allowing RcppEigen to fail on Solaris.

> So I have reached the point of saying "goodbye" to R, Rcpp and lme4 and
> switching all of my development effort to Julia.  I'm sorry but others are going
> to need to determine how to maintain lme4 to the satisfaction of the CRAN
> maintainers or whether there should be an alternative distribution mechanism
> for R packages.

This is a great loss for the R community. nlme was one of the first R
packages that I used, and I still remember taking a SAS-based mixed
models course, while reading "Mixed-Effects Models in S and S-PLUS"
and doing all the homework in R. I certainly learned much more about
mixed models and data analysis from you and your book than I did from
that class! Your patient and thoughtful responses to questions about R
and statistics have helped me become a better statistician, and have
helped many others solve their real scientific problems.

While I hope that one day we can lure you back to R with better ways
of distributing packages, I wish you all the best in making great
modelling software for julia. The julia community is truly lucky to
have you!

Hadley

-- 
http://had.co.nz/


From sorenh at math.aau.dk  Mon Dec  9 22:04:39 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 9 Dec 2013 21:04:39 +0000
Subject: [R-sig-ME] [Rcpp-devel] Question on lme4 book
In-Reply-To: <CABdHhvG_nrbJ_BN2QzWQvsw0=5JqLKJ1yJXU3Ny8VwajbEgW9g@mail.gmail.com>
References: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
	<CABdHhvG_nrbJ_BN2QzWQvsw0=5JqLKJ1yJXU3Ny8VwajbEgW9g@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3931EA711@AD-EXCHMBX2-1.aau.dk>

While perhaps not too surprising, it is still sad news that Doug has decided to give up his work in the R community. It is such a pitty that this Solaris-issue can have such dramatic consequences. Perhaps it is a selection bias, but I think I only know one or two persons who actually use Solaris...

I have greatly enjoyed using RcppEigen in my graphical modelling packages; if RccpEigen does not continue to live on CRAN then my packages will go away too. 

Hopefully a sustainable solution will show up :) In the meantime we are lucky to have github...

Seasons greetings
S?ren


-----Original Message-----
From: rcpp-devel-bounces at lists.r-forge.r-project.org [mailto:rcpp-devel-bounces at lists.r-forge.r-project.org] On Behalf Of Hadley Wickham
Sent: 9. december 2013 20:36
To: Douglas Bates
Cc: R-mixed models mailing list; rcpp-devel
Subject: Re: [Rcpp-devel] Question on lme4 book

> Maintaining an Rcpp-based package on CRAN these days is a case of "no 
> good deed shall go unpunished" and "the flogging will continue until 
> morale improves".  I am the maintainer of the RcppEigen package which 
> apparently also makes me the maintainer of an Eigen port to Solaris.  
> When compilers on Solaris report errors in code from Eigen I am 
> supposed to fix them.  This is difficult in that I don't have access 
> to any computers running Solaris, which is a proprietary operating 
> system as far as I can tell, and Eigen is a complex code base using what is called "template meta-programming" in C++.
> Making modifications to such code can be difficult.  I can't claim to 
> fully understand all the details in Eigen and in Rcpp.  I am a user of 
> these code bases, not a developer. The Eigen authors themselves don't 
> test their code under Solaris because they don't have access to 
> Solaris systems either and they don't regard Solaris as an important platform for numerical computing.
> The CRAN maintainers feel differently, which puts me in a box.

It's not just packages that use Rcpp that suffer from this problem.
lubridate, which has extensive user tests, often fails on solaris because it does something different to every other platform. While this has uncovered a number of bugs and limitations in R's datetime support, the only feedback we get from CRAN is extremely negative.

For lubridate, in the absence of any help from a solaris expert (and no evidence that anyone on solaris uses lubridate), we have simply told CRAN that it does not work on solaris. We continue to argue that the CRAN policies only require that an R package need only work on two major platforms to be distributed via CRAN, and while the CRAN maintainers continue to push back at us, they are bound by their own words.

(While a somewhat biased sample, we see very few solaris downloads from the Rstudio cran mirror: since Jan 1, there were 845 packages downloaded from solaris, 0.003% of the total)

> There are days when I am tempted to say, "okay, if RcppEigen is not 
> suitable for CRAN then remove it" which would result in removal of all 
> the packages that depend on it, including lme4.  That may seem 
> childish of me but I really don't know what else to do.

I have been tempted to do this too, and for RcppEigen more than an empty threat. Currently the complete reverse dependencies (Depends, Imports, LinkingTo and Suggests) of RcppEigen includes 3626 packages, almost three-quarters of CRAN. It would certainly create more work for CRAN can allowing RcppEigen to fail on Solaris.

> So I have reached the point of saying "goodbye" to R, Rcpp and lme4 
> and switching all of my development effort to Julia.  I'm sorry but 
> others are going to need to determine how to maintain lme4 to the 
> satisfaction of the CRAN maintainers or whether there should be an 
> alternative distribution mechanism for R packages.

This is a great loss for the R community. nlme was one of the first R packages that I used, and I still remember taking a SAS-based mixed models course, while reading "Mixed-Effects Models in S and S-PLUS"
and doing all the homework in R. I certainly learned much more about mixed models and data analysis from you and your book than I did from that class! Your patient and thoughtful responses to questions about R and statistics have helped me become a better statistician, and have helped many others solve their real scientific problems.

While I hope that one day we can lure you back to R with better ways of distributing packages, I wish you all the best in making great modelling software for julia. The julia community is truly lucky to have you!

Hadley

--
http://had.co.nz/
_______________________________________________
Rcpp-devel mailing list
Rcpp-devel at lists.r-forge.r-project.org
https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel


From bbolker at gmail.com  Mon Dec  9 22:09:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 09 Dec 2013 16:09:35 -0500
Subject: [R-sig-ME] Question on lme4 book
In-Reply-To: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
References: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
Message-ID: <52A6318F.5090201@gmail.com>


  A short and non-can-of-worms-opening answer to "how should I cite the
lme4 package"? is to use the results of citation(package="lme4").  We
are working toward a couple of submissions for the Journal of
Statistical Software, which we hope to finish soon (!) -- at which point
we will update the package citation information so that
citation(package="lme4") reports those packages ...

  cheers
    Ben Bolker

 On 13-12-09 12:56 PM, Douglas Bates wrote:
> Yesterday Taylor Russ asked
> 
> What it the proper citation for the lme4 package and the Bates' book?
> 
>  Also, can lme4 datasets (e.g., Pastes, ScotsSec, InstEval etc.) be
>  used for illustration in publications?  Can the authors grant
>  permission or is the permission from the source needed?
> 
>  Many thanks for the package and the book.  When can I hold a
> non-digital copy in my hands?
> 
> I inadvertently deleted the message and so must respond without maintaining
> the thread.
> 
> The data sets can be used in other publications.  At least my understanding
> is that the data themselves cannot be copyright (despite the "Microsoft
> Patents 1's, 0's" headline in The Onion many years ago - for those of you
> who don't know that The Onion is a satirical newspaper, that didn't really
> occur).  It is only the representation of the data, such as a table in a
> copyright publication, that can be copyright.  I suppose I should provide
> the usual caveat, "I am (thankfully) not a lawyer".
> 
> The other lme4 authors may be able to respond to the question of citing the
> lme4 package.  I regret to say that I don't know of a good way of citing
> the book and that there won't be non-digital copies.
> 
> Partly this can be attributed to my personality - I'm good at starting
> projects but not so good at finishing them.  However, finishing the book
> would involve spending time maintaining and developing the lme4 package for
> CRAN and I have completely lost my enthusiasm for doing so.
> 
> As many of you know, I am doing most of my work in the Julia language (
> www.julialang.org) now.  R is wonderful and I enjoyed most of my time
> working on R and R packages but there are inherent limitations to R,
> particularly when trying to achieve good performance on fitting complex
> models to large data sets, that make this difficult.  It would be
> attractive to have a "pure R" implementation of mixed-models but I don't
> see a way of making it run quickly and without using a lot of memory.  In
> Julia I can build a package that achieves good performance without the need
> to interface to code written in C, C++ or Fortran - in the sense that my
> package doesn't need to require compilation of code outside of that
> provided by the language itself.
> 
> It is not surprising that the design of R is starting to show its age.
>  Although R has only been around for 15-18 years, its syntax and much of
> the semantics are based on the design of "S3" which is 25-30 years old.
> 
> R packages can include code to be compiled along with the interface code
> and there are many wonderful tools to facilitate this - such as the Rcpp
> package, the devtools package and RStudio support for these packages.  I
> used these in the compiled code underlying lme4_1.0.
> 
> But even though Dirk would describe the use of Rcpp as "seamless", in my
> experience it is not, especially if you wish to have your package available
> on CRAN.
> 
> Maintaining an Rcpp-based package on CRAN these days is a case of "no good
> deed shall go unpunished" and "the flogging will continue until morale
> improves".  I am the maintainer of the RcppEigen package which apparently
> also makes me the maintainer of an Eigen port to Solaris.  When compilers
> on Solaris report errors in code from Eigen I am supposed to fix them.
>  This is difficult in that I don't have access to any computers running
> Solaris, which is a proprietary operating system as far as I can tell, and
> Eigen is a complex code base using what is called "template
> meta-programming" in C++.  Making modifications to such code can be
> difficult.  I can't claim to fully understand all the details in Eigen and
> in Rcpp.  I am a user of these code bases, not a developer. The Eigen
> authors themselves don't test their code under Solaris because they don't
> have access to Solaris systems either and they don't regard Solaris as an
> important platform for numerical computing.  The CRAN maintainers feel
> differently, which puts me in a box.
> 
> There are days when I am tempted to say, "okay, if RcppEigen is not
> suitable for CRAN then remove it" which would result in removal of all the
> packages that depend on it, including lme4.  That may seem childish of me
> but I really don't know what else to do.
> 
> So I have reached the point of saying "goodbye" to R, Rcpp and lme4 and
> switching all of my development effort to Julia.  I'm sorry but others are
> going to need to determine how to maintain lme4 to the satisfaction of the
> CRAN maintainers or whether there should be an alternative distribution
> mechanism for R packages.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Mon Dec  9 22:51:32 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 09 Dec 2013 16:51:32 -0500
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
Message-ID: <52A63B64.5010904@gmail.com>

On 13-12-07 10:50 PM, Egor Ananyev wrote:
> Hello everyone,
> 
> I have a question on how to calculate confidence intervals for predicted
> proportions from a mixed effects logistic model with glmer. It's probably
> very basic, but I'm at my wit's end. Below is a simplified reproducible
> example. I have a single three-level categorical independent variable. The
> method that I use (based on 1.96*SE) doesn't seem to work, because the
> confidence intervals for significantly different effects overlap.
> 
> Here's the output of the code below:
>              Est.   SE     z      P       BSum   ME     BlSum  BuSum
> PSum   PlSum  PuSum
> (Intercept)  2.21   0.60   3.69  <0.001   2.21   1.17   1.04   3.38
> 0.90   0.74   0.97
> vision1     -2.41   0.91  -2.66   0.008  -0.20   1.78  -1.98   1.58
> 0.45   0.12   0.83
> vision2     -1.11   0.97  -1.14   0.253   1.10   1.91  -0.81   3.00
> 0.75   0.31   0.95
> 
> As you can see, (Intercept) and vision1 CIs overlap -- for both cumulative
> (sum) B and the resulting proportions. I killed a few weekends to try to
> solve this problem and couldn't. Your help would be greatly appreciated.
> 
> Thanks,
> --Egor
> 

# preparing the data set:
## file URL: https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv
## inputDir = 'C:/Dropbox/Computer/Eclipse/R/HT/_input/'
library(RCurl)
txt <- getURL("https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv")
ds = read.csv(textConnection(txt),header=TRUE)
ds$subject = as.factor(ds$subject)
ds$vision = as.factor(ds$vision)

# running the model:
library(lme4)
m = glmer(seen ~ vision + (1|subject), data = ds, family = 'binomial')
## better to use accessor methods if possible
msum = as.data.frame(coef(summary(m)))

contrMat <- matrix(c(1,0,0,1,1,0,1,0,1),byrow=TRUE,ncol=3)
msums <- contrMat %*% fixef(m)
# calculating confidence intervals for the estimates:
msum$BSum[1] = msum$Estimate[1]
msum$BSum[2:3] = msum$Estimate[1] + msum$Estimate[2:3]
all.equal(msum$BSum,c(msums))  ## TRUE

## BMB:  I don't know why you expect these calculations to work;
##  the correct calculation is on the variance-covariance matrix
msum$ME = msum$`Std. Error` * 1.96 # margin of error
msum$BlSum = msum$BSum - msum$ME # lower bound on B sum
msum$BuSum = msum$BSum + msum$ME # upper bound on B sum
msum$PSum = plogis(msum$BSum) # predicted probability
msum$PlSum = plogis(msum$BlSum) # lower bound on predicted probability
msum$PuSum = plogis(msum$BuSum) # upper bound on predicted probability

mvcov <- contrMat %*% vcov(m) %*% t(contrMat)
mstderr <- sqrt(diag(mvcov))
mlwr <- msums - 1.96*mstderr
mupr <- msums + 1.96*mstderr
mlwrpred <- plogis(mlwr)
muprpred <- plogis(mupr)

The easier way to do this (which isn't as generalizable
to arbitrary contrasts, but works if all you want to do
is predict values for each level):

m2  <- update(m, . ~ . - 1)  ## take out the intercept
all.equal(unname(fixef(m2)),c(msums), tol=1e-5)  ## TRUE
(cc <- confint(m2,method="Wald"))
all.equal(cbind(mlwr,mupr),unname(cc), tol=2e-5)  ## TRUE

The other thing to notice is that all of these confidence
intervals still **do** overlap.  Taking overlap of 95% confidence intervals
as indicating 95% difference is conservative: try searching for
"95% confidence intervals overlap conservative" on Google scholar ...

For what it's worth most of this question isn't GLMM-specific
or even GLM-specific ...


From mlgentes2 at yahoo.com  Tue Dec 10 02:17:32 2013
From: mlgentes2 at yahoo.com (marieline gentes)
Date: Mon, 9 Dec 2013 17:17:32 -0800 (PST)
Subject: [R-sig-ME] glmer on binomial data with 1 random effect - get p
	values from anova table ?
Message-ID: <1386638252.34251.YahooMailNeo@web160804.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131209/68115cf4/attachment.pl>

From egor.ananyev at gmail.com  Tue Dec 10 02:32:21 2013
From: egor.ananyev at gmail.com (Egor Ananyev)
Date: Tue, 10 Dec 2013 09:32:21 +0800
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <52A63B64.5010904@gmail.com>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
	<52A63B64.5010904@gmail.com>
Message-ID: <CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131210/61749ffa/attachment.pl>

From bbolker at gmail.com  Tue Dec 10 03:36:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 09 Dec 2013 21:36:33 -0500
Subject: [R-sig-ME] glmer on binomial data with 1 random effect - get p
 values from anova table ?
In-Reply-To: <1386638252.34251.YahooMailNeo@web160804.mail.bf1.yahoo.com>
References: <1386638252.34251.YahooMailNeo@web160804.mail.bf1.yahoo.com>
Message-ID: <52A67E31.9070500@gmail.com>

On 13-12-09 08:17 PM, marieline gentes wrote:
> Dear list,
> 
> I'm fairly new with mixed models and just starting to use glmer. I
> have a very basic question, which seems so basic I,m almost
> embarrased to ask.
> 
> I work with habitat use data (summarized binomial data) which I
> fitted in a mixed model of the binomial family with a random factor
> accounting for repeated sampling of the same individual.We simply
> want basic descriptions of the data - effects of sex and year on the
> proportion of time spent in each habitat.
> 
> The code is as follow (for a simple model without interaction):
> 
> Colony.glmerSexYear <- glmer(cbind(ColoYes.allnoF24, ColoNo.allnoF24)
> ~ year.coded + sex + (1| Bague), family=binomial, data=mydata)
> 
> I simply want to report the fact that my predictor 'year'
> (categorical, three levels) is not significant. if I use the anova
> command anova(Colony.glmerSexYear) I get an anova table with degrees
> of freedom and  F values, but no p values
> 
> Analysis of Variance Table Df Sum Sq Mean Sq F value year.coded  2
> 6.8140  3.4070  3.4070 sex         1 9.0351  9.0351  9.0351
> 
> 
> What is the proper way to obtain those missing p values ? or should I
> not use this anova table at all ? I was also suggested to conduct a
> likelyhood ratio test, but I don't have enough statistical background
> (yet) to do this without external help.


  Take a look at the ?pvalues help page in the lme4 package.
  I'm a little surprised that you're getting that particular anova()
table out of lme4 for a glmer() model -- can you give a *little* more
detail about what you're doing?  (If you show the glmer() statement and
the results of sessionInfo(), in particular the versions of packages you
have loaded, that should be enough for now ...)


From pierces1 at msu.edu  Tue Dec 10 14:42:41 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 10 Dec 2013 08:42:41 -0500
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>	<52A63B64.5010904@gmail.com>
	<CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>
Message-ID: <001f01cef5ad$b2d5dab0$18819010$@msu.edu>

Egor,

These papers may give you a start on finding relevant work about how to
interpret CI overlap. 

Cumming, G. (2009). Inference by eye: Reading the overlap of independent
confidence intervals. Statistics in Medicine, 28(2), 205-220. doi:
10.1002/sim.3471

Cumming, G. (2007). Inference by eye: Pictures of confidence intervals and
thinking about levels of confidence. Teaching Statistics, 29, 89-93.

Cumming, G., & Finch, S. (2005). Inference by eye: Confidence intervals and
how to read pictures of data. American Psychologist, 60(2), 170-180. doi:
10.1037/0003-066X.60.2.170


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University
E-mail: pierces1 at msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Egor Ananyev [mailto:egor.ananyev at gmail.com] 
Sent: Monday, December 09, 2013 8:32 PM
To: Ben Bolker
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Probability CIs for Mixed Logistic Regression

Hi Ben,

Thanks a lot! I've since tried to do the same with predict(), but, as you
noted, it doesn't include the function for estimating the standard error (<
https://github.com/lme4/lme4/issues/147>). So I also tried to do this with
a bootstrap method from ez package:

# with ez package (bootstrap):
library(ez)
preds = ezPredict(m, boot = TRUE)
ezPlot2(preds, x=vision)

But the intervals still overlap: <
https://dl.dropboxusercontent.com/u/9147994/ezPlot2.pdf>. I'll try to run
the search and see what I can find about conservative CIs...

Thanks again,
--Egor


On 10 December 2013 05:51, Ben Bolker <bbolker at gmail.com> wrote:

> On 13-12-07 10:50 PM, Egor Ananyev wrote:
> > Hello everyone,
> >
> > I have a question on how to calculate confidence intervals for predicted
> > proportions from a mixed effects logistic model with glmer. It's
probably
> > very basic, but I'm at my wit's end. Below is a simplified reproducible
> > example. I have a single three-level categorical independent variable.
> The
> > method that I use (based on 1.96*SE) doesn't seem to work, because the
> > confidence intervals for significantly different effects overlap.
> >
> > Here's the output of the code below:
> >              Est.   SE     z      P       BSum   ME     BlSum  BuSum
> > PSum   PlSum  PuSum
> > (Intercept)  2.21   0.60   3.69  <0.001   2.21   1.17   1.04   3.38
> > 0.90   0.74   0.97
> > vision1     -2.41   0.91  -2.66   0.008  -0.20   1.78  -1.98   1.58
> > 0.45   0.12   0.83
> > vision2     -1.11   0.97  -1.14   0.253   1.10   1.91  -0.81   3.00
> > 0.75   0.31   0.95
> >
> > As you can see, (Intercept) and vision1 CIs overlap -- for both
> cumulative
> > (sum) B and the resulting proportions. I killed a few weekends to try to
> > solve this problem and couldn't. Your help would be greatly appreciated.
> >
> > Thanks,
> > --Egor
> >
>
> # preparing the data set:
> ## file URL: https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv
> ## inputDir = 'C:/Dropbox/Computer/Eclipse/R/HT/_input/'
> library(RCurl)
> txt <- getURL("https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv")
> ds = read.csv(textConnection(txt),header=TRUE)
> ds$subject = as.factor(ds$subject)
> ds$vision = as.factor(ds$vision)
>
> # running the model:
> library(lme4)
> m = glmer(seen ~ vision + (1|subject), data = ds, family = 'binomial')
> ## better to use accessor methods if possible
> msum = as.data.frame(coef(summary(m)))
>
> contrMat <- matrix(c(1,0,0,1,1,0,1,0,1),byrow=TRUE,ncol=3)
> msums <- contrMat %*% fixef(m)
> # calculating confidence intervals for the estimates:
> msum$BSum[1] = msum$Estimate[1]
> msum$BSum[2:3] = msum$Estimate[1] + msum$Estimate[2:3]
> all.equal(msum$BSum,c(msums))  ## TRUE
>
> ## BMB:  I don't know why you expect these calculations to work;
> ##  the correct calculation is on the variance-covariance matrix
> msum$ME = msum$`Std. Error` * 1.96 # margin of error
> msum$BlSum = msum$BSum - msum$ME # lower bound on B sum
> msum$BuSum = msum$BSum + msum$ME # upper bound on B sum
> msum$PSum = plogis(msum$BSum) # predicted probability
> msum$PlSum = plogis(msum$BlSum) # lower bound on predicted probability
> msum$PuSum = plogis(msum$BuSum) # upper bound on predicted probability
>
> mvcov <- contrMat %*% vcov(m) %*% t(contrMat)
> mstderr <- sqrt(diag(mvcov))
> mlwr <- msums - 1.96*mstderr
> mupr <- msums + 1.96*mstderr
> mlwrpred <- plogis(mlwr)
> muprpred <- plogis(mupr)
>
> The easier way to do this (which isn't as generalizable
> to arbitrary contrasts, but works if all you want to do
> is predict values for each level):
>
> m2  <- update(m, . ~ . - 1)  ## take out the intercept
> all.equal(unname(fixef(m2)),c(msums), tol=1e-5)  ## TRUE
> (cc <- confint(m2,method="Wald"))
> all.equal(cbind(mlwr,mupr),unname(cc), tol=2e-5)  ## TRUE
>
> The other thing to notice is that all of these confidence
> intervals still **do** overlap.  Taking overlap of 95% confidence
intervals
> as indicating 95% difference is conservative: try searching for
> "95% confidence intervals overlap conservative" on Google scholar ...
>
> For what it's worth most of this question isn't GLMM-specific
> or even GLM-specific ...
>

	[[alternative HTML version deleted]]


From kasperdanielhansen at gmail.com  Tue Dec 10 16:00:53 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 10 Dec 2013 10:00:53 -0500
Subject: [R-sig-ME] [Rcpp-devel] Question on lme4 book
In-Reply-To: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
References: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
Message-ID: <CAC2h7us-KmJ3PozwmGWygyeJfwk+dOxen3d+dXBW6EK6faDTnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131210/16e6bf4c/attachment.pl>

From krzysztof.sakrejda at gmail.com  Tue Dec 10 16:20:02 2013
From: krzysztof.sakrejda at gmail.com (Krzysztof Sakrejda)
Date: Tue, 10 Dec 2013 10:20:02 -0500
Subject: [R-sig-ME] [Rcpp-devel] Question on lme4 book
In-Reply-To: <CAC2h7us-KmJ3PozwmGWygyeJfwk+dOxen3d+dXBW6EK6faDTnw@mail.gmail.com>
References: <CAO7JsnQugtx-ZdKWcsg5A2wLJOWSQq+Ssxvd6HimYD48f4Zcyg@mail.gmail.com>
	<CAC2h7us-KmJ3PozwmGWygyeJfwk+dOxen3d+dXBW6EK6faDTnw@mail.gmail.com>
Message-ID: <CAJCSVaAaPrcpxXeZcRSRSqsEWDSXx6oKX6LFiUeYewuQJ2X9bw@mail.gmail.com>

On Tue, Dec 10, 2013 at 10:00 AM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
>  It is basically
> impossible to address these issues without a system.  It would be great if
> someone made a virtual machine with R and everything that I (and others)
> could download and test with.

Isn't that something one could ask the Solaris people for?  It seems
like a common issue with making
their platform more usable w.r.t. R.  I imagine that sort of request
would only work coming from one of
their paying users.

Krzysztof


From sheryn.olson at maine.edu  Wed Dec 11 02:59:48 2013
From: sheryn.olson at maine.edu (Sheryn Olson)
Date: Tue, 10 Dec 2013 20:59:48 -0500
Subject: [R-sig-ME] What is the Correct glmmadmb syntax for random repeated
	measure and block?
Message-ID: <CAATUFefbvYmo=hPppy9BFD_wZpAu1WGdwebYc=xKPbBi7x0dBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131210/6551262c/attachment.pl>

From bbolker at gmail.com  Wed Dec 11 05:02:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Dec 2013 23:02:41 -0500
Subject: [R-sig-ME] What is the Correct glmmadmb syntax for random
 repeated measure and block?
In-Reply-To: <CAATUFefbvYmo=hPppy9BFD_wZpAu1WGdwebYc=xKPbBi7x0dBA@mail.gmail.com>
References: <CAATUFefbvYmo=hPppy9BFD_wZpAu1WGdwebYc=xKPbBi7x0dBA@mail.gmail.com>
Message-ID: <52A7E3E1.6080803@gmail.com>

On 13-12-10 08:59 PM, Sheryn Olson wrote:
> Hello everyone,
> 
> In this model:
> 
> strctr.all <- glmmadmb(pellets ~ season * (totl.splgs + totl.trees +
>                                        pctMidCov + lc +
>                                        cc + BAsplgs + BAtrees) +
>                                        offset(ln.days)+(1|plot/stand)+
> (1|year),
>                                        data=hv, family="nbinom")
> 
> Is (1|plot/stand) correct to mean group=stand ?

  There are two spatial grouping levels here -- it sounds like you
should use stand/plot (i.e., stand and plot within stand).
> 
> Is the repeated measurement correctly addressed with (1|year) ?
> 
> There are 3 repeated measures of summer (2010,2011,2012); 3 of winter
> (years 2011,2012,2013) but the 3 measures per season are a "nuisance"
> source of random variation.   The Season variable Is the fixed variable of
> interest.

  You should probably use Year+(1|Season:Year), i.e. Season and Year are
fixed (Year fixed because there aren't enough years to estimate
among-year-variance reliably).

Each plot is sampled multiple times, right?


> Data structure: 2,184 plot records of pellet counts - the response variable.
> In 26 forest stands were subsampled with 20 summer and 10 winter
> Plots/stand for vegetation metrics. Stands are replicates.
> 
> Thanks much,
> Sheryn
>


From egor.ananyev at gmail.com  Wed Dec 11 06:50:34 2013
From: egor.ananyev at gmail.com (Egor Ananyev)
Date: Wed, 11 Dec 2013 13:50:34 +0800
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <001f01cef5ad$b2d5dab0$18819010$@msu.edu>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
	<52A63B64.5010904@gmail.com>
	<CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>
	<001f01cef5ad$b2d5dab0$18819010$@msu.edu>
Message-ID: <CAOtryJi44jQ8XLrtbADikKYDrHGb7yZOnFz7c1t_MXZNoOtqww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131211/ac8e59c5/attachment.pl>

From chris at trickysolutions.com.au  Wed Dec 11 07:07:27 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Wed, 11 Dec 2013 17:07:27 +1100
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <CAOtryJi44jQ8XLrtbADikKYDrHGb7yZOnFz7c1t_MXZNoOtqww@mail.gmail.com>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
	<52A63B64.5010904@gmail.com>	<CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>
	<001f01cef5ad$b2d5dab0$18819010$@msu.edu>
	<CAOtryJi44jQ8XLrtbADikKYDrHGb7yZOnFz7c1t_MXZNoOtqww@mail.gmail.com>
Message-ID: <c0a15d65948e5eef092ac5f348735c24@mail.gmail.com>

I often use 90% CI's since they give a closer approximation to a 5%
hypothesis test than 95% CI's. It's still conservative but not as much as
using 95% CI's, so there is still overlap when a 5% hypothesis test would
be rejected but not as much. I had a paper that suggested using 90% CI's
for this reasons somewhere but I can?t find it. The best I can do is the
following which gives a more general solution.

Harvey Goldstein; Michael J. R. Healy  (1995) The Graphical Presentation
of a Collection of Means. Journal of the Royal Statistical Society. Series
A (Statistics in Society), Vol. 158, No. 1. (1995), pp. 175-177.



Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(skype) chris.howden
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Egor
Ananyev
Sent: Wednesday, 11 December 2013 4:51 PM
To: Steven J. Pierce
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Probability CIs for Mixed Logistic Regression

Thank you for the recommended readings, Steven!

Cumming (2009) seems to be a proponent of the visual inspection with the
following rule for proportions (which is my case):
"Two independent proportions, 95 per cent CIs: For a comparison of two
independent proportions, two-tailed p </= 0.05 when Proportion Overlap is
about 0.5 or lessin other words the overlap of the 95 per cent CIs is no
more than about half the average arm length, meaning the average of the
two arms that overlap (Figure 3, left panel)."
You don't have to study cognitive psychology to see how this could be a
bit problematic.

But even that advice is only valid for groups more than 10. In my case,
the design is unbalanced, with two groups fewer than 10 (6 and 9). On an
practical level, I wonder if, given the discrepancy between the
probabilities and CIs, we should display 1.5*SE intervals on the estimated
probability plots. This is what Moses (1987) did here <
http://elearning.lsgi.org/GDM/Handouts/Graphical%20Methods%20in%20Statisti
cal%20Analysis.pdf>.
This approach allows easy detection of significant difference "by eye".

What's your opinion on this? I really appreciate all your help with this,
especially given that this is a more general statistics question.

Best,
--Egor


On 10 December 2013 21:42, Steven J. Pierce <pierces1 at msu.edu> wrote:

> Egor,
>
> These papers may give you a start on finding relevant work about how
> to interpret CI overlap.
>
> Cumming, G. (2009). Inference by eye: Reading the overlap of
> independent confidence intervals. Statistics in Medicine, 28(2),
205-220. doi:
> 10.1002/sim.3471
>
> Cumming, G. (2007). Inference by eye: Pictures of confidence intervals
> and thinking about levels of confidence. Teaching Statistics, 29, 89-93.
>
> Cumming, G., & Finch, S. (2005). Inference by eye: Confidence
> intervals and how to read pictures of data. American Psychologist,
60(2), 170-180. doi:
> 10.1037/0003-066X.60.2.170
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT) Michigan State
> University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
>
> -----Original Message-----
> From: Egor Ananyev [mailto:egor.ananyev at gmail.com]
> Sent: Monday, December 09, 2013 8:32 PM
> To: Ben Bolker
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Probability CIs for Mixed Logistic Regression
>
> Hi Ben,
>
> Thanks a lot! I've since tried to do the same with predict(), but, as
> you noted, it doesn't include the function for estimating the standard
> error (< https://github.com/lme4/lme4/issues/147>). So I also tried to
> do this with a bootstrap method from ez package:
>
> # with ez package (bootstrap):
> library(ez)
> preds = ezPredict(m, boot = TRUE)
> ezPlot2(preds, x=vision)
>
> But the intervals still overlap: <
> https://dl.dropboxusercontent.com/u/9147994/ezPlot2.pdf>. I'll try to
> run the search and see what I can find about conservative CIs...
>
> Thanks again,
> --Egor
>
>
> On 10 December 2013 05:51, Ben Bolker <bbolker at gmail.com> wrote:
>
> > On 13-12-07 10:50 PM, Egor Ananyev wrote:
> > > Hello everyone,
> > >
> > > I have a question on how to calculate confidence intervals for
> predicted
> > > proportions from a mixed effects logistic model with glmer. It's
> probably
> > > very basic, but I'm at my wit's end. Below is a simplified
> > > reproducible example. I have a single three-level categorical
independent variable.
> > The
> > > method that I use (based on 1.96*SE) doesn't seem to work, because
> > > the confidence intervals for significantly different effects
overlap.
> > >
> > > Here's the output of the code below:
> > >              Est.   SE     z      P       BSum   ME     BlSum  BuSum
> > > PSum   PlSum  PuSum
> > > (Intercept)  2.21   0.60   3.69  <0.001   2.21   1.17   1.04   3.38
> > > 0.90   0.74   0.97
> > > vision1     -2.41   0.91  -2.66   0.008  -0.20   1.78  -1.98   1.58
> > > 0.45   0.12   0.83
> > > vision2     -1.11   0.97  -1.14   0.253   1.10   1.91  -0.81   3.00
> > > 0.75   0.31   0.95
> > >
> > > As you can see, (Intercept) and vision1 CIs overlap -- for both
> > cumulative
> > > (sum) B and the resulting proportions. I killed a few weekends to
> > > try
> to
> > > solve this problem and couldn't. Your help would be greatly
> appreciated.
> > >
> > > Thanks,
> > > --Egor
> > >
> >
> > # preparing the data set:
> > ## file URL: https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv
> > ## inputDir = 'C:/Dropbox/Computer/Eclipse/R/HT/_input/'
> > library(RCurl)
> > txt <-
> > getURL("https://dl.dropboxusercontent.com/u/9147994/ds_seen.csv")
> > ds = read.csv(textConnection(txt),header=TRUE)
> > ds$subject = as.factor(ds$subject)
> > ds$vision = as.factor(ds$vision)
> >
> > # running the model:
> > library(lme4)
> > m = glmer(seen ~ vision + (1|subject), data = ds, family =
> > 'binomial') ## better to use accessor methods if possible msum =
> > as.data.frame(coef(summary(m)))
> >
> > contrMat <- matrix(c(1,0,0,1,1,0,1,0,1),byrow=TRUE,ncol=3)
> > msums <- contrMat %*% fixef(m)
> > # calculating confidence intervals for the estimates:
> > msum$BSum[1] = msum$Estimate[1]
> > msum$BSum[2:3] = msum$Estimate[1] + msum$Estimate[2:3]
> > all.equal(msum$BSum,c(msums))  ## TRUE
> >
> > ## BMB:  I don't know why you expect these calculations to work; ##
> > the correct calculation is on the variance-covariance matrix msum$ME
> > = msum$`Std. Error` * 1.96 # margin of error msum$BlSum = msum$BSum
> > - msum$ME # lower bound on B sum msum$BuSum = msum$BSum + msum$ME #
> > upper bound on B sum msum$PSum = plogis(msum$BSum) # predicted
> > probability msum$PlSum = plogis(msum$BlSum) # lower bound on
> > predicted probability msum$PuSum = plogis(msum$BuSum) # upper bound
> > on predicted probability
> >
> > mvcov <- contrMat %*% vcov(m) %*% t(contrMat) mstderr <-
> > sqrt(diag(mvcov)) mlwr <- msums - 1.96*mstderr mupr <- msums +
> > 1.96*mstderr mlwrpred <- plogis(mlwr) muprpred <- plogis(mupr)
> >
> > The easier way to do this (which isn't as generalizable to arbitrary
> > contrasts, but works if all you want to do is predict values for
> > each level):
> >
> > m2  <- update(m, . ~ . - 1)  ## take out the intercept
> > all.equal(unname(fixef(m2)),c(msums), tol=1e-5)  ## TRUE (cc <-
> > confint(m2,method="Wald")) all.equal(cbind(mlwr,mupr),unname(cc),
> > tol=2e-5)  ## TRUE
> >
> > The other thing to notice is that all of these confidence intervals
> > still **do** overlap.  Taking overlap of 95% confidence
> intervals
> > as indicating 95% difference is conservative: try searching for "95%
> > confidence intervals overlap conservative" on Google scholar ...
> >
> > For what it's worth most of this question isn't GLMM-specific or
> > even GLM-specific ...
> >
>
>         [[alternative HTML version deleted]]
>
>
>
>

	[[alternative HTML version deleted]]


From mhnunes at fc.ul.pt  Wed Dec 11 14:08:26 2013
From: mhnunes at fc.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Wed, 11 Dec 2013 13:08:26 +0000
Subject: [R-sig-ME] Unable to install the package glmmADMB
Message-ID: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>

Dear all,

I've tried to install the package glmmADMB, but it didn't work. I followed the installation steps of the web page http://glmmadmb.r-forge.r-project.org/, but I've got the  messages reported below. I might stress that I entered into R ( R version 3.0.2) as administrator because I clicked in the option "Run as administrator". What can I do to handle this problem?

Thanks in advanced.

Regards, Helena.

1)
>
> install.packages("glmmADMB", repos="http://r-forge.r-project.org",type="source")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> Warning message:
> package ?glmmADMB? is not available (for R version 3.0.2)
>
> 2) install.packages("glmmADMB",
> +    repos=c("http://glmmadmb.r-forge.r-project.org/repos",  getOption("repos")),type="source")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> also installing the dependency ?R2admb?
>
> trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
> opened URL
> downloaded 609 Kb
>
> trying URL 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.7.7.tar.gz'
> Content type 'application/x-gzip' length 10358095 bytes (9.9 Mb)
> opened URL
> downloaded 9.9 Mb
>
> * installing *source* package 'R2admb' ...
> ** package 'R2admb' successfully unpacked and MD5 sums checked
> Warning in file(file, ifelse(append, "a", "w")) :
>    cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such file or directory
> Error in file(file, ifelse(append, "a", "w")) :
>    cannot open the connection
> ERROR: installing package DESCRIPTION failed for package 'R2admb'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
> ERROR: dependency 'R2admb' is not available for package 'glmmADMB'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/glmmADMB'
>
> The downloaded source packages are in
>          ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpMzOIeU\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/R2admb_0.7.10.tar.gz' had status 1
> 2: In install.packages("glmmADMB", repos = c("http://glmmadmb.r-forge.r-project.org/repos",  :
>    installation of package ?R2admb? had non-zero exit status
> 3: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/glmmADMB_0.7.7.tar.gz' had status 1
> 4: In install.packages("glmmADMB", repos = c("http://glmmadmb.r-forge.r-project.org/repos",  :
>    installation of package ?glmmADMB? had non-zero exit status

From pierces1 at msu.edu  Wed Dec 11 15:07:43 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 11 Dec 2013 09:07:43 -0500
Subject: [R-sig-ME] Probability CIs for Mixed Logistic Regression
In-Reply-To: <CAOtryJi44jQ8XLrtbADikKYDrHGb7yZOnFz7c1t_MXZNoOtqww@mail.gmail.com>
References: <CAOtryJgYM2fGtsPQJv6bj5KSnibvvAhju+vT1mE98DOAAehTUA@mail.gmail.com>
	<52A63B64.5010904@gmail.com>
	<CAOtryJgn=fLGykKno2vbZczrXWKhh-dWzZfSq_ajUX3t4+32Uw@mail.gmail.com>
	<001f01cef5ad$b2d5dab0$18819010$@msu.edu>
	<CAOtryJi44jQ8XLrtbADikKYDrHGb7yZOnFz7c1t_MXZNoOtqww@mail.gmail.com>
Message-ID: <002c01cef67a$5c93b4b0$15bb1e10$@msu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131211/9f9b6d20/attachment.pl>

From Tania.Cerni at unitn.it  Wed Dec 11 15:20:15 2013
From: Tania.Cerni at unitn.it (Cerni, Tania)
Date: Wed, 11 Dec 2013 15:20:15 +0100
Subject: [R-sig-ME] summary vs anova in lmerTest
Message-ID: <06085402EB5F15428D04F536A3BE2C8D02F4B517FC@MBX.unitn.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131211/22e77eef/attachment.pl>

From bbolker at gmail.com  Wed Dec 11 17:35:05 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Dec 2013 11:35:05 -0500
Subject: [R-sig-ME] Unable to install the package glmmADMB
In-Reply-To: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>
References: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>
Message-ID: <52A89439.7040207@gmail.com>

On 13-12-11 08:08 AM, Maria Helena Mourino Silva Nunes wrote:
> Dear all,
> 


> I've tried to install the package glmmADMB, but it didn't work. I
> followed the installation steps of the web page
> http://glmmadmb.r-forge.r-project.org/, but I've got the  messages
> reported below. I might stress that I entered into R ( R version
> 3.0.2) as administrator because I clicked in the option "Run as
> administrator". What can I do to handle this problem?
> 


> Thanks in advanced.
> 
> Regards, Helena.
> 
> 1)
>> 
>> install.packages("glmmADMB",
>> repos="http://r-forge.r-project.org",type="source") Installing
>> package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0? 
>> (as ?lib? is unspecified) Warning message: package ?glmmADMB? is
>> not available (for R version 3.0.2)

  This is more or less as expected, for now -- I have to do some work to
get glmmADMB building on r-forge ...

>> 
>> 2) install.packages("glmmADMB", +
>> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>> getOption("repos")),type="source") Installing package into
>> ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0? (as ?lib? is
>> unspecified) also installing the dependency ?R2admb?
>> 
>> trying URL
>> 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz' 
>> Content type 'application/x-gzip' length 624522 bytes (609 Kb) 
>> opened URL downloaded 609 Kb
>> 
>> trying URL
>> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.7.7.tar.gz'
>>
>> 
>> Content type 'application/x-gzip' length 10358095 bytes (9.9 Mb)
>> opened URL downloaded 9.9 Mb

 So far so good.

>> 
>> * installing *source* package 'R2admb' ... 
>> ** package 'R2admb'
>> successfully unpacked and MD5 sums checked 

  So far so good.

>> Warning in file(file,
>> ifelse(append, "a", "w")) : cannot open file 'C:/Users/Helena
>> Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such
>> file or directory Error in file(file, ifelse(append, "a", "w")) : 
>> cannot open the connection 
>> ERROR: installing package DESCRIPTION
>> failed for package 'R2admb' 

  This is where things go wrong. It's a bit bizarre that the
error message lists the path as

'C:/Users/Helena Mouriqo/Documents/...'

while elsewhere in the output it's listed as

?C:/Users/Helena Mouri?o/Documents/...'

  Based on the error message I'm *guessing* that this is happening in
the read.dcf() function, as called from install.packages(), and that
there's something funny going on with the special character in your file
path getting mangled.

What happens if you just

install.packages("R2admb")

?

Does

install.packages("R2admb",type="source")

give you the same error?  What about

install.packages("plotrix",type="source")?
(this is just picking an arbitrary, harmless package to try)

  What do you get if you type traceback() after you receive the
error above?

  Ben Bolker


>> * removing 'C:/Users/Helena
>> Mouri?o/Documents/R/win-library/3.0/R2admb' ERROR: dependency
>> 'R2admb' is not available for package 'glmmADMB' * removing
>> 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/glmmADMB'
>> 
>> The downloaded source packages are in ?C:\Users\Helena
>> Mouri?o\AppData\Local\Temp\RtmpMzOIeU\downloaded_packages? Warning
>> messages: 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R"
>> CMD INSTALL -l "C:\Users\Helena
>> Mouri?o\Documents\R\win-library\3.0"
>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/R2admb_0.7.10.tar.gz'
>> had status 1 2: In install.packages("glmmADMB", repos =
>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>> package ?R2admb? had non-zero exit status 3: running command
>> '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena
>> Mouri?o\Documents\R\win-library\3.0"
>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/glmmADMB_0.7.7.tar.gz'
>> had status 1 4: In install.packages("glmmADMB", repos =
>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>> package ?glmmADMB? had non-zero exit status
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mhnunes at fc.ul.pt  Wed Dec 11 18:39:20 2013
From: mhnunes at fc.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Wed, 11 Dec 2013 17:39:20 +0000
Subject: [R-sig-ME] Unable to install the package glmmADMB
In-Reply-To: <52A89439.7040207@gmail.com>
References: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>,
	<52A89439.7040207@gmail.com>
Message-ID: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF80@FC-MBXCLUSTER.fc.ul.pt>

Dear Ben,

thanks for your help! The results of your suggestions are the following:

1) The command  "install.packages("R2admb")"  is OK! 

install.packages("R2admb")
Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
trying URL 'http://cran.ma.imperial.ac.uk/bin/windows/contrib/3.0/R2admb_0.7.10.zip'
Content type 'application/zip' length 419933 bytes (410 Kb)
opened URL
downloaded 410 Kb

package ?R2admb? successfully unpacked and MD5 sums checked


2) But.... the computer doesn't like the command  "install.packages("R2admb",type="source")"....... and the same happens with  "install.packages("plotrix",type="source")?"

In both cases, the computer changes the "n tilde" to "q"... and I don't understand why...

Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
Content type 'application/x-gzip' length 624522 bytes (609 Kb)
opened URL
downloaded 609 Kb

* installing *source* package 'R2admb' ...
** package 'R2admb' successfully unpacked and MD5 sums checked
Warning in file(file, ifelse(append, "a", "w")) :
  cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such file or directory
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
ERROR: installing package DESCRIPTION failed for package 'R2admb'
* removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
* restoring previous 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'

The downloaded source packages are in
        ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/R2admb_0.7.10.tar.gz' had status 1 
2: In install.packages("R2admb", type = "source") :
  installation of package ?R2admb? had non-zero exit status


install.packages("plotrix",type="source")
Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/plotrix_3.5-2.tar.gz'
Content type 'application/x-gzip' length 217258 bytes (212 Kb)
opened URL
downloaded 212 Kb

* installing *source* package 'plotrix' ...
** package 'plotrix' successfully unpacked and MD5 sums checked
Warning in file(file, ifelse(append, "a", "w")) :
  cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/plotrix/DESCRIPTION': No such file or directory
Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
ERROR: installing package DESCRIPTION failed for package 'plotrix'
* removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/plotrix'

The downloaded source packages are in
        ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/plotrix_3.5-2.tar.gz' had status 1 
2: In install.packages("plotrix", type = "source") :
  installation of package ?plotrix? had non-zero exit status


Helena.

________________________________________
De: Ben Bolker [bbolker at gmail.com]
Enviado: quarta-feira, 11 de Dezembro de 2013 16:35
Para: Maria Helena Mourino Silva Nunes; r-sig-mixed-models
Assunto: Re: [R-sig-ME] Unable to install the package glmmADMB

On 13-12-11 08:08 AM, Maria Helena Mourino Silva Nunes wrote:
> Dear all,
>


> I've tried to install the package glmmADMB, but it didn't work. I
> followed the installation steps of the web page
> http://glmmadmb.r-forge.r-project.org/, but I've got the  messages
> reported below. I might stress that I entered into R ( R version
> 3.0.2) as administrator because I clicked in the option "Run as
> administrator". What can I do to handle this problem?
>


> Thanks in advanced.
>
> Regards, Helena.
>
> 1)
>>
>> install.packages("glmmADMB",
>> repos="http://r-forge.r-project.org",type="source") Installing
>> package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
>> (as ?lib? is unspecified) Warning message: package ?glmmADMB? is
>> not available (for R version 3.0.2)

  This is more or less as expected, for now -- I have to do some work to
get glmmADMB building on r-forge ...

>>
>> 2) install.packages("glmmADMB", +
>> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>> getOption("repos")),type="source") Installing package into
>> ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0? (as ?lib? is
>> unspecified) also installing the dependency ?R2admb?
>>
>> trying URL
>> 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
>> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
>> opened URL downloaded 609 Kb
>>
>> trying URL
>> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.7.7.tar.gz'
>>
>>
>> Content type 'application/x-gzip' length 10358095 bytes (9.9 Mb)
>> opened URL downloaded 9.9 Mb

 So far so good.

>>
>> * installing *source* package 'R2admb' ...
>> ** package 'R2admb'
>> successfully unpacked and MD5 sums checked

  So far so good.

>> Warning in file(file,
>> ifelse(append, "a", "w")) : cannot open file 'C:/Users/Helena
>> Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such
>> file or directory Error in file(file, ifelse(append, "a", "w")) :
>> cannot open the connection
>> ERROR: installing package DESCRIPTION
>> failed for package 'R2admb'

  This is where things go wrong. It's a bit bizarre that the
error message lists the path as

'C:/Users/Helena Mouriqo/Documents/...'

while elsewhere in the output it's listed as

?C:/Users/Helena Mouri?o/Documents/...'

  Based on the error message I'm *guessing* that this is happening in
the read.dcf() function, as called from install.packages(), and that
there's something funny going on with the special character in your file
path getting mangled.

What happens if you just

install.packages("R2admb")

?

Does

install.packages("R2admb",type="source")

give you the same error?  What about

install.packages("plotrix",type="source")?
(this is just picking an arbitrary, harmless package to try)

  What do you get if you type traceback() after you receive the
error above?

  Ben Bolker


>> * removing 'C:/Users/Helena
>> Mouri?o/Documents/R/win-library/3.0/R2admb' ERROR: dependency
>> 'R2admb' is not available for package 'glmmADMB' * removing
>> 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/glmmADMB'
>>
>> The downloaded source packages are in ?C:\Users\Helena
>> Mouri?o\AppData\Local\Temp\RtmpMzOIeU\downloaded_packages? Warning
>> messages: 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R"
>> CMD INSTALL -l "C:\Users\Helena
>> Mouri?o\Documents\R\win-library\3.0"
>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/R2admb_0.7.10.tar.gz'
>> had status 1 2: In install.packages("glmmADMB", repos =
>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>> package ?R2admb? had non-zero exit status 3: running command
>> '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena
>> Mouri?o\Documents\R\win-library\3.0"
>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/glmmADMB_0.7.7.tar.gz'
>> had status 1 4: In install.packages("glmmADMB", repos =
>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>> package ?glmmADMB? had non-zero exit status
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Wed Dec 11 19:13:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Dec 2013 13:13:18 -0500
Subject: [R-sig-ME] Unable to install the package glmmADMB
In-Reply-To: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF80@FC-MBXCLUSTER.fc.ul.pt>
References: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>,
	<52A89439.7040207@gmail.com>
	<CE9565EEC2A21641A7FF431FBCB78892BE8402DF80@FC-MBXCLUSTER.fc.ul.pt>
Message-ID: <52A8AB3E.6050700@gmail.com>


  My best guess is that this is a bug in R.  However, it's going to be
hard to replicate on someone else's system, which is the prerequisite
for getting it fixed.

  You should actually be able to use

install.packages("glmmADMB",repos="http://glmmadmb.r-forge.r-project.org/repos")

(i.e. you shouldn't need 'type="source"', which is what's causing the
trouble).

  For future reference, can you send the results of sessionInfo()?  This
will include your R version, platform (Windows), and locale information,
which will all be relevant to the problem?

  Ben Bolker


On 13-12-11 12:39 PM, Maria Helena Mourino Silva Nunes wrote:
> Dear Ben,
> 
> thanks for your help! The results of your suggestions are the following:
> 
> 1) The command  "install.packages("R2admb")"  is OK! 
> 
> install.packages("R2admb")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/bin/windows/contrib/3.0/R2admb_0.7.10.zip'
> Content type 'application/zip' length 419933 bytes (410 Kb)
> opened URL
> downloaded 410 Kb
> 
> package ?R2admb? successfully unpacked and MD5 sums checked
> 
> 
> 2) But.... the computer doesn't like the command  "install.packages("R2admb",type="source")"....... and the same happens with  "install.packages("plotrix",type="source")?"
> 
> In both cases, the computer changes the "n tilde" to "q"... and I don't understand why...
> 
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
> opened URL
> downloaded 609 Kb
> 
> * installing *source* package 'R2admb' ...
> ** package 'R2admb' successfully unpacked and MD5 sums checked
> Warning in file(file, ifelse(append, "a", "w")) :
>   cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such file or directory
> Error in file(file, ifelse(append, "a", "w")) : 
>   cannot open the connection
> ERROR: installing package DESCRIPTION failed for package 'R2admb'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
> * restoring previous 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
> 
> The downloaded source packages are in
>         ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/R2admb_0.7.10.tar.gz' had status 1 
> 2: In install.packages("R2admb", type = "source") :
>   installation of package ?R2admb? had non-zero exit status
> 
> 
> install.packages("plotrix",type="source")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/plotrix_3.5-2.tar.gz'
> Content type 'application/x-gzip' length 217258 bytes (212 Kb)
> opened URL
> downloaded 212 Kb
> 
> * installing *source* package 'plotrix' ...
> ** package 'plotrix' successfully unpacked and MD5 sums checked
> Warning in file(file, ifelse(append, "a", "w")) :
>   cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/plotrix/DESCRIPTION': No such file or directory
> Error in file(file, ifelse(append, "a", "w")) : 
>   cannot open the connection
> ERROR: installing package DESCRIPTION failed for package 'plotrix'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/plotrix'
> 
> The downloaded source packages are in
>         ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/plotrix_3.5-2.tar.gz' had status 1 
> 2: In install.packages("plotrix", type = "source") :
>   installation of package ?plotrix? had non-zero exit status
> 
> 
> Helena.
> 
> ________________________________________
> De: Ben Bolker [bbolker at gmail.com]
> Enviado: quarta-feira, 11 de Dezembro de 2013 16:35
> Para: Maria Helena Mourino Silva Nunes; r-sig-mixed-models
> Assunto: Re: [R-sig-ME] Unable to install the package glmmADMB
> 
> On 13-12-11 08:08 AM, Maria Helena Mourino Silva Nunes wrote:
>> Dear all,
>>
> 
> 
>> I've tried to install the package glmmADMB, but it didn't work. I
>> followed the installation steps of the web page
>> http://glmmadmb.r-forge.r-project.org/, but I've got the  messages
>> reported below. I might stress that I entered into R ( R version
>> 3.0.2) as administrator because I clicked in the option "Run as
>> administrator". What can I do to handle this problem?
>>
> 
> 
>> Thanks in advanced.
>>
>> Regards, Helena.
>>
>> 1)
>>>
>>> install.packages("glmmADMB",
>>> repos="http://r-forge.r-project.org",type="source") Installing
>>> package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
>>> (as ?lib? is unspecified) Warning message: package ?glmmADMB? is
>>> not available (for R version 3.0.2)
> 
>   This is more or less as expected, for now -- I have to do some work to
> get glmmADMB building on r-forge ...
> 
>>>
>>> 2) install.packages("glmmADMB", +
>>> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>> getOption("repos")),type="source") Installing package into
>>> ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0? (as ?lib? is
>>> unspecified) also installing the dependency ?R2admb?
>>>
>>> trying URL
>>> 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
>>> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
>>> opened URL downloaded 609 Kb
>>>
>>> trying URL
>>> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.7.7.tar.gz'
>>>
>>>
>>> Content type 'application/x-gzip' length 10358095 bytes (9.9 Mb)
>>> opened URL downloaded 9.9 Mb
> 
>  So far so good.
> 
>>>
>>> * installing *source* package 'R2admb' ...
>>> ** package 'R2admb'
>>> successfully unpacked and MD5 sums checked
> 
>   So far so good.
> 
>>> Warning in file(file,
>>> ifelse(append, "a", "w")) : cannot open file 'C:/Users/Helena
>>> Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such
>>> file or directory Error in file(file, ifelse(append, "a", "w")) :
>>> cannot open the connection
>>> ERROR: installing package DESCRIPTION
>>> failed for package 'R2admb'
> 
>   This is where things go wrong. It's a bit bizarre that the
> error message lists the path as
> 
> 'C:/Users/Helena Mouriqo/Documents/...'
> 
> while elsewhere in the output it's listed as
> 
> ?C:/Users/Helena Mouri?o/Documents/...'
> 
>   Based on the error message I'm *guessing* that this is happening in
> the read.dcf() function, as called from install.packages(), and that
> there's something funny going on with the special character in your file
> path getting mangled.
> 
> What happens if you just
> 
> install.packages("R2admb")
> 
> ?
> 
> Does
> 
> install.packages("R2admb",type="source")
> 
> give you the same error?  What about
> 
> install.packages("plotrix",type="source")?
> (this is just picking an arbitrary, harmless package to try)
> 
>   What do you get if you type traceback() after you receive the
> error above?
> 
>   Ben Bolker
> 
> 
>>> * removing 'C:/Users/Helena
>>> Mouri?o/Documents/R/win-library/3.0/R2admb' ERROR: dependency
>>> 'R2admb' is not available for package 'glmmADMB' * removing
>>> 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/glmmADMB'
>>>
>>> The downloaded source packages are in ?C:\Users\Helena
>>> Mouri?o\AppData\Local\Temp\RtmpMzOIeU\downloaded_packages? Warning
>>> messages: 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R"
>>> CMD INSTALL -l "C:\Users\Helena
>>> Mouri?o\Documents\R\win-library\3.0"
>>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/R2admb_0.7.10.tar.gz'
>>> had status 1 2: In install.packages("glmmADMB", repos =
>>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>>> package ?R2admb? had non-zero exit status 3: running command
>>> '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena
>>> Mouri?o\Documents\R\win-library\3.0"
>>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/glmmADMB_0.7.7.tar.gz'
>>> had status 1 4: In install.packages("glmmADMB", repos =
>>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>>> package ?glmmADMB? had non-zero exit status
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


From chrecapet at gmail.com  Wed Dec 11 19:18:13 2013
From: chrecapet at gmail.com (=?ISO-8859-1?Q?Charlotte_R=E9capet?=)
Date: Wed, 11 Dec 2013 19:18:13 +0100
Subject: [R-sig-ME] Different outputs between two versions of lmerTest
Message-ID: <CABv-bkH792Q9yc9g9gMn9arGQjVBg+Vp8qLx7sKWf84NXJcEdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131211/48852815/attachment.pl>

From achaz.hardenberg at gmail.com  Thu Dec 12 10:27:58 2013
From: achaz.hardenberg at gmail.com (Achaz Hardenberg)
Date: Thu, 12 Dec 2013 10:27:58 +0100
Subject: [R-sig-ME] predictions from MCMCglmm multinomial model
Message-ID: <F7787B82-3289-4F03-B3E7-8BBD9AFD0BCE@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131212/0d84b75f/attachment.pl>

From alku at dtu.dk  Thu Dec 12 15:13:58 2013
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Thu, 12 Dec 2013 14:13:58 +0000
Subject: [R-sig-ME]  summary vs anova in lmerTest
Message-ID: <0566E17B6DEC62459078112371B7508E109B68@ait-pex02mbx05.win.dtu.dk>

Dear Charlotte,

 1) As illustrated in the first part of the script, the new version does not perform the same elimination process as the old one: different elimination and rank and statistics
 I have looked at your example. Thank you for providing a reproducible example. Although I have tested on the lmerTest version 1.2-1 and the results agree with the new version 2.0-3. Which old version did you use?
  
 2) Then, in the new version, the anova function does not give the same statistic and denominator degrees of freedom as the step function for the first eliminated effect.
 WE have been here already - the reason lies in the REML comparing to ML

 3) Eventually, on a smaller dataset, when eliminating one of the two random effects (variance=0), the step function considers the model as fixed-effects only and does not do any effects selection. In the old version, with the same data, I got a selection.
 By default the program eliminates the random effects with 0 component. We will probably add a keep option in order to remain random effect anyways (I am not sure why it did not eliminate in the old version - probably the variance was not 0, as the new lme4 can give slightly different variance estimates comparing to the old one because of some computational changes)

 Again the results seem strange that you gave of the "old" version - as far as I have tested I do not get them. Again which version did you use? Or probably it is somehow related to the R version that you used as well... Also some remark: and probably here lies a reason that you got such results: you need to convert to a factor d$ringf <- as.factor(d$ringf) before you call model and step functions.

Hope that will help,

With regards,
Alexandra

From mhnunes at fc.ul.pt  Thu Dec 12 15:42:41 2013
From: mhnunes at fc.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Thu, 12 Dec 2013 14:42:41 +0000
Subject: [R-sig-ME] Unable to install the package glmmADMB
In-Reply-To: <52A8AB3E.6050700@gmail.com>
References: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF7C@FC-MBXCLUSTER.fc.ul.pt>,
	<52A89439.7040207@gmail.com>
	<CE9565EEC2A21641A7FF431FBCB78892BE8402DF80@FC-MBXCLUSTER.fc.ul.pt>,
	<52A8AB3E.6050700@gmail.com>
Message-ID: <CE9565EEC2A21641A7FF431FBCB78892BE8402DF8A@FC-MBXCLUSTER.fc.ul.pt>

Dear Ben and David,

thank you very much for your answers. I would like to confirm that I have Rtools installed in my computer. I've installed it a few days ago because I've found "similar" problems in the net that were solved by installing the Rtools. Unfortunately, this is not my case...

Here are the results from sessionInfo().

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252  LC_CTYPE=Portuguese_Portugal.1252    LC_MONETARY=Portuguese_Portugal.1252
[4] LC_NUMERIC=C                         LC_TIME=Portuguese_Portugal.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.0.2


Thanks,
Helena.
________________________________________
De: Ben Bolker [bbolker at gmail.com]
Enviado: quarta-feira, 11 de Dezembro de 2013 18:13
Para: Maria Helena Mourino Silva Nunes; r-sig-mixed-models
Assunto: Re: [R-sig-ME] Unable to install the package glmmADMB

  My best guess is that this is a bug in R.  However, it's going to be
hard to replicate on someone else's system, which is the prerequisite
for getting it fixed.

  You should actually be able to use

install.packages("glmmADMB",repos="http://glmmadmb.r-forge.r-project.org/repos")

(i.e. you shouldn't need 'type="source"', which is what's causing the
trouble).

  For future reference, can you send the results of sessionInfo()?  This
will include your R version, platform (Windows), and locale information,
which will all be relevant to the problem?

  Ben Bolker


On 13-12-11 12:39 PM, Maria Helena Mourino Silva Nunes wrote:
> Dear Ben,
>
> thanks for your help! The results of your suggestions are the following:
>
> 1) The command  "install.packages("R2admb")"  is OK!
>
> install.packages("R2admb")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/bin/windows/contrib/3.0/R2admb_0.7.10.zip'
> Content type 'application/zip' length 419933 bytes (410 Kb)
> opened URL
> downloaded 410 Kb
>
> package ?R2admb? successfully unpacked and MD5 sums checked
>
>
> 2) But.... the computer doesn't like the command  "install.packages("R2admb",type="source")"....... and the same happens with  "install.packages("plotrix",type="source")?"
>
> In both cases, the computer changes the "n tilde" to "q"... and I don't understand why...
>
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
> opened URL
> downloaded 609 Kb
>
> * installing *source* package 'R2admb' ...
> ** package 'R2admb' successfully unpacked and MD5 sums checked
> Warning in file(file, ifelse(append, "a", "w")) :
>   cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such file or directory
> Error in file(file, ifelse(append, "a", "w")) :
>   cannot open the connection
> ERROR: installing package DESCRIPTION failed for package 'R2admb'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
> * restoring previous 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/R2admb'
>
> The downloaded source packages are in
>         ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/R2admb_0.7.10.tar.gz' had status 1
> 2: In install.packages("R2admb", type = "source") :
>   installation of package ?R2admb? had non-zero exit status
>
>
> install.packages("plotrix",type="source")
> Installing package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://cran.ma.imperial.ac.uk/src/contrib/plotrix_3.5-2.tar.gz'
> Content type 'application/x-gzip' length 217258 bytes (212 Kb)
> opened URL
> downloaded 212 Kb
>
> * installing *source* package 'plotrix' ...
> ** package 'plotrix' successfully unpacked and MD5 sums checked
> Warning in file(file, ifelse(append, "a", "w")) :
>   cannot open file 'C:/Users/Helena Mouriqo/Documents/R/win-library/3.0/plotrix/DESCRIPTION': No such file or directory
> Error in file(file, ifelse(append, "a", "w")) :
>   cannot open the connection
> ERROR: installing package DESCRIPTION failed for package 'plotrix'
> * removing 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/plotrix'
>
> The downloaded source packages are in
>         ?C:\Users\Helena Mouri?o\AppData\Local\Temp\RtmpQlj4G7\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena Mouri?o\Documents\R\win-library\3.0" C:\Users\HELENA~1\AppData\Local\Temp\RtmpQlj4G7/downloaded_packages/plotrix_3.5-2.tar.gz' had status 1
> 2: In install.packages("plotrix", type = "source") :
>   installation of package ?plotrix? had non-zero exit status
>
>
> Helena.
>
> ________________________________________
> De: Ben Bolker [bbolker at gmail.com]
> Enviado: quarta-feira, 11 de Dezembro de 2013 16:35
> Para: Maria Helena Mourino Silva Nunes; r-sig-mixed-models
> Assunto: Re: [R-sig-ME] Unable to install the package glmmADMB
>
> On 13-12-11 08:08 AM, Maria Helena Mourino Silva Nunes wrote:
>> Dear all,
>>
>
>
>> I've tried to install the package glmmADMB, but it didn't work. I
>> followed the installation steps of the web page
>> http://glmmadmb.r-forge.r-project.org/, but I've got the  messages
>> reported below. I might stress that I entered into R ( R version
>> 3.0.2) as administrator because I clicked in the option "Run as
>> administrator". What can I do to handle this problem?
>>
>
>
>> Thanks in advanced.
>>
>> Regards, Helena.
>>
>> 1)
>>>
>>> install.packages("glmmADMB",
>>> repos="http://r-forge.r-project.org",type="source") Installing
>>> package into ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0?
>>> (as ?lib? is unspecified) Warning message: package ?glmmADMB? is
>>> not available (for R version 3.0.2)
>
>   This is more or less as expected, for now -- I have to do some work to
> get glmmADMB building on r-forge ...
>
>>>
>>> 2) install.packages("glmmADMB", +
>>> repos=c("http://glmmadmb.r-forge.r-project.org/repos",
>>> getOption("repos")),type="source") Installing package into
>>> ?C:/Users/Helena Mouri?o/Documents/R/win-library/3.0? (as ?lib? is
>>> unspecified) also installing the dependency ?R2admb?
>>>
>>> trying URL
>>> 'http://cran.ma.imperial.ac.uk/src/contrib/R2admb_0.7.10.tar.gz'
>>> Content type 'application/x-gzip' length 624522 bytes (609 Kb)
>>> opened URL downloaded 609 Kb
>>>
>>> trying URL
>>> 'http://glmmadmb.r-forge.r-project.org/repos/src/contrib/glmmADMB_0.7.7.tar.gz'
>>>
>>>
>>> Content type 'application/x-gzip' length 10358095 bytes (9.9 Mb)
>>> opened URL downloaded 9.9 Mb
>
>  So far so good.
>
>>>
>>> * installing *source* package 'R2admb' ...
>>> ** package 'R2admb'
>>> successfully unpacked and MD5 sums checked
>
>   So far so good.
>
>>> Warning in file(file,
>>> ifelse(append, "a", "w")) : cannot open file 'C:/Users/Helena
>>> Mouriqo/Documents/R/win-library/3.0/R2admb/DESCRIPTION': No such
>>> file or directory Error in file(file, ifelse(append, "a", "w")) :
>>> cannot open the connection
>>> ERROR: installing package DESCRIPTION
>>> failed for package 'R2admb'
>
>   This is where things go wrong. It's a bit bizarre that the
> error message lists the path as
>
> 'C:/Users/Helena Mouriqo/Documents/...'
>
> while elsewhere in the output it's listed as
>
> ?C:/Users/Helena Mouri?o/Documents/...'
>
>   Based on the error message I'm *guessing* that this is happening in
> the read.dcf() function, as called from install.packages(), and that
> there's something funny going on with the special character in your file
> path getting mangled.
>
> What happens if you just
>
> install.packages("R2admb")
>
> ?
>
> Does
>
> install.packages("R2admb",type="source")
>
> give you the same error?  What about
>
> install.packages("plotrix",type="source")?
> (this is just picking an arbitrary, harmless package to try)
>
>   What do you get if you type traceback() after you receive the
> error above?
>
>   Ben Bolker
>
>
>>> * removing 'C:/Users/Helena
>>> Mouri?o/Documents/R/win-library/3.0/R2admb' ERROR: dependency
>>> 'R2admb' is not available for package 'glmmADMB' * removing
>>> 'C:/Users/Helena Mouri?o/Documents/R/win-library/3.0/glmmADMB'
>>>
>>> The downloaded source packages are in ?C:\Users\Helena
>>> Mouri?o\AppData\Local\Temp\RtmpMzOIeU\downloaded_packages? Warning
>>> messages: 1: running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R"
>>> CMD INSTALL -l "C:\Users\Helena
>>> Mouri?o\Documents\R\win-library\3.0"
>>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/R2admb_0.7.10.tar.gz'
>>> had status 1 2: In install.packages("glmmADMB", repos =
>>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>>> package ?R2admb? had non-zero exit status 3: running command
>>> '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Helena
>>> Mouri?o\Documents\R\win-library\3.0"
>>> C:\Users\HELENA~1\AppData\Local\Temp\RtmpMzOIeU/downloaded_packages/glmmADMB_0.7.7.tar.gz'
>>> had status 1 4: In install.packages("glmmADMB", repos =
>>> c("http://glmmadmb.r-forge.r-project.org/repos",  : installation of
>>> package ?glmmADMB? had non-zero exit status
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


From tghoward at gw.dec.state.ny.us  Thu Dec 12 19:39:04 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Thu, 12 Dec 2013 13:39:04 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
Message-ID: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>

List members - 
I am learning a lot, quickly, but still have a way to go. I would 
greatly appreciate some help with model specification in glmer.
I can't find a good example that parallels what I've got.

My dataset consists of spatially-balanced random samples of rare 
plants within alpine summits. There were two sampling bouts (yr1 and yr2)
with yr2 collected 6 years after yr1. A new set of random plots were 
collected at each bout (e.g. new estimate of the population, not repeated 
measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
 
These are count data with many zeros, fitting a negative binomial distribution.
 
This is what confuses me:  I ALSO have environmental information 
that influences density, such as elevation, solar radiation, slope (and more)
I would like to include these variables in the model, but I am not 
exactly sure how. Based on my reading, this is what I think I have:
 
block random effects: summit
continuous random effects: elev, solrad, slope
fixed effect: time (=samp)
individual random effects to deal with overdisperson: plotID
 
I have over 350 plots for each sample bout, spread among 17 summits.
 
Given this I think my model is:
 
mod <- glmer(count ~ samp + (1|summit) + (1|elev) + (1|solrad) + (1|slope) + (1|pltID), 
       data=dat, family="poisson")
 
My primary questions: 
Is this the appropriate way to handle these environmental variables?
Am I approaching this the right way?
 
###
## To provide a better feel for the structure
## I've created a reproduceable example with dummy data, below.
## ... I've only created one dummy environmental variable...
###
 
library(lme4)
set.seed(5555)
dat.a <- data.frame(pltID = 1001:1100, 
    samp = "yr1", 
    summit = rep(c("sOne","sTwo","sThree","sFour"),c(30, 30, 30, 10)), 
    count = rnbinom(size = 0.06, mu = 19.87, n=100))
dat.b <- data.frame(pltID = 2001:2100, 
    samp = "yr2",
    summit = rep(c("sOne","sTwo","sThree","sFour"),c(33, 28, 34, 5)),
    count = rnbinom(size = 0.06, mu = 20.15, n=100))
dat <- rbind(dat.a, dat.b)
x <- lapply(20+dat$count/2, function(X)rnbinom(size=1,mu=X,n=1))
dat <- cbind(dat, envvar=unlist(x))

mp1 <- glmer(count ~ samp + (1|summit) + (1|envvar) + (1|pltID),
                data = dat, family="poisson")
                
summary(mp1)
##
# end
##

Thank you in advance for any assistance.
Tim


From annajess at gmx.de  Thu Dec 12 10:47:29 2013
From: annajess at gmx.de (Anna-Marie Corman)
Date: Thu, 12 Dec 2013 10:47:29 +0100
Subject: [R-sig-ME] Problems with lme model prediction
Message-ID: <52A98631.9060908@gmx.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131212/1efed7c3/attachment.pl>

From gaelle.damour at cirad.fr  Thu Dec 12 13:02:04 2013
From: gaelle.damour at cirad.fr (=?iso-8859-1?Q?Ga=EBlle_DAMOUR?=)
Date: Thu, 12 Dec 2013 08:02:04 -0400 (AST)
Subject: [R-sig-ME] Errors using GLMM with overdispersed data
Message-ID: <f61c0a13.000009d0.00000009@DAMOUR_GAE-181>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131212/d2b9f551/attachment.pl>

From hans.ekbrand at gmail.com  Fri Dec 13 11:03:29 2013
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Fri, 13 Dec 2013 11:03:29 +0100
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>
References: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>
Message-ID: <20131213100329.GB15352@pc245.socio.gu.se>

On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
> List members - 
> I am learning a lot, quickly, but still have a way to go. I would 
> greatly appreciate some help with model specification in glmer.
> I can't find a good example that parallels what I've got.
> 
> My dataset consists of spatially-balanced random samples of rare 
> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
> with yr2 collected 6 years after yr1. A new set of random plots were 
> collected at each bout (e.g. new estimate of the population, not repeated 
> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
>  
> These are count data with many zeros, fitting a negative binomial distribution.
>  
> This is what confuses me:  I ALSO have environmental information 
> that influences density, such as elevation, solar radiation, slope (and more)
> I would like to include these variables in the model, but I am not 
> exactly sure how. Based on my reading, this is what I think I have:
>  
> block random effects: summit
> continuous random effects: elev, solrad, slope
> fixed effect: time (=samp)
> individual random effects to deal with overdisperson: plotID
>  
> I have over 350 plots for each sample bout, spread among 17 summits.
>  
> Given this I think my model is:
>  
> mod <- glmer(count ~ samp + (1|summit) + (1|elev) + (1|solrad) + (1|slope) + (1|pltID), 
>        data=dat, family="poisson")
>  
> My primary questions: 
> Is this the appropriate way to handle these environmental variables?

>From my limited understanding of these issues, I'd say elev, solrad
and slope should be fixed effects - the are universal in the sense
that they are defined for every (imaginable) case.

If they vary within each summit, you could - in addition to having
them as fixed terms - also include them as random slope terms:
(elev|summit) + (solrad|summit) + (slope|summit), if you want to
explain (some of) the variance between summits.

Since you do not have repeated measures of pltID, you can not include
a random term for pltID - there is no variance within each value of
pltID.

I would model like this 

mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope, data=dat, family="poisson")

And possibly try (but I don't think you have enough data for this)

mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope + (elev|summit) + (solrad|summit) + (slope|summit), data=dat, family="poisson")


From neilandertal at gmail.com  Fri Dec 13 11:12:26 2013
From: neilandertal at gmail.com (Neil Collier)
Date: Fri, 13 Dec 2013 18:12:26 +0800
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <20131213100329.GB15352@pc245.socio.gu.se>
References: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>
	<20131213100329.GB15352@pc245.socio.gu.se>
Message-ID: <CAOVghqoreuLSMsaHQpBL8+mUN87qew3A58N-Xvd=YGrnStddHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131213/e3eb6555/attachment.pl>

From hans.ekbrand at gmail.com  Fri Dec 13 11:14:39 2013
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Fri, 13 Dec 2013 11:14:39 +0100
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>
References: <52A9BC78020000D500B83466@gwsmtp.dec.state.ny.us>
Message-ID: <20131213101439.GC15352@pc245.socio.gu.se>

On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
> List members - 
> I am learning a lot, quickly, but still have a way to go. I would 
> greatly appreciate some help with model specification in glmer.
> I can't find a good example that parallels what I've got.
> 
> My dataset consists of spatially-balanced random samples of rare 
> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
> with yr2 collected 6 years after yr1. A new set of random plots were 
> collected at each bout (e.g. new estimate of the population, not repeated 
> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 

If you only want to test if there is a difference in plant density
between yr1 and yr2, then I don't think you should include the
environmental variables, since difference in the outcome that relates
to changes in the environmental variables between yr1 and yr2 would be
attributed to the enviromental variables and "hide" the actual
differences in outcome between yr1 and yr2.

mod <- glmer(count ~ samp + (1|summit), data = dat, family="poisson")

would be more appropriate, I think.

Inclusions of the envirmental variables should only be done if you
want to explain differences between yr1 and yr2, not for estimating
their size.


From tghoward at gw.dec.state.ny.us  Fri Dec 13 14:29:39 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 13 Dec 2013 08:29:39 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
Message-ID: <52AAC573020000D500B83505@gwsmtp.dec.state.ny.us>

Hans,
Thank you for your reply. Some comments inserted ...

>From: Hans Ekbrand <hans.ekbrand at gmail.com>
>>On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
>> List members - 
>> I am learning a lot, quickly, but still have a way to go. I would 
>> greatly appreciate some help with model specification in glmer.
>> I can't find a good example that parallels what I've got.
>> 
>> My dataset consists of spatially-balanced random samples of rare 
>> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
>> with yr2 collected 6 years after yr1. A new set of random plots were 
>> collected at each bout (e.g. new estimate of the population, not repeated 
>> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
>>  
>> These are count data with many zeros, fitting a negative binomial distribution.
>>  
>> This is what confuses me:  I ALSO have environmental information 
>> that influences density, such as elevation, solar radiation, slope (and more)
>> I would like to include these variables in the model, but I am not 
>> exactly sure how. Based on my reading, this is what I think I have:
>>  
>> block random effects: summit
>> continuous random effects: elev, solrad, slope
>> fixed effect: time (=samp)
>> individual random effects to deal with overdisperson: plotID
>>  
>> I have over 350 plots for each sample bout, spread among 17 summits.
>>  
>> Given this I think my model is:
>>  
>> mod <- glmer(count ~ samp + (1|summit) + (1|elev) + (1|solrad) + (1|slope) + (1|pltID), 
>>        data=dat, family="poisson")
>>  
>> My primary questions: 
>> Is this the appropriate way to handle these environmental variables?
>
>From my limited understanding of these issues, I'd say elev, solrad
>and slope should be fixed effects - the are universal in the sense
>that they are defined for every (imaginable) case.
Ah!  I had been understanding that, since any new point would also most likely 
have a *different* value for these variables, then my samples did not define all the 
possibilities and thus needed to be random effects. 
 
>
>If they vary within each summit, you could - in addition to having
>them as fixed terms - also include them as random slope terms:
>(elev|summit) + (solrad|summit) + (slope|summit), if you want to
>explain (some of) the variance between summits.
>
>Since you do not have repeated measures of pltID, you can not include
>a random term for pltID - there is no variance within each value of
>pltID.
 
Here, I was following earlier discussions about how to deal with overdispersion, such as this one:
 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015867.html
 
A key problem is that I'd rather be using a negative binomial, rather than poisson, to fit these data.

>
>I would model like this 
>
>mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope, data=dat, family="poisson")
>
>And possibly try (but I don't think you have enough data for this)
>
>mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope + (elev|summit) + (solrad|summit) + (slope|summit), data=dat, family="poisson")
>
Thank you! I'll work through these.
Tim

From tghoward at gw.dec.state.ny.us  Fri Dec 13 14:34:32 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 13 Dec 2013 08:34:32 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
Message-ID: <52AAC698020000D500B83509@gwsmtp.dec.state.ny.us>

Neil,
Ok. Thank you. I'll check out glmmADMB as well. 
Tim


>Date: Fri, 13 Dec 2013 18:12:26 +0800
>From: Neil Collier <neilandertal at gmail.com>
>To: Hans Ekbrand <hans.ekbrand at gmail.com>
>Cc: r-sig-mixed-models at r-project.org 
>Subject: Re: [R-sig-ME] model specification for continuous
>	environmental vars
>Message-ID:
>	<CAOVghqoreuLSMsaHQpBL8+mUN87qew3A58N-Xvd=YGrnStddHw at mail.gmail.com>
>Content-Type: text/plain
>
>I agree with Hans. You should probably plot your data to check whether
>these random effects terms might improve model fit.
>
>Also, If the data are zero-inflated inter alia check out the glmmADMB
>package.
>
>Cheers,
>
>Neil
>
>
>On Fri, Dec 13, 2013 at 6:03 PM, Hans Ekbrand <hans.ekbrand at gmail.com>wrote:
>
>> On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
>> > List members -
>> > I am learning a lot, quickly, but still have a way to go. I would
>> > greatly appreciate some help with model specification in glmer.
>> > I can't find a good example that parallels what I've got.
>> >
>> > My dataset consists of spatially-balanced random samples of rare
>> > plants within alpine summits. There were two sampling bouts (yr1 and yr2)
>> > with yr2 collected 6 years after yr1. A new set of random plots were
>> > collected at each bout (e.g. new estimate of the population, not repeated
>> > measures). I would like to test the difference in plant density from yr1
>> to yr2, overall.
>> >
>> > These are count data with many zeros, fitting a negative binomial
>> distribution.
>> >
>> > This is what confuses me:  I ALSO have environmental information
>> > that influences density, such as elevation, solar radiation, slope (and
>> more)
>> > I would like to include these variables in the model, but I am not
>> > exactly sure how. Based on my reading, this is what I think I have:
>> >
>> > block random effects: summit
>> > continuous random effects: elev, solrad, slope
>> > fixed effect: time (=samp)
>> > individual random effects to deal with overdisperson: plotID
>> >
>> > I have over 350 plots for each sample bout, spread among 17 summits.
>> >
>> > Given this I think my model is:
>> >
>> > mod <- glmer(count ~ samp + (1|summit) + (1|elev) + (1|solrad) +
>> (1|slope) + (1|pltID),
>> >        data=dat, family="poisson")
>> >
>> > My primary questions:
>> > Is this the appropriate way to handle these environmental variables?
>>
>> >From my limited understanding of these issues, I'd say elev, solrad
>> and slope should be fixed effects - the are universal in the sense
>> that they are defined for every (imaginable) case.
>>
>> If they vary within each summit, you could - in addition to having
>> them as fixed terms - also include them as random slope terms:
>> (elev|summit) + (solrad|summit) + (slope|summit), if you want to
>> explain (some of) the variance between summits.
>>
>> Since you do not have repeated measures of pltID, you can not include
>> a random term for pltID - there is no variance within each value of
>> pltID.
>>
>> I would model like this
>>
>> mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope, data=dat,
>> family="poisson")
>>
>> And possibly try (but I don't think you have enough data for this)
>>
>> mod <- glmer(count ~ samp + (1|summit) + elev + solrad + slope +
>> (elev|summit) + (solrad|summit) + (slope|summit), data=dat,
>> family="poisson")
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>


From tghoward at gw.dec.state.ny.us  Fri Dec 13 14:40:55 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 13 Dec 2013 08:40:55 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
Message-ID: <52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>


>Date: Fri, 13 Dec 2013 11:14:39 +0100
>From: Hans Ekbrand <hans.ekbrand at gmail.com>
>To: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] model specification for continuous
>environmental vars
>Message-ID: <20131213101439.GC15352 at pc245.socio.gu.se>
>Content-Type: text/plain; charset=us-ascii
>
>On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
>> List members - 
>> I am learning a lot, quickly, but still have a way to go. I would 
>> greatly appreciate some help with model specification in glmer.
>> I can't find a good example that parallels what I've got.
>> 
>> My dataset consists of spatially-balanced random samples of rare 
>> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
>> with yr2 collected 6 years after yr1. A new set of random plots were 
>> collected at each bout (e.g. new estimate of the population, not repeated 
>> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
>
>If you only want to test if there is a difference in plant density
>between yr1 and yr2, then I don't think you should include the
>environmental variables, since difference in the outcome that relates
>to changes in the environmental variables between yr1 and yr2 would be
>attributed to the enviromental variables and "hide" the actual
>differences in outcome between yr1 and yr2.
>
>mod <- glmer(count ~ samp + (1|summit), data = dat, family="poisson")
>
>would be more appropriate, I think.
>
>Inclusions of the envirmental variables should only be done if you
>want to explain differences between yr1 and yr2, not for estimating
>their size.
These are good points. My reasoning was that I need to control for these
variables somehow. What if I have higher densities in yr2 but it is completely 
due to sampling -- that my plots happened to be at elevations where there are
higher densities? I want to remove the effect of differences in elevation when 
testing for the differences between yr1 and yr2. 
 
Thank you for the feedback!
Best, 
Tim
 
 
 

From hans.ekbrand at gmail.com  Fri Dec 13 18:42:17 2013
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Fri, 13 Dec 2013 18:42:17 +0100
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
	<52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>
Message-ID: <20131213174217.GA20488@vardagsrummet>

On Fri, Dec 13, 2013 at 08:40:55AM -0500, Tim Howard wrote:
> >From: Hans Ekbrand <hans.ekbrand at gmail.com>
> >On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
> >> List members - 
> >> I am learning a lot, quickly, but still have a way to go. I would 
> >> greatly appreciate some help with model specification in glmer.
> >> I can't find a good example that parallels what I've got.
> >> 
> >> My dataset consists of spatially-balanced random samples of rare 
> >> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
> >> with yr2 collected 6 years after yr1. A new set of random plots were 
> >> collected at each bout (e.g. new estimate of the population, not repeated 
> >> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
> >
> >If you only want to test if there is a difference in plant density
> >between yr1 and yr2, then I don't think you should include the
> >environmental variables, since difference in the outcome that relates
> >to changes in the environmental variables between yr1 and yr2 would be
> >attributed to the enviromental variables and "hide" the actual
> >differences in outcome between yr1 and yr2.
> >
> >mod <- glmer(count ~ samp + (1|summit), data = dat, family="poisson")
> >
> >would be more appropriate, I think.
> >
> >Inclusions of the envirmental variables should only be done if you
> >want to explain differences between yr1 and yr2, not for estimating
> >their size.
> These are good points. My reasoning was that I need to control for these
> variables somehow. What if I have higher densities in yr2 but it is completely 
> due to sampling -- that my plots happened to be at elevations where there are
> higher densities? I want to remove the effect of differences in elevation when 
> testing for the differences between yr1 and yr2. 

OK, I thought about real changes between yr1 and yr2, not artifacts
due to sampling. elevation and slope does not vary over time, but
solar radiation could vary over time, I guess.

If your research question is about changes over time, then why did you
change the sampled areas between the measure points?


From tghoward at gw.dec.state.ny.us  Fri Dec 13 19:02:40 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 13 Dec 2013 13:02:40 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <20131213174217.GA20488@vardagsrummet>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
	<52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>
	<20131213174217.GA20488@vardagsrummet>
Message-ID: <52AB0570020000D500B835BE@gwsmtp.dec.state.ny.us>


>>>> Hans Ekbrand <hans.ekbrand at gmail.com> 12/13/2013 12:42 PM >>>
>On Fri, Dec 13, 2013 at 08:40:55AM -0500, Tim Howard wrote:
>> >From: Hans Ekbrand <hans.ekbrand at gmail.com>
>> >On Thu, Dec 12, 2013 at 01:39:04PM -0500, Tim Howard wrote:
>> >> List members - 
>> >> I am learning a lot, quickly, but still have a way to go. I would 
>> >> greatly appreciate some help with model specification in glmer.
>> >> I can't find a good example that parallels what I've got.
>> >> 
>> >> My dataset consists of spatially-balanced random samples of rare 
>> >> plants within alpine summits. There were two sampling bouts (yr1 and yr2)
>> >> with yr2 collected 6 years after yr1. A new set of random plots were 
>> >> collected at each bout (e.g. new estimate of the population, not repeated 
>> >> measures). I would like to test the difference in plant density from yr1 to yr2, overall. 
>> >
>> >If you only want to test if there is a difference in plant density
>> >between yr1 and yr2, then I don't think you should include the
>> >environmental variables, since difference in the outcome that relates
>> >to changes in the environmental variables between yr1 and yr2 would be
>> >attributed to the enviromental variables and "hide" the actual
>> >differences in outcome between yr1 and yr2.
>> >
>> >mod <- glmer(count ~ samp + (1|summit), data = dat, family="poisson")
>> >
>> >would be more appropriate, I think.
>> >
>> >Inclusions of the envirmental variables should only be done if you
>> >want to explain differences between yr1 and yr2, not for estimating
>> >their size.
>> These are good points. My reasoning was that I need to control for these
>> variables somehow. What if I have higher densities in yr2 but it is completely 
>> due to sampling -- that my plots happened to be at elevations where there are
>> higher densities? I want to remove the effect of differences in elevation when 
>> testing for the differences between yr1 and yr2. 
>
>OK, I thought about real changes between yr1 and yr2, not artifacts
>due to sampling. elevation and slope does not vary over time, but
>solar radiation could vary over time, I guess.
>
>If your research question is about changes over time, then why did you
>change the sampled areas between the measure points?
 
I am following the idea of Probabilistic Survey designs championed by USEPA (authors
are primarily Kincaid and Olsen, randomization method is GRTS using R package spsurvey). The main
idea is that you get an estimate of the target population through a random sample at T1 and then 
another estimate of the population through a separate random sample at T2. 
 
http://www.epa.gov/nheerl/arm/designpages/monitdesign/survey_overview.htm 
 
Perhaps that was a bad idea! :)  But, it actually would have been VERY 
hard to visit the exact same locations again and again so this approach does 
make sense in this context. 
 
Best, 
Tim
 
 


From seth at swbigelow.net  Fri Dec 13 20:36:04 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Fri, 13 Dec 2013 14:36:04 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <52AB0570020000D500B835BE@gwsmtp.dec.state.ny.us>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>	<52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>	<20131213174217.GA20488@vardagsrummet>
	<52AB0570020000D500B835BE@gwsmtp.dec.state.ny.us>
Message-ID: <000c01cef83a$93e60500$bbb20f00$@net>

Re: the plant count & summits discussion:
 
-I've had good results with glmmadmb & negative binomial distribution,
though the zero-inflation addition has not worked, probably because of a
small dataset.

- Is slope incorporated into the calculation of solar radiation? If so it
might be feasible to drop one of these terms to simplify the model

- There may be a quadratic relationship with elevation and plant count, it
would be wise to test for this (e.g., make models with and without quadratic
elevation term and use <- anova(linearmodel, quadraticmodel) to test.

- the David Atkins et al. tutorial on count regression, often mentioned on
this list, is highly recommended 

- one way of putting the questions would be, 'does the relationship between
plant count and elevation change from the first survey to the second?
Syntax:

glmmadmb(count~sample*elevation + solar.radiation + (1|summit), data=dat,
family="nbinom", zeroInflation=TRUE) 

...and test this vs. the no-interaction model.

--Seth 


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tim Howard
Sent: Friday, December 13, 2013 1:03 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] model specification for continuous environmental
vars


>>>> Hans Ekbrand <hans.ekbrand at gmail.com> 12/13/2013 12:42 PM >>>
>On Fri, Dec 13, 2013 at 08:40:55AM -0500, Tim Howard wrote:
>> >From: Hans Ekbrand <hans.ekbrand at gmail.com> On Thu, Dec 12, 2013 at 
>> >01:39:04PM -0500, Tim Howard wrote:
>> >> List members -
>> >> I am learning a lot, quickly, but still have a way to go. I would 
>> >> greatly appreciate some help with model specification in glmer.
>> >> I can't find a good example that parallels what I've got.
>> >> 
>> >> My dataset consists of spatially-balanced random samples of rare 
>> >> plants within alpine summits. There were two sampling bouts (yr1 
>> >> and yr2) with yr2 collected 6 years after yr1. A new set of random 
>> >> plots were collected at each bout (e.g. new estimate of the 
>> >> population, not repeated measures). I would like to test the
difference in plant density from yr1 to yr2, overall.
>> >
>> >If you only want to test if there is a difference in plant density 
>> >between yr1 and yr2, then I don't think you should include the 
>> >environmental variables, since difference in the outcome that 
>> >relates to changes in the environmental variables between yr1 and 
>> >yr2 would be attributed to the enviromental variables and "hide" the 
>> >actual differences in outcome between yr1 and yr2.
>> >
>> >mod <- glmer(count ~ samp + (1|summit), data = dat, 
>> >family="poisson")
>> >
>> >would be more appropriate, I think.
>> >
>> >Inclusions of the envirmental variables should only be done if you 
>> >want to explain differences between yr1 and yr2, not for estimating 
>> >their size.
>> These are good points. My reasoning was that I need to control for 
>> these variables somehow. What if I have higher densities in yr2 but 
>> it is completely due to sampling -- that my plots happened to be at 
>> elevations where there are higher densities? I want to remove the 
>> effect of differences in elevation when testing for the differences
between yr1 and yr2.
>
>OK, I thought about real changes between yr1 and yr2, not artifacts due 
>to sampling. elevation and slope does not vary over time, but solar 
>radiation could vary over time, I guess.
>
>If your research question is about changes over time, then why did you 
>change the sampled areas between the measure points?
 
I am following the idea of Probabilistic Survey designs championed by USEPA
(authors are primarily Kincaid and Olsen, randomization method is GRTS using
R package spsurvey). The main idea is that you get an estimate of the target
population through a random sample at T1 and then another estimate of the
population through a separate random sample at T2. 
 
http://www.epa.gov/nheerl/arm/designpages/monitdesign/survey_overview.htm 
 
Perhaps that was a bad idea! :)  But, it actually would have been VERY hard
to visit the exact same locations again and again so this approach does make
sense in this context. 
 
Best,
Tim
 
 

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tghoward at gw.dec.state.ny.us  Fri Dec 13 21:18:26 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 13 Dec 2013 15:18:26 -0500
Subject: [R-sig-ME] model specification for continuous environmental vars
In-Reply-To: <000c01cef83a$93e60500$bbb20f00$@net>
References: <mailman.3.1386932402.8862.r-sig-mixed-models@r-project.org>
	<52AAC817020000D500B83519@gwsmtp.dec.state.ny.us>
	<20131213174217.GA20488@vardagsrummet>
	<52AB0570020000D500B835BE@gwsmtp.dec.state.ny.us>
	<000c01cef83a$93e60500$bbb20f00$@net>
Message-ID: <52AB2542020000D500B83600@gwsmtp.dec.state.ny.us>

Seth,
Thank you for the pointers and help. I've found the Atkins et al. tutorial and 
will go through it. 
 
Based on the earlier responses, I'm finding success with glmmadmb as 
well so I'm glad you are indicating the same. I'll continue down that path. 
 
Your question to test and model specification with the anova test also helps, thanks!
 
Tim

>>> "Seth Bigelow" <seth at swbigelow.net> 12/13/2013 2:36 PM >>>
Re: the plant count & summits discussion:

-I've had good results with glmmadmb & negative binomial distribution,
though the zero-inflation addition has not worked, probably because of a
small dataset.

- Is slope incorporated into the calculation of solar radiation? If so it
might be feasible to drop one of these terms to simplify the model

- There may be a quadratic relationship with elevation and plant count, it
would be wise to test for this (e.g., make models with and without quadratic
elevation term and use <- anova(linearmodel, quadraticmodel) to test.

- the David Atkins et al. tutorial on count regression, often mentioned on
this list, is highly recommended 

- one way of putting the questions would be, 'does the relationship between
plant count and elevation change from the first survey to the second?
Syntax:

glmmadmb(count~sample*elevation + solar.radiation + (1|summit), data=dat,
family="nbinom", zeroInflation=TRUE) 

...and test this vs. the no-interaction model.

--Seth 


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tim Howard
Sent: Friday, December 13, 2013 1:03 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] model specification for continuous environmental
vars


>>>> Hans Ekbrand <hans.ekbrand at gmail.com> 12/13/2013 12:42 PM >>>
>On Fri, Dec 13, 2013 at 08:40:55AM -0500, Tim Howard wrote:
>> >From: Hans Ekbrand <hans.ekbrand at gmail.com> On Thu, Dec 12, 2013 at 
>> >01:39:04PM -0500, Tim Howard wrote:
>> >> List members -
>> >> I am learning a lot, quickly, but still have a way to go. I would 
>> >> greatly appreciate some help with model specification in glmer.
>> >> I can't find a good example that parallels what I've got.
>> >> 
>> >> My dataset consists of spatially-balanced random samples of rare 
>> >> plants within alpine summits. There were two sampling bouts (yr1 
>> >> and yr2) with yr2 collected 6 years after yr1. A new set of random 
>> >> plots were collected at each bout (e.g. new estimate of the 
>> >> population, not repeated measures). I would like to test the
difference in plant density from yr1 to yr2, overall.
>> >
>> >If you only want to test if there is a difference in plant density 
>> >between yr1 and yr2, then I don't think you should include the 
>> >environmental variables, since difference in the outcome that 
>> >relates to changes in the environmental variables between yr1 and 
>> >yr2 would be attributed to the enviromental variables and "hide" the 
>> >actual differences in outcome between yr1 and yr2.
>> >
>> >mod <- glmer(count ~ samp + (1|summit), data = dat, 
>> >family="poisson")
>> >
>> >would be more appropriate, I think.
>> >
>> >Inclusions of the envirmental variables should only be done if you 
>> >want to explain differences between yr1 and yr2, not for estimating 
>> >their size.
>> These are good points. My reasoning was that I need to control for 
>> these variables somehow. What if I have higher densities in yr2 but 
>> it is completely due to sampling -- that my plots happened to be at 
>> elevations where there are higher densities? I want to remove the 
>> effect of differences in elevation when testing for the differences
between yr1 and yr2.
>
>OK, I thought about real changes between yr1 and yr2, not artifacts due 
>to sampling. elevation and slope does not vary over time, but solar 
>radiation could vary over time, I guess.
>
>If your research question is about changes over time, then why did you 
>change the sampled areas between the measure points?

I am following the idea of Probabilistic Survey designs championed by USEPA
(authors are primarily Kincaid and Olsen, randomization method is GRTS using
R package spsurvey). The main idea is that you get an estimate of the target
population through a random sample at T1 and then another estimate of the
population through a separate random sample at T2. 

http://www.epa.gov/nheerl/arm/designpages/monitdesign/survey_overview.htm 

Perhaps that was a bad idea! :)  But, it actually would have been VERY hard
to visit the exact same locations again and again so this approach does make
sense in this context. 

Best,
Tim



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pauljohn32 at gmail.com  Sun Dec 15 19:57:53 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 15 Dec 2013 12:57:53 -0600
Subject: [R-sig-ME] 4 pre measurements, 2 post measurements. Ideas?
Message-ID: <CAErODj9LH-z9SbEAQZVWseS_U-dZ=5E8daUZWVB_KkbJcWeA1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131215/42b0cafe/attachment.pl>

From jwiley.psych at gmail.com  Sun Dec 15 22:36:55 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 15 Dec 2013 13:36:55 -0800
Subject: [R-sig-ME] 4 pre measurements, 2 post measurements. Ideas?
In-Reply-To: <CAErODj9LH-z9SbEAQZVWseS_U-dZ=5E8daUZWVB_KkbJcWeA1A@mail.gmail.com>
References: <CAErODj9LH-z9SbEAQZVWseS_U-dZ=5E8daUZWVB_KkbJcWeA1A@mail.gmail.com>
Message-ID: <CANz9Z_+mPXj0CRb8AojTtUgP2HKhye_Lwyf79x07vb6==9N_3A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131215/b6cdaddd/attachment.pl>

From bbolker at gmail.com  Mon Dec 16 14:50:09 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 16 Dec 2013 08:50:09 -0500
Subject: [R-sig-ME] Why no "dataClasses" attribute at terms for lmer
	object
In-Reply-To: <B3CA8FF72715FD47967BD311CCC4DAF74E9345A2@invexcpv01.agresearch.co.nz>
References: <B3CA8FF72715FD47967BD311CCC4DAF74E9345A2@invexcpv01.agresearch.co.nz>
Message-ID: <52AF0511.9080409@gmail.com>

On 13-12-15 08:51 PM, Luo, Dongwen wrote:
> Dear Sir,
> 
> 
> 
> I have written a package depends on lme4, in some of my functions
> need info about which term in the model is numeric (or factor) .
> Usually, we can get it by using
> 
> attr(terms(lmer), ?dataClasses?)
> 
> However, now in lme4 this attribute is disappear, anyway I could
> find the info?
> 

  This workaround might help you in the short term, although there are
lots of situations where it will be fragile/won't work properly:

sapply(all.vars(formula(fm1)),function(x) class(model.frame(fm1)[[x]]))
##  Reaction      Days   Subject
## "numeric" "numeric"  "factor"

 (you can use fixed.only=TRUE in formula() if you want to exclude the
random effects variables from the list).

  In the medium/long term, we can look into what is going on here: I've
opened https://github.com/lme4/lme4/issues/160



> 
> 
> Best regards
> 
> 
> 
> Dongwen Luo Statistician T +64 6 351 8139 F +64 6 351 8032 E
> dongwen.luo at agresearch.co.nz <mailto:dongwen.luo at agresearch.co.nz>
> 
> Grasslands Research Centre Tennent Drive, Private Bag 11008,
> Palmerston North 4442, New Zealand T  +64 6 356 8019  F  +64 6 351
> 8032  www.agresearch.co.nz <http://www.agresearch.co.nz>
> 
> 
> 
> =======================================================================
>
> 
Attention: The information contained in this message and...{{dropped:10}}


From bagchi.r at gmail.com  Mon Dec 16 15:35:00 2013
From: bagchi.r at gmail.com (robert bagchi)
Date: Mon, 16 Dec 2013 15:35:00 +0100
Subject: [R-sig-ME] Negative log-likelihood-ratios in parametric bootstrap
Message-ID: <CAFJ9WUAuXs3aKKcQ=SUQVdmHH_15Wht0TzLP+Bba47qvS3AnEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131216/96b6ce4e/attachment.pl>

From stgries at gmail.com  Tue Dec 17 03:21:40 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Mon, 16 Dec 2013 18:21:40 -0800
Subject: [R-sig-ME] Syntax for nested random effects
Message-ID: <CAFrBz2msYyrPn3KjBm8qDzvFk9gMWp_hS9dq_U--H=pg66R9Jg@mail.gmail.com>

Hi all

I have some questions regarding how to handle nested effects, which
are related to an earlier one but may be more concise. I hope these
are not too basic but I did look in several places incl. the draft
version of Bates (2010), Crawley (2013), Faraway (2006), and this
discussion <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000313.html>.

I am fitting a binomial glmer with some fixed effects (say, a and b)
and some random effects (say, x, y, q, w, and e). Now, the random
effects have the following structure:
- the random effect y is nested into x;
- the random effect e is nested into w, which in turn is nested u

Thus, I thought the formula has to look like this:
m1a <- glmer(Y ~ a + b + (1|x/y) + (1|q/w/e))

## Question 1a: Is that correct?
## Question 1b: following Bates (2010:42) (and Crawley (2013:692), I
should also be able to say this:

m1b <- glmer(Y ~ a + b + (1|x) + (1|y) + (1|q) + (1|w) + (1|e))

However, while the results for the fixed effects differ only just a
bit, the results for the random effects are very different:

> summary(m1a)[[13]]
 Groups                  Name        Std.Dev.
 e:(w:q) (Intercept) 1.082242
 y:x             (Intercept) 0.020518
 x                   (Intercept) 0.016475
 w:q            (Intercept) 0.021113
 q                    (Intercept) 0.435931
> summary(m1b)[[13]]
 Groups   Name        Std.Dev.
 e (Intercept) 1.0906344
 y    (Intercept) 0.0090171
 x    (Intercept) 0.0148924
 w  (Intercept) 0.0034299
 q     (Intercept) 0.4336554

## Question 2a: If I now want to see whether, say, the level of
resolution/granularity e is needed or not, can I do that as follows?
m2 <- glmer(Y ~ a + b + (1|x/y) + 1(q/w))
anova(m1a, m2, test="Chisq")

## Question 2b: If I now want to see whether, say, the level of
resolution/granularity w is needed or not, can I do that as follows?
q_w <- interaction(q,w)
m3 <- glmer(Y ~ a + b + (1|x/y) + 1(q_w/e))

Any input would be much appreciated
STG


From bates at stat.wisc.edu  Tue Dec 17 18:57:59 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 17 Dec 2013 11:57:59 -0600
Subject: [R-sig-ME] Need a help for glmer use.
In-Reply-To: <957590BA0FEB064FBE99521277B3B862328CEBBB9D@EXCHMBX1.chu-lyon.fr>
References: <957590BA0FEB064FBE99521277B3B862328CEBBB9D@EXCHMBX1.chu-lyon.fr>
Message-ID: <CAO7JsnRX9tG8urTikSBV=jcECsjAv6WqxM7FRO4wfaF9SAFFJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131217/50dea97f/attachment.pl>

From bbolker at gmail.com  Tue Dec 17 21:59:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Dec 2013 15:59:07 -0500
Subject: [R-sig-ME] Need a help for glmer use.
In-Reply-To: <CAO7JsnRX9tG8urTikSBV=jcECsjAv6WqxM7FRO4wfaF9SAFFJA@mail.gmail.com>
References: <957590BA0FEB064FBE99521277B3B862328CEBBB9D@EXCHMBX1.chu-lyon.fr>
	<CAO7JsnRX9tG8urTikSBV=jcECsjAv6WqxM7FRO4wfaF9SAFFJA@mail.gmail.com>
Message-ID: <52B0BB1B.5060409@gmail.com>


  If you google "'what' must be a character string or a function" you get

http://stackoverflow.com/questions/19801070/error-message-in-lme4glmer-what-must-be-a-character-string-or-a-function

as the first hit, which explains that this is a bug in lme4, fixed in
the development version of lme4, and that there is a very simple
workaround: delete any variable called 'new' in your workspace.

  sincerely
    Ben Bolker


On 13-12-17 12:57 PM, Douglas Bates wrote:
> Generally it is best to send questions like this to the
> R-SIG-Mixed-Models at R-project.org mailing list (see instructions at
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models).  Many of
> those who read that list can reply and often much faster than I am
> able to.
> 
> 
> 
> On Tue, Dec 17, 2013 at 10:30 AM, <olayide.boussari at chu-lyon.fr> wrote:
> 
>> Dear Bates,
>> I try to use the function glmer to perform a GLMM but it not run.I face
>> the same problem even when I try with an example in the lme4 package. It
>> return me an error message as shown in the following lines. Is their
>> something to do? I am using R version 3.0.2.
>>
>>> glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),data =
>> cbpp, family = "binomial")
>> Error in do.call(new, c(list(Class = "glmResp", family = family),
>> ll[setdiff(names(ll),  :
>>   'what' must be a character string or a function
>>
>>
>> Best regard
>>
>> Olayide Boussari
>> PhD student, Biostatistics
>> Universit? Claude Bernard Lyon 1, FRANCE
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From t.h.ergon at ibv.uio.no  Wed Dec 18 19:28:03 2013
From: t.h.ergon at ibv.uio.no (=?ISO-8859-1?Q?Torbj=F8rn_Ergon?=)
Date: Wed, 18 Dec 2013 19:28:03 +0100
Subject: [R-sig-ME] Parametrization of the beta-binomial model in glmmadmb
	{glmmADMB}
In-Reply-To: <4D31AABF.2080709@gmail.com>
References: <4D31AABF.2080709@gmail.com>
Message-ID: <52B1E933.9060408@ibv.uio.no>

Dear list,

I want to do some simulation based goodness-of-fit assessment of a 
(zero-inflated) beta-binomial model fitted with glmmadmb, but I realize 
I don't quite understand how this model is parameterized.

I understand that the linear predictor is 
inverse-logit(alfa/(alpha+beta)) where alpha and beta are the parameters 
of the beta-distribution (right?). But what is the exact definition of 
"Beta-binomial dispersion parameter" (fit.glmmadmb$alpha) expressed in 
terms of the parameters of the beta distribution (alpha and beta)?

Cheers,

Torbj?rn Ergon
University of Oslo


From lowrey.blake at gmail.com  Wed Dec 18 22:54:59 2013
From: lowrey.blake at gmail.com (Blake Lowrey)
Date: Wed, 18 Dec 2013 13:54:59 -0800
Subject: [R-sig-ME] k-fold cross validation for S4 class model object
Message-ID: <52b219b7.e68e420a.6720.6ad9@mx.google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131218/1b5ed74c/attachment.pl>

From richard.asturia at gmail.com  Wed Dec 18 23:46:24 2013
From: richard.asturia at gmail.com (Richard Asturia)
Date: Wed, 18 Dec 2013 16:46:24 -0600
Subject: [R-sig-ME] Yet another question on CIs for coef(model) extracted
	conditional coefficients
Message-ID: <CA+xNL7pxrr=YuHbm7H539MR+ZnA6f7+sgJ=ihf-_EQcDW0CdkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131218/ee35b29d/attachment.pl>

From robert.espesser at lpl-aix.fr  Fri Dec 20 00:06:26 2013
From: robert.espesser at lpl-aix.fr (espesser)
Date: Fri, 20 Dec 2013 00:06:26 +0100
Subject: [R-sig-ME] getting pvalues of fixed effects coefficients in a lmer
 model with bootMer
Message-ID: <52B37BF2.3030405@lpl-aix.fr>

  Dear List,
I want to get the pvalues  of the coefficients of a lmer model using 
Bootmer.
I am specially interested in obtaining pvalues for  factor(s) with more 
than 2 levels.

Here is an example:

library(lme4)
data(cake)
str(cake)
'data.frame':   270 obs. of  5 variables:
  $ replicate  : Factor w/ 15 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 
1 1 ...
  $ recipe     : Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 2 2 2 2 ...
  $ temperature: Ord.factor w/ 6 levels "175"<"185"<"195"<..: 1 2 3 4 5 
6 1 2 3 4 ...
  $ angle      : int  42 46 47 39 53 42 39 46 51 49 ...
  $ temp       : num  175 185 195 205 215 225 175 185 195 205 ...

# fitting  the model
   cakenum.lmer_new = lmer(angle ~ recipe + temp + (1|recipe:replicate), 
cake)

  summary(cakenum.lmer_new)
Linear mixed model fit by REML ['merModLmerTest']
Formula: angle ~ recipe + temp + (1 | recipe:replicate)
    Data: cake

REML criterion at convergence: 1693.844

Random effects:
  Groups           Name        Variance Std.Dev.
  recipe:replicate (Intercept) 41.80    6.465
  Residual                     20.71    4.551
Number of obs: 270, groups: recipe:replicate, 45

Fixed effects:
              Estimate Std. Error        df t value Pr(>|t|)
(Intercept)   1.51587    3.67895 257.81000   0.412    0.681
recipeB      -1.47778    2.45625  42.00000  -0.602    0.551
recipeC      -1.52222    2.45625  42.00000  -0.620    0.539
temp          0.15803    0.01622 224.00000   9.746 <2e-16 ***

(please dismiss the SAS df and pvalues )


###   bootstrap confidence intervals

confint(cakenum.lmer_new, method="boot",nsim=N) -> cakenum.lmer_new.confint
Computing bootstrap confidence intervals ...

                                      2.5 %    97.5 %
sd_(Intercept)|recipe:replicate  4.9334498 7.9448858
sigma                            4.1213029 4.9908540
(Intercept)                     -5.5832955 8.6921784
recipeB                         -6.2738450 3.1064975
recipeC                         -6.5293123 3.2290811
temp                             0.1270242 0.1882827


###  bootstrap pvalues

# definition of the private external function

mafun<- function(fit) {
      return(fixef(fit))
  }

N=1000

  resu.boot=bootMer(cakenum.lmer_new, mafun, nsim=N)
  fixeboot = resu.boot$t

  # the code below is derived from pvals.fnc()
  prop <- colSums(fixeboot > 0)/N
  prop
(Intercept)     recipeB     recipeC        temp
       0.631       0.281       0.269       1.000

ans <- 2 * pmax(0.5/N, pmin(prop, 1 - prop))
  ans
[1] 0.738    0.562         0.538         0.001
Inter        recipeB      recipeC      temp        # corresponding fixed 
coeff

which looks plausible (compared to old pvals.fnc() results) and
in line with the preceding  confint results.


a) Is this procedure valid ?
b) Is it valid whatever are the complexity of the model and/or the 
random terms ?

Thanks a lot

R. Espesser

-- 
Robert Espesser
CNRS UMR  7309 - Universit? Aix-Marseille
5 Avenue Pasteur
13100 AIX-EN-PROVENCE

Tel: +33 (0)413 55 36 26


From jurij.diaci at bf.uni-lj.si  Fri Dec 20 13:52:02 2013
From: jurij.diaci at bf.uni-lj.si (Jurij Diaci BF)
Date: Fri, 20 Dec 2013 13:52:02 +0100
Subject: [R-sig-ME] random effects with nbinom glmmadmb
Message-ID: <000701cefd82$47a5b120$d6f11360$@bf.uni-lj.si>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131220/20f70bdf/attachment.pl>

From bbolker at gmail.com  Fri Dec 20 15:31:46 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 20 Dec 2013 09:31:46 -0500
Subject: [R-sig-ME] random effects with nbinom glmmadmb
In-Reply-To: <000701cefd82$47a5b120$d6f11360$@bf.uni-lj.si>
References: <000701cefd82$47a5b120$d6f11360$@bf.uni-lj.si>
Message-ID: <52B454D2.3030509@gmail.com>

On 13-12-20 07:52 AM, Jurij Diaci BF wrote:
> Hi,
> 
> I model emergence of seedling counts (sp: spruce) in four canopy openings
> created by a bark beetle calamity (random factor opening). Two openings were
> fenced and two were not fenced (factor fence). Within openings plots were
> placed in a stratified random manner to sample two different orographic
> features: plateau and sinkhole (factor relief) and two positions within
> canopy opening  (factor location). Sampling was repeated after seven years
> (factor year). I sampled also several covariates (c1: rockiness; c2: ground
> vegetation coverage).
> 
> The total dataset consist of: 2(fence)*2(relief)*2(location)*2(year)*30 =
> 480 plots.
> I applied a negative binomial model:
> 
> nbm.sp <- glm.nb(sp  ~  fence  + relief + location + year+c1 +c2, link =
> "log", data = krese2) Results seem OK, but I'm aware of pseudoreplication.

> 
> Therefore, I applied a mixed negative binomial model:
> 
> mnbm.sp <- glmmadmb(sp ~ fence  + relief + location + year + location:year +
>                       (1 | opening), family="nbinom", data = krese2) 

> Results are similar compared to the first model, with slightly larger std.
> errors.
> 
> I understand that 4 openings are at the lower limit for calculation of
> random effects.
> 
> Do the results below look OK?
> 
> Is this a correct approach? Namely, there is a fixed factor "fence"
> connected to openings:
> 
> table(krese2$fence, krese2$opening)

>          opening
>          a   b   c  d
> fenced   0   0 120 120
> nonfenc 40 200   0   0
> 
> Call:

> glmmadmb(formula = sp ~ fence  + relief + location + year + location:year +
>                       (1 | opening), data = krese2, family = "nbinom")
> AIC: 2933.7
> 
> Coefficients:
> 
>                 Estimate Std. Error z value Pr(>|z|)
> (Intercept)   1.588      0.194    8.20  2.4e-16 ***
> reliefsink    0.243      0.170    1.43  0.15350
> fencefe       0.488      0.211    2.31  0.02082 *
> locationedge  0.785      0.172    4.56  5.0e-06 ***
> year2013     -0.408      0.118   -3.46  0.00054 ***
> 
> reliefsink:locationedge   -0.541      0.240   -2.26  0.02413 *
> Number of observations: total=480, opening=4 Random effect variance(s):
> Group=Odd
>             Variance StdDev
> (Intercept)  0.02702 0.1644
> Negative binomial dispersion parameter: 0.66844 (std. err.: 0.048389)
> Log-likelihood: -1458.86


  This looks reasonable overall.  Some comments:

 * Why do your fixed effects differ between models?  You have the
location:year interaction in the GLMM and not the GLM, and the covariates
in the GLM but not the GLMM.  (But I don't see the location:year parameter
in the output ... is that really location:relief ??)
 * It would be nice to compare the GLM with 'opening' as a fixed
effect, but you can't quite do this -- the fence effect will be partially
confounded with opening ...
 * Be aware that the p-values quoted are Wald effects, so don't take
account of finite-size effects. It's a bit hard to get the values
exactly, but your fence effect would require 8 df to be significant
at the 0.05 level (qt(0.975,8)=2.306) ... so I would be quite careful
with that p-value.  (You might be able to use MCMC to get more reliable
values -- I believe the glmmADMB vignette has an example.)


From Jurij.Diaci at bf.uni-lj.si  Sat Dec 21 09:09:34 2013
From: Jurij.Diaci at bf.uni-lj.si (Diaci, Jurij)
Date: Sat, 21 Dec 2013 08:09:34 +0000
Subject: [R-sig-ME] random effects with nbinom glmmadmb
In-Reply-To: <52B454D2.3030509@gmail.com>
References: <000701cefd82$47a5b120$d6f11360$@bf.uni-lj.si>,
	<52B454D2.3030509@gmail.com>
Message-ID: <2704FB2E9FC47F418E968B11C9F06D1506A16298@MAIL-BF>

Dear Ben,
thank you very much for the help.
*1 Sorry for the mistake with fixed effects. This was due to translation of variable names from 
Slovene. In this replay R output is original, and the legend is following:
Odd = opening, random 4 levels
PL_VR = relief, fixed 2 levels (sinkhole and plateau)
N_O = fence, fixed 2 levels
C_S = location, fixed 2 levels (forest edge and center)
*2 You were right about including of "opening" as fixed effect. Results are appended below.
*3a Below are also results from GLMM. I've applied anova test for two fits - one without fence 
effects and the differnce is not significant (p = 0.05919).
Should I proceed in this way for all the effects and report this p values in paper? I usually work 
with glm.nb and drop1 function to get significant effects and then continue with glmmadmb which is 
slower. Is this OK?
*3b I've tried also mcmc.opts with 1000 iterations and results look OK.
I've got so far following estimates and errors (parenthesis) for fence (N_O) effect:
GLM with opening     0.444(0.118)
GLM without opening  0.862(0.244)
GLMM                  0.488(0.211)
GLMM with MCMC        0.542(0.315)
(1000 iterations)
How many iterations are neccessary?
I guess there are no p values for the effects in mcmc, but only estimates and errors?
Shuld I report comparative anova results for p values, and estimates and errors from MCMC?
How can the geweke.diag outpot for N_O[T.og] 1.0322 be interpreted?
*3c Vinnete example works fine, thank you very much. I've found only one problem/error with the 
line:
# tm <- tm[, !grepl("^u\\", colnames(m))]
# Error in grepl("^u\\", colnames(m)) :   invalid regular expression '^u\', reason 'Trailing backslash'

Best regards,
Jurij

*******************************************************
Ad *2 Results from GLM with oppening as a fixed effect.
Call:
glm.nb(formula = sm_si ~ PL_VR + N_O + C_S + Leto + PL_VR:C_S + 
    Odd, data = krese2, link = "log", init.theta = 0.6738688778)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.1282  -1.1526  -0.4309   0.3075   2.8425  
Coefficients: (1 not defined because of singularities)
                        Estimate Std. Error z value Pr(>|z|)    
(Intercept)               1.3243     0.1696   7.807 5.84e-15 ***
PL_VR[T.vrt]              0.2319     0.1668   1.390 0.164455    
N_O[T.og]                 0.8618     0.2437   3.536 0.000405 ***
C_S[T.rob]                0.7444     0.1664   4.473 7.70e-06 ***
Leto[T.2013]             -0.4120     0.1167  -3.531 0.000415 ***
Odd[T.39]                -0.1253     0.2361  -0.531 0.595541    
Odd[T.42]                 0.5644     0.1669   3.381 0.000723 ***
Odd[T.51]                     NA         NA      NA       NA    
PL_VR[T.vrt]:C_S[T.rob]  -0.5412     0.2368  -2.285 0.022301 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Dispersion parameter for Negative Binomial(0.6739) family taken to be 1)
    Null deviance: 610.76  on 479  degrees of freedom
Residual deviance: 545.05  on 472  degrees of freedom
AIC: 2927.7
Number of Fisher Scoring iterations: 1

              Theta:  0.6739 
          Std. Err.:  0.0487 
 2 x log-likelihood:  -2909.6520
*******************************************************
Ad *3a Results from GLMM
Call:
glmmadmb(formula = sm_si ~ PL_VR + N_O + C_S + Leto + PL_VR:C_S + 
    (1 | Odd), data = krese2, family = "nbinom")
AIC: 2933.7 
Coefficients:
                Estimate Std. Error z value Pr(>|z|)    
(Intercept)        1.588      0.194    8.20  2.4e-16 ***
PL_VRvrt           0.243      0.170    1.43  0.15350    
N_Oog              0.488      0.211    2.31  0.02082 *  
C_Srob             0.785      0.172    4.56  5.0e-06 ***
Leto2013          -0.408      0.118   -3.46  0.00054 ***
PL_VRvrt:C_Srob   -0.541      0.240   -2.26  0.02413 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Number of observations: total=480, Odd=4 
Random effect variance(s):
Group=Odd
            Variance StdDev
(Intercept)  0.02702 0.1644
Negative binomial dispersion parameter: 0.66844 (std. err.: 0.048389)
Log-likelihood: -1458.86
*******************************************************
Ad *3b
Iterations = 1:1000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 1000 
1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:
                             Mean      SD Naive SE Time-series SE
(Intercept)              1.589093 0.25872 0.008182       0.049969
PL_VR[T.vrt]             0.230967 0.16032 0.005070       0.024057
N_O[T.og]                0.542544 0.31503 0.009962       0.066181
C_S[T.rob]               0.784867 0.17890 0.005657       0.028402
Leto[T.2013]            -0.369402 0.11369 0.003595       0.017880
PL_VR[T.vrt]:C_S[T.rob] -0.540553 0.22776 0.007203       0.032046
tmpL                     0.268618 0.19983 0.006319       0.049266
alpha                    0.664778 0.04325 0.001368       0.006534
u.1                      0.009318 0.50282 0.015900       0.099104
u.2                     -0.245842 0.70595 0.022324       0.131085
u.3                      0.650843 0.55947 0.017692       0.118921
u.4                     -0.872515 0.69354 0.021932       0.201181
2. Quantiles for each variable:
                             2.5%     25%     50%     75%   97.5%
(Intercept)              0.930400  1.4410  1.5882  1.7564  2.0519
PL_VR[T.vrt]            -0.066268  0.1125  0.2209  0.3400  0.5594
N_O[T.og]               -0.009899  0.3491  0.5050  0.6717  1.3622
C_S[T.rob]               0.414240  0.6696  0.7848  0.9348  1.0667
Leto[T.2013]            -0.621706 -0.4321 -0.3664 -0.3002 -0.1434
PL_VR[T.vrt]:C_S[T.rob] -1.033963 -0.7135 -0.5374 -0.3748 -0.1126
tmpL                     0.004204  0.1227  0.2268  0.3824  0.7823
alpha                    0.589223  0.6349  0.6655  0.6885  0.7551
u.1                     -1.014267 -0.2826  0.0225  0.3082  1.0957
u.2                     -1.735785 -0.6892 -0.1468  0.2218  0.9345
u.3                     -0.370678  0.2548  0.6098  1.0719  1.7863
u.4                     -2.133338 -1.3691 -0.9411 -0.3733  0.5059

From bbolker at gmail.com  Sun Dec 22 00:32:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Dec 2013 18:32:22 -0500
Subject: [R-sig-ME] Parametrization of the beta-binomial model in
 glmmadmb {glmmADMB}
In-Reply-To: <52B1E933.9060408@ibv.uio.no>
References: <4D31AABF.2080709@gmail.com> <52B1E933.9060408@ibv.uio.no>
Message-ID: <52B62506.1040106@gmail.com>

On 13-12-18 01:28 PM, Torbj?rn Ergon wrote:
> Dear list,
> 
> I want to do some simulation based goodness-of-fit assessment of a
> (zero-inflated) beta-binomial model fitted with glmmadmb, but I realize
> I don't quite understand how this model is parameterized.
> 
> I understand that the linear predictor is
> inverse-logit(alfa/(alpha+beta)) where alpha and beta are the parameters
> of the beta-distribution (right?). But what is the exact definition of
> "Beta-binomial dispersion parameter" (fit.glmmadmb$alpha) expressed in
> terms of the parameters of the beta distribution (alpha and beta)?

    The ultimate answer is in the glmmadmb.tpl file included in the package:

 system.file("tpl","glmmadmb.tpl",package="glmmADMB")


    case 9: // beta-binomial
	Ni = sum(y(_i));
	tmpl = log_comb(Ni,y(_i,1)) + // log(C(Ni,y(_i,1)))
               gammln(y(_i,2)+alpha*(1-lambda))+
               gammln(y(_i,1)+alpha*lambda)-
               gammln(Ni+alpha) + // lbeta(...)
	    -(gammln(alpha*(1-lambda))+
                gammln(alpha*lambda)-gammln(alpha)); // lbeta(...)

  Have you looked at the Morris, W. 1997. American Naturalist
150:299-327 reference given?  This is also discussed in Bolker 2008:

Morris (1997) suggests a different parameterization that
uses an overdispersion parameter ? , like the k parameter of the
negative binomial distribution. In this case the parameters are N, the
per-trial probability p (= a/(a + b)), and ? (= a + b).

  ? in Bolker 2008 corresponds to "alpha" here.
  p in Bolker 2008 corresponds to "lambda" here, and is the
inverse-logit / logistic transformation of the linear predictor (beta_0
+ beta_1*x_1 + ....)







> 
> Cheers,
> 
> Torbj?rn Ergon
> University of Oslo
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Sun Dec 22 00:45:59 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 21 Dec 2013 18:45:59 -0500
Subject: [R-sig-ME] Yet another question on CIs for coef(model)
 extracted conditional coefficients
In-Reply-To: <CA+xNL7pxrr=YuHbm7H539MR+ZnA6f7+sgJ=ihf-_EQcDW0CdkQ@mail.gmail.com>
References: <CA+xNL7pxrr=YuHbm7H539MR+ZnA6f7+sgJ=ihf-_EQcDW0CdkQ@mail.gmail.com>
Message-ID: <52B62837.6050104@gmail.com>

On 13-12-18 05:46 PM, Richard Asturia wrote:
> Dear list, this one is probably already answered somewhere, but to the best
> of my efforts I did not find precisely the information I am looking for,
> although I did find a lot of useful comments about the overall subject.
> 
> So, what I wanna do is the usual procedure of calculating CIs for the
> coefficients at the grouping levels, i.e. the ones extracted with
> coef(model) , which are the same as ranef(model) + fixef(model).
> 
> I found the explanation on the FAQ on how to extract the standard errors
> for the conditional means with ranef(model, condVar = TRUE), but I still
> don't know what would be the best practice here for using those to
> calculate CIs. The FAQ does not seem to discuss that particular issue.
> 
> I know that functions such as dotplot and coefplot2 give me intervals, but
> seems to me as a rather na?ve way of calculating those. Please, is there
> any suggestions you could make on how to accomplish that, i.e. how to
> calculate CIs for the conditional coef(model) coefficients, by using the
> standard errors extracted with condVar=TRUE?

  This is not easy.  The following (long) thread is probably the best
discussion I've seen:

http://thread.gmane.org/gmane.comp.lang.r.general/286283/focus=9589


From N.Robinson at colorado.edu  Sun Dec 22 23:13:22 2013
From: N.Robinson at colorado.edu (Natalie Robinson)
Date: Sun, 22 Dec 2013 15:13:22 -0700
Subject: [R-sig-ME] Conceptual question with mixed effects models
Message-ID: <011b01ceff63$0b1dca70$21595f50$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131222/f3fb29f6/attachment.pl>

From M.Fairbrother at bristol.ac.uk  Mon Dec 23 16:07:54 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 23 Dec 2013 15:07:54 +0000
Subject: [R-sig-ME] call for papers (social scientists)
Message-ID: <CAAH-yP-5c1msgEpaqAjw50zt=H5Jf61-oQCWbLTTDWW0KiWKsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131223/a512bf5e/attachment.pl>

From bbonit at tin.it  Tue Dec 31 13:54:56 2013
From: bbonit at tin.it (bbonit at tin.it)
Date: Tue, 31 Dec 2013 13:54:56 +0100 (CET)
Subject: [R-sig-ME] Sample size calculation
Message-ID: <14348b8a279.bbonit@tin.it>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20131231/ed27ee7d/attachment.pl>

From t.h.ergon at ibv.uio.no  Sun Dec 22 05:03:40 2013
From: t.h.ergon at ibv.uio.no (=?UTF-8?B?VG9yYmrDuHJuIEVyZ29u?=)
Date: Sun, 22 Dec 2013 05:03:40 +0100
Subject: [R-sig-ME] Parametrization of the beta-binomial model in
 glmmadmb {glmmADMB}
In-Reply-To: <52B62506.1040106@gmail.com>
References: <4D31AABF.2080709@gmail.com> <52B1E933.9060408@ibv.uio.no>
	<52B62506.1040106@gmail.com>
Message-ID: <52B6649C.4030600@ibv.uio.no>

On 22.12.2013 00:32, Ben Bolker wrote:
> On 13-12-18 01:28 PM, Torbj?rn Ergon wrote:
>> Dear list,
>>
>> I want to do some simulation based goodness-of-fit assessment of a
>> (zero-inflated) beta-binomial model fitted with glmmadmb, but I realize
>> I don't quite understand how this model is parameterized.
>>
>> I understand that the linear predictor is
>> inverse-logit(alfa/(alpha+beta)) where alpha and beta are the parameters
>> of the beta-distribution (right?). But what is the exact definition of
>> "Beta-binomial dispersion parameter" (fit.glmmadmb$alpha) expressed in
>> terms of the parameters of the beta distribution (alpha and beta)?
>
>      The ultimate answer is in the glmmadmb.tpl file included in the package:
>
>   system.file("tpl","glmmadmb.tpl",package="glmmADMB")
>
>
>      case 9: // beta-binomial
> 	Ni = sum(y(_i));
> 	tmpl = log_comb(Ni,y(_i,1)) + // log(C(Ni,y(_i,1)))
>                 gammln(y(_i,2)+alpha*(1-lambda))+
>                 gammln(y(_i,1)+alpha*lambda)-
>                 gammln(Ni+alpha) + // lbeta(...)
> 	    -(gammln(alpha*(1-lambda))+
>                  gammln(alpha*lambda)-gammln(alpha)); // lbeta(...)
>
>    Have you looked at the Morris, W. 1997. American Naturalist
> 150:299-327 reference given?  This is also discussed in Bolker 2008:
>
> Morris (1997) suggests a different parameterization that
> uses an overdispersion parameter ? , like the k parameter of the
> negative binomial distribution. In this case the parameters are N, the
> per-trial probability p (= a/(a + b)), and ? (= a + b).
>
>    ? in Bolker 2008 corresponds to "alpha" here.
>    p in Bolker 2008 corresponds to "lambda" here, and is the
> inverse-logit / logistic transformation of the linear predictor (beta_0
> + beta_1*x_1 + ....)
>
>

Thanks!

It is confusing that the help file (?glmmadmb version 0.7.7) uses alpha 
in the text (as in the glmmadmb object) but theta in the expression of 
the density function.

I think it would help a lot if you, after the first sentence referring 
to Morris, wrote something like "p = a/(a+b) and alpha = a+b, where a 
and b are the two parameters of the beta-distribution. Hence, the 
variance of the beta-binomial distribution is 
V_{B}(N)*(alpha+N)/(alpha+1) where V_{B}(N) is the in the binomial 
variance Np(1-p)".

Cheers,

Torbj?rn


