From mark.lyman at atk.com  Wed Oct  1 18:46:44 2008
From: mark.lyman at atk.com (Mark Lyman)
Date: Wed, 1 Oct 2008 16:46:44 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Wrong_degrees_of_freedom_in_nested_model=2C?=
	=?utf-8?q?=09what_goes_wrong_here=3F?=
References: <1276C0564833F043AB4C85ED8DA9CFE501B74DBD@ctemail1.nioo.int>
Message-ID: <loom.20081001T164137-346@post.gmane.org>

Marvelde, Luc te <L.teMarvelde at ...> writes:

> so, a first simple model i think i have to run (but please say so if you 
disagree), is this:
> 
> model1<-lme(TFoodhrC ~ age + age2 + STATUS ,random=~1|nest/birdid/age, 
method="ML", data=r))
> # I used the method="ML" to be able to compare models using anova(model1, 
model2)
> # Model1  fits a non-linear effect of age with an additive effect of status
> 
> Here we expect both age and age2 to have 1 df and each STATUS-group will have 
1 df as well (which makes 4 df for
> the factor STATUS with its 5 levels)... right?
  
> Both age and age2 have 266 df here and STATUS even 71 each! I dont know what 
is going wrong here. 
> 
> Can anyone see what goes wrong here?
> 
> Many many thanks in advance!
> 
> Luc te Marvelde
> 

Try anova(model1) and see if that sheds some light on what you are seeing.

Mark Lyman



From davamaillist at gmail.com  Wed Oct  1 21:39:00 2008
From: davamaillist at gmail.com (david dav)
Date: Wed, 1 Oct 2008 21:39:00 +0200
Subject: [R-sig-ME] Errors in computing GEE models
Message-ID: <772cb06e0810011239xedce0e0ia55c225f9215db5c@mail.gmail.com>

Hi,
I posted this on the general R-announce list a few weeks ago. I was
suggested to try it here :

I would like to fit a GLM model with GEE on clustered data.
I tried to use gee in the GEE package on a twin data set. All cluster
are of size 2. I removed the missing data first.

library(gee)
mod.Y <- gee(Y ~ X1 + X2 , id = IDENTIF2,  family = binomial, corstr
= "unstructured", data = na.omit(df))

Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
(Intercept)         X1M  X2Sans AMP      X2Stim
 -2.7756284   0.4658861  -1.6508288  -1.5059518
Erreur dans gee(Y ~ X1 + X2, id = IDENTIF2, family = binomial, corstr
= "unstructured",  :
 NA/NaN/Inf dans un appel ? une fonction externe (argument 2)   #
meaning in a call to an external function
De plus : Warning message:
In gee(Y ~ X1 + X2, id = IDENTIF2, family = binomial, corstr =
"unstructured",  :
 NAs introduits lors de la conversion automatique   # meaning NAs
introduced during the automatic conversion

The regression gives results with SAS version 8 on the same dataset
(results are pretty close from the results of a naive logistic
regression).
I tried to change the explanatory variables (X1 alone, X2 alone, other
possible explanatory variables : no result). I do not find where the
error could come from.
Thanks



From ken at kjbeath.com.au  Thu Oct  2 04:31:11 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 2 Oct 2008 12:31:11 +1000
Subject: [R-sig-ME] Errors in computing GEE models
In-Reply-To: <772cb06e0810011239xedce0e0ia55c225f9215db5c@mail.gmail.com>
References: <772cb06e0810011239xedce0e0ia55c225f9215db5c@mail.gmail.com>
Message-ID: <C2B799BF-2FB5-4B55-B37F-D1E41EEEAB67@kjbeath.com.au>

On 02/10/2008, at 5:39 AM, david dav wrote:

> Hi,
> I posted this on the general R-announce list a few weeks ago. I was
> suggested to try it here :
>
> I would like to fit a GLM model with GEE on clustered data.
> I tried to use gee in the GEE package on a twin data set. All cluster
> are of size 2. I removed the missing data first.
>

Trying geepack may be the best solution.

Check what is actually returned from na.omit and that there is not  
perfect correlation between clusters. Changing to "exchangeable"  
corstr shouldn't make any difference but maybe worth a try.

Ken



> library(gee)
> mod.Y <- gee(Y ~ X1 + X2 , id = IDENTIF2,  family = binomial, corstr
> = "unstructured", data = na.omit(df))
>
> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
> running glm to get initial regression estimate
> (Intercept)         X1M  X2Sans AMP      X2Stim
> -2.7756284   0.4658861  -1.6508288  -1.5059518
> Erreur dans gee(Y ~ X1 + X2, id = IDENTIF2, family = binomial, corstr
> = "unstructured",  :
> NA/NaN/Inf dans un appel ? une fonction externe (argument 2)   #
> meaning in a call to an external function
> De plus : Warning message:
> In gee(Y ~ X1 + X2, id = IDENTIF2, family = binomial, corstr =
> "unstructured",  :
> NAs introduits lors de la conversion automatique   # meaning NAs
> introduced during the automatic conversion
>
> The regression gives results with SAS version 8 on the same dataset
> (results are pretty close from the results of a naive logistic
> regression).
> I tried to change the explanatory variables (X1 alone, X2 alone, other
> possible explanatory variables : no result). I do not find where the
> error could come from.
> Thanks
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kingsfordjones at gmail.com  Wed Oct  1 22:31:51 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Wed, 1 Oct 2008 14:31:51 -0600
Subject: [R-sig-ME] Wrong degrees of freedom in nested model,
	what goes wrong here?
In-Reply-To: <1276C0564833F043AB4C85ED8DA9CFE501B74DBD@ctemail1.nioo.int>
References: <Acki1qLv18UN5XgvR26rDdOPfhJ8KA==>
	<1276C0564833F043AB4C85ED8DA9CFE501B74DBD@ctemail1.nioo.int>
Message-ID: <2ad0cc110810011331t2f43a787oda651428499f2ab7@mail.gmail.com>

Luc,

Note this part of the output:


> Number of Observations: 352
> Number of Groups:
>                     nest          birdid %in% nest age %in% birdid %in% nest
>                        9                        84                       352
>


hth,

Kingsford Jones




> Both age and age2 have 266 df here and STATUS even 71 each! I dont know what is going wrong here.
>
> Can anyone see what goes wrong here?
>
> Many many thanks in advance!
>
> Luc te Marvelde
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lorenz.gygax at art.admin.ch  Thu Oct  2 08:09:47 2008
From: lorenz.gygax at art.admin.ch (lorenz.gygax at art.admin.ch)
Date: Thu, 2 Oct 2008 08:09:47 +0200
Subject: [R-sig-ME] Type of residuals for assessing assumptions in extended
	lme's
Message-ID: <145C63777EF3ED41A5A99035845F7DD90241CE58@EVD-C8001.bk.evdad.admin.ch>

Dear all,

I am currently evaluating different models regarding haemodynamic reactions in the brain. Thus the realtive concentration of O2Hb and HHb are my response variables. These concentrations are recorded over relatively short stimulation periods (75 sec) and are presently available at a rate of 1 Hz (one measurement per second). One stimulation period is our main observational unit which is then nested in treatment, individual probands etc. I am trying to model the time course within the stimulation period using natural splines.

Not surprisingly, there is strong serial correlation in the raw / pearson residuals. Using "correlation= corARMA (..., p= 2)" gets rid of those. It may be the case that there is som heteroscedasticity as well so an additional "weighst= varIdent (...)" may become nesseary (more of that below).

Main question:

My main issue now is which type of residuals is needed to check assumptions of a model that includes some correlation structure (and may or may not include some additional variance structure). I have, of course, consulted Pinheiro & Bates (chapt 5). It seems obvious that normalised residuals are needed for checking whether the correlation structure is successful in catching the serial correlations (and there are examples of those in said book). I am not quite sure but I also assume based on the gls examples towards the end of chapt 5 that the normalised residuals need to be plotted for other plots used in assessing assumptions such as normal-plots, Tukey-Anscombe-plots and so on (and this seems nothing but consistent). Is that correct in your view?

Secondary question:

What actually happens in our data set is that the normalised residuals do not show any serial correlation any longer but are far from a normal distribution. Whereas the raw / pearson residuals follow a normal distribution very closely and seem to be homoscedastic, the normalised residuals are heteroscedastic regarding some explanatory variables and have much longer lower und upper tails than a normal distribution. Thus, if my notion stated above is correct (namely, that the normalised residuals should generally be used in assessing model assumptions if a correlation structure is present), our models may not be valid if based on a normal distribution.

I would see two basic solutions: (1) either use a model that allows for a distribution with longer tails than a normal or (2) thin the measurement series. lmer might accomodate another distribution family but - if I have followed the discussions on this list correclty - does not allow for a serial correlation structure. Thus, this approach might need a lot of new programming and developping. The second approach would presume that not all the data are actually necessary to model the change of concentrations and that fewer observations are sufficient with the advantage that they are serially uncorrelated. Any oppinions on these two strategies?

Many thanks for your time and ideas, Lorenz
- 
Lorenz Gygax, Dr. sc. nat.
Federal Veterinary Office
Centre for proper housing of ruminants and pigs
T?nikon, CH-8356 Ettenhausen / Switzerland



From danielezrajohnson at gmail.com  Thu Oct  2 18:06:57 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 2 Oct 2008 17:06:57 +0100
Subject: [R-sig-ME] polychotomous response data
Message-ID: <a46630750810020906kd889b90lbf0eaf4af097f97a@mail.gmail.com>

Can anyone suggest what I might do to analyze data where:

- response has more than two values (nominal)
- observations are grouped by subject
- predictors are both categorical and continuous
- some predictors are within-subject, some are between-subject

If it wasn't for the within-subject predictors, I thought this was
going to be a compositional data analysis problem, so I was looking
into the "compositions" library (which I found confusing).

However, treating each subject's data as a single composition, while
it makes sense, is not going to enable the analysis of within-subject
predictors.

Is there a way to use lme4 or another library to extend GLMM to a
multi-category response?

Sorry for the generic question,
Thanks,
Daniel



From gregor.gorjanc at bfro.uni-lj.si  Fri Oct  3 10:14:45 2008
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 3 Oct 2008 08:14:45 +0000 (UTC)
Subject: [R-sig-ME] polychotomous response data
References: <a46630750810020906kd889b90lbf0eaf4af097f97a@mail.gmail.com>
Message-ID: <loom.20081003T081014-72@post.gmane.org>

Daniel Ezra Johnson <danielezrajohnson at ...> writes:
> Can anyone suggest what I might do to analyze data where:
> 
> - response has more than two values (nominal)
> - observations are grouped by subject
> - predictors are both categorical and continuous
> - some predictors are within-subject, some are between-subject
> 
> If it wasn't for the within-subject predictors, I thought this was
> going to be a compositional data analysis problem, so I was looking
> into the "compositions" library (which I found confusing).

Nope, compositions can be used when you measure the composition of a particular
things, say you have a soil and you measure % os sand, % of, ...

> However, treating each subject's data as a single composition, while
> it makes sense, is not going to enable the analysis of within-subject
> predictors.
>
> Is there a way to use lme4 or another library to extend GLMM to a
> multi-category response?

I would first fit a "threshold" model with polr() in MASS. Then I would try to
add "mixed" effects with use of BUGS. Latest Book by Gelman and Hill is a very
good resourse about this topic.



From David.LeBlond at abbott.com  Fri Oct  3 20:55:14 2008
From: David.LeBlond at abbott.com (David LeBlond)
Date: Fri, 3 Oct 2008 13:55:14 -0500
Subject: [R-sig-ME] Fw: mcmcsamp(lme4): What is contained in $ST and $sigma?
Message-ID: <OFCC9B63F9.C6AA3CED-ON862574D7.0067C409-862574D7.0067F529@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081003/75da3d6e/attachment.pl>

From bolker at ufl.edu  Fri Oct  3 22:37:45 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 03 Oct 2008 16:37:45 -0400
Subject: [R-sig-ME] Wald F tests
Message-ID: <48E68299.3040203@ufl.edu>

 [forwarding to R-sig-mixed, where it is likely to get more
responses]

Mark Fowler wrote:

Hello,
	Might anyone know how to conduct Wald-type F-tests of the fixed
effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
and have seen it recommended in user group discussions, but haven't come
across any code to accomplish it. I understand the anova function treats
a glmmPQL fit as an lme fit, with the test assumptions based on maximum
likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
have R 2.7 and S-Plus 8 if necessary.



From David.LeBlond at abbott.com  Fri Oct  3 20:37:55 2008
From: David.LeBlond at abbott.com (David LeBlond)
Date: Fri, 3 Oct 2008 13:37:55 -0500
Subject: [R-sig-ME] mcmcsamp(lme4): What is contained in $ST and $sigma?
Message-ID: <OF349AE7F3.BE1D928B-ON862574D7.0060760D-862574D7.00665F85@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081003/361eb511/attachment.pl>

From Olivier.Renaud at unige.ch  Mon Oct  6 14:34:16 2008
From: Olivier.Renaud at unige.ch (Olivier Renaud)
Date: Mon, 06 Oct 2008 14:34:16 +0200
Subject: [R-sig-ME] correlation structure in gls or lme/lmer with several
 observations per day
Message-ID: <48EA05C8.6080005@unige.ch>

Hi,

To simplify, suppose I have 2 observations each day for three days. I 
would like to define the correlation structure of these 6 observations 
as follows: the correlation of 2 observations on the same day is, say, 
alpha, the correlation for 2 observations one day apart is rho and the 
correlation for 2 observations 2 days apart is rho^2. I.e. I would like 
to have an AR1 correlation + a correlation for the same day. I tried 
with gls and lme from the nlme package, but with no success. One 
difficulty arises since corAR1 seems to require only one observation per 
day (see example below). Any idea on how to implement it, either with 
special correlation structures, or through random effects in lme/lmer ? 
should I try to define a "new" correlation structure corMultiAR1 ? If 
so, where can I find help on how to write such a piece of code ( 
nlme:::corAR1 is not clear to me) ?

Olivier



*> obs6 <- matrix( c(1,2,3,4,5,6, 1,1,2,2,3,3), byrow=F, nc=2)
 > dimnames(obs6) <- list(NULL, c("y","time"))
 > obs6 <- data.frame(obs6)
 > obs6
  y time
1 1    1
2 2    1
3 3    2
4 4    2
5 5    3
6 6    3
 > gls (y~1, correl=corAR1(0.0,~time), data=obs6)
Error in Initialize.corAR1(X[[1L]], ...) :
  Covariate must have unique values within groups for corAR1 objects
*


-- 
Olivier.Renaud at unige.ch                 http://www.unige.ch/~renaud/
Methodology & Data Analysis - Psychology Dept - University of Geneva
UniMail, Office 4142  -  40, Bd du Pont d'Arve   -  CH-1211 Geneva 4



From dannyliu1002 at yahoo.com.cn  Tue Oct  7 09:06:54 2008
From: dannyliu1002 at yahoo.com.cn (Ming Liu)
Date: Tue, 7 Oct 2008 15:06:54 +0800 (CST)
Subject: [R-sig-ME] how to extract the values in the nlme package?
Message-ID: <493275.79661.qm@web15601.mail.cnb.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081007/5cec85c1/attachment.pl>

From martijn.vandegehuchte at ugent.be  Tue Oct  7 15:21:23 2008
From: martijn.vandegehuchte at ugent.be (Martijn Vandegehuchte)
Date: Tue, 7 Oct 2008 15:21:23 +0200
Subject: [R-sig-ME] generalized linear mixed models: large differences when
	using glmmPQL or lmer with laplace approximation
Message-ID: <046780BC8E8D47DD9765E84222E8858C@Mythimna>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081007/4baf62f5/attachment.pl>

From martijn.vandegehuchte at ugent.be  Tue Oct  7 15:28:43 2008
From: martijn.vandegehuchte at ugent.be (Martijn Vandegehuchte)
Date: Tue, 7 Oct 2008 15:28:43 +0200
Subject: [R-sig-ME] generalized linear mixed models: large differences when
	using glmmPQL or lmer with laplace approximation
Message-ID: <559E1B0449214BB483273F44A927D926@Mythimna>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081007/d2a93058/attachment.pl>

From HDoran at air.org  Tue Oct  7 16:17:12 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 7 Oct 2008 10:17:12 -0400
Subject: [R-sig-ME] generalized linear mixed models: large differences
	whenusing glmmPQL or lmer with laplace approximation
In-Reply-To: <559E1B0449214BB483273F44A927D926@Mythimna>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE016E24E8@DC1EXCL01.air.org>

Do you have access to Generalized, Linear and Mixed Models (McCullough
and Searle)? There is a nice little discussion comparing PQL and laplace
and discussing why PQL may result in estimates that are biased and
inconsistent.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Martijn Vandegehuchte
> Sent: Tuesday, October 07, 2008 9:29 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] generalized linear mixed models: large 
> differences whenusing glmmPQL or lmer with laplace approximation
> 
> Dear list,
> 
> First of all, I am a mere ecologist, trying to get the truth 
> out of his data, and not a statistician, so forgive me my 
> lack of statistical background and possible conceptual 
> misunderstandings.
> 
> I am currently comparing generalized linear mixed models in 
> glmmPQL and lmer, with a quasipoisson family, and have found 
> out that parameter estimates are quite different for both 
> methods. I read some of the discussions on the R-forum and it 
> seems that the Laplace approximation used in the current 
> version of lmer is generally preferred to the PQL method. I 
> am an ex-SAS user, and in proc glimmix in SAS the default is 
> PQL, and the estimates and p-values are almost exact the same 
> as with glmmPQL in R. But lmer gives quite different results, 
> and now I am wondering what would be the best option for me.
> 
> First of all, parameter estimates of a same model can be 
> somewhat different in lmer or glmmPQL. Second of all, in 
> lmer, I only get t-values but no associated p-values 
> (apparently they are omitted because of the uncertainty about 
> the df). But if I compare the t-values generated by glmmPQL 
> with those of a same model in lmer, the differences are 
> substantial. My dataset consists of 120 observations, so 
> basically you could guess the order of magnitude of the 
> p-values in lmer based on the t-value and a "large" df.
> 
> First example:
> In lmer:
> 
> > 
> model<-lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1|site),fa
> > mily=quasipoisson)
> > summary (model)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: schirufu ~ diameter + leafvit + densroot + cover + 
> nemcm + (1 |      site) 
>   AIC  BIC logLik deviance
>  2045 2068  -1015     2029
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept) 12.700   3.5638  
>  Residual             15.182   3.8964  
> Number of obs: 120, groups: site, 6
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  1.31017    1.47249   0.890
> diameter    -0.24799    0.29180  -0.850
> leafvit      1.29007    0.21041   6.131
> densroot     0.31024    0.04939   6.281
> cover       -0.24544    0.22179  -1.107
> nemcm        0.24817    0.12028   2.063
> 
> Correlation of Fixed Effects:
>          (Intr) diamtr leafvt densrt cover 
> diameter  0.031                            
> leafvit  -0.083  0.321                     
> densroot  0.011 -0.017 -0.202              
> cover     0.021 -0.448  0.016  0.214       
> nemcm    -0.014  0.114  0.114  0.310 -0.017
> > 
> 
> Although no p-values are given, it suggests that fixed 
> effects leafvit, densroot and nemcm would be significant.
> In glmmPQL:
> 
> > 
> model<-glmmPQL(schirufu~diameter+leafvit+densroot+cover+nemcm,random=~
> > 1|site,family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
> > summary(model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>   AIC BIC logLik
>    NA  NA     NA
> 
> Random effects:
>  Formula: ~1 | site
>         (Intercept) Residual
> StdDev:   0.7864989  4.63591
> 
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: schirufu ~ diameter + leafvit + densroot + 
> cover + nemcm 
>                  Value Std.Error  DF   t-value p-value
> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
> densroot     0.3236446 0.0596342 109  5.427164  0.0000
> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
>  Correlation: 
>          (Intr) diamtr leafvt densrt cover 
> diameter  0.130                            
> leafvit  -0.335  0.313                     
> densroot  0.027 -0.022 -0.203              
> cover     0.090 -0.463  0.015  0.214       
> nemcm    -0.056  0.097  0.107  0.301 -0.014
> 
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max 
> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928 
> 
> Number of Observations: 120
> Number of Groups: 6 
> > 
> 
> Note the difference in parameter estimates. Also, the fixed 
> effect nemcm now is not significant any more.
> 
> Second example,now with an offset:
> In lmer:
> 
> > 
> model<-lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+(1|
> > site), offset= loglength, family=quasipoisson) summary (model)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + 
> cover + schirufu +      (1 | site) 
>   AIC  BIC logLik deviance
>  1593 1618 -787.4     1575
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept)  21.522   4.6392 
>  Residual             173.888  13.1867 
> Number of obs: 120, groups: site, 6
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  0.06733    1.92761  0.0349
> diameter     0.14665    0.60693  0.2416
> leafvit     -0.19902    0.48802 -0.4078
> densroot    -0.49178    0.64221 -0.7658
> rootvit      0.37699    0.46810  0.8054
> cover       -0.23545    0.57896 -0.4067
> schirufu     0.23226    0.46866  0.4956
> 
> Correlation of Fixed Effects:
>          (Intr) diamtr leafvt densrt rootvt cover 
> diameter -0.016                                   
> leafvit   0.015  0.396                            
> densroot  0.055 -0.233 -0.291                     
> rootvit  -0.038 -0.251 -0.629  0.277              
> cover     0.024 -0.796 -0.133  0.253  0.117       
> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
> > 
> 
> This suggests no significant effects at all.
> In glmmPQL:
> 
> > 
> model<-glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+
> > offset(loglength),random=~1|site, family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> > summary (model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>   AIC BIC logLik
>    NA  NA     NA
> 
> Random effects:
>  Formula: ~1 | site
>         (Intercept) Residual
> StdDev:   0.2684477 4.507758
> 
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt 
> Fixed effects: nemcm ~ diameter + leafvit + densroot + 
> rootvit + cover + schirufu +      offset(loglength) 
>                  Value Std.Error  DF    t-value p-value
> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
>  Correlation: 
>          (Intr) diamtr leafvt densrt rootvt cover 
> diameter -0.050                                   
> leafvit   0.077  0.360                            
> densroot  0.217 -0.168 -0.262                     
> rootvit  -0.163 -0.202 -0.632  0.257              
> cover     0.084 -0.772 -0.098  0.200  0.073       
> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
> 
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max 
> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368 
> 
> Number of Observations: 120
> Number of Groups: 6 
> > 
> 
> Again some differences in parameter estimates, but now the 
> two fixed effects densroot and rootvit turn out to be significant.
> So my questions are:
> - what would you recommend me to use? lmer or glmmPQL 
> (laplace approximation or penalized quasi-likelihood)?
> - if lmer is the better option, is there a way to get a 
> reliable p-value for the fixed effects?
> I have experienced that deleting a term and comparing models 
> using anova() always overestimates the significance of that 
> term, probably because the quasipoisson correction for 
> overdispersion is not taken into account. 
> 
> Thank you very much beforehand,
> 
> Martijn.
> 
> --
> Martijn Vandegehuchte
> Ghent University
> Department Biology
> Terrestrial Ecology Unit
> K.L.Ledeganckstraat 35
> B-9000 Ghent
> telephone: +32 (0)9/264 50 84
> e-mail: martijn.vandegehuchte at ugent.be 
> 
> website TEREC: www.ecology.ugent.be/terec
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From Greg.Snow at imail.org  Tue Oct  7 18:44:51 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 7 Oct 2008 10:44:51 -0600
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when	using glmmPQL or lmer with laplace approximation
In-Reply-To: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6157DA5052@LP-EXMBVS10.CO.IHC.COM>

Martijn,

Absolute truth is the realm of pure mathematics, philosophy, and religion.  R deals with statistics where we are more concerned with usefulness than absolute correctness.

One famous quote among statisticians is: "All models are wrong, some models are useful".

Given that, I would suggest looking at the quality of the predictions from your models.  Get predicted values from the 2 different fits and compare them to each other and the original data.  If one set of predictions is clearly superior, then you have your answer.  If the predictions are not that different, then that can tell you that possibly there are multiple models that are equally useful for this data.  Then you can look at the predictions from models fit with fewer predictors to see how that affects the predictions.

Hope this helps,

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Martijn Vandegehuchte
> Sent: Tuesday, October 07, 2008 7:21 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] generalized linear mixed models: large differences
> when using glmmPQL or lmer with laplace approximation
>
> Dear list,
>
> First of all, I am a mere ecologist, trying to get the truth out of his
> data, and not a statistician, so forgive me my lack of statistical
> background and possible conceptual misunderstandings.
>
> I am currently comparing generalized linear mixed models in glmmPQL and
> lmer, with a quasipoisson family, and have found out that parameter
> estimates are quite different for both methods. I read some of the
> discussions on the R-forum and it seems that the Laplace approximation
> used in the current version of lmer is generally preferred to the PQL
> method. I am an ex-SAS user, and in proc glimmix in SAS the default is
> PQL, and the estimates and p-values are almost exact the same as with
> glmmPQL in R. But lmer gives quite different results, and now I am
> wondering what would be the best option for me.
>
> First of all, parameter estimates of a same model can be somewhat
> different in lmer or glmmPQL. Second of all, in lmer, I only get t-
> values but no associated p-values (apparently they are omitted because
> of the uncertainty about the df). But if I compare the t-values
> generated by glmmPQL with those of a same model in lmer, the
> differences are substantial. My dataset consists of 120 observations,
> so basically you could guess the order of magnitude of the p-values in
> lmer based on the t-value and a "large" df.
>
> First example:
> In lmer:
>
> > model<-
> lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1|site),family=qua
> sipoisson)
> > summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: schirufu ~ diameter + leafvit + densroot + cover + nemcm + (1
> |      site)
>   AIC  BIC logLik deviance
>  2045 2068  -1015     2029
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept) 12.700   3.5638
>  Residual             15.182   3.8964
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  1.31017    1.47249   0.890
> diameter    -0.24799    0.29180  -0.850
> leafvit      1.29007    0.21041   6.131
> densroot     0.31024    0.04939   6.281
> cover       -0.24544    0.22179  -1.107
> nemcm        0.24817    0.12028   2.063
>
> Correlation of Fixed Effects:
>          (Intr) diamtr leafvt densrt cover
> diameter  0.031
> leafvit  -0.083  0.321
> densroot  0.011 -0.017 -0.202
> cover     0.021 -0.448  0.016  0.214
> nemcm    -0.014  0.114  0.114  0.310 -0.017
> >
>
> Although no p-values are given, it suggests that fixed effects leafvit,
> densroot and nemcm would be significant.
> In glmmPQL:
>
> > model<-
> glmmPQL(schirufu~diameter+leafvit+densroot+cover+nemcm,random=~1|site,f
> amily=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
> > summary(model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>   AIC BIC logLik
>    NA  NA     NA
>
> Random effects:
>  Formula: ~1 | site
>         (Intercept) Residual
> StdDev:   0.7864989  4.63591
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: schirufu ~ diameter + leafvit + densroot + cover + nemcm
>                  Value Std.Error  DF   t-value p-value
> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
> densroot     0.3236446 0.0596342 109  5.427164  0.0000
> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
>  Correlation:
>          (Intr) diamtr leafvt densrt cover
> diameter  0.130
> leafvit  -0.335  0.313
> densroot  0.027 -0.022 -0.203
> cover     0.090 -0.463  0.015  0.214
> nemcm    -0.056  0.097  0.107  0.301 -0.014
>
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928
>
> Number of Observations: 120
> Number of Groups: 6
> >
>
> Note the difference in parameter estimates. Also, the fixed effect
> nemcm now is not significant any more.
>
> Second example,now with an offset:
> In lmer:
>
> > model<-
> lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+(1|site),
> offset= loglength, family=quasipoisson)
> > summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + cover +
> schirufu +      (1 | site)
>   AIC  BIC logLik deviance
>  1593 1618 -787.4     1575
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept)  21.522   4.6392
>  Residual             173.888  13.1867
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  0.06733    1.92761  0.0349
> diameter     0.14665    0.60693  0.2416
> leafvit     -0.19902    0.48802 -0.4078
> densroot    -0.49178    0.64221 -0.7658
> rootvit      0.37699    0.46810  0.8054
> cover       -0.23545    0.57896 -0.4067
> schirufu     0.23226    0.46866  0.4956
>
> Correlation of Fixed Effects:
>          (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.016
> leafvit   0.015  0.396
> densroot  0.055 -0.233 -0.291
> rootvit  -0.038 -0.251 -0.629  0.277
> cover     0.024 -0.796 -0.133  0.253  0.117
> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
> >
>
> This suggests no significant effects at all.
> In glmmPQL:
>
> > model<-
> glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+offset(l
> oglength),random=~1|site, family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> > summary (model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>   AIC BIC logLik
>    NA  NA     NA
>
> Random effects:
>  Formula: ~1 | site
>         (Intercept) Residual
> StdDev:   0.2684477 4.507758
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: nemcm ~ diameter + leafvit + densroot + rootvit + cover
> + schirufu +      offset(loglength)
>                  Value Std.Error  DF    t-value p-value
> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
>  Correlation:
>          (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.050
> leafvit   0.077  0.360
> densroot  0.217 -0.168 -0.262
> rootvit  -0.163 -0.202 -0.632  0.257
> cover     0.084 -0.772 -0.098  0.200  0.073
> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
>
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368
>
> Number of Observations: 120
> Number of Groups: 6
> >
>
> Again some differences in parameter estimates, but now the two fixed
> effects densroot and rootvit turn out to be significant.
> So my questions are:
> - what would you recommend me to use? lmer or glmmPQL (laplace
> approximation or penalized quasi-likelihood)?
> - if lmer is the better option, is there a way to get a reliable p-
> value for the fixed effects?
> I have experienced that deleting a term and comparing models using
> anova() always overestimates the significance of that term, probably
> because the quasipoisson correction for overdispersion is not taken
> into account.
>
> Thank you very much beforehand,
>
> Martijn.
>
> --
> Martijn Vandegehuchte
> Ghent University
> Department Biology
> Terrestrial Ecology Unit
> K.L.Ledeganckstraat 35
> B-9000 Ghent
> telephone: +32 (0)9/264 50 84
> e-mail: martijn.vandegehuchte at ugent.be
>
> website TEREC: www.ecology.ugent.be/terec
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Tue Oct  7 19:21:12 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 07 Oct 2008 13:21:12 -0400
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when	using glmmPQL or lmer with laplace approximation
In-Reply-To: <DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
References: <559E1B0449214BB483273F44A927D926@Mythimna>
	<48EB7DEC.6070306@ufl.edu>
	<DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
Message-ID: <48EB9A88.4030207@ufl.edu>

Martijn Vandegehuchte wrote:
> First of all, thanks a lot for the info.
> 
> I know the differences seem small, but most ecological journals still
> let their opinion about ecological relevance of predictors depend
> completely on p-values... So I think I'll stick to lmer because of the
> Laplace approximation.
> 
> But I don't really know what you mean by: "If you are happy with the df
> given by lme you can use them ... this corresponds to the
> "between-within" option in SAS, Satterthwaite et al. are not available
> in R." I'm familiar to Satterthwaite's correction for the ddfm, I use it
> in SAS proc glimmix, but then I'm stuck with PQL again... But for my
> data the degrees of freedom should be large enough that it doesn't make
> that much of a difference. I just tested the same models in SAS proc
> glimmix, with and without Satterthwaite, and there's no difference. So
> if there is a way of getting the df to obtain a p-value in lmer, I would
> do so.

> 
> Then (maybe stupid) question is: how do I get the df? You mention lme,
> but can I make the same models in lme?
> 
> Thanks again,
> 

  Sorry, I meant glmmPQL -- glmmPQL basically calls lme as a back end,
so "df from lme" is the same as "df from lme".  You can either take
those df (I believe in your case it was 120 (total samples) - 6 (sites)
- 6 (est. fixed parameters) = 108, or run SAS with Satterthwaite and
see what it says df should be.  If you then have a t statistic you
can estimate its (two-tailed) p value with

pt(tstat,df,lower.tail=FALSE)*2

[you can try this on the lme values and see if you get the
right answers]

  Ben Bolker



From bolker at ufl.edu  Tue Oct  7 19:43:37 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 07 Oct 2008 13:43:37 -0400
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when	using glmmPQL or lmer with laplace approximation
In-Reply-To: <DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
References: <559E1B0449214BB483273F44A927D926@Mythimna>
	<48EB7DEC.6070306@ufl.edu>
	<DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
Message-ID: <48EB9FC9.3060101@ufl.edu>

Martijn Vandegehuchte wrote:
> First of all, thanks a lot for the info.
> 
> I know the differences seem small, but most ecological journals still
> let their opinion about ecological relevance of predictors depend
> completely on p-values... So I think I'll stick to lmer because of the
> Laplace approximation.

  Well, Laplace should be better anyway.  (If the difference were in
the other direction -- non-significant with Laplace and significant with
glmmPQL -- I would still tell you to use Laplace.)

  To speak to Greg Snow's comment ("don't worry about p-values, just
look at predictions") -- this is really tough.  I still don't know
what to do about the compromise between how statistics should be done
and how journal editors seem to insist it should be done ...

  cheers
   Ben



From Greg.Snow at imail.org  Tue Oct  7 20:31:20 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 7 Oct 2008 12:31:20 -0600
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when	using glmmPQL or lmer with laplace approximation
In-Reply-To: <48EB9FC9.3060101@ufl.edu>
References: <559E1B0449214BB483273F44A927D926@Mythimna>
	<48EB7DEC.6070306@ufl.edu>	<DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
	<48EB9FC9.3060101@ufl.edu>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6157DA511E@LP-EXMBVS10.CO.IHC.COM>

You make reference to my comment below, but I think you overstate my position a bit (the words in quotes are not a direct quote of what I said).

The original poster mentioned that 2 different methods gave 2 different models, one possibility is that one method gave a wrong model (biased in a non-good way), another possibility is that the predictor variables are correlated enough that there are multiple good models.  I merely pointed out that comparing the predicted values to the original values would be one way to possibly distinguish between the 2 cases.

Focusing too much on the predicted values can lead to overfitting, so we should not depend only on that.  P-values are useful in some cases, so I would not say "don't worry about the p-values" as a general statement.

The issue of editors wanting p-values even when they answer the wrong question is part of the result of statisticians doing to good a job of training other researchers.  Now it is our responsibility to continue to train them as to when to use certain tools.

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Tuesday, October 07, 2008 11:44 AM
> To: Martijn Vandegehuchte; R Mixed Models
> Subject: Re: [R-sig-ME] generalized linear mixed models: large
> differences when using glmmPQL or lmer with laplace approximation
>
> Martijn Vandegehuchte wrote:
> > First of all, thanks a lot for the info.
> >
> > I know the differences seem small, but most ecological journals still
> > let their opinion about ecological relevance of predictors depend
> > completely on p-values... So I think I'll stick to lmer because of
> the
> > Laplace approximation.
>
>   Well, Laplace should be better anyway.  (If the difference were in
> the other direction -- non-significant with Laplace and significant
> with
> glmmPQL -- I would still tell you to use Laplace.)
>
>   To speak to Greg Snow's comment ("don't worry about p-values, just
> look at predictions") -- this is really tough.  I still don't know
> what to do about the compromise between how statistics should be done
> and how journal editors seem to insist it should be done ...
>
>   cheers
>    Ben
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Oct  7 22:59:38 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 15:59:38 -0500
Subject: [R-sig-ME] generalized linear mixed models: large differences
	when using glmmPQL or lmer with laplace approximation
In-Reply-To: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
Message-ID: <40e66e0b0810071359h23f3cc13u27bc167c34475d5c@mail.gmail.com>

Due to some travel and the need to attend to other projects, I haven't
been keeping up as closely with this list as I normally do.  Regarding
the comparison between the PQL and Laplace methods for fitting
generalized linear mixed models, I believe that the estimates produced
by the Laplace method are more reliable than those from the PQL
method.  The objective function optimized by the Laplace method is a
direct approxmation, and generally a very good approximation, to the
log-likelihood for the model being fit.  The PQL method is indirect
(the "QL" part of the name stands for "quasi-likelihood") and, because
it involves alternating conditional optimization, can alternate
back-and-forth between two potential solutions, neither of which is
optimal.  (To be fair, such alternating occurs more frequently in the
analogous method for nonlinear mixed-models, in which I was one of the
co-conspirators, than in the PQL method for GLMMs.)

It may be that the problem you are encountering has more to do with
the use of the quasipoisson family than with the Laplace
approximation.  I am not sure that the derivation of the standard
errors in lmer when using the quasipoisson family is correct, in part
because I don't really understand the quasipoisson and quasibinomial
families.  As far as I know, they don't correspond to probability
distributions so the theory is a bit iffy.

Do you need to use the quasipoisson family or could you use the
poisson family?  Generally the motivation for the quasipoisson familiy
is to accomodate overdispersion.  Often in a generalized linear mixed
model the problem is underdispersion rather than overdispersion.

In one of Ben's replies in this thread he discusses the degrees of
freedom attributed to certain t-statistics.  Regular readers of this
list are aware that degrees of freedom is one of my least favorite
topics.  If one has a reasonably large number of observations and a
reasonably large number of groups then the issue is unimportant.
(Uncertainty in degrees of freedom is important only when the value of
the degrees of freedom is small.  In fact, when I first started
studying statistics we used the standard normal in place of the
t-distribution whenever the degrees of freedom exceeded 30).
Considering that the quasi-Poisson doesn't correspond to a probability
distribution in the first place, (readers should feel free to correct
me if I am wrong about this) I find the issue of the number of degrees
of freedom that should be attributed to a distribution of a quantity
calculated from a non-existent distribution to be somewhat off the
point.

I think the problem is more likely that the standard errors are not
being calculated correctly.  Is that what you concluded from your
simulations, Ben?

On Tue, Oct 7, 2008 at 8:21 AM, Martijn Vandegehuchte
<martijn.vandegehuchte at ugent.be> wrote:
> Dear list,

> First of all, I am a mere ecologist, trying to get the truth out of his data, and not a statistician, so forgive me my lack of statistical background and possible conceptual misunderstandings.

> I am currently comparing generalized linear mixed models in glmmPQL and lmer, with a quasipoisson family, and have found out that parameter estimates are quite different for both methods. I read some of the discussions on the R-forum and it seems that the Laplace approximation used in the current version of lmer is generally preferred to the PQL method. I am an ex-SAS user, and in proc glimmix in SAS the default is PQL, and the estimates and p-values are almost exact the same as with glmmPQL in R. But lmer gives quite different results, and now I am wondering what would be the best option for me.

> First of all, parameter estimates of a same model can be somewhat different in lmer or glmmPQL. Second of all, in lmer, I only get t-values but no associated p-values (apparently they are omitted because of the uncertainty about the df). But if I compare the t-values generated by glmmPQL with those of a same model in lmer, the differences are substantial. My dataset consists of 120 observations, so basically you could guess the order of magnitude of the p-values in lmer based on the t-value and a "large" df.

> First example:
> In lmer:
>
>> model<-lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1|site),family=quasipoisson)
>> summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: schirufu ~ diameter + leafvit + densroot + cover + nemcm + (1 |      site)
>  AIC  BIC logLik deviance
>  2045 2068  -1015     2029
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept) 12.700   3.5638
>  Residual             15.182   3.8964
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  1.31017    1.47249   0.890
> diameter    -0.24799    0.29180  -0.850
> leafvit      1.29007    0.21041   6.131
> densroot     0.31024    0.04939   6.281
> cover       -0.24544    0.22179  -1.107
> nemcm        0.24817    0.12028   2.063
>
> Correlation of Fixed Effects:
>         (Intr) diamtr leafvt densrt cover
> diameter  0.031
> leafvit  -0.083  0.321
> densroot  0.011 -0.017 -0.202
> cover     0.021 -0.448  0.016  0.214
> nemcm    -0.014  0.114  0.114  0.310 -0.017
>>
>
> Although no p-values are given, it suggests that fixed effects leafvit, densroot and nemcm would be significant.
> In glmmPQL:
>
>> model<-glmmPQL(schirufu~diameter+leafvit+densroot+cover+nemcm,random=~1|site,family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
>> summary(model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>  AIC BIC logLik
>   NA  NA     NA
>
> Random effects:
>  Formula: ~1 | site
>        (Intercept) Residual
> StdDev:   0.7864989  4.63591
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: schirufu ~ diameter + leafvit + densroot + cover + nemcm
>                 Value Std.Error  DF   t-value p-value
> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
> densroot     0.3236446 0.0596342 109  5.427164  0.0000
> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
>  Correlation:
>         (Intr) diamtr leafvt densrt cover
> diameter  0.130
> leafvit  -0.335  0.313
> densroot  0.027 -0.022 -0.203
> cover     0.090 -0.463  0.015  0.214
> nemcm    -0.056  0.097  0.107  0.301 -0.014
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928
>
> Number of Observations: 120
> Number of Groups: 6
>>
>
> Note the difference in parameter estimates. Also, the fixed effect nemcm now is not significant any more.
>
> Second example,now with an offset:
> In lmer:
>
>> model<-lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+(1|site), offset= loglength, family=quasipoisson)
>> summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + cover + schirufu +      (1 | site)
>  AIC  BIC logLik deviance
>  1593 1618 -787.4     1575
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  site     (Intercept)  21.522   4.6392
>  Residual             173.888  13.1867
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  0.06733    1.92761  0.0349
> diameter     0.14665    0.60693  0.2416
> leafvit     -0.19902    0.48802 -0.4078
> densroot    -0.49178    0.64221 -0.7658
> rootvit      0.37699    0.46810  0.8054
> cover       -0.23545    0.57896 -0.4067
> schirufu     0.23226    0.46866  0.4956
>
> Correlation of Fixed Effects:
>         (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.016
> leafvit   0.015  0.396
> densroot  0.055 -0.233 -0.291
> rootvit  -0.038 -0.251 -0.629  0.277
> cover     0.024 -0.796 -0.133  0.253  0.117
> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
>>
>
> This suggests no significant effects at all.
> In glmmPQL:
>
>> model<-glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+offset(loglength),random=~1|site, family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
>> summary (model)
> Linear mixed-effects model fit by maximum likelihood
>  Data: NULL
>  AIC BIC logLik
>   NA  NA     NA
>
> Random effects:
>  Formula: ~1 | site
>        (Intercept) Residual
> StdDev:   0.2684477 4.507758
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: nemcm ~ diameter + leafvit + densroot + rootvit + cover + schirufu +      offset(loglength)
>                 Value Std.Error  DF    t-value p-value
> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
>  Correlation:
>         (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.050
> leafvit   0.077  0.360
> densroot  0.217 -0.168 -0.262
> rootvit  -0.163 -0.202 -0.632  0.257
> cover     0.084 -0.772 -0.098  0.200  0.073
> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368
>
> Number of Observations: 120
> Number of Groups: 6
>>
>
> Again some differences in parameter estimates, but now the two fixed effects densroot and rootvit turn out to be significant.
> So my questions are:
> - what would you recommend me to use? lmer or glmmPQL (laplace approximation or penalized quasi-likelihood)?
> - if lmer is the better option, is there a way to get a reliable p-value for the fixed effects?
> I have experienced that deleting a term and comparing models using anova() always overestimates the significance of that term, probably because the quasipoisson correction for overdispersion is not taken into account.
>
> Thank you very much beforehand,
>
> Martijn.
>
> --
> Martijn Vandegehuchte
> Ghent University
> Department Biology
> Terrestrial Ecology Unit
> K.L.Ledeganckstraat 35
> B-9000 Ghent
> telephone: +32 (0)9/264 50 84
> e-mail: martijn.vandegehuchte at ugent.be
>
> website TEREC: www.ecology.ugent.be/terec
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ken at kjbeath.com.au  Tue Oct  7 23:07:50 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 8 Oct 2008 08:07:50 +1100
Subject: [R-sig-ME] generalized linear mixed models: large differences
	when using glmmPQL or lmer with laplace approximation
In-Reply-To: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
Message-ID: <96A80D27-185D-4AC7-AA29-69AE4B3F3A3A@kjbeath.com.au>

There is a large difference between the estimated std of the random  
effect, usually a sign that the glmmPQL approximation isn't working.

I would try using adaptive Gauss-Hermite. Set the nAGQ parameter to  
increasing values until the results stabilise.

Ken

On 08/10/2008, at 12:21 AM, Martijn Vandegehuchte wrote:

> Dear list,
>
> First of all, I am a mere ecologist, trying to get the truth out of  
> his data, and not a statistician, so forgive me my lack of  
> statistical background and possible conceptual misunderstandings.
>
> I am currently comparing generalized linear mixed models in glmmPQL  
> and lmer, with a quasipoisson family, and have found out that  
> parameter estimates are quite different for both methods. I read  
> some of the discussions on the R-forum and it seems that the Laplace  
> approximation used in the current version of lmer is generally  
> preferred to the PQL method. I am an ex-SAS user, and in proc  
> glimmix in SAS the default is PQL, and the estimates and p-values  
> are almost exact the same as with glmmPQL in R. But lmer gives quite  
> different results, and now I am wondering what would be the best  
> option for me.
>
> First of all, parameter estimates of a same model can be somewhat  
> different in lmer or glmmPQL. Second of all, in lmer, I only get t- 
> values but no associated p-values (apparently they are omitted  
> because of the uncertainty about the df). But if I compare the t- 
> values generated by glmmPQL with those of a same model in lmer, the  
> differences are substantial. My dataset consists of 120  
> observations, so basically you could guess the order of magnitude of  
> the p-values in lmer based on the t-value and a "large" df.
>
> First example:
> In lmer:
>
>> model<-lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1| 
>> site),family=quasipoisson)
>> summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: schirufu ~ diameter + leafvit + densroot + cover + nemcm +  
> (1 |      site)
>  AIC  BIC logLik deviance
> 2045 2068  -1015     2029
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 12.700   3.5638
> Residual             15.182   3.8964
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  1.31017    1.47249   0.890
> diameter    -0.24799    0.29180  -0.850
> leafvit      1.29007    0.21041   6.131
> densroot     0.31024    0.04939   6.281
> cover       -0.24544    0.22179  -1.107
> nemcm        0.24817    0.12028   2.063
>
> Correlation of Fixed Effects:
>         (Intr) diamtr leafvt densrt cover
> diameter  0.031
> leafvit  -0.083  0.321
> densroot  0.011 -0.017 -0.202
> cover     0.021 -0.448  0.016  0.214
> nemcm    -0.014  0.114  0.114  0.310 -0.017
>>
>
> Although no p-values are given, it suggests that fixed effects  
> leafvit, densroot and nemcm would be significant.
> In glmmPQL:
>
>> model<-glmmPQL(schirufu~diameter+leafvit+densroot+cover 
>> +nemcm,random=~1|site,family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
>> summary(model)
> Linear mixed-effects model fit by maximum likelihood
> Data: NULL
>  AIC BIC logLik
>   NA  NA     NA
>
> Random effects:
> Formula: ~1 | site
>        (Intercept) Residual
> StdDev:   0.7864989  4.63591
>
> Variance function:
> Structure: fixed weights
> Formula: ~invwt
> Fixed effects: schirufu ~ diameter + leafvit + densroot + cover +  
> nemcm
>                 Value Std.Error  DF   t-value p-value
> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
> densroot     0.3236446 0.0596342 109  5.427164  0.0000
> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
> Correlation:
>         (Intr) diamtr leafvt densrt cover
> diameter  0.130
> leafvit  -0.335  0.313
> densroot  0.027 -0.022 -0.203
> cover     0.090 -0.463  0.015  0.214
> nemcm    -0.056  0.097  0.107  0.301 -0.014
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928
>
> Number of Observations: 120
> Number of Groups: 6
>>
>
> Note the difference in parameter estimates. Also, the fixed effect  
> nemcm now is not significant any more.
>
> Second example,now with an offset:
> In lmer:
>
>> model<-lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu 
>> +(1|site), offset= loglength, family=quasipoisson)
>> summary (model)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + cover +  
> schirufu +      (1 | site)
>  AIC  BIC logLik deviance
> 1593 1618 -787.4     1575
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept)  21.522   4.6392
> Residual             173.888  13.1867
> Number of obs: 120, groups: site, 6
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  0.06733    1.92761  0.0349
> diameter     0.14665    0.60693  0.2416
> leafvit     -0.19902    0.48802 -0.4078
> densroot    -0.49178    0.64221 -0.7658
> rootvit      0.37699    0.46810  0.8054
> cover       -0.23545    0.57896 -0.4067
> schirufu     0.23226    0.46866  0.4956
>
> Correlation of Fixed Effects:
>         (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.016
> leafvit   0.015  0.396
> densroot  0.055 -0.233 -0.291
> rootvit  -0.038 -0.251 -0.629  0.277
> cover     0.024 -0.796 -0.133  0.253  0.117
> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
>>
>
> This suggests no significant effects at all.
> In glmmPQL:
>
>> model<-glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover 
>> +schirufu+offset(loglength),random=~1|site, family=quasipoisson)
> iteration 1
> iteration 2
> iteration 3
>> summary (model)
> Linear mixed-effects model fit by maximum likelihood
> Data: NULL
>  AIC BIC logLik
>   NA  NA     NA
>
> Random effects:
> Formula: ~1 | site
>        (Intercept) Residual
> StdDev:   0.2684477 4.507758
>
> Variance function:
> Structure: fixed weights
> Formula: ~invwt
> Fixed effects: nemcm ~ diameter + leafvit + densroot + rootvit +  
> cover + schirufu +      offset(loglength)
>                 Value Std.Error  DF    t-value p-value
> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
> Correlation:
>         (Intr) diamtr leafvt densrt rootvt cover
> diameter -0.050
> leafvit   0.077  0.360
> densroot  0.217 -0.168 -0.262
> rootvit  -0.163 -0.202 -0.632  0.257
> cover     0.084 -0.772 -0.098  0.200  0.073
> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
>
> Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368
>
> Number of Observations: 120
> Number of Groups: 6
>>
>
> Again some differences in parameter estimates, but now the two fixed  
> effects densroot and rootvit turn out to be significant.
> So my questions are:
> - what would you recommend me to use? lmer or glmmPQL (laplace  
> approximation or penalized quasi-likelihood)?
> - if lmer is the better option, is there a way to get a reliable p- 
> value for the fixed effects?
> I have experienced that deleting a term and comparing models using  
> anova() always overestimates the significance of that term, probably  
> because the quasipoisson correction for overdispersion is not taken  
> into account.
>
> Thank you very much beforehand,
>
> Martijn.
>
> -- 
> Martijn Vandegehuchte
> Ghent University
> Department Biology
> Terrestrial Ecology Unit
> K.L.Ledeganckstraat 35
> B-9000 Ghent
> telephone: +32 (0)9/264 50 84
> e-mail: martijn.vandegehuchte at ugent.be
>
> website TEREC: www.ecology.ugent.be/terec
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue Oct  7 23:12:51 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 16:12:51 -0500
Subject: [R-sig-ME] how to extract the values in the nlme package?
In-Reply-To: <493275.79661.qm@web15601.mail.cnb.yahoo.com>
References: <493275.79661.qm@web15601.mail.cnb.yahoo.com>
Message-ID: <40e66e0b0810071412s61fe6f71we18b96db9c8046f8@mail.gmail.com>

On Tue, Oct 7, 2008 at 2:06 AM, Ming Liu <dannyliu1002 at yahoo.com.cn> wrote:
> Dear friends,
>
>  I take a lm for an example.
>>
>> Call:
>> lm(formula = weight ~ group)
>> Residuals:
>>     Min      1Q  Median      3Q     Max
>> -1.0710 -0.4938  0.0685  0.2462  1.3690
>> Coefficients:
>>             Estimate Std. Error t value Pr(>|t|)
>> (Intercept)   5.0320     0.2202  22.850 9.55e-15 ***
>> groupTrt     -0.3710     0.3114  -1.191    0.249
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> Residual standard error: 0.6964 on 18 degrees of freedom
>> Multiple R-squared: 0.07308,    Adjusted R-squared: 0.02158
>> F-statistic: 1.419 on 1 and 18 DF,  p-value: 0.249
>  I can use the commands (summary(lm.D9)$r.squared,
> summary(lm.D9)$coef[1,4]) to extract the values(r.squared, p-value)
>  from the above result.

But that only works if there are components named r.squared and coef
in the object returned by the summary method and it really has nothing
to do with the object returned by an nlme or lme fit.  If you want the
estimate of the standard deviation of the random effects, you should
look at

> library(nlme)
> ?VarCorr
> example(VarCorr)

VarCrr> fm1 <- lme(distance ~ age, data = Orthodont, random = ~age)

VarCrr> VarCorr(fm1)
Subject = pdLogChol(age)
            Variance   StdDev    Corr
(Intercept) 5.41508751 2.3270341 (Intr)
age         0.05126955 0.2264278 -0.609
Residual    1.71620400 1.3100397

It happens that the object returned by VarCorr is a character matrix
(not a really great design, I must admit) so you would need to use
something like

as.numeric(VarCorr(fm1)["(Intercept)", "StdDev"])

to get the numeric value.

>  So, in your package I want to extract the values the StdDev of Random
>  effects, could you give me a hand ?  Thank you so much indeed.
>
>
>
> Best wishes,
>
>  Danny
>
>
>
> ---------------------------------
>  ????????????
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

From bates at stat.wisc.edu  Tue Oct  7 23:18:42 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 16:18:42 -0500
Subject: [R-sig-ME] generalized linear mixed models: large differences
	when using glmmPQL or lmer with laplace approximation
In-Reply-To: <96A80D27-185D-4AC7-AA29-69AE4B3F3A3A@kjbeath.com.au>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
	<96A80D27-185D-4AC7-AA29-69AE4B3F3A3A@kjbeath.com.au>
Message-ID: <40e66e0b0810071418s57931113ne07fb62aee288f7e@mail.gmail.com>

On Tue, Oct 7, 2008 at 4:07 PM, Ken Beath <ken at kjbeath.com.au> wrote:
> There is a large difference between the estimated std of the random effect,
> usually a sign that the glmmPQL approximation isn't working.

Or that there is a mistake in the calculation of the standard errors
for the random effects, which is more likely in this case.

The actual optimization is with respect to the relative standard
deviation of the random effects (relative to the scale parameter in
the conditional standard deviation of the response).  For the Poisson
family or the binomial family that scale parameter is fixed at 1 (you
could also consider the situation to be that there isn't a scale
parameter in those cases).  For the quasipoisson and quasibinomial
families you maybe estimate a value there or maybe not.  I don't know.
 I believe Ben's simulations showed that I was doing the wrong thing
there.

> I would try using adaptive Gauss-Hermite. Set the nAGQ parameter to
> increasing values until the results stabilise.
>
> Ken
>
> On 08/10/2008, at 12:21 AM, Martijn Vandegehuchte wrote:
>
>> Dear list,
>>
>> First of all, I am a mere ecologist, trying to get the truth out of his
>> data, and not a statistician, so forgive me my lack of statistical
>> background and possible conceptual misunderstandings.
>>
>> I am currently comparing generalized linear mixed models in glmmPQL and
>> lmer, with a quasipoisson family, and have found out that parameter
>> estimates are quite different for both methods. I read some of the
>> discussions on the R-forum and it seems that the Laplace approximation used
>> in the current version of lmer is generally preferred to the PQL method. I
>> am an ex-SAS user, and in proc glimmix in SAS the default is PQL, and the
>> estimates and p-values are almost exact the same as with glmmPQL in R. But
>> lmer gives quite different results, and now I am wondering what would be the
>> best option for me.
>>
>> First of all, parameter estimates of a same model can be somewhat
>> different in lmer or glmmPQL. Second of all, in lmer, I only get t-values
>> but no associated p-values (apparently they are omitted because of the
>> uncertainty about the df). But if I compare the t-values generated by
>> glmmPQL with those of a same model in lmer, the differences are substantial.
>> My dataset consists of 120 observations, so basically you could guess the
>> order of magnitude of the p-values in lmer based on the t-value and a
>> "large" df.
>>
>> First example:
>> In lmer:
>>
>>>
>>> model<-lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1|site),family=quasipoisson)
>>> summary (model)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: schirufu ~ diameter + leafvit + densroot + cover + nemcm + (1 |
>>    site)
>>  AIC  BIC logLik deviance
>> 2045 2068  -1015     2029
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept) 12.700   3.5638
>> Residual             15.182   3.8964
>> Number of obs: 120, groups: site, 6
>>
>> Fixed effects:
>>           Estimate Std. Error t value
>> (Intercept)  1.31017    1.47249   0.890
>> diameter    -0.24799    0.29180  -0.850
>> leafvit      1.29007    0.21041   6.131
>> densroot     0.31024    0.04939   6.281
>> cover       -0.24544    0.22179  -1.107
>> nemcm        0.24817    0.12028   2.063
>>
>> Correlation of Fixed Effects:
>>        (Intr) diamtr leafvt densrt cover
>> diameter  0.031
>> leafvit  -0.083  0.321
>> densroot  0.011 -0.017 -0.202
>> cover     0.021 -0.448  0.016  0.214
>> nemcm    -0.014  0.114  0.114  0.310 -0.017
>>>
>>
>> Although no p-values are given, it suggests that fixed effects leafvit,
>> densroot and nemcm would be significant.
>> In glmmPQL:
>>
>>>
>>> model<-glmmPQL(schirufu~diameter+leafvit+densroot+cover+nemcm,random=~1|site,family=quasipoisson)
>>
>> iteration 1
>> iteration 2
>> iteration 3
>> iteration 4
>> iteration 5
>>>
>>> summary(model)
>>
>> Linear mixed-effects model fit by maximum likelihood
>> Data: NULL
>>  AIC BIC logLik
>>  NA  NA     NA
>>
>> Random effects:
>> Formula: ~1 | site
>>       (Intercept) Residual
>> StdDev:   0.7864989  4.63591
>>
>> Variance function:
>> Structure: fixed weights
>> Formula: ~invwt
>> Fixed effects: schirufu ~ diameter + leafvit + densroot + cover + nemcm
>>                Value Std.Error  DF   t-value p-value
>> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
>> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
>> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
>> densroot     0.3236446 0.0596342 109  5.427164  0.0000
>> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
>> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
>> Correlation:
>>        (Intr) diamtr leafvt densrt cover
>> diameter  0.130
>> leafvit  -0.335  0.313
>> densroot  0.027 -0.022 -0.203
>> cover     0.090 -0.463  0.015  0.214
>> nemcm    -0.056  0.097  0.107  0.301 -0.014
>>
>> Standardized Within-Group Residuals:
>>      Min         Q1        Med         Q3        Max
>> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928
>>
>> Number of Observations: 120
>> Number of Groups: 6
>>>
>>
>> Note the difference in parameter estimates. Also, the fixed effect nemcm
>> now is not significant any more.
>>
>> Second example,now with an offset:
>> In lmer:
>>
>>>
>>> model<-lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+(1|site),
>>> offset= loglength, family=quasipoisson)
>>> summary (model)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + cover +
>> schirufu +      (1 | site)
>>  AIC  BIC logLik deviance
>> 1593 1618 -787.4     1575
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept)  21.522   4.6392
>> Residual             173.888  13.1867
>> Number of obs: 120, groups: site, 6
>>
>> Fixed effects:
>>           Estimate Std. Error t value
>> (Intercept)  0.06733    1.92761  0.0349
>> diameter     0.14665    0.60693  0.2416
>> leafvit     -0.19902    0.48802 -0.4078
>> densroot    -0.49178    0.64221 -0.7658
>> rootvit      0.37699    0.46810  0.8054
>> cover       -0.23545    0.57896 -0.4067
>> schirufu     0.23226    0.46866  0.4956
>>
>> Correlation of Fixed Effects:
>>        (Intr) diamtr leafvt densrt rootvt cover
>> diameter -0.016
>> leafvit   0.015  0.396
>> densroot  0.055 -0.233 -0.291
>> rootvit  -0.038 -0.251 -0.629  0.277
>> cover     0.024 -0.796 -0.133  0.253  0.117
>> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
>>>
>>
>> This suggests no significant effects at all.
>> In glmmPQL:
>>
>>>
>>> model<-glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+offset(loglength),random=~1|site,
>>> family=quasipoisson)
>>
>> iteration 1
>> iteration 2
>> iteration 3
>>>
>>> summary (model)
>>
>> Linear mixed-effects model fit by maximum likelihood
>> Data: NULL
>>  AIC BIC logLik
>>  NA  NA     NA
>>
>> Random effects:
>> Formula: ~1 | site
>>       (Intercept) Residual
>> StdDev:   0.2684477 4.507758
>>
>> Variance function:
>> Structure: fixed weights
>> Formula: ~invwt
>> Fixed effects: nemcm ~ diameter + leafvit + densroot + rootvit + cover +
>> schirufu +      offset(loglength)
>>                Value Std.Error  DF    t-value p-value
>> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
>> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
>> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
>> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
>> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
>> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
>> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
>> Correlation:
>>        (Intr) diamtr leafvt densrt rootvt cover
>> diameter -0.050
>> leafvit   0.077  0.360
>> densroot  0.217 -0.168 -0.262
>> rootvit  -0.163 -0.202 -0.632  0.257
>> cover     0.084 -0.772 -0.098  0.200  0.073
>> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
>>
>> Standardized Within-Group Residuals:
>>      Min         Q1        Med         Q3        Max
>> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368
>>
>> Number of Observations: 120
>> Number of Groups: 6
>>>
>>
>> Again some differences in parameter estimates, but now the two fixed
>> effects densroot and rootvit turn out to be significant.
>> So my questions are:
>> - what would you recommend me to use? lmer or glmmPQL (laplace
>> approximation or penalized quasi-likelihood)?
>> - if lmer is the better option, is there a way to get a reliable p-value
>> for the fixed effects?
>> I have experienced that deleting a term and comparing models using anova()
>> always overestimates the significance of that term, probably because the
>> quasipoisson correction for overdispersion is not taken into account.
>>
>> Thank you very much beforehand,
>>
>> Martijn.
>>
>> --
>> Martijn Vandegehuchte
>> Ghent University
>> Department Biology
>> Terrestrial Ecology Unit
>> K.L.Ledeganckstraat 35
>> B-9000 Ghent
>> telephone: +32 (0)9/264 50 84
>> e-mail: martijn.vandegehuchte at ugent.be
>>
>> website TEREC: www.ecology.ugent.be/terec
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue Oct  7 23:35:01 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 16:35:01 -0500
Subject: [R-sig-ME] Fw: mcmcsamp(lme4): What is contained in $ST and
	$sigma?
In-Reply-To: <OFCC9B63F9.C6AA3CED-ON862574D7.0067C409-862574D7.0067F529@abbott.com>
References: <OFCC9B63F9.C6AA3CED-ON862574D7.0067C409-862574D7.0067F529@abbott.com>
Message-ID: <40e66e0b0810071435m936e1dau60043ad07fa1905@mail.gmail.com>

On Fri, Oct 3, 2008 at 1:55 PM, David LeBlond <David.LeBlond at abbott.com> wrote:
> Dear List,
>
> I am new to lme4. I believe it will be very useful for analysis of
> pharmaceutical stability data in which batches are considered to have
> random slopes and intercepts. We now use SAS Proc Mixed for this, but I
> like the lme4 approach and the other capabilities of R better.
>
> What attracts me to lme4 is the possibility of obtaining a posterior
> sample using mcmcsamp(). How else can one obtain meaningful interval
> estimates or make predictions about future data?
>
> However, I do not know how to interpret the contents of the mcmcsamp
> output slots $ST and $sigma. I find that the samples contained in those
> slots do not agree with the estimates provided by lmer(). I hope someone
> more knowledgeable will be willing to explain this to me.
>
> To make things concrete, I provide below an example analysis of simulated
> data.
>
> The following code generates 50 batches worth of stability tests. Batch
> intercepts and slopes are drawn from N(100,,4^2) and N(-1,2^2). Analytical
> results at each time point (0,3,...,36 months) are drawn from
> N(intercept+slope*month, 1^2). So there are 3 random paramters (variance
> for slope, intercept, and error) and 2 fixed effects (mean slope and
> intercept). With such a large balanced data set, I expect rapid
> convergence of the Gibbs sampler.
>
> B<-50 # number of batches
> Months<-c(0,3,6,9,12,24,30,36) # pull points
> n.Months<-length(Months)
> Init.mean<-100 # initial level for the process
> Init.SD<-4 # SD of the process initial
> Slope.mean<- -1
> Slope.SD<- 2
> Error.SD<- 1
> # Prepare Data Vectors
> Batch<-rep(NA,B*n.Months)
> Month<-rep(NA,B*n.Months)
> Y<-rep(NA,B*n.Months)
> for(i in 1:B){
>  slope<-rnorm(1,Slope.mean,Slope.SD)
>  intercept<-rnorm(1,Init.mean,Init.SD)
>  for(j in 1:n.Months){
>    k<-(i-1)*n.Months+j
>    Batch[k]<-i
>    Month[k]<-Months[j]
>    Y[k]<-intercept+Month[k]*slope+rnorm(1,0,Error.SD)
>  }
> }
> Stab<-cbind(Batch=factor(Batch),Month=Month,Y=Y);Stab
>
> I use the following to analyze these data:
>
> library(lme4)
> anal<-lmer(Y~1+Month+(1|Batch)+(-1+Month|Batch))
> anal
>
> The following output is obtained:
>
> Linear mixed model fit by REML
> Formula: Y ~ 1 + Month + (1 | Batch) + (-1 + Month | Batch)
>  AIC  BIC logLik deviance REMLdev
>  1821 1841 -905.4     1811    1811
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Batch    (Intercept) 19.5551  4.42212
>  Batch    Month        4.4818  2.11704
>  Residual              0.9780  0.98894
> Number of obs: 400, groups: Batch, 50
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept) 100.0254     0.6302  158.73
> Month        -1.3988     0.2994   -4.67
>
> Correlation of Fixed Effects:
>      (Intr)
> Month -0.001
>
> This is terrific. The estimates agree well with theory. Armed with
> confidence (or rather credibility?) I obtain interval estimate as follows:
>
> HPDinterval(mcmcsamp(anal,n=10000))
>
> The following output is obtained:
>
> $fixef
>                lower       upper
> (Intercept) 99.447112 100.5605457
> Month       -1.905921  -0.8496636
> attr(,"Probability")
> [1] 0.95
>
> $ST
>         lower     upper
> [1,] 0.7546098 0.9719147
> [2,] 0.6913345 1.7690498
> attr(,"Probability")
> [1] 0.95
>
> $sigma
>        lower    upper
> [1,] 1.710004 2.169471
> attr(,"Probability")
> [1] 0.95
>
> While the fixed effect posteriors compare very well with truth and with
> lmer point estimates, the $sigma is strange. I expect it to be close to 1
> since this is the error SD used to generate the data and also the value
> reported by lmer. Instead $sigma contains a values between 1.7 and 2.2.
> Why?

Most likely because there is a mistake in the mcmcsamp function at
present.  I have seen the same thing when trying to get an MCMC sample
from a model with two uncorrelated random effects per group.  I'm not
sure if the problem is in the theory or in the implementation but
there is definitely a problem.  (I hope it is in the implementation
and not the theory.)

> Also, I expect the $ST slot to bear some resemblance to the true SDs for
> intercept and slope (the other 2 random parameters in the model).  I
> expect values near 4 and 2 respectively, not near 0.8 and 1.1
> respectively. I realize there may be some "common scale" factor involved
> here, but I cannot rationalize how to transform $ST into something I can
> use. This is particularly vexing since the "common scale factor" ($sigma)
> bears little resemblence to expectation. Further, the common scale factor
> is actually a paramter and therefore has a distribution; a simple
> multiplication by a point estimate of sigma would not seem appropriate to
> obtain posteriors for SD.slope and SD.intercept.

Yes.  What is supposed to happen is that the product of an element of
the ST array (these are the parameters that determine the relative
standard deviations of the random effects) and the corresponding
element of sigma would give you the value of the standard deviation of
the random effects.

> The kind readers who have followed me through this will realize I am quite
> clueless. Possibly I have not found the right background material (though
> I have searched hard. Prof Bates kindly provided me some useful
> presentations). Or possibly, mcmcsamp() is simply not ready for prime
> time. I can live with that - for now. Maybe I am using the functions
> inappropriately.

The current implementation of mcmcsamp is not ready for prime time.

> I can obtain posterior samples using the PRIOR statement of SAS Proc Mixed
> for a wide class of variance component models. The difficulty with SAS is
> that technical descriptions of the methodology are not forthcoming, SAS
> has not been very progressive, the modeling syntax is confusing and
> non-intuitive, one is quickly limited by the very painful SAS graphics,
> and - of course - SAS is not free.
>
> Any suggestions, comments, or insight would be greatly appreciated. This
> lmeX library could be extremely useful to me in my nonclinical statistical
> work and I really appreciate that it is under development. I hope to
> understand it better and thank you in advance for your help!!
>
> Best regards,
>
> Dave LeBlond
> Sr. Statistician, Non-Clinical Statistics
> email: david.leblond at abbott.com
> voice mail: 847-935-6031
> Dept R436, Bldg AP9A-1
> Abbott Laboratories
> 100 Abbott Park Road
> Abbott Park, IL 60064-3500
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Oct  7 23:35:49 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 07 Oct 2008 17:35:49 -0400
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when using glmmPQL or lmer with laplace approximation
In-Reply-To: <40e66e0b0810071359h23f3cc13u27bc167c34475d5c@mail.gmail.com>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
	<40e66e0b0810071359h23f3cc13u27bc167c34475d5c@mail.gmail.com>
Message-ID: <48EBD635.1030406@ufl.edu>

Douglas Bates wrote:
  [snip]
> 
> It may be that the problem you are encountering has more to do with
> the use of the quasipoisson family than with the Laplace
> approximation.  I am not sure that the derivation of the standard
> errors in lmer when using the quasipoisson family is correct, in part
> because I don't really understand the quasipoisson and quasibinomial
> families.  As far as I know, they don't correspond to probability
> distributions so the theory is a bit iffy.
> 
> Do you need to use the quasipoisson family or could you use the
> poisson family?  Generally the motivation for the quasipoisson familiy
> is to accomodate overdispersion.  Often in a generalized linear mixed
> model the problem is underdispersion rather than overdispersion.

  In ecological data it's quite common to have dispersion remaining
in a GLMM even after accounting for known grouping factors.

> In one of Ben's replies in this thread he discusses the degrees of
> freedom attributed to certain t-statistics.  Regular readers of this
> list are aware that degrees of freedom is one of my least favorite
> topics.  If one has a reasonably large number of observations and a
> reasonably large number of groups then the issue is unimportant.
> (Uncertainty in degrees of freedom is important only when the value of
> the degrees of freedom is small.  In fact, when I first started
> studying statistics we used the standard normal in place of the
> t-distribution whenever the degrees of freedom exceeded 30).
> Considering that the quasi-Poisson doesn't correspond to a probability
> distribution in the first place, (readers should feel free to correct
> me if I am wrong about this) I find the issue of the number of degrees
> of freedom that should be attributed to a distribution of a quantity
> calculated from a non-existent distribution to be somewhat off the
> point.

  Fair enough, but backing up to wanting p-values associated with
(sensible???) hypothesis tests -- we don't have mcmcsamp for GLMMs,
so our options are (1) no p-values at all, (2) Z tests (i.e. don't
worry about uncertainty in the scale parameter estimate, (3) ??
simulation from the null hypothesis.  See

  http://www.zoo.ufl.edu/bolker/glmm/glmersim.pdf

> I think the problem is more likely that the standard errors are not
> being calculated correctly.  Is that what you concluded from your
> simulations, Ben?

  Yes.

  http://www.zoo.ufl.edu/bolker/glmm/quasitest.pdf

  By the way, I'd be more than happy for any input on the
above-referenced URLs -- if anyone thinks (and can argue
reasonably convincingly) that they're wrong and/or misguided
I'll take them down so as not to mislead the public.
The Sweave files are up in the same place (substitute .Rnw
for .pdf)

  cheers
    Ben



From bates at stat.wisc.edu  Tue Oct  7 23:41:27 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 16:41:27 -0500
Subject: [R-sig-ME] Wald F tests
In-Reply-To: <48E68299.3040203@ufl.edu>
References: <48E68299.3040203@ufl.edu>
Message-ID: <40e66e0b0810071441v169abe60k2d298d29eac7973b@mail.gmail.com>

If I were using glmer to fit a generalized linear mixed model I would
use likelihood ratio tests rather than Wald tests.  That is, I would
fit a model including a particular term then fit it again without that
term and calculate the difference in the deviance values, comparing
that to a chi-square.

I'm not sure how one would do this using the results from glmmPQL.

On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>  [forwarding to R-sig-mixed, where it is likely to get more
> responses]
>
> Mark Fowler wrote:
>
> Hello,
>        Might anyone know how to conduct Wald-type F-tests of the fixed
> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
> and have seen it recommended in user group discussions, but haven't come
> across any code to accomplish it. I understand the anova function treats
> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
> have R 2.7 and S-Plus 8 if necessary.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Oct  7 23:51:01 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 07 Oct 2008 17:51:01 -0400
Subject: [R-sig-ME] [Fwd: Re:  Wald F tests]
Message-ID: <48EBD9C5.7080102@ufl.edu>


  But ... LRTs are non-recommended (anticonservative) for
comparing fixed effects of LMMs hence (presumably) for
GLMMs, unless sample size (# blocks/"residual" total sample
size) is large, no?

I just got through telling readers of
a forthcoming TREE (Trends in Ecology and Evolution) article
that they should use Wald Z, chi^2, t, or F (depending on
whether testing a single or multiple parameters, and whether
there is overdispersion or not), in preference to LRTs,
for testing fixed effects ... ?  Or do you consider LRT
better than Wald in this case (in which case as far as
we know _nothing_ works very well for GLMMs, and I might
just start to cry ...)  Or perhaps I have to get busy
running some simulations ...

  Where would _you_ go to find advice on inference
(as opposed to estimation) on estimated GLMM parameters?

  cheers
   Ben Bolker

Douglas Bates wrote:
> If I were using glmer to fit a generalized linear mixed model I would
> use likelihood ratio tests rather than Wald tests.  That is, I would
> fit a model including a particular term then fit it again without that
> term and calculate the difference in the deviance values, comparing
> that to a chi-square.
>
> I'm not sure how one would do this using the results from glmmPQL.
>
> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>  [forwarding to R-sig-mixed, where it is likely to get more
>> responses]
>>
>> Mark Fowler wrote:
>>
>> Hello,
>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>> and have seen it recommended in user group discussions, but haven't come
>> across any code to accomplish it. I understand the anova function treats
>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>> have R 2.7 and S-Plus 8 if necessary.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From David.LeBlond at abbott.com  Tue Oct  7 23:57:29 2008
From: David.LeBlond at abbott.com (David LeBlond)
Date: Tue, 7 Oct 2008 16:57:29 -0500
Subject: [R-sig-ME] Fw: mcmcsamp(lme4): What is contained in $ST and
	$sigma?
In-Reply-To: <40e66e0b0810071435m936e1dau60043ad07fa1905@mail.gmail.com>
Message-ID: <OF4E267BE3.16515B10-ON862574DB.007741E8-862574DB.0078A4CB@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081007/397bf517/attachment.pl>

From bates at stat.wisc.edu  Wed Oct  8 00:31:03 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 7 Oct 2008 17:31:03 -0500
Subject: [R-sig-ME] Fw: mcmcsamp(lme4): What is contained in $ST and
	$sigma?
In-Reply-To: <OF4E267BE3.16515B10-ON862574DB.007741E8-862574DB.0078A4CB@abbott.com>
References: <40e66e0b0810071435m936e1dau60043ad07fa1905@mail.gmail.com>
	<OF4E267BE3.16515B10-ON862574DB.007741E8-862574DB.0078A4CB@abbott.com>
Message-ID: <40e66e0b0810071531q425c5520o1ff8c4fe15699297@mail.gmail.com>

On Tue, Oct 7, 2008 at 4:57 PM, David LeBlond <David.LeBlond at abbott.com> wrote:

> Prof. Bates,

> Thanks for the note. Hopefully I am responding properly to the list.

Indeed you are.

> Now I understand better. mcmcsamp is still under development. It will be
> really useful when it is available. I know this is eminently (if not
> imminently) doable. Having the posterior opens up all kinds of
> possibilities. I really encourage this project!!!

> While not yet "ready for prime time", I do have a question about generating
> posteriors from variance parameters when finally available. As I understand
> it mcmcsamp will produce a posterior sample directly for all fixed effects
> and for the error variance. I understand from your comment that to get the
> posterior sample for the other random effect variances, I will need to
> multiply the error variance times the appropriate vector in $ST for each
> draw (ie- a vector multiplication). The resulting vector would be a sample
> from the posterior of the random effect variance. That is - we are taking 2
> posterior samples (the $sigma and the $ST[?] and forming the desired
> posterior sample by their vector product. Do I have this right? Please
> ignore my confusing sigmas and variances. I like sigmas better too.

The plan is to have extractor function, actually a method for the
VarCorr generic, that will calculate the desired quantities, be they
variances and covariances or standard deviations and correlations or
logarithms of standard deviations and Fisher's z-transform of the
correlations, from the sigma and ST components.  (The name ST comes
from the fact that the relative covariance factor is the product of a
diagonal scale matrix S and a unit lower triangular matrix T.)

There are hints of that code in the lme4/R/lmer.R and
lme4/src/lmer.[ch] files but they have not yet been fleshed out.  I
figure I should get mcmcsamp working before trying to figure out what
to do with the results.

> "Douglas Bates" <bates at stat.wisc.edu>
> Sent by: dmbates at gmail.com
>
> 10/07/2008 04:35 PM
>
> To
> "David LeBlond" <David.LeBlond at abbott.com>
> cc
> r-sig-mixed-models at r-project.org
> Subject
> Re: [R-sig-ME] Fw: mcmcsamp(lme4): What is contained in $ST and $sigma?
>
>
>
>
> On Fri, Oct 3, 2008 at 1:55 PM, David LeBlond <David.LeBlond at abbott.com>
> wrote:
>> Dear List,
>>
>> I am new to lme4. I believe it will be very useful for analysis of
>> pharmaceutical stability data in which batches are considered to have
>> random slopes and intercepts. We now use SAS Proc Mixed for this, but I
>> like the lme4 approach and the other capabilities of R better.
>>
>> What attracts me to lme4 is the possibility of obtaining a posterior
>> sample using mcmcsamp(). How else can one obtain meaningful interval
>> estimates or make predictions about future data?
>>
>> However, I do not know how to interpret the contents of the mcmcsamp
>> output slots $ST and $sigma. I find that the samples contained in those
>> slots do not agree with the estimates provided by lmer(). I hope someone
>> more knowledgeable will be willing to explain this to me.
>>
>> To make things concrete, I provide below an example analysis of simulated
>> data.
>>
>> The following code generates 50 batches worth of stability tests. Batch
>> intercepts and slopes are drawn from N(100,,4^2) and N(-1,2^2). Analytical
>> results at each time point (0,3,...,36 months) are drawn from
>> N(intercept+slope*month, 1^2). So there are 3 random paramters (variance
>> for slope, intercept, and error) and 2 fixed effects (mean slope and
>> intercept). With such a large balanced data set, I expect rapid
>> convergence of the Gibbs sampler.
>>
>> B<-50 # number of batches
>> Months<-c(0,3,6,9,12,24,30,36) # pull points
>> n.Months<-length(Months)
>> Init.mean<-100 # initial level for the process
>> Init.SD<-4 # SD of the process initial
>> Slope.mean<- -1
>> Slope.SD<- 2
>> Error.SD<- 1
>> # Prepare Data Vectors
>> Batch<-rep(NA,B*n.Months)
>> Month<-rep(NA,B*n.Months)
>> Y<-rep(NA,B*n.Months)
>> for(i in 1:B){
>>  slope<-rnorm(1,Slope.mean,Slope.SD)
>>  intercept<-rnorm(1,Init.mean,Init.SD)
>>  for(j in 1:n.Months){
>>    k<-(i-1)*n.Months+j
>>    Batch[k]<-i
>>    Month[k]<-Months[j]
>>    Y[k]<-intercept+Month[k]*slope+rnorm(1,0,Error.SD)
>>  }
>> }
>> Stab<-cbind(Batch=factor(Batch),Month=Month,Y=Y);Stab
>>
>> I use the following to analyze these data:
>>
>> library(lme4)
>> anal<-lmer(Y~1+Month+(1|Batch)+(-1+Month|Batch))
>> anal
>>
>> The following output is obtained:
>>
>> Linear mixed model fit by REML
>> Formula: Y ~ 1 + Month + (1 | Batch) + (-1 + Month | Batch)
>>  AIC  BIC logLik deviance REMLdev
>>  1821 1841 -905.4     1811    1811
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Batch    (Intercept) 19.5551  4.42212
>>  Batch    Month        4.4818  2.11704
>>  Residual              0.9780  0.98894
>> Number of obs: 400, groups: Batch, 50
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept) 100.0254     0.6302  158.73
>> Month        -1.3988     0.2994   -4.67
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> Month -0.001
>>
>> This is terrific. The estimates agree well with theory. Armed with
>> confidence (or rather credibility?) I obtain interval estimate as follows:
>>
>> HPDinterval(mcmcsamp(anal,n=10000))
>>
>> The following output is obtained:
>>
>> $fixef
>>                lower       upper
>> (Intercept) 99.447112 100.5605457
>> Month       -1.905921  -0.8496636
>> attr(,"Probability")
>> [1] 0.95
>>
>> $ST
>>         lower     upper
>> [1,] 0.7546098 0.9719147
>> [2,] 0.6913345 1.7690498
>> attr(,"Probability")
>> [1] 0.95
>>
>> $sigma
>>        lower    upper
>> [1,] 1.710004 2.169471
>> attr(,"Probability")
>> [1] 0.95
>>
>> While the fixed effect posteriors compare very well with truth and with
>> lmer point estimates, the $sigma is strange. I expect it to be close to 1
>> since this is the error SD used to generate the data and also the value
>> reported by lmer. Instead $sigma contains a values between 1.7 and 2.2.
>> Why?
>
> Most likely because there is a mistake in the mcmcsamp function at
> present.  I have seen the same thing when trying to get an MCMC sample
> from a model with two uncorrelated random effects per group.  I'm not
> sure if the problem is in the theory or in the implementation but
> there is definitely a problem.  (I hope it is in the implementation
> and not the theory.)
>
>> Also, I expect the $ST slot to bear some resemblance to the true SDs for
>> intercept and slope (the other 2 random parameters in the model).  I
>> expect values near 4 and 2 respectively, not near 0.8 and 1.1
>> respectively. I realize there may be some "common scale" factor involved
>> here, but I cannot rationalize how to transform $ST into something I can
>> use. This is particularly vexing since the "common scale factor" ($sigma)
>> bears little resemblence to expectation. Further, the common scale factor
>> is actually a paramter and therefore has a distribution; a simple
>> multiplication by a point estimate of sigma would not seem appropriate to
>> obtain posteriors for SD.slope and SD.intercept.
>
> Yes.  What is supposed to happen is that the product of an element of
> the ST array (these are the parameters that determine the relative
> standard deviations of the random effects) and the corresponding
> element of sigma would give you the value of the standard deviation of
> the random effects.
>
>> The kind readers who have followed me through this will realize I am quite
>> clueless. Possibly I have not found the right background material (though
>> I have searched hard. Prof Bates kindly provided me some useful
>> presentations). Or possibly, mcmcsamp() is simply not ready for prime
>> time. I can live with that - for now. Maybe I am using the functions
>> inappropriately.
>
> The current implementation of mcmcsamp is not ready for prime time.
>
>> I can obtain posterior samples using the PRIOR statement of SAS Proc Mixed
>> for a wide class of variance component models. The difficulty with SAS is
>> that technical descriptions of the methodology are not forthcoming, SAS
>> has not been very progressive, the modeling syntax is confusing and
>> non-intuitive, one is quickly limited by the very painful SAS graphics,
>> and - of course - SAS is not free.
>>
>> Any suggestions, comments, or insight would be greatly appreciated. This
>> lmeX library could be extremely useful to me in my nonclinical statistical
>> work and I really appreciate that it is under development. I hope to
>> understand it better and thank you in advance for your help!!
>>
>> Best regards,
>>
>> Dave LeBlond
>> Sr. Statistician, Non-Clinical Statistics
>> email: david.leblond at abbott.com
>> voice mail: 847-935-6031
>> Dept R436, Bldg AP9A-1
>> Abbott Laboratories
>> 100 Abbott Park Road
>> Abbott Park, IL 60064-3500
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



From martijn.vandegehuchte at ugent.be  Wed Oct  8 11:59:13 2008
From: martijn.vandegehuchte at ugent.be (Martijn Vandegehuchte)
Date: Wed, 8 Oct 2008 11:59:13 +0200
Subject: [R-sig-ME] generalized linear mixed models: large differences
	when using glmmPQL or lmer with laplace approximation
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
	<40e66e0b0810071359h23f3cc13u27bc167c34475d5c@mail.gmail.com>
Message-ID: <D79EA1E4D4134B86921403DD9AFA3857@Mythimna>

Thank you for this explanation. My dataset consists of 120 observations, 
with 6 levels of the random effect (20 observations per level). I think in 
my case the df, like you say, are not the point, because the number is 
rather large.

Considering the quasipoisson family, I do not really know how it works or 
what it does (like I said, I am not a statistician at all). I only learned 
that it is a way to deal with overdispersion, and yes, my data are highly 
overdispersed. If I make the same models with lmer with a poisson family, 
all the effects become highly significant, so the correction seems 
necessary.

Another remark: by now I found out that when I use poisson or quasipoisson, 
the results with glmmPQL are exactly the same, and still quite close to the 
quasipoisson results of lmer (as opposed to the poisson results of lmer). I 
have been searching for information about the quasi families, but I can't 
seem to find any. I'm a bit puzzled by this at the moment. Why is there a 
huge difference between quasipoisson and poisson with lmer and not with 
glmmPQL? It seems that glmmPQL already accounts for the overdispersion, also 
because when I compare the results with the output of SAS proc glimmix, the 
results of glmmPQL are exactly the same only if I put the overdispersion 
correction "random _residual_" in SAS.

Also, the overdispersion in my data is to a large extent due to the amount 
of zeroes. I have been searching for ways to build ZIP models, but in SAS 
with proc nlmixed, it is quite complex, and with glmm.admb() in R, I also 
get strange results and warning messages, and I have problems with obtaining 
the output I need. Now a colleague from my lab just pointed out that a glmm 
with a correction for overdispersion gave very similar results compared with 
ZIP models in a study of his. And besides that, the overdispersion in my 
case is not only due to the zeroes, there are also some large values in my 
dependent variables, so I'm not even sure if a ZIP model is the right way to 
deal with it. But maybe it is a way to avoid the quasifamilies, if they 
should be avoided at all. It's just a thought.

I would appreciate your ideas on these matters,

Thank you for your time and effort,

Martijn.


-- 
Martijn Vandegehuchte
Ghent University
Department Biology
Terrestrial Ecology Unit
K.L.Ledeganckstraat 35
B-9000 Ghent
telephone: +32 (0)9/264 50 84
e-mail: martijn.vandegehuchte at ugent.be

website TEREC: www.ecology.ugent.be/terec

----- Original Message ----- 
From: "Douglas Bates" <bates at stat.wisc.edu>
To: "Martijn Vandegehuchte" <martijn.vandegehuchte at ugent.be>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Tuesday, October 07, 2008 10:59 PM
Subject: Re: [R-sig-ME] generalized linear mixed models: large differences 
when using glmmPQL or lmer with laplace approximation


> Due to some travel and the need to attend to other projects, I haven't
> been keeping up as closely with this list as I normally do.  Regarding
> the comparison between the PQL and Laplace methods for fitting
> generalized linear mixed models, I believe that the estimates produced
> by the Laplace method are more reliable than those from the PQL
> method.  The objective function optimized by the Laplace method is a
> direct approxmation, and generally a very good approximation, to the
> log-likelihood for the model being fit.  The PQL method is indirect
> (the "QL" part of the name stands for "quasi-likelihood") and, because
> it involves alternating conditional optimization, can alternate
> back-and-forth between two potential solutions, neither of which is
> optimal.  (To be fair, such alternating occurs more frequently in the
> analogous method for nonlinear mixed-models, in which I was one of the
> co-conspirators, than in the PQL method for GLMMs.)
>
> It may be that the problem you are encountering has more to do with
> the use of the quasipoisson family than with the Laplace
> approximation.  I am not sure that the derivation of the standard
> errors in lmer when using the quasipoisson family is correct, in part
> because I don't really understand the quasipoisson and quasibinomial
> families.  As far as I know, they don't correspond to probability
> distributions so the theory is a bit iffy.
>
> Do you need to use the quasipoisson family or could you use the
> poisson family?  Generally the motivation for the quasipoisson familiy
> is to accomodate overdispersion.  Often in a generalized linear mixed
> model the problem is underdispersion rather than overdispersion.
>
> In one of Ben's replies in this thread he discusses the degrees of
> freedom attributed to certain t-statistics.  Regular readers of this
> list are aware that degrees of freedom is one of my least favorite
> topics.  If one has a reasonably large number of observations and a
> reasonably large number of groups then the issue is unimportant.
> (Uncertainty in degrees of freedom is important only when the value of
> the degrees of freedom is small.  In fact, when I first started
> studying statistics we used the standard normal in place of the
> t-distribution whenever the degrees of freedom exceeded 30).
> Considering that the quasi-Poisson doesn't correspond to a probability
> distribution in the first place, (readers should feel free to correct
> me if I am wrong about this) I find the issue of the number of degrees
> of freedom that should be attributed to a distribution of a quantity
> calculated from a non-existent distribution to be somewhat off the
> point.
>
> I think the problem is more likely that the standard errors are not
> being calculated correctly.  Is that what you concluded from your
> simulations, Ben?
>
> On Tue, Oct 7, 2008 at 8:21 AM, Martijn Vandegehuchte
> <martijn.vandegehuchte at ugent.be> wrote:
>> Dear list,
>
>> First of all, I am a mere ecologist, trying to get the truth out of his 
>> data, and not a statistician, so forgive me my lack of statistical 
>> background and possible conceptual misunderstandings.
>
>> I am currently comparing generalized linear mixed models in glmmPQL and 
>> lmer, with a quasipoisson family, and have found out that parameter 
>> estimates are quite different for both methods. I read some of the 
>> discussions on the R-forum and it seems that the Laplace approximation 
>> used in the current version of lmer is generally preferred to the PQL 
>> method. I am an ex-SAS user, and in proc glimmix in SAS the default is 
>> PQL, and the estimates and p-values are almost exact the same as with 
>> glmmPQL in R. But lmer gives quite different results, and now I am 
>> wondering what would be the best option for me.
>
>> First of all, parameter estimates of a same model can be somewhat 
>> different in lmer or glmmPQL. Second of all, in lmer, I only get t-values 
>> but no associated p-values (apparently they are omitted because of the 
>> uncertainty about the df). But if I compare the t-values generated by 
>> glmmPQL with those of a same model in lmer, the differences are 
>> substantial. My dataset consists of 120 observations, so basically you 
>> could guess the order of magnitude of the p-values in lmer based on the 
>> t-value and a "large" df.
>
>> First example:
>> In lmer:
>>
>>> model<-lmer(schirufu~diameter+leafvit+densroot+cover+nemcm+(1|site),family=quasipoisson)
>>> summary (model)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: schirufu ~ diameter + leafvit + densroot + cover + nemcm + (1 | 
>> site)
>>  AIC  BIC logLik deviance
>>  2045 2068  -1015     2029
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  site     (Intercept) 12.700   3.5638
>>  Residual             15.182   3.8964
>> Number of obs: 120, groups: site, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)  1.31017    1.47249   0.890
>> diameter    -0.24799    0.29180  -0.850
>> leafvit      1.29007    0.21041   6.131
>> densroot     0.31024    0.04939   6.281
>> cover       -0.24544    0.22179  -1.107
>> nemcm        0.24817    0.12028   2.063
>>
>> Correlation of Fixed Effects:
>>         (Intr) diamtr leafvt densrt cover
>> diameter  0.031
>> leafvit  -0.083  0.321
>> densroot  0.011 -0.017 -0.202
>> cover     0.021 -0.448  0.016  0.214
>> nemcm    -0.014  0.114  0.114  0.310 -0.017
>>>
>>
>> Although no p-values are given, it suggests that fixed effects leafvit, 
>> densroot and nemcm would be significant.
>> In glmmPQL:
>>
>>> model<-glmmPQL(schirufu~diameter+leafvit+densroot+cover+nemcm,random=~1|site,family=quasipoisson)
>> iteration 1
>> iteration 2
>> iteration 3
>> iteration 4
>> iteration 5
>>> summary(model)
>> Linear mixed-effects model fit by maximum likelihood
>>  Data: NULL
>>  AIC BIC logLik
>>   NA  NA     NA
>>
>> Random effects:
>>  Formula: ~1 | site
>>        (Intercept) Residual
>> StdDev:   0.7864989  4.63591
>>
>> Variance function:
>>  Structure: fixed weights
>>  Formula: ~invwt
>> Fixed effects: schirufu ~ diameter + leafvit + densroot + cover + nemcm
>>                 Value Std.Error  DF   t-value p-value
>> (Intercept)  1.4486735 0.4174843 109  3.470007  0.0007
>> diameter    -0.2600504 0.3477017 109 -0.747913  0.4561
>> leafvit      1.2236406 0.2489291 109  4.915619  0.0000
>> densroot     0.3236446 0.0596342 109  5.427164  0.0000
>> cover       -0.2523163 0.2698555 109 -0.935005  0.3519
>> nemcm        0.2336305 0.1451751 109  1.609301  0.1104
>>  Correlation:
>>         (Intr) diamtr leafvt densrt cover
>> diameter  0.130
>> leafvit  -0.335  0.313
>> densroot  0.027 -0.022 -0.203
>> cover     0.090 -0.463  0.015  0.214
>> nemcm    -0.056  0.097  0.107  0.301 -0.014
>>
>> Standardized Within-Group Residuals:
>>       Min         Q1        Med         Q3        Max
>> -2.4956188 -0.4154369 -0.1333850  0.1724601  4.7355928
>>
>> Number of Observations: 120
>> Number of Groups: 6
>>>
>>
>> Note the difference in parameter estimates. Also, the fixed effect nemcm 
>> now is not significant any more.
>>
>> Second example,now with an offset:
>> In lmer:
>>
>>> model<-lmer(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+(1|site), 
>>> offset= loglength, family=quasipoisson)
>>> summary (model)
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: nemcm ~ diameter + leafvit + densroot + rootvit + cover + 
>> schirufu +      (1 | site)
>>  AIC  BIC logLik deviance
>>  1593 1618 -787.4     1575
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  site     (Intercept)  21.522   4.6392
>>  Residual             173.888  13.1867
>> Number of obs: 120, groups: site, 6
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)  0.06733    1.92761  0.0349
>> diameter     0.14665    0.60693  0.2416
>> leafvit     -0.19902    0.48802 -0.4078
>> densroot    -0.49178    0.64221 -0.7658
>> rootvit      0.37699    0.46810  0.8054
>> cover       -0.23545    0.57896 -0.4067
>> schirufu     0.23226    0.46866  0.4956
>>
>> Correlation of Fixed Effects:
>>         (Intr) diamtr leafvt densrt rootvt cover
>> diameter -0.016
>> leafvit   0.015  0.396
>> densroot  0.055 -0.233 -0.291
>> rootvit  -0.038 -0.251 -0.629  0.277
>> cover     0.024 -0.796 -0.133  0.253  0.117
>> schirufu -0.032  0.137 -0.029 -0.505 -0.078 -0.121
>>>
>>
>> This suggests no significant effects at all.
>> In glmmPQL:
>>
>>> model<-glmmPQL(nemcm~diameter+leafvit+densroot+rootvit+cover+schirufu+offset(loglength),random=~1|site, 
>>> family=quasipoisson)
>> iteration 1
>> iteration 2
>> iteration 3
>>> summary (model)
>> Linear mixed-effects model fit by maximum likelihood
>>  Data: NULL
>>  AIC BIC logLik
>>   NA  NA     NA
>>
>> Random effects:
>>  Formula: ~1 | site
>>        (Intercept) Residual
>> StdDev:   0.2684477 4.507758
>>
>> Variance function:
>>  Structure: fixed weights
>>  Formula: ~invwt
>> Fixed effects: nemcm ~ diameter + leafvit + densroot + rootvit + cover + 
>> schirufu +      offset(loglength)
>>                 Value Std.Error  DF    t-value p-value
>> (Intercept)  0.1131898 0.1656949 108  0.6831220  0.4960
>> diameter     0.1225231 0.1976568 108  0.6198779  0.5366
>> leafvit     -0.2191361 0.1697784 108 -1.2907181  0.1996
>> densroot    -0.4733839 0.2221562 108 -2.1308604  0.0354
>> rootvit      0.3858120 0.1615706 108  2.3878846  0.0187
>> cover       -0.2075038 0.1922054 108 -1.0795940  0.2827
>> schirufu     0.2028444 0.1633954 108  1.2414323  0.2171
>>  Correlation:
>>         (Intr) diamtr leafvt densrt rootvt cover
>> diameter -0.050
>> leafvit   0.077  0.360
>> densroot  0.217 -0.168 -0.262
>> rootvit  -0.163 -0.202 -0.632  0.257
>> cover     0.084 -0.772 -0.098  0.200  0.073
>> schirufu -0.103  0.099 -0.050 -0.483 -0.068 -0.075
>>
>> Standardized Within-Group Residuals:
>>       Min         Q1        Med         Q3        Max
>> -1.1146287 -0.5208003 -0.1927005  0.2462878  7.9755368
>>
>> Number of Observations: 120
>> Number of Groups: 6
>>>
>>
>> Again some differences in parameter estimates, but now the two fixed 
>> effects densroot and rootvit turn out to be significant.
>> So my questions are:
>> - what would you recommend me to use? lmer or glmmPQL (laplace 
>> approximation or penalized quasi-likelihood)?
>> - if lmer is the better option, is there a way to get a reliable p-value 
>> for the fixed effects?
>> I have experienced that deleting a term and comparing models using 
>> anova() always overestimates the significance of that term, probably 
>> because the quasipoisson correction for overdispersion is not taken into 
>> account.
>>
>> Thank you very much beforehand,
>>
>> Martijn.
>>
>> --
>> Martijn Vandegehuchte
>> Ghent University
>> Department Biology
>> Terrestrial Ecology Unit
>> K.L.Ledeganckstraat 35
>> B-9000 Ghent
>> telephone: +32 (0)9/264 50 84
>> e-mail: martijn.vandegehuchte at ugent.be
>>
>> website TEREC: www.ecology.ugent.be/terec
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From j.dewoody at soton.ac.uk  Wed Oct  8 16:41:23 2008
From: j.dewoody at soton.ac.uk (De Woody J.A.)
Date: Wed, 8 Oct 2008 15:41:23 +0100
Subject: [R-sig-ME] FW: Suspicious output from lme4-mcmcsamp
Message-ID: <5F338719C0D0DE44BDFDD2B83D3FF7A18F592C937B@UOS-CL-EX7-L3.soton.ac.uk>

Hello, lme4 community,

Sorry for the re-post, but I hadn't realized there was a list specific to lme4 when I posted to the R-help earlier.

I have been using the lmer and mcmcsamp functions in R with some difficulty.  I do not believe this is my code or data, however, because my attempts to use the sample code and 'sleepstudy' data provided with the lme4 packaged (and used on several R-Wiki pages) do not return the same results as those indicated in the help pages.  For instance:

> sessionInfo()
R version 2.7.2 (2008-08-25)
i386-pc-mingw32

locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-26   Matrix_0.999375-11 lattice_0.17-13

loaded via a namespace (and not attached):
[1] grid_2.7.2

> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> sm1 <- mcmcsamp(fm1, 5000)
Error in .local(object, n, verbose, ...) :
  Code for non-trivial theta_T not yet written

##
I cannot find exactly what this theta_T error means, although I do find it mentioned in what I believe to be source code.  Regardless, I cannot understand why the mcmcsamp returns the error for this data set.

Even when I change the model and the mcmcsamp appears to run, the output is not as expected:


> fm2 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
> sm2 <- mcmcsamp(fm2, 5000)
> summary(sm2)
 Length   Class    Mode
      1 merMCMC      S4
> str(sm2)
Formal class 'merMCMC' [package "lme4"] with 9 slots
  ..@ Gp      : int [1:2] 0 18
  ..@ ST      : num [1, 1:5000] 1.198 0.932 0.835 0.826 0.933 ...
  ..@ call    : language lmer(formula = Reaction ~ Days + (1 | Subject), data = sleepstudy)
  ..@ deviance: num [1:5000] 1794 1794 1796 1798 1798 ...
  ..@ dims    : Named int [1:17] 1 180 2 18 1 1 1 2 5 1 ...
  .. ..- attr(*, "names")= chr [1:17] "nf" "n" "p" "q" ...
  ..@ fixef   : num [1:2, 1:5000] 251.4  10.5 253.3  11.0 259.5 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "(Intercept)" "Days"
  .. .. ..$ : NULL
  ..@ nc      : int 1
  ..@ ranef   : num[1:18, 0 ]
  ..@ sigma   : num [1, 1:5000] 31.0 29.7 30.4 28.4 38.1 ...

##
As I understand it, the call >summary(sm2) should return information of the results of the mcmcsamp distribution.    In addition, I am expecting the str(sm2) to show the 'fixef' slot to have something resembling "log(sigma^2)" and "log(Subject.(In))".  Am I wrong?  Are all of the outputs in the correct form?

Has anyone else had this problem?  Could this be related to the possible 'mistake in the mcmcsamp function at present' mentioned in the recent postings regarding the $ST and $sigma slots (Re: mcmcsamp(lme4): What is contained in $ST and $sigma?)?

Any thoughts, suggestions, or directions would, of course, be most appreciated.

Many thanks!
Jenn

****************************
Jennifer DeWoody
University of Southampton
School of Biological Sciences
Building 62, Room 6007, Boldrewood Campus Southampton  SO16 7PX United Kingdom
Voice: +44 (0)23 8059 4286
Email: j.dewoody at soton.ac.uk



From bates at stat.wisc.edu  Wed Oct  8 19:27:44 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 8 Oct 2008 12:27:44 -0500
Subject: [R-sig-ME] Fwd:  FW: Suspicious output from lme4-mcmcsamp
In-Reply-To: <40e66e0b0810081027k232a0158v70f4bb2ece6d5ec4@mail.gmail.com>
References: <5F338719C0D0DE44BDFDD2B83D3FF7A18F592C937B@UOS-CL-EX7-L3.soton.ac.uk>
	<40e66e0b0810081027k232a0158v70f4bb2ece6d5ec4@mail.gmail.com>
Message-ID: <40e66e0b0810081027q7c902599i350728c2d59aa9bb@mail.gmail.com>

I meant to cc: this reply to the list.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Wed, Oct 8, 2008 at 12:27 PM
Subject: Re: [R-sig-ME] FW: Suspicious output from lme4-mcmcsamp
To: "De Woody J.A." <j.dewoody at soton.ac.uk>


On Wed, Oct 8, 2008 at 9:41 AM, De Woody J.A. <j.dewoody at soton.ac.uk> wrote:
> Hello, lme4 community,
>
> Sorry for the re-post, but I hadn't realized there was a list specific to lme4 when I posted to the R-help earlier.
>
> I have been using the lmer and mcmcsamp functions in R with some difficulty.  I do not believe this is my code or data, however, because my attempts to use the sample code and 'sleepstudy' data provided with the lme4 packaged (and used on several R-Wiki pages) do not return the same results as those indicated in the help pages.  For instance:
>
>> sessionInfo()
> R version 2.7.2 (2008-08-25)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-26   Matrix_0.999375-11 lattice_0.17-13
>
> loaded via a namespace (and not attached):
> [1] grid_2.7.2
>
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> sm1 <- mcmcsamp(fm1, 5000)
> Error in .local(object, n, verbose, ...) :
>  Code for non-trivial theta_T not yet written
>
> ##
> I cannot find exactly what this theta_T error means, although I do find it mentioned in what I believe to be source code.  Regardless, I cannot understand why the mcmcsamp returns the error for this data set.

As Dieter Menne indicated, this is one of the error messages that is
meant more as a reminder to myself that I should write the code for
this case.  The rather crytic terminology relates to the particular
way that the covariance matrix of the random effects is parameterized,
as sigma^2 * T %*% S %*% S %*% t(T) where S is a diagonal (S)cale
matrix with non-negative diagonal elements and T is a unit,
lower-(T)riangular matrix.  If the random effects are uncorrelated
then T is the identity matrix and there is no need to sample from the
posterior distribution of the parameters determining T.  I haven't yet
written the code to sample from that posterior distribution when the
random effects are correlated.

> Even when I change the model and the mcmcsamp appears to run, the output is not as expected:

Expected by whom?  I don't know of examples where summary of an
merMCMC object has had a form other than what is shown below.

Such objects are in an S4 class and, in the fullness of time, as Bill
Venables is fond of saying, there will be extractor methods for them
that will provide more meaningful output.  At present there is not a
lot of useful output.  Mostly I look at the plots produced by

xyplot(sm2)

to see how the chains evolved.  At present, even that has a few
problems for models with multiple, uncorrelated random effects per
level of the grouping factor.

>
>> fm2 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>> sm2 <- mcmcsamp(fm2, 5000)
>> summary(sm2)
>  Length   Class    Mode
>      1 merMCMC      S4
>> str(sm2)
> Formal class 'merMCMC' [package "lme4"] with 9 slots
>  ..@ Gp      : int [1:2] 0 18
>  ..@ ST      : num [1, 1:5000] 1.198 0.932 0.835 0.826 0.933 ...
>  ..@ call    : language lmer(formula = Reaction ~ Days + (1 | Subject), data = sleepstudy)
>  ..@ deviance: num [1:5000] 1794 1794 1796 1798 1798 ...
>  ..@ dims    : Named int [1:17] 1 180 2 18 1 1 1 2 5 1 ...
>  .. ..- attr(*, "names")= chr [1:17] "nf" "n" "p" "q" ...
>  ..@ fixef   : num [1:2, 1:5000] 251.4  10.5 253.3  11.0 259.5 ...
>  .. ..- attr(*, "dimnames")=List of 2
>  .. .. ..$ : chr [1:2] "(Intercept)" "Days"
>  .. .. ..$ : NULL
>  ..@ nc      : int 1
>  ..@ ranef   : num[1:18, 0 ]
>  ..@ sigma   : num [1, 1:5000] 31.0 29.7 30.4 28.4 38.1 ...
>
> ##
> As I understand it, the call >summary(sm2) should return information of the results of the mcmcsamp distribution.    In addition, I am expecting the str(sm2) to show the 'fixef' slot to have something resembling "log(sigma^2)" and "log(Subject.(In))".  Am I wrong?  Are all of the outputs in the correct form?

I don't understand why the fixef slot would have log(sigma^2), etc.
The fixef slot is the values of the fixed-effects parameters in the
sample.

The sigma slot is the sample from the distribution of the common scale
parameter, which is written as sigma.  The ST slot is the sample from
the distribution of the relative standard deviation of the random
effects.  To get the standard deviation of the random effects you
multiply ST by sigma.

I am not confident of the results from mcmcsamp at present and
regrettably I won't have time to look at it in more detail for a
couple of months.  If it were better to avoid confusion for the time
being I could disable it.  If someone else wants to experiment with it
send me email off-list and I will outline what should be happending in
that code.

>
> Has anyone else had this problem?  Could this be related to the possible 'mistake in the mcmcsamp function at present' mentioned in the recent postings regarding the $ST and $sigma slots (Re: mcmcsamp(lme4): What is contained in $ST and $sigma?)?
>
> Any thoughts, suggestions, or directions would, of course, be most appreciated.
>
> Many thanks!
> Jenn
>
> ****************************
> Jennifer DeWoody
> University of Southampton
> School of Biological Sciences
> Building 62, Room 6007, Boldrewood Campus Southampton  SO16 7PX United Kingdom
> Voice: +44 (0)23 8059 4286
> Email: j.dewoody at soton.ac.uk
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Wed Oct  8 23:39:09 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 08 Oct 2008 17:39:09 -0400
Subject: [R-sig-ME] generalized linear mixed models: large differences
 when	using glmmPQL or lmer with laplace approximation
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6157DA511E@LP-EXMBVS10.CO.IHC.COM>
References: <559E1B0449214BB483273F44A927D926@Mythimna>	<48EB7DEC.6070306@ufl.edu>	<DAB755DB243541A1A96BC9CFEDECD120@Mythimna>
	<48EB9FC9.3060101@ufl.edu>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6157DA511E@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <48ED287D.5020500@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Greg Snow wrote:
> You make reference to my comment below, but I think you overstate my position a bit

 (the words in quotes are not a direct quote of what I said).

  Fair enough.  Sorry about that.
> 
> The original poster mentioned that 2 different methods gave 2 different models, 

one possibility is that one method gave a wrong model (biased in a
non-good way),

another possibility is that the predictor variables are correlated
enough that

there are multiple good models.  I merely pointed out that comparing the

predicted values to the original values would be one way to possibly
distinguish between the 2 cases.

  Looking at the parameters, they seemed to be pretty similar to me,
although of course the details of the data (range of predictor
variables) matters too.
> 
> Focusing too much on the predicted values can lead to overfitting, 

so we should not depend only on that.  P-values are useful in some cases,

so I would not say "don't worry about the p-values" as a general statement.

  Point taken.

> The issue of editors wanting p-values even when they answer the wrong question 

is part of the result of statisticians doing to good a job of training
other researchers.

Now it is our responsibility to continue to train them as to when to use
certain tools.
> 
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
> 
> 
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
>> models-bounces at r-project.org] On Behalf Of Ben Bolker
>> Sent: Tuesday, October 07, 2008 11:44 AM
>> To: Martijn Vandegehuchte; R Mixed Models
>> Subject: Re: [R-sig-ME] generalized linear mixed models: large
>> differences when using glmmPQL or lmer with laplace approximation
>>
>> Martijn Vandegehuchte wrote:
>>> First of all, thanks a lot for the info.
>>>
>>> I know the differences seem small, but most ecological journals still
>>> let their opinion about ecological relevance of predictors depend
>>> completely on p-values... So I think I'll stick to lmer because of
>> the
>>> Laplace approximation.
>>   Well, Laplace should be better anyway.  (If the difference were in
>> the other direction -- non-significant with Laplace and significant
>> with
>> glmmPQL -- I would still tell you to use Laplace.)
>>
>>   To speak to Greg Snow's comment ("don't worry about p-values, just
>> look at predictions") -- this is really tough.  I still don't know
>> what to do about the compromise between how statistics should be done
>> and how journal editors seem to insist it should be done ...
>>
>>   cheers
>>    Ben
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFI7Sh9c5UpGjwzenMRAsXeAKCMiqRLxikc8u8zxnXPK702D0XoNgCgjm2q
y/NYurfZ/jK/AOK7aGkdDkc=
=f++H
-----END PGP SIGNATURE-----



From logodall at yahoo.fr  Thu Oct  9 10:45:19 2008
From: logodall at yahoo.fr (logodall)
Date: Thu, 9 Oct 2008 08:45:19 +0000 (GMT)
Subject: [R-sig-ME] problems of compatibility between different versions of
	lme4?
Message-ID: <845974.75951.qm@web26005.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081009/05d7fd25/attachment.pl>

From francois.mercier at novartis.com  Thu Oct  9 14:27:41 2008
From: francois.mercier at novartis.com (francois.mercier at novartis.com)
Date: Thu, 9 Oct 2008 08:27:41 -0400
Subject: [R-sig-ME] Singular estimated var-cov
Message-ID: <OF039D515D.596C1EB3-ON852574DD.00446335-852574DD.0044743A@ah.novartis.com>

Dear list members,

I try to fit a model (using lmer) to data recorded at 4 time points 
(days). Each such time series corresponds to a distinct subject. There are 
two treatment groups. There is also a patient-level covariate ("o" or 
"b").  I am attaching the data frame (as a binary R object) and the R 
script that loads the data frame and fits the models.

The questions are 1) whether the drug effect is influenced by the 
covariate, and 2) whether there is a temporal trend in drug effect over 
days.

The problem is that according LMER the covariance matrix for this problem 
is singular, and as a result the fitted models do not capture the 
variability of slopes that is seen in the data. Apparently there is a 
strong correlation between some parameters that leads to this singularity 
? Perhaps I misspecified the model for LMER (and LME) ?

Thank you very much for your help!
Best regards,

Francois



From francois.mercier at novartis.com  Thu Oct  9 14:39:56 2008
From: francois.mercier at novartis.com (francois.mercier at novartis.com)
Date: Thu, 9 Oct 2008 08:39:56 -0400
Subject: [R-sig-ME] Singular estimated var-cov
In-Reply-To: <OF039D515D.596C1EB3-ON852574DD.00446335-852574DD.0044743A@ah.novartis.com>
Message-ID: <OFA828439E.712B8B75-ON852574DD.00458928-852574DD.0045934F@ah.novartis.com>

francois.mercier at novartis.com 
Sent by: r-sig-mixed-models-bounces at r-project.org
10/09/2008 08:37 AM

To
r-sig-mixed-models at r-project.org
cc

Subject
[R-sig-ME] Singular estimated var-cov






Dear list members,

I try to fit a model (using lmer) to data recorded at 4 time points 
(days). Each such time series corresponds to a distinct subject. There are 

two treatment groups. There is also a patient-level covariate ("o" or 
"b").  I am attaching the data frame (as a binary R object) and the R 
script that loads the data frame and fits the models.

The questions are 1) whether the drug effect is influenced by the 
covariate, and 2) whether there is a temporal trend in drug effect over 
days.

The problem is that according LMER the covariance matrix for this problem 
is singular, and as a result the fitted models do not capture the 
variability of slopes that is seen in the data. Apparently there is a 
strong correlation between some parameters that leads to this singularity 
? Perhaps I misspecified the model for LMER (and LME) ?

Thank you very much for your help!
Best regards,

Francois


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Wolfgang.Viechtbauer at STAT.unimaas.nl  Thu Oct  9 18:25:58 2008
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 9 Oct 2008 18:25:58 +0200
Subject: [R-sig-ME] [Rd] seg.fault from nlme::gnls() {was " GNLS Crash"}
In-Reply-To: <FBFBD35F5823FD4E97ACDEBB353DD9C608D79D@NA-PA-VBE01.na.tibco.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF0EB93FB9@um-mail0136.unimaas.nl>

Hello All,

I just wanted to bring this back again to the attention of the list(s) just to see if this issue can be resolved (but I'll understand if the development of the new mixed-model functions would take precedence over this).

Best,

-- 
Wolfgang Viechtbauer
?Department of Methodology and Statistics
?University of Maastricht, The Netherlands
?http://www.wvbauer.com/



----Original Message----
From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Monday, September 29, 2008 21:03
To: Martin Maechler; Viechtbauer Wolfgang (STAT)
Cc: r-sig-mixed-models at r-project.org; R-devel at stat.math.ethz.ch
Subject: RE: [Rd] seg.fault from nlme::gnls() {was "[R-sig-ME] GNLS
Crash"} 

>  When I run this under valgrind with gctorture(TRUE) I see memory
> misuse in mat_mult (matrix.c, line 82): % R-2.8.0-dev
> --debugger=valgrind --debugger-args=--db-attach=yes ... copyright
> blah blah ...   
>> data(Orange)
>> gctorture(TRUE)
>> gnls(circumference ~ Asym/(1 + exp(-(age-xmid)/scal)) ,
> + data = Orange, correlation = corExp(form = ~1 | Tree),
> + start = c(Asym=150, xmid=750, scal=300))
> r==5894== Invalid read of size 4
> ==5894==    at 0x580268F: mult_mat (matrix.c:82)
> ==5894==    by 0x57FF1B0: corStruct_recalc (corStruct.c:70)
> ==5894==    by 0x5801F89: gnls_objective (gnls.c:100)
> ==5894==    by 0x58020FE: fit_gnls (gnls.c:152)
> ==5894==    by 0x81439A2: do_dotCode (dotcode.c:1758)
> ==5894==    by 0x8161C56: Rf_eval (eval.c:487)
> ==5894==    by 0x81637D5: do_set (eval.c:1422)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==    by 0x816384B: do_begin (eval.c:1174)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==    by 0x816397B: do_repeat (eval.c:1137)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==  Address 0x4E4A8CC is 12 bytes inside a block of size 864
> free'd ==5894==    at 0x40052A3: free (vg_replace_malloc.c:233)
> ==5894==    by 0x805ACFD: R_gc_internal (memory.c:767)
> ==5894==    by 0x805B933: Rf_cons (memory.c:1755)
> ==5894==    by 0x805B98E: Rf_allocList (memory.c:2094)
> ==5894==    by 0x815AB4C: replaceCall (Rinlinedfuns.h:84)
> ==5894==    by 0x8163476: applydefine (eval.c:919)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==    by 0x816384B: do_begin (eval.c:1174)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> ==5894==    by 0x816384B: do_begin (eval.c:1174)
> ==5894==    by 0x8161B3B: Rf_eval (eval.c:461)
> 
> My copy of valgrind doesn't get along with my copy of gdb,
> so when it pops into gdb the debugger doesn't get any information
> from *.so files.  I don't have the time now to put printf statements
> into mat_mult.  
> 
> Bill Dunlap
> wdunlap tibco.com
> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Maechler 
> Sent: Saturday, September 27, 2008 2:20 AM
> To: Viechtbauer Wolfgang (STAT)
> Cc: r-sig-mixed-models at r-project.org; R-devel at stat.math.ethz.ch
> Subject: [Rd] seg.fault from nlme::gnls() {was "[R-sig-ME] GNLS
> Crash"} 
> 
>>>>>> "VW" == Viechtbauer Wolfgang (STAT)
>>>>>>     <Wolfgang.Viechtbauer at STAT.unimaas.nl> on Fri, 26 Sep 2008
>>>>>> 18:00:19 +0200 writes: 
> 
>> Hi all, I'm trying to fit a marginal (longitudinal)
>> model with an exponential serial correlation function to
>> the Orange tree data set. However, R crashes frequently
>> when using the gnls() function. With the following
>> simple example, I was able to reproduce the problem.
> 
> 
>> gnls.exp <- gnls(circumference ~ Asym/(1 + exp(-(age-xmid)/scal)) ,
>> data = Orange, correlation = corExp(form = ~1 | Tree),
>> start = c(Asym=150, xmid=750, scal=300))
> 
> Yes, I can reproduce it (on a Linux (RHEL 5) 64bit server), using R
> 2.8.0 alpha : Use this 
> 
> for(i in 1:20)# for MM: ca. 8 to 10 times --> seg.fault try( gnls.exp
>               <- gnls(circumference ~ Asym/(1 +
>               exp(-(age-xmid)/scal)) , data = Orange, correlation =
> corExp(form = ~1 | Tree), start = c(Asym=150, xmid=750, scal=300)) )
> 
> If I run it in the debugger and then do a backtrace I see
> 
> Error in gnls(circumference ~ Asym/(1 + exp(-(age - xmid)/scal)),
>   data = Orange,  : Step halving factor reduced below minimum in NLS
> step 
> 
> [............................................................]
> [...................the same about 6 times...................]
> [............................................................] 
> 
> Error in gnls(circumference ~ Asym/(1 + exp(-(age - xmid)/scal)),
>   data = Orange,  : Step halving factor reduced below minimum in NLS
>   step Error in .makeMessage(..., domain = domain) : incorrect number
> of arguments to "<-" 
> Error in .makeMessage(..., domain = domain) :
>   incorrect number of arguments to "<-"
> 
> Program received signal SIGABRT, Aborted.
> 0x0000003294e30155 in raise () from /lib64/libc.so.6
> (gdb) bt
> #0  0x0000003294e30155 in raise () from /lib64/libc.so.6
> #1  0x0000003294e31bf0 in abort () from /lib64/libc.so.6
> #2  0x00000000004184f5 in R_gc_internal (size_needed=0)
>     at ../../../R/src/main/memory.c:761
> #3  0x000000000041b121 in Rf_cons (car=0x1b2ec088, cdr=0x1a3436d8)
>     at ../../../R/src/main/memory.c:1755
> #4  0x0000000000578472 in applydefine (call=<value optimized out>,
>     op=0x1a3617a8, args=0x1ad47590, rho=0x1b2ea428)
>     at ../../../R/src/include/Rinlinedfuns.h:153
> #5  0x0000000000575a42 in Rf_eval (e=0x1ad47558, rho=0x1b2ea428)
>     at ../../../R/src/main/eval.c:461
> #6  0x0000000000576d50 in do_begin (call=0x1ad48450, op=0x1a362518,
>     args=0x1ad47520, rho=0x1b2ea428) at
>     ../../../R/src/main/eval.c:1174 #7  0x0000000000575a42 in Rf_eval
> (e=0x1ad48450, rho=0x1b2ea428) at ../../../R/src/main/eval.c:461 #8 
>     0x0000000000578f9c in Rf_applyClosure (call=0x1b2e9958,
>     op=0x1ad48370, arglist=0x1b2e9a70, rho=0x1b690298,
> suppliedenv=0x1b2e99c8) at ../../../R/src/main/eval.c:667 #9 
>     0x00000000004285b9 in Rf_usemethod (generic=0x67e8d7 "[",
>     obj=<value optimized out>, call=<value optimized out>,
>     args=<value optimized out>, rho=0xffffffffffffffff,
>     callrho=0x1b690298, defrho=0x1a384f28, ans=0x7fffcaa8d5a8) at
>     ../../../R/src/main/objects.c:311 #10 0x0000000000576a25 in
>     Rf_DispatchOrEval (call=0x1a81d8d0, op=0x1a3622e8,
>     generic=0x67e8d7 "[", args=0x1a81d908, rho=0x1b690298,
> ans=0x7fffcaa8d5a8, dropmissing=0, argsevald=0) at
>     ../../../R/src/main/eval.c:1930 #11 0x00000000004afc40 in
> do_subset (call=0x7716, op=0x7716, args=0xffffffffffffffff,
>     rho=0x1b690298) at ../../../R/src/main/subset.c:577 #12
>     0x0000000000575a42 in Rf_eval (e=0x1a81d8d0, rho=0x1b690298) at
> ../../../R/src/main/eval.c:461 #13 0x00000000005780c7 in applydefine
>     (call=0x1a81d748, op=0x1a3617a8, args=0x6,
> rho=0xffffffffffffffff) at ../../../R/src/main/eval.c:1318 #14
> 0x0000000000575a42 in Rf_eval (e=0x1a81d748, rho=0x1b690298) at
> ../../../R/src/main/eval.c:461 #15 0x00000000005775de in do_for
> (call=0x1a81d668, op=0x1a360180, args=0x1a81d6a0, rho=0x1b690298) at
> ../../../R/src/main/eval.c:1073     
> 
> ..... and more (downto #155 for R's main(...)
> 
> This is a bug,  probably in the C code of package nlme which I guess
> corrupts memory somehere earlier, and we are seeing the effect only
> later. I'll leave this to the (memory-)debugging experts...  
> 
> Martin
> 
>> On my and one other computer, R usually crashes when calling the
>> gnls() function with this code three times in a row. I stumbled
>> across this when trying to fit this model with different starting
>> values.   
> 
>> Version information:
> 
>> platform       i386-pc-mingw32
>     ......
>> version.string R version 2.7.2 (2008-08-25)
> 
>> Can anybody help figure out what causes this problem?
> 
>> Best,
> 
>> --
>> Wolfgang Viechtbauer
>> ?Department of Methodology and Statistics
>> ?University of Maastricht, The Netherlands
>> ?http://www.wvbauer.com/



From bolker at ufl.edu  Fri Oct 10 21:47:51 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 10 Oct 2008 15:47:51 -0400
Subject: [R-sig-ME] Fwd: Re:  Wald F tests
Message-ID: <48EFB167.4000003@ufl.edu>


  Does anyone out there have opinions on this subject?
How should one test hypotheses about fixed effects in
(G)LMMs, especially for small to moderate sample sizes?
(Please ignore issues of _estimation_ (PQL
vs Laplace vs AGQ vs ...)

  Should it amuse you to do so, you can vote at:

http://www.surveymonkey.com/s.aspx?sm=yLyfrV_2ftw6WGx2dEFLWnIw_3d_3d

(since we all know that scientific questions are settled
by a democratic process)

a hypothesis testing is soooo 20th century, don't bother
b likelihood ratio tests [ignore known anticonservatism]
c F tests (LMM) or Wald tests (GLMM) [ignore mismatch with hypothesized
null distributions]
d bootstrapped confidence intervals
e [mcmcsamp confidence intervals -- if available]
f randomization/simulation tests of nested null hypotheses
g AIC comparisons [ignore that prediction != hypothesis testing]

  Note that Wald Z tests [option c] are more or less what you're
doing, implicitly, if you just eyeball the estimated
parameter values and their standard errors.

  cheers
    Ben Bolker

-------- Original Message --------
Subject: [Fwd: Re: [R-sig-ME] Wald F tests]
Date: Tue, 07 Oct 2008 17:51:01 -0400
From: Ben Bolker <bolker at ufl.edu>
To: R Mixed Models <r-sig-mixed-models at r-project.org>


  But ... LRTs are non-recommended (anticonservative) for
comparing fixed effects of LMMs hence (presumably) for
GLMMs, unless sample size (# blocks/"residual" total sample
size) is large, no?

I just got through telling readers of
a forthcoming TREE (Trends in Ecology and Evolution) article
that they should use Wald Z, chi^2, t, or F (depending on
whether testing a single or multiple parameters, and whether
there is overdispersion or not), in preference to LRTs,
for testing fixed effects ... ?  Or do you consider LRT
better than Wald in this case (in which case as far as
we know _nothing_ works very well for GLMMs, and I might
just start to cry ...)  Or perhaps I have to get busy
running some simulations ...

  Where would _you_ go to find advice on inference
(as opposed to estimation) on estimated GLMM parameters?

  cheers
   Ben Bolker

Douglas Bates wrote:
> If I were using glmer to fit a generalized linear mixed model I would
> use likelihood ratio tests rather than Wald tests.  That is, I would
> fit a model including a particular term then fit it again without that
> term and calculate the difference in the deviance values, comparing
> that to a chi-square.
>
> I'm not sure how one would do this using the results from glmmPQL.
>
> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>  [forwarding to R-sig-mixed, where it is likely to get more
>> responses]
>>
>> Mark Fowler wrote:
>>
>> Hello,
>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>> and have seen it recommended in user group discussions, but haven't come
>> across any code to accomplish it. I understand the anova function treats
>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>> have R 2.7 and S-Plus 8 if necessary.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From john.maindonald at anu.edu.au  Sat Oct 11 07:09:04 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 11 Oct 2008 16:09:04 +1100
Subject: [R-sig-ME] Fwd: Re:  Wald F tests
In-Reply-To: <48EFB167.4000003@ufl.edu>
References: <48EFB167.4000003@ufl.edu>
Message-ID: <E605F02E-067C-4ECF-8915-4168F72B14C2@anu.edu.au>

I think it is going too far to say that one should not be
testing hypotheses (the implication of that "is soooo 20th C"?).
But the place of that activity is much more limited than is
commonly recognized.

Basically, I do not like the range of options that this (half-serious?)
survey has on offer, and I'd need to write half a page or more
to explain why.  Democracy maybe, but (as I suppose is
always the case in the political democracies that are on offer)
the choices are severely constrained.

Where such a hypothesis testing perspective may be
appropriate, the preferred starting point is almost always
a confidence interval.  Why not ask the comparable questions
arise for estimation?

There's an editorial in Volume 72(5) (pp.1057-1058) of the
Journal of Wildlife Management with which I pretty much agree:
"... understand that the average reader of the Journal is
interested in the biological questions addressed with your
work.  The analytical framework and resulting results should
support those questions and flow from them, not overwhelm
them."

But I guess that Ben would like us to assume that the proper
support framework is in place!

Note also, on pages 1272-1278 of the same issue:
"Suggestions for Basic Graph Use When Reporting Wildlife
Research Results", by Brett Collier.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 11/10/2008, at 6:47 AM, Ben Bolker wrote:

>
> Does anyone out there have opinions on this subject?
> How should one test hypotheses about fixed effects in
> (G)LMMs, especially for small to moderate sample sizes?
> (Please ignore issues of _estimation_ (PQL
> vs Laplace vs AGQ vs ...)
>
> Should it amuse you to do so, you can vote at:
>
> http://www.surveymonkey.com/s.aspx?sm=yLyfrV_2ftw6WGx2dEFLWnIw_3d_3d
>
> (since we all know that scientific questions are settled
> by a democratic process)
>
> a hypothesis testing is soooo 20th century, don't bother
> b likelihood ratio tests [ignore known anticonservatism]
> c F tests (LMM) or Wald tests (GLMM) [ignore mismatch with  
> hypothesized
> null distributions]
> d bootstrapped confidence intervals
> e [mcmcsamp confidence intervals -- if available]
> f randomization/simulation tests of nested null hypotheses
> g AIC comparisons [ignore that prediction != hypothesis testing]
>
> Note that Wald Z tests [option c] are more or less what you're
> doing, implicitly, if you just eyeball the estimated
> parameter values and their standard errors.
>
> cheers
>   Ben Bolker
>
> -------- Original Message --------
> Subject: [Fwd: Re: [R-sig-ME] Wald F tests]
> Date: Tue, 07 Oct 2008 17:51:01 -0400
> From: Ben Bolker <bolker at ufl.edu>
> To: R Mixed Models <r-sig-mixed-models at r-project.org>
>
>
> But ... LRTs are non-recommended (anticonservative) for
> comparing fixed effects of LMMs hence (presumably) for
> GLMMs, unless sample size (# blocks/"residual" total sample
> size) is large, no?
>
> I just got through telling readers of
> a forthcoming TREE (Trends in Ecology and Evolution) article
> that they should use Wald Z, chi^2, t, or F (depending on
> whether testing a single or multiple parameters, and whether
> there is overdispersion or not), in preference to LRTs,
> for testing fixed effects ... ?  Or do you consider LRT
> better than Wald in this case (in which case as far as
> we know _nothing_ works very well for GLMMs, and I might
> just start to cry ...)  Or perhaps I have to get busy
> running some simulations ...
>
> Where would _you_ go to find advice on inference
> (as opposed to estimation) on estimated GLMM parameters?
>
> cheers
>  Ben Bolker
>
> Douglas Bates wrote:
>> If I were using glmer to fit a generalized linear mixed model I would
>> use likelihood ratio tests rather than Wald tests.  That is, I would
>> fit a model including a particular term then fit it again without  
>> that
>> term and calculate the difference in the deviance values, comparing
>> that to a chi-square.
>>
>> I'm not sure how one would do this using the results from glmmPQL.
>>
>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>> [forwarding to R-sig-mixed, where it is likely to get more
>>> responses]
>>>
>>> Mark Fowler wrote:
>>>
>>> Hello,
>>>      Might anyone know how to conduct Wald-type F-tests of the fixed
>>> effects estimated by glmmPQL? I see this implemented in SAS  
>>> (GLIMMIX),
>>> and have seen it recommended in user group discussions, but  
>>> haven't come
>>> across any code to accomplish it. I understand the anova function  
>>> treats
>>> a glmmPQL fit as an lme fit, with the test assumptions based on  
>>> maximum
>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I  
>>> also
>>> have R 2.7 and S-Plus 8 if necessary.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken at kjbeath.com.au  Sat Oct 11 07:17:45 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Sat, 11 Oct 2008 16:17:45 +1100
Subject: [R-sig-ME] generalized linear mixed models: large differences
	when using glmmPQL or lmer with laplace approximation
In-Reply-To: <40e66e0b0810071418s57931113ne07fb62aee288f7e@mail.gmail.com>
References: <046780BC8E8D47DD9765E84222E8858C@Mythimna>
	<96A80D27-185D-4AC7-AA29-69AE4B3F3A3A@kjbeath.com.au>
	<40e66e0b0810071418s57931113ne07fb62aee288f7e@mail.gmail.com>
Message-ID: <B77C60E9-D81B-496B-84A4-18E1BBF160CD@kjbeath.com.au>


On 08/10/2008, at 8:18 AM, Douglas Bates wrote:

> On Tue, Oct 7, 2008 at 4:07 PM, Ken Beath <ken at kjbeath.com.au> wrote:
>> There is a large difference between the estimated std of the random  
>> effect,
>> usually a sign that the glmmPQL approximation isn't working.
>
> Or that there is a mistake in the calculation of the standard errors
> for the random effects, which is more likely in this case.
>
> The actual optimization is with respect to the relative standard
> deviation of the random effects (relative to the scale parameter in
> the conditional standard deviation of the response).  For the Poisson
> family or the binomial family that scale parameter is fixed at 1 (you
> could also consider the situation to be that there isn't a scale
> parameter in those cases).  For the quasipoisson and quasibinomial
> families you maybe estimate a value there or maybe not.  I don't know.
> I believe Ben's simulations showed that I was doing the wrong thing
> there

Definitely something wrong. I did some simulations of my own using  
Poisson distributed data. The standard error of the fixed effects also  
seems rather large.

 > nsubj <- 100
 > npersubj <- 20
 >
 > subject <- factor(rep(1:nsubj,each=npersubj))
 >
 > means <- exp(rep(10+rnorm(nsubj),each=npersubj))
 >
 > y <- rpois(nsubj*npersubj,means)
 >
 > simdata <- data.frame(y,subject)
 >
 > lmer1 <- lmer(y~(1|subject),data=simdata,family=poisson)
 > summary(lmer1)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ (1 | subject)
    Data: simdata
   AIC  BIC logLik deviance
  3329 3341  -1663     3325
Random effects:
  Groups  Name        Variance Std.Dev.
  subject (Intercept) 0.9102   0.95405
Number of obs: 2000, groups: subject, 100

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   9.9734     0.0954   104.5   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 >
 > lmer2 <- lmer(y~(1|subject),data=simdata,family=quasipoisson)
 > summary(lmer2)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ (1 | subject)
    Data: simdata
   AIC  BIC logLik deviance
  3331 3348  -1663     3325
Random effects:
  Groups   Name        Variance Std.Dev.
  subject  (Intercept) 11794    108.60
  Residual             12957    113.83
Number of obs: 2000, groups: subject, 100

Fixed effects:
             Estimate Std. Error t value
(Intercept)    9.973     10.860  0.9184
 >


Ken


From bolker at ufl.edu  Sat Oct 11 23:06:20 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 11 Oct 2008 17:06:20 -0400
Subject: [R-sig-ME] Fwd: Re:  Wald F tests
In-Reply-To: <E605F02E-067C-4ECF-8915-4168F72B14C2@anu.edu.au>
References: <48EFB167.4000003@ufl.edu>
	<E605F02E-067C-4ECF-8915-4168F72B14C2@anu.edu.au>
Message-ID: <48F1154C.2060806@ufl.edu>

  Yes, this is partly tongue in cheek, and I agree that
hypothesis testing is overemphasized (I suspect that many
of the r-sig-mixed-models regulars would also agree).  Let's
say we want to construct confidence intervals rather than
test null hypotheses.  Then our choices are something like

* construct Z- or t-based confidence intervals from
estimated standard error
* bootstrap confidence intervals
* mcmcsamp confidence intervals

  which correspond to c,d,e below.  I suppose another
choice (corresponding more or less to b, LRT)
would be likelihood profile
confidence intervals, but I would really worry in
this case that the known anticonservatism of LRTs
would translate to profile confidence intervals
with poor coverage.

Most of the difficulties that arise in null-hypothesis testing have
analogues in constructing appropriate confidence intervals.

  cheers
    Ben Bolker

>> c F tests (LMM) or Wald tests (GLMM) [ignore mismatch with hypothesized
>> null distributions]
>> d bootstrapped confidence intervals
>> e [mcmcsamp confidence intervals -- if available]
>> f randomization/simulation tests of nested null hypotheses
>> g AIC comparisons [ignore that prediction != hypothesis testing]

John Maindonald wrote:
> I think it is going too far to say that one should not be
> testing hypotheses (the implication of that "is soooo 20th C"?).
> But the place of that activity is much more limited than is
> commonly recognized.
> 
> Basically, I do not like the range of options that this (half-serious?)
> survey has on offer, and I'd need to write half a page or more
> to explain why.  Democracy maybe, but (as I suppose is
> always the case in the political democracies that are on offer)
> the choices are severely constrained.
> 
> Where such a hypothesis testing perspective may be
> appropriate, the preferred starting point is almost always
> a confidence interval.  Why not ask the comparable questions
> arise for estimation?
> 
> There's an editorial in Volume 72(5) (pp.1057-1058) of the
> Journal of Wildlife Management with which I pretty much agree:
> "... understand that the average reader of the Journal is
> interested in the biological questions addressed with your
> work.  The analytical framework and resulting results should
> support those questions and flow from them, not overwhelm
> them."
> 
> But I guess that Ben would like us to assume that the proper
> support framework is in place!
> 
> Note also, on pages 1272-1278 of the same issue:
> "Suggestions for Basic Graph Use When Reporting Wildlife
> Research Results", by Brett Collier.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 11/10/2008, at 6:47 AM, Ben Bolker wrote:
> 
>>
>> Does anyone out there have opinions on this subject?
>> How should one test hypotheses about fixed effects in
>> (G)LMMs, especially for small to moderate sample sizes?
>> (Please ignore issues of _estimation_ (PQL
>> vs Laplace vs AGQ vs ...)
>>
>> Should it amuse you to do so, you can vote at:
>>
>> http://www.surveymonkey.com/s.aspx?sm=yLyfrV_2ftw6WGx2dEFLWnIw_3d_3d
>>
>> (since we all know that scientific questions are settled
>> by a democratic process)
>>
>> a hypothesis testing is soooo 20th century, don't bother
>> b likelihood ratio tests [ignore known anticonservatism]
>> c F tests (LMM) or Wald tests (GLMM) [ignore mismatch with hypothesized
>> null distributions]
>> d bootstrapped confidence intervals
>> e [mcmcsamp confidence intervals -- if available]
>> f randomization/simulation tests of nested null hypotheses
>> g AIC comparisons [ignore that prediction != hypothesis testing]
>>
>> Note that Wald Z tests [option c] are more or less what you're
>> doing, implicitly, if you just eyeball the estimated
>> parameter values and their standard errors.
>>
>> cheers
>>   Ben Bolker
>>
>> -------- Original Message --------
>> Subject: [Fwd: Re: [R-sig-ME] Wald F tests]
>> Date: Tue, 07 Oct 2008 17:51:01 -0400
>> From: Ben Bolker <bolker at ufl.edu>
>> To: R Mixed Models <r-sig-mixed-models at r-project.org>
>>
>>
>> But ... LRTs are non-recommended (anticonservative) for
>> comparing fixed effects of LMMs hence (presumably) for
>> GLMMs, unless sample size (# blocks/"residual" total sample
>> size) is large, no?
>>
>> I just got through telling readers of
>> a forthcoming TREE (Trends in Ecology and Evolution) article
>> that they should use Wald Z, chi^2, t, or F (depending on
>> whether testing a single or multiple parameters, and whether
>> there is overdispersion or not), in preference to LRTs,
>> for testing fixed effects ... ?  Or do you consider LRT
>> better than Wald in this case (in which case as far as
>> we know _nothing_ works very well for GLMMs, and I might
>> just start to cry ...)  Or perhaps I have to get busy
>> running some simulations ...
>>
>> Where would _you_ go to find advice on inference
>> (as opposed to estimation) on estimated GLMM parameters?
>>
>> cheers
>>  Ben Bolker
>>
>> Douglas Bates wrote:
>>> If I were using glmer to fit a generalized linear mixed model I would
>>> use likelihood ratio tests rather than Wald tests.  That is, I would
>>> fit a model including a particular term then fit it again without that
>>> term and calculate the difference in the deviance values, comparing
>>> that to a chi-square.
>>>
>>> I'm not sure how one would do this using the results from glmmPQL.
>>>
>>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>> [forwarding to R-sig-mixed, where it is likely to get more
>>>> responses]
>>>>
>>>> Mark Fowler wrote:
>>>>
>>>> Hello,
>>>>      Might anyone know how to conduct Wald-type F-tests of the fixed
>>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>>> and have seen it recommended in user group discussions, but haven't
>>>> come
>>>> across any code to accomplish it. I understand the anova function
>>>> treats
>>>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>>> have R 2.7 and S-Plus 8 if necessary.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From reinhold.kliegl at gmail.com  Mon Oct 13 08:18:58 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 13 Oct 2008 14:18:58 +0800
Subject: [R-sig-ME] dotplot of ranef
Message-ID: <aefe4d0a0810122318p6e334087ocf887e58a3ee2e55@mail.gmail.com>

Taking the example from:
?ranef

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
rr1 <- ranef(fm1, postVar = TRUE)
dotplot(rr1,scales = list(x = list(relation = 'free')))[["Subject"]]

How would I need to modify dotplot() to have "Subject" sorted for
"Days", rather than "(Intercept)"?

Thanks in advance.

Reinhold Kliegl



From paul.goedhart at wur.nl  Mon Oct 13 16:52:31 2008
From: paul.goedhart at wur.nl (Goedhart, Paul)
Date: Mon, 13 Oct 2008 16:52:31 +0200
Subject: [R-sig-ME]  [Fwd: Re: Wald F tests]
Message-ID: <1F4755565F237F45AA01135B72E8C1B2013E3F49@scomp0039.wurnet.nl>

Hello,

Apparently Ben Bolker and Douglas Bates have different opinions on
testing fixed effects in GLMMs (see below). Does anyone know of any
(simulation) papers on this issue?

Ben Bolker wrote
> But ... LRTs are non-recommended (anticonservative) for comparing 
> fixed effects of LMMs hence (presumably) for GLMMs, unless sample 
> size (# blocks/"residual" total sample size) is large, no?

Douglas Bates wrote:
> If I were using glmer to fit a generalized linear mixed model I would 
> use likelihood ratio tests rather than Wald tests. That is, I would 
> fit a model including a particular term then fit it again without that

> term and calculate the difference in the deviance values, comparing 
> that to a chi-square.
>

Paul Goedhart, Biometris, Wageningen UR, The Netherlands



From bates at stat.wisc.edu  Mon Oct 13 21:05:49 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2008 14:05:49 -0500
Subject: [R-sig-ME] [Fwd: Re: Wald F tests]
In-Reply-To: <48EBD9C5.7080102@ufl.edu>
References: <48EBD9C5.7080102@ufl.edu>
Message-ID: <40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>

On Tue, Oct 7, 2008 at 4:51 PM, Ben Bolker <bolker at ufl.edu> wrote:

>  But ... LRTs are non-recommended (anticonservative) for
> comparing fixed effects of LMMs hence (presumably) for
> GLMMs, unless sample size (# blocks/"residual" total sample
> size) is large, no?

> I just got through telling readers of
> a forthcoming TREE (Trends in Ecology and Evolution) article
> that they should use Wald Z, chi^2, t, or F (depending on
> whether testing a single or multiple parameters, and whether
> there is overdispersion or not), in preference to LRTs,
> for testing fixed effects ... ?  Or do you consider LRT
> better than Wald in this case (in which case as far as
> we know _nothing_ works very well for GLMMs, and I might
> just start to cry ...)  Or perhaps I have to get busy
> running some simulations ...

My reasoning, based on my experiences with nonlinear regression models
and other nonlinear models, is that a test that involves fitting the
alternative model and the null model then comparing the quality of the
fit will give more realistic results than a test that only involves
fitting the alternative model and using that fit to extrapolate to
what the null model fit should be like.

We will always use approximations in statistics but as we get more
powerful computing facilities some of the approximations that we
needed to use in the past can be avoided.  I view Wald tests as an
approximation to the quantity that we want to use to compare models,
which is some measure of the comparative fit.  The likelihood ratio or
the change in the deviance seems to be a reasonable way of comparing
the fits of two nested models.  There may be problems with calibrating
that quantity (i.e. converting it to a p-value) in which case we may
want to use a bootstrap or some other simulation-based method like
MCMC.  However, I don't think this difficulty would cause me to say
that it is better to use an approximation to the model fit under the
null hypothesis than to go ahead and fit it.

>  Where would _you_ go to find advice on inference
> (as opposed to estimation) on estimated GLMM parameters?

I'm not sure.  As I once said to Martin, my research involves far too
much "re" and far too little "search".  Probably because of laziness I
tend to try to reason things out instead of conducting literature
reviews.

>  cheers
>   Ben Bolker
>
> Douglas Bates wrote:
>> If I were using glmer to fit a generalized linear mixed model I would
>> use likelihood ratio tests rather than Wald tests.  That is, I would
>> fit a model including a particular term then fit it again without that
>> term and calculate the difference in the deviance values, comparing
>> that to a chi-square.
>>
>> I'm not sure how one would do this using the results from glmmPQL.
>>
>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>  [forwarding to R-sig-mixed, where it is likely to get more
>>> responses]
>>>
>>> Mark Fowler wrote:
>>>
>>> Hello,
>>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>> and have seen it recommended in user group discussions, but haven't come
>>> across any code to accomplish it. I understand the anova function treats
>>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>> have R 2.7 and S-Plus 8 if necessary.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Mon Oct 13 21:46:54 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 13 Oct 2008 15:46:54 -0400
Subject: [R-sig-ME] [Fwd: Re: Wald F tests]
In-Reply-To: <40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
References: <48EBD9C5.7080102@ufl.edu>
	<40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
Message-ID: <48F3A5AE.1090705@ufl.edu>


  Doug's response makes perfect sense to me.

  However, from the on-the-ground, what-do-I-say-about-my-data-now
point of view, it seems that this is really an empirical question.
I would guess (wildly) that both the LRT and the Wald test would
converge asymptotically on the right answer.  **For classical ML
problems**, I have the feeling (unsupported by evidence!) that
LRT converges faster/is less wrong at any given value of N than
Wald tests (which, as you say, represent a second level of
approximation). I have no idea if this is true for GLMMs.
Really the only reason that I spoke against LRTs was that it
is well known (as shown e.g. in PB2000) that they are dicey for
LMMs, while the situation for Wald tests is relatively unknown.
In the absence of data, which is stronger: our prior belief that Wald
tests are bad because they're less reliable than LRT in some other
contexts, or our optimism that Wald tests aren't bad because they
haven't been shown to be so?

  If it really hasn't been done (and while I'm far from omniscient
I did *try* to review the literature on this topic, and have yet
to find an answer, or to have anyone on this list provide
an answer), I guess it's time to crank up
the old simulation engine and have a look ...

  For what it's worth, the results of the (possibly misguided)
inference survey so far are:

don't test hypotheses: 5
LRTs: 5
F/Wald tests: 7
bootstrap: 4
mcmcsamp: 8
randomization of null hyp: 5
AIC: 4
  + 2 write-ins:
  1 for "consilience of approaches"
  1 for BIC

  (out of 26 respondents)

  In hindsight, I would have liked to take mcmcsamp off the table
(or put it in a separate category) since I am really most interested in
finding out/telling researchers what to do NOW.

  cheers
    Ben Bolker

Douglas Bates wrote:
> On Tue, Oct 7, 2008 at 4:51 PM, Ben Bolker <bolker at ufl.edu> wrote:
> 
>>  But ... LRTs are non-recommended (anticonservative) for
>> comparing fixed effects of LMMs hence (presumably) for
>> GLMMs, unless sample size (# blocks/"residual" total sample
>> size) is large, no?
> 
>> I just got through telling readers of
>> a forthcoming TREE (Trends in Ecology and Evolution) article
>> that they should use Wald Z, chi^2, t, or F (depending on
>> whether testing a single or multiple parameters, and whether
>> there is overdispersion or not), in preference to LRTs,
>> for testing fixed effects ... ?  Or do you consider LRT
>> better than Wald in this case (in which case as far as
>> we know _nothing_ works very well for GLMMs, and I might
>> just start to cry ...)  Or perhaps I have to get busy
>> running some simulations ...
> 
> My reasoning, based on my experiences with nonlinear regression models
> and other nonlinear models, is that a test that involves fitting the
> alternative model and the null model then comparing the quality of the
> fit will give more realistic results than a test that only involves
> fitting the alternative model and using that fit to extrapolate to
> what the null model fit should be like.
> 
> We will always use approximations in statistics but as we get more
> powerful computing facilities some of the approximations that we
> needed to use in the past can be avoided.  I view Wald tests as an
> approximation to the quantity that we want to use to compare models,
> which is some measure of the comparative fit.  The likelihood ratio or
> the change in the deviance seems to be a reasonable way of comparing
> the fits of two nested models.  There may be problems with calibrating
> that quantity (i.e. converting it to a p-value) in which case we may
> want to use a bootstrap or some other simulation-based method like
> MCMC.  However, I don't think this difficulty would cause me to say
> that it is better to use an approximation to the model fit under the
> null hypothesis than to go ahead and fit it.
> 
>>  Where would _you_ go to find advice on inference
>> (as opposed to estimation) on estimated GLMM parameters?
> 
> I'm not sure.  As I once said to Martin, my research involves far too
> much "re" and far too little "search".  Probably because of laziness I
> tend to try to reason things out instead of conducting literature
> reviews.
> 
>>  cheers
>>   Ben Bolker
>>
>> Douglas Bates wrote:
>>> If I were using glmer to fit a generalized linear mixed model I would
>>> use likelihood ratio tests rather than Wald tests.  That is, I would
>>> fit a model including a particular term then fit it again without that
>>> term and calculate the difference in the deviance values, comparing
>>> that to a chi-square.
>>>
>>> I'm not sure how one would do this using the results from glmmPQL.
>>>
>>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>  [forwarding to R-sig-mixed, where it is likely to get more
>>>> responses]
>>>>
>>>> Mark Fowler wrote:
>>>>
>>>> Hello,
>>>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>>> and have seen it recommended in user group discussions, but haven't come
>>>> across any code to accomplish it. I understand the anova function treats
>>>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>>> have R 2.7 and S-Plus 8 if necessary.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From maj at stats.waikato.ac.nz  Mon Oct 13 21:53:21 2008
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 14 Oct 2008 08:53:21 +1300
Subject: [R-sig-ME] [Fwd: Re: Wald F tests]
In-Reply-To: <40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
References: <48EBD9C5.7080102@ufl.edu>
	<40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
Message-ID: <48F3A731.8010706@stats.waikato.ac.nz>

Not that Doug needs my support but his support of the likelihood ratio 
as the right thing to be looking at regardless of any calibration 
difficulties strikes a chord with me. There is a famous Tukey quote that 
I can perhaps bend into service here:

?Far better an approximate answer to the right question, than the exact 
answer to the wrong question, which can always be made precise.?

In this context I take the "right question" to be interpretation of the 
likelihood ratio and the "wrong question" to be the local properties of 
the fitted "larger" model.

Murray Jorgensen

Douglas Bates wrote:
> On Tue, Oct 7, 2008 at 4:51 PM, Ben Bolker <bolker at ufl.edu> wrote:
> 
>>  But ... LRTs are non-recommended (anticonservative) for
>> comparing fixed effects of LMMs hence (presumably) for
>> GLMMs, unless sample size (# blocks/"residual" total sample
>> size) is large, no?
> 
>> I just got through telling readers of
>> a forthcoming TREE (Trends in Ecology and Evolution) article
>> that they should use Wald Z, chi^2, t, or F (depending on
>> whether testing a single or multiple parameters, and whether
>> there is overdispersion or not), in preference to LRTs,
>> for testing fixed effects ... ?  Or do you consider LRT
>> better than Wald in this case (in which case as far as
>> we know _nothing_ works very well for GLMMs, and I might
>> just start to cry ...)  Or perhaps I have to get busy
>> running some simulations ...
> 
> My reasoning, based on my experiences with nonlinear regression models
> and other nonlinear models, is that a test that involves fitting the
> alternative model and the null model then comparing the quality of the
> fit will give more realistic results than a test that only involves
> fitting the alternative model and using that fit to extrapolate to
> what the null model fit should be like.
> 
> We will always use approximations in statistics but as we get more
> powerful computing facilities some of the approximations that we
> needed to use in the past can be avoided.  I view Wald tests as an
> approximation to the quantity that we want to use to compare models,
> which is some measure of the comparative fit.  The likelihood ratio or
> the change in the deviance seems to be a reasonable way of comparing
> the fits of two nested models.  There may be problems with calibrating
> that quantity (i.e. converting it to a p-value) in which case we may
> want to use a bootstrap or some other simulation-based method like
> MCMC.  However, I don't think this difficulty would cause me to say
> that it is better to use an approximation to the model fit under the
> null hypothesis than to go ahead and fit it.
> 
>>  Where would _you_ go to find advice on inference
>> (as opposed to estimation) on estimated GLMM parameters?
> 
> I'm not sure.  As I once said to Martin, my research involves far too
> much "re" and far too little "search".  Probably because of laziness I
> tend to try to reason things out instead of conducting literature
> reviews.
> 
>>  cheers
>>   Ben Bolker
>>
>> Douglas Bates wrote:
>>> If I were using glmer to fit a generalized linear mixed model I would
>>> use likelihood ratio tests rather than Wald tests.  That is, I would
>>> fit a model including a particular term then fit it again without that
>>> term and calculate the difference in the deviance values, comparing
>>> that to a chi-square.
>>>
>>> I'm not sure how one would do this using the results from glmmPQL.
>>>
>>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>  [forwarding to R-sig-mixed, where it is likely to get more
>>>> responses]
>>>>
>>>> Mark Fowler wrote:
>>>>
>>>> Hello,
>>>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>>> and have seen it recommended in user group discussions, but haven't come
>>>> across any code to accomplish it. I understand the anova function treats
>>>> a glmmPQL fit as an lme fit, with the test assumptions based on maximum
>>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>>> have R 2.7 and S-Plus 8 if necessary.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From bolker at ufl.edu  Mon Oct 13 22:36:10 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 13 Oct 2008 16:36:10 -0400
Subject: [R-sig-ME] [Fwd: Re: Wald F tests]
In-Reply-To: <48F3A731.8010706@stats.waikato.ac.nz>
References: <48EBD9C5.7080102@ufl.edu>
	<40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
	<48F3A731.8010706@stats.waikato.ac.nz>
Message-ID: <48F3B13A.2010209@ufl.edu>

   Somewhat off-topic, but relevant to the larger question:
is there a good way to hack profile confidence limits for
[g]lmer fits?  (Nothing obvious springs to the eye ...) Has
anyone tried it?

  cheers
    Ben Bolker


Murray Jorgensen wrote:
> Not that Doug needs my support but his support of the likelihood ratio
> as the right thing to be looking at regardless of any calibration
> difficulties strikes a chord with me. There is a famous Tukey quote that
> I can perhaps bend into service here:
> 
> ?Far better an approximate answer to the right question, than the exact
> answer to the wrong question, which can always be made precise.?
> 
> In this context I take the "right question" to be interpretation of the
> likelihood ratio and the "wrong question" to be the local properties of
> the fitted "larger" model.
> 
> Murray Jorgensen
> 
> Douglas Bates wrote:
>> On Tue, Oct 7, 2008 at 4:51 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>
>>>  But ... LRTs are non-recommended (anticonservative) for
>>> comparing fixed effects of LMMs hence (presumably) for
>>> GLMMs, unless sample size (# blocks/"residual" total sample
>>> size) is large, no?
>>
>>> I just got through telling readers of
>>> a forthcoming TREE (Trends in Ecology and Evolution) article
>>> that they should use Wald Z, chi^2, t, or F (depending on
>>> whether testing a single or multiple parameters, and whether
>>> there is overdispersion or not), in preference to LRTs,
>>> for testing fixed effects ... ?  Or do you consider LRT
>>> better than Wald in this case (in which case as far as
>>> we know _nothing_ works very well for GLMMs, and I might
>>> just start to cry ...)  Or perhaps I have to get busy
>>> running some simulations ...
>>
>> My reasoning, based on my experiences with nonlinear regression models
>> and other nonlinear models, is that a test that involves fitting the
>> alternative model and the null model then comparing the quality of the
>> fit will give more realistic results than a test that only involves
>> fitting the alternative model and using that fit to extrapolate to
>> what the null model fit should be like.
>>
>> We will always use approximations in statistics but as we get more
>> powerful computing facilities some of the approximations that we
>> needed to use in the past can be avoided.  I view Wald tests as an
>> approximation to the quantity that we want to use to compare models,
>> which is some measure of the comparative fit.  The likelihood ratio or
>> the change in the deviance seems to be a reasonable way of comparing
>> the fits of two nested models.  There may be problems with calibrating
>> that quantity (i.e. converting it to a p-value) in which case we may
>> want to use a bootstrap or some other simulation-based method like
>> MCMC.  However, I don't think this difficulty would cause me to say
>> that it is better to use an approximation to the model fit under the
>> null hypothesis than to go ahead and fit it.
>>
>>>  Where would _you_ go to find advice on inference
>>> (as opposed to estimation) on estimated GLMM parameters?
>>
>> I'm not sure.  As I once said to Martin, my research involves far too
>> much "re" and far too little "search".  Probably because of laziness I
>> tend to try to reason things out instead of conducting literature
>> reviews.
>>
>>>  cheers
>>>   Ben Bolker
>>>
>>> Douglas Bates wrote:
>>>> If I were using glmer to fit a generalized linear mixed model I would
>>>> use likelihood ratio tests rather than Wald tests.  That is, I would
>>>> fit a model including a particular term then fit it again without that
>>>> term and calculate the difference in the deviance values, comparing
>>>> that to a chi-square.
>>>>
>>>> I'm not sure how one would do this using the results from glmmPQL.
>>>>
>>>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>>  [forwarding to R-sig-mixed, where it is likely to get more
>>>>> responses]
>>>>>
>>>>> Mark Fowler wrote:
>>>>>
>>>>> Hello,
>>>>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>>>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>>>> and have seen it recommended in user group discussions, but haven't
>>>>> come
>>>>> across any code to accomplish it. I understand the anova function
>>>>> treats
>>>>> a glmmPQL fit as an lme fit, with the test assumptions based on
>>>>> maximum
>>>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>>>> have R 2.7 and S-Plus 8 if necessary.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>



From bates at stat.wisc.edu  Tue Oct 14 00:29:41 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2008 17:29:41 -0500
Subject: [R-sig-ME] [Fwd: Re: Wald F tests]
In-Reply-To: <48F3B13A.2010209@ufl.edu>
References: <48EBD9C5.7080102@ufl.edu>
	<40e66e0b0810131205i639e0ee8i526d94e3d41d5281@mail.gmail.com>
	<48F3A731.8010706@stats.waikato.ac.nz> <48F3B13A.2010209@ufl.edu>
Message-ID: <40e66e0b0810131529g2767c496te7bb2fc2b24df94e@mail.gmail.com>

On Mon, Oct 13, 2008 at 3:36 PM, Ben Bolker <bolker at ufl.edu> wrote:
>   Somewhat off-topic, but relevant to the larger question:
> is there a good way to hack profile confidence limits for
> [g]lmer fits?  (Nothing obvious springs to the eye ...) Has
> anyone tried it?

For the fixed effects parameters or for the parameters which I write
as theta and which determine the relative covariance of the random
effects?

In lmer the log-likelihood is optimized as a function of theta only so
you can't profile with respect to the fixed-effects parameters
directly.

You could do it indirectly by changing the offset.  For definiteness,
suppose that you want to profile with respect to the intercept
coefficient then you move the intercept column from the X matrix to
the offset.  Changing the coefficient corresponds to scaling the
intercept after which you reoptimize the model.

That is by no means a complete description of an algorithm but I hope
it gives the flavor of the calculation.

> Murray Jorgensen wrote:
>> Not that Doug needs my support but his support of the likelihood ratio
>> as the right thing to be looking at regardless of any calibration
>> difficulties strikes a chord with me. There is a famous Tukey quote that
>> I can perhaps bend into service here:
>>
>> "Far better an approximate answer to the right question, than the exact
>> answer to the wrong question, which can always be made precise."
>>
>> In this context I take the "right question" to be interpretation of the
>> likelihood ratio and the "wrong question" to be the local properties of
>> the fitted "larger" model.
>>
>> Murray Jorgensen
>>
>> Douglas Bates wrote:
>>> On Tue, Oct 7, 2008 at 4:51 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>
>>>>  But ... LRTs are non-recommended (anticonservative) for
>>>> comparing fixed effects of LMMs hence (presumably) for
>>>> GLMMs, unless sample size (# blocks/"residual" total sample
>>>> size) is large, no?
>>>
>>>> I just got through telling readers of
>>>> a forthcoming TREE (Trends in Ecology and Evolution) article
>>>> that they should use Wald Z, chi^2, t, or F (depending on
>>>> whether testing a single or multiple parameters, and whether
>>>> there is overdispersion or not), in preference to LRTs,
>>>> for testing fixed effects ... ?  Or do you consider LRT
>>>> better than Wald in this case (in which case as far as
>>>> we know _nothing_ works very well for GLMMs, and I might
>>>> just start to cry ...)  Or perhaps I have to get busy
>>>> running some simulations ...
>>>
>>> My reasoning, based on my experiences with nonlinear regression models
>>> and other nonlinear models, is that a test that involves fitting the
>>> alternative model and the null model then comparing the quality of the
>>> fit will give more realistic results than a test that only involves
>>> fitting the alternative model and using that fit to extrapolate to
>>> what the null model fit should be like.
>>>
>>> We will always use approximations in statistics but as we get more
>>> powerful computing facilities some of the approximations that we
>>> needed to use in the past can be avoided.  I view Wald tests as an
>>> approximation to the quantity that we want to use to compare models,
>>> which is some measure of the comparative fit.  The likelihood ratio or
>>> the change in the deviance seems to be a reasonable way of comparing
>>> the fits of two nested models.  There may be problems with calibrating
>>> that quantity (i.e. converting it to a p-value) in which case we may
>>> want to use a bootstrap or some other simulation-based method like
>>> MCMC.  However, I don't think this difficulty would cause me to say
>>> that it is better to use an approximation to the model fit under the
>>> null hypothesis than to go ahead and fit it.
>>>
>>>>  Where would _you_ go to find advice on inference
>>>> (as opposed to estimation) on estimated GLMM parameters?
>>>
>>> I'm not sure.  As I once said to Martin, my research involves far too
>>> much "re" and far too little "search".  Probably because of laziness I
>>> tend to try to reason things out instead of conducting literature
>>> reviews.
>>>
>>>>  cheers
>>>>   Ben Bolker
>>>>
>>>> Douglas Bates wrote:
>>>>> If I were using glmer to fit a generalized linear mixed model I would
>>>>> use likelihood ratio tests rather than Wald tests.  That is, I would
>>>>> fit a model including a particular term then fit it again without that
>>>>> term and calculate the difference in the deviance values, comparing
>>>>> that to a chi-square.
>>>>>
>>>>> I'm not sure how one would do this using the results from glmmPQL.
>>>>>
>>>>> On Fri, Oct 3, 2008 at 3:37 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>>>  [forwarding to R-sig-mixed, where it is likely to get more
>>>>>> responses]
>>>>>>
>>>>>> Mark Fowler wrote:
>>>>>>
>>>>>> Hello,
>>>>>>        Might anyone know how to conduct Wald-type F-tests of the fixed
>>>>>> effects estimated by glmmPQL? I see this implemented in SAS (GLIMMIX),
>>>>>> and have seen it recommended in user group discussions, but haven't
>>>>>> come
>>>>>> across any code to accomplish it. I understand the anova function
>>>>>> treats
>>>>>> a glmmPQL fit as an lme fit, with the test assumptions based on
>>>>>> maximum
>>>>>> likelihood, which is inappropriate for PQL. I'm using S-Plus 7. I also
>>>>>> have R 2.7 and S-Plus 8 if necessary.
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>



From bates at stat.wisc.edu  Tue Oct 14 00:47:00 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Oct 2008 17:47:00 -0500
Subject: [R-sig-ME] Singular estimated var-cov
In-Reply-To: <OF039D515D.596C1EB3-ON852574DD.00446335-852574DD.0044743A@ah.novartis.com>
References: <OF039D515D.596C1EB3-ON852574DD.00446335-852574DD.0044743A@ah.novartis.com>
Message-ID: <40e66e0b0810131546m5cfa9624j2f79d86e16290b41@mail.gmail.com>

On Thu, Oct 9, 2008 at 7:27 AM,  <francois.mercier at novartis.com> wrote:
> Dear list members,

> I try to fit a model (using lmer) to data recorded at 4 time points
> (days). Each such time series corresponds to a distinct subject. There are
> two treatment groups. There is also a patient-level covariate ("o" or
> "b").  I am attaching the data frame (as a binary R object) and the R
> script that loads the data frame and fits the models.

I regret it has taken so long for you to get a response to your
question but I don't think that we can try the fit because you didn't
attach the data frame or the script - or at least they didn't make it
through the mail list software if you did include them.

> The questions are 1) whether the drug effect is influenced by the
> covariate, and 2) whether there is a temporal trend in drug effect over
> days.

> The problem is that according LMER the covariance matrix for this problem
> is singular, and as a result the fitted models do not capture the
> variability of slopes that is seen in the data. Apparently there is a
> strong correlation between some parameters that leads to this singularity
> ? Perhaps I misspecified the model for LMER (and LME) ?

It is possible for the estimated covariance matrix to be singular even
when there is significant variability in both the slope and the
intercept.  An example of that is enclosed.

We can think of fitting mixed models as a smoothing problem where we
need to balance fidelity to the data against the complexity of the
model.  The model complexity happens to be measured by a determinant
and a model with a singular covariance for the random effects has a
small value of this determinant.  If there is not a correspondingly
large loss of fidelity to the data caused by the singular covariance
matrix then the estimates will be singular.

From gillian.raab at googlemail.com  Tue Oct 14 01:12:17 2008
From: gillian.raab at googlemail.com (Gillian Raab)
Date: Tue, 14 Oct 2008 00:12:17 +0100
Subject: [R-sig-ME] Singular estimated var-cov
In-Reply-To: <40e66e0b0810131546m5cfa9624j2f79d86e16290b41@mail.gmail.com>
References: <OF039D515D.596C1EB3-ON852574DD.00446335-852574DD.0044743A@ah.novartis.com>
	<40e66e0b0810131546m5cfa9624j2f79d86e16290b41@mail.gmail.com>
Message-ID: <df33d1f90810131612h1390cb13u21211243fb25aded@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081014/88890228/attachment.pl>

From marcioestat at pop.com.br  Wed Oct 15 23:32:29 2008
From: marcioestat at pop.com.br (marcioestat at pop.com.br)
Date: Wed, 15 Oct 2008 19:32:29 -0200 (BRST)
Subject: [R-sig-ME] Generate variable bernoulli
Message-ID: <52955.198.168.27.224.1224106349.squirrel@nwebmail.pop.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081015/2f16bb3e/attachment.pl>

From p.dalgaard at biostat.ku.dk  Thu Oct 16 00:14:08 2008
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 16 Oct 2008 00:14:08 +0200
Subject: [R-sig-ME] Generate variable bernoulli
In-Reply-To: <52955.198.168.27.224.1224106349.squirrel@nwebmail.pop.com.br>
References: <52955.198.168.27.224.1224106349.squirrel@nwebmail.pop.com.br>
Message-ID: <48F66B30.1020608@biostat.ku.dk>

marcioestat at pop.com.br wrote:
> 
> Hi all,
> Could anybody tell me why my R(2.5.1) software is not finding the
> funcion RBERN that generates bernoulli variables!
> I have already looked at the search of the R website and there is
> this function, but when I try to use doesn't show at the software.
> Do I need to install a new version or do I need to install any
> package or do other thing to aloud this function!
> Thanks,
> M?rcio


What makes you think that there should be an RBERN, and what does it 
have to do with mixed models???

Anyways, Bernoulli variables are binomials with size=1, so try rbinom.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From francois.mercier at novartis.com  Thu Oct 16 00:18:07 2008
From: francois.mercier at novartis.com (francois.mercier at novartis.com)
Date: Wed, 15 Oct 2008 18:18:07 -0400
Subject: [R-sig-ME] Singular estimated var-cov
In-Reply-To: <df33d1f90810131612h1390cb13u21211243fb25aded@mail.gmail.com>
Message-ID: <OF8ED6DA1E.9FAD2DBB-ON852574E3.007909FF-852574E3.007A8295@ah.novartis.com>

Thank you for your answers. I don't know why the attached file in my 
initial post were not distributed. I attached hereafter the data set in 
.txt format, hoping that it'll make it this time.

In addition, here are some further considerations on the problem I'm 
facing with ...

1/ Load the data + run the original model which results in a 'singularity' 
problem:
==================================================================
library(lme4)
dat <- read.csv("SerialData1.txt")

# Note: Random effects on both intercept and slope

lmer (formula = y ~ bas + drug + time + drug:time + (1+time|id), data = 
dat)

Linear mixed-effects model fit by REML 
Formula: y ~ bas + drug + time + drug:time + (1 + time | id) 
   Data: dat 
   AIC   BIC logLik MLdeviance REMLdeviance
 735.8 759.8 -359.9      714.7        719.8
Random effects:
 Groups   Name        Variance   Std.Dev.   Corr 
 id       (Intercept) 6.6569e+00 2.5801e+00 
          time        2.3614e-09 4.8594e-05 0.000 
 Residual             4.7228e+00 2.1732e+00 
number of obs: 148, groups: id, 37

Fixed effects:
            Estimate Std. Error t value
(Intercept)  3.55523    4.13153   0.861
bas          0.81279    0.15726   5.168
drug        -1.53070    1.04169  -1.469
time        -0.13033    0.10880  -1.198
drug:time    0.02914    0.15598   0.187

Correlation of Fixed Effects:
          (Intr) bas    drug   time 
bas       -0.986 
drug       0.163 -0.280 
time      -0.066  0.000  0.261 
drug:time  0.046  0.000 -0.374 -0.697
Warning message:
In .local(x, ..., value) :
  Estimated variance-covariance for factor ?id? is singular

2/ As per Gillian's suggestion, try out using centered time:
==================================================================
lmer (formula = y ~ bas + drug + ctime + drug:ctime + (1+ctime|id), data = 
dat)
#   ...estimated var-cov matrix is still singular

Linear mixed-effects model fit by REML 
Formula: y ~ bas + drug + ctime + drug:ctime + (1 + ctime | id) 
   Data: dat 
   AIC   BIC logLik MLdeviance REMLdeviance
 735.8 759.8 -359.9      714.7        719.8
Random effects:
 Groups   Name        Variance   Std.Dev.   Corr 
 id       (Intercept) 6.6569e+00 2.5801e+00 
          ctime       2.3614e-09 4.8594e-05 0.000 
 Residual             4.7228e+00 2.1732e+00 
number of obs: 148, groups: id, 37

Fixed effects:
            Estimate Std. Error t value
(Intercept)  3.22942    4.12257   0.783
bas          0.81279    0.15726   5.168
drug        -1.45786    0.96595  -1.509
ctime       -0.13033    0.10880  -1.198
drug:ctime   0.02914    0.15598   0.187

Correlation of Fixed Effects:
           (Intr) bas    drug   ctime 
bas        -0.988 
drug        0.195 -0.302 
ctime       0.000  0.000  0.000 
drug:ctime  0.000  0.000  0.000 -0.697
Warning message:
In .local(x, ..., value) :
  Estimated variance-covariance for factor ?id? is singular

3/ Is there a correlation between slopes and intercepts?
==================================================================
# fit linear models to individual patient data y=1+time
lmfit.1 <- lmList (y ~ 1 + time|id, data=dat)

# create vectors of intercepts and slopes
ints<-vector(length=37)
slps<-vector(length=37)
for (i in 1:37) ints[i]<-lmfit.1[[i]]$coefficients[1]
for (i in 1:37) slps[i]<-lmfit.1[[i]]$coefficients[2]

# scatterplot of slopes and intercepts by drug group
plot(ints,slps,col=2*(as.numeric(dat$drug[dat$time==0])+1))
lm0 <- 
lm(slps[dat$drug[dat$time==0]==0]~ints[dat$drug[dat$time==0]==0])$coefficients
lm1 <- 
lm(slps[dat$drug[dat$time==0]==1]~ints[dat$drug[dat$time==0]==1])$coefficients
curve(lm0[1]+lm0[2]*x,min(ints),max(ints),col=2,add=T)
curve(lm1[1]+lm1[2]*x,min(ints),max(ints),col=4,add=T)



# compute correlation coefficients
# cor for drug 0 is 0.2
cor(slps[dat$drug[dat$time==0]==0], ints[dat$drug[dat$time==0]==0])
# cor for drug 1 is -0.5
cor(slps[dat$drug[dat$time==0]==1], ints[dat$drug[dat$time==0]==1])

 ...is it possible that correlation ~0.5 as found below
  is enough to produce a singular var-cov matrix?

4/ Random effect only on the slope
==================================================================
lmer (formula = y ~ bas + drug + time + drug:time + (time-1|id), data = 
dat)

Linear mixed-effects model fit by REML 
Formula: y ~ bas + drug + time + drug:time + (time - 1 | id) 
   Data: dat 
   AIC   BIC logLik MLdeviance REMLdeviance
 778.9 796.9 -383.5        761        766.9
Random effects:
 Groups   Name Variance Std.Dev.
 id       time 0.23548  0.48526 
 Residual      8.43043  2.90352 
number of obs: 148, groups: id, 37

Fixed effects:
            Estimate Std. Error t value
(Intercept)  3.93406    2.58167   1.524
bas          0.79816    0.09786   8.156
drug        -1.50356    0.72968  -2.061
time        -0.13033    0.18309  -0.712
drug:time    0.02914    0.26250   0.111

Correlation of Fixed Effects:
          (Intr) bas    drug   time 
bas       -0.982 
drug       0.115 -0.249 
time      -0.112  0.000  0.395 
drug:time  0.078  0.000 -0.567 -0.697

#   ...the fit is successful.
#   note that correlation of fixed effects for "bas" and intercept is 
almost 1
#   does this mean that value of y before treatment ("bas") eliminates the
#   need for a random effect on the intercept?

Best regards,
Francois






"Gillian Raab" <gillian.raab at googlemail.com> 
10/13/2008 07:12 PM

To
"Douglas Bates" <bates at stat.wisc.edu>
cc
francois.mercier at novartis.com, r-sig-mixed-models at r-project.org
Subject
Re: [R-sig-ME] Singular estimated var-cov






I am sure the master (DB) is right in his comments But I wonder if you 
have tried something easier. I did not get your data eitehr but you said 
something  about high correlations. Is your time variable centerd around 
zero? This will make no difference to your fitted values and likelihood if 
the models have converged to the ML solution, but centering will 
sometimes overcome fitting problems. 

If the variance covariance matrix at the solution really is singular then 
obviously it won't help. If your fit gives you random effects than I would 
suggest extracting them and plotting the equivalent lines, so you can see 
what is going on. The most likley scenario from what you describe is that 
your lines all pass through a common point for some choice of X value. You 
could probably work this out from the fitted variance covariance matrix, 
but I find the fitted lines help me to see what is going on better than 
the algebra.

Gillian Raab, Edinburgh


On 13/10/2008, Douglas Bates <bates at stat.wisc.edu> wrote:
On Thu, Oct 9, 2008 at 7:27 AM,  <francois.mercier at novartis.com> wrote:
> Dear list members,

> I try to fit a model (using lmer) to data recorded at 4 time points
> (days). Each such time series corresponds to a distinct subject. There 
are
> two treatment groups. There is also a patient-level covariate ("o" or
> "b").  I am attaching the data frame (as a binary R object) and the R
> script that loads the data frame and fits the models.

I regret it has taken so long for you to get a response to your
question but I don't think that we can try the fit because you didn't
attach the data frame or the script - or at least they didn't make it
through the mail list software if you did include them.

> The questions are 1) whether the drug effect is influenced by the
> covariate, and 2) whether there is a temporal trend in drug effect over
> days.

> The problem is that according LMER the covariance matrix for this 
problem
> is singular, and as a result the fitted models do not capture the
> variability of slopes that is seen in the data. Apparently there is a
> strong correlation between some parameters that leads to this 
singularity
> ? Perhaps I misspecified the model for LMER (and LME) ?

It is possible for the estimated covariance matrix to be singular even
when there is significant variability in both the slope and the
intercept.  An example of that is enclosed.

We can think of fitting mixed models as a smoothing problem where we
need to balance fidelity to the data against the complexity of the
model.  The model complexity happens to be measured by a determinant
and a model with a singular covariance for the random effects has a
small value of this determinant.  If there is not a correspondingly
large loss of fidelity to the data caused by the singular covariance
matrix then the estimates will be singular.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Gillian M Raab
10 Ainslie Place EH3 6AS
tel 0131 226 6234
mobile 07748 678 551 

_________________________

CONFIDENTIALITY NOTICE

The information contained in this e-mail message is intended only for the 
exclusive use of the individual or entity named above and may contain 
information that is privileged, confidential or exempt from disclosure 
under applicable law. If the reader of this message is not the intended 
recipient, or the employee or agent responsible for delivery of the 
message to the intended recipient, you are hereby notified that any 
dissemination, distribution or copying of this communication is strictly 
prohibited. If you have received this communication in error, please 
notify the sender immediately by e-mail and delete the material from any 
computer.  Thank you.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: SerialData1.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081015/a58f04b3/attachment.txt>

From ken at kjbeath.com.au  Thu Oct 16 10:47:50 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 16 Oct 2008 19:47:50 +1100
Subject: [R-sig-ME] Singular estimated var-cov
In-Reply-To: <OF8ED6DA1E.9FAD2DBB-ON852574E3.007909FF-852574E3.007A8295@ah.novartis.com>
References: <OF8ED6DA1E.9FAD2DBB-ON852574E3.007909FF-852574E3.007A8295@ah.novartis.com>
Message-ID: <CA9F9F6E-FF67-4993-9C32-653C5F44F438@kjbeath.com.au>

On 16/10/2008, at 9:18 AM, francois.mercier at novartis.com wrote:

> Thank you for your answers. I don't know why the attached file in my
> initial post were not distributed. I attached hereafter the data set  
> in
> .txt format, hoping that it'll make it this time.
>

I get slightly different results with the variance-covariance not  
singular due to the time random effect variance being 0.0012559. This  
is with lme4 version 0.999375-26.

The reason for the singularity problem is that the random effect  
variance for time is close to zero, and doesn't need to be in the  
model. If the model is fitted without it the log  likelihood hardly  
changes and the AIC and BIC are both lower.

Ken

> In addition, here are some further considerations on the problem I'm
> facing with ...
>
> 1/ Load the data + run the original model which results in a  
> 'singularity'
> problem:
> ==================================================================
> library(lme4)
> dat <- read.csv("SerialData1.txt")
>
> # Note: Random effects on both intercept and slope
>
> lmer (formula = y ~ bas + drug + time + drug:time + (1+time|id),  
> data =
> dat)
>
> Linear mixed-effects model fit by REML
> Formula: y ~ bas + drug + time + drug:time + (1 + time | id)
>   Data: dat
>   AIC   BIC logLik MLdeviance REMLdeviance
> 735.8 759.8 -359.9      714.7        719.8
> Random effects:
> Groups   Name        Variance   Std.Dev.   Corr
> id       (Intercept) 6.6569e+00 2.5801e+00
>          time        2.3614e-09 4.8594e-05 0.000
> Residual             4.7228e+00 2.1732e+00
> number of obs: 148, groups: id, 37
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  3.55523    4.13153   0.861
> bas          0.81279    0.15726   5.168
> drug        -1.53070    1.04169  -1.469
> time        -0.13033    0.10880  -1.198
> drug:time    0.02914    0.15598   0.187
>
> Correlation of Fixed Effects:
>          (Intr) bas    drug   time
> bas       -0.986
> drug       0.163 -0.280
> time      -0.066  0.000  0.261
> drug:time  0.046  0.000 -0.374 -0.697
> Warning message:
> In .local(x, ..., value) :
>  Estimated variance-covariance for factor ?id? is singular
>
> 2/ As per Gillian's suggestion, try out using centered time:
> ==================================================================
> lmer (formula = y ~ bas + drug + ctime + drug:ctime + (1+ctime|id),  
> data =
> dat)
> #   ...estimated var-cov matrix is still singular
>
> Linear mixed-effects model fit by REML
> Formula: y ~ bas + drug + ctime + drug:ctime + (1 + ctime | id)
>   Data: dat
>   AIC   BIC logLik MLdeviance REMLdeviance
> 735.8 759.8 -359.9      714.7        719.8
> Random effects:
> Groups   Name        Variance   Std.Dev.   Corr
> id       (Intercept) 6.6569e+00 2.5801e+00
>          ctime       2.3614e-09 4.8594e-05 0.000
> Residual             4.7228e+00 2.1732e+00
> number of obs: 148, groups: id, 37
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  3.22942    4.12257   0.783
> bas          0.81279    0.15726   5.168
> drug        -1.45786    0.96595  -1.509
> ctime       -0.13033    0.10880  -1.198
> drug:ctime   0.02914    0.15598   0.187
>
> Correlation of Fixed Effects:
>           (Intr) bas    drug   ctime
> bas        -0.988
> drug        0.195 -0.302
> ctime       0.000  0.000  0.000
> drug:ctime  0.000  0.000  0.000 -0.697
> Warning message:
> In .local(x, ..., value) :
>  Estimated variance-covariance for factor ?id? is singular
>
> 3/ Is there a correlation between slopes and intercepts?
> ==================================================================
> # fit linear models to individual patient data y=1+time
> lmfit.1 <- lmList (y ~ 1 + time|id, data=dat)
>
> # create vectors of intercepts and slopes
> ints<-vector(length=37)
> slps<-vector(length=37)
> for (i in 1:37) ints[i]<-lmfit.1[[i]]$coefficients[1]
> for (i in 1:37) slps[i]<-lmfit.1[[i]]$coefficients[2]
>
> # scatterplot of slopes and intercepts by drug group
> plot(ints,slps,col=2*(as.numeric(dat$drug[dat$time==0])+1))
> lm0 <-
> lm(slps[dat$drug[dat$time==0]==0]~ints[dat$drug[dat$time==0]==0]) 
> $coefficients
> lm1 <-
> lm(slps[dat$drug[dat$time==0]==1]~ints[dat$drug[dat$time==0]==1]) 
> $coefficients
> curve(lm0[1]+lm0[2]*x,min(ints),max(ints),col=2,add=T)
> curve(lm1[1]+lm1[2]*x,min(ints),max(ints),col=4,add=T)
>
>
>
> # compute correlation coefficients
> # cor for drug 0 is 0.2
> cor(slps[dat$drug[dat$time==0]==0], ints[dat$drug[dat$time==0]==0])
> # cor for drug 1 is -0.5
> cor(slps[dat$drug[dat$time==0]==1], ints[dat$drug[dat$time==0]==1])
>
> ...is it possible that correlation ~0.5 as found below
>  is enough to produce a singular var-cov matrix?
>
> 4/ Random effect only on the slope
> ==================================================================
> lmer (formula = y ~ bas + drug + time + drug:time + (time-1|id),  
> data =
> dat)
>
> Linear mixed-effects model fit by REML
> Formula: y ~ bas + drug + time + drug:time + (time - 1 | id)
>   Data: dat
>   AIC   BIC logLik MLdeviance REMLdeviance
> 778.9 796.9 -383.5        761        766.9
> Random effects:
> Groups   Name Variance Std.Dev.
> id       time 0.23548  0.48526
> Residual      8.43043  2.90352
> number of obs: 148, groups: id, 37
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  3.93406    2.58167   1.524
> bas          0.79816    0.09786   8.156
> drug        -1.50356    0.72968  -2.061
> time        -0.13033    0.18309  -0.712
> drug:time    0.02914    0.26250   0.111
>
> Correlation of Fixed Effects:
>          (Intr) bas    drug   time
> bas       -0.982
> drug       0.115 -0.249
> time      -0.112  0.000  0.395
> drug:time  0.078  0.000 -0.567 -0.697
>
> #   ...the fit is successful.
> #   note that correlation of fixed effects for "bas" and intercept is
> almost 1
> #   does this mean that value of y before treatment ("bas")  
> eliminates the
> #   need for a random effect on the intercept?
>
> Best regards,
> Francois
>
>
>
>
>
>
> "Gillian Raab" <gillian.raab at googlemail.com>
> 10/13/2008 07:12 PM
>
> To
> "Douglas Bates" <bates at stat.wisc.edu>
> cc
> francois.mercier at novartis.com, r-sig-mixed-models at r-project.org
> Subject
> Re: [R-sig-ME] Singular estimated var-cov
>
>
>
>
>
>
> I am sure the master (DB) is right in his comments But I wonder if you
> have tried something easier. I did not get your data eitehr but you  
> said
> something  about high correlations. Is your time variable centerd  
> around
> zero? This will make no difference to your fitted values and  
> likelihood if
> the models have converged to the ML solution, but centering will
> sometimes overcome fitting problems.
>
> If the variance covariance matrix at the solution really is singular  
> then
> obviously it won't help. If your fit gives you random effects than I  
> would
> suggest extracting them and plotting the equivalent lines, so you  
> can see
> what is going on. The most likley scenario from what you describe is  
> that
> your lines all pass through a common point for some choice of X  
> value. You
> could probably work this out from the fitted variance covariance  
> matrix,
> but I find the fitted lines help me to see what is going on better  
> than
> the algebra.
>
> Gillian Raab, Edinburgh
>
>
> On 13/10/2008, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Thu, Oct 9, 2008 at 7:27 AM,  <francois.mercier at novartis.com>  
> wrote:
>> Dear list members,
>
>> I try to fit a model (using lmer) to data recorded at 4 time points
>> (days). Each such time series corresponds to a distinct subject.  
>> There
> are
>> two treatment groups. There is also a patient-level covariate ("o" or
>> "b").  I am attaching the data frame (as a binary R object) and the R
>> script that loads the data frame and fits the models.
>
> I regret it has taken so long for you to get a response to your
> question but I don't think that we can try the fit because you didn't
> attach the data frame or the script - or at least they didn't make it
> through the mail list software if you did include them.
>
>> The questions are 1) whether the drug effect is influenced by the
>> covariate, and 2) whether there is a temporal trend in drug effect  
>> over
>> days.
>
>> The problem is that according LMER the covariance matrix for this
> problem
>> is singular, and as a result the fitted models do not capture the
>> variability of slopes that is seen in the data. Apparently there is a
>> strong correlation between some parameters that leads to this
> singularity
>> ? Perhaps I misspecified the model for LMER (and LME) ?
>
> It is possible for the estimated covariance matrix to be singular even
> when there is significant variability in both the slope and the
> intercept.  An example of that is enclosed.
>
> We can think of fitting mixed models as a smoothing problem where we
> need to balance fidelity to the data against the complexity of the
> model.  The model complexity happens to be measured by a determinant
> and a model with a singular covariance for the random effects has a
> small value of this determinant.  If there is not a correspondingly
> large loss of fidelity to the data caused by the singular covariance
> matrix then the estimates will be singular.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> -- 
> Gillian M Raab
> 10 Ainslie Place EH3 6AS
> tel 0131 226 6234
> mobile 07748 678 551
>
> _________________________
>
> CONFIDENTIALITY NOTICE
>
> The information contained in this e-mail message is intended only  
> for the
> exclusive use of the individual or entity named above and may contain
> information that is privileged, confidential or exempt from disclosure
> under applicable law. If the reader of this message is not the  
> intended
> recipient, or the employee or agent responsible for delivery of the
> message to the intended recipient, you are hereby notified that any
> dissemination, distribution or copying of this communication is  
> strictly
> prohibited. If you have received this communication in error, please
> notify the sender immediately by e-mail and delete the material from  
> any
> computer.  Thank you.
> <SerialData1.txt>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.LeBlond at abbott.com  Thu Oct 16 15:14:31 2008
From: David.LeBlond at abbott.com (David LeBlond)
Date: Thu, 16 Oct 2008 08:14:31 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 22, Issue 17
In-Reply-To: <mailman.14388.1224146902.8193.r-sig-mixed-models@r-project.org>
Message-ID: <OFE78BA986.B7714FE7-ON862574E4.00489CDB-862574E4.0048C3D7@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081016/6210cb21/attachment.pl>

From paul.goedhart at wur.nl  Thu Oct 16 17:31:21 2008
From: paul.goedhart at wur.nl (Goedhart, Paul)
Date: Thu, 16 Oct 2008 17:31:21 +0200
Subject: [R-sig-ME] Overdispersion and quasi distributions
Message-ID: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>

Dear All,
 
I am new to R (coming from GenStat) and to this discussion list. In postings in the third quarter of 2008 there were some queries about GLMMs for overdispersed data and problems with LME4 (see e.g. https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001430.html and https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001404.html). In the second posting Douglas Bates writes that "If someone can suggest what the formula for the scale factor should be, I ...". 
 
I am having trouble understanding the GLMM algorithm in lme4, but most estimation methods, among which Breslow and Clayton (1993), use a first order Laplace approximation of the likelihood. The iterative algorithm employed, is based on a linear mixed model for an adjusted dependent variable which is updated in each iteration step. The linear mixed model is fitted with REML resulting in estimates for the fixed effects and predictions for the random effects. Then a new adjusted dependent variable (using the fitted values and the predictions) is calculated and the procedure is repeated. This algorithm involves additional weights that are associated with an added residual variance component (fixed at value 1). The over-dispersed (or quasi-likelihood) version of this estimation method comprises an unknown residual variance, i.e. not fixed at value 1, which is estimated by REML. This unknown residual variance component is the scale or overdispersion factor. In the GLMM routine in GenStat the difference in the specification of the random model is (e.g. for a simple block design, "residual" is a factor with a separate level for each observation and "value" is the estimate from the previous iteration)
   without overdispersion:  random=block+residual ; initialvalue=value,1 ; constraint=none,fixed
   with overdispersion:  random=block+residual ; initialvalue=value,value ; constraint=none,none
 
Note that in an ordinary GLM SEs are multiplied by the square root of the overdispersion factor, and that the estimates of the fixed effects themselves do not change. This is because the overdispersion factor is estimated from Pearson's chi-squared or the deviance after the GLM model has been fitted. However in a GLMM this might work differently as the overdispersion factor can and should be estimated in every iteration possibly leading to different estimates for both variance components and fixed effects. When there is considerable overdispersion there will in general be a difference between the estimated variance components for the model without and the model with overdispersion. This is because in the model without overdispersion the extra variation at the residual stratum will partly be absorbed by the random effects in the linear predictor. 

 

As a final remark note that in the algorithm above there is already a residual random effect in the estimation method, so there is no room for a residual random effect in the linear predictor. This can also be viewed in the following way: the algorithm employs predictions for the random effects. A residual random effect does not have replications and therefore predictions for such a random effect are notoriously unstable. Note that this a property (or one might say a defect) of the estimation method. That is why the documentation of the GLMM routine in GenStat states that "The random model must exclude the bottom stratum" Maximum likelihood does not have this restriction, but ML requires that all random effects are integrated out and this is generally not feasible. 

 

Best regards,

Paul Goedhart



From michael.beaulieu at c-strasbourg.fr  Fri Oct 17 14:08:38 2008
From: michael.beaulieu at c-strasbourg.fr (Michael Beaulieu)
Date: Fri, 17 Oct 2008 14:08:38 +0200
Subject: [R-sig-ME] Large data set and mixed models
Message-ID: <48F88046.4080204@c-strasbourg.fr>



From michael.beaulieu at c-strasbourg.fr  Fri Oct 17 15:02:10 2008
From: michael.beaulieu at c-strasbourg.fr (Michael Beaulieu)
Date: Fri, 17 Oct 2008 15:02:10 +0200
Subject: [R-sig-ME] Large data set and mixed models
Message-ID: <48F88CD2.8070407@c-strasbourg.fr>

I would like two compare the diving behaviour of two groups of penguins 
(7 penguin in each group). Each penguin performed several dives within 
several foraging trips. As a result, I got a huge data set of dives 
(nearly 100000).
To compare the diving behaviour of the two groups, I used a mixed model 
with:
-the penguin as a random factor,
-the number of dives nested in the foraging trip as a repeated factor,
-the group, the foraging trip and maximal depth as fixed factors.
Covariance structure was auto-regressive.
I tried this model on SPSS, SAS and R but all failed.

Has anybody been faced with such a huge dataset analysed with mixed models?

Thank you

MiKL



From rense.nieuwenhuis at me.com  Fri Oct 17 15:34:49 2008
From: rense.nieuwenhuis at me.com (Rense Nieuwenhuis)
Date: Fri, 17 Oct 2008 15:34:49 +0200
Subject: [R-sig-ME] Large data set and mixed models
In-Reply-To: <48F88CD2.8070407@c-strasbourg.fr>
References: <48F88CD2.8070407@c-strasbourg.fr>
Message-ID: <04326924-68F4-4CAA-997B-72EEFD498CDE@me.com>

Dear Michael,

perhaps you could send more details about the model you're trying to  
estimate, so we could be of help.

i.e.:
- What is the model specification
- What happens -> error message, uninterpretable findings?
- A closer description of the data
- What system are you trying to estimate this model with?

In general I wouldn't say the 100000 cases is 'huge' in terms of R- 
Project. Sure, some models will take some time to converge, but it  
should be doable.

If you'd send me (a sample of) your data, I'd be willing to take a  
look at it.

Kind regards,

Rense



On 17-okt-2008, at 15:02, Michael Beaulieu wrote:

> I would like two compare the diving behaviour of two groups of  
> penguins (7 penguin in each group). Each penguin performed several  
> dives within several foraging trips. As a result, I got a huge data  
> set of dives (nearly 100000).
> To compare the diving behaviour of the two groups, I used a mixed  
> model with:
> -the penguin as a random factor,
> -the number of dives nested in the foraging trip as a repeated factor,
> -the group, the foraging trip and maximal depth as fixed factors.
> Covariance structure was auto-regressive.
> I tried this model on SPSS, SAS and R but all failed.
>
> Has anybody been faced with such a huge dataset analysed with mixed  
> models?
>
> Thank you
>
> MiKL
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Oct 17 17:15:20 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 17 Oct 2008 10:15:20 -0500
Subject: [R-sig-ME] Large data set and mixed models
In-Reply-To: <04326924-68F4-4CAA-997B-72EEFD498CDE@me.com>
References: <48F88CD2.8070407@c-strasbourg.fr>
	<04326924-68F4-4CAA-997B-72EEFD498CDE@me.com>
Message-ID: <40e66e0b0810170815h49b6796cgc2c21cf21e36fbcc@mail.gmail.com>

On Fri, Oct 17, 2008 at 8:34 AM, Rense Nieuwenhuis
<rense.nieuwenhuis at me.com> wrote:
> Dear Michael,

> perhaps you could send more details about the model you're trying to
> estimate, so we could be of help.

> i.e.:
> - What is the model specification
> - What happens -> error message, uninterpretable findings?
> - A closer description of the data
> - What system are you trying to estimate this model with?

> In general I wouldn't say the 100000 cases is 'huge' in terms of R-Project.
> Sure, some models will take some time to converge, but it should be doable.

Agreed.  The largest example that I have fit with lme4 in R has about
1.7 million observations and over 60,000 non-nested random effects.

> If you'd send me (a sample of) your data, I'd be willing to take a look at
> it.

A good start would be if Michael could show us a transcript of his
attempt to fit the model he want in R, including the output from

sessionInfo()

so we know the versions of all packages being used.

> On 17-okt-2008, at 15:02, Michael Beaulieu wrote:
>
>> I would like two compare the diving behaviour of two groups of penguins (7
>> penguin in each group). Each penguin performed several dives within several
>> foraging trips. As a result, I got a huge data set of dives (nearly 100000).
>> To compare the diving behaviour of the two groups, I used a mixed model
>> with:
>> -the penguin as a random factor,
>> -the number of dives nested in the foraging trip as a repeated factor,
>> -the group, the foraging trip and maximal depth as fixed factors.
>> Covariance structure was auto-regressive.
>> I tried this model on SPSS, SAS and R but all failed.
>>
>> Has anybody been faced with such a huge dataset analysed with mixed
>> models?
>>
>> Thank you
>>
>> MiKL
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From aslez at ssc.wisc.edu  Sat Oct 18 00:09:31 2008
From: aslez at ssc.wisc.edu (aslez at ssc.wisc.edu)
Date: Fri, 17 Oct 2008 17:09:31 -0500 (CDT)
Subject: [R-sig-ME] sample weights in lmer
Message-ID: <4739.128.104.27.172.1224281371.squirrel@webmail.ssc.wisc.edu>

Fellow R users,

I was wondering whether it is possible incorporate sample weights into the
lmer command.  My understanding is that the existing weights option
follows the types of weights used with the lm command; that is, they are
the type of weights you would use when doing something like weighted least
squares models.  To the best of my knowledge, sample or design weights are
not equivalent to the types of model weights we use for WLS.  I have at
least quasi-confirmed this by comparing lmer results to results produced
using HLM.  Without weights, the results are identical. With weights, they
differ.  I know for a fact HLM is using sample weights.

This maybe a relatively simple question, but I just made the switch to R,
so the answer isn't completely obvious to me.  My thought is either that
there is a way of linking svydesign commands with the lmer routine, or
that theres a way of "tricking" lmer so that it produces sample-weighted
results using the WLS-type weights command.

Any help would be much appreciated.

Adam



From cotter.rs at gmail.com  Mon Oct 20 12:02:58 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Mon, 20 Oct 2008 12:02:58 +0200
Subject: [R-sig-ME] Problems with running diagnostic plot for a lmer object
Message-ID: <742479270810200302n661e4d29x86c38d027165536e@mail.gmail.com>

Dear all,

I have recently learn how to run logistic regression with lmer. But I
have problems with running a diagnostic plot. I have tried plot(mod),
but get this message:
Error in object$coefficients : $ operator not defined for this S4
class. Tried to search for it, but without success. What means this?

Is there other ways to do a diagnostic plot for an lmer object?

Regards Cotter



From Thierry.ONKELINX at inbo.be  Mon Oct 20 17:33:03 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 20 Oct 2008 17:33:03 +0200
Subject: [R-sig-ME] How to implement nested fixed effect
Message-ID: <2E9C414912813E4EB981326983E0A10405A1FE6E@inboexch.inbo.be>

Dear all,

First let me start with a brief description of the design of the study.
A colleague examined the effect of 6 different products (including one
blanco). Each product was applied in two doses: a base dose and twice
the base dose. The blanco has offcourse only one dose. Each plot was
measured twice after treatment.
What we want to know is: is there a difference between the products, is
there a difference between the doses and is there a difference between
the years.

So what I tried was:
lme(Response ~ Product * Dose * Year, random = ~1|plot)
But I got 
Error in MEEM(object, conLin, control$niterEM) : 
  Singularity in backsolve at level 0, block 1
I noticed that lm(Response ~ Product * Dose * Year) yields two
coefficients with NA: one for Product5:Dose and one for
Product5:Dose:Year2. Hence I suppose the problem is due to single dosage
for the blanc product (=no treatment). Any solutions to solve this. Or
should I better stick to lme(Response ~ Treatment * Year, random =
~1|plot) where Treatment combines the info from Product and Dose.

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From David.LeBlond at abbott.com  Mon Oct 20 19:50:05 2008
From: David.LeBlond at abbott.com (David LeBlond)
Date: Mon, 20 Oct 2008 12:50:05 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 22, Issue 15
In-Reply-To: <mailman.11241.1223930191.8193.r-sig-mixed-models@r-project.org>
Message-ID: <OF1CA4DABB.C0472253-ON862574E8.0061844F-862574E8.0061FE76@abbott.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081020/86823c28/attachment.pl>

From p.dalgaard at biostat.ku.dk  Mon Oct 20 20:20:31 2008
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 20 Oct 2008 20:20:31 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 22, Issue 15
In-Reply-To: <OF1CA4DABB.C0472253-ON862574E8.0061844F-862574E8.0061FE76@abbott.com>
References: <OF1CA4DABB.C0472253-ON862574E8.0061844F-862574E8.0061FE76@abbott.com>
Message-ID: <48FCCBEF.5070100@biostat.ku.dk>

David LeBlond wrote:
> All these frequentist approximations are very confusing to those of us 
> with lesser analytical skills.
> 
> I think it is worth remembering the big picture. The likelihood without 
> the prior is like the emperor without his clothes.
> 
> We need mcmcsamp so we don't have to look at anymore naked posteriors.
> 
> :-)

Um, you might want to review your fairy tales there. Even with his new 
clothes on, the emperor was displaying his posterior in public. People 
just wouldn't admit so because they had been told that that the clothes 
would be transparent to those unsuited for their position...

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From a.renwick at abdn.ac.uk  Tue Oct 21 11:33:13 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Tue, 21 Oct 2008 10:33:13 +0100
Subject: [R-sig-ME] Poisson mixed models
In-Reply-To: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
References: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
Message-ID: <B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>

 Dear All
There has been a lot of talk recently on this forum regarding (over)dispersion and quasi models.  I am running a GLMM with a poisson family for some tick burden data I have and I wanted to check if I had overdispersion in my model (and thus a poisson family would be inappropriate).  The only method I have found to do this is to run the model with a quasipoisson family and then ask for the scale parameter using:

lme4:::sigma(model)

However, when I do this my model appears severely UNDER dispersed:
 sigmaML
3.779694e-06

Without the random effect in the model (i.e a GLM) the scale parameter is 1.07 - almost perfect for a poisson family.  Is the method I  am trying not appropriate to determine the dispersion in the mixed model?  Does anyone know a better method?

Many thanks,
Anna


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From HStevens at muohio.edu  Tue Oct 21 12:19:23 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 21 Oct 2008 06:19:23 -0400
Subject: [R-sig-ME] Poisson mixed models
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>
References: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>
Message-ID: <C7B4619A-87B6-4709-BD17-4E844C2EC419@muohio.edu>

Hi Anna,
So you tried a GLMM with quasipoisson and a GLM with Poisson? How  
about a GLMM with Poisson? Sounds like you may have a random effect  
that is necessary for your hypothesis test, but which does not  
explain any variation (but I really have no way of knowing).
Hank
On Oct 21, 2008, at 5:33 AM, Renwick, A. R. wrote:

>  Dear All
> There has been a lot of talk recently on this forum regarding (over) 
> dispersion and quasi models.  I am running a GLMM with a poisson  
> family for some tick burden data I have and I wanted to check if I  
> had overdispersion in my model (and thus a poisson family would be  
> inappropriate).  The only method I have found to do this is to run  
> the model with a quasipoisson family and then ask for the scale  
> parameter using:
>
> lme4:::sigma(model)
>
> However, when I do this my model appears severely UNDER dispersed:
>  sigmaML
> 3.779694e-06
>
> Without the random effect in the model (i.e a GLM) the scale  
> parameter is 1.07 - almost perfect for a poisson family.  Is the  
> method I  am trying not appropriate to determine the dispersion in  
> the mixed model?  Does anyone know a better method?
>
> Many thanks,
> Anna
>
>
> The University of Aberdeen is a charity registered in Scotland, No  
> SC013683.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From a.renwick at abdn.ac.uk  Tue Oct 21 12:24:38 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Tue, 21 Oct 2008 11:24:38 +0100
Subject: [R-sig-ME] Poisson mixed models
In-Reply-To: <C7B4619A-87B6-4709-BD17-4E844C2EC419@muohio.edu>
References: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>
	<C7B4619A-87B6-4709-BD17-4E844C2EC419@muohio.edu>
Message-ID: <B9D1301370916C44B5874AF340C18B9B28ACF89F47@VMAILB.uoa.abdn.ac.uk>

I did run a GLMM with poisson - that is the model type I want to use.  I only used a GLMM with quasipoisson to check the scale parameter as I am unaware as to how to check if you have over/under dispersion in the poisson model, and hence violating the assumption of the model, and other way.

# glmm with poisson family
mix<-lmer(trianlarvae~Sex+width+sess+Nhat+Sex:width+Sex:sess+Sex:Nhat+width:sess+width:Nhat+sess:Nhat+(1|LocTran), family=poisson, data=larv, REML=FALSE)
summary(mix)

Generalized linear mixed model fit by the Laplace approximation
Formula: trianlarvae ~ Sex + width + sess + Nhat + Sex:width + Sex:sess +      Sex:Nhat + width:sess + width:Nhat + sess:Nhat + (1 | LocTran)
   Data: larv
 AIC   BIC logLik deviance
 464 572.7   -212      424
Random effects:
 Groups  Name        Variance Std.Dev.
 LocTran (Intercept) 1.3462   1.1603
Number of obs: 1697, groups: LocTran, 14

Fixed effects:
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)         -4.218e+00  1.708e+00 -2.4694   0.0135 *
Sexmale              6.999e-01  1.189e+00  0.5887   0.5561
width               -1.426e-01  2.360e-01 -0.6044   0.5456
sessAugust           1.486e+00  2.060e+00  0.7212   0.4708
sessJune            -1.545e+01  1.212e+03 -0.0127   0.9898
sessOctober          3.119e+00  1.838e+00  1.6973   0.0896 .
Nhat                -4.909e-02  5.814e-02 -0.8442   0.3985
Sexmale:width        1.159e-01  7.612e-02  1.5222   0.1280
Sexmale:sessAugust  -7.540e-01  1.632e+00 -0.4621   0.6440
Sexmale:sessJune     1.310e+01  1.212e+03  0.0108   0.9914
Sexmale:sessOctober -1.118e+00  1.223e+00 -0.9139   0.3608
Sexmale:Nhat         9.881e-03  1.012e-02  0.9765   0.3288
width:sessAugust     8.245e-01  5.882e-01  1.4017   0.1610
width:sessJune      -4.034e-02  2.791e-01 -0.1445   0.8851
width:sessOctober   -1.045e-02  2.057e-01 -0.0508   0.9595
width:Nhat           4.239e-03  3.654e-03  1.1600   0.2460
sessAugust:Nhat     -1.484e-01  1.299e-01 -1.1422   0.2534
sessJune:Nhat        2.646e-02  6.249e-02  0.4235   0.6719
sessOctober:Nhat     1.462e-03  5.776e-02  0.0253   0.9798




-----Original Message-----
From: Martin Henry H. Stevens [mailto:HStevens at muohio.edu]
Sent: 21 October 2008 11:19
To: Renwick, A. R.
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Poisson mixed models

Hi Anna,
So you tried a GLMM with quasipoisson and a GLM with Poisson? How about a GLMM with Poisson? Sounds like you may have a random effect that is necessary for your hypothesis test, but which does not explain any variation (but I really have no way of knowing).
Hank
On Oct 21, 2008, at 5:33 AM, Renwick, A. R. wrote:

>  Dear All
> There has been a lot of talk recently on this forum regarding (over)
> dispersion and quasi models.  I am running a GLMM with a poisson
> family for some tick burden data I have and I wanted to check if I had
> overdispersion in my model (and thus a poisson family would be
> inappropriate).  The only method I have found to do this is to run the
> model with a quasipoisson family and then ask for the scale parameter
> using:
>
> lme4:::sigma(model)
>
> However, when I do this my model appears severely UNDER dispersed:
>  sigmaML
> 3.779694e-06
>
> Without the random effect in the model (i.e a GLM) the scale parameter
> is 1.07 - almost perfect for a poisson family.  Is the method I  am
> trying not appropriate to determine the dispersion in the mixed model?
> Does anyone know a better method?
>
> Many thanks,
> Anna
>
>
> The University of Aberdeen is a charity registered in Scotland, No
> SC013683.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html







The University of Aberdeen is a charity registered in Scotland, No SC013683.



From bates at stat.wisc.edu  Tue Oct 21 14:37:11 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 21 Oct 2008 07:37:11 -0500
Subject: [R-sig-ME] Poisson mixed models
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28ACF89F47@VMAILB.uoa.abdn.ac.uk>
References: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>
	<C7B4619A-87B6-4709-BD17-4E844C2EC419@muohio.edu>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F47@VMAILB.uoa.abdn.ac.uk>
Message-ID: <40e66e0b0810210537x766544eex93687235f236afd2@mail.gmail.com>

On Tue, Oct 21, 2008 at 5:24 AM, Renwick, A. R. <a.renwick at abdn.ac.uk> wrote:
> I did run a GLMM with poisson - that is the model type I want to use.  I only used a GLMM with quasipoisson to check the scale parameter as I am unaware as to how to check if you have over/under dispersion in the poisson model, and hence violating the assumption of the model, and other way.
>
> # glmm with poisson family
> mix<-lmer(trianlarvae~Sex+width+sess+Nhat+Sex:width+Sex:sess+Sex:Nhat+width:sess+width:Nhat+sess:Nhat+(1|LocTran), family=poisson, data=larv, REML=FALSE)
> summary(mix)
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: trianlarvae ~ Sex + width + sess + Nhat + Sex:width + Sex:sess +      Sex:Nhat + width:sess + width:Nhat + sess:Nhat + (1 | LocTran)
>   Data: larv
>  AIC   BIC logLik deviance
>  464 572.7   -212      424
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  LocTran (Intercept) 1.3462   1.1603
> Number of obs: 1697, groups: LocTran, 14
>
> Fixed effects:
>                      Estimate Std. Error z value Pr(>|z|)
> (Intercept)         -4.218e+00  1.708e+00 -2.4694   0.0135 *
> Sexmale              6.999e-01  1.189e+00  0.5887   0.5561
> width               -1.426e-01  2.360e-01 -0.6044   0.5456
> sessAugust           1.486e+00  2.060e+00  0.7212   0.4708
> sessJune            -1.545e+01  1.212e+03 -0.0127   0.9898
> sessOctober          3.119e+00  1.838e+00  1.6973   0.0896 .
> Nhat                -4.909e-02  5.814e-02 -0.8442   0.3985
> Sexmale:width        1.159e-01  7.612e-02  1.5222   0.1280
> Sexmale:sessAugust  -7.540e-01  1.632e+00 -0.4621   0.6440
> Sexmale:sessJune     1.310e+01  1.212e+03  0.0108   0.9914
> Sexmale:sessOctober -1.118e+00  1.223e+00 -0.9139   0.3608
> Sexmale:Nhat         9.881e-03  1.012e-02  0.9765   0.3288
> width:sessAugust     8.245e-01  5.882e-01  1.4017   0.1610
> width:sessJune      -4.034e-02  2.791e-01 -0.1445   0.8851
> width:sessOctober   -1.045e-02  2.057e-01 -0.0508   0.9595
> width:Nhat           4.239e-03  3.654e-03  1.1600   0.2460
> sessAugust:Nhat     -1.484e-01  1.299e-01 -1.1422   0.2534
> sessJune:Nhat        2.646e-02  6.249e-02  0.4235   0.6719
> sessOctober:Nhat     1.462e-03  5.776e-02  0.0253   0.9798
>
>
>
>
> -----Original Message-----
> From: Martin Henry H. Stevens [mailto:HStevens at muohio.edu]
> Sent: 21 October 2008 11:19
> To: Renwick, A. R.
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Poisson mixed models
>
> Hi Anna,
> So you tried a GLMM with quasipoisson and a GLM with Poisson? How about a GLMM with Poisson? Sounds like you may have a random effect that is necessary for your hypothesis test, but which does not explain any variation (but I really have no way of knowing).
> Hank
> On Oct 21, 2008, at 5:33 AM, Renwick, A. R. wrote:
>
>>  Dear All
>> There has been a lot of talk recently on this forum regarding (over)
>> dispersion and quasi models.  I am running a GLMM with a poisson
>> family for some tick burden data I have and I wanted to check if I had
>> overdispersion in my model (and thus a poisson family would be
>> inappropriate).  The only method I have found to do this is to run the
>> model with a quasipoisson family and then ask for the scale parameter
>> using:
>>
>> lme4:::sigma(model)
>>
>> However, when I do this my model appears severely UNDER dispersed:
>>  sigmaML
>> 3.779694e-06
>>
>> Without the random effect in the model (i.e a GLM) the scale parameter
>> is 1.07 - almost perfect for a poisson family.  Is the method I  am
>> trying not appropriate to determine the dispersion in the mixed model?
>> Does anyone know a better method?
>>
>> Many thanks,
>> Anna

That seems to be an unusually low value for the dispersion.

I would have to check the code to see exactly what the sigma function
returns in the case of the quasipoisson family.  It is quite possible
that it is an inappropriate value.

I think it is more straightforward to look at the penalized, weighted
residual sum of squares, model at deviance["pwrss"], divided by the
number of observations, model at dims["n"].  You can do that for a model
fit with the Poisson family.

It also looks as if you will want to reduce the number of
fixed-effects terms in the model.



From bates at stat.wisc.edu  Tue Oct 21 15:38:08 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 21 Oct 2008 08:38:08 -0500
Subject: [R-sig-ME] My lack of responses to questions on the list
Message-ID: <40e66e0b0810210638o949907fu9bc89287a162e005@mail.gmail.com>

I do appreciate the questions and the discussions on this email list.

I feel I should explain why I have not been responding rapidly of
late.  Martin Maechler and I have been extending the Matrix by adding
Tim Davis's recently released SparseSuiteQR library, which provides a
rank-revealing QR decomposition for sparse matrices.  We are also
preparing the Matrix package for its 1.0 release and for its inclusion
as a recommended package for R-2.9.0.  That caused somewhat more
modification than we had planned.

I had hoped to be able to use the sparse QR decomposition in
preference to the sparse Cholesky decomposition in the lme4 package.
The approaches are equivalent but in some ways the QR decomposition is
more easily understood.  Also, this implementation of the QR can take
advantage of multiple cores in the processor.  However, it turns out
that, even with multithreading, for the types of model matrices
encountered in big mixed models the QR is considerably slower than the
Cholesky.  This is one of the differences between working on theory
and working on implementations.  When you are working on theory you
are done when you finish writing out the equations and perhaps do one
simple example.  When working on the implementation you need to
actually do an implementation before you can check whether it is
worthwhile making a change.

There is a new (and, of course, incomplete at present) version of the
"Computational Methods for Mixed Models" vignette in the current lme4
package.  It describes a general approach to mixed models based on
PIRLS, a penalized iteratively-reweighted least squares optimization.
I have a branch of the SVN archive at R-forge called "allcoef" where I
am reworking the implementation.  (Don't try to install it in its
current form - it's all in pieces right now although I do expect to be
able to reassemble it into a working package). If you are interested
you can poke around a bit there.  The objective is to create a common
core for PIRLS optimization in linear, generalized linear, nonlinear
and generalized nonlinear mixed models.  That core can then be
included in classes that implement the covariance factors and provide
for different conditional variances of the response.



From vmuggeo at dssm.unipa.it  Tue Oct 21 16:10:58 2008
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Tue, 21 Oct 2008 16:10:58 +0200
Subject: [R-sig-ME] using glmer with user-defined link function
Message-ID: <48FDE2F2.4000706@dssm.unipa.it>

dear all,
I am trying to use an user-specified link function in glmer() (via the 
argument family), but the error is

Error in famType(glmFit$family) : unknown link: ?my_link?

my_link is a proper link function (of class "link-glm") which works 
correctly with glm() and also with MASS::glmmPQL()

It appears that the function lme4::famType() checks for the name by 
comparing it with the names in "famNms" which includes "gaussian", 
"binomial", "Gamma", ... however I do not know whether it is sufficient 
to include "my_link" in famNms, and possibly I do not how to do it.. :-)

many thanks,
vito



-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612
http://dssm.unipa.it/vmuggeo



From michael.beaulieu at c-strasbourg.fr  Tue Oct 21 16:20:55 2008
From: michael.beaulieu at c-strasbourg.fr (Michael Beaulieu)
Date: Tue, 21 Oct 2008 16:20:55 +0200
Subject: [R-sig-ME] Difficulty with mixed models in R
Message-ID: <48FDE547.9020305@c-strasbourg.fr>

Dear R users,

I would like two compare the diving behaviour of two groups of penguins 
(7 penguin in each group). Each penguin performed several dives within 
several foraging trips. As a result, I got a huge data set of dives 
(nearly 100000).
To compare the diving behaviour (in the script PDD) of the two groups, I 
used a mixed model with:
-the penguin as a random factor,
-the number of dives nested in the foraging trip as a repeated factor,
-the group, the foraging trip and maximal depth (MD) as fixed factors.
Covariance structure was auto-regressive.

Here is the script I used:

library(nlme)
penguin = read.table(file = "C://Documents and 
Settings//Administrateur//Bureau//mk9ter.txt", header = T, sep = "\t", 
dec = ".", na.strings="NA")
penguin$Penguin =  as.factor(penguin$Penguin)
penguin$Ndive =  as.factor(penguin$Ndive)
penguin$Ntrip =  as.factor(penguin$Ntrip)
penguin = penguin[!is.na(penguin$Penguin),]
Penguin = groupedData(formula = PDD ~ Ntrip | Penguin, data = penguin)
rm(penguin)
model = lme(PDD ~ Ntrip + Status + MD + Ntrip/Ndive,
             data=Penguin,
             random= ~ Status | Penguin,
         correlation=corAR1() )

And here is the result I get:
Reached the total allocation of 1022 Mb: see help (memory.size)

Moreover I should add interactions between fixed effects.

Before I feel totally depressed, is there anybody who could help me ?

Thank you in advance

MiKL



From Thierry.ONKELINX at inbo.be  Tue Oct 21 17:23:53 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 21 Oct 2008 17:23:53 +0200
Subject: [R-sig-ME] Difficulty with mixed models in R
In-Reply-To: <48FDE547.9020305@c-strasbourg.fr>
References: <48FDE547.9020305@c-strasbourg.fr>
Message-ID: <2E9C414912813E4EB981326983E0A10405A201CA@inboexch.inbo.be>

Dear Michael,

I think you want 

model <- lme(PDD ~ Status + MD,
             data = Penguin,
             random = ~ Status | Penguin/Ntrip/Ndive,
             correlation = corAR1()) 

And make shure that Ndive is unique for each dive. You'll get into
trouble if each Ntrip has Ndive = 1.

If you don't have multiple observations per dive than you don't need to
add Ndive.
model <- lme(PDD ~ Status + MD,
             data = Penguin,
             random= ~ Status | Penguin/Ntrip,
             correlation = corAR1()) 

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Michael
Beaulieu
Verzonden: dinsdag 21 oktober 2008 16:21
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Difficulty with mixed models in R

Dear R users,

I would like two compare the diving behaviour of two groups of penguins 
(7 penguin in each group). Each penguin performed several dives within 
several foraging trips. As a result, I got a huge data set of dives 
(nearly 100000).
To compare the diving behaviour (in the script PDD) of the two groups, I

used a mixed model with:
-the penguin as a random factor,
-the number of dives nested in the foraging trip as a repeated factor,
-the group, the foraging trip and maximal depth (MD) as fixed factors.
Covariance structure was auto-regressive.

Here is the script I used:

library(nlme)
penguin = read.table(file = "C://Documents and 
Settings//Administrateur//Bureau//mk9ter.txt", header = T, sep = "\t", 
dec = ".", na.strings="NA")
penguin$Penguin =  as.factor(penguin$Penguin)
penguin$Ndive =  as.factor(penguin$Ndive)
penguin$Ntrip =  as.factor(penguin$Ntrip)
penguin = penguin[!is.na(penguin$Penguin),]
Penguin = groupedData(formula = PDD ~ Ntrip | Penguin, data = penguin)
rm(penguin)
model = lme(PDD ~ Ntrip + Status + MD + Ntrip/Ndive,
             data=Penguin,
             random= ~ Status | Penguin,
         correlation=corAR1() )

And here is the result I get:
Reached the total allocation of 1022 Mb: see help (memory.size)

Moreover I should add interactions between fixed effects.

Before I feel totally depressed, is there anybody who could help me ?

Thank you in advance

MiKL

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bolker at ufl.edu  Tue Oct 21 20:57:34 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 21 Oct 2008 14:57:34 -0400
Subject: [R-sig-ME] using glmer with user-defined link function
Message-ID: <48FE261E.5020703@ufl.edu>



  I tried to deal with this at one point to put in a negative
binomial model.  I, too, was hopeful that just
adding the name of my link function to the list
of allowed names would be all that was
needed. Unfortunately, the variance functions are
hard coded within the glmer code, so it will not be completely
trivial to do this ...

   Ben


vito muggeo wrote:
> dear all,
> I am trying to use an user-specified link function in glmer() (via the
> argument family), but the error is
> 
> Error in famType(glmFit$family) : unknown link: ?my_link?
> 
> my_link is a proper link function (of class "link-glm") which works
> correctly with glm() and also with MASS::glmmPQL()
> 
> It appears that the function lme4::famType() checks for the name by
> comparing it with the names in "famNms" which includes "gaussian",
> "binomial", "Gamma", ... however I do not know whether it is sufficient
> to include "my_link" in famNms, and possibly I do not how to do it.. :-)
> 
> many thanks,
> vito
> 
> 
>



From bates at stat.wisc.edu  Tue Oct 21 21:29:28 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 21 Oct 2008 14:29:28 -0500
Subject: [R-sig-ME] using glmer with user-defined link function
In-Reply-To: <48FE261E.5020703@ufl.edu>
References: <48FE261E.5020703@ufl.edu>
Message-ID: <40e66e0b0810211229l6bc7d0c5h952eaad16f10f662@mail.gmail.com>

You can use a "quasi" family with separate specification of the link
and the variance function but there are only a limited number of
variance functions available.

The reason that the inverse link and the variance functions are
hard-coded in glmer is because the number of evaluations of these
functions is potentially much, much greater than the number of
evaluations involved in fitting a generalized linear model (glm).  As
always, it doesn't matter that much when you have a small to moderate
sample size but it does matter when you have large sample sizes and
for models like IRT (item response theory) models the sample size can
be large indeed (tens of millions is not uncommon since each answer by
each candidate constitutes a distinct response).  It is difficult to
design code that is both efficient on large data sets and is flexible
in terms of the model specification.  In this case I chose to go with
the ability to handle large data sets.

If you have a custom variance function of inverse link function that
you would like to use, you are welcome to contribute the code for
them.  See the C functions lme4_varFunc, lme4_muEta and lme4_devResid
in lme4/src/lmer.c for the currently available code.

On Tue, Oct 21, 2008 at 1:57 PM, Ben Bolker <bolker at ufl.edu> wrote:
>
>
>  I tried to deal with this at one point to put in a negative
> binomial model.  I, too, was hopeful that just
> adding the name of my link function to the list
> of allowed names would be all that was
> needed. Unfortunately, the variance functions are
> hard coded within the glmer code, so it will not be completely
> trivial to do this ...
>
>   Ben
>
>
> vito muggeo wrote:
>> dear all,
>> I am trying to use an user-specified link function in glmer() (via the
>> argument family), but the error is
>>
>> Error in famType(glmFit$family) : unknown link: 'my_link'
>>
>> my_link is a proper link function (of class "link-glm") which works
>> correctly with glm() and also with MASS::glmmPQL()
>>
>> It appears that the function lme4::famType() checks for the name by
>> comparing it with the names in "famNms" which includes "gaussian",
>> "binomial", "Gamma", ... however I do not know whether it is sufficient
>> to include "my_link" in famNms, and possibly I do not how to do it.. :-)
>>
>> many thanks,
>> vito
>>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Oct 21 22:47:48 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 21 Oct 2008 16:47:48 -0400
Subject: [R-sig-ME] using glmer with user-defined link function
In-Reply-To: <40e66e0b0810211229l6bc7d0c5h952eaad16f10f662@mail.gmail.com>
References: <48FE261E.5020703@ufl.edu>
	<40e66e0b0810211229l6bc7d0c5h952eaad16f10f662@mail.gmail.com>
Message-ID: <48FE3FF4.3010808@ufl.edu>

  The rationale certainly makes sense.

  Eventually I would like to add a negative binomial link
function, but that will (a) require some time and (b) require
me to write an additional loop around glmer that searches
for the MLE of the overdispersion parameter.  (I did look briefly
at the code, but I don't remember offhand whether it would
be hard to have a link function with an additional parameter.
Looking now at lme4_varFunc, it looks hard -- the function
takes only var (computed variance), mu (mean value), n (number
of samples), vTyp (variance model) -- no slot for a "theta"
or "k" parameter.)

  thanks
    Ben Bolker

Douglas Bates wrote:
> You can use a "quasi" family with separate specification of the link
> and the variance function but there are only a limited number of
> variance functions available.
> 
> The reason that the inverse link and the variance functions are
> hard-coded in glmer is because the number of evaluations of these
> functions is potentially much, much greater than the number of
> evaluations involved in fitting a generalized linear model (glm).  As
> always, it doesn't matter that much when you have a small to moderate
> sample size but it does matter when you have large sample sizes and
> for models like IRT (item response theory) models the sample size can
> be large indeed (tens of millions is not uncommon since each answer by
> each candidate constitutes a distinct response).  It is difficult to
> design code that is both efficient on large data sets and is flexible
> in terms of the model specification.  In this case I chose to go with
> the ability to handle large data sets.
> 
> If you have a custom variance function of inverse link function that
> you would like to use, you are welcome to contribute the code for
> them.  See the C functions lme4_varFunc, lme4_muEta and lme4_devResid
> in lme4/src/lmer.c for the currently available code.
> 
> On Tue, Oct 21, 2008 at 1:57 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>
>>  I tried to deal with this at one point to put in a negative
>> binomial model.  I, too, was hopeful that just
>> adding the name of my link function to the list
>> of allowed names would be all that was
>> needed. Unfortunately, the variance functions are
>> hard coded within the glmer code, so it will not be completely
>> trivial to do this ...
>>
>>   Ben
>>
>>
>> vito muggeo wrote:
>>> dear all,
>>> I am trying to use an user-specified link function in glmer() (via the
>>> argument family), but the error is
>>>
>>> Error in famType(glmFit$family) : unknown link: 'my_link'
>>>
>>> my_link is a proper link function (of class "link-glm") which works
>>> correctly with glm() and also with MASS::glmmPQL()
>>>
>>> It appears that the function lme4::famType() checks for the name by
>>> comparing it with the names in "famNms" which includes "gaussian",
>>> "binomial", "Gamma", ... however I do not know whether it is sufficient
>>> to include "my_link" in famNms, and possibly I do not how to do it.. :-)
>>>
>>> many thanks,
>>> vito
>>>
>>>
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From sundar.dorai-raj at pdf.com  Tue Oct 21 23:57:50 2008
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 21 Oct 2008 14:57:50 -0700
Subject: [R-sig-ME] Binomial GLMM with different versions of lme4
Message-ID: <48FE505E.4070100@pdf.com>

Hi, Prof. Bates (and all other interested parties),

I haven't been using the lme4 package recently for binomial modeling but 
have recently returned for some analysis and found some puzzling 
problems. The current package version (0.999375-27) incorrectly 
estimates the dispersion parameter when using a quasibinomial. I think 
this is referred to indirectly in the following thread:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001501.html

However, I have attached a working example that shows (I believe) the 
last known package where the dispersion is believable. For now, I'm 
using the older package to do the analysis but would be grateful for any 
corrections or workarounds.

<code>
# library(lme4, lib = "D:/R/archive") ## version 0.99875-9
library(lme4)                         ## version 0.999375-27

set.seed(2)
## simulate data
A <- factor(rep(1:10, each = 10))
n <- length(A)
rA <- rnorm(nlevels(A))
y <- rbinom(n, 1, binomial()$linkinv(0.5 + rA[A]))
(f <- lmer(y ~ (1 | A), family = quasibinomial))

extractVar.lmer <- function (object, ...) {
   vc <- VarCorr(object)
   vdc <- unlist(lapply(lapply(vc, as.matrix), diag))
   names(vdc) <- sub("\\.\\(.*\\)", "", names(vdc))
   Var <- c(vdc, attr(vc, "sc")^2)
   names(Var)[length(Var)] <- "residual"
   Var
}

v <- extractVar.lmer(f)
c(v[1]/v[2], v[2])

sessionInfo()
</code>

<output version="0.99875-9">
 > (f <- lmer(y ~ (1 | A), family = quasibinomial))
Generalized linear mixed model fit using Laplace
Formula: y ~ (1 | A)
  Family: quasibinomial(logit link)
  AIC   BIC logLik deviance
  130 135.2    -63      126
Random effects:
  Groups   Name        Variance Std.Dev.
  A        (Intercept) 0.22075  0.46984
  Residual             0.95095  0.97517
number of obs: 100, groups: A, 10

Fixed effects:
             Estimate Std. Error t value
(Intercept)   0.7443     0.2572   2.893
 >
 > v <- extractVar.lmer(f)
 > c(v[1]/v[2], v[1])
         A  residual
0.2321391 0.9509488
 > sessionInfo()
R version 2.7.2 (2008-08-25)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.99875-9     Matrix_0.999375-15 lattice_0.17-15

loaded via a namespace (and not attached):
[1] grid_2.7.2
</output>

<output version="0.999375-27">
 > (f <- lmer(y ~ (1 | A), family = quasibinomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ (1 | A)
  AIC   BIC logLik deviance
  132 139.8    -63      126
Random effects:
  Groups   Name        Variance Std.Dev.
  A        (Intercept) 0.046833 0.21641
  Residual             0.205057 0.45283
Number of obs: 100, groups: A, 10

Fixed effects:
             Estimate Std. Error t value
(Intercept)   0.7463     0.1191   6.264
 >
 > v <- extractVar.lmer(f)
 > c(v[1]/v[2], v[1])
         A  residual
0.2283881 0.2050567
 >
 > sessionInfo()
R version 2.7.2 (2008-08-25)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-27   Matrix_0.999375-15 lattice_0.17-15

loaded via a namespace (and not attached):
[1] grid_2.7.2
</output>

Thanks,

--sundar



From ken at kjbeath.com.au  Wed Oct 22 01:54:53 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 22 Oct 2008 10:54:53 +1100
Subject: [R-sig-ME] Poisson mixed models
In-Reply-To: <40e66e0b0810210537x766544eex93687235f236afd2@mail.gmail.com>
References: <1F4755565F237F45AA01135B72E8C1B2053527@scomp0039.wurnet.nl>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F45@VMAILB.uoa.abdn.ac.uk>
	<C7B4619A-87B6-4709-BD17-4E844C2EC419@muohio.edu>
	<B9D1301370916C44B5874AF340C18B9B28ACF89F47@VMAILB.uoa.abdn.ac.uk>
	<40e66e0b0810210537x766544eex93687235f236afd2@mail.gmail.com>
Message-ID: <61F3556A-E276-4CDA-97D8-E29C1139FDBA@kjbeath.com.au>

On 21/10/2008, at 11:37 PM, Douglas Bates wrote:

> On Tue, Oct 21, 2008 at 5:24 AM, Renwick, A. R.  
> <a.renwick at abdn.ac.uk> wrote:
>>
>>> Dear All
>>> There has been a lot of talk recently on this forum regarding (over)
>>> dispersion and quasi models.  I am running a GLMM with a poisson
>>> family for some tick burden data I have and I wanted to check if I  
>>> had
>>> overdispersion in my model (and thus a poisson family would be
>>> inappropriate).  The only method I have found to do this is to run  
>>> the
>>> model with a quasipoisson family and then ask for the scale  
>>> parameter
>>> using:
>>>
>>> lme4:::sigma(model)
>>>
>>> However, when I do this my model appears severely UNDER dispersed:
>>> sigmaML
>>> 3.779694e-06
>>>
>>> Without the random effect in the model (i.e a GLM) the scale  
>>> parameter
>>> is 1.07 - almost perfect for a poisson family.  Is the method I  am
>>> trying not appropriate to determine the dispersion in the mixed  
>>> model?
>>> Does anyone know a better method?
>>>
>>> Many thanks,
>>> Anna
>
> That seems to be an unusually low value for the dispersion.
>
> I would have to check the code to see exactly what the sigma function
> returns in the case of the quasipoisson family.  It is quite possible
> that it is an inappropriate value.
>
> I think it is more straightforward to look at the penalized, weighted
> residual sum of squares, model at deviance["pwrss"], divided by the
> number of observations, model at dims["n"].  You can do that for a model
> fit with the Poisson family.
>
> It also looks as if you will want to reduce the number of
> fixed-effects terms in the model.
>

I posted this before but it seems to have been missed.

A quick simulation shows that something is wrong. What I did was to  
generate random effects Poisson data and fit both as Poisson and quasi  
Poisson, and should give similar results except with slightly larger  
SE for quasi. Note the change in the subject random effect std dev.  
This seems to be close to the square of the mean of the Poisson data.  
Standard errors for fixed effects are totally wrong.

Ken

 > nsubj <- 100
 > npersubj <- 20
 >
 > subject <- factor(rep(1:nsubj,each=npersubj))
 >
 > means <- exp(rep(10+rnorm(nsubj),each=npersubj))
 >
 > y <- rpois(nsubj*npersubj,means)
 >
 > simdata <- data.frame(y,subject)
 >
 > lmer1 <- lmer(y~(1|subject),data=simdata,family=poisson)
 > summary(lmer1)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ (1 | subject)
    Data: simdata
   AIC  BIC logLik deviance
  3305 3316  -1650     3301
Random effects:
  Groups  Name        Variance Std.Dev.
  subject (Intercept) 0.9891   0.99453
Number of obs: 2000, groups: subject, 100

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) 10.12714    0.09945   101.8   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 >
 > lmer2 <- lmer(y~(1|subject),data=simdata,family=quasipoisson)
 > summary(lmer2)
Generalized linear mixed model fit by the Laplace approximation
Formula: y ~ (1 | subject)
    Data: simdata
   AIC  BIC logLik deviance
  3307 3324  -1650     3301
Random effects:
  Groups   Name        Variance Std.Dev.
  subject  (Intercept) 15137    123.03
  Residual             15304    123.71
Number of obs: 2000, groups: subject, 100

Fixed effects:
             Estimate Std. Error t value
(Intercept)    10.13      12.30  0.8231



From bolker at ufl.edu  Fri Oct 24 17:19:39 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 24 Oct 2008 11:19:39 -0400
Subject: [R-sig-ME] 1991 indian literacy data
Message-ID: <4901E78B.3070302@ufl.edu>


  Right now I need another project like I need a hole
in the head (as they say), but ...

  Does anyone happen to have their hands on the
literacy data from the Indian 1991 census that is
used as an example in

Browne, W. J., S. V. Subramanian, K. Jones, and H. Goldstein. 2005.
Variance partitioning in multilevel logistic models that exhibit
overdispersion. Journal of the Royal Statistical Society Series A 168,
no. 3: 599-613. doi:10.1111/j.1467-985X.2004.00365.x.

 and in earlier papers by Subramanian ... ?

  cheers
    Ben Bolker



From vanmete7 at msu.edu  Fri Oct 24 15:36:32 2008
From: vanmete7 at msu.edu (Page E. Van Meter)
Date: Fri, 24 Oct 2008 09:36:32 -0400
Subject: [R-sig-ME] Generalized mixed models for poisson distributions
Message-ID: <4901CF60.8000204@msu.edu>

Hello,
Reading through this forum has been very informative, but I am afraid I 
have a rather basic question. I am new to both R and generlized models 
(I have experience running linear mixed models with SPSS).

I have been playing with the glm function in R (using Faraway as my 
guide), but this forum seems to focus on glmer and lmer. What is the 
difference between running mixed effects models using glm and glmer?

Thanks,
-Page
-- 
************************************
Page E. Van Meter
Michigan State University
Department of Zoology

**
*



From bates at stat.wisc.edu  Fri Oct 24 17:42:19 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 24 Oct 2008 10:42:19 -0500
Subject: [R-sig-ME] Generalized mixed models for poisson distributions
In-Reply-To: <4901CF60.8000204@msu.edu>
References: <4901CF60.8000204@msu.edu>
Message-ID: <40e66e0b0810240842l26899db0o3a1de2cee547a385@mail.gmail.com>

On Fri, Oct 24, 2008 at 8:36 AM, Page E. Van Meter <vanmete7 at msu.edu> wrote:
> Hello,
> Reading through this forum has been very informative, but I am afraid I have
> a rather basic question. I am new to both R and generlized models (I have
> experience running linear mixed models with SPSS).

> I have been playing with the glm function in R (using Faraway as my guide),
> but this forum seems to focus on glmer and lmer. What is the difference
> between running mixed effects models using glm and glmer?

I think you are confusing generalized linear models, which are models
used when the response is binary or binomial or a count, and
mixed-effects models, which are models where some of the coefficients
in the predictor are fixed-effects parameters, which apply to an
entire population or well-defined subgroups of the population (females
vs males, say), and other coefficients are random effects, which apply
to the particular observational or experimental units being
considered.

The glm function fits generalized linear models with fixed-effects
parameters only.  The glmer function fits generalized linear mixed
models (the 'me' in the name is from 'mixed-effects').

I hope this helps.



From ruhil at ohio.edu  Fri Oct 24 18:27:30 2008
From: ruhil at ohio.edu (Anirudh V.S. Ruhil)
Date: Fri, 24 Oct 2008 12:27:30 -0400
Subject: [R-sig-ME] 1991 indian literacy data
In-Reply-To: <4901E78B.3070302@ufl.edu>
References: <4901E78B.3070302@ufl.edu>
Message-ID: <4901F772.7030200@ohio.edu>

Ben:

Check with *Subramanian, S V*. He is at Harvard's SPH; url is:
http://www.hsph.harvard.edu/faculty/venkata-sankaranarayanan/index.html

Ani

Ben Bolker wrote:
>   Right now I need another project like I need a hole
> in the head (as they say), but ...
>
>   Does anyone happen to have their hands on the
> literacy data from the Indian 1991 census that is
> used as an example in
>
> Browne, W. J., S. V. Subramanian, K. Jones, and H. Goldstein. 2005.
> Variance partitioning in multilevel logistic models that exhibit
> overdispersion. Journal of the Royal Statistical Society Series A 168,
> no. 3: 599-613. doi:10.1111/j.1467-985X.2004.00365.x.
>
>  and in earlier papers by Subramanian ... ?
>
>   cheers
>     Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   


From vanmete7 at msu.edu  Fri Oct 24 22:41:24 2008
From: vanmete7 at msu.edu (Page E. Van Meter)
Date: Fri, 24 Oct 2008 16:41:24 -0400
Subject: [R-sig-ME] Generalized mixed models for poisson distributions
In-Reply-To: <4901ED26.7010807@zoology.ufl.edu>
References: <4901CF60.8000204@msu.edu> <4901ED26.7010807@zoology.ufl.edu>
Message-ID: <490232F4.7020503@msu.edu>


Thanks!
To clarify the simple mistake I was making for possible future novice 
readers of this mailing list:
I did not understand that the glm function cannot handle random effects 
(which Faraway NEVER mentions in his book). I also did not understand 
that glmer and lmer can both handle non-linear data as long as the 
"family" is specified.

I am very comfortable with linear models, linear mixed effect models, 
and non-linear models, but I have been having a lot of trouble tackling 
non-linear mixed effect models. I really do wish we could all agree on 
terms for these models (GLM is used for both general linear mixed models 
and generalized mixed models in many fields). Anyway, these were very 
rudimentary stumbling blocks that were not immediately apparent to me, 
so hopefully this will clarify for others.
Thanks again,
-Page

Ben Bolker wrote:
> glm doesn't do mixed effects models at all.
>
>   You might (?) be confused about this because some software
> packages (SAS in particular, I don't know about SPSS) use the acronym
> GLM to refer to "general linear models" (rather than general*ized*
> linear models).  Some particular kinds of linear mixed models
> (nested, balanced designs) can be estimated using the same
> general approaches used for ANOVA (in R, this would correspond
> to using aov with an Error term in the model).
>
>   Linear models: lm (or aov)
>   Generalized linear models: glm
>
>   For linear mixed models you need lme (in the nlme package)
> or lmer (lme4).  For generalized linear mixed models you
> need glmmPQL (MASS/nlme) or glmer (lme4).
>
>   Ben Bolker
>
>   

-- 
************************************
Page E. Van Meter
Michigan State University
Department of Zoology
vanmete7 at msu.edu
**http://msu.edu/~vanmete7/*



From bolker at ufl.edu  Fri Oct 24 23:21:45 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 24 Oct 2008 16:21:45 -0500
Subject: [R-sig-ME] Generalized mixed models for poisson distributions
In-Reply-To: <490232F4.7020503@msu.edu>
References: <4901CF60.8000204@msu.edu> <4901ED26.7010807@zoology.ufl.edu>
	<490232F4.7020503@msu.edu>
Message-ID: <49023C69.9060503@ufl.edu>

Page E. Van Meter wrote:
>
> Thanks!
> To clarify the simple mistake I was making for possible future novice 
> readers of this mailing list:
> I did not understand that the glm function cannot handle random 
> effects (which Faraway NEVER mentions in his book). I also did not 
> understand that glmer and lmer can both handle non-linear data as long 
> as the "family" is specified.
>
> I am very comfortable with linear models, linear mixed effect models, 
> and non-linear models, but I have been having a lot of trouble 
> tackling non-linear mixed effect models. I really do wish we could all 
> agree on terms for these models (GLM is used for both general linear 
> mixed models and generalized mixed models in many fields). Anyway, 
> these were very rudimentary stumbling blocks that were not immediately 
> apparent to me, so hopefully this will clarify for others.
  1.  It is too bad about the GLM thing, but I think both usages 
("general" and "generalized" are here to stay).
  2. Just to clarify a tiny bit more: "nonlinear mixed effect models" 
usually implies normally distributed data (i.e. error terms) with 
non-linear, NON-linearizable dependence of expected values on continuous 
covariates (if they were linearizable then one could handle a 
normal-error model with family(gaussian,link="..."))
nlmer handles these -- it doesn't complain about a "family" argument, 
but based on a quick look on the output it looks like the function
actually ignores it.
  3. GLMMs handle exponential-family data and linearizable 
nonlinearities -- and they are indeed much harder than LMMs or GLMs.

> Ben Bolker wrote:
>> glm doesn't do mixed effects models at all.
>>
>>   You might (?) be confused about this because some software
>> packages (SAS in particular, I don't know about SPSS) use the acronym
>> GLM to refer to "general linear models" (rather than general*ized*
>> linear models).  Some particular kinds of linear mixed models
>> (nested, balanced designs) can be estimated using the same
>> general approaches used for ANOVA (in R, this would correspond
>> to using aov with an Error term in the model).
>>
>>   Linear models: lm (or aov)
>>   Generalized linear models: glm
>>
>>   For linear mixed models you need lme (in the nlme package)
>> or lmer (lme4).  For generalized linear mixed models you
>> need glmmPQL (MASS/nlme) or glmer (lme4).
>>
>>   Ben Bolker
>>
>>   
>



From vanmete7 at msu.edu  Sat Oct 25 00:37:09 2008
From: vanmete7 at msu.edu (Page E. Van Meter)
Date: Fri, 24 Oct 2008 18:37:09 -0400
Subject: [R-sig-ME] fitting models with poisson distributed data
In-Reply-To: <49023C69.9060503@ufl.edu>
References: <4901CF60.8000204@msu.edu> <4901ED26.7010807@zoology.ufl.edu>
	<490232F4.7020503@msu.edu> <49023C69.9060503@ufl.edu>
Message-ID: <49024E15.3040201@msu.edu>

Hi,
Now that I have the code figured out, I hoping for some help on defining 
my model. I might be guilty of trying to fit an overly complex model to 
my data, although my model seems very simple in comparison to what has 
been discussed here. I'm hoping for feedback on my model design. Thanks 
in advance!

I have some pretty ugly longitudinal data measuring hormones and 
behaviors from individual hyenas over many years (355 samples from 39 
individuals). We collect hormone samples based on opportunity and have 
several samples from each individual (3-9 samples per hyena). My 
ultimate goal is to see if my hormone data explains any of the variation 
we see in the behavior data (aggression, I'll call it aggs). My 
dependent measurement is a behavior rate, count of aggs over time just 
prior to hormone sample collection. It is very zero heavy (lots of 
individuals did not aggress prior to hormone sample donation) and 
resistant to transformation to normality, but seems to be a pretty 
poisson distribution. My predictors are hormones and reproductive state 
(pregnant or lactating, which effect both aggression and hormones).

m2<-lmer(aggs~reprostate+hrm1+hrm2+(1|id), family=poisson, aggs)

Generalized linear mixed model fit using Laplace
Formula: aggs ~ reprostate + hrm1 + hrm2 + (1 | id)
   Data: aggs
 Family: poisson(log link)
   AIC   BIC logLik deviance
 12369 12387  -6179    12359
Random effects:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 4.9353   2.2216 
number of obs: 307, groups: id, 39

Estimated scale (compare to  1 )  7.682887

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept) -3.07625    0.39575  -7.773 7.65e-15 ***
reprostate 2.32056    0.07724  30.044  < 2e-16 ***
hrm1        0.12575    0.04020   3.128  0.00176 **
hrm2       -0.80434    0.04770 -16.862  < 2e-16 ***
---

Correlation of Fixed Effects:
         (Intr) statct ecent
statecat -0.381             
ecent    -0.085  0.271      
acent     0.136 -0.339 -0.079

-- 
************************************
Page E. Van Meter
Michigan State University
Department of Zoology
vanmete7 at msu.edu
**http://msu.edu/~vanmete7/*



From brant.inman at me.com  Mon Oct 27 02:17:04 2008
From: brant.inman at me.com (Brant Inman)
Date: Sun, 26 Oct 2008 21:17:04 -0400
Subject: [R-sig-ME] Multilevel weighted regression
Message-ID: <53859174-C61D-420B-96E2-A2C24E991A6C@me.com>


Hi,

I would like to use lmer to perform a meta-regression using a  
multilevel weighted regression.  I am having difficulty understanding  
how to use weights appropriately with lmer.  I have attached some code  
to demonstrate the type of problem that I will be modeling.

---------------

 > sessionInfo()
R version 2.7.2 (2008-08-25)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] nlme_3.1-89        foreign_0.8-29     car_1.2-8           
arm_1.1-15
  [5] R2WinBUGS_2.1-8    coda_0.13-2        MASS_7.2-44         
lme4_0.999375-24
  [9] Matrix_0.999375-11 lattice_0.17-13    meta_0.8-2

loaded via a namespace (and not attached):
[1] grid_2.7.2

--------------

Here is the example code for the BCG dataset of Colditz.

--------------

# Get dataset and format it appropriately into wide (BCG) and long  
(BCG.long) datasets

data('BCG', package='HSAUR')

logrr      <- log((BCG[,2] / BCG[,3]) / (BCG[,4] / BCG[,5]))
logrr.var  <- (1/BCG[,2]) + (1/BCG[,4]) - (1/BCG[,3]) - (1/BCG[,5])
logor	   <- log((BCG[,2]*(BCG[,5]-BCG[,4])) / (BCG[,4]*(BCG[,3]-BCG[, 
2])))
logor.var  <- sqrt((1/BCG[,2]) + (1/BCG[,4]) + (1/(BCG[,3]-BCG[,2])) +  
(1/(BCG[,5]-BCG[,4])))

BCG.long		 <- rbind(BCG[,c(1,6,7)], BCG[,c(1,6,7)])
	BCG.long$vaccine <- c(rep(1,13), rep(0,13))	
	BCG.long$event	 <- c(BCG[,2], BCG[,4])
	BCG.long$atrisk	 <- c(BCG[,3], BCG[,5])

# Fixed effects model using 'lm', RR scale, 2 explanatory variables
f1 <- lm(logrr ~ Latitude + Year, weights = (1/logrr.var), data=BCG)
	summary(f1)		
	mse <- sqrt(sum(f1$weights * f1$residuals^2) / f1$df.residual)
	sqrt(diag(vcov(f1))) / mse			# Adjust parameter SEs for weighting

# Fixed effects model using 'lmer', OR scale, no explanatory variables
f2 <- lmer(cbind(event,atrisk) ~ vaccine + (1 | study), data=BCG.long,  
family=binomial)
	summary(f2)

# Random effects model using 'lmer', OR scale, no explanatory variables
f3 <- lmer(cbind(event,atrisk) ~ vaccine + (vaccine | study),  
data=BCG.long, family=binomial)
	summary(f3)

---------------

What I would like to ask help for is:
1) How do I do write a weighted model like model 'f1' but using lmer  
so that I can fit a random effects model with covariates on RR scale?

2) How do I correctly specify the random effects model 'f3' to  
incorporate the covariates 'Latitude' and 'Year' on the OR scale?


I appreciate any time that any of you spare for this.

Brant Inman
Chapel Hill, NC



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Mon Oct 27 10:12:37 2008
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 27 Oct 2008 10:12:37 +0100
Subject: [R-sig-ME] Multilevel weighted regression
In-Reply-To: <53859174-C61D-420B-96E2-A2C24E991A6C@me.com>
Message-ID: <329A68716B57D54E8D39FD3F8A4A84DF0EB93FE5@um-mail0136.unimaas.nl>

Hi Brant,

This is not a direct answer to your question, but something that still may be useful for you. Using the normal approximation to the log relative risk:

yi    <- c(-0.89, -1.59, -1.35, -1.44, -0.22, -0.79, 
           -1.62,  0.01, -0.47, -1.37, -0.34,  0.45, -0.02)
vi    <- c(0.326, 0.195, 0.415, 0.020, 0.051, 0.007, 
           0.223, 0.004, 0.056, 0.073, 0.012, 0.533, 0.071)
ablat <- c(44, 55, 42, 52, 13, 44, 19, 13, 27, 42, 18, 33, 33)
year  <- c(1948, 1949, 1960, 1977, 1973, 1953, 
           1973, 1980, 1968, 1961, 1974, 1969, 1976)

source("http://www.wvbauer.com/downloads/mima.ssc")

mima(yi, vi, mods=cbind(ablat, year), method="REML")

This is for the random-effects model. To get the same results as your model f1 (without having to go through the adjustment step for the SEs):

mima(yi, vi, mods=cbind(ablat, year), fe="yes")

There is a short tutorial about the function at: http://www.wvbauer.com/downloads.html

I am curious as well to hear how lmer can be used in this context.

Best,

-- 
Wolfgang Viechtbauer
?Department of Methodology and Statistics
?University of Maastricht, The Netherlands
?http://www.wvbauer.com/



----Original Message----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Brant
Inman Sent: Monday, October 27, 2008 02:17 To:
r-sig-mixed-models at r-project.org Subject: [R-sig-ME] Multilevel
weighted regression 

> Hi,
> 
> I would like to use lmer to perform a meta-regression using a
> multilevel weighted regression.  I am having difficulty understanding
> how to use weights appropriately with lmer.  I have attached some code
> to demonstrate the type of problem that I will be modeling.
> 
> ---------------
> 
>  > sessionInfo()
> R version 2.7.2 (2008-08-25)
> i386-apple-darwin8.11.1
> 
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
>   [1] nlme_3.1-89        foreign_0.8-29     car_1.2-8
> arm_1.1-15
>   [5] R2WinBUGS_2.1-8    coda_0.13-2        MASS_7.2-44
> lme4_0.999375-24
>   [9] Matrix_0.999375-11 lattice_0.17-13    meta_0.8-2
> 
> loaded via a namespace (and not attached):
> [1] grid_2.7.2
> 
> --------------
> 
> Here is the example code for the BCG dataset of Colditz.
> 
> --------------
> 
> # Get dataset and format it appropriately into wide (BCG) and long
> (BCG.long) datasets
> 
> data('BCG', package='HSAUR')
> 
> logrr      <- log((BCG[,2] / BCG[,3]) / (BCG[,4] / BCG[,5]))
> logrr.var  <- (1/BCG[,2]) + (1/BCG[,4]) - (1/BCG[,3]) - (1/BCG[,5])
> logor	   <- log((BCG[,2]*(BCG[,5]-BCG[,4])) / (BCG[,4]*(BCG[,3]-BCG[,
> 2])))
> logor.var  <- sqrt((1/BCG[,2]) + (1/BCG[,4]) + (1/(BCG[,3]-BCG[,2])) +
> (1/(BCG[,5]-BCG[,4])))
> 
> BCG.long		 <- rbind(BCG[,c(1,6,7)], BCG[,c(1,6,7)])
> 	BCG.long$vaccine <- c(rep(1,13), rep(0,13))
> 	BCG.long$event	 <- c(BCG[,2], BCG[,4])
> 	BCG.long$atrisk	 <- c(BCG[,3], BCG[,5])
> 
> # Fixed effects model using 'lm', RR scale, 2 explanatory variables
> 	f1 <- lm(logrr ~ Latitude + Year, weights = (1/logrr.var), data=BCG)
> 	summary(f1) mse <- sqrt(sum(f1$weights * f1$residuals^2) /
> 	f1$df.residual) sqrt(diag(vcov(f1))) / mse			# Adjust parameter SEs
> for weighting 
> 
> # Fixed effects model using 'lmer', OR scale, no explanatory
> variables f2 <- lmer(cbind(event,atrisk) ~ vaccine + (1 | study),
> 	data=BCG.long, family=binomial) summary(f2)
> 
> # Random effects model using 'lmer', OR scale, no explanatory
> variables f3 <- lmer(cbind(event,atrisk) ~ vaccine + (vaccine |
> 	study), data=BCG.long, family=binomial) summary(f3)
> 
> ---------------
> 
> What I would like to ask help for is:
> 1) How do I do write a weighted model like model 'f1' but using lmer
> so that I can fit a random effects model with covariates on RR scale?
> 
> 2) How do I correctly specify the random effects model 'f3' to
> incorporate the covariates 'Latitude' and 'Year' on the OR scale?
> 
> 
> I appreciate any time that any of you spare for this.
> 
> Brant Inman
> Chapel Hill, NC



From Thierry.ONKELINX at inbo.be  Mon Oct 27 10:51:17 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 27 Oct 2008 10:51:17 +0100
Subject: [R-sig-ME] Something broken in lme4 after update?
Message-ID: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>

Dear Douglas,

After updating the R packages I get on error when loading lme4. Error in
inDL(x, as.logical(local), as.logical(now), ...) : function
'cholmod_start' not provided by package 'Matrix' Error:
package/namespace load failed for 'lme4'

You'll find more detail below. This was run in a fresh R session. I have
lme4 version 0.999375-27 installed.

Thierry

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs 


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rcond,
         rowMeans,
         rowSums 

Error in inDL(x, as.logical(local), as.logical(now), ...) : 
  function 'cholmod_start' not provided by package 'Matrix'
Error: package/namespace load failed for 'lme4'
> sessionInfo()
R version 2.8.0 (2008-10-20) 
i386-pc-mingw32 

locale:
LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Du
tch_Belgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices datasets  tcltk     utils     methods

[8] base     

other attached packages:
[1] Matrix_0.999375-17 lattice_0.17-15    svSocket_0.9-5     svIO_0.9-5

[5] R2HTML_1.59        svMisc_0.9-5       svIDE_0.9-5       

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Thierry.ONKELINX at inbo.be  Mon Oct 27 16:27:05 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 27 Oct 2008 16:27:05 +0100
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
Message-ID: <2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>

A little update. lme4_0.999375-27 works fine after installing
Matrix_0.999375-16 (CRAN) instead of Matrix_0.999375-17 (R-forge)

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens ONKELINX,
Thierry
Verzonden: maandag 27 oktober 2008 10:51
Aan: R-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Something broken in lme4 after update?

Dear Douglas,

After updating the R packages I get on error when loading lme4. Error in
inDL(x, as.logical(local), as.logical(now), ...) : function
'cholmod_start' not provided by package 'Matrix' Error:
package/namespace load failed for 'lme4'

You'll find more detail below. This was run in a fresh R session. I have
lme4 version 0.999375-27 installed.

Thierry

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs 


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rcond,
         rowMeans,
         rowSums 

Error in inDL(x, as.logical(local), as.logical(now), ...) :
  function 'cholmod_start' not provided by package 'Matrix'
Error: package/namespace load failed for 'lme4'
> sessionInfo()
R version 2.8.0 (2008-10-20) 
i386-pc-mingw32 

locale:
LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Du
tch_Belgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices datasets  tcltk     utils     methods

[8] base     

other attached packages:
[1] Matrix_0.999375-17 lattice_0.17-15    svSocket_0.9-5     svIO_0.9-5

[5] R2HTML_1.59        svMisc_0.9-5       svIDE_0.9-5       

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet
bevestigd is
door een geldig ondertekend document. The views expressed in  this
message 
and any annex are purely those of the writer and may not be regarded as
stating 
an official position of INBO, as long as the message is not confirmed by
a duly 
signed document.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From brant.inman at me.com  Mon Oct 27 16:38:48 2008
From: brant.inman at me.com (Brant Inman)
Date: Mon, 27 Oct 2008 10:38:48 -0500
Subject: [R-sig-ME] Multilevel weighted regression
In-Reply-To: <329A68716B57D54E8D39FD3F8A4A84DF0EB93FE5@um-mail0136.unimaas.nl>
References: <329A68716B57D54E8D39FD3F8A4A84DF0EB93FE5@um-mail0136.unimaas.nl>
Message-ID: <55849902675084277988805004837140545504-Webmail2@me.com>

 Wolgang,

The mima function is indeed very useful for meta-regression and I thank you for kindly sharing it.  The problem is that the example I have to work with in real life has covariates both at the study level (Level 2) and the patient level (Level 1), and to my knowledge this is not a scenario that mima can handle.

My main interest with lmer and the BCG example is that I might be able to generalize it to the scenario where I have 2 different levels of covariates. However, prior to doing that, I need to figure out how to get lmer to work right with just one level of covariates.

Now we are two to wait for some guidance on lmer in the context of meta-analysis!

Brant


>Hi Brant,
>
>This is not a direct answer to your question, but something that still may be useful for you. Using the normal approximation to the log relative risk:
>
>yi    <- c(-0.89, -1.59, -1.35, -1.44, -0.22, -0.79, 
>           -1.62,  0.01, -0.47, -1.37, -0.34,  0.45, -0.02)
>vi    <- c(0.326, 0.195, 0.415, 0.020, 0.051, 0.007, 
>           0.223, 0.004, 0.056, 0.073, 0.012, 0.533, 0.071)
>ablat <- c(44, 55, 42, 52, 13, 44, 19, 13, 27, 42, 18, 33, 33)
>year  <- c(1948, 1949, 1960, 1977, 1973, 1953, 
>           1973, 1980, 1968, 1961, 1974, 1969, 1976)
>
>source("http://www.wvbauer.com/downloads/mima.ssc")
>
>mima(yi, vi, mods=cbind(ablat, year), method="REML")
>
>This is for the random-effects model. To get the same results as your model f1 (without having to go through the adjustment step for the SEs):
>
>mima(yi, vi, mods=cbind(ablat, year), fe="yes")
>
>There is a short tutorial about the function at: http://www.wvbauer.com/downloads.html
>
>I am curious as well to hear how lmer can be used in this context.
>
>Best,
>
>-- 
>Wolfgang Viechtbauer
> Department of Methodology and Statistics
> University of Maastricht, The Netherlands
> http://www.wvbauer.com/
>
>



From bates at stat.wisc.edu  Mon Oct 27 17:09:17 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Oct 2008 11:09:17 -0500
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
Message-ID: <40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>

On Mon, Oct 27, 2008 at 10:27 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> A little update. lme4_0.999375-27 works fine after installing
> Matrix_0.999375-16 (CRAN) instead of Matrix_0.999375-17 (R-forge)

The issue is a bit more subtle than that.  You need to reinstall the
lme4 package after changing the version of the Matrix package.
There is a change in the internal code in the Matrix package between
-16 and -17.  The -16 version requires two versions of every function
in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
back to only one version.  However, lme4 must be reinstalled (in
particular, the C code must be recompiled) after a change in the
Matrix package.



From shubhankar_ray at merck.com  Mon Oct 27 19:23:17 2008
From: shubhankar_ray at merck.com (Ray, Shubhankar)
Date: Mon, 27 Oct 2008 14:23:17 -0400
Subject: [R-sig-ME] matrix square root factorization in nlme
Message-ID: <4FB5A1689D998C40B6BE0E8A7D1C8AB201E3E8F0@usctmx1124.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081027/38cfb6b4/attachment.pl>

From shubhankar_ray at merck.com  Mon Oct 27 19:26:25 2008
From: shubhankar_ray at merck.com (Ray, Shubhankar)
Date: Mon, 27 Oct 2008 14:26:25 -0400
Subject: [R-sig-ME] matrix square root factorization in nlme
Message-ID: <4FB5A1689D998C40B6BE0E8A7D1C8AB201E3E8F1@usctmx1124.merck.com>


Hello Everyone,

I am curious about the type of factorization used by pdFactor() in nlme
to calculate the square root factor of a matrix. Square root factors are
also used in normalizing residuals in residuals.lme. 

I get different answers when I normalize the residuals by the following
principal sqrt matrix, calculated as:
E=eigen(C)  #Correlation Matrix C
SqrtC=E$vector%*%sqrt(diag(E$values))%*%t(E$vector);

It will be great if you could describe the factorization.

Thanks in advance,
Shubhankar



Shubhankar Ray, Ph.D.
Biometrics Research
Merck & Company
P.O. Box 2000
Rahway, NJ 07065


Notice:  This e-mail message, together with any attachme...{{dropped:12}}



From Thierry.ONKELINX at inbo.be  Tue Oct 28 11:12:52 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 28 Oct 2008 11:12:52 +0100
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>

Dear Douglas,

Reinstalling lme4 from R-forge after removing it from the harddisk
worked.

Thank you,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: dmbates at gmail.com [mailto:dmbates at gmail.com] Namens Douglas Bates
Verzonden: maandag 27 oktober 2008 17:09
Aan: ONKELINX, Thierry
CC: R-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Something broken in lme4 after update?

On Mon, Oct 27, 2008 at 10:27 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> A little update. lme4_0.999375-27 works fine after installing
> Matrix_0.999375-16 (CRAN) instead of Matrix_0.999375-17 (R-forge)

The issue is a bit more subtle than that.  You need to reinstall the
lme4 package after changing the version of the Matrix package.
There is a change in the internal code in the Matrix package between
-16 and -17.  The -16 version requires two versions of every function
in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
back to only one version.  However, lme4 must be reinstalled (in
particular, the C code must be recompiled) after a change in the
Matrix package.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From ken at kjbeath.com.au  Tue Oct 28 12:11:22 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Tue, 28 Oct 2008 22:11:22 +1100
Subject: [R-sig-ME] fitting models with poisson distributed data
In-Reply-To: <49024E15.3040201@msu.edu>
References: <4901CF60.8000204@msu.edu> <4901ED26.7010807@zoology.ufl.edu>
	<490232F4.7020503@msu.edu> <49023C69.9060503@ufl.edu>
	<49024E15.3040201@msu.edu>
Message-ID: <CE042575-9869-4CCF-8B3D-CD082AB83FA0@kjbeath.com.au>

On 25/10/2008, at 9:37 AM, Page E. Van Meter wrote:

> Hi,
> Now that I have the code figured out, I hoping for some help on  
> defining my model. I might be guilty of trying to fit an overly  
> complex model to my data, although my model seems very simple in  
> comparison to what has been discussed here. I'm hoping for feedback  
> on my model design. Thanks in advance!
>
> I have some pretty ugly longitudinal data measuring hormones and  
> behaviors from individual hyenas over many years (355 samples from  
> 39 individuals). We collect hormone samples based on opportunity and  
> have several samples from each individual (3-9 samples per hyena).  
> My ultimate goal is to see if my hormone data explains any of the  
> variation we see in the behavior data (aggression, I'll call it  
> aggs). My dependent measurement is a behavior rate, count of aggs  
> over time just prior to hormone sample collection. It is very zero  
> heavy (lots of individuals did not aggress prior to hormone sample  
> donation) and resistant to transformation to normality, but seems to  
> be a pretty poisson distribution. My predictors are hormones and  
> reproductive state (pregnant or lactating, which effect both  
> aggression and hormones).
>

 From the output the estimated scale (I don't see this in the version  
of lmer I'm using?)  is 7.7 so data is definitely not Poisson.  
Assuming Poisson will give incorrect p values.

Seeing the quasi Poisson doesn't seem to work properly I'm not certain  
what is a good choice. I haven't tried it but maybe quasi Poisson  
works in one of the GEE packages.

It may be Ok to limit the analysis to no aggression/aggression  
allowing fitting as binomial data.

Ken


> m2<-lmer(aggs~reprostate+hrm1+hrm2+(1|id), family=poisson, aggs)
>
> Generalized linear mixed model fit using Laplace
> Formula: aggs ~ reprostate + hrm1 + hrm2 + (1 | id)
>  Data: aggs
> Family: poisson(log link)
>  AIC   BIC logLik deviance
> 12369 12387  -6179    12359
> Random effects:
> Groups Name        Variance Std.Dev.
> id     (Intercept) 4.9353   2.2216 number of obs: 307, groups: id, 39
>
> Estimated scale (compare to  1 )  7.682887
>
> Fixed effects:
>           Estimate Std. Error z value Pr(>|z|)   (Intercept)  
> -3.07625    0.39575  -7.773 7.65e-15 ***
> reprostate 2.32056    0.07724  30.044  < 2e-16 ***
> hrm1        0.12575    0.04020   3.128  0.00176 **
> hrm2       -0.80434    0.04770 -16.862  < 2e-16 ***
> ---
>
> Correlation of Fixed Effects:
>        (Intr) statct ecent
> statecat -0.381             ecent    -0.085  0.271      acent      
> 0.136 -0.339 -0.079
>
> -- 
> ************************************
> Page E. Van Meter
> Michigan State University
> Department of Zoology
> vanmete7 at msu.edu
> **http://msu.edu/~vanmete7/*
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From vanmete7 at msu.edu  Tue Oct 28 13:20:37 2008
From: vanmete7 at msu.edu (Page E. Van Meter)
Date: Tue, 28 Oct 2008 08:20:37 -0400
Subject: [R-sig-ME] fitting models with poisson distributed data
In-Reply-To: <CE042575-9869-4CCF-8B3D-CD082AB83FA0@kjbeath.com.au>
References: <4901CF60.8000204@msu.edu> <4901ED26.7010807@zoology.ufl.edu>
	<490232F4.7020503@msu.edu> <49023C69.9060503@ufl.edu>
	<49024E15.3040201@msu.edu>
	<CE042575-9869-4CCF-8B3D-CD082AB83FA0@kjbeath.com.au>
Message-ID: <49070395.2040908@msu.edu>

Thanks, Ken. I am coming to a similar conclusion. My data is very zero 
inflated and I have considered using negative binomial, which also does 
not seem to work with lmer.
I will try working on both quasipoisson and a binomial version of my 
data. Thanks,
-Page

Ken Beath wrote:
> On 25/10/2008, at 9:37 AM, Page E. Van Meter wrote:
>
>> Hi,
>> Now that I have the code figured out, I hoping for some help on 
>> defining my model. I might be guilty of trying to fit an overly 
>> complex model to my data, although my model seems very simple in 
>> comparison to what has been discussed here. I'm hoping for feedback 
>> on my model design. Thanks in advance!
>>
>> I have some pretty ugly longitudinal data measuring hormones and 
>> behaviors from individual hyenas over many years (355 samples from 39 
>> individuals). We collect hormone samples based on opportunity and 
>> have several samples from each individual (3-9 samples per hyena). My 
>> ultimate goal is to see if my hormone data explains any of the 
>> variation we see in the behavior data (aggression, I'll call it 
>> aggs). My dependent measurement is a behavior rate, count of aggs 
>> over time just prior to hormone sample collection. It is very zero 
>> heavy (lots of individuals did not aggress prior to hormone sample 
>> donation) and resistant to transformation to normality, but seems to 
>> be a pretty poisson distribution. My predictors are hormones and 
>> reproductive state (pregnant or lactating, which effect both 
>> aggression and hormones).
>>
>
> From the output the estimated scale (I don't see this in the version 
> of lmer I'm using?)  is 7.7 so data is definitely not Poisson. 
> Assuming Poisson will give incorrect p values.
>
> Seeing the quasi Poisson doesn't seem to work properly I'm not certain 
> what is a good choice. I haven't tried it but maybe quasi Poisson 
> works in one of the GEE packages.
>
> It may be Ok to limit the analysis to no aggression/aggression 
> allowing fitting as binomial data.
>
> Ken
>
>
>> m2<-lmer(aggs~reprostate+hrm1+hrm2+(1|id), family=poisson, aggs)
>>
>> Generalized linear mixed model fit using Laplace
>> Formula: aggs ~ reprostate + hrm1 + hrm2 + (1 | id)
>>  Data: aggs
>> Family: poisson(log link)
>>  AIC   BIC logLik deviance
>> 12369 12387  -6179    12359
>> Random effects:
>> Groups Name        Variance Std.Dev.
>> id     (Intercept) 4.9353   2.2216 number of obs: 307, groups: id, 39
>>
>> Estimated scale (compare to  1 )  7.682887
>>
>> Fixed effects:
>>           Estimate Std. Error z value Pr(>|z|)   (Intercept) 
>> -3.07625    0.39575  -7.773 7.65e-15 ***
>> reprostate 2.32056    0.07724  30.044  < 2e-16 ***
>> hrm1        0.12575    0.04020   3.128  0.00176 **
>> hrm2       -0.80434    0.04770 -16.862  < 2e-16 ***
>> ---
>>
>> Correlation of Fixed Effects:
>>        (Intr) statct ecent
>> statecat -0.381             ecent    -0.085  0.271      acent     
>> 0.136 -0.339 -0.079
>>
>> -- 
>> ************************************
>> Page E. Van Meter
>> Michigan State University
>> Department of Zoology
>> vanmete7 at msu.edu
>> **http://msu.edu/~vanmete7/*
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

-- 
************************************
Page E. Van Meter
Michigan State University
Department of Zoology
vanmete7 at msu.edu
**http://msu.edu/~vanmete7/*



From vanmete7 at msu.edu  Thu Oct 30 00:11:06 2008
From: vanmete7 at msu.edu (Page E. Van Meter)
Date: Wed, 29 Oct 2008 19:11:06 -0400
Subject: [R-sig-ME] The simple burning questions about lmer and their answers
Message-ID: <4908ED8A.40001@msu.edu>

Hello all,
I have been teaching myself how to use generalized linear mixed effect 
models in R. While I find that the message boards like this one are 
extremely helpful, they have a "time travel" issue. I am finding answers 
to my burning questions that are years old and I am having trouble 
determining if the issues raised in 2006 are still issues today. So I 
wanted to put all of the hot topics I have been reading about, and the 
overly simplified answers I have gleaned in one thread. I hope others 
may add their burning questions and the answers they use to this thread 
as well?? And always the hope for comments:

Q1: Should I use ML or REML to compare the fixed effects in a set of 
nested models using likelihood-ratio testing (LRT)?
A1: It is much better to use ML to compare fixed effects in your model.

Q2: Should I use ML or REML to compare the random effects in a set of 
nested models using likelihood-ratio testing (LRT)?
A2: To test the worth of random effects in your model, REML is better. 
HOWEVER, if using lmer with a family specification to call glmer (family 
= binomial or poisson) you are automatically using ML. REML is not an 
option for generalized linear mixed effect models using lmer.

Q3: Ok, so how do I asses the value of random effects in my generalized 
linear mixed effect model?
A3: <insert cricket sounds here>
I gather that your experimental design should be the major indicator 
that a random term is needed in your model specification. But sometimes 
showing that the random effect is valuable (perhaps in a case where none 
of your fixed effects are worth anything) is, in itself, an interesting 
result.  Help?

Q4: So what is the hoopla about p-values for fixed effects in lmer?
A4: Short answer is that p-values are now included in the current 
incarnation of lme4 (can't find documentation of this but I see them so 
they must be there right?). The long answer about why you should be 
hesitant to use them and more hesitant to NEED them was provided by Doug 
here :
http://www.nabble.com/lmer%2C-p-values-and-all-that-p4476689.html



************************************
Page E. Van Meter
Michigan State University
Department of Zoology
vanmete7 at msu.edu
**http://msu.edu/~vanmete7/*



From bates at stat.wisc.edu  Tue Nov  4 21:21:03 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 4 Nov 2008 14:21:03 -0600
Subject: [R-sig-ME] [R] Extract Residual Variance from lmer using VarCorr
In-Reply-To: <20081104141453.153653v9stbzq2o0@web.mail.umich.edu>
References: <20081104141453.153653v9stbzq2o0@web.mail.umich.edu>
Message-ID: <40e66e0b0811041221v759c0578m1b46939a8a91ba3@mail.gmail.com>

It is important when discussing the behavior of lmer and other
functions in the lme4 package to state the version of the package that
you are using.  The package changes as I experiment with the
computational methods.

Using version 0.999375-27 of the lme4 package you can see the following

> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> str(VarCorr(fm1))
List of 1
 $ Subject: num [1:2, 1:2] 612.1 9.6 9.6 35.1
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:2] "(Intercept)" "Days"
  .. ..$ : chr [1:2] "(Intercept)" "Days"
  ..- attr(*, "stddev")= Named num [1:2] 24.74 5.92
  .. ..- attr(*, "names")= chr [1:2] "(Intercept)" "Days"
  ..- attr(*, "correlation")= num [1:2, 1:2] 1 0.0655 0.0655 1
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "(Intercept)" "Days"
  .. .. ..$ : chr [1:2] "(Intercept)" "Days"
 - attr(*, "sc")= Named num 25.6
  ..- attr(*, "names")= chr "sigmaREML"

so the value that you want for the residual standard deviation is

attr(VarCorr(fm1), "sc")

An alternative is to examine

> fm1 at deviance
          ML         REML         ldL2        ldRX2      sigmaML    sigmaREML
1.751986e+03 1.743628e+03 7.595997e+01 8.276128e+00 2.544924e+01 2.559182e+01
       pwrss         disc         usqr         wrss          dev         llik
1.165795e+05 9.888088e+04 1.769928e+04 9.888024e+04           NA           NA
     NULLdev
          NA

and notice that there are two elements called "sigmaML" and "sigmaREML".

Both these methods are sub-optimal in that they rely on a particular
version of the fitted model object.  I wrote an extractor named
"sigma" to obtain the estimate of the standard deviation but did not
export it because I am not convinced that this is a good name for such
an extractor.  Suggestions for the name of an extractor (or comments
that I have missed the obvious generic function) and what it should
return are welcome.

I have cc:'d the R-SIG-Mixed-Models mailing list as it is the more
likely list for help on such questions.


On Tue, Nov 4, 2008 at 1:14 PM, Benjamin Michael Kelcey
<bkelcey at umich.edu> wrote:
>
> I am trying to extract the residual variance from an lmer object. I have
> tried using VarCorr() which allows me to see the estimate but can not save
> it by itself.
>
> How can I get this from VarCorr() or is there another function available for
> this?
> Thanks,
> ben
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From melissayen at gmail.com  Thu Nov  6 17:19:48 2008
From: melissayen at gmail.com (Miao-Hsuan Yen)
Date: Fri, 7 Nov 2008 00:19:48 +0800
Subject: [R-sig-ME] algorithm did not converge when running general linear
	mixed mode (logistic)
Message-ID: <86f8e5070811060819p23b16890k2bafc21fd23fe453@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081107/05c5b1be/attachment.pl>

From bates at stat.wisc.edu  Thu Nov  6 20:15:32 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Nov 2008 13:15:32 -0600
Subject: [R-sig-ME] algorithm did not converge when running general
	linear mixed mode (logistic)
In-Reply-To: <86f8e5070811060819p23b16890k2bafc21fd23fe453@mail.gmail.com>
References: <86f8e5070811060819p23b16890k2bafc21fd23fe453@mail.gmail.com>
Message-ID: <40e66e0b0811061115n1431f3dpd22aec2815d33b1d@mail.gmail.com>

On Thu, Nov 6, 2008 at 10:19 AM, Miao-Hsuan Yen <melissayen at gmail.com> wrote:
> Dear mixed-list
>
> I am quite new with the lmer program.
> I have a data set with binary response (1, 0 and NA for missing trials).
>
> First, I'd like to make sure that it is correct to use the following command
> to analyze such data.
>
> model = lmer(resp ~ A + B + C + B:C + (1|sub) + (1|item), data = xxx, family
> = "binomial")
>
> Second, for some instances, I got the warning message:
> In glm.fit(fr$X, fr$Y, weights = wts, offset = offset, family = family,  :
>  algorithm did not converge

That is an indication that your fixed-effects terms may be
overspecified.  To obtain starting estimates for the fixed-effects
parameters a model without random effects is fit initially.  It is the
equivalent of

glm(resp ~ A + B + C + B:C, data = xxx, family = "binomial")

that is failing so you may want to check the fixed-effects specification.

> and I got extremely small z values and all Pr(>|z|)s = 1.
>
> Is there anything I can do to solve this problem?
>
> Thank you.
>
> Best,
> Melissa
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From marco at imada.sdu.dk  Fri Nov  7 18:51:31 2008
From: marco at imada.sdu.dk (Marco Chiarandini)
Date: Fri, 07 Nov 2008 18:51:31 +0100
Subject: [R-sig-ME] Variance components in generalized mixed models
Message-ID: <49148023.6040002@imada.sdu.dk>

Dear list,

I have some problems with lmer of lme4.

Using the latest version 0.999375-27 I receive as 
messages the following:

 > lmer(quality~ 
1+(1|instance),data=OONR,family=Gamma())
Error in mer_finalize(ans) :
   General form of glmer_linkinv not yet written
 > lmer(quality~ 
1+(1|instance),data=OONR,family=Gamma(link="log"))
Error in if (any(sd < 0)) return("'sd' slot has 
negative entries") :
   missing value where TRUE/FALSE needed


Before I was using the version 0.99875-9 and there 
my problems were the following:

1) Fitting a generalized mixed model with random 
effects having Gamma distribution, one obtains an 
estmate for the variance of the random effects as 
if it were a standard linear model (ie, with 
errors normally distributed). What is the exact 
meaning of this estimated variance? In other 
terms, to which parameter of the Gamma 
distribution it corresponds? (see examples below 
for code and results)

2) In lmer the approximation method "PQL" is said 
to be the default. Nevertheless running the 
examples that follows one obtains very different 
results. Why is this happening?

 > lmer(quality~ 
1+(1|instance),data=OONR,family=Gamma(link="log"),method="PQL")
Generalized linear mixed model fit using PQL
Formula: quality ~ 1 + (1 | instance)
    Data: OONR
  Family: Gamma(log link)
  AIC  BIC logLik deviance
   72 74.8    -34       68
Random effects:
  Groups   Name        Variance Std.Dev.
  instance (Intercept) 4.45e-01 0.66708
  Residual             2.68e-05 0.00518
number of obs: 30, groups: instance, 6

Fixed effects:
             Estimate Std. Error t value
(Intercept)    2.111      0.272    7.75
 > lmer(quality~ 
1+(1|instance),data=OONR,family=Gamma(link="log"))
Generalized linear mixed model fit using Laplace
Formula: quality ~ 1 + (1 | instance)
    Data: OONR
  Family: Gamma(log link)
   AIC  BIC logLik deviance
  14.7 17.5  -5.33     10.7
Random effects:
  Groups   Name        Variance Std.Dev.
  instance (Intercept) 0.0415   0.204
  Residual             0.2005   0.448
number of obs: 30, groups: instance, 6

Fixed effects:
             Estimate Std. Error t value
(Intercept)    2.166      0.117    18.6
 >

 > sessionInfo()
R version 2.7.0 (2008-04-22)
i486-pc-linux-gnu

locale:
C


The data OONR are available at:
http://www.imada.sdu.dk/~marco/Mixed/OONR.Rdata


Thank you in advance for any help you may provide.

Best regards,
Marco


-- 
Marco Chiarandini
Department of Mathematics and Computer Science,
University of Southern Denmark
Campusvej 55, DK-5230 Odense M, Denmark
marco at imada.sdu.dk,  http://www.imada.sdu.dk/~marco
Phone: +45 6550 4031,  Fax: +45 6550 2325



From bates at stat.wisc.edu  Sat Nov  8 21:56:39 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 8 Nov 2008 14:56:39 -0600
Subject: [R-sig-ME] [R] AIC value in lmer
In-Reply-To: <A54BCD9B13BDC64782C3F913CA24DD76CDF9FD@owadepot.bureautique.uqar.qc.ca>
References: <AclA+r/bUNwzuVg3RcG8YtSWCWsaDQ==>
	<A54BCD9B13BDC64782C3F913CA24DD76CDF9FD@owadepot.bureautique.uqar.qc.ca>
Message-ID: <40e66e0b0811081256l4fe9f23dre11b6df1c9ba3a1@mail.gmail.com>

On Fri, Nov 7, 2008 at 11:03 AM,  <ARNAUD_MOSNIER at uqar.qc.ca> wrote:
> Dear R Users,

> May be this message should be directy send to Douglas Bates ...
> I just want to know if I can use the AIC value given in the output of an lmer model to classify my logistic models.
> I heard that the AIC value given in GLIMMIX output (SAS) is false because it come from a calculation based on pseudo-likelyhood.
> Is it the same for lmer ???

I don't know about the situation with SAS.  The AIC value returned by
lmer is based on an approximation to the integral of the conditional
density of the random effects.  I had thought that I could evaluate
that conditional density from the sum of the deviance residuals for
the glm family but, given some recent discussion on the
R-SIG-Mixed-Models mailing list regarding the quasibinomial and
quasipoisson families, i am starting to doubt that.

So the quantity that is returned is based on something that is more
like the likelihood than is the pseudo-likelihood but may not be the
actual likelihood.

I do plan to change the value returned to be the likelihood for the
gaussian, binomial, poisson and Gamma families.  I don't know what to
do about the quasi families.  As far as I can see there isn't a
likelihood for those families because they don't represent a
probability distribution.

I am cc:ing the R-SIG-Mixed-Models mailing list on this reply.  I
suggest we move further discussion, if any, to that list.



From robert.espesser at lpl-aix.fr  Mon Nov 10 11:42:31 2008
From: robert.espesser at lpl-aix.fr (robert espesser)
Date: Mon, 10 Nov 2008 11:42:31 +0100
Subject: [R-sig-ME] opposite MCMC results with  two lmer versions
Message-ID: <49181017.5030905@lpl-aix.fr>

Dear R Users,

Looking for a teaching  example about the interest of mixed models,
I tried the "shoes data" from the "SMpracticals" package.
It's about the amount of wear in a paired comparison of two materials
used for soling the shoes of 10 boys.
The materials were allocated randomly to the left and right feet.
The dataframe is:	

 >shoe

    material boy foot    y
1         A   1    L 13.2
2         B   1    R 14.0
3         A   2    L  8.2
4         B   2    R  8.8
5         A   3    R 10.9
6         B   3    L 11.2
7         A   4    L 14.3
8         B   4    R 14.2
9         A   5    R 10.7
10        B   5    L 11.8
11        A   6    L  6.6
12        B   6    R  6.4
13        A   7    L  9.5
14        B   7    R  9.8
15        A   8    L 10.8
16        B   8    R 11.3
17        A   9    R  8.8
18        B   9    L  9.3
19        A  10    L 13.3
20        B  10    R 13.6

I obtained very different HPD intervals and pMCMC values according to 
these 2 sessionInfo :

############
A)   Last available versions of lme4 and languageR

 > sessionInfo()
R version 2.8.0 (2008-10-20)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] languageR_0.953    zipfR_0.6-0        lme4_0.999375-27 
Matrix_0.999375-16
[5] lattice_0.17-15

 > lmer(y ~ material +(1|boy),data=shoe) ->  mat.lmer
 > summary(mat.lmer)
Linear mixed model fit by REML
Formula: y ~ material + (1 | boy)
    Data: shoe
    AIC   BIC logLik deviance REMLdev
  62.94 66.92 -27.47    53.82   54.94
Random effects:
  Groups   Name        Variance Std.Dev.
  boy      (Intercept) 6.100889 2.47000
  Residual             0.074944 0.27376
Number of obs: 20, groups: boy, 10

Fixed effects:
             Estimate Std. Error t value
(Intercept)  10.6300     0.7858  13.527
materialB     0.4100     0.1224   3.349

 > pvals.fnc(mat.lmer)
$fixed
             Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    10.63  10.6379      9.126     12.175 0.0001   0.0000
materialB       0.41   0.4098     -1.593      2.345 0.6542   0.0036

$random
     Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1      boy (Intercept)   2.4700     0.8747   0.8570     0.0000     1.8015
2 Residual               0.2738     2.1350   2.1818     1.2191     3.1653

The MCMC results show materialB is here clearly unsignificant.


############
B)  Previous versions  of lme4 and languageR
same model & data, with :
R version 2.6.2 (2008-02-08)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] languageR_0.4     coda_0.13-1       lme4_0.99875-9    Matrix_0.999375-6
[5] zipfR_0.6-0       lattice_0.17-6

 > lmer(y ~ material +(1|boy),data=shoe) ->  mat_old.lmer
 > summary(mat_old.lmer)
Linear mixed-effects model fit by REML
Formula: y ~ material + (1 | boy)
    Data: shoe
    AIC   BIC logLik MLdeviance REMLdeviance
  60.94 63.92 -27.47      53.82        54.94
Random effects:
  Groups   Name        Variance Std.Dev.
  boy      (Intercept) 6.073101 2.46437
  Residual             0.075285 0.27438
number of obs: 20, groups: boy, 10

Fixed effects:
             Estimate Std. Error t value
(Intercept)  10.6300     0.7841  13.557
materialB     0.4100     0.1227   3.341

 > pvals.fnc(mat_old.lmer)
$fixed
             Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)    10.63  10.6182      8.818     12.357 0.0001   0.0000
materialB       0.41   0.4118      0.119      0.684 0.0102   0.0036

$random
          MCMCmean HPD95lower HPD95upper
sigma      0.2928     0.1829     0.4869
boy.(In)   2.5999     1.6610     4.3302

The MCMC results show  materialB is clearly significant


The both versions of  lme4 showed a similar LRT result between the
"null" model and the regular test :
 > anova(empty.lmer,mat.lmer)
Data: shoe
Models:
empty.lmer: y ~ 1 + (1 | boy)
mat.lmer: y ~ material + (1 | boy)
           Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
empty.lmer  3  67.937  70.924 -30.968
mat.lmer   4  61.817  65.800 -26.909 8.1197      1   0.004379 **

I know it's anti-conservative, but it's quite opposite to the
results of MCMC values of A).

The old classical paired t.test  method gave results similar to B)



So, which are the  results I can trust in ?
Thank you very much

Robert Espesser
Laboratoire Parole and Langage, CNRS UMR 6057
Universit? de Provence
Aix en Provence, France



From marc.moragues at gmail.com  Tue Nov 11 15:30:43 2008
From: marc.moragues at gmail.com (Marc Moragues Canela)
Date: Tue, 11 Nov 2008 14:30:43 +0000
Subject: [R-sig-ME] User defined variance-covariance matrix of random effects
Message-ID: <661eac670811110630h68891132l1b4f1d2e5f5bea48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081111/da53bebe/attachment.pl>

From rroa at udec.cl  Tue Nov 11 19:31:46 2008
From: rroa at udec.cl (=?ISO-8859-1?Q?Rub=E9n_Roa-Ureta?=)
Date: Tue, 11 Nov 2008 15:31:46 -0300
Subject: [R-sig-ME] New computational aproach to estimation of mixed models
Message-ID: <4919CF92.9020107@udec.cl>

comRades:

I haven't read the paper, but by reading the abstract it looks like 
there is an analytical way to estimate an approximation to the 
covariance structure of a glmm by first estimating the random effects as 
fixed effects in a conventional glm. Maybe something worth looking at to 
consider for lem4?

TI: Computationally feasible estimation of the covariance structure in generalized linear mixed models
AU: Alam, MD. Moudud; Carling, Kenneth
JN: Journal of Statistical Computation and Simulation
PD: 2008
VO: 78
NO: 12
PG: 1227-1237(11)
PB: Taylor &#38; Francis	
IS: 0094-9655
URL: http://www.ingentaconnect.com/content/tandf/gscs/2008/00000078/00000012/art00008 

Rub?n



From bates at stat.wisc.edu  Tue Nov 11 21:19:09 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 11 Nov 2008 14:19:09 -0600
Subject: [R-sig-ME] New computational aproach to estimation of mixed
	models
In-Reply-To: <4919CF92.9020107@udec.cl>
References: <4919CF92.9020107@udec.cl>
Message-ID: <40e66e0b0811111219x6da9a85dhb50e5461cecf0284@mail.gmail.com>

On Tue, Nov 11, 2008 at 12:31 PM, Rub?n Roa-Ureta <rroa at udec.cl> wrote:
> comRades:

> I haven't read the paper, but by reading the abstract it looks like there is
> an analytical way to estimate an approximation to the covariance structure
> of a glmm by first estimating the random effects as fixed effects in a
> conventional glm. Maybe something worth looking at to consider for lem4?

> TI: Computationally feasible estimation of the covariance structure in
> generalized linear mixed models
> AU: Alam, MD. Moudud; Carling, Kenneth
> JN: Journal of Statistical Computation and Simulation
> PD: 2008
> VO: 78
> NO: 12
> PG: 1227-1237(11)
> PB: Taylor &#38; Francis
> IS: 0094-9655
> URL:
> http://www.ingentaconnect.com/content/tandf/gscs/2008/00000078/00000012/art00008

I too haven't read the paper and it wouldn't be wise for me to make
too many comments without doing so.  The description in the abstract
reminds me of what were called "two-stage" methods for fitting
nonlinear mixed-effects models in pharmacokinetics a couple of decades
ago.  You fit the model to each cluster then try to estimate the
variance of the random effects from the within-cluster estimates.

There are several reasons why this doesn't always work well -
unbalanced clusters, small clusters that do not support individual
parameter estimates, models with crossed or partially crossed random
effects, models with random effects corresponding to a subset of the
fixed-effects parameters, etc.

I think the general approach of trying to reduce the parameter
estimation to subproblems and somehow sew the results from the
subproblems back together loses sight of an important characteristic
which is that we want the parameter estimates to optimize a criterion,
such as the log-likelihood.  Sometimes people get hung up on the
particular algorithm and want to compare, say PQL estimates to Laplace
approximation estimates to adaptive Gauss-Hermite quadrature
estimates, etc.  In the field of nonlinear mixed-effects models there
are even more acronyms and estimation methods.  To me this misses the
point. If you want maximum likelihood estimates you should agree on
how to evaluate the likelihood then compare estimates by comparing the
likelihoods.  How you get to the estimates is not as important as
whether the likelihood at the estimates is sufficiently close to the
optimal value.

The abstract for this paper claims that standard methods for
estimating the parameters in generalized linear mixed models are too
slow then proposes a method for a relatively simple estimation
situation (large cluster sizes and few random effects per cluster).  I
haven't really encountered slow estimation progress on such cases and
I do fit such models frequently.  We are routinely analyzing 50,000
binary responses with models that have thousands of clusters defining
the random effects and 10 to 15 fixed effects parameters.  It might
take 10 to 15 minutes to fit such a model but that doesn't alarm me.
The data cleaning takes much, much longer than that.

I am working on a modification of the current lme4 that will, I hope,
speed up parameter estimation for such models.  It involves folding
the fixed-effects parameter optimization into the penalized,
iteratively-reweighted least squares calculation.

There are a whole group of techniques for obtaining estimates



From David.Duffy at qimr.edu.au  Tue Nov 11 22:27:53 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 12 Nov 2008 07:27:53 +1000 (EST)
Subject: [R-sig-ME] User defined variance-covariance matrix of random
 effects
In-Reply-To: <661eac670811110630h68891132l1b4f1d2e5f5bea48@mail.gmail.com>
References: <661eac670811110630h68891132l1b4f1d2e5f5bea48@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0811120722370.426@orpheus.qimr.edu.au>

On Tue, 11 Nov 2008, Marc Moragues Canela wrote:

> Dear all,
>
> I am trying to build a mixed model to do association mapping of QTL.
> Basically I want to know if a marker is correlated with a trait. I know
> there are some packages that do this type of analysis like GenABEL, but I
> need more flexibility to modify the model to include, for example, the
> genotype by environment interaction.
>

You will have to use the kinship package, which uses lme.  It is 
pretty fast, unless you have very large pedigrees.  Doug Bates and 
others are still working on a lmer based equivalent.

David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Shin.Lin at uphs.upenn.edu  Wed Nov 12 03:31:25 2008
From: Shin.Lin at uphs.upenn.edu (Lin, Shin)
Date: Tue, 11 Nov 2008 21:31:25 -0500
Subject: [R-sig-ME] coding a certain model
Message-ID: <84D11048BB18234D8A56474645E8EC0210465B92@uphsmbx5.UPHS.PENNHEALTH.PRV>

Hello:
 
Does anyone know how to code the following?
 
As on page 162 of Mixed Effects Models in S and S-Plus by Pinheiro and Bates with the same b_i** and PSI** but with W_i = 
 
1 1 0 0                         1
1 0 1 0    Kronecker product    1 
1 1 1 1                         1
                                1 
 
The difference is in the last row of the 3x4 matrix. 
 
Granted, it's a weird model, but this situation actually mimics a biological scenario.  I'm guessing that the solution, if there is one, would be in the manipulation of the groupedData object (Oats in this case).
 
Thanks.
 
Shin    


The information contained in this e-mail message is intended only for the personal and confidential use of the recipient(s) named above. If the reader of this message is not the intended recipient or an agent responsible for delivering it to the intended recipient, you are hereby notified that you have received this document in error and that any review, dissemination, distribution, or copying of this message is strictly prohibited. If you have received this communication in error, please notify us immediately by e-mail, and delete the original message.



From matthew_wiener at merck.com  Thu Nov 13 15:29:16 2008
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Thu, 13 Nov 2008 09:29:16 -0500
Subject: [R-sig-ME] Variance-covariance matrix for normalized residuals in
	lme
Message-ID: <4E9A692D8755DF478B56A2892388EE1F0351933D@usctmx1118.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081113/771b1d7c/attachment.pl>

From kingsfordjones at gmail.com  Thu Nov 13 18:52:03 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Thu, 13 Nov 2008 10:52:03 -0700
Subject: [R-sig-ME] Variance-covariance matrix for normalized residuals
	in lme
In-Reply-To: <4E9A692D8755DF478B56A2892388EE1F0351933D@usctmx1118.merck.com>
References: <4E9A692D8755DF478B56A2892388EE1F0351933D@usctmx1118.merck.com>
Message-ID: <2ad0cc110811130952l50b037a6n393f136abf650111@mail.gmail.com>

On Thu, Nov 13, 2008 at 7:29 AM, Wiener, Matthew
<matthew_wiener at merck.com> wrote:
> All -
>
> We are fitting an lme model with several fixed effects, a single random
> effect, and an AR1 structure on the residuals.  To assess the model we
> examine the residuals.  The predicted vs. residual plots look fine using
> raw residuals or Pearson residuals (leaving aside serial correlations).
> However, the normalized residuals - which should account for the AR1
> structure - have a very strange feature.  For large predicted values,
> they show HUGE residuals - residuals an order of magnitude larger than
> the predicted values themselves.
>
> Working to figure out what was going on, we constructed the
> variance-covariance matrix of the residuals based on the parameter
> estimates, and calculated the normalization matrix independently.  When
> we multiplied that matrix by the vector of residuals, we ended up with
> normalized residuals that looked fine - there were no extremely large
> normalized residuals.
>
> We would like to compare our hand-computed variance-covariance matrix to
> the one used by lme, but we have not been able to figure out how to
> extract that matrix.  In lme4, we would use VarCorr, but in lme4, as far
> as we can tell, we can't have the AR1 correlation structure, which is
> very important in our problem.
>
> Is there some way to get at that matrix?

Does nlme::getVarCov return what you're looking for?

> And has anyone else had the
> normalized residuals blow up in this way?
>

I don't recall ever seeing this, but a guess is high leverage points
(e.g. some outlying large values in the column space of the X matrix).

hth,

Kingsford Jones


> Thanks,
>
> Matt Wiener, Shubhankar Ray, Vladimir Svetnik
> Notice:  This e-mail message, together with any attachme...{{dropped:15}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From s.chamaille at yahoo.fr  Fri Nov 14 10:50:14 2008
From: s.chamaille at yahoo.fr (=?iso-8859-1?Q?Simon_Chamaill=E9?=)
Date: Fri, 14 Nov 2008 09:50:14 +0000 (GMT)
Subject: [R-sig-ME] R implementation of Xu's r-square ?
Message-ID: <200592.98349.qm@web24307.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081114/7479259e/attachment.pl>

From nicebread at gmx.net  Tue Nov 18 18:02:17 2008
From: nicebread at gmx.net (=?ISO-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Tue, 18 Nov 2008 18:02:17 +0100
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
Message-ID: <0F7F4669-3546-42B6-867F-B551671B6DBE@gmx.net>

Hi all,

in my workgroup the HLM program by Raudenbush et al. is the de facto  
standard - however, I'd like to do my mixed models in R using the lme4  
package (as I do all other computations in R as well...)

Both as a practice and as an argument for my colleagues I tried to  
replicate (amongst others) the omnipresent "math-achievement-in- 
catholic-vs.-public schools"-example (using the original HLM-data set)  
in lme4.

My first question is: is my formula in lmer the right one?

--> HLM-style model ( Y = MATHACH; ID = grouping factor)

Level-1 Model

	Y = B0 + B1*(SES) + R

Level-2 Model
	B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
	B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1

Combined Model:
	
	Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +  
G12*(MEANSES)*(SES) + U0 + U1*(SES) + R

--> lmer-style:

	HSB.ML <- lmer(mathach ~ sector + meanses + ses + meanses*ses +  
sector*ses + (ses.gmc | id), data=HSB)



All models yield the same results concerning fixed effects; models  
including random slopes however show some minor divergence in the  
random effects variance (not very much, but it is there ...; see  
sample outputs below). In the presented example, the variance  
component is 0.10 (lme4) vs. 0.15 (HLM).
I am aware that these differences are really small - in this case the  
difference was only 0.1% of the residual variance.

Nonetheless I would really be happy if someone could shed some light  
on this issue, so that I can go to my colleagues and say: "We get  
slightly different results _because_ [...], BUT this is not a problem,  
_because_ ..."


 From my web and literature searches I have two guesses about these  
differences in both programs:

- a statement by Douglas Bates, that lme4 uses another estimation  
algorithm:
"[...] but may be of interest to some who are familiar with a  
generalized least squares (GLS) representation of mixed-models (such  
as used in MLWin and HLM). The lme4 package uses a penalized least  
squares (PLS) representation instead."
(http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS 
+page:1+mid:hb6p6mk6sztkvii2+state:results)

- HLM maybe does some Bayesian Estimation, what lme4 does not do (?)

But: these only are guesses from my side ... I'm not a statistician,  
but would like to understand it (a bit)

All best,
Felix


#-----------------------------------
# OUTPUT FROM HLM
# ------------------------------------

  Final estimation of fixed effects:
   
----------------------------------------------------------------------------
                                        Standard             Approx.
     Fixed Effect         Coefficient   Error      T-ratio   d.f.      
P-value
   
----------------------------------------------------------------------------
  For       INTRCPT1, B0
     INTRCPT2, G00          12.096006   0.198734    60.865        
157    0.000
       SECTOR, G01           1.226384   0.306271     4.004        
157    0.000
      MEANSES, G02           5.333056   0.369161    14.446        
157    0.000
  For      SES slope, B1
     INTRCPT2, G10           2.937980   0.157140    18.697        
157    0.000
       SECTOR, G11          -1.640951   0.242912    -6.755        
157    0.000
      MEANSES, G12           1.034418   0.302574     3.419        
157    0.001
   
----------------------------------------------------------------------------


  Final estimation of variance components:
   
-----------------------------------------------------------------------------
  Random Effect           Standard      Variance     df    Chi-square   
P-value
                          Deviation     Component
   
-----------------------------------------------------------------------------
  INTRCPT1,       U0        1.54271       2.37996   157      
605.29563    0.000
       SES slope, U1        0.38603       0.14902   157      
162.30883    0.369
   level-1,       R         6.05831      36.70309
   
-----------------------------------------------------------------------------



#-----------------------------------
# OUTPUT FROM LMER
#---------------------------------------

Linear mixed model fit by REML
Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc +  
sector *      ses.gmc + (ses.gmc | id)
    Data: HSB
    AIC   BIC logLik deviance REMLdev
  46524 46592 -23252    46496   46504

Random effects:
  Groups   Name        Variance Std.Dev. Corr
  id       (Intercept)  2.379   1.543
           ses.gmc      0.101   0.318    0.391
  Residual             36.721   6.060
Number of obs: 7185, groups: id, 160

Fixed effects:
                 Estimate Std. Error t value
(Intercept)     12.09600    0.19873  60.866
meanses          5.33291    0.36916  14.446
sector           1.22645    0.30627   4.005
ses.gmc          2.93877    0.15509  18.949
meanses:ses.gmc  1.03890    0.29889   3.476
sector:ses.gmc  -1.64261    0.23978  -6.850


___________________________________
Dipl. Psych. Felix Sch?nbrodt
Department of Psychology
Ludwig-Maximilian-Universit?t (LMU) Munich
Leopoldstr. 13
D-80802 M?nchen


From HDoran at air.org  Tue Nov 18 19:54:35 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 18 Nov 2008 13:54:35 -0500
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <0F7F4669-3546-42B6-867F-B551671B6DBE@gmx.net>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7D839@DC1EXCL01.air.org>

Felix

I think I can help a bit. I need to know what ses.gmc is. I have those data and have run the following model:

lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)

My output below shows the data (your and mine) have the same number of obs. But, the original data distributed with HLM does not have a variable called ses.gmc. The only variables in the data are:

> str(hsb)
'data.frame':   7185 obs. of  11 variables:
 $ id      : Factor w/ 160 levels "1224","1288",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ minority: num  0 0 0 0 0 0 0 0 0 0 ...
 $ female  : num  1 1 0 0 0 0 1 0 1 0 ...
 $ ses     : num  -1.528 -0.588 -0.528 -0.668 -0.158 ...
 $ mathach : num   5.88 19.71 20.35  8.78 17.90 ...
 $ size    : num  842 842 842 842 842 842 842 842 842 842 ...
 $ sector  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ pracad  : num  0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 ...
 $ disclim : num  1.60 1.60 1.60 1.60 1.60 ...
 $ himinty : num  0 0 0 0 0 0 0 0 0 0 ...
 $ meanses : num  -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 ...

Also you should report what version of lme4 you are using. Do a sessionInfo() and this will appear.

> lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
Linear mixed model fit by REML 
Formula: mathach ~ meanses * ses + sector * ses + (ses | id) 
   Data: hsb 
   AIC   BIC logLik deviance REMLdev
 46525 46594 -23253    46498   46505
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 id       (Intercept)  2.40744 1.55159        
          ses          0.01462 0.12091  1.000 
 Residual             36.75838 6.06287        
Number of obs: 7185, groups: id, 160

Fixed effects:
            Estimate Std. Error t value
(Intercept)  12.0948     0.2028   59.65
meanses       3.3202     0.3885    8.55
ses           2.9052     0.1483   19.59
sector        1.1949     0.3079    3.88
meanses:ses   0.8462     0.2718    3.11
ses:sector   -1.5781     0.2245   -7.03

Correlation of Fixed Effects:
            (Intr) meanss ses    sector mnss:s
meanses      0.213                            
ses          0.076 -0.146                     
sector      -0.676 -0.344 -0.064              
meanses:ses -0.143  0.178  0.278 -0.081       
ses:sector  -0.062 -0.080 -0.679  0.093 -0.356

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Felix Sch?nbrodt
> Sent: Tuesday, November 18, 2008 12:02 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in 
> estimation?
> 
> Hi all,
> 
> in my workgroup the HLM program by Raudenbush et al. is the 
> de facto standard - however, I'd like to do my mixed models 
> in R using the lme4 package (as I do all other computations 
> in R as well...)
> 
> Both as a practice and as an argument for my colleagues I 
> tried to replicate (amongst others) the omnipresent 
> "math-achievement-in- catholic-vs.-public schools"-example 
> (using the original HLM-data set) in lme4.
> 
> My first question is: is my formula in lmer the right one?
> 
> --> HLM-style model ( Y = MATHACH; ID = grouping factor)
> 
> Level-1 Model
> 
> 	Y = B0 + B1*(SES) + R
> 
> Level-2 Model
> 	B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
> 	B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1
> 
> Combined Model:
> 	
> 	Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +
> G12*(MEANSES)*(SES) + U0 + U1*(SES) + R
> 
> --> lmer-style:
> 
> 	HSB.ML <- lmer(mathach ~ sector + meanses + ses + 
> meanses*ses + sector*ses + (ses.gmc | id), data=HSB)
> 
> 
> 
> All models yield the same results concerning fixed effects; 
> models including random slopes however show some minor 
> divergence in the random effects variance (not very much, but 
> it is there ...; see sample outputs below). In the presented 
> example, the variance component is 0.10 (lme4) vs. 0.15 (HLM).
> I am aware that these differences are really small - in this 
> case the difference was only 0.1% of the residual variance.
> 
> Nonetheless I would really be happy if someone could shed 
> some light on this issue, so that I can go to my colleagues 
> and say: "We get slightly different results _because_ [...], 
> BUT this is not a problem, _because_ ..."
> 
> 
>  From my web and literature searches I have two guesses about 
> these differences in both programs:
> 
> - a statement by Douglas Bates, that lme4 uses another estimation
> algorithm:
> "[...] but may be of interest to some who are familiar with a 
> generalized least squares (GLS) representation of 
> mixed-models (such as used in MLWin and HLM). The lme4 
> package uses a penalized least squares (PLS) representation instead."
> (http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS 
> +page:1+mid:hb6p6mk6sztkvii2+state:results)
> 
> - HLM maybe does some Bayesian Estimation, what lme4 does not do (?)
> 
> But: these only are guesses from my side ... I'm not a 
> statistician, but would like to understand it (a bit)
> 
> All best,
> Felix
> 
> 
> #-----------------------------------
> # OUTPUT FROM HLM
> # ------------------------------------
> 
>   Final estimation of fixed effects:
>    
> --------------------------------------------------------------
> --------------
>                                         Standard             Approx.
>      Fixed Effect         Coefficient   Error      T-ratio   
> d.f.      
> P-value
>    
> --------------------------------------------------------------
> --------------
>   For       INTRCPT1, B0
>      INTRCPT2, G00          12.096006   0.198734    60.865        
> 157    0.000
>        SECTOR, G01           1.226384   0.306271     4.004        
> 157    0.000
>       MEANSES, G02           5.333056   0.369161    14.446        
> 157    0.000
>   For      SES slope, B1
>      INTRCPT2, G10           2.937980   0.157140    18.697        
> 157    0.000
>        SECTOR, G11          -1.640951   0.242912    -6.755        
> 157    0.000
>       MEANSES, G12           1.034418   0.302574     3.419        
> 157    0.001
>    
> --------------------------------------------------------------
> --------------
> 
> 
>   Final estimation of variance components:
>    
> --------------------------------------------------------------
> ---------------
>   Random Effect           Standard      Variance     df    
> Chi-square   
> P-value
>                           Deviation     Component
>    
> --------------------------------------------------------------
> ---------------
>   INTRCPT1,       U0        1.54271       2.37996   157      
> 605.29563    0.000
>        SES slope, U1        0.38603       0.14902   157      
> 162.30883    0.369
>    level-1,       R         6.05831      36.70309
>    
> --------------------------------------------------------------
> ---------------
> 
> 
> 
> #-----------------------------------
> # OUTPUT FROM LMER
> #---------------------------------------
> 
> Linear mixed model fit by REML
> Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc +  
> sector *      ses.gmc + (ses.gmc | id)
>     Data: HSB
>     AIC   BIC logLik deviance REMLdev
>   46524 46592 -23252    46496   46504
> 
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   id       (Intercept)  2.379   1.543
>            ses.gmc      0.101   0.318    0.391
>   Residual             36.721   6.060
> Number of obs: 7185, groups: id, 160
> 
> Fixed effects:
>                  Estimate Std. Error t value
> (Intercept)     12.09600    0.19873  60.866
> meanses          5.33291    0.36916  14.446
> sector           1.22645    0.30627   4.005
> ses.gmc          2.93877    0.15509  18.949
> meanses:ses.gmc  1.03890    0.29889   3.476
> sector:ses.gmc  -1.64261    0.23978  -6.850
> 
> 
> ___________________________________
> Dipl. Psych. Felix Sch?nbrodt
> Department of Psychology
> Ludwig-Maximilian-Universit?t (LMU) Munich Leopoldstr. 13
> D-80802 M?nchen
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From nicebread at gmx.net  Tue Nov 18 20:30:07 2008
From: nicebread at gmx.net (=?ISO-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Tue, 18 Nov 2008 20:30:07 +0100
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE01A7D839@DC1EXCL01.air.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE01A7D839@DC1EXCL01.air.org>
Message-ID: <80E93977-7C3B-42D7-B61B-844B1132039B@gmx.net>

Thanks for your fast reply,

your right, I missed that in my explanation: Raudenbush et al. enter  
the socioeconomic status (ses) group centered into their model.
Therefore I calculated that group centered variable and called it  
ses.gmc (gmc = group mean centered; [I just recognize that this notion  
is ambiguous to "grand mean centered...])

# group-centering of ses (as R&B do ...)
# ses.gm = group mean
# ses.gmc = ses [group mean centered]

gMeans <- aggregate(HSB$ses, list(HSB$id), mean)
names(gMeans) <- c("id", "ses.gm")
HSB <- merge(HSB, gMeans, by="id")
HSB$ses.gmc <- HSB$ses - HSB$ses.gm

HSB.ML <- lmer(mathach ~ meanses + sector + ses.gmc + meanses*ses.gmc  
+ sector*ses.gmc + (ses.gmc|id), data=HSB)

I think despite that, we have the same dataset.
I used lme4_0.999375-27.

Felix




Am 18.11.2008 um 19:54 schrieb Doran, Harold:

> Felix
>
> I think I can help a bit. I need to know what ses.gmc is. I have  
> those data and have run the following model:
>
> lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
>
> My output below shows the data (your and mine) have the same number  
> of obs. But, the original data distributed with HLM does not have a  
> variable called ses.gmc. The only variables in the data are:
>
>> str(hsb)
> 'data.frame':   7185 obs. of  11 variables:
> $ id      : Factor w/ 160 levels "1224","1288",..: 1 1 1 1 1 1 1 1 1  
> 1 ...
> $ minority: num  0 0 0 0 0 0 0 0 0 0 ...
> $ female  : num  1 1 0 0 0 0 1 0 1 0 ...
> $ ses     : num  -1.528 -0.588 -0.528 -0.668 -0.158 ...
> $ mathach : num   5.88 19.71 20.35  8.78 17.90 ...
> $ size    : num  842 842 842 842 842 842 842 842 842 842 ...
> $ sector  : num  0 0 0 0 0 0 0 0 0 0 ...
> $ pracad  : num  0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 ...
> $ disclim : num  1.60 1.60 1.60 1.60 1.60 ...
> $ himinty : num  0 0 0 0 0 0 0 0 0 0 ...
> $ meanses : num  -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428  
> -0.428 -0.428 -0.428 ...
>
> Also you should report what version of lme4 you are using. Do a  
> sessionInfo() and this will appear.
>
>> lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
> Linear mixed model fit by REML
> Formula: mathach ~ meanses * ses + sector * ses + (ses | id)
>   Data: hsb
>   AIC   BIC logLik deviance REMLdev
> 46525 46594 -23253    46498   46505
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
> id       (Intercept)  2.40744 1.55159
>          ses          0.01462 0.12091  1.000
> Residual             36.75838 6.06287
> Number of obs: 7185, groups: id, 160
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  12.0948     0.2028   59.65
> meanses       3.3202     0.3885    8.55
> ses           2.9052     0.1483   19.59
> sector        1.1949     0.3079    3.88
> meanses:ses   0.8462     0.2718    3.11
> ses:sector   -1.5781     0.2245   -7.03
>
> Correlation of Fixed Effects:
>            (Intr) meanss ses    sector mnss:s
> meanses      0.213
> ses          0.076 -0.146
> sector      -0.676 -0.344 -0.064
> meanses:ses -0.143  0.178  0.278 -0.081
> ses:sector  -0.062 -0.080 -0.679  0.093 -0.356
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>> Of Felix Sch?nbrodt
>> Sent: Tuesday, November 18, 2008 12:02 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in
>> estimation?
>>
>> Hi all,
>>
>> in my workgroup the HLM program by Raudenbush et al. is the
>> de facto standard - however, I'd like to do my mixed models
>> in R using the lme4 package (as I do all other computations
>> in R as well...)
>>
>> Both as a practice and as an argument for my colleagues I
>> tried to replicate (amongst others) the omnipresent
>> "math-achievement-in- catholic-vs.-public schools"-example
>> (using the original HLM-data set) in lme4.
>>
>> My first question is: is my formula in lmer the right one?
>>
>> --> HLM-style model ( Y = MATHACH; ID = grouping factor)
>>
>> Level-1 Model
>>
>> 	Y = B0 + B1*(SES) + R
>>
>> Level-2 Model
>> 	B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
>> 	B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1
>>
>> Combined Model:
>> 	
>> 	Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +
>> G12*(MEANSES)*(SES) + U0 + U1*(SES) + R
>>
>> --> lmer-style:
>>
>> 	HSB.ML <- lmer(mathach ~ sector + meanses + ses +
>> meanses*ses + sector*ses + (ses.gmc | id), data=HSB)
>>
>>
>>
>> All models yield the same results concerning fixed effects;
>> models including random slopes however show some minor
>> divergence in the random effects variance (not very much, but
>> it is there ...; see sample outputs below). In the presented
>> example, the variance component is 0.10 (lme4) vs. 0.15 (HLM).
>> I am aware that these differences are really small - in this
>> case the difference was only 0.1% of the residual variance.
>>
>> Nonetheless I would really be happy if someone could shed
>> some light on this issue, so that I can go to my colleagues
>> and say: "We get slightly different results _because_ [...],
>> BUT this is not a problem, _because_ ..."
>>
>>
>> From my web and literature searches I have two guesses about
>> these differences in both programs:
>>
>> - a statement by Douglas Bates, that lme4 uses another estimation
>> algorithm:
>> "[...] but may be of interest to some who are familiar with a
>> generalized least squares (GLS) representation of
>> mixed-models (such as used in MLWin and HLM). The lme4
>> package uses a penalized least squares (PLS) representation instead."
>> (http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS
>> +page:1+mid:hb6p6mk6sztkvii2+state:results)
>>
>> - HLM maybe does some Bayesian Estimation, what lme4 does not do (?)
>>
>> But: these only are guesses from my side ... I'm not a
>> statistician, but would like to understand it (a bit)
>>
>> All best,
>> Felix
>>
>>
>> #-----------------------------------
>> # OUTPUT FROM HLM
>> # ------------------------------------
>>
>>  Final estimation of fixed effects:
>>
>> --------------------------------------------------------------
>> --------------
>>                                        Standard             Approx.
>>     Fixed Effect         Coefficient   Error      T-ratio
>> d.f.
>> P-value
>>
>> --------------------------------------------------------------
>> --------------
>>  For       INTRCPT1, B0
>>     INTRCPT2, G00          12.096006   0.198734    60.865
>> 157    0.000
>>       SECTOR, G01           1.226384   0.306271     4.004
>> 157    0.000
>>      MEANSES, G02           5.333056   0.369161    14.446
>> 157    0.000
>>  For      SES slope, B1
>>     INTRCPT2, G10           2.937980   0.157140    18.697
>> 157    0.000
>>       SECTOR, G11          -1.640951   0.242912    -6.755
>> 157    0.000
>>      MEANSES, G12           1.034418   0.302574     3.419
>> 157    0.001
>>
>> --------------------------------------------------------------
>> --------------
>>
>>
>>  Final estimation of variance components:
>>
>> --------------------------------------------------------------
>> ---------------
>>  Random Effect           Standard      Variance     df
>> Chi-square
>> P-value
>>                          Deviation     Component
>>
>> --------------------------------------------------------------
>> ---------------
>>  INTRCPT1,       U0        1.54271       2.37996   157
>> 605.29563    0.000
>>       SES slope, U1        0.38603       0.14902   157
>> 162.30883    0.369
>>   level-1,       R         6.05831      36.70309
>>
>> --------------------------------------------------------------
>> ---------------
>>
>>
>>
>> #-----------------------------------
>> # OUTPUT FROM LMER
>> #---------------------------------------
>>
>> Linear mixed model fit by REML
>> Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc +
>> sector *      ses.gmc + (ses.gmc | id)
>>    Data: HSB
>>    AIC   BIC logLik deviance REMLdev
>>  46524 46592 -23252    46496   46504
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  id       (Intercept)  2.379   1.543
>>           ses.gmc      0.101   0.318    0.391
>>  Residual             36.721   6.060
>> Number of obs: 7185, groups: id, 160
>>
>> Fixed effects:
>>                 Estimate Std. Error t value
>> (Intercept)     12.09600    0.19873  60.866
>> meanses          5.33291    0.36916  14.446
>> sector           1.22645    0.30627   4.005
>> ses.gmc          2.93877    0.15509  18.949
>> meanses:ses.gmc  1.03890    0.29889   3.476
>> sector:ses.gmc  -1.64261    0.23978  -6.850
>>
>>
>> ___________________________________
>> Dipl. Psych. Felix Sch?nbrodt
>> Department of Psychology
>> Ludwig-Maximilian-Universit?t (LMU) Munich Leopoldstr. 13
>> D-80802 M?nchen
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From HDoran at air.org  Tue Nov 18 21:05:09 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 18 Nov 2008 15:05:09 -0500
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <80E93977-7C3B-42D7-B61B-844B1132039B@gmx.net>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7D84E@DC1EXCL01.air.org>

Felix:

First off, you haven't group mean centered. With that said, I don't know why people do this anyhow, but I can see that you are not using a group mean centered variable. 

Group mean centering means the SES variable for person i in school j would be the same for all i. But, in your variable, ses.gmc varies by student just as it does in the original variable ses. Your variable ses.gm is the group mean variable

In fact, what you would need for a group mean centered variable is:

hsb$ses.gmc <- ave(hsb$ses, hsb$id)

Which requires less work than your code, but gives the same result.

Now, the variable meanses in the HSB data is supposed to be the group mean centered variable. But, when you compare to my values using ave() you can see the meanses variable in the HSB data are wrong.

I suspect you are not using the same data between HLM and R and that may be the problem. That is, in R you create a variable called ses.gmc thinking this is a group mean centered variable. But, HLM "automagically" does group mean centering for you if you ask it to.

When you work in HLM are you using the exact same data file that you created for your use in R? Or, are you relying on HLM to group mean center for you? If so, I suspect that is the issue. In fact, we can see that the difference in your estimates lies in this variable and this is the variable you manipulate in R, so I suspect the error may no be a function of estimation differences, but of data differences.

With that said, I have found GLMM results between HLM and lmer to match exactly even though HLM uses a 6th order taylor series expansion and R uses a laplace approximation with a 2nd order taylor series. I have also found estimates from linear models to match exactly even though HLM uses a different method of estimation than lmer as well.

> -----Original Message-----
> From: Felix Sch?nbrodt [mailto:nicebread at gmx.net] 
> Sent: Tuesday, November 18, 2008 2:30 PM
> To: Doran, Harold
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme4 vs. HLM (program) - differences 
> in estimation?
> 
> Thanks for your fast reply,
> 
> your right, I missed that in my explanation: Raudenbush et 
> al. enter the socioeconomic status (ses) group centered into 
> their model.
> Therefore I calculated that group centered variable and 
> called it ses.gmc (gmc = group mean centered; [I just 
> recognize that this notion is ambiguous to "grand mean centered...])
> 
> # group-centering of ses (as R&B do ...) # ses.gm = group 
> mean # ses.gmc = ses [group mean centered]
> 
> gMeans <- aggregate(HSB$ses, list(HSB$id), mean)
> names(gMeans) <- c("id", "ses.gm")
> HSB <- merge(HSB, gMeans, by="id")
> HSB$ses.gmc <- HSB$ses - HSB$ses.gm
> 
> HSB.ML <- lmer(mathach ~ meanses + sector + ses.gmc + 
> meanses*ses.gmc  
> + sector*ses.gmc + (ses.gmc|id), data=HSB)
> 
> I think despite that, we have the same dataset.
> I used lme4_0.999375-27.
> 
> Felix
> 
> 
> 
> 
> Am 18.11.2008 um 19:54 schrieb Doran, Harold:
> 
> > Felix
> >
> > I think I can help a bit. I need to know what ses.gmc is. I 
> have those 
> > data and have run the following model:
> >
> > lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
> >
> > My output below shows the data (your and mine) have the 
> same number of 
> > obs. But, the original data distributed with HLM does not have a 
> > variable called ses.gmc. The only variables in the data are:
> >
> >> str(hsb)
> > 'data.frame':   7185 obs. of  11 variables:
> > $ id      : Factor w/ 160 levels "1224","1288",..: 1 1 1 1 
> 1 1 1 1 1  
> > 1 ...
> > $ minority: num  0 0 0 0 0 0 0 0 0 0 ...
> > $ female  : num  1 1 0 0 0 0 1 0 1 0 ...
> > $ ses     : num  -1.528 -0.588 -0.528 -0.668 -0.158 ...
> > $ mathach : num   5.88 19.71 20.35  8.78 17.90 ...
> > $ size    : num  842 842 842 842 842 842 842 842 842 842 ...
> > $ sector  : num  0 0 0 0 0 0 0 0 0 0 ...
> > $ pracad  : num  0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35 
> 0.35 0.35 ...
> > $ disclim : num  1.60 1.60 1.60 1.60 1.60 ...
> > $ himinty : num  0 0 0 0 0 0 0 0 0 0 ...
> > $ meanses : num  -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428
> > -0.428 -0.428 -0.428 ...
> >
> > Also you should report what version of lme4 you are using. Do a
> > sessionInfo() and this will appear.
> >
> >> lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
> > Linear mixed model fit by REML
> > Formula: mathach ~ meanses * ses + sector * ses + (ses | id)
> >   Data: hsb
> >   AIC   BIC logLik deviance REMLdev
> > 46525 46594 -23253    46498   46505
> > Random effects:
> > Groups   Name        Variance Std.Dev. Corr
> > id       (Intercept)  2.40744 1.55159
> >          ses          0.01462 0.12091  1.000
> > Residual             36.75838 6.06287
> > Number of obs: 7185, groups: id, 160
> >
> > Fixed effects:
> >            Estimate Std. Error t value
> > (Intercept)  12.0948     0.2028   59.65
> > meanses       3.3202     0.3885    8.55
> > ses           2.9052     0.1483   19.59
> > sector        1.1949     0.3079    3.88
> > meanses:ses   0.8462     0.2718    3.11
> > ses:sector   -1.5781     0.2245   -7.03
> >
> > Correlation of Fixed Effects:
> >            (Intr) meanss ses    sector mnss:s
> > meanses      0.213
> > ses          0.076 -0.146
> > sector      -0.676 -0.344 -0.064
> > meanses:ses -0.143  0.178  0.278 -0.081 ses:sector  -0.062 -0.080 
> > -0.679  0.093 -0.356
> >
> >> -----Original Message-----
> >> From: r-sig-mixed-models-bounces at r-project.org
> >> [mailto:r-sig-mixed-models-bounces at r-project.org] On 
> Behalf Of Felix 
> >> Sch?nbrodt
> >> Sent: Tuesday, November 18, 2008 12:02 PM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in 
> >> estimation?
> >>
> >> Hi all,
> >>
> >> in my workgroup the HLM program by Raudenbush et al. is 
> the de facto 
> >> standard - however, I'd like to do my mixed models in R using the 
> >> lme4 package (as I do all other computations in R as well...)
> >>
> >> Both as a practice and as an argument for my colleagues I tried to 
> >> replicate (amongst others) the omnipresent
> >> "math-achievement-in- catholic-vs.-public schools"-example 
> (using the 
> >> original HLM-data set) in lme4.
> >>
> >> My first question is: is my formula in lmer the right one?
> >>
> >> --> HLM-style model ( Y = MATHACH; ID = grouping factor)
> >>
> >> Level-1 Model
> >>
> >> 	Y = B0 + B1*(SES) + R
> >>
> >> Level-2 Model
> >> 	B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
> >> 	B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1
> >>
> >> Combined Model:
> >> 	
> >> 	Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +
> >> G12*(MEANSES)*(SES) + U0 + U1*(SES) + R
> >>
> >> --> lmer-style:
> >>
> >> 	HSB.ML <- lmer(mathach ~ sector + meanses + ses + meanses*ses + 
> >> sector*ses + (ses.gmc | id), data=HSB)
> >>
> >>
> >>
> >> All models yield the same results concerning fixed effects; models 
> >> including random slopes however show some minor divergence in the 
> >> random effects variance (not very much, but it is there ...; see 
> >> sample outputs below). In the presented example, the variance 
> >> component is 0.10 (lme4) vs. 0.15 (HLM).
> >> I am aware that these differences are really small - in 
> this case the 
> >> difference was only 0.1% of the residual variance.
> >>
> >> Nonetheless I would really be happy if someone could shed 
> some light 
> >> on this issue, so that I can go to my colleagues and say: "We get 
> >> slightly different results _because_ [...], BUT this is not a 
> >> problem, _because_ ..."
> >>
> >>
> >> From my web and literature searches I have two guesses about these 
> >> differences in both programs:
> >>
> >> - a statement by Douglas Bates, that lme4 uses another estimation
> >> algorithm:
> >> "[...] but may be of interest to some who are familiar with a 
> >> generalized least squares (GLS) representation of 
> mixed-models (such 
> >> as used in MLWin and HLM). The lme4 package uses a penalized least 
> >> squares (PLS) representation instead."
> >> (http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS
> >> +page:1+mid:hb6p6mk6sztkvii2+state:results)
> >>
> >> - HLM maybe does some Bayesian Estimation, what lme4 does 
> not do (?)
> >>
> >> But: these only are guesses from my side ... I'm not a 
> statistician, 
> >> but would like to understand it (a bit)
> >>
> >> All best,
> >> Felix
> >>
> >>
> >> #-----------------------------------
> >> # OUTPUT FROM HLM
> >> # ------------------------------------
> >>
> >>  Final estimation of fixed effects:
> >>
> >> --------------------------------------------------------------
> >> --------------
> >>                                        Standard             Approx.
> >>     Fixed Effect         Coefficient   Error      T-ratio
> >> d.f.
> >> P-value
> >>
> >> --------------------------------------------------------------
> >> --------------
> >>  For       INTRCPT1, B0
> >>     INTRCPT2, G00          12.096006   0.198734    60.865
> >> 157    0.000
> >>       SECTOR, G01           1.226384   0.306271     4.004
> >> 157    0.000
> >>      MEANSES, G02           5.333056   0.369161    14.446
> >> 157    0.000
> >>  For      SES slope, B1
> >>     INTRCPT2, G10           2.937980   0.157140    18.697
> >> 157    0.000
> >>       SECTOR, G11          -1.640951   0.242912    -6.755
> >> 157    0.000
> >>      MEANSES, G12           1.034418   0.302574     3.419
> >> 157    0.001
> >>
> >> --------------------------------------------------------------
> >> --------------
> >>
> >>
> >>  Final estimation of variance components:
> >>
> >> --------------------------------------------------------------
> >> ---------------
> >>  Random Effect           Standard      Variance     df
> >> Chi-square
> >> P-value
> >>                          Deviation     Component
> >>
> >> --------------------------------------------------------------
> >> ---------------
> >>  INTRCPT1,       U0        1.54271       2.37996   157
> >> 605.29563    0.000
> >>       SES slope, U1        0.38603       0.14902   157
> >> 162.30883    0.369
> >>   level-1,       R         6.05831      36.70309
> >>
> >> --------------------------------------------------------------
> >> ---------------
> >>
> >>
> >>
> >> #-----------------------------------
> >> # OUTPUT FROM LMER
> >> #---------------------------------------
> >>
> >> Linear mixed model fit by REML
> >> Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc +
> >> sector *      ses.gmc + (ses.gmc | id)
> >>    Data: HSB
> >>    AIC   BIC logLik deviance REMLdev
> >>  46524 46592 -23252    46496   46504
> >>
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  id       (Intercept)  2.379   1.543
> >>           ses.gmc      0.101   0.318    0.391
> >>  Residual             36.721   6.060
> >> Number of obs: 7185, groups: id, 160
> >>
> >> Fixed effects:
> >>                 Estimate Std. Error t value
> >> (Intercept)     12.09600    0.19873  60.866
> >> meanses          5.33291    0.36916  14.446
> >> sector           1.22645    0.30627   4.005
> >> ses.gmc          2.93877    0.15509  18.949
> >> meanses:ses.gmc  1.03890    0.29889   3.476
> >> sector:ses.gmc  -1.64261    0.23978  -6.850
> >>
> >>
> >> ___________________________________
> >> Dipl. Psych. Felix Sch?nbrodt
> >> Department of Psychology
> >> Ludwig-Maximilian-Universit?t (LMU) Munich Leopoldstr. 13
> >> D-80802 M?nchen
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> 
> 



From bates at stat.wisc.edu  Tue Nov 18 21:10:28 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Nov 2008 14:10:28 -0600
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <0F7F4669-3546-42B6-867F-B551671B6DBE@gmx.net>
References: <0F7F4669-3546-42B6-867F-B551671B6DBE@gmx.net>
Message-ID: <40e66e0b0811181210q39a33fbfk8c2be259e265f789@mail.gmail.com>

On Tue, Nov 18, 2008 at 11:02 AM, Felix Sch?nbrodt <nicebread at gmx.net> wrote:
> Hi all,
>
> in my workgroup the HLM program by Raudenbush et al. is the de facto
> standard - however, I'd like to do my mixed models in R using the lme4
> package (as I do all other computations in R as well...)
>
> Both as a practice and as an argument for my colleagues I tried to replicate
> (amongst others) the omnipresent "math-achievement-in-catholic-vs.-public
> schools"-example (using the original HLM-data set) in lme4.
>
> My first question is: is my formula in lmer the right one?
>
> --> HLM-style model ( Y = MATHACH; ID = grouping factor)
>
> Level-1 Model
>
>        Y = B0 + B1*(SES) + R
>
> Level-2 Model
>        B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
>        B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1
>
> Combined Model:
>
>        Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +
> G12*(MEANSES)*(SES) + U0 + U1*(SES) + R
>
> --> lmer-style:
>
>        HSB.ML <- lmer(mathach ~ sector + meanses + ses + meanses*ses +
> sector*ses + (ses.gmc | id), data=HSB)

That formula is not incorrect but it is a bit redundant.  In the R
formula notation the ':' operator creates an interaction and the '*'
operator is used to cross effects.  Thus meanses*ses expands to
meanses + ses + meanses:ses

> All models yield the same results concerning fixed effects; models including
> random slopes however show some minor divergence in the random effects
> variance (not very much, but it is there ...; see sample outputs below). In
> the presented example, the variance component is 0.10 (lme4) vs. 0.15 (HLM).
> I am aware that these differences are really small - in this case the
> difference was only 0.1% of the residual variance.

Does the HLM specification allow for correlation of the random effects
within ID group?  The lmer specification does.

> Nonetheless I would really be happy if someone could shed some light on this
> issue, so that I can go to my colleagues and say: "We get slightly different
> results _because_ [...], BUT this is not a problem, _because_ ..."
>
>
> From my web and literature searches I have two guesses about these
> differences in both programs:
>
> - a statement by Douglas Bates, that lme4 uses another estimation algorithm:
> "[...] but may be of interest to some who are familiar with a generalized
> least squares (GLS) representation of mixed-models (such as used in MLWin
> and HLM). The lme4 package uses a penalized least squares (PLS)
> representation instead."
> (http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS+page:1+mid:hb6p6mk6sztkvii2+state:results)

The criterion, either the log-likelihood for ML estimates or the REML
criterion for REML estimates, is defined as a property of the data and
the model.  The issue I was discussing there is how to evaluate the
log-likelihood or the REML criterion given the data, the model and
values of the parameters.  Solving a penalized least squares problem
or a generalized least squares problem is just a step in the
evaluation.  Both paths should give the same answer.  The reasons I
prefer the penalized least squares approach have to do with accuracy,
reliability and speed as well as generality of the approach.

I think it will be more important to check that the model
specifications are the same and that you are using the same criterion.
 The default criterion for lmer is REML.  I don't know what the
default criterion for HLM is.

> - HLM maybe does some Bayesian Estimation, what lme4 does not do (?)

I'm not sure what that would mean.  To a statistician "Bayesian
Estimation" would be associated with Bayesian representations of
models in which the parameters are regarded as random variables.  The
estimation criterion would change from the likelihood (or a related
criterion like the REML criterion) to maximizing the "posterior
density" of the parameters.  Because the posterior density depends on
the likelihood and on the prior density you must specify both the
probability model and prior densities to be able to define the
estimates.

At least that is the statistician's view of Bayesian estimation.  In
some fields, like machine learning, the adjective Bayesian is applied
to any algorithm that seems remotely related to a probability model.
For example, if you check how movie ratings are calculated at imdb.com
they use what they term is a Bayesian algorithm which, in their case,
means that they use a weighted average of the actual votes for the
movie and a typical vote so that a movie that is highly rated by very
few people doesn't suddenly become their number 1 rated movie of all
time.  Just saying it is Bayesian doesn't define the answer.  You need
to specify the probability model.

I would check two things: does HLM estimate two variances and a
covariance for the random effects and is it using the REML criterion
or the ML criterion.

>
> But: these only are guesses from my side ... I'm not a statistician, but
> would like to understand it (a bit)
>
> All best,
> Felix
>
>
> #-----------------------------------
> # OUTPUT FROM HLM
> # ------------------------------------
>
>  Final estimation of fixed effects:
>  ----------------------------------------------------------------------------
>                                       Standard             Approx.
>    Fixed Effect         Coefficient   Error      T-ratio   d.f.     P-value
>  ----------------------------------------------------------------------------
>  For       INTRCPT1, B0
>    INTRCPT2, G00          12.096006   0.198734    60.865       157    0.000
>      SECTOR, G01           1.226384   0.306271     4.004       157    0.000
>     MEANSES, G02           5.333056   0.369161    14.446       157    0.000
>  For      SES slope, B1
>    INTRCPT2, G10           2.937980   0.157140    18.697       157    0.000
>      SECTOR, G11          -1.640951   0.242912    -6.755       157    0.000
>     MEANSES, G12           1.034418   0.302574     3.419       157    0.001
>  ----------------------------------------------------------------------------
>
>
>  Final estimation of variance components:
>  -----------------------------------------------------------------------------
>  Random Effect           Standard      Variance     df    Chi-square
>  P-value
>                         Deviation     Component
>  -----------------------------------------------------------------------------
>  INTRCPT1,       U0        1.54271       2.37996   157     605.29563
>  0.000
>      SES slope, U1        0.38603       0.14902   157     162.30883    0.369
>  level-1,       R         6.05831      36.70309
>  -----------------------------------------------------------------------------
>
>
>
> #-----------------------------------
> # OUTPUT FROM LMER
> #---------------------------------------
>
> Linear mixed model fit by REML
> Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc + sector *
>      ses.gmc + (ses.gmc | id)
>   Data: HSB
>   AIC   BIC logLik deviance REMLdev
>  46524 46592 -23252    46496   46504
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  id       (Intercept)  2.379   1.543
>          ses.gmc      0.101   0.318    0.391
>  Residual             36.721   6.060
> Number of obs: 7185, groups: id, 160
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)     12.09600    0.19873  60.866
> meanses          5.33291    0.36916  14.446
> sector           1.22645    0.30627   4.005
> ses.gmc          2.93877    0.15509  18.949
> meanses:ses.gmc  1.03890    0.29889   3.476
> sector:ses.gmc  -1.64261    0.23978  -6.850
>
>
> ___________________________________
> Dipl. Psych. Felix Sch?nbrodt
> Department of Psychology
> Ludwig-Maximilian-Universit?t (LMU) Munich
> Leopoldstr. 13
> D-80802 M?nchen
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue Nov 18 21:23:59 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Nov 2008 14:23:59 -0600
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE01A7D84E@DC1EXCL01.air.org>
References: <80E93977-7C3B-42D7-B61B-844B1132039B@gmx.net>
	<ED7B522EE00C9A4FA515AA71724D61EE01A7D84E@DC1EXCL01.air.org>
Message-ID: <40e66e0b0811181223l46fba3a2t5f916b33a5a652da@mail.gmail.com>

On Tue, Nov 18, 2008 at 2:05 PM, Doran, Harold <HDoran at air.org> wrote:
> Felix:

> First off, you haven't group mean centered. With that said, I don't know why people do this anyhow, but I can see that you are not using a group mean centered variable.

> Group mean centering means the SES variable for person i in school j would be the same for all i. But, in your variable, ses.gmc varies by student just as it does in the original variable ses. Your variable ses.gm is the group mean variable

I'm not sure about that.  I believe that Felix is correct that the
"centered" part refers to the difference between the student's ses
score and some standard value and the "group mean centered" would
refer to using the observed mean ses for each group as the centering
value.  The variable ses.gmc would vary with person i in school j but
it would have the property that the values of ses.gmc summed across
all the students in school j would be zero.

Having said that, I would agree with you that there is more emphasis
on centering of variables in the HLM literature than I feel is
warranted.  Centering is related to parameterization and most of the
time changing parameters does not change the model.  One set of
parameters may be more convenient than another or provide a better
conditioned estimation situation but usually the model is not changed.

> In fact, what you would need for a group mean centered variable is:
>
> hsb$ses.gmc <- ave(hsb$ses, hsb$id)

> Which requires less work than your code, but gives the same result.

> Now, the variable meanses in the HSB data is supposed to be the group mean centered variable. But, when you compare to my values using ave() you can see the meanses variable in the HSB data are wrong.

I recall getting a result like that when I first looked at those data.
 I spent some time trying to reproduce the HLM results but eventually
gave up because of anomalies like this. The code for lmer is available
for anyone who wants to check exactly what is going on and the
evaluation of the log-likelihood and the REML criterion is described
in some detail - probably more detail than most people would want to
know - in one of the vignettes

> I suspect you are not using the same data between HLM and R and that may be the problem. That is, in R you create a variable called ses.gmc thinking this is a group mean centered variable. But, HLM "automagically" does group mean centering for you if you ask it to.
>
> When you work in HLM are you using the exact same data file that you created for your use in R? Or, are you relying on HLM to group mean center for you? If so, I suspect that is the issue. In fact, we can see that the difference in your estimates lies in this variable and this is the variable you manipulate in R, so I suspect the error may no be a function of estimation differences, but of data differences.
>
> With that said, I have found GLMM results between HLM and lmer to match exactly even though HLM uses a 6th order taylor series expansion and R uses a laplace approximation with a 2nd order taylor series. I have also found estimates from linear models to match exactly even though HLM uses a different method of estimation than lmer as well.
>
>> -----Original Message-----
>> From: Felix Sch?nbrodt [mailto:nicebread at gmx.net]
>> Sent: Tuesday, November 18, 2008 2:30 PM
>> To: Doran, Harold
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lme4 vs. HLM (program) - differences
>> in estimation?
>>
>> Thanks for your fast reply,
>>
>> your right, I missed that in my explanation: Raudenbush et
>> al. enter the socioeconomic status (ses) group centered into
>> their model.
>> Therefore I calculated that group centered variable and
>> called it ses.gmc (gmc = group mean centered; [I just
>> recognize that this notion is ambiguous to "grand mean centered...])
>>
>> # group-centering of ses (as R&B do ...) # ses.gm = group
>> mean # ses.gmc = ses [group mean centered]
>>
>> gMeans <- aggregate(HSB$ses, list(HSB$id), mean)
>> names(gMeans) <- c("id", "ses.gm")
>> HSB <- merge(HSB, gMeans, by="id")
>> HSB$ses.gmc <- HSB$ses - HSB$ses.gm
>>
>> HSB.ML <- lmer(mathach ~ meanses + sector + ses.gmc +
>> meanses*ses.gmc
>> + sector*ses.gmc + (ses.gmc|id), data=HSB)
>>
>> I think despite that, we have the same dataset.
>> I used lme4_0.999375-27.
>>
>> Felix
>>
>>
>>
>>
>> Am 18.11.2008 um 19:54 schrieb Doran, Harold:
>>
>> > Felix
>> >
>> > I think I can help a bit. I need to know what ses.gmc is. I
>> have those
>> > data and have run the following model:
>> >
>> > lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
>> >
>> > My output below shows the data (your and mine) have the
>> same number of
>> > obs. But, the original data distributed with HLM does not have a
>> > variable called ses.gmc. The only variables in the data are:
>> >
>> >> str(hsb)
>> > 'data.frame':   7185 obs. of  11 variables:
>> > $ id      : Factor w/ 160 levels "1224","1288",..: 1 1 1 1
>> 1 1 1 1 1
>> > 1 ...
>> > $ minority: num  0 0 0 0 0 0 0 0 0 0 ...
>> > $ female  : num  1 1 0 0 0 0 1 0 1 0 ...
>> > $ ses     : num  -1.528 -0.588 -0.528 -0.668 -0.158 ...
>> > $ mathach : num   5.88 19.71 20.35  8.78 17.90 ...
>> > $ size    : num  842 842 842 842 842 842 842 842 842 842 ...
>> > $ sector  : num  0 0 0 0 0 0 0 0 0 0 ...
>> > $ pracad  : num  0.35 0.35 0.35 0.35 0.35 0.35 0.35 0.35
>> 0.35 0.35 ...
>> > $ disclim : num  1.60 1.60 1.60 1.60 1.60 ...
>> > $ himinty : num  0 0 0 0 0 0 0 0 0 0 ...
>> > $ meanses : num  -0.428 -0.428 -0.428 -0.428 -0.428 -0.428 -0.428
>> > -0.428 -0.428 -0.428 ...
>> >
>> > Also you should report what version of lme4 you are using. Do a
>> > sessionInfo() and this will appear.
>> >
>> >> lmer(mathach ~ meanses * ses + sector * ses + (ses | id), hsb)
>> > Linear mixed model fit by REML
>> > Formula: mathach ~ meanses * ses + sector * ses + (ses | id)
>> >   Data: hsb
>> >   AIC   BIC logLik deviance REMLdev
>> > 46525 46594 -23253    46498   46505
>> > Random effects:
>> > Groups   Name        Variance Std.Dev. Corr
>> > id       (Intercept)  2.40744 1.55159
>> >          ses          0.01462 0.12091  1.000
>> > Residual             36.75838 6.06287
>> > Number of obs: 7185, groups: id, 160
>> >
>> > Fixed effects:
>> >            Estimate Std. Error t value
>> > (Intercept)  12.0948     0.2028   59.65
>> > meanses       3.3202     0.3885    8.55
>> > ses           2.9052     0.1483   19.59
>> > sector        1.1949     0.3079    3.88
>> > meanses:ses   0.8462     0.2718    3.11
>> > ses:sector   -1.5781     0.2245   -7.03
>> >
>> > Correlation of Fixed Effects:
>> >            (Intr) meanss ses    sector mnss:s
>> > meanses      0.213
>> > ses          0.076 -0.146
>> > sector      -0.676 -0.344 -0.064
>> > meanses:ses -0.143  0.178  0.278 -0.081 ses:sector  -0.062 -0.080
>> > -0.679  0.093 -0.356
>> >
>> >> -----Original Message-----
>> >> From: r-sig-mixed-models-bounces at r-project.org
>> >> [mailto:r-sig-mixed-models-bounces at r-project.org] On
>> Behalf Of Felix
>> >> Sch?nbrodt
>> >> Sent: Tuesday, November 18, 2008 12:02 PM
>> >> To: r-sig-mixed-models at r-project.org
>> >> Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in
>> >> estimation?
>> >>
>> >> Hi all,
>> >>
>> >> in my workgroup the HLM program by Raudenbush et al. is
>> the de facto
>> >> standard - however, I'd like to do my mixed models in R using the
>> >> lme4 package (as I do all other computations in R as well...)
>> >>
>> >> Both as a practice and as an argument for my colleagues I tried to
>> >> replicate (amongst others) the omnipresent
>> >> "math-achievement-in- catholic-vs.-public schools"-example
>> (using the
>> >> original HLM-data set) in lme4.
>> >>
>> >> My first question is: is my formula in lmer the right one?
>> >>
>> >> --> HLM-style model ( Y = MATHACH; ID = grouping factor)
>> >>
>> >> Level-1 Model
>> >>
>> >>    Y = B0 + B1*(SES) + R
>> >>
>> >> Level-2 Model
>> >>    B0 = G00 + G01*(SECTOR) + G02*(MEANSES) + U0
>> >>    B1 = G10 + G11*(SECTOR) + G12*(MEANSES) + U1
>> >>
>> >> Combined Model:
>> >>
>> >>    Y = G00 + G01*(SECTOR) + G02*(MEANSES) + G11*(SECTOR)*(SES) +
>> >> G12*(MEANSES)*(SES) + U0 + U1*(SES) + R
>> >>
>> >> --> lmer-style:
>> >>
>> >>    HSB.ML <- lmer(mathach ~ sector + meanses + ses + meanses*ses +
>> >> sector*ses + (ses.gmc | id), data=HSB)
>> >>
>> >>
>> >>
>> >> All models yield the same results concerning fixed effects; models
>> >> including random slopes however show some minor divergence in the
>> >> random effects variance (not very much, but it is there ...; see
>> >> sample outputs below). In the presented example, the variance
>> >> component is 0.10 (lme4) vs. 0.15 (HLM).
>> >> I am aware that these differences are really small - in
>> this case the
>> >> difference was only 0.1% of the residual variance.
>> >>
>> >> Nonetheless I would really be happy if someone could shed
>> some light
>> >> on this issue, so that I can go to my colleagues and say: "We get
>> >> slightly different results _because_ [...], BUT this is not a
>> >> problem, _because_ ..."
>> >>
>> >>
>> >> From my web and literature searches I have two guesses about these
>> >> differences in both programs:
>> >>
>> >> - a statement by Douglas Bates, that lme4 uses another estimation
>> >> algorithm:
>> >> "[...] but may be of interest to some who are familiar with a
>> >> generalized least squares (GLS) representation of
>> mixed-models (such
>> >> as used in MLWin and HLM). The lme4 package uses a penalized least
>> >> squares (PLS) representation instead."
>> >> (http://markmail.org/search/?q=lme4+PLS+GLS#query:lme4%20PLS%20GLS
>> >> +page:1+mid:hb6p6mk6sztkvii2+state:results)
>> >>
>> >> - HLM maybe does some Bayesian Estimation, what lme4 does
>> not do (?)
>> >>
>> >> But: these only are guesses from my side ... I'm not a
>> statistician,
>> >> but would like to understand it (a bit)
>> >>
>> >> All best,
>> >> Felix
>> >>
>> >>
>> >> #-----------------------------------
>> >> # OUTPUT FROM HLM
>> >> # ------------------------------------
>> >>
>> >>  Final estimation of fixed effects:
>> >>
>> >> --------------------------------------------------------------
>> >> --------------
>> >>                                        Standard             Approx.
>> >>     Fixed Effect         Coefficient   Error      T-ratio
>> >> d.f.
>> >> P-value
>> >>
>> >> --------------------------------------------------------------
>> >> --------------
>> >>  For       INTRCPT1, B0
>> >>     INTRCPT2, G00          12.096006   0.198734    60.865
>> >> 157    0.000
>> >>       SECTOR, G01           1.226384   0.306271     4.004
>> >> 157    0.000
>> >>      MEANSES, G02           5.333056   0.369161    14.446
>> >> 157    0.000
>> >>  For      SES slope, B1
>> >>     INTRCPT2, G10           2.937980   0.157140    18.697
>> >> 157    0.000
>> >>       SECTOR, G11          -1.640951   0.242912    -6.755
>> >> 157    0.000
>> >>      MEANSES, G12           1.034418   0.302574     3.419
>> >> 157    0.001
>> >>
>> >> --------------------------------------------------------------
>> >> --------------
>> >>
>> >>
>> >>  Final estimation of variance components:
>> >>
>> >> --------------------------------------------------------------
>> >> ---------------
>> >>  Random Effect           Standard      Variance     df
>> >> Chi-square
>> >> P-value
>> >>                          Deviation     Component
>> >>
>> >> --------------------------------------------------------------
>> >> ---------------
>> >>  INTRCPT1,       U0        1.54271       2.37996   157
>> >> 605.29563    0.000
>> >>       SES slope, U1        0.38603       0.14902   157
>> >> 162.30883    0.369
>> >>   level-1,       R         6.05831      36.70309
>> >>
>> >> --------------------------------------------------------------
>> >> ---------------
>> >>
>> >>
>> >>
>> >> #-----------------------------------
>> >> # OUTPUT FROM LMER
>> >> #---------------------------------------
>> >>
>> >> Linear mixed model fit by REML
>> >> Formula: mathach ~ meanses + sector + ses.gmc + meanses * ses.gmc +
>> >> sector *      ses.gmc + (ses.gmc | id)
>> >>    Data: HSB
>> >>    AIC   BIC logLik deviance REMLdev
>> >>  46524 46592 -23252    46496   46504
>> >>
>> >> Random effects:
>> >>  Groups   Name        Variance Std.Dev. Corr
>> >>  id       (Intercept)  2.379   1.543
>> >>           ses.gmc      0.101   0.318    0.391
>> >>  Residual             36.721   6.060
>> >> Number of obs: 7185, groups: id, 160
>> >>
>> >> Fixed effects:
>> >>                 Estimate Std. Error t value
>> >> (Intercept)     12.09600    0.19873  60.866
>> >> meanses          5.33291    0.36916  14.446
>> >> sector           1.22645    0.30627   4.005
>> >> ses.gmc          2.93877    0.15509  18.949
>> >> meanses:ses.gmc  1.03890    0.29889   3.476
>> >> sector:ses.gmc  -1.64261    0.23978  -6.850
>> >>
>> >>
>> >> ___________________________________
>> >> Dipl. Psych. Felix Sch?nbrodt
>> >> Department of Psychology
>> >> Ludwig-Maximilian-Universit?t (LMU) Munich Leopoldstr. 13
>> >> D-80802 M?nchen
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From HDoran at air.org  Tue Nov 18 21:39:23 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 18 Nov 2008 15:39:23 -0500
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <40e66e0b0811181223l46fba3a2t5f916b33a5a652da@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7D856@DC1EXCL01.air.org>

> I'm not sure about that.  I believe that Felix is correct 
> that the "centered" part refers to the difference between the 
> student's ses score and some standard value and the "group 
> mean centered" would refer to using the observed mean ses for 
> each group as the centering value.  The variable ses.gmc 
> would vary with person i in school j but it would have the 
> property that the values of ses.gmc summed across all the 
> students in school j would be zero.

You're right. I do this so rarely I had forgotten. I referred to my HLM
book and they note that a group mean centered variable is

x_{ij} - \bar{X_{.j}}

Where \bar{X_{.j}} is the mean of the variable x for individuals in
group j. Now, I still suspect a data difference. My suspicion is that
HLM is doing the group mean centering using the variable meanses, which
is not the same group mean variable as Felix computes in R, which is
done properly.



From nicebread at gmx.net  Tue Nov 18 22:51:34 2008
From: nicebread at gmx.net (=?ISO-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Tue, 18 Nov 2008 22:51:34 +0100
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <40e66e0b0811181223l46fba3a2t5f916b33a5a652da@mail.gmail.com>
References: <80E93977-7C3B-42D7-B61B-844B1132039B@gmx.net>
	<ED7B522EE00C9A4FA515AA71724D61EE01A7D84E@DC1EXCL01.air.org>
	<40e66e0b0811181223l46fba3a2t5f916b33a5a652da@mail.gmail.com>
Message-ID: <FEA4E668-81DE-4792-9F0B-B433C3D49D80@gmx.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081118/c4bbd969/attachment.pl>

From HDoran at air.org  Tue Nov 18 23:08:02 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 18 Nov 2008 17:08:02 -0500
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <FEA4E668-81DE-4792-9F0B-B433C3D49D80@gmx.net>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7D86E@DC1EXCL01.air.org>

Felix:
 
Just a thought. There is an implicit assumption in this thread that the lmer function is useful or correct because it lines up with HLM results. Now, I don't think looking to such comparisons is a bad idea, per se, especially when one is doing software development and maybe some unit testing is in order. Or, if one is very familiar with HLM and wants to learn to use lmer by comparing HLM output with the new results obtained under lmer.

However, I would offer caution that lmer isn't good because it aligns with HLM. In fact, the computational methods implemented for lmer far exceed the computational methods of almost all other programs designed for linear mixed effects (or generalized linear) models. 

Lmer also lives inside a very nice programming environment (R) that allows for you to manipulate data and run the model all in one place, so there are significant ease of use issues.

I don't think you are making this assumption necessarily. But, it may be useful for you to outline for your colleagues criteria for software evaluation and line HLM and lmer up next to each other based on these criteria. 

HLM is a useful program, but I would argue that the lmer function is much more capable of handling some complex issues.

Take care,
Harold


________________________________

	From: Felix Sch?nbrodt [mailto:nicebread at gmx.net] 
	Sent: Tuesday, November 18, 2008 4:52 PM
	To: Douglas Bates
	Cc: Doran, Harold; r-sig-mixed-models at r-project.org
	Subject: Re: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
	
	
	Thanks very much for your thorough remarks! 



			I suspect you are not using the same data between HLM and R and that may be the problem. That is, in R you create a variable called ses.gmc thinking this is a group mean centered variable. But, HLM "automagically" does group mean centering for you if you ask it to.
			


			When you work in HLM are you using the exact same data file that you created for your use in R? Or, are you relying on HLM to group mean center for you? If so, I suspect that is the issue. In fact, we can see that the difference in your estimates lies in this variable and this is the variable you manipulate in R, so I suspect the error may no be a function of estimation differences, but of data differences.

		
		


	I followed your suggestion about the possibly different centering approach in HLM and did a run only with raw variables (no centering). The small differences stay.


		I would check two things: does HLM estimate two variances and a
		covariance for the random effects and is it using the REML criterion
		or the ML criterion.


	HLM is using the REML criterion; concerning the variances for random effects I couldn't dig deep enough till now to answer this question ...

	From a lot of comparisons I have run now, I can conclude the following:
	- fixed effects usually are equal up to 3 digits after the decimal point
	- random variance components can show small deviations if they are very close to zero (and are not siginificant anyway - following the p-value reported by HLM, which is usually > 0.50 in these cases). However, I am aware of the discussion concerning the appropriateness of p-values reported by HLM (see also http://markmail.org/search/?q=lme4+p-value#query:lme4%20p-value+page:1+mid:3t4hxxrlh3uvb7kh+state:results).

	Maybe I was too nitpicking about these small differences - they only seem to appear in coefficients/ variance components that are insignificant anyway. But the discussion was definitely productive for me, and I think I now can convince my colleagues to use lme4 instead ;-)
	Maybe someoner wants to dig deeper into this issue; the data set from the HLM program (HS&B data) can be downloaded here for example: http://www.hlm-online.com/datasets/HSBDataset/HSBdata.zip.


	Thanks,
	Felix



From bates at stat.wisc.edu  Wed Nov 19 00:04:43 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Nov 2008 17:04:43 -0600
Subject: [R-sig-ME] lme4 vs. HLM (program) - differences in estimation?
In-Reply-To: <FEA4E668-81DE-4792-9F0B-B433C3D49D80@gmx.net>
References: <80E93977-7C3B-42D7-B61B-844B1132039B@gmx.net>
	<ED7B522EE00C9A4FA515AA71724D61EE01A7D84E@DC1EXCL01.air.org>
	<40e66e0b0811181223l46fba3a2t5f916b33a5a652da@mail.gmail.com>
	<FEA4E668-81DE-4792-9F0B-B433C3D49D80@gmx.net>
Message-ID: <40e66e0b0811181504k595381cfued806409abec4a4a@mail.gmail.com>

On Tue, Nov 18, 2008 at 3:51 PM, Felix Sch?nbrodt <nicebread at gmx.net> wrote:
> Thanks very much for your thorough remarks!
>
> I suspect you are not using the same data between HLM and R and that may be
> the problem. That is, in R you create a variable called ses.gmc thinking
> this is a group mean centered variable. But, HLM "automagically" does group
> mean centering for you if you ask it to.
>
> When you work in HLM are you using the exact same data file that you created
> for your use in R? Or, are you relying on HLM to group mean center for you?
> If so, I suspect that is the issue. In fact, we can see that the difference
> in your estimates lies in this variable and this is the variable you
> manipulate in R, so I suspect the error may no be a function of estimation
> differences, but of data differences.
>
> I followed your suggestion about the possibly different centering approach
> in HLM and did a run only with raw variables (no centering). The small
> differences stay.
>
> I would check two things: does HLM estimate two variances and a
> covariance for the random effects and is it using the REML criterion
> or the ML criterion.
>
> HLM is using the REML criterion; concerning the variances for random effects
> I couldn't dig deep enough till now to answer this question ...
> From a lot of comparisons I have run now, I can conclude the following:
> - fixed effects usually are equal up to 3 digits after the decimal point
> - random variance components can show small deviations if they are very
> close to zero (and are not siginificant anyway - following the p-value
> reported by HLM, which is usually > 0.50 in these cases). However, I am
> aware of the discussion concerning the appropriateness of p-values reported
> by HLM (see
> also http://markmail.org/search/?q=lme4+p-value#query:lme4%20p-value+page:1+mid:3t4hxxrlh3uvb7kh+state:results).

That's an interesting point about the biggest apparent differences
being in the small variance estimates.  It has been a while since I
looked at descriptions of the computational methods in HLM but I
believe that they work in terms of the precision of the random effects
(the inverse of the variance) instead of the variance.  In the way
that the model was typically expressed when that software was written
it is easier to work with the precision matrix than with the variance
matrix of the random effects.

When you look at the situation in more detail, however, you find that
it is possible to have estimates of zero for the variances of the
random effects whereas you cannot have an estimate of zero for the
precision, corresponding to infinite variance.  Optimizing the
log-likelihood with respect to the variance parameters (or, better,
the standard deviations) is more stable than optimizing with respect
to the precision.  The instability of optimizing with respect to the
precision parameters is most noticeable for small variance components
(large precision estimates).  It is particularly dramatic when the
variance goes to zero (precision to infinity).  Some of the many,
incompatible changes to the lme4 package - changes that have
inconvenienced many of its users whom I thank for their patience -
have been specifically for the purpose of stabilizing the estimation
situation for very small variance components.

The place where the choice of estimation algorithm matters the most is
in the estimation of small variance components so it doesn't surprise
me that differences crop up there.


> Maybe I was too nitpicking about these small differences - they only seem to
> appear in coefficients/ variance components that are insignificant anyway.
> But the discussion was definitely productive for me, and I think I now can
> convince my colleagues to use lme4 instead ;-)
> Maybe someoner wants to dig deeper into this issue; the data set from the
> HLM program (HS&B data) can be downloaded here for
> example: http://www.hlm-online.com/datasets/HSBDataset/HSBdata.zip.
>
> Thanks,
> Felix
>



From anne.dubois at inserm.fr  Thu Nov 20 15:52:46 2008
From: anne.dubois at inserm.fr (Anne Dubois)
Date: Thu, 20 Nov 2008 15:52:46 +0100
Subject: [R-sig-ME] how to extract the degrees of freedom in lmer
Message-ID: <492579BE.5000404@inserm.fr>

Dear all,

Previously I was using "lme" and I could extract the denominator degrees 
of freedom   with : summary(fit)$tTable[,3]

Now, I am trying to do the same in "lmer" but I do not know if it is 
possible because the degrees of freedom does not appear in the summary. 
Can you help me, please ?

Thank you for your time.
Sincerely,

Anne Dubois (anne.dubois at inserm.fr)

PS : To illustrate my problem, I use the dataset ergoStool (see below)


 > Stool.lme<-lme(effort~Type,random=~1|Subject,data=ergoStool)
 > summary(Stool.lme)
Linear mixed-effects model fit by REML
 Data: ergoStool
       AIC      BIC   logLik
  133.1308 141.9252 -60.5654

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.332465 1.100295

Fixed effects: effort ~ Type
               Value Std.Error DF   t-value p-value
(Intercept) 8.555556 0.5760123 24 14.853079  0.0000
TypeT2      3.888889 0.5186838 24  7.497610  0.0000
TypeT3      2.222222 0.5186838 24  4.284348  0.0003
TypeT4      0.666667 0.5186838 24  1.285304  0.2110
 Correlation:
       (Intr) TypeT2 TypeT3
TypeT2 -0.45              
TypeT3 -0.45   0.50       
TypeT4 -0.45   0.50   0.50

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054

Number of Observations: 36
Number of Groups: 9
 > summary(Stool.lme)$tTable[,3]
(Intercept)      TypeT2      TypeT3      TypeT4
         24          24          24          24



 > Stool.lmer<-lmer(effort~Type+(1|Subject),data=ergoStool)
 > summary(Stool.lmer)
Linear mixed model fit by REML
Formula: effort ~ Type + (1 | Subject)
   Data: ergoStool
   AIC   BIC logLik deviance REMLdev
 133.1 142.6 -60.57    122.1   121.1
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 1.7753   1.3324 
 Residual             1.2107   1.1003 
Number of obs: 36, groups: Subject, 9

Fixed effects:
            Estimate Std. Error t value
(Intercept)   8.5556     0.5760  14.853
TypeT2        3.8889     0.5187   7.498
TypeT3        2.2222     0.5187   4.284
TypeT4        0.6667     0.5187   1.285

Correlation of Fixed Effects:
       (Intr) TypeT2 TypeT3
TypeT2 -0.450             
TypeT3 -0.450  0.500      
TypeT4 -0.450  0.500  0.500



-- 
Anne DUBOIS
INSERM UMR 738
16, rue Henri Huchard
75018 PARIS
Tel : 01 57 27 73 52
anne.dubois at inserm.fr



From bolker at ufl.edu  Thu Nov 20 19:46:24 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 20 Nov 2008 13:46:24 -0500
Subject: [R-sig-ME] how to extract the degrees of freedom in lmer
In-Reply-To: <492579BE.5000404@inserm.fr>
References: <492579BE.5000404@inserm.fr>
Message-ID: <4925B080.3080105@ufl.edu>

  This is really a special case of R FAQ 7.35,

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f

  The very short answer is that Doug Bates, the author
of lmer, no longer believes in the dominant paradigm of computing F
statistics with a given numerator and a denominator df extracted by some
approximation (preferably one which works correctly when applied
to classical balanced orthogonal nested designs, where the
paradigm is appropriate).  If you need to work in this paradigm
you should probably continue to use lme ...

  (and yes, that *was* "very short" compared to the discussion
referenced in the above FAQ item ...)

  Ben Bolker


Anne Dubois wrote:
> Dear all,
> 
> Previously I was using "lme" and I could extract the denominator degrees
> of freedom   with : summary(fit)$tTable[,3]
> 
> Now, I am trying to do the same in "lmer" but I do not know if it is
> possible because the degrees of freedom does not appear in the summary.
> Can you help me, please ?
> 
> Thank you for your time.
> Sincerely,
> 
> Anne Dubois (anne.dubois at inserm.fr)
> 
> PS : To illustrate my problem, I use the dataset ergoStool (see below)
> 
> 
>> Stool.lme<-lme(effort~Type,random=~1|Subject,data=ergoStool)
>> summary(Stool.lme)
> Linear mixed-effects model fit by REML
> Data: ergoStool
>       AIC      BIC   logLik
>  133.1308 141.9252 -60.5654
> 
> Random effects:
> Formula: ~1 | Subject
>        (Intercept) Residual
> StdDev:    1.332465 1.100295
> 
> Fixed effects: effort ~ Type
>               Value Std.Error DF   t-value p-value
> (Intercept) 8.555556 0.5760123 24 14.853079  0.0000
> TypeT2      3.888889 0.5186838 24  7.497610  0.0000
> TypeT3      2.222222 0.5186838 24  4.284348  0.0003
> TypeT4      0.666667 0.5186838 24  1.285304  0.2110
> Correlation:
>       (Intr) TypeT2 TypeT3
> TypeT2 -0.45              TypeT3 -0.45   0.50       TypeT4 -0.45  
> 0.50   0.50
> 
> Standardized Within-Group Residuals:
>        Min          Q1         Med          Q3         Max
> -1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054
> 
> Number of Observations: 36
> Number of Groups: 9
>> summary(Stool.lme)$tTable[,3]
> (Intercept)      TypeT2      TypeT3      TypeT4
>         24          24          24          24
> 
> 
> 
>> Stool.lmer<-lmer(effort~Type+(1|Subject),data=ergoStool)
>> summary(Stool.lmer)
> Linear mixed model fit by REML
> Formula: effort ~ Type + (1 | Subject)
>   Data: ergoStool
>   AIC   BIC logLik deviance REMLdev
> 133.1 142.6 -60.57    122.1   121.1
> Random effects:
> Groups   Name        Variance Std.Dev.
> Subject  (Intercept) 1.7753   1.3324 Residual             1.2107  
> 1.1003 Number of obs: 36, groups: Subject, 9
> 
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   8.5556     0.5760  14.853
> TypeT2        3.8889     0.5187   7.498
> TypeT3        2.2222     0.5187   4.284
> TypeT4        0.6667     0.5187   1.285
> 
> Correlation of Fixed Effects:
>       (Intr) TypeT2 TypeT3
> TypeT2 -0.450             TypeT3 -0.450  0.500      TypeT4 -0.450 
> 0.500  0.500
> 
> 
>



From bates at stat.wisc.edu  Thu Nov 20 20:01:05 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 20 Nov 2008 13:01:05 -0600
Subject: [R-sig-ME] how to extract the degrees of freedom in lmer
In-Reply-To: <4925B080.3080105@ufl.edu>
References: <492579BE.5000404@inserm.fr> <4925B080.3080105@ufl.edu>
Message-ID: <40e66e0b0811201101h3b2d61c0s6289ad02de063124@mail.gmail.com>

On Thu, Nov 20, 2008 at 12:46 PM, Ben Bolker <bolker at ufl.edu> wrote:
>  This is really a special case of R FAQ 7.35,
>
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f
>
>  The very short answer is that Doug Bates, the author
> of lmer, no longer believes in the dominant paradigm of computing F
> statistics with a given numerator and a denominator df extracted by some
> approximation (preferably one which works correctly when applied
> to classical balanced orthogonal nested designs, where the
> paradigm is appropriate).  If you need to work in this paradigm
> you should probably continue to use lme ...
>
>  (and yes, that *was* "very short" compared to the discussion
> referenced in the above FAQ item ...)

You're not trying to indicate that I am somewhat wordy, are you, Ben?

> Anne Dubois wrote:
>> Dear all,
>>
>> Previously I was using "lme" and I could extract the denominator degrees
>> of freedom   with : summary(fit)$tTable[,3]
>>
>> Now, I am trying to do the same in "lmer" but I do not know if it is
>> possible because the degrees of freedom does not appear in the summary.
>> Can you help me, please ?
>>
>> Thank you for your time.
>> Sincerely,
>>
>> Anne Dubois (anne.dubois at inserm.fr)
>>
>> PS : To illustrate my problem, I use the dataset ergoStool (see below)
>>
>>
>>> Stool.lme<-lme(effort~Type,random=~1|Subject,data=ergoStool)
>>> summary(Stool.lme)
>> Linear mixed-effects model fit by REML
>> Data: ergoStool
>>       AIC      BIC   logLik
>>  133.1308 141.9252 -60.5654
>>
>> Random effects:
>> Formula: ~1 | Subject
>>        (Intercept) Residual
>> StdDev:    1.332465 1.100295
>>
>> Fixed effects: effort ~ Type
>>               Value Std.Error DF   t-value p-value
>> (Intercept) 8.555556 0.5760123 24 14.853079  0.0000
>> TypeT2      3.888889 0.5186838 24  7.497610  0.0000
>> TypeT3      2.222222 0.5186838 24  4.284348  0.0003
>> TypeT4      0.666667 0.5186838 24  1.285304  0.2110
>> Correlation:
>>       (Intr) TypeT2 TypeT3
>> TypeT2 -0.45              TypeT3 -0.45   0.50       TypeT4 -0.45
>> 0.50   0.50
>>
>> Standardized Within-Group Residuals:
>>        Min          Q1         Med          Q3         Max
>> -1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054
>>
>> Number of Observations: 36
>> Number of Groups: 9
>>> summary(Stool.lme)$tTable[,3]
>> (Intercept)      TypeT2      TypeT3      TypeT4
>>         24          24          24          24
>>
>>
>>
>>> Stool.lmer<-lmer(effort~Type+(1|Subject),data=ergoStool)
>>> summary(Stool.lmer)
>> Linear mixed model fit by REML
>> Formula: effort ~ Type + (1 | Subject)
>>   Data: ergoStool
>>   AIC   BIC logLik deviance REMLdev
>> 133.1 142.6 -60.57    122.1   121.1
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> Subject  (Intercept) 1.7753   1.3324 Residual             1.2107
>> 1.1003 Number of obs: 36, groups: Subject, 9
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)   8.5556     0.5760  14.853
>> TypeT2        3.8889     0.5187   7.498
>> TypeT3        2.2222     0.5187   4.284
>> TypeT4        0.6667     0.5187   1.285
>>
>> Correlation of Fixed Effects:
>>       (Intr) TypeT2 TypeT3
>> TypeT2 -0.450             TypeT3 -0.450  0.500      TypeT4 -0.450
>> 0.500  0.500
>>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From leog at anicca-vijja.de  Fri Nov 21 07:49:51 2008
From: leog at anicca-vijja.de (=?ISO-8859-15?Q?Leo_G=FCrtler?=)
Date: Fri, 21 Nov 2008 07:49:51 +0100
Subject: [R-sig-ME] residuals for different levels (lmer)
Message-ID: <49265A0F.2000903@anicca-vijja.de>

Dear SIG-ME,

is there a way to obtain residuals for the different levels with lmer as
it is possible with lme?

library(nlme)
example(lme)
residuals(fm1, level=0:1)

library(lme4)
example(lmer)
residuals(fm1, level=0:1)

-> the call to 'residuals' in combination with 'lmer' brings only the
residuals of one level.

How can I obtain residuals for different levels?

thanks,
best regards,

leo g?rtler



From bates at stat.wisc.edu  Fri Nov 21 15:29:07 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Nov 2008 08:29:07 -0600
Subject: [R-sig-ME] residuals for different levels (lmer)
In-Reply-To: <49265A0F.2000903@anicca-vijja.de>
References: <49265A0F.2000903@anicca-vijja.de>
Message-ID: <40e66e0b0811210629y562a8fan7f433c8b8e1419ad@mail.gmail.com>

On Fri, Nov 21, 2008 at 12:49 AM, Leo G?rtler <leog at anicca-vijja.de> wrote:
> Dear SIG-ME,

> is there a way to obtain residuals for the different levels with lmer as
> it is possible with lme?

To fit a model with lme incorporating random effects for more than one
grouping factor you must have nested grouping factors, which means
that the concept of levels will make sense.  The lmer specification is
more general, allowing for crossed or partially crossed grouping
factors.  In those circumstances defining residuals incorporating
random effects from some grouping factors but not from others is
trickier.  That's even before considering other models like
generalized linear mixed models and nonlinear mixed models that can be
fit in lme4.

I often regret adding code that works for certain special cases
without thinking through the general situation.  The "coef" method in
lme4 is an example of such a case.  It is not clear that the result is
meaningful when applied to models with crossed or partially crossed
grouping factors.

> library(nlme)
> example(lme)
> residuals(fm1, level=0:1)
>
> library(lme4)
> example(lmer)
> residuals(fm1, level=0:1)
>
> -> the call to 'residuals' in combination with 'lmer' brings only the
> residuals of one level.
>
> How can I obtain residuals for different levels?
>
> thanks,
> best regards,
>
> leo g?rtler
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bendantzer at gmail.com  Sat Nov 22 16:14:46 2008
From: bendantzer at gmail.com (Benjamin Dantzer)
Date: Sat, 22 Nov 2008 10:14:46 -0500
Subject: [R-sig-ME] Update on MCMCsamp for glmer models
Message-ID: <611BBD63-276B-430F-9411-30BC308EE243@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081122/e9c01285/attachment.pl>

From leog at anicca-vijja.de  Sun Nov 23 11:48:47 2008
From: leog at anicca-vijja.de (=?ISO-8859-1?Q?Leo_G=FCrtler?=)
Date: Sun, 23 Nov 2008 11:48:47 +0100
Subject: [R-sig-ME] residuals for different levels (lmer)
In-Reply-To: <40e66e0b0811210629y562a8fan7f433c8b8e1419ad@mail.gmail.com>
References: <49265A0F.2000903@anicca-vijja.de>
	<40e66e0b0811210629y562a8fan7f433c8b8e1419ad@mail.gmail.com>
Message-ID: <4929350F.90500@anicca-vijja.de>

Dear Douglas,

> To fit a model with lme incorporating random effects for more than one
> grouping factor you must have nested grouping factors, which means
> that the concept of levels will make sense.  The lmer specification is
> more general, allowing for crossed or partially crossed grouping
> factors.  In those circumstances defining residuals incorporating
> random effects from some grouping factors but not from others is
> trickier.  That's even before considering other models like
> generalized linear mixed models and nonlinear mixed models that can be
> fit in lme4.

thanks for your explanations. In my case the grouping factors are nested
and in the way they are nested they do make sense (i.e. no crossed or
patially crossed grouping factors):

repeated measurements of persons in classes in schools

However, your answer means that I have to write my own code in
accordance to the level for which I need residuals. AFAIU the residuals
(e.g. on the level of 'classes') are 'shrunken' towards the group mean
so I have to reflate them? Is there a formula for that (I found in the
literature a formula for 'intercept' but not for 'slope'). In my case I
have 'slope' involved.

Thanks - to know how to reflate would be sufficient for me (or any
literature link where I can find that). I assume that by knowing how to
reflate I can proceed by formulating the equation for the level for
which I need residuals.

best regards,
leo

> 
> I often regret adding code that works for certain special cases
> without thinking through the general situation.  The "coef" method in
> lme4 is an example of such a case.  It is not clear that the result is
> meaningful when applied to models with crossed or partially crossed
> grouping factors.
> 
>> library(nlme)
>> example(lme)
>> residuals(fm1, level=0:1)
>>
>> library(lme4)
>> example(lmer)
>> residuals(fm1, level=0:1)
>>
>> -> the call to 'residuals' in combination with 'lmer' brings only the
>> residuals of one level.
>>
>> How can I obtain residuals for different levels?
>>
>> thanks,
>> best regards,
>>
>> leo g?rtler
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From mjuanjorda at gmail.com  Mon Nov 24 14:53:03 2008
From: mjuanjorda at gmail.com (Maria Jose Juan Jorda)
Date: Mon, 24 Nov 2008 14:53:03 +0100
Subject: [R-sig-ME]  lmer and warming message when using method=ML
Message-ID: <9bcbdf360811240553i12ab3f0bvc13c2fb0918e96e9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081124/24873aa5/attachment.pl>

From a.renwick at abdn.ac.uk  Mon Nov 24 15:20:52 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Mon, 24 Nov 2008 14:20:52 +0000
Subject: [R-sig-ME] lmer and warming message when using method=ML
In-Reply-To: <9bcbdf360811240553i12ab3f0bvc13c2fb0918e96e9@mail.gmail.com>
References: <9bcbdf360811240553i12ab3f0bvc13c2fb0918e96e9@mail.gmail.com>
Message-ID: <B9D1301370916C44B5874AF340C18B9B28ADB43DD3@VMAILB.uoa.abdn.ac.uk>

When you use a lmer model you have to use the command REML=FALSE instead of method=ML.

One thing to note also is that when you use an lmer model in at not possible at present to use the REML method.

Doug Bates replyed to my question asking just that on the 17th Sep "The REML criterion is not defined for generalized linear mixed models. Well, at least I don't know of a definition that makes sense for GLMMs. "
Hope that helps,
Anna

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Maria Jose Juan Jorda
Sent: 24 November 2008 13:53
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lmer and warming message when using method=ML

Hello lmer experts

In the past the lmer function allowed to choose either ML or REML as the estimation method.

I just updated the R version  to *R version 2.8.0* (2008-10-20)
(i386-pc-mingw32)  and the lme4 package to *lme4_0.999375-27.


*I am running my old code choosing ML as the estimation method and I am getting this warming:

Warning message:
In lmer(meansize ~ year + (year | id), data = cas, method = "ML") :
  Argument 'method' is deprecated.  Use 'REML' instead


This is my code:

model.a<-lmer(meansize~year+ (year|id),data=cas, method="ML")


I have tried to look for the asnwer myself in the R-sig-mixed message board and I could not find an answer.

Does anybody understand the reason why ML cannot be used anymore?

Thanks in advance.

Maria

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From bates at stat.wisc.edu  Mon Nov 24 16:20:52 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 24 Nov 2008 09:20:52 -0600
Subject: [R-sig-ME] lmer and warming message when using method=ML
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28ADB43DD3@VMAILB.uoa.abdn.ac.uk>
References: <9bcbdf360811240553i12ab3f0bvc13c2fb0918e96e9@mail.gmail.com>
	<B9D1301370916C44B5874AF340C18B9B28ADB43DD3@VMAILB.uoa.abdn.ac.uk>
Message-ID: <40e66e0b0811240720k16924669ua060dd2231dbf52@mail.gmail.com>

On Mon, Nov 24, 2008 at 8:20 AM, Renwick, A. R. <a.renwick at abdn.ac.uk> wrote:
> When you use a lmer model you have to use the command REML=FALSE instead of method=ML.

> One thing to note also is that when you use an lmer model in at not possible at present to use the REML method.

I think you mean that REML is not available for a glmer model (i.e. a
generalized linear mixed model).  For an lmer model REML is the
default and, as you indicated, you get ML estimates by stating REML =
FALSE in your call to lmer.

> Doug Bates replyed to my question asking just that on the 17th Sep "The REML criterion is not defined for generalized linear mixed models. Well, at least I don't know of a definition that makes sense for GLMMs. "

> Hope that helps,
> Anna
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Maria Jose Juan Jorda
> Sent: 24 November 2008 13:53
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lmer and warming message when using method=ML
>
> Hello lmer experts
>
> In the past the lmer function allowed to choose either ML or REML as the estimation method.
>
> I just updated the R version  to *R version 2.8.0* (2008-10-20)
> (i386-pc-mingw32)  and the lme4 package to *lme4_0.999375-27.
>
>
> *I am running my old code choosing ML as the estimation method and I am getting this warming:
>
> Warning message:
> In lmer(meansize ~ year + (year | id), data = cas, method = "ML") :
>  Argument 'method' is deprecated.  Use 'REML' instead
>
>
> This is my code:
>
> model.a<-lmer(meansize~year+ (year|id),data=cas, method="ML")
>
>
> I have tried to look for the asnwer myself in the R-sig-mixed message board and I could not find an answer.
>
> Does anybody understand the reason why ML cannot be used anymore?
>
> Thanks in advance.
>
> Maria
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ggrothendieck at gmail.com  Mon Nov 24 17:45:11 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 24 Nov 2008 11:45:11 -0500
Subject: [R-sig-ME] HPDinterval conflict between lme4 and coda
Message-ID: <971536df0811240845h66640eeeyea6e6d01d6222a9@mail.gmail.com>

HPDinterval has a conflict between lme4 and coda.  I can
work around it by loading lme4 second or using lme4::HPDinterval
but thought I would mention this just in case:

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rcond,
         rowMeans,
         rowSums

> library(coda)

Attaching package: 'coda'


        The following object(s) are masked from package:lme4 :

         HPDinterval

> example(mcmcsamp)
... output deleted ...

> HPDinterval(samp0)
Error in UseMethod("HPDinterval") :
  no applicable method for "HPDinterval"
> lme4::HPDinterval(samp0)
$fixef
                 lower     upper
(Intercept) 241.502786 261.52128
Days          7.082658  14.23481
attr(,"Probability")
[1] 0.95

$ST
         lower     upper
[1,] 0.2795465 0.8468348
[2,] 0.1431433 0.3713343
attr(,"Probability")
[1] 0.95

$sigma
        lower    upper
[1,] 23.61387 30.01333
attr(,"Probability")
[1] 0.95

> R.version.string
[1] "R version 2.8.0 Patched (2008-11-10 r46884)"
> packageDescription("lme4")$Version
[1] "0.999375-27"
> packageDescription("coda")$Version
[1] "0.13-3"



From Thierry.ONKELINX at inbo.be  Tue Nov 25 10:35:43 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 25 Nov 2008 10:35:43 +0100
Subject: [R-sig-ME] [R] lme4 and false convergence
In-Reply-To: <492AE645.5070203@cornell.edu>
References: <492AE645.5070203@cornell.edu>
Message-ID: <2E9C414912813E4EB981326983E0A10405C96458@inboexch.inbo.be>

Dear Ben,

Your questions suite better in R-SIG-Mixed-Models which I am cc'ing.
Have checked the mailing list? Try RSiteSearch("lme4 false convergence")

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
Namens Ben Zuckerberg
Verzonden: maandag 24 november 2008 18:37
Aan: r-help at r-project.org
Onderwerp: [R] lme4 and false convergence

Dear R-users,

I am using the most updated package of lme4 (lme4_0.999375-2).  I have a

data set consisting of ~900 observations at ~440 independent survey 
sites.  There are an unbalanced number of surveys at each site.  I am 
attempting to develop several models evaluating the presence/absence of 
a species (PRES) at these random sites (SITE) using a number of 
predictor variables.  The response variable (PRES) is binomial and the 
included predictor variables are either proportions (e.g., AG, FOR, 
OPEN, LDEV,or DEV) or numerical (COUNT[min. 1 to max. 37,mean = 10]). 
---------------------------------------------------------------------
PROBLEM 1:

I have developed the following GLMM:

mix.1<-glmer(PRES~AG+FOR+OPEN+LDEV+DEV+COUNT+(1|SITE),family=binomial,da
ta=merge1) 


I receive the following error:
Warning message:
In mer_finalize(ans) : false convergence (8)

There is model output, but I am worried it might be biased. 

I have tried:
-Data transformation of the predictor variables (e.g., log(COUNT)), 
which does seem successful in some simpler models, but does not work 
consistently.
-The most updated version of lme4

---------------------------------------------------------------------
PROBLEM #2:
In addition, I am interested in visualizing the predicted probabilities 
from this output using the fixed effect function, but receive the 
following message:

fixef(mix.1)
Error in UseMethod("fixef") : no applicable method for "fixef"

Any suggestions would be greatly appreciated!

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From bz73 at cornell.edu  Tue Nov 25 18:03:23 2008
From: bz73 at cornell.edu (Ben Zuckerberg)
Date: Tue, 25 Nov 2008 12:03:23 -0500
Subject: [R-sig-ME] fixef and lme4
Message-ID: <492C2FDB.6070102@cornell.edu>

I can not seem to get the fixef function to work in lme4.  Any 
suggestions would be very welcome...

 >  data(sleepstudy)

 >  test<-lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)

 >  summary(test)

Linear mixed model fit by REML

Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)

   Data: sleepstudy

  AIC  BIC logLik deviance REMLdev

 1754 1770 -871.8     1752    1744

Random effects:

 Groups   Name        Variance Std.Dev.

 Subject  (Intercept) 627.568  25.0513

 Subject  Days         35.858   5.9882

 Residual             653.584  25.5653

Number of obs: 180, groups: Subject, 18

Fixed effects:

            Estimate Std. Error t value

(Intercept)  251.405      6.885   36.51

Days          10.467      1.559    6.71

Correlation of Fixed Effects:

     (Intr)

Days -0.184

 >  fixef(test)

Error in UseMethod("fixef") : no applicable method for "fixef



From nicebread at gmx.net  Tue Nov 25 19:07:58 2008
From: nicebread at gmx.net (=?ISO-8859-1?Q?Felix_Sch=F6nbrodt?=)
Date: Tue, 25 Nov 2008 19:07:58 +0100
Subject: [R-sig-ME] fixef and lme4
In-Reply-To: <492C2FDB.6070102@cornell.edu>
References: <492C2FDB.6070102@cornell.edu>
Message-ID: <230E3931-F655-4296-95A6-422C58C2F189@gmx.net>

Hi Ben,

maybe you loaded the nlme-library after lme4. In this case the fixef- 
function from lme4 is masked and replaced by the nlme-function with  
the same name.

 > library(nlme)

Attache Paket: 'nlme'


	The following object(s) are masked _by_ .GlobalEnv :

	 corMatrix


	The following object(s) are masked from package:lme4 :

	 BIC,
	 VarCorr,
	 fixef,
	 lmList,
	 ranef

 > fixef(ML.anova)
Fehler in UseMethod("fixef") : keine anwendbare Methode f?r "fixef"
 >

Just unload nlme and it should work...
detach("package:nlme")

Felix



Am 25.11.2008 um 18:03 schrieb Ben Zuckerberg:

> I can not seem to get the fixef function to work in lme4.  Any  
> suggestions would be very welcome...
>
> >  data(sleepstudy)
>
> >  test<-lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),  
> sleepstudy)
>
> >  summary(test)
>
> Linear mixed model fit by REML
>
> Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>
>  Data: sleepstudy
>
> AIC  BIC logLik deviance REMLdev
>
> 1754 1770 -871.8     1752    1744
>
> Random effects:
>
> Groups   Name        Variance Std.Dev.
>
> Subject  (Intercept) 627.568  25.0513
>
> Subject  Days         35.858   5.9882
>
> Residual             653.584  25.5653
>
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>
>           Estimate Std. Error t value
>
> (Intercept)  251.405      6.885   36.51
>
> Days          10.467      1.559    6.71
>
> Correlation of Fixed Effects:
>
>    (Intr)
>
> Days -0.184
>
> >  fixef(test)
>
> Error in UseMethod("fixef") : no applicable method for "fixef
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From njbisaac at googlemail.com  Tue Nov 25 19:09:32 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Tue, 25 Nov 2008 18:09:32 +0000
Subject: [R-sig-ME] fixef and lme4
In-Reply-To: <492C2FDB.6070102@cornell.edu>
References: <492C2FDB.6070102@cornell.edu>
Message-ID: <a072ed700811251009v61c8f73dg18fd518df4d28fb5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081125/8d2ea216/attachment.pl>

From bz73 at cornell.edu  Tue Nov 25 14:46:27 2008
From: bz73 at cornell.edu (Ben Zuckerberg)
Date: Tue, 25 Nov 2008 08:46:27 -0500
Subject: [R-sig-ME] lme4 and false convergence
Message-ID: <492C01B3.4000300@cornell.edu>

Dear R-users,

I am using the most updated package of lme4 (lme4_0.999375-2).  I have a 
data set consisting of ~900 observations at ~440 independent survey 
sites.  There are an unbalanced number of surveys at each site.  I am 
attempting to develop several models evaluating the presence/absence of 
a species (PRES) at these random sites (SITE) using a number of 
predictor variables.  The response variable (PRES) is binomial and the 
included predictor variables are either proportions (e.g., AG, FOR, 
OPEN, LDEV,or DEV) or numerical (COUNT[min. 1 to max. 37,mean = 10]). 
---------------------------------------------------------------------
PROBLEM 1:

I have developed the following GLMM:

mix.1<-glmer(PRES~AG+FOR+OPEN+LDEV+DEV+COUNT+(1|SITE),family=binomial,data=merge1) 


I receive the following error:
Warning message:
In mer_finalize(ans) : false convergence (8)

There is model output, but I am worried it might be biased.
I have tried:
-Data transformation of the predictor variables (e.g., log(COUNT)), 
which does seem successful in some simpler models, but does not work 
consistently.
-The most updated version of lme4

---------------------------------------------------------------------
PROBLEM #2:
In addition, I am interested in visualizing the predicted probabilities 
from this output using the fixed effect function, but receive the 
following message:

fixef(mix.1)
Error in UseMethod("fixef") : no applicable method for "fixef"

Any suggestions would be greatly appreciated!

-- 
Benjamin Zuckerberg, Ph.D.
Post-doctoral Associate
Spatial Ecologist, Citizen Science
Cornell Laboratory of Ornithology
159 Sapsucker Woods Road
Ithaca, NY 14850 
Tele: 607-254-2174
Fax: 607-254-2111



From bates at stat.wisc.edu  Tue Nov 25 19:53:44 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 25 Nov 2008 12:53:44 -0600
Subject: [R-sig-ME] fixef and lme4
In-Reply-To: <492C2FDB.6070102@cornell.edu>
References: <492C2FDB.6070102@cornell.edu>
Message-ID: <40e66e0b0811251053j7acd1e6ep38d66ecd2d3218fb@mail.gmail.com>

On Tue, Nov 25, 2008 at 11:03 AM, Ben Zuckerberg <bz73 at cornell.edu> wrote:
> I can not seem to get the fixef function to work in lme4.  Any suggestions
> would be very welcome...
>
>>  data(sleepstudy)
>
>>  test<-lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
>
>>  summary(test)
>
> Linear mixed model fit by REML
>
> Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
>
>  Data: sleepstudy
>
>  AIC  BIC logLik deviance REMLdev
>
> 1754 1770 -871.8     1752    1744
>
> Random effects:
>
> Groups   Name        Variance Std.Dev.
>
> Subject  (Intercept) 627.568  25.0513
>
> Subject  Days         35.858   5.9882
>
> Residual             653.584  25.5653
>
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>
>           Estimate Std. Error t value
>
> (Intercept)  251.405      6.885   36.51
>
> Days          10.467      1.559    6.71
>
> Correlation of Fixed Effects:
>
>    (Intr)
>
> Days -0.184
>
>>  fixef(test)
>
> Error in UseMethod("fixef") : no applicable method for "fixef

Felix is correct in his diagnosis that the problem originates with
having the nlme package loaded after lme4.  The clue is that the error
message states UseMethod which indicates S3 method dispatch.  The S4
method is still accessible but you need to call it as

lme4::fixef

The safest course is not to load the lme4 and nlme packages simultaneously.



From matthew_wiener at merck.com  Tue Nov 25 20:09:01 2008
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 25 Nov 2008 14:09:01 -0500
Subject: [R-sig-ME] Variance-covariance matrix for normalized residuals
	in lme
In-Reply-To: <2ad0cc110811130952l50b037a6n393f136abf650111@mail.gmail.com>
References: <4E9A692D8755DF478B56A2892388EE1F0351933D@usctmx1118.merck.com>
	<2ad0cc110811130952l50b037a6n393f136abf650111@mail.gmail.com>
Message-ID: <4E9A692D8755DF478B56A2892388EE1F0357765F@usctmx1118.merck.com>

Thanks for your reply.  I played around with the getVarCov.lme function
for a little while.   The code indicates that you can only have a single
level of random effect, and I pass that test with a random effect for
subject only.  However, my correlation structure on the residuals
depends on two levels - correlations occur within subject and date.

The two levels there seem to cause a problem, as the
corMatrix(obj$modelStruct$varStruct) has names that indicate subject and
day, while we try to take levels of them by subject only.

It does look as though the calculations should still work, and at any
rate now I can find some of these things.

Regards,

Matt

-----Original Message-----
From: Kingsford Jones [mailto:kingsfordjones at gmail.com] 
Sent: Thursday, November 13, 2008 12:52 PM
To: Wiener, Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Variance-covariance matrix for normalized
residuals in lme

On Thu, Nov 13, 2008 at 7:29 AM, Wiener, Matthew
<matthew_wiener at merck.com> wrote:
> All -
>
> We are fitting an lme model with several fixed effects, a single
random
> effect, and an AR1 structure on the residuals.  To assess the model we
> examine the residuals.  The predicted vs. residual plots look fine
using
> raw residuals or Pearson residuals (leaving aside serial
correlations).
> However, the normalized residuals - which should account for the AR1
> structure - have a very strange feature.  For large predicted values,
> they show HUGE residuals - residuals an order of magnitude larger than
> the predicted values themselves.
>
> Working to figure out what was going on, we constructed the
> variance-covariance matrix of the residuals based on the parameter
> estimates, and calculated the normalization matrix independently.
When
> we multiplied that matrix by the vector of residuals, we ended up with
> normalized residuals that looked fine - there were no extremely large
> normalized residuals.
>
> We would like to compare our hand-computed variance-covariance matrix
to
> the one used by lme, but we have not been able to figure out how to
> extract that matrix.  In lme4, we would use VarCorr, but in lme4, as
far
> as we can tell, we can't have the AR1 correlation structure, which is
> very important in our problem.
>
> Is there some way to get at that matrix?

Does nlme::getVarCov return what you're looking for?

> And has anyone else had the
> normalized residuals blow up in this way?
>

I don't recall ever seeing this, but a guess is high leverage points
(e.g. some outlying large values in the column space of the X matrix).

hth,

Kingsford Jones


> Thanks,
>
> Matt Wiener, Shubhankar Ray, Vladimir Svetnik
> Notice:  This e-mail message, together with any
attachme...{{dropped:15}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
Notice:  This e-mail message, together with any attachme...{{dropped:12}}



From ken at kjbeath.com.au  Wed Nov 26 11:29:29 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 26 Nov 2008 21:29:29 +1100
Subject: [R-sig-ME] lme4 and false convergence
In-Reply-To: <492C01B3.4000300@cornell.edu>
References: <492C01B3.4000300@cornell.edu>
Message-ID: <77B82199-8553-4EFE-A9BD-42CE74DF37E8@kjbeath.com.au>

On 26/11/2008, at 12:46 AM, Ben Zuckerberg wrote:

> Dear R-users,
>
> I am using the most updated package of lme4 (lme4_0.999375-2).  I  
> have a data set consisting of ~900 observations at ~440 independent  
> survey sites.  There are an unbalanced number of surveys at each  
> site.  I am attempting to develop several models evaluating the  
> presence/absence of a species (PRES) at these random sites (SITE)  
> using a number of predictor variables.  The response variable (PRES)  
> is binomial and the included predictor variables are either  
> proportions (e.g., AG, FOR, OPEN, LDEV,or DEV) or numerical  
> (COUNT[min. 1 to max. 37,mean = 10]).  
> ---------------------------------------------------------------------
> PROBLEM 1:
>
> I have developed the following GLMM:
>
> mix.1<-glmer(PRES~AG+FOR+OPEN+LDEV+DEV+COUNT+(1| 
> SITE),family=binomial,data=merge1)
>
> I receive the following error:
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>
> There is model output, but I am worried it might be biased.
> I have tried:
> -Data transformation of the predictor variables (e.g., log(COUNT)),  
> which does seem successful in some simpler models, but does not work  
> consistently.
> -The most updated version of lme4
>

This is difficult without the output.

Possibly there is a high correlation within sites. Try using the  
adaptive Gauss-Hermite option with nAGQ=5 or more.

It may also indicate a close to complete separation indicated by a  
large parameter estimate. There is not much that can be done if a  
parameter close to perfectly predicts.

Ken


> ---------------------------------------------------------------------
> PROBLEM #2:
> In addition, I am interested in visualizing the predicted  
> probabilities from this output using the fixed effect function, but  
> receive the following message:
>
> fixef(mix.1)
> Error in UseMethod("fixef") : no applicable method for "fixef"
>
> Any suggestions would be greatly appreciated!
>
> -- 
> Benjamin Zuckerberg, Ph.D.
> Post-doctoral Associate
> Spatial Ecologist, Citizen Science
> Cornell Laboratory of Ornithology
> 159 Sapsucker Woods Road
> Ithaca, NY 14850 Tele: 607-254-2174
> Fax: 607-254-2111
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From a.renwick at abdn.ac.uk  Wed Nov 26 12:11:57 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Wed, 26 Nov 2008 11:11:57 +0000
Subject: [R-sig-ME] Between and within variance in a GLMM
Message-ID: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>


I have a wee query regarding the variation explained by the random effect in a GLMM using lme4 package.  In the model output I was under the assumption that the value given as Std Dev is the VARIANCE BETWEEN the random factor and the VARIANCE WITHIN could be calculated using the following equation:



Variance WITHIN = ST value x Variance BETWEEN.
Therefore, Variance WITHIN = ST value x Std Dev value in model output.

However, the ST value is always equal to the Std Dev given in model output so can someone clarify how to calulate the within and between variance of the random effect.

EXAMPLE:

Generalized linear mixed model fit by the Laplace approximation
Formula: fleapresence ~ sex + width + sess + Nhat + alt + width:sess +      (1 | LocTran)
   Data: flea
  AIC  BIC logLik deviance
 1797 1863 -886.7     1773
Random effects:
 Groups  Name        Variance Std.Dev.
 LocTran (Intercept) 0.10512  0.32422
Number of obs: 1697, groups: LocTran, 14


  ..@ ST      :List of 1
  .. ..$ : num [1, 1] 0.324


Thanks
Anna

Anna Renwick
Institute of Biological & Environment Sciences
University of Aberdeen
Zoology Building
Tillydrone Avenue
Aberdeen
AB24 2TZ


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From bates at stat.wisc.edu  Wed Nov 26 15:29:55 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 26 Nov 2008 08:29:55 -0600
Subject: [R-sig-ME] Between and within variance in a GLMM
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
References: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
Message-ID: <40e66e0b0811260629t5f1c0840ha359c3d17f941608@mail.gmail.com>

On Wed, Nov 26, 2008 at 5:11 AM, Renwick, A. R. <a.renwick at abdn.ac.uk> wrote:

> I have a wee query regarding the variation explained by the random effect in a GLMM using lme4 package.  In the model output I was under the assumption that the value given as Std Dev is the VARIANCE BETWEEN the random factor and the VARIANCE WITHIN could be calculated using the following equation:

> Variance WITHIN = ST value x Variance BETWEEN.
> Therefore, Variance WITHIN = ST value x Std Dev value in model output.

> However, the ST value is always equal to the Std Dev given in model output so can someone clarify how to calulate the within and between variance of the random effect.

> EXAMPLE:

> Generalized linear mixed model fit by the Laplace approximation
> Formula: fleapresence ~ sex + width + sess + Nhat + alt + width:sess +      (1 | LocTran)
>   Data: flea
>  AIC  BIC logLik deviance
>  1797 1863 -886.7     1773
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  LocTran (Intercept) 0.10512  0.32422
> Number of obs: 1697, groups: LocTran, 14

>  ..@ ST      :List of 1
>  .. ..$ : num [1, 1] 0.324

Is fleapresence a binary response?

Your question doesn't have an answer for models fit to a binary
response (Bernoulli or binomial conditional distribution) or to a
count response (Poisson conditional distribution).

The way that the GLMM models fit by glmer are defined, the
unconditional distribution of the random effects is always a
multivariate Gaussian distribution with mean zero and a parameterized
variance-covariance matrix.  Thus there are parameters in the model
that represent the variances of the random effects. The conditional
distribution of the response given a value of the random effects can
be Gaussian or Bernoulli or Poisson or gamma or ...  We do require the
components are conditionally independent and that the scalar
conditional distributions be completely determined by the conditional
mean and, at most, one additional parameter that is common to all
components.  If this parameter exists then a "within" sum of squares
has an interpretation.  However, the Bernoulli or Poisson conditional
distributions are completely determined by the conditional mean so
there isn't any separate scale parameter.  (Those who would claim that
the quasibinomial or quasipoisson families allow for this should bear
in mind that these families do not correspond to actual probability
distributions, which is why it is difficult to define a likelihood for
such models.  These families are artificial constructs with, at best,
questionable mathematical justification.)

When you leave the world of Gaussian distributions and start dabbling
in other conditional distributions you must give up many convenient
properties.  In the Gaussian distribution the mean and
variance/covariance are orthogonal to one another.  You can change the
mean without affecting the variance/covariance and vice versa.  With
other distributions you can't do that.

This is all to say that a "within sum of squares" doesn't correspond
to any parameter or property of the distributions in the model.  One
could create a number that kind-of, sort-of represents something like
the estimate of the scalar conditional variance in a Gaussian mixed
model but it has no meaning for the model.  It is strictly an
artificial construct.

This is not a criticism of your question.  To me the fact that so many
concepts in the realm of analysis of variance are deeply misunderstood
is a symptom of the way that statisticians have taught the subject.
R. A. Fisher had brilliant geometric insight and was able to determine
how comparisons between certain nested models could be conveniently
summarized by partitioning the variability of the response, as
expressed by the sum of squares of the deviations about the mean, into
orthogonal components.  Unfortunately we often present these beautiful
mathematical results by starting at the intermediate steps - sums of
squares, degrees of freedom, mean squares, expected mean squares - and
not mentioning that these are simply computational short-cuts that
only apply to certain, very highly structured models, and furthermore
they are unnecessary in modern computing environments.  The result,
unfortunately, is that we ascribe properties or interpretations to
models inappropriately.

Again, let me emphasize that I am not criticising your question.  If I
haven't explained myself adequately let me know and I will try again.



From paul.goedhart at wur.nl  Thu Nov 27 09:07:40 2008
From: paul.goedhart at wur.nl (Goedhart, Paul)
Date: Thu, 27 Nov 2008 09:07:40 +0100
Subject: [R-sig-ME] lme4 and false convergence
In-Reply-To: <492C01B3.4000300@cornell.edu>
References: <492C01B3.4000300@cornell.edu>
Message-ID: <1F4755565F237F45AA01135B72E8C1B201554964@scomp0039.wurnet.nl>

I had a similar problem which disappeared after standardizing the
predictor variables. Apparently there is some numerical instability
within LME4. Below you will find a simulated example for a loglinear
model.

Paul W. Goedhart 
Biometris,  Wageningen UR,  Postbus 100,  6700 AC Wageningen, The
Netherlands

> require(lme4)
Loading required package: lme4
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 xtabs 

Warning messages:
1: package 'lme4' was built under R version 2.7.2 
2: package 'Matrix' was built under R version 2.7.2 
> # Simulate counts for a block design with a random blockeffect
> set.seed(93923142)
> nblock <- 10
> nplot  <- 4
> nunit  <- nblock * nplot
> block  <- rep(1:nblock, each=nplot)
> plot   <- rep(1:nplot, nblock)
> rmean  <- 25000
> beta   <- 10/rmean
> xx     <- round(rnorm(nunit, mean=rmean, sd=1000))
> rblock <- rep(rnorm(nblock, mean=0, sd=0.5), each=nplot)
> lp     <-  -9 + beta * xx
> mu     <- exp(lp + rblock)
> response <- mu
> for (ii in 1:nunit)
+   {
+   response[ii] <- rpois(1, mu[ii])
+   }
> # GLMM with UN-STANDARDISED explanatory
> mean(xx)
[1] 24897.15
> glmer  <- glmer(response ~ xx + (1 | block), family=poisson)
Warning message:
In mer_finalize(ans) : false convergence (8)
> glmer
Generalized linear mixed model fit by the Laplace approximation 
Formula: response ~ xx + (1 | block) 
   AIC   BIC logLik deviance
 59.16 64.23 -26.58    53.16
Random effects:
 Groups Name        Variance Std.Dev.
 block  (Intercept) 0.66667  0.8165  
Number of obs: 40, groups: block, 10

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -1.025e+01  2.915e+00  -3.517 0.000437 ***
xx           4.454e-04  1.151e-04   3.872 0.000108 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Correlation of Fixed Effects:
   (Intr)
xx -0.995
> # GLMM with STANDARDISED explanatory
> xxstan <- (xx-mean(xx))/sd(xx)
> glmer  <- glmer(response ~ xxstan + (1 | block), family=poisson)
> glmer
Generalized linear mixed model fit by the Laplace approximation 
Formula: response ~ xxstan + (1 | block) 
   AIC   BIC logLik deviance
 57.12 62.18 -25.56    51.12
Random effects:
 Groups Name        Variance Std.Dev.
 block  (Intercept) 0.28949  0.53804 
Number of obs: 40, groups: block, 10

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   0.9260     0.1995   4.640 3.48e-06 ***
xxstan        0.3597     0.1042   3.451  0.00056 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Correlation of Fixed Effects:
       (Intr)
xxstan -0.166
> q()

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
Zuckerberg
Sent: dinsdag 25 november 2008 14:46
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lme4 and false convergence

Dear R-users,

I am using the most updated package of lme4 (lme4_0.999375-2).  I have a
data set consisting of ~900 observations at ~440 independent survey
sites.  There are an unbalanced number of surveys at each site.  I am
attempting to develop several models evaluating the presence/absence of
a species (PRES) at these random sites (SITE) using a number of
predictor variables.  The response variable (PRES) is binomial and the
included predictor variables are either proportions (e.g., AG, FOR,
OPEN, LDEV,or DEV) or numerical (COUNT[min. 1 to max. 37,mean = 10]). 
---------------------------------------------------------------------
PROBLEM 1:

I have developed the following GLMM:

mix.1<-glmer(PRES~AG+FOR+OPEN+LDEV+DEV+COUNT+(1|SITE),family=binomial,da
ta=merge1) 


I receive the following error:
Warning message:
In mer_finalize(ans) : false convergence (8)

There is model output, but I am worried it might be biased.
I have tried:
-Data transformation of the predictor variables (e.g., log(COUNT)),
which does seem successful in some simpler models, but does not work
consistently.
-The most updated version of lme4

---------------------------------------------------------------------
PROBLEM #2:
In addition, I am interested in visualizing the predicted probabilities
from this output using the fixed effect function, but receive the
following message:

fixef(mix.1)
Error in UseMethod("fixef") : no applicable method for "fixef"

Any suggestions would be greatly appreciated!

--
Benjamin Zuckerberg, Ph.D.
Post-doctoral Associate
Spatial Ecologist, Citizen Science
Cornell Laboratory of Ornithology
159 Sapsucker Woods Road
Ithaca, NY 14850
Tele: 607-254-2174
Fax: 607-254-2111

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From a.renwick at abdn.ac.uk  Thu Nov 27 14:51:20 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Thu, 27 Nov 2008 13:51:20 +0000
Subject: [R-sig-ME] Likelihood test for random effect in a GLMM
Message-ID: <B9D1301370916C44B5874AF340C18B9B28AE890CDD@VMAILB.uoa.abdn.ac.uk>

Dear All
Many apologises for asking yet another question to the forum!
This time I am questioning the validity of using a likelihood test to test the significance of a random effect in a GLMM.  I am using GLMM for data with a binomial distribution and also with a poisson distribution.  I want to determine if the GLMM provides a better description of the data than the GLM therefore I used the following test:

#GLM
model<-glm(fleaburden~sex+width+sess+Nhat+alt+sex:width+sex:sess+sex:Nhat+sex:alt+width:sess+width:alt+sess:Nhat+sess:alt, family=poisson, data=flea, subset=-233)

#GLMM
bin<-lmer(fleaburden~sex+width+sess+Nhat+alt+sex:width+sex:sess+sex:Nhat+sex:alt+width:sess+width:alt+sess:Nhat+sess:alt+(1|LocTran), family=poisson, data=flea, REML=FALSE, subset=-233)

#use loglikelihood to test to see if sig difference between glm and glmm
as.numeric(2*(logLik(bin)-logLik(model)))
#940.5673
 pchisq(940.5673,1,lower=FALSE)
# 1.294078e-10

However, the p value obtained seems to exceedingly low and thus I was wondering if this is a reliable test to preform.

Many thanks,
Anna

Anna Renwick
Institute of Biological & Environment Sciences
University of Aberdeen
Zoology Building
Tillydrone Avenue
Aberdeen
AB24 2TZ


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From njbisaac at googlemail.com  Thu Nov 27 15:11:55 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Thu, 27 Nov 2008 14:11:55 +0000
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
Message-ID: <DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>


>> The issue is a bit more subtle than that.  You need to reinstall the
>> lme4 package after changing the version of the Matrix package.
>> There is a change in the internal code in the Matrix package between
>> -16 and -17.  The -16 version requires two versions of every function
>> in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
>> back to only one version.  However, lme4 must be reinstalled (in
>> particular, the C code must be recompiled) after a change in the
>> Matrix package.

On 28 Oct 2008, at 10:12, ONKELINX, Thierry wrote:
> Dear Douglas,
>
> Reinstalling lme4 from R-forge after removing it from the harddisk
> worked.
>
> Thank you,
>
> Thierry
>
>


I have come up against the same issue as Thierry, but Prof Bates'  
solution does not work for me. The problem seems to be at:

Matrix_stubs.c:494: error: conflicting types for ?M_R_cholmod_error?
cholmod.h:798: error: previous declaration of ?M_R_cholmod_error? was  
here

I have tried removing both lme4 and Matrix in a different order and  
by various means (deleting the folder in library vs remove.packages 
()). Most recently, I removed both lme4 and Matrix, emptied the trash  
then reinstalled Matrix from r-forge before quitting R and restarting  
my machine. On restarting R I tried:

 > install.packages("lme4",type="source",repos="http://r-forge.r- 
project.org")

A full transcript of the session is attached.

The attached is a full session history from the most recent attempt.  
I would be grateful for any suggestions.
Best wishes, Nick


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R Console.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081127/eb393dfd/attachment.txt>
-------------- next part --------------




 > sessionInfo()
R version 2.8.0 (2008-10-20)
i386-apple-darwin8.11.1

locale:
en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Matrix_0.999375-17 lattice_0.17-15

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0

 > install.packages("lme4",type="source",repos="http://r-forge.r- 
project.org")

>

From a.renwick at abdn.ac.uk  Thu Nov 27 15:15:36 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Thu, 27 Nov 2008 14:15:36 +0000
Subject: [R-sig-ME] Between and within variance in a GLMM
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
References: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
Message-ID: <B9D1301370916C44B5874AF340C18B9B28AE890CDF@VMAILB.uoa.abdn.ac.uk>

Sorry I missed an earlier posting on a similar question which answers my problem - see link below
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001175.html

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Renwick, A. R.
Sent: 26 November 2008 11:12
To: 'r-sig-mixed-models at r-project.org'
Subject: [R-sig-ME] Between and within variance in a GLMM


I have a wee query regarding the variation explained by the random effect in a GLMM using lme4 package.  In the model output I was under the assumption that the value given as Std Dev is the VARIANCE BETWEEN the random factor and the VARIANCE WITHIN could be calculated using the following equation:



Variance WITHIN = ST value x Variance BETWEEN.
Therefore, Variance WITHIN = ST value x Std Dev value in model output.

However, the ST value is always equal to the Std Dev given in model output so can someone clarify how to calulate the within and between variance of the random effect.

EXAMPLE:

Generalized linear mixed model fit by the Laplace approximation
Formula: fleapresence ~ sex + width + sess + Nhat + alt + width:sess +      (1 | LocTran)
   Data: flea
  AIC  BIC logLik deviance
 1797 1863 -886.7     1773
Random effects:
 Groups  Name        Variance Std.Dev.
 LocTran (Intercept) 0.10512  0.32422
Number of obs: 1697, groups: LocTran, 14


  ..@ ST      :List of 1
  .. ..$ : num [1, 1] 0.324


Thanks
Anna

Anna Renwick
Institute of Biological & Environment Sciences University of Aberdeen Zoology Building Tillydrone Avenue Aberdeen
AB24 2TZ


The University of Aberdeen is a charity registered in Scotland, No SC013683.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From bates at stat.wisc.edu  Thu Nov 27 16:39:05 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Nov 2008 09:39:05 -0600
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
	<DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>
Message-ID: <40e66e0b0811270739k7a29b000kb7b3c0041f0ddd31@mail.gmail.com>

Is anyone else encountering this problem?  It looks like Mac OS X and
apparently a problem with the Matrix package declarations.  It is a
trivial-enough problem, a declaration of an argument as "const char*"
in one case and "char*" in another but I don't know which installed
version of the Matrix package this occurs in.

On Thu, Nov 27, 2008 at 8:11 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>
>>> The issue is a bit more subtle than that.  You need to reinstall the
>>> lme4 package after changing the version of the Matrix package.
>>> There is a change in the internal code in the Matrix package between
>>> -16 and -17.  The -16 version requires two versions of every function
>>> in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
>>> back to only one version.  However, lme4 must be reinstalled (in
>>> particular, the C code must be recompiled) after a change in the
>>> Matrix package.
>
> On 28 Oct 2008, at 10:12, ONKELINX, Thierry wrote:
>>
>> Dear Douglas,
>>
>> Reinstalling lme4 from R-forge after removing it from the harddisk
>> worked.
>>
>> Thank you,
>>
>> Thierry
>>
>>
>
>
> I have come up against the same issue as Thierry, but Prof Bates' solution
> does not work for me. The problem seems to be at:
>
> Matrix_stubs.c:494: error: conflicting types for 'M_R_cholmod_error'
> cholmod.h:798: error: previous declaration of 'M_R_cholmod_error' was here
>
> I have tried removing both lme4 and Matrix in a different order and by
> various means (deleting the folder in library vs remove.packages()). Most
> recently, I removed both lme4 and Matrix, emptied the trash then reinstalled
> Matrix from r-forge before quitting R and restarting my machine. On
> restarting R I tried:
>
>>
>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>
> A full transcript of the session is attached.
>
> The attached is a full session history from the most recent attempt. I would
> be grateful for any suggestions.
> Best wishes, Nick
>
>
>
>
>
>
>
>> sessionInfo()
> R version 2.8.0 (2008-10-20)
> i386-apple-darwin8.11.1
>
> locale:
> en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Matrix_0.999375-17 lattice_0.17-15
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.0  tools_2.8.0
>
>>
>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>
>>
>
>



From danielezrajohnson at gmail.com  Thu Nov 27 17:15:02 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 27 Nov 2008 16:15:02 +0000
Subject: [R-sig-ME] Between and within variance in a GLMM
In-Reply-To: <B9D1301370916C44B5874AF340C18B9B28AE890CDF@VMAILB.uoa.abdn.ac.uk>
References: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
	<B9D1301370916C44B5874AF340C18B9B28AE890CDF@VMAILB.uoa.abdn.ac.uk>
Message-ID: <a46630750811270815v2790ea34v4f8e043f54a90498@mail.gmail.com>

I've done a very quick test of this issue of deviance() vs. logLik(),
using a simpler model than the type illustrated in the link
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001175.html.

For glmer() whether its a "gaussian" or "binomial" model,
deviance(mod) equals -2*logLik(mod).

For glm() the same is true if it's a "binomial" model.

For a "gaussian" glm() model, the two quantities are different. i
believe that deviance() gives the residual sum of squares, and that
logLik() gives ... a scaled deviance? I don't know.

Contrary to what was said above, I think that logLik() of a glm()
gaussian model is the quantity that is comparable to logLik() or
deviance() of a glmer() gaussian model.

Dan



From bates at stat.wisc.edu  Thu Nov 27 18:06:01 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Nov 2008 11:06:01 -0600
Subject: [R-sig-ME] Between and within variance in a GLMM
In-Reply-To: <a46630750811270815v2790ea34v4f8e043f54a90498@mail.gmail.com>
References: <B9D1301370916C44B5874AF340C18B9B28ADB43DE1@VMAILB.uoa.abdn.ac.uk>
	<B9D1301370916C44B5874AF340C18B9B28AE890CDF@VMAILB.uoa.abdn.ac.uk>
	<a46630750811270815v2790ea34v4f8e043f54a90498@mail.gmail.com>
Message-ID: <40e66e0b0811270906wa9122b8pa72d81f757afde01@mail.gmail.com>

I believe this discrepancy is related to the common scale parameter,
sigma, in the Gaussian model.

When I wrote the code for the Gaussian mixed model I realized that I
could profile out both the fixed effects and one scale parameter so
the deviance or the REML criterion are evaluated as functions only of
the parameters that determine the covariance matrix of the random
effects.

The glm families define "deviance residuals" whose sum is related to
the deviance but is not the same as the deviance.  The deviance and
the log-likelihood are defined in the AIC function in the family
(which, by the way, returns NA for the quasi families).  I imagine
this is all documented somewhere but I, for one, find it rather
confusing.  I am still sorting it out, which typically means that I
need to derive it from scratch.  Some progress is being made in that I
now understand the iteratively reweighted least squares algorithm and
its generalization, penalized iteratively reweighted least squares
(PIRLS), for generalized linear mixed models.  I think I know how to
define the deviance for binomial (Bernoulli) or Poisson GLMMs and that
there isn't a deviance for the quasi families.  The Gamma family is
giving me problems because one of the properties that I thought
applied to the link function - mapping the allowable range of the mean
to the entire real line - doesn't apply to the canonical link
function, which is the reciprocal.


On Thu, Nov 27, 2008 at 10:15 AM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> I've done a very quick test of this issue of deviance() vs. logLik(),
> using a simpler model than the type illustrated in the link
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001175.html.
>
> For glmer() whether its a "gaussian" or "binomial" model,
> deviance(mod) equals -2*logLik(mod).
>
> For glm() the same is true if it's a "binomial" model.
>
> For a "gaussian" glm() model, the two quantities are different. i
> believe that deviance() gives the residual sum of squares, and that
> logLik() gives ... a scaled deviance? I don't know.
>
> Contrary to what was said above, I think that logLik() of a glm()
> gaussian model is the quantity that is comparable to logLik() or
> deviance() of a glmer() gaussian model.
>
> Dan
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bendantzer at gmail.com  Fri Nov 28 17:49:59 2008
From: bendantzer at gmail.com (Benjamin Dantzer)
Date: Fri, 28 Nov 2008 11:49:59 -0500
Subject: [R-sig-ME] Likelihood test for random effect in a GLMM
Message-ID: <65D4F748-F3E7-4366-B334-35FA87C21EDF@gmail.com>

I am doing very similar analyses and get similar results (enormously  
low P-values) when I compare a GLMM to GLM using the LRT.

However, from my earlier search for an answer to the question such as  
yours, I thought that glmms  (glmer) are fit using ML and glm ONLY via  
REML?  So that a LRT is not appropriate. But I cannot provide a  
complete answer here.

See the following:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001180.html

-Ben Dantzer
_______________________________________
Benjamin J. Dantzer
PhD Candidate

Ecology, Evolutionary Biology, and Behavior Program
Department of Zoology
203 Natural Science Building
Michigan State University
East Lansing, MI 48824-1115

Lab Phone: 517-432-5555
Web:	http://www.msu.edu/~dantzer
		http://www.redsquirrel.msu.edu



From h.wickham at gmail.com  Fri Nov 28 18:02:22 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 28 Nov 2008 11:02:22 -0600
Subject: [R-sig-ME] Likelihood test for random effect in a GLMM
In-Reply-To: <65D4F748-F3E7-4366-B334-35FA87C21EDF@gmail.com>
References: <65D4F748-F3E7-4366-B334-35FA87C21EDF@gmail.com>
Message-ID: <f8e6ff050811280902n4072c8dejeb0c16216c002d51@mail.gmail.com>

On Fri, Nov 28, 2008 at 10:49 AM, Benjamin Dantzer <bendantzer at gmail.com> wrote:
> I am doing very similar analyses and get similar results (enormously low
> P-values) when I compare a GLMM to GLM using the LRT.
>
> However, from my earlier search for an answer to the question such as yours,
> I thought that glmms  (glmer) are fit using ML and glm ONLY via REML?  So
> that a LRT is not appropriate. But I cannot provide a complete answer here.
>
> See the following:
>
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001180.html

In general, I think it's a *VERY* bad idea to compare log-likelihoods
produced by different modelling functions.  Unless you are completely
sure that the likelihoods are defined in the exactly same way (i.e.
that the same constants have been dropped, or not), you are unlikely
to get meaningful results.

I think that the model that the original poster provided could more
clearly be written as:

fleaburden ~ (sex + width + sess + Nhat + alt) ^ 2

(andcodeismucheasiertoreadifyouusespaces)


Hadley

-- 
http://had.co.nz/



From bates at stat.wisc.edu  Fri Nov 28 19:47:04 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 28 Nov 2008 12:47:04 -0600
Subject: [R-sig-ME] lme4 and false convergence
In-Reply-To: <1F4755565F237F45AA01135B72E8C1B201554964@scomp0039.wurnet.nl>
References: <492C01B3.4000300@cornell.edu>
	<1F4755565F237F45AA01135B72E8C1B201554964@scomp0039.wurnet.nl>
Message-ID: <40e66e0b0811281047v7aa802c2g992950683bc5c2f1@mail.gmail.com>

On Thu, Nov 27, 2008 at 2:07 AM, Goedhart, Paul <paul.goedhart at wur.nl> wrote:
> I had a similar problem which disappeared after standardizing the
> predictor variables. Apparently there is some numerical instability
> within LME4.

I think a case could be made for the numerical instability being in
the model definition, not in lme4.

> Below you will find a simulated example for a loglinear
> model.
>
> Paul W. Goedhart
> Biometris,  Wageningen UR,  Postbus 100,  6700 AC Wageningen, The
> Netherlands
>
>> require(lme4)
> Loading required package: lme4
> Loading required package: Matrix
> Loading required package: lattice
>
> Attaching package: 'Matrix'
>
>
>        The following object(s) are masked from package:stats :
>
>         xtabs
>
> Warning messages:
> 1: package 'lme4' was built under R version 2.7.2
> 2: package 'Matrix' was built under R version 2.7.2
>> # Simulate counts for a block design with a random blockeffect
>> set.seed(93923142)
>> nblock <- 10
>> nplot  <- 4
>> nunit  <- nblock * nplot
>> block  <- rep(1:nblock, each=nplot)
>> plot   <- rep(1:nplot, nblock)
>> rmean  <- 25000
>> beta   <- 10/rmean
>> xx     <- round(rnorm(nunit, mean=rmean, sd=1000))
>> rblock <- rep(rnorm(nblock, mean=0, sd=0.5), each=nplot)
>> lp     <-  -9 + beta * xx
>> mu     <- exp(lp + rblock)
>> response <- mu
>> for (ii in 1:nunit)
> +   {
> +   response[ii] <- rpois(1, mu[ii])
> +   }
>> # GLMM with UN-STANDARDISED explanatory
>> mean(xx)
> [1] 24897.15
>> glmer  <- glmer(response ~ xx + (1 | block), family=poisson)
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>> glmer
> Generalized linear mixed model fit by the Laplace approximation
> Formula: response ~ xx + (1 | block)
>   AIC   BIC logLik deviance
>  59.16 64.23 -26.58    53.16
> Random effects:
>  Groups Name        Variance Std.Dev.
>  block  (Intercept) 0.66667  0.8165
> Number of obs: 40, groups: block, 10
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.025e+01  2.915e+00  -3.517 0.000437 ***
> xx           4.454e-04  1.151e-04   3.872 0.000108 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>   (Intr)
> xx -0.995
>> # GLMM with STANDARDISED explanatory
>> xxstan <- (xx-mean(xx))/sd(xx)
>> glmer  <- glmer(response ~ xxstan + (1 | block), family=poisson)
>> glmer
> Generalized linear mixed model fit by the Laplace approximation
> Formula: response ~ xxstan + (1 | block)
>   AIC   BIC logLik deviance
>  57.12 62.18 -25.56    51.12
> Random effects:
>  Groups Name        Variance Std.Dev.
>  block  (Intercept) 0.28949  0.53804
> Number of obs: 40, groups: block, 10
>
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)   0.9260     0.1995   4.640 3.48e-06 ***
> xxstan        0.3597     0.1042   3.451  0.00056 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>       (Intr)
> xxstan -0.166
>> q()
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
> Zuckerberg
> Sent: dinsdag 25 november 2008 14:46
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme4 and false convergence
>
> Dear R-users,
>
> I am using the most updated package of lme4 (lme4_0.999375-2).  I have a
> data set consisting of ~900 observations at ~440 independent survey
> sites.  There are an unbalanced number of surveys at each site.  I am
> attempting to develop several models evaluating the presence/absence of
> a species (PRES) at these random sites (SITE) using a number of
> predictor variables.  The response variable (PRES) is binomial and the
> included predictor variables are either proportions (e.g., AG, FOR,
> OPEN, LDEV,or DEV) or numerical (COUNT[min. 1 to max. 37,mean = 10]).
> ---------------------------------------------------------------------
> PROBLEM 1:
>
> I have developed the following GLMM:
>
> mix.1<-glmer(PRES~AG+FOR+OPEN+LDEV+DEV+COUNT+(1|SITE),family=binomial,da
> ta=merge1)
>
>
> I receive the following error:
> Warning message:
> In mer_finalize(ans) : false convergence (8)
>
> There is model output, but I am worried it might be biased.
> I have tried:
> -Data transformation of the predictor variables (e.g., log(COUNT)),
> which does seem successful in some simpler models, but does not work
> consistently.
> -The most updated version of lme4
>
> ---------------------------------------------------------------------
> PROBLEM #2:
> In addition, I am interested in visualizing the predicted probabilities
> from this output using the fixed effect function, but receive the
> following message:
>
> fixef(mix.1)
> Error in UseMethod("fixef") : no applicable method for "fixef"
>
> Any suggestions would be greatly appreciated!
>
> --
> Benjamin Zuckerberg, Ph.D.
> Post-doctoral Associate
> Spatial Ecologist, Citizen Science
> Cornell Laboratory of Ornithology
> 159 Sapsucker Woods Road
> Ithaca, NY 14850
> Tele: 607-254-2174
> Fax: 607-254-2111
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tura at centroin.com.br  Sun Nov 30 16:06:37 2008
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Sun, 30 Nov 2008 13:06:37 -0200
Subject: [R-sig-ME] A complex mixed model
Message-ID: <1228057597.26456.31.camel@R1-Thux>

Hi R-Masters!

I need create a model for predicting a risk of death in heart surgery in
my country. The problem is a very complex nature of the problem.

Essentially the model of risk of death is
 
Risk(death) ~ risk(patient) + risk(surgery) + risk(site) + error1 

but

Risk(patient) ~ clinical variables + error2

Risk(surgery) ~ procedure variables + (Risk(patient)|type) + error3

Risk(site) ~ site + (Risk(surgery)|site)+ (Risk(patient)|site) + error4


A fake database is 

site<-sample(rep(LETTERS[1:4],500))
death<-factor(rbinom(2000,1,.16))
cirR<-ifelse(death==1,rbinom(2000,1,.05),rbinom(2000,1,.6))
cirV<-ifelse(cirR==1,rbinom(2000,1,.07),rbinom(2000,1,.7))
type<-factor(cirR+2*cirV)
age<-ifelse(death==1,rpois(2000,55),rpois(2000,30))
sex<-factor(ifelse(death==1,rbinom(2000,1,.4),rbinom(2000,1,.1)))
urg<-factor(ifelse(death==1,rbinom(2000,1,.5),rbinom(2000,1,.01)))
surg<-data.frame(site,cirR,cirV,type,age,sex,urg,death)

in this case

Risk(death) ~ risk(patient) + risk(surgery) + risk(site) + error1

Risk(patient) ~ age + sex + error2

Risk(surgery) ~ type + urg + (Risk(patient)|type) + error3

Risk(site) ~ site + (Risk(surgery)|site) + (Risk(patient)|site) + error4

I am having trouble to write a correct formula for this model. It would
be nice to count with your help.  

-- 
Bernardo Rangel Tura, M.D,MPH,Ph.D
National Institute of Cardiology
Brazil



From mjuanjorda at gmail.com  Mon Dec  1 18:32:01 2008
From: mjuanjorda at gmail.com (Maria Jose Juan Jorda)
Date: Mon, 1 Dec 2008 18:32:01 +0100
Subject: [R-sig-ME] it is difficult to deal with within-group errors
	heteroscedasticity
Message-ID: <9bcbdf360812010932y340ff108mb19eb6984e9fd7f1@mail.gmail.com>

Dear Mixed list:

I am trying to fit a mixed linear model, particularly, a longitudinal study
with the lme function and I am really need some advise..... My question is
about how to deal with the within-group errors heteroscedasticity. This is
my first mixed model so the learning curve is high.


First I give you background with my model.

1)  I am trying to quantify how the mean length of different species of fish
are changing over time. However, I do not have one time series of main size
over time for each specie. What I have it is many time series for each
specie because those species are fished with different gears. So each time
series belongs to a different fishing gear and then many time series of
fishing gears belong to a specie. Not all the species are fished with the
same gears. So there are different number of time series for each specie.

I have attached figure 1 with the data if you want to see.

This is my basic model:

model3<-lme(meansize~year*stock,random=~year|id, data=cas)

Variables:
meansize: mean length of the fish, continuous variable
year: the years, continuous variable
stock: 3 species of fish, categorical variable.
id: it is the variable identifying each of the time series.

So in this model I am interested in estimating a mean intercept and a mean
slope for each specie and quantify how much the mean size of the specie has
change over time and see what species are decreasing more. I am treating
each of the time series of the gears as random effects. In my head I am
imaging an experiment where I have random fishing gears fishing in the ocean
and they are a random sample which will tell me if mean size of fish are
decreasing or increasing over time. Well, in reality, they are not random
samples, this is the real data that exist but i am treating them as random.
Any comments about this?

Now there are not predictors in  the model, because first I want to quantify
how much the species have decreae/increase over time, but in the future i
will add predictors  such us level of fishing exploitation or the biology of
the specie to explain why some species decrease more than others.

1)  This is the sessionInfo()
R version 2.8.0 (2008-10-20)
i386-pc-mingw32
[1] nlme_3.1-89


2) The first modification of the model is to account for the fact that some
gear catch more quantity of fish than others so I want to give more weights
to the gears that fish more and less weights to the gears that fish less
fish. So I have a variable the it is number of fish for each year, gear and
specie.
-the variable called w are the weights from 0 to 1, to give more importance
to the gear catching more fish.

this will be my model:
model3.1<-lme(meansize~year*stock,random=~year|id,
data=cas,weights=varFixed(~1/w), method="ML")

So this is the model I would choose following my logic and my needs.

So now my problems:

1) I compared model3 with model3.1  which have the same fix effects.

> anova(model3,model3.1)
         Model df      AIC      BIC    logLik
model3       1 10 6532.240 6580.253 -3256.120
model3.1     2 10 7876.156 7924.169 -3928.078

and the AIC  suggest selecting model 3.

But the research question tells me to choose model3.1 because for me it is
important to give more weights to the gears fishing more.

So what do I do?

I imagine to follow my research question but...it gets more complicated....


2) Problem 2
I explored the residuals and the normality assuption of model 3 and
model3.1.

plot(model3, form=resid(., type="p")~fitted(.)| stock,abline=0,
ylim=c(-10,10))
plot(model3.1, form=resid(., type="p")~fitted(.)| stock,abline=0,
ylim=c(-10,10))
qqnorm(resid(model3,type="p"),cex=1,main="")
qqnorm(resid(model3.1,type="p"),cex=1,main="")

and it is clear, the variance is not the same across groups (here stocks).
The residuals suggest to use different variance components for each species,
and the qq plots are horrible, it does not follow the normality assumption
for any of the models.


So I did two things:

-I added to model 3 the varIdent function to account for the different
variance across groups.
model3.6<-lme(meansize~year*stock,random=~year|id,
data=cas,weights=varIdent(form=~1|stock),
control=list(maxIter=500, msMaxIter=500, niterEM=500))

-I added to model3.1 the varIdent function too. So now I am using the
function VarComb to take into account two things 1) give more importance to
gears fishing more wth varFixed and 2) to take into account the variance
across the 3 species (3 groups)

model3.9<-lme(meansize~year*stock,random=~year|id,
data=cas,weights=varComb(varFixed(~1/w),varIdent(form=~1|stock)),control=list(maxIter=500,
msMaxIter=500, niterEM=500))


Now I explore the residuals for both models (model3.6 and model3.9). the
residuals for each group look better for model 3.9 than model 3.6, in model
3.9 they do not follow any clear trend. But the qq plot still looks bad for
both models,the normality plot is distinctly curved for both models. I have
attached QQplot model3.9. Basically I don?t know what to do or how to
follow.

I compare the two models (below) and the AIC suggest to choose the model 3.6
and looking at my residual plots I would chose model3.9 over model3.6.

anova(model3.6,model3.9)> anova(model3.6,model3.9)
         Model df      AIC      BIC    logLik
model3.6     1 12 5893.051 5950.667 -2934.526
model3.9     2 12 7599.363 7656.978 -3787.681


So I am confused here, can anybody give me some advise?


I would choose model3.9, one because the residuals look better (but still I
have the problem with the QQplot that I don?t know how to solve the problem)
and two because following my research question I NEED and I WANT to give
more weights to the gears catching more fish.

But when I compare the two models, the AIC and the BIC and the loglik
suggest to choose the mode3.6 where I am not taking into account the weights
for the gears and the residuals look bad.


I have attached the data and the code to reproduce everything in a fast way.

I would appreciate any help of how to proceed, I don?t know who else to ask.

Thanks  and thanks in advance.

Maria Jose









The right-hand plot
shows the highly non-normal distribution of errors.
-- 
>))):)   >))):)   >))):)   >))):)   >))):)   >))):)   >))):)   >))):)

Maria Jose Juan Jorda

AZTI - Tecnalia / Unidad de Investigaci?n Marina
Herrera Kaia Portualde z/g
20110 Pasaia, Gipuzkoa, Spain

Recursos Marinos y Pesquerias
Depart. Biologia Animal, Vegetal y Ecologia
Universidade A Coru?a
Campus A Zapateira s/n
15071, A Coru?a, Spain

Tel. Oficina +34-981167000 ext. 2204
Tel. Mobil + 34-671072900
Fax. +34981167065
mjuan at pas.azti.es
mjuanjorda at gmail.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Figure_one.pdf
Type: application/pdf
Size: 82812 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081201/1d683428/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: QQplot_model3.9.pdf
Type: application/pdf
Size: 64370 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081201/1d683428/attachment-0001.pdf>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Forum_linear_mixed_model.r
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081201/1d683428/attachment.pl>

From datkins at fuller.edu  Mon Dec  1 19:26:05 2008
From: datkins at fuller.edu (Dave Atkins)
Date: Mon, 01 Dec 2008 10:26:05 -0800
Subject: [R-sig-ME] [Fwd: Re: Matrix broken on Mac...]
Message-ID: <49342C3D.8040902@fuller.edu>


[whoops, first sent this from my current email, which the listserv 
didn't recognize.  apologies if this comes through twice.]

Doug--

You had inquired whether anyone else was having problems with Matrix on
a Mac... yep.  I am.  You'll see below that I removed both lme4 and
Matrix, re-install from r-forge, but get an error msg.  sessionInfo() at
bottom.

Could someone point me to an earlier version of Matrix?  I don't believe
I had this problem prior to the most recent update.

cheers, Dave

Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu


> remove.packages("Matrix")
Warning in remove.packages("Matrix") :
   argument 'lib' is missing: using
/Library/Frameworks/R.framework/Resources/library
> remove.packages("lme4")
Warning in remove.packages("lme4") :
   argument 'lib' is missing: using
/Library/Frameworks/R.framework/Resources/library
> install.packages("Matrix", repos = "http://r-forge.r-project.org")
trying URL
'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/Matrix_0.999375-17.tgz'
Content type 'application/x-gzip' length 2740286 bytes (2.6 Mb)
opened URL
==================================================
downloaded 2.6 Mb


The downloaded packages are in
	/var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
> install.packages("lme4", repos = "http://r-forge.r-project.org")
trying URL
'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/lme4_0.999375-27.tgz'
Content type 'application/x-gzip' length 913761 bytes (892 Kb)
opened URL
==================================================
downloaded 892 Kb


The downloaded packages are in
	/var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
> library(lme4)
Loading required package: Matrix
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared library
'/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':

dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so, 

6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
   Referenced from:
/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
   Reason: image not found
Error: package 'Matrix' could not be loaded
> sessionInfo()
R version 2.8.0 (2008-10-20)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.17-17

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0



From datkins at u.washington.edu  Mon Dec  1 19:23:30 2008
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 01 Dec 2008 10:23:30 -0800
Subject: [R-sig-ME] Matrix broken on Mac...
In-Reply-To: <mailman.954.1228154120.4348.r-sig-mixed-models@r-project.org>
References: <mailman.954.1228154120.4348.r-sig-mixed-models@r-project.org>
Message-ID: <49342BA2.2050503@u.washington.edu>


Doug--

You had inquired whether anyone else was having problems with Matrix on 
a Mac... yep.  I am.  You'll see below that I removed both lme4 and 
Matrix, re-install from r-forge, but get an error msg.  sessionInfo() at 
bottom.

Could someone point me to an earlier version of Matrix?  I don't believe 
I had this problem prior to the most recent update.

cheers, Dave

Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu


 > remove.packages("Matrix")
Warning in remove.packages("Matrix") :
   argument 'lib' is missing: using 
/Library/Frameworks/R.framework/Resources/library
 > remove.packages("lme4")
Warning in remove.packages("lme4") :
   argument 'lib' is missing: using 
/Library/Frameworks/R.framework/Resources/library
 > install.packages("Matrix", repos = "http://r-forge.r-project.org")
trying URL 
'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/Matrix_0.999375-17.tgz'
Content type 'application/x-gzip' length 2740286 bytes (2.6 Mb)
opened URL
==================================================
downloaded 2.6 Mb


The downloaded packages are in
	/var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
 > install.packages("lme4", repos = "http://r-forge.r-project.org")
trying URL 
'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/lme4_0.999375-27.tgz'
Content type 'application/x-gzip' length 913761 bytes (892 Kb)
opened URL
==================================================
downloaded 892 Kb


The downloaded packages are in
	/var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
 > library(lme4)
Loading required package: Matrix
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared library 
'/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
 
dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so, 
6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
   Referenced from: 
/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
   Reason: image not found
Error: package 'Matrix' could not be loaded
 > sessionInfo()
R version 2.8.0 (2008-10-20)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.17-17

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0



From bates at stat.wisc.edu  Mon Dec  1 19:45:09 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 1 Dec 2008 12:45:09 -0600
Subject: [R-sig-ME] [Fwd: Re: Matrix broken on Mac...]
In-Reply-To: <49342C3D.8040902@fuller.edu>
References: <49342C3D.8040902@fuller.edu>
Message-ID: <40e66e0b0812011045x34278b0am3250d361d213e0ba@mail.gmail.com>

Does

library(Matrix)

without any reference to lme4 work for you?

The other person who was having difficulty loading the Matrix package
on a Mac was able to resolve the problem although I forget the details
of how it was resolved.

The messages indicate that the problem is more with Matrix than with lme4.

On Mon, Dec 1, 2008 at 12:26 PM, Dave Atkins <datkins at fuller.edu> wrote:
>
> [whoops, first sent this from my current email, which the listserv didn't
> recognize.  apologies if this comes through twice.]

And it did come through twice.  I read the messages in the wrong order
and authorized the posting from the other address before reading this
message.  Sorry for the extra noise.

> Doug--
>
> You had inquired whether anyone else was having problems with Matrix on
> a Mac... yep.  I am.  You'll see below that I removed both lme4 and
> Matrix, re-install from r-forge, but get an error msg.  sessionInfo() at
> bottom.
>
> Could someone point me to an earlier version of Matrix?  I don't believe
> I had this problem prior to the most recent update.
>
> cheers, Dave
>
> Dave Atkins, PhD
> Research Associate Professor
> Center for the Study of Health and Risk Behaviors
> Department of  Psychiatry and Behavioral Science
> 1100 NE 45th Street, Suite 300
> Seattle, WA  98105
> 206-616-3879
> datkins at u.washington.edu
>
>
>> remove.packages("Matrix")
>
> Warning in remove.packages("Matrix") :
>  argument 'lib' is missing: using
> /Library/Frameworks/R.framework/Resources/library
>>
>> remove.packages("lme4")
>
> Warning in remove.packages("lme4") :
>  argument 'lib' is missing: using
> /Library/Frameworks/R.framework/Resources/library
>>
>> install.packages("Matrix", repos = "http://r-forge.r-project.org")
>
> trying URL
> 'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/Matrix_0.999375-17.tgz'
> Content type 'application/x-gzip' length 2740286 bytes (2.6 Mb)
> opened URL
> ==================================================
> downloaded 2.6 Mb
>
>
> The downloaded packages are in
>
>  /var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
>>
>> install.packages("lme4", repos = "http://r-forge.r-project.org")
>
> trying URL
> 'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/lme4_0.999375-27.tgz'
> Content type 'application/x-gzip' length 913761 bytes (892 Kb)
> opened URL
> ==================================================
> downloaded 892 Kb
>
>
> The downloaded packages are in
>
>  /var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
>>
>> library(lme4)
>
> Loading required package: Matrix
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared library
> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>
> dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
> 6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
>  Referenced from:
> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>  Reason: image not found
> Error: package 'Matrix' could not be loaded
>>
>> sessionInfo()
>
> R version 2.8.0 (2008-10-20)
> i386-apple-darwin8.11.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lattice_0.17-17
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.0  tools_2.8.0
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at fuller.edu  Mon Dec  1 20:39:18 2008
From: datkins at fuller.edu (Dave Atkins)
Date: Mon, 01 Dec 2008 11:39:18 -0800
Subject: [R-sig-ME] [Fwd: Re: Matrix broken on Mac...]
In-Reply-To: <40e66e0b0812011045x34278b0am3250d361d213e0ba@mail.gmail.com>
References: <49342C3D.8040902@fuller.edu>
	<40e66e0b0812011045x34278b0am3250d361d213e0ba@mail.gmail.com>
Message-ID: <49343D66.1080805@fuller.edu>



Douglas Bates wrote:
> Does
> 
> library(Matrix)
> 
> without any reference to lme4 work for you?

No, if I start a fresh R session and call Matrix on its own, I get:

 > library(Matrix)
Loading required package: lattice
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared library 
'/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
 
dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so, 
6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
   Referenced from: 
/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
   Reason: image not found
Error: package/namespace load failed for 'Matrix'

 > sessionInfo()
R version 2.8.0 (2008-10-20)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.17-17

loaded via a namespace (and not attached):
[1] grid_2.8.0
 >

Any ideas?  Anything else I can pass along?

thanks, Dave

> 
> The other person who was having difficulty loading the Matrix package
> on a Mac was able to resolve the problem although I forget the details
> of how it was resolved.
> 
> The messages indicate that the problem is more with Matrix than with lme4.
> 
> On Mon, Dec 1, 2008 at 12:26 PM, Dave Atkins <datkins at fuller.edu> wrote:
>> [whoops, first sent this from my current email, which the listserv didn't
>> recognize.  apologies if this comes through twice.]
> 
> And it did come through twice.  I read the messages in the wrong order
> and authorized the posting from the other address before reading this
> message.  Sorry for the extra noise.
> 
>> Doug--
>>
>> You had inquired whether anyone else was having problems with Matrix on
>> a Mac... yep.  I am.  You'll see below that I removed both lme4 and
>> Matrix, re-install from r-forge, but get an error msg.  sessionInfo() at
>> bottom.
>>
>> Could someone point me to an earlier version of Matrix?  I don't believe
>> I had this problem prior to the most recent update.
>>
>> cheers, Dave
>>
>> Dave Atkins, PhD
>> Research Associate Professor
>> Center for the Study of Health and Risk Behaviors
>> Department of  Psychiatry and Behavioral Science
>> 1100 NE 45th Street, Suite 300
>> Seattle, WA  98105
>> 206-616-3879
>> datkins at u.washington.edu
>>
>>
>>> remove.packages("Matrix")
>> Warning in remove.packages("Matrix") :
>>  argument 'lib' is missing: using
>> /Library/Frameworks/R.framework/Resources/library
>>> remove.packages("lme4")
>> Warning in remove.packages("lme4") :
>>  argument 'lib' is missing: using
>> /Library/Frameworks/R.framework/Resources/library
>>> install.packages("Matrix", repos = "http://r-forge.r-project.org")
>> trying URL
>> 'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/Matrix_0.999375-17.tgz'
>> Content type 'application/x-gzip' length 2740286 bytes (2.6 Mb)
>> opened URL
>> ==================================================
>> downloaded 2.6 Mb
>>
>>
>> The downloaded packages are in
>>
>>  /var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
>>> install.packages("lme4", repos = "http://r-forge.r-project.org")
>> trying URL
>> 'http://r-forge.r-project.org/bin/macosx/universal/contrib/2.8/lme4_0.999375-27.tgz'
>> Content type 'application/x-gzip' length 913761 bytes (892 Kb)
>> opened URL
>> ==================================================
>> downloaded 892 Kb
>>
>>
>> The downloaded packages are in
>>
>>  /var/folders/eF/eFm91WFiEm8IX1HSzMCn4E+++TI/-Tmp-//RtmpVgGfBC/downloaded_packages
>>> library(lme4)
>> Loading required package: Matrix
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>  unable to load shared library
>> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>>
>> dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
>> 6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
>>  Referenced from:
>> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>>  Reason: image not found
>> Error: package 'Matrix' could not be loaded
>>> sessionInfo()
>> R version 2.8.0 (2008-10-20)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lattice_0.17-17
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.8.0  tools_2.8.0
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From Leonardo.Lancia at univ-provence.fr  Wed Dec  3 12:03:02 2008
From: Leonardo.Lancia at univ-provence.fr (Leonardo LANCIA)
Date: Wed, 3 Dec 2008 12:03:02 +0100 (CET)
Subject: [R-sig-ME] Logisting regression for same-different speaker
	classification
In-Reply-To: <mailman.5.1228215601.3552.r-sig-mixed-models@r-project.org>
References: <mailman.5.1228215601.3552.r-sig-mixed-models@r-project.org>
Message-ID: <9555723.429.1228302182606.JavaMail.root@frontal1>

Dear List,

I would like to use a mixed logistic regression model as a classifier which decides if two speech signals representing two istances of the same phoneme (uttered in a specified phentic context) are produced by the same speaker or not. To do that I should use a huge number of predictors (more or less 50 acoustic features). More over, for each acoustic feature I should specify a random interaction with the following factors : the phonetic label attached to the acoustic signals, and a phonetic label correspoding to the context from which the acoustic signals are extracted. 
I am not interested in hypotesis testing but I would like to have an estimation of the contributoin to this task of each of the predictors and an estimate of the correction coefficients associated to the random effects.
Do you think that a mixed logistic regression would do the job or should I move to Support vector machines algorithms?

Leonardo Lancia



From lamprianou at yahoo.com  Fri Dec  5 23:10:57 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 5 Dec 2008 14:10:57 -0800 (PST)
Subject: [R-sig-ME] lmer
In-Reply-To: <mailman.5.1228388401.9984.r-sig-mixed-models@r-project.org>
Message-ID: <111312.17432.qm@web54111.mail.re2.yahoo.com>

Dear friends, 
does anyone know how (if) I can run a multilevel Partial Credit Rasch model using lmer? I am aware of the "Estimating the Multilevel Rasch Model: With the lme4 Package" but I think that this only refers to the dichotomous Rasch case. Or, alternatively, redirect me to any other free package that can handle multilevel Rasch/IRT models. 
Thanks

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Thu, 4/12/08, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 24, Issue 4
> To: r-sig-mixed-models at r-project.org
> Date: Thursday, 4 December, 2008, 11:00 AM
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body
> 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models
> digest..."
> 
> 
> Today's Topics:
> 
>    1. Logisting regression for same-different speaker
>       classification (Leonardo LANCIA)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Wed, 3 Dec 2008 12:03:02 +0100 (CET)
> From: Leonardo LANCIA
> <Leonardo.Lancia at univ-provence.fr>
> Subject: [R-sig-ME] Logisting regression for same-different
> speaker
> 	classification
> To: r-sig-mixed-models at r-project.org
> Message-ID:
> <9555723.429.1228302182606.JavaMail.root at frontal1>
> Content-Type: text/plain; charset=iso-8859-1
> 
> Dear List,
> 
> I would like to use a mixed logistic regression model as a
> classifier which decides if two speech signals representing
> two istances of the same phoneme (uttered in a specified
> phentic context) are produced by the same speaker or not. To
> do that I should use a huge number of predictors (more or
> less 50 acoustic features). More over, for each acoustic
> feature I should specify a random interaction with the
> following factors : the phonetic label attached to the
> acoustic signals, and a phonetic label correspoding to the
> context from which the acoustic signals are extracted. 
> I am not interested in hypotesis testing but I would like
> to have an estimation of the contributoin to this task of
> each of the predictors and an estimate of the correction
> coefficients associated to the random effects.
> Do you think that a mixed logistic regression would do the
> job or should I move to Support vector machines algorithms?
> 
> Leonardo Lancia
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 24, Issue 4
> *************************************************






From frl2 at psu.edu  Fri Dec  5 20:53:34 2008
From: frl2 at psu.edu (Frank Lawrence)
Date: Fri, 5 Dec 2008 14:53:34 -0500
Subject: [R-sig-ME] mcmcsamp
Message-ID: <003001c95713$29172e70$7b458b50$@edu>

I was attempting to run mcmcsamp on an lmer model without success.  From the
archive I noted that some users had a similar difficulty a couple of months
ago with obtaining fixed effect estimates.  I was wondering if there is any
new information on using mcmcsamp to obtain confidence intervals for fixed
effects from an lmer object.

Windows Vista, Home Premium. R-2.8

Respectfully,

Frank R. Lawrence



From HDoran at air.org  Sat Dec  6 16:34:37 2008
From: HDoran at air.org (Doran, Harold)
Date: Sat, 6 Dec 2008 10:34:37 -0500
Subject: [R-sig-ME] Master's Partial Credit with lmer [was:RE:  lmer]
References: <111312.17432.qm@web54111.mail.re2.yahoo.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE2719D0@DC1EXCL01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081206/b2a539b0/attachment.pl>

From ahimsa at camposarceiz.com  Sat Dec  6 17:24:56 2008
From: ahimsa at camposarceiz.com (Ahimsa Campos Arceiz)
Date: Sun, 7 Dec 2008 01:24:56 +0900
Subject: [R-sig-ME] lmer & negative binomial family -- confused by
	contradictory information on R-help lists
Message-ID: <BB9E22EE-1810-43E8-B139-C4DEAC4AE08D@camposarceiz.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081207/acaad674/attachment.pl>

From otter at otter-rsch.com  Sat Dec  6 20:36:30 2008
From: otter at otter-rsch.com (dave fournier)
Date: Sat, 06 Dec 2008 11:36:30 -0800
Subject: [R-sig-ME] lmer & negative binomial family -- confused
 by	contradictory information on R-help lists
In-Reply-To: <BB9E22EE-1810-43E8-B139-C4DEAC4AE08D@camposarceiz.com>
References: <BB9E22EE-1810-43E8-B139-C4DEAC4AE08D@camposarceiz.com>
Message-ID: <493AD43E.80503@otter-rsch.com>

Hi,

The package glmmADMB for R based on AD model Builder can fit
nbmm's.  AD Model Builder is now freely available so you can modify this
package as well.

     http://admb-foundation.org/

   Cheers,

    Dave


-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From epistat at gmail.com  Sun Dec  7 02:34:36 2008
From: epistat at gmail.com (zhijie zhang)
Date: Sun, 7 Dec 2008 09:34:36 +0800
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
Message-ID: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081207/b2aba7af/attachment.pl>

From ken at kjbeath.com.au  Sun Dec  7 04:14:19 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Sun, 7 Dec 2008 14:14:19 +1100
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
Message-ID: <4AD602F3-D983-436E-978B-E47397A3EF66@kjbeath.com.au>

On 07/12/2008, at 12:34 PM, zhijie zhang wrote:

> Dear Rusers,
>   Sorry for re-post my question in this list. Some person has  
> recommend
> that this list is more specific for me.
>   I have used R,S-PLUS and SAS to analyze the sample data "bacteria"  
> in
> MASS package. Their results are listed below.
> I have three questions, anybody can give me possible answers?
> Q1:From the results, we see that R get 'NAs'for AIC,BIC and logLik,  
> while
> S-PLUS8.0 gave the exact values for them. Why? I had thought that R  
> should
> give the same results as SPLUS here.
>

PQL is not maximum likelihood (it is an approximation which uses lme  
internally and this is what generates the results) so the results  
should be NA. The R and S-Plus versions have obviously diverged.

SAS nlmixed uses maximum likelihood so a log likelihood is available.

> Q2: The model to analyse the data is logity=b0+u+b1*trt 
> +b2*I(week>2), but
> the results for Random effects in R/SPLUS confused me. SAS may be  
> clearer.
> Random effects:
> Formula: ~1 | ID
>               (Intercept)          Residual
> StdDev:    1.410637             0.7800511
>  Which is the random effect 'sigma'? I think it is "1.410637", but  
> what
> does "0.7800511" mean? That is, i want ot know how to explain/use  
> the above
> two data for Random effects.
>

I wonder if in PQL these have any real meaning, as they are obtained  
from the linear mixed effects step. Try using lmer in the lme4 package.

> Q3:In SAS and other softwares, we can get p-values for the random  
> effect
> 'sigma', but i donot see the p-values in the results of R/SPLUS. I  
> have used
> attributes() to look for them, but no p values. Anybody knows how to  
> get
> p-values for the random effect 'sigma',.

The standard answer is of the form "Just because SAS has it, doesn't  
mean it is a good idea".  There was a recent discussion on this list  
about significance of random effects.

Ken


>
>  Any suggestions or help are greatly appreciated.
> #R Results:MASS' version 7.2-44; R version 2.7.2
> library(MASS)
> summary(glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,family =  
> binomial,
> data = bacteria))
> Linear mixed-effects model fit by maximum likelihood
> Data: bacteria
>  AIC BIC logLik
>   NA  NA     NA
> Random effects:
> Formula: ~1 | ID
>        (Intercept)  Residual
> StdDev:    1.410637 0.7800511
> Variance function:
> Structure: fixed weights
> Formula: ~invwt
> Fixed effects: y ~ trt + I(week > 2)
>                    Value          Std.Error      DF       t-value
> p-value
> (Intercept)      3.412014    0.5185033   169       6.580506  0.0000
> trtdrug         -1.247355     0.6440635     47      -1.936696  0.0588
> trtdrug+        -0.754327    0.6453978     47      -1.168779  0.2484
> I(week > 2)TRUE -1.607257 0.3583379 169     -4.485311  0.0000
> Correlation:
>                (Intr) trtdrg trtdr+
> trtdrug         -0.598
> trtdrug+        -0.571  0.460
> I(week > 2)TRUE -0.537  0.047 -0.001
> #S-PLUS8.0: The results are the same as R except the followings:
> AIC      BIC    logLik
> 1113.622 1133.984 -550.8111
> #SAS9.1.3
> proc nlmixed data=b;
> parms b0=-1 b1=1 b2=1 sigma=0.4;
> yy=b0+u+b1*trt+b2*week;
> p=1/(1+exp(-yy));
> Model response~binary(p);
> Random u~normal(0,sigma) subject=id;
> Run;
> -2 Log Likelihood = 192.2
> AIC (smaller is better)=200.2
> AICC (smaller is better) =200.3
> BIC (smaller is better)= 207.8
>
>                                      Parameter Estimates
>                       Standard
>  Parameter  Estimate     Error    DF  t Value  Pr > |t|   Alpha
> Lower     Upper  Gradient
>  b0             3.4966    0.6512    49     5.37    <.0001    0.05
> 2.1880    4.8052  -4.69E-6
>  trt              -0.6763    0.3352    49    -2.02    0.0491    0.05
> -1.3500  -0.00266  -0.00001
>  I(week>2)   -1.6132    0.4785    49    -3.37    0.0015    0.05    
> -2.5747
> -0.6516  -9.35E-7
>  sigma        1.5301    0.9632    49     1.59    0.1186    0.05
> -0.4054    3.4656  -2.42E-6
>
> -- 
> With Kind Regards,
>
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> [***********************************************************************]
> ZhiJie Zhang ,PhD
> Dept.of Epidemiology, School of Public Health,Fudan University
> Office:Room 443, Building 8
> Office Tel./Fax.:+86-21-54237410
> Address:No. 138 Yi Xue Yuan Road,Shanghai,China
> Postcode:200032
> Email:epistat at gmail.com <Email%3Aepistat at gmail.com>
> Website: www.statABC.com
> [***********************************************************************]
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gabraham at csse.unimelb.edu.au  Sun Dec  7 13:10:46 2008
From: gabraham at csse.unimelb.edu.au (Gad Abraham)
Date: Sun, 07 Dec 2008 23:10:46 +1100
Subject: [R-sig-ME] Penalized mixed-effects regression
Message-ID: <493BBD46.3000908@csse.unimelb.edu.au>

Hi,

I'm interested in doing mixed-effects logistic regression on gene 
expression data (genes in each batch as fixed effects, and different 
batches as random effects). The data has many times more variables than 
samples. This calls for a penalised likelihood function, e.g., lasso or 
ridge.

I couldn't find any information about whether lme4 or nlme support 
penalised regression.

Any advice on whether this is possible?

Thanks,
Gad

-- 
Gad Abraham
Dept. CSSE and NICTA
The University of Melbourne
Parkville 3010, Victoria, Australia
email: gabraham at csse.unimelb.edu.au
web: http://www.csse.unimelb.edu.au/~gabraham



From lamprianou at yahoo.com  Sun Dec  7 16:01:09 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 7 Dec 2008 07:01:09 -0800 (PST)
Subject: [R-sig-ME] Master's Partial Credit with lmer [was:RE:  lmer]
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE2719D0@DC1EXCL01.air.org>
Message-ID: <448036.29290.qm@web54108.mail.re2.yahoo.com>

Thank you Doran for your response. If anyone else is aware of any other R package that can run multilevel Rasch/IRT models, please respond.

Jason

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Sat, 6/12/08, Doran, Harold <HDoran at air.org> wrote:

> From: Doran, Harold <HDoran at air.org>
> Subject: Master's Partial Credit with lmer [was:RE: [R-sig-ME] lmer]
> To: lamprianou at yahoo.com, r-sig-mixed-models at r-project.org
> Date: Saturday, 6 December, 2008, 3:34 PM
> The answer is no, the PCM cannot be run using lmer. Also, it
> is best not to ask a new question by replying to a different
> thread.
> 
> Harold
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of
> Iasonas Lamprianou
> Sent: Fri 12/5/2008 5:10 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lmer
>  
> Dear friends, 
> does anyone know how (if) I can run a multilevel Partial
> Credit Rasch model using lmer? I am aware of the
> "Estimating the Multilevel Rasch Model: With the lme4
> Package" but I think that this only refers to the
> dichotomous Rasch case. Or, alternatively, redirect me to
> any other free package that can handle multilevel Rasch/IRT
> models. 
> Thanks
> 
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044  161 275 3485
> iasonas.lamprianou at manchester.ac.uk
> 
> 
> --- On Thu, 4/12/08,
> r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org> wrote:
> 
> > From: r-sig-mixed-models-request at r-project.org
> <r-sig-mixed-models-request at r-project.org>
> > Subject: R-sig-mixed-models Digest, Vol 24, Issue 4
> > To: r-sig-mixed-models at r-project.org
> > Date: Thursday, 4 December, 2008, 11:00 AM
> > Send R-sig-mixed-models mailing list submissions to
> > 	r-sig-mixed-models at r-project.org
> > 
> > To subscribe or unsubscribe via the World Wide Web,
> visit
> >
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body
> > 'help' to
> > 	r-sig-mixed-models-request at r-project.org
> > 
> > You can reach the person managing the list at
> > 	r-sig-mixed-models-owner at r-project.org
> > 
> > When replying, please edit your Subject line so it is
> more
> > specific
> > than "Re: Contents of R-sig-mixed-models
> > digest..."
> > 
> > 
> > Today's Topics:
> > 
> >    1. Logisting regression for same-different speaker
> >       classification (Leonardo LANCIA)
> > 
> > 
> >
> ----------------------------------------------------------------------
> > 
> > Message: 1
> > Date: Wed, 3 Dec 2008 12:03:02 +0100 (CET)
> > From: Leonardo LANCIA
> > <Leonardo.Lancia at univ-provence.fr>
> > Subject: [R-sig-ME] Logisting regression for
> same-different
> > speaker
> > 	classification
> > To: r-sig-mixed-models at r-project.org
> > Message-ID:
> >
> <9555723.429.1228302182606.JavaMail.root at frontal1>
> > Content-Type: text/plain; charset=iso-8859-1
> > 
> > Dear List,
> > 
> > I would like to use a mixed logistic regression model
> as a
> > classifier which decides if two speech signals
> representing
> > two istances of the same phoneme (uttered in a
> specified
> > phentic context) are produced by the same speaker or
> not. To
> > do that I should use a huge number of predictors (more
> or
> > less 50 acoustic features). More over, for each
> acoustic
> > feature I should specify a random interaction with the
> > following factors : the phonetic label attached to the
> > acoustic signals, and a phonetic label correspoding to
> the
> > context from which the acoustic signals are extracted.
> 
> > I am not interested in hypotesis testing but I would
> like
> > to have an estimation of the contributoin to this task
> of
> > each of the predictors and an estimate of the
> correction
> > coefficients associated to the random effects.
> > Do you think that a mixed logistic regression would do
> the
> > job or should I move to Support vector machines
> algorithms?
> > 
> > Leonardo Lancia
> > 
> > 
> > 
> > ------------------------------
> > 
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> >
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > 
> > End of R-sig-mixed-models Digest, Vol 24, Issue 4
> > *************************************************
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models






From bill at edmeasure.com  Sun Dec  7 18:34:39 2008
From: bill at edmeasure.com (Bill Auty)
Date: Sun, 07 Dec 2008 11:34:39 -0600
Subject: [R-sig-ME] Master's Partial Credit with lmer [was:RE:  lmer]
In-Reply-To: <448036.29290.qm@web54108.mail.re2.yahoo.com>
References: <448036.29290.qm@web54108.mail.re2.yahoo.com>
Message-ID: <493C092F.7090809@edmeasure.com>

I approached this problem by creating a dichotomous item for each 
threshold of the rated item. For a 4-level rating (0,1,2,3,4), I created 
3 dichotomous items. A score of 0 translates to 0,0,0; 1=1,0,0; 2=1,1,0 
and 3=1,1,1. Then I combined my created items with the originally 
dichotomous items and ran models using lmer as described in the paper.

I don't know if the mathematics works out exactly, but I think this is 
logically equivalent to the Partial Credit Model. If someone see a 
theoretical reason not to do this, I'd be interested to know.

Clearly, this tactic weights the data from the rated item more than a 
dichotomous items (3x in my example), but that was appropriate for my 
purposes.


Iasonas Lamprianou wrote:
> Thank you Doran for your response. If anyone else is aware of any other R package that can run multilevel Rasch/IRT models, please respond.
> 
> Jason
> 
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044  161 275 3485
> iasonas.lamprianou at manchester.ac.uk
> 
> 
> --- On Sat, 6/12/08, Doran, Harold <HDoran at air.org> wrote:
> 
>> From: Doran, Harold <HDoran at air.org>
>> Subject: Master's Partial Credit with lmer [was:RE: [R-sig-ME] lmer]
>> To: lamprianou at yahoo.com, r-sig-mixed-models at r-project.org
>> Date: Saturday, 6 December, 2008, 3:34 PM
>> The answer is no, the PCM cannot be run using lmer. Also, it
>> is best not to ask a new question by replying to a different
>> thread.
>>
>> Harold
>>
>>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org on behalf of
>> Iasonas Lamprianou
>> Sent: Fri 12/5/2008 5:10 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] lmer
>>  
>> Dear friends, 
>> does anyone know how (if) I can run a multilevel Partial
>> Credit Rasch model using lmer? I am aware of the
>> "Estimating the Multilevel Rasch Model: With the lme4
>> Package" but I think that this only refers to the
>> dichotomous Rasch case. Or, alternatively, redirect me to
>> any other free package that can handle multilevel Rasch/IRT
>> models. 
>> Thanks
>>
>> Dr. Iasonas Lamprianou
>> Department of Education
>> The University of Manchester
>> Oxford Road, Manchester M13 9PL, UK
>> Tel. 0044  161 275 3485
>> iasonas.lamprianou at manchester.ac.uk
>>
>>
>> --- On Thu, 4/12/08,
>> r-sig-mixed-models-request at r-project.org
>> <r-sig-mixed-models-request at r-project.org> wrote:
>>
>>> From: r-sig-mixed-models-request at r-project.org
>> <r-sig-mixed-models-request at r-project.org>
>>> Subject: R-sig-mixed-models Digest, Vol 24, Issue 4
>>> To: r-sig-mixed-models at r-project.org
>>> Date: Thursday, 4 December, 2008, 11:00 AM
>>> Send R-sig-mixed-models mailing list submissions to
>>> 	r-sig-mixed-models at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web,
>> visit
>> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> or, via email, send a message with subject or body
>>> 'help' to
>>> 	r-sig-mixed-models-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>> 	r-sig-mixed-models-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is
>> more
>>> specific
>>> than "Re: Contents of R-sig-mixed-models
>>> digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>    1. Logisting regression for same-different speaker
>>>       classification (Leonardo LANCIA)
>>>
>>>
>>>
>> ----------------------------------------------------------------------
>>> Message: 1
>>> Date: Wed, 3 Dec 2008 12:03:02 +0100 (CET)
>>> From: Leonardo LANCIA
>>> <Leonardo.Lancia at univ-provence.fr>
>>> Subject: [R-sig-ME] Logisting regression for
>> same-different
>>> speaker
>>> 	classification
>>> To: r-sig-mixed-models at r-project.org
>>> Message-ID:
>>>
>> <9555723.429.1228302182606.JavaMail.root at frontal1>
>>> Content-Type: text/plain; charset=iso-8859-1
>>>
>>> Dear List,
>>>
>>> I would like to use a mixed logistic regression model
>> as a
>>> classifier which decides if two speech signals
>> representing
>>> two istances of the same phoneme (uttered in a
>> specified
>>> phentic context) are produced by the same speaker or
>> not. To
>>> do that I should use a huge number of predictors (more
>> or
>>> less 50 acoustic features). More over, for each
>> acoustic
>>> feature I should specify a random interaction with the
>>> following factors : the phonetic label attached to the
>>> acoustic signals, and a phonetic label correspoding to
>> the
>>> context from which the acoustic signals are extracted.
>>> I am not interested in hypotesis testing but I would
>> like
>>> to have an estimation of the contributoin to this task
>> of
>>> each of the predictors and an estimate of the
>> correction
>>> coefficients associated to the random effects.
>>> Do you think that a mixed logistic regression would do
>> the
>>> job or should I move to Support vector machines
>> algorithms?
>>> Leonardo Lancia
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> _______________________________________________
>>> R-sig-mixed-models mailing list
>>> R-sig-mixed-models at r-project.org
>>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> End of R-sig-mixed-models Digest, Vol 24, Issue 4
>>> *************************************************
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Bill Auty
Education Measurement Consulting
1126 NW 29th St Corvallis, OR 97330
(541) 207-3632 (office) (541) 760-2148 (cell)



From epistat at gmail.com  Mon Dec  8 04:24:54 2008
From: epistat at gmail.com (zhijie zhang)
Date: Mon, 8 Dec 2008 11:24:54 +0800
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <4AD602F3-D983-436E-978B-E47397A3EF66@kjbeath.com.au>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
	<4AD602F3-D983-436E-978B-E47397A3EF66@kjbeath.com.au>
Message-ID: <2fc17e30812071924h5a67bf0bg4a81ddb7b4f38abc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081208/1e635209/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Dec  8 06:40:33 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 8 Dec 2008 15:40:33 +1000 (EST)
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>

On Sun, 7 Dec 2008, zhijie zhang wrote:

> Dear Rusers,
>   Sorry for re-post my question in this list. Some person has recommend
> that this list is more specific for me.
>   I have used R,S-PLUS and SAS to analyze the sample data "bacteria" in
> MASS package. Their results are listed below.
>
> Q3:In SAS and other softwares, we can get p-values for the random effect
> 'sigma', but i donot see the p-values in the results of R/SPLUS. I have used
> attributes() to look for them, but no p values. Anybody knows how to get
> p-values for the random effect 'sigma',.
>

Someone answered your specific questions before.
Because this is a simple random intercept model, you can also use the
glmmML R package, which gives:

glmmML(y ~ trt + I(week > 2), cluster=ID, family=binomial, data=bacteria)

                    coef se(coef)      z Pr(>|z|)
(Intercept)      3.5482   0.6933  5.118 3.09e-07
trtdrug         -1.3667   0.6768 -2.020 4.34e-02
trtdrug+        -0.7826   0.6830 -1.146 2.52e-01
I(week > 2)TRUE -1.5986   0.4754 -3.363 7.71e-04

Standard deviation in mixing distribution:  1.242
Std. Error:                                 0.4024

Residual deviance: 192.3 on 215 degrees of freedom      AIC: 202.3

You can then construct a test for the random effect.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From epistat at gmail.com  Mon Dec  8 07:11:31 2008
From: epistat at gmail.com (zhijie zhang)
Date: Mon, 8 Dec 2008 14:11:31 +0800
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
	<Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>
Message-ID: <2fc17e30812072211l43062687o5a487fc59038894b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081208/0a05c33e/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Dec  8 08:29:06 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 8 Dec 2008 17:29:06 +1000 (EST)
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <2fc17e30812072211l43062687o5a487fc59038894b@mail.gmail.com>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
	<Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>
	<2fc17e30812072211l43062687o5a487fc59038894b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0812081716360.16294@orpheus.qimr.edu.au>

On Mon, 8 Dec 2008, zhijie zhang wrote:

>
> Do u mean the following method?
> > model0<-glmmML(y ~ trt + I(week > 2), cluster=ID, family=binomial,
> data=bacteria)
>> model1<-glm(y ~ trt + I(week > 2), family=binomial, data=bacteria)
>> anova(model0,model1)
> Error message occurred.

anova does not have a method for glmmML, but the deviances seem to be 
calculated the same (see model0$cluster.null.deviance etc):.

model0 Residual deviance: 192.3  on 215 degrees of freedom      AIC: 202.3
model1 Residual deviance: 199.18 on 216  degrees of freedom

LRTS = 6.88.  We will assume that the test statistic is distributed 1/2 
X2(0) and 1/2 X2(1), so P ~ 0.004.  Comparing to a Wald test using the SE 
on the random effect SD, I get:

Z = 1.242/0.4024 = 3.08, P=0.001




-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From epistat at gmail.com  Mon Dec  8 08:42:31 2008
From: epistat at gmail.com (zhijie zhang)
Date: Mon, 8 Dec 2008 15:42:31 +0800
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <Pine.LNX.4.64.0812081716360.16294@orpheus.qimr.edu.au>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
	<Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>
	<2fc17e30812072211l43062687o5a487fc59038894b@mail.gmail.com>
	<Pine.LNX.4.64.0812081716360.16294@orpheus.qimr.edu.au>
Message-ID: <2fc17e30812072342x3b93c15bs66a5faccbdf0e5a0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081208/b5734632/attachment.pl>

From ken at kjbeath.com.au  Mon Dec  8 10:39:19 2008
From: ken at kjbeath.com.au (Ken Beath)
Date: Mon, 8 Dec 2008 20:39:19 +1100
Subject: [R-sig-ME] Questions on the results from glmmPQL(MASS)
In-Reply-To: <2fc17e30812072342x3b93c15bs66a5faccbdf0e5a0@mail.gmail.com>
References: <2fc17e30812061734r705ae24dg81c26249ee21885e@mail.gmail.com>
	<Pine.LNX.4.64.0812081533510.12233@orpheus.qimr.edu.au>
	<2fc17e30812072211l43062687o5a487fc59038894b@mail.gmail.com>
	<Pine.LNX.4.64.0812081716360.16294@orpheus.qimr.edu.au>
	<2fc17e30812072342x3b93c15bs66a5faccbdf0e5a0@mail.gmail.com>
Message-ID: <B13CBFBA-CBAF-4380-BE4D-42B712876415@kjbeath.com.au>


On 08/12/2008, at 6:42 PM, zhijie zhang wrote:

> On Mon, Dec 8, 2008 at 3:29 PM, David Duffy  
> <David.Duffy at qimr.edu.au> wrote:
>
>> On Mon, 8 Dec 2008, zhijie zhang wrote:
>>
>>
>>> Do u mean the following method?
>>>> model0<-glmmML(y ~ trt + I(week > 2), cluster=ID, family=binomial,
>>> data=bacteria)
>>>
>>>> model1<-glm(y ~ trt + I(week > 2), family=binomial, data=bacteria)
>>>> anova(model0,model1)
>>>>
>>> Error message occurred.
>>>
>>
>> anova does not have a method for glmmML, but the deviances seem to be
>> calculated the same (see model0$cluster.null.deviance etc):.
>>
>> model0 Residual deviance: 192.3  on 215 degrees of freedom       
>> AIC: 202.3
>> model1 Residual deviance: 199.18 on 216  degrees of freedom
>>
>>
>
>> LRTS = 6.88.  We will assume that the test statistic is distributed  
>> 1/2
>> X2(0) and 1/2 X2(1), so P ~ 0.004.
>
>
> 1/2 X2(0) and 1/2 X2(1): ?? what do they mean?
>

X2 is chi-square. Because the test is on the boundary the test  
statistic is distributed as the weighted sum of chi-square rather than  
the usual chi-square. Verbeke and Molenberghs cover this in their books.

Simulation (parametric bootstrap) seems a better way of doing this.  
Information criteria (AIC or BIC) can also be used. Most usual  
justification for a random effect is that there is expected to be one,  
so provided it can be estimated it is included.


>> Comparing to a Wald test using the SE on the random effect SD, I get:
>>
>> Z = 1.242/0.4024 = 3.08, P=0.001
>
> Is this a "clerical error"? Based on your hints, it seems that p  
> should be
> 0.003475077 .
>> dnorm(3.08)
> [1] 0.003475077
>   Thanks.
>

P value for z test is 2*dnorm(3.08) which is close enough to 0.001  
given that the test is only an approximation.

Ken


>>
>>
>>
>>
>>
>> --
>> | David Duffy (MBBS PhD)                                         ,- 
>> _|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax:  
>> -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research    
>> \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG  
>> 4D0B994A v
>>
>
>
>
> -- 
> With Kind Regards,
>
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> [***********************************************************************]
> ZhiJie Zhang ,PhD
> Dept.of Epidemiology, School of Public Health,Fudan University
> Office:Room 443, Building 8
> Office Tel./Fax.:+86-21-54237410
> Address:No. 138 Yi Xue Yuan Road,Shanghai,China
> Postcode:200032
> Email:epistat at gmail.com <Email%3Aepistat at gmail.com>
> Website: www.statABC.com
> [***********************************************************************]
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tahirajamil at yahoo.com  Mon Dec  8 12:04:21 2008
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Mon, 8 Dec 2008 03:04:21 -0800 (PST)
Subject: [R-sig-ME] update a nonlinear Mixed effect model in lme4
Message-ID: <719189.1571.qm@web50802.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081208/52d7cc99/attachment.pl>

From David.Grimardias at st-pee.inra.fr  Mon Dec  8 14:12:23 2008
From: David.Grimardias at st-pee.inra.fr (David Grimardias)
Date: Mon, 08 Dec 2008 14:12:23 +0100
Subject: [R-sig-ME] Likelihood Ratio tests and fixed effects with LMER
Message-ID: <493D1D37.2020506@st-pee.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081208/c58fbcc8/attachment.pl>

From Herve.Chapuis at tours.inra.fr  Mon Dec  8 15:47:29 2008
From: Herve.Chapuis at tours.inra.fr (=?ISO-8859-1?Q?Herv=E9_CHAPUIS?=)
Date: Mon, 08 Dec 2008 15:47:29 +0100
Subject: [R-sig-ME] residual variances in glmer
Message-ID: <493D3381.9080308@tours.inra.fr>

Hello every one.
I am a real R-mix models-newbie. A colleague told me I should ask  the  
list.
Well, when dealing with  discrete traits  in animal genetics, we have 
many possibilities :
- use an home-made program based, for instance, on Gianola & Foulley 
(1993) algorithm.
- treat the data as a classical gaussian performance, use a linear mixed 
model (lmer works fine) and then compute the heritability coefficient on 
the observed scale  as h? = 4 x sire_variance (sire_variance + 
dam_variance + residual_variance).
After that, use the Dempster & Lerner formula to obtain the heritability 
on the  underlying scale.
- or use directly a general linear mixed model.

That's what I have done but I have been puzzled by the results.
On simulated data, (I have simulated a vector of gaussian performances 
accounting for Mendelian rules, before transforming them into binary 
data through a given threshold value)  the first two options give me  
"good" results and an estimated h? reasonably close  to the expected value.
If  I use glmer instead of lmer, I still obtain a result but I cannot 
safely obtain the h? assuming that the residual variance is 1, can I ?
If so, the estimated h? is very high, if not above 1.
Any hint ?

-- 
Cordialement, 


Herv? CHAPUIS
SYSAAF
Station de Recherches Avicoles
37380 NOUZILLY

tel : 02 47 42 76 77
fax : 02 47 42 76 46



From frl2 at psu.edu  Mon Dec  8 16:24:05 2008
From: frl2 at psu.edu (Frank Lawrence)
Date: Mon, 8 Dec 2008 10:24:05 -0500
Subject: [R-sig-ME] mcmcsamp
In-Reply-To: <20081206194521.GR1253@ms.unimelb.edu.au>
References: <003001c95713$29172e70$7b458b50$@edu>
	<20081206194521.GR1253@ms.unimelb.edu.au>
Message-ID: <000001c95949$0250e370$06f2aa50$@edu>

Hi Andrew:

Sorry for not including the example at the outset.

>sessionInfo()
R version 2.8.0 (2008-10-20) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
 [1] grid      splines   stats     graphics  grDevices datasets 
 [7] tcltk     utils     methods   base     

other attached packages:
 [1] MCMCpack_0.9-5     coda_0.13-3        statmod_1.3.8     
 [4] polycor_0.7-6      sfsmisc_1.0-6      mvtnorm_0.9-2     
 [7] xtable_1.5-4       prettyR_1.3-5      lme4_0.999375-27  
[10] Matrix_0.999375-16 effects_2.0-0      nnet_7.2-44       
[13] mvnormtest_0.1-6   xlsReadWrite_1.3.2 gmodels_2.14.1    
[16] gtools_2.5.0       latticeExtra_0.5-4 lattice_0.17-17   
[19] RColorBrewer_1.0-2 doBy_3.6           foreign_0.8-29    
[22] Design_2.1-2       survival_2.34-1    e1071_1.5-18      
[25] class_7.2-44       car_1.2-9          mitools_2.0       
[28] MASS_7.2-44        svSocket_0.9-5     TinnR_1.0.2       
[31] R2HTML_1.59        Hmisc_3.4-4     

##artificial data
> nn <- 1e2

> mm <- seq(1,5,1)

> cv  <- matrix(data = rep(x = 0.3, times = 25), nc = 5, nr = 5)

> diag(cv) <- 1

> dat <- cbind.data.frame(id = seq(1,nn,1), mvrnorm(n = nn, m = mm, S = cv,
emp = T))

> names(dat)[2:6] <- paste('y',1:5,sep='')

> d.t <- reshape(data = dat, varying = list(names(dat)[2:6]), v.names = 'y',
times = seq(0,4,1), idvar = 'id', drop = NULL, dir = 'l')

> m1 <- lmer(form = y ~ time + (1|id), data = d.t, fam = gaussian, R = F, na
= na.exclude)
> m1
Linear mixed model fit by maximum likelihood 
Formula: y ~ time + (1 | id) 
   Data: d.t 
  AIC  BIC logLik deviance REMLdev
 1370 1387   -681     1362    1371
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 0.409    0.640   
 Residual             0.955    0.977   
Number of obs: 500, groups: id, 100

Fixed effects:
            Estimate Std. Error t value
(Intercept)   1.0000     0.0860    11.6
time          1.0000     0.0309    32.4

Correlation of Fixed Effects:
     (Intr)
time -0.719

> x <- mcmcsamp(obj = m1, n = 1e3)

> str(x)
Formal class 'merMCMC' [package "lme4"] with 9 slots
  ..@ Gp      : int [1:2] 0 100
  ..@ ST      : num [1, 1:1000] 0.655 0.529 0.448 0.401 0.406 ...
  ..@ call    : language lmer(formula = y ~ time + (1 | id), data = d.t,
REML = F, na.action = na.exclude)
  ..@ deviance: num [1:1000] 1362 1350 1353 1359 1364 ...
  ..@ dims    : Named int [1:18] 1 500 2 100 1 1 0 0 2 5 ...
  .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
  ..@ fixef   : num [1:2, 1:1000] 1 1 1.093 0.989 1.038 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "(Intercept)" "time"
  .. .. ..$ : NULL
  ..@ nc      : int 1
  ..@ ranef   : num[1:100, 0 ] 
  ..@ sigma   : num [1, 1:1000] 0.977 0.853 0.84 0.862 0.921 ...

##then I did the following which is not in the help file
> xyplot(x)##check 

> x <- mcmcsamp(obj = m41, n = 1e3)

> summary(t(x at fixef))
  (Intercept)       emosympt          schprob        totalnetscr    
 Min.   : 1.82   Min.   :-0.4772   Min.   :-0.206   Min.   :-0.529  
 1st Qu.:22.11   1st Qu.:-0.1980   1st Qu.: 0.176   1st Qu.:-0.434  
 Median :27.10   Median :-0.1144   Median : 0.268   Median :-0.408  
 Mean   :27.20   Mean   :-0.1184   Mean   : 0.262   Mean   :-0.407  
 3rd Qu.:32.15   3rd Qu.:-0.0416   3rd Qu.: 0.348   3rd Qu.:-0.381  
 Max.   :51.48   Max.   : 0.2662   Max.   : 0.636   Max.   :-0.264  

> colMeans(t(x at fixef))
(Intercept)    emosympt     schprob totalnetscr 
     27.200      -0.118       0.262      -0.407 
##UCL and LCL
> colMeans(t(x at fixef)) + 1.96*sqrt(colVars(t(x at fixef)))
(Intercept)    emosympt     schprob totalnetscr 
     41.537       0.107       0.526      -0.330 

> colMeans(t(x at fixef)) - 1.96*sqrt(colVars(t(x at fixef)))
(Intercept)    emosympt     schprob totalnetscr 
   12.86248    -0.34386    -0.00259    -0.48348

Respectfully,

Frank R. Lawrence

# -----Original Message-----
# From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
# Sent: Saturday, December 06, 2008 2:45 PM
# To: Frank Lawrence
# Subject: Re: [R-sig-ME] mcmcsamp
# 
# Hi Frank,
# 
# can you provide a minimal, executable example?
# 
# Cheers
# 
# Andrew
# 
# On Fri, Dec 05, 2008 at 02:53:34PM -0500, Frank Lawrence wrote:
# > I was attempting to run mcmcsamp on an lmer model without success.  From
# the
# > archive I noted that some users had a similar difficulty a couple of
months
# > ago with obtaining fixed effect estimates.  I was wondering if there is
any
# > new information on using mcmcsamp to obtain confidence intervals for
fixed
# > effects from an lmer object.
# >
# > Windows Vista, Home Premium. R-2.8
# >
# > Respectfully,
# >
# > Frank R. Lawrence
# >
# > _______________________________________________
# > R-sig-mixed-models at r-project.org mailing list
# > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
# 
# --
# Andrew Robinson
# Department of Mathematics and Statistics            Tel: +61-3-8344-6410
# University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
# http://www.ms.unimelb.edu.au/~andrewpr
# http://blogs.mbs.edu/fishing-in-the-bay/



From Virgilio.Gomez at uclm.es  Mon Dec  8 19:27:51 2008
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Mon, 08 Dec 2008 18:27:51 +0000
Subject: [R-sig-ME] Problem using pdSymm matrix to fit spatial models
Message-ID: <1228760871.15723.15.camel@Virgilio-Gomez>

Dear all,

I am trying to use a Spatially Autoregressive specification for the
variance of the random effects to fit a model with spatial structure but
I am having some trouble with that. Basically, I want to define the
follwing variance matrix for the random effects:

V=sigma^2*((I-rho*W)*(I-rho*W))^{-1}

where I is the identity matrix, rho is the autocorrelation coefficient
and W is an adjacency matrix that measures dependence between areas. 

The model is then

y_{ij}=mu_i+u_i+e_{ij}
(u_1, ..., u_n)~N(0, V)
e_{ij}~N(0, kappa^2)

The following is an example of what I am trying to do:

#Example with simulated data
library(nlme)
ssize<-rep(10, 42)
set.seed(1)
mu<-rnorm(42)*10
y<-rnorm(sum(ssize), mean=rep(mu, each=ssize), sd=.5)
Sdf<-data.frame(y=y, REGION=rep(1:42, each=ssize))

rho<-.2
n<-42
#W is an adjacency matrix
W<-matrix(0, ncol=42, nrow=42)
for(i in 1:41){W[i, i+1]<-.5;W[i+1,i]<-.5}
m<-pdSymm(solve( (diag(n)-rho*W)%*%(diag(n)-rho*t(W)) ),
   nam=as.character(1:42),
   form=~REGION-1)

model2<-lme(y~1, random=list(REGION=m), data=Sdf)


But I keep getting the following error:

Error in `Names<-.pdMat`(`*tmp*`, value = "REGION") : 
  Length of names should be 42


I think that I have used argument 'nam' in the right way when defining
the matrix, but it seems that I am missing something here.

I would appreciate any comments on this, in special if you think that
another approach would be better. The next step is to provide a way of
estimating rho, sigma^2 and kappa^2 (probably, by calling lme several
times) so that I can fit a wide range of spatial models.

Many thanks,

Virgilio



From A.Robinson at ms.unimelb.edu.au  Mon Dec  8 20:51:30 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 9 Dec 2008 06:51:30 +1100
Subject: [R-sig-ME] mcmcsamp
In-Reply-To: <000001c95949$0250e370$06f2aa50$@edu>
References: <003001c95713$29172e70$7b458b50$@edu>
	<20081206194521.GR1253@ms.unimelb.edu.au>
	<000001c95949$0250e370$06f2aa50$@edu>
Message-ID: <20081208195130.GE1252@ms.unimelb.edu.au>

Hi Frank,

thanks ... but, I guess I should have asked you for a commentary as
well.   Can you make our lives easier by identifying exactly what your
problem is?

Andrew

On Mon, Dec 08, 2008 at 10:24:05AM -0500, Frank Lawrence wrote:
> Hi Andrew:
> 
> Sorry for not including the example at the outset.
> 
> >sessionInfo()
> R version 2.8.0 (2008-10-20) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
>  [1] grid      splines   stats     graphics  grDevices datasets 
>  [7] tcltk     utils     methods   base     
> 
> other attached packages:
>  [1] MCMCpack_0.9-5     coda_0.13-3        statmod_1.3.8     
>  [4] polycor_0.7-6      sfsmisc_1.0-6      mvtnorm_0.9-2     
>  [7] xtable_1.5-4       prettyR_1.3-5      lme4_0.999375-27  
> [10] Matrix_0.999375-16 effects_2.0-0      nnet_7.2-44       
> [13] mvnormtest_0.1-6   xlsReadWrite_1.3.2 gmodels_2.14.1    
> [16] gtools_2.5.0       latticeExtra_0.5-4 lattice_0.17-17   
> [19] RColorBrewer_1.0-2 doBy_3.6           foreign_0.8-29    
> [22] Design_2.1-2       survival_2.34-1    e1071_1.5-18      
> [25] class_7.2-44       car_1.2-9          mitools_2.0       
> [28] MASS_7.2-44        svSocket_0.9-5     TinnR_1.0.2       
> [31] R2HTML_1.59        Hmisc_3.4-4     
> 
> ##artificial data
> > nn <- 1e2
> 
> > mm <- seq(1,5,1)
> 
> > cv  <- matrix(data = rep(x = 0.3, times = 25), nc = 5, nr = 5)
> 
> > diag(cv) <- 1
> 
> > dat <- cbind.data.frame(id = seq(1,nn,1), mvrnorm(n = nn, m = mm, S = cv,
> emp = T))
> 
> > names(dat)[2:6] <- paste('y',1:5,sep='')
> 
> > d.t <- reshape(data = dat, varying = list(names(dat)[2:6]), v.names = 'y',
> times = seq(0,4,1), idvar = 'id', drop = NULL, dir = 'l')
> 
> > m1 <- lmer(form = y ~ time + (1|id), data = d.t, fam = gaussian, R = F, na
> = na.exclude)
> > m1
> Linear mixed model fit by maximum likelihood 
> Formula: y ~ time + (1 | id) 
>    Data: d.t 
>   AIC  BIC logLik deviance REMLdev
>  1370 1387   -681     1362    1371
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  id       (Intercept) 0.409    0.640   
>  Residual             0.955    0.977   
> Number of obs: 500, groups: id, 100
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   1.0000     0.0860    11.6
> time          1.0000     0.0309    32.4
> 
> Correlation of Fixed Effects:
>      (Intr)
> time -0.719
> 
> > x <- mcmcsamp(obj = m1, n = 1e3)
> 
> > str(x)
> Formal class 'merMCMC' [package "lme4"] with 9 slots
>   ..@ Gp      : int [1:2] 0 100
>   ..@ ST      : num [1, 1:1000] 0.655 0.529 0.448 0.401 0.406 ...
>   ..@ call    : language lmer(formula = y ~ time + (1 | id), data = d.t,
> REML = F, na.action = na.exclude)
>   ..@ deviance: num [1:1000] 1362 1350 1353 1359 1364 ...
>   ..@ dims    : Named int [1:18] 1 500 2 100 1 1 0 0 2 5 ...
>   .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
>   ..@ fixef   : num [1:2, 1:1000] 1 1 1.093 0.989 1.038 ...
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : chr [1:2] "(Intercept)" "time"
>   .. .. ..$ : NULL
>   ..@ nc      : int 1
>   ..@ ranef   : num[1:100, 0 ] 
>   ..@ sigma   : num [1, 1:1000] 0.977 0.853 0.84 0.862 0.921 ...
> 
> ##then I did the following which is not in the help file
> > xyplot(x)##check 
> 
> > x <- mcmcsamp(obj = m41, n = 1e3)
> 
> > summary(t(x at fixef))
>   (Intercept)       emosympt          schprob        totalnetscr    
>  Min.   : 1.82   Min.   :-0.4772   Min.   :-0.206   Min.   :-0.529  
>  1st Qu.:22.11   1st Qu.:-0.1980   1st Qu.: 0.176   1st Qu.:-0.434  
>  Median :27.10   Median :-0.1144   Median : 0.268   Median :-0.408  
>  Mean   :27.20   Mean   :-0.1184   Mean   : 0.262   Mean   :-0.407  
>  3rd Qu.:32.15   3rd Qu.:-0.0416   3rd Qu.: 0.348   3rd Qu.:-0.381  
>  Max.   :51.48   Max.   : 0.2662   Max.   : 0.636   Max.   :-0.264  
> 
> > colMeans(t(x at fixef))
> (Intercept)    emosympt     schprob totalnetscr 
>      27.200      -0.118       0.262      -0.407 
> ##UCL and LCL
> > colMeans(t(x at fixef)) + 1.96*sqrt(colVars(t(x at fixef)))
> (Intercept)    emosympt     schprob totalnetscr 
>      41.537       0.107       0.526      -0.330 
> 
> > colMeans(t(x at fixef)) - 1.96*sqrt(colVars(t(x at fixef)))
> (Intercept)    emosympt     schprob totalnetscr 
>    12.86248    -0.34386    -0.00259    -0.48348
> 
> Respectfully,
> 
> Frank R. Lawrence
> 
> # -----Original Message-----
> # From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
> # Sent: Saturday, December 06, 2008 2:45 PM
> # To: Frank Lawrence
> # Subject: Re: [R-sig-ME] mcmcsamp
> # 
> # Hi Frank,
> # 
> # can you provide a minimal, executable example?
> # 
> # Cheers
> # 
> # Andrew
> # 
> # On Fri, Dec 05, 2008 at 02:53:34PM -0500, Frank Lawrence wrote:
> # > I was attempting to run mcmcsamp on an lmer model without success.  From
> # the
> # > archive I noted that some users had a similar difficulty a couple of
> months
> # > ago with obtaining fixed effect estimates.  I was wondering if there is
> any
> # > new information on using mcmcsamp to obtain confidence intervals for
> fixed
> # > effects from an lmer object.
> # >
> # > Windows Vista, Home Premium. R-2.8
> # >
> # > Respectfully,
> # >
> # > Frank R. Lawrence
> # >
> # > _______________________________________________
> # > R-sig-mixed-models at r-project.org mailing list
> # > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> # 
> # --
> # Andrew Robinson
> # Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> # University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> # http://www.ms.unimelb.edu.au/~andrewpr
> # http://blogs.mbs.edu/fishing-in-the-bay/

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From David.Duffy at qimr.edu.au  Mon Dec  8 23:07:26 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 9 Dec 2008 08:07:26 +1000 (EST)
Subject: [R-sig-ME] residual variances in glmer
In-Reply-To: <493D3381.9080308@tours.inra.fr>
References: <493D3381.9080308@tours.inra.fr>
Message-ID: <Pine.LNX.4.64.0812090802230.28334@orpheus.qimr.edu.au>

On Mon, 8 Dec 2008, Herv? CHAPUIS wrote:

> Hello every one.
> I am a real R-mix models-newbie. A colleague told me I should ask  the  list.
> Well, when dealing with  discrete traits  in animal genetics, we have many 
> possibilities :
> - use an home-made program based, for instance, on Gianola & Foulley (1993) 
> algorithm.
> - treat the data as a classical gaussian performance, use a linear mixed 
> model (lmer works fine) and then compute the heritability coefficient on the 
> observed scale  as h2 = 4 x sire_variance (sire_variance + dam_variance 
> + residual_variance).
> After that, use the Dempster & Lerner formula to obtain the heritability on 
> the  underlying scale.
> - or use directly a general linear mixed model.
>
> That's what I have done but I have been puzzled by the results.
> On simulated data, (I have simulated a vector of gaussian performances 
> accounting for Mendelian rules, before transforming them into binary data 
> through a given threshold value)  the first two options give me  "good" 
> results and an estimated h? reasonably close  to the expected value.
> If  I use glmer instead of lmer, I still obtain a result but I cannot safely 
> obtain the h2 assuming that the residual variance is 1, can I ?
> If so, the estimated h2 is very high, if not above 1.
> Any hint ?
>

The problem is that in the binomial GLMM, the phenotypic variance varies 
according to the value of the intercept, which depends on included fixed 
effects etc.  There is an approximate heritability for this model 
described in Yazdi et al J. Dairy Sci. 85:1563??1577.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From minhuangr at gmail.com  Tue Dec  9 06:20:16 2008
From: minhuangr at gmail.com (huang min)
Date: Tue, 9 Dec 2008 13:20:16 +0800
Subject: [R-sig-ME] variance of the variance components
Message-ID: <bfc676680812082120t7a9c1670wd3dc07640e2bc1ff@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081209/1ca91422/attachment.pl>

From HDoran at air.org  Tue Dec  9 11:37:11 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Dec 2008 05:37:11 -0500
Subject: [R-sig-ME] variance of the variance components
References: <bfc676680812082120t7a9c1670wd3dc07640e2bc1ff@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01C649BA@DC1EXCL01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081209/d2d77194/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Dec  9 13:59:18 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 9 Dec 2008 13:59:18 +0100
Subject: [R-sig-ME] Out of memory with spatial correlation.
Message-ID: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>

Dear all,

My model runs fine with just the fixed and random effects. But when I
add a spatial correlation structure it runs out of memory (Error: cannot
allocate vector of size 185.6 Mb). The problem is that the data is
clearly spatially correlated. I have tried the simplify the fixed
effects and the random effects with no avail. So the problem is probably
in the correlation structure (see code below). Any suggestion on how to
incorporate the spatial autocorrelation?

A description of the design.

We are testing a methodology to monitor bats. Basically volunteers ride
along a predefined route by car (30 km/h) or by bike (15 km/h). They
record the echolocation sounds of the bats at fixed intervals. There
position is tracked by GPS so we know were each recording was made. An
expert counts the number of pulses in each recording.
We predefined 10 routes, 5 for the cars and 5 for the bikes. Each car
route overlaps with one bike route. So we have 5 groups of routes.
Within each group we have an longer car route that overlaps with a
shorter bike route. There is no overlap between groups. All routes were
driven three times, all vehicules started their route simultanious.
We have about 400 recordings per route of 10 routes at 3 occasions =
12000 rows.

Our nullhypothese is that the average number of recordings does not
depend on the type of vehicule.

The model that fails is:
library(nlme)
lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group,
correlation = corExp(form = ~ X + Y))

The model works if I omit the correlation structure:
lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)

I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. --mem-size is
set at the maximum (2047 MB).

Regards,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From frl2 at psu.edu  Mon Dec  8 21:09:28 2008
From: frl2 at psu.edu (Frank Lawrence)
Date: Mon, 8 Dec 2008 15:09:28 -0500
Subject: [R-sig-ME] mcmcsamp
In-Reply-To: <20081208195130.GE1252@ms.unimelb.edu.au>
References: <003001c95713$29172e70$7b458b50$@edu>
	<20081206194521.GR1253@ms.unimelb.edu.au>
	<000001c95949$0250e370$06f2aa50$@edu>
	<20081208195130.GE1252@ms.unimelb.edu.au>
Message-ID: <003601c95970$e06e3d20$a14ab760$@edu>

Hi Andrew:

In the past I have been able to obtain confidence intervals for the
parameter estimates using something like the following:

     set.seed(281)
	nn <- 2e3
     ss1 <- mcmcsamp(obj = x, n = nn, v = F)#markov chain sampling from
posterior distribution of parameter estimates
     k <- as.matrix(t(apply(X = ss1, MARGIN = 2, FUN = quantile, p =
c(0.025, 0.5, 0.975), na = T, names = T, type = 7)))
     colnames(k) <- c('2.5%', '50%', '97.5%')

The series of commands no longer works.  I transitioned to something like I
had illustrated below but was not sure it was the most effective or
efficient syntax.  I was wondering if there was a better alternative.

Respectfully,

Frank R. Lawrence


# -----Original Message-----
# From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
# Sent: Monday, December 08, 2008 2:52 PM
# To: Frank Lawrence
# Cc: R-sig-mixed-models at r-project.org
# Subject: Re: [R-sig-ME] mcmcsamp
# 
# Hi Frank,
# 
# thanks ... but, I guess I should have asked you for a commentary as
# well.   Can you make our lives easier by identifying exactly what your
# problem is?
# 
# Andrew
# 
# On Mon, Dec 08, 2008 at 10:24:05AM -0500, Frank Lawrence wrote:
# > Hi Andrew:
# >
# > Sorry for not including the example at the outset.
# >
# > >sessionInfo()
# > R version 2.8.0 (2008-10-20)
# > i386-pc-mingw32
# >
# > locale:
# > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
# > States.1252;LC_MONETARY=English_United
# > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
# >
# > attached base packages:
# >  [1] grid      splines   stats     graphics  grDevices datasets
# >  [7] tcltk     utils     methods   base
# >
# > other attached packages:
# >  [1] MCMCpack_0.9-5     coda_0.13-3        statmod_1.3.8
# >  [4] polycor_0.7-6      sfsmisc_1.0-6      mvtnorm_0.9-2
# >  [7] xtable_1.5-4       prettyR_1.3-5      lme4_0.999375-27
# > [10] Matrix_0.999375-16 effects_2.0-0      nnet_7.2-44
# > [13] mvnormtest_0.1-6   xlsReadWrite_1.3.2 gmodels_2.14.1
# > [16] gtools_2.5.0       latticeExtra_0.5-4 lattice_0.17-17
# > [19] RColorBrewer_1.0-2 doBy_3.6           foreign_0.8-29
# > [22] Design_2.1-2       survival_2.34-1    e1071_1.5-18
# > [25] class_7.2-44       car_1.2-9          mitools_2.0
# > [28] MASS_7.2-44        svSocket_0.9-5     TinnR_1.0.2
# > [31] R2HTML_1.59        Hmisc_3.4-4
# >
# > ##artificial data
# > > nn <- 1e2
# >
# > > mm <- seq(1,5,1)
# >
# > > cv  <- matrix(data = rep(x = 0.3, times = 25), nc = 5, nr = 5)
# >
# > > diag(cv) <- 1
# >
# > > dat <- cbind.data.frame(id = seq(1,nn,1), mvrnorm(n = nn, m = mm, S =
cv,
# > emp = T))
# >
# > > names(dat)[2:6] <- paste('y',1:5,sep='')
# >
# > > d.t <- reshape(data = dat, varying = list(names(dat)[2:6]), v.names =
# 'y',
# > times = seq(0,4,1), idvar = 'id', drop = NULL, dir = 'l')
# >
# > > m1 <- lmer(form = y ~ time + (1|id), data = d.t, fam = gaussian, R =
F,
# na
# > = na.exclude)
# > > m1
# > Linear mixed model fit by maximum likelihood
# > Formula: y ~ time + (1 | id)
# >    Data: d.t
# >   AIC  BIC logLik deviance REMLdev
# >  1370 1387   -681     1362    1371
# > Random effects:
# >  Groups   Name        Variance Std.Dev.
# >  id       (Intercept) 0.409    0.640
# >  Residual             0.955    0.977
# > Number of obs: 500, groups: id, 100
# >
# > Fixed effects:
# >             Estimate Std. Error t value
# > (Intercept)   1.0000     0.0860    11.6
# > time          1.0000     0.0309    32.4
# >
# > Correlation of Fixed Effects:
# >      (Intr)
# > time -0.719
# >
# > > x <- mcmcsamp(obj = m1, n = 1e3)
# >
# > > str(x)
# > Formal class 'merMCMC' [package "lme4"] with 9 slots
# >   ..@ Gp      : int [1:2] 0 100
# >   ..@ ST      : num [1, 1:1000] 0.655 0.529 0.448 0.401 0.406 ...
# >   ..@ call    : language lmer(formula = y ~ time + (1 | id), data = d.t,
# > REML = F, na.action = na.exclude)
# >   ..@ deviance: num [1:1000] 1362 1350 1353 1359 1364 ...
# >   ..@ dims    : Named int [1:18] 1 500 2 100 1 1 0 0 2 5 ...
# >   .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
# >   ..@ fixef   : num [1:2, 1:1000] 1 1 1.093 0.989 1.038 ...
# >   .. ..- attr(*, "dimnames")=List of 2
# >   .. .. ..$ : chr [1:2] "(Intercept)" "time"
# >   .. .. ..$ : NULL
# >   ..@ nc      : int 1
# >   ..@ ranef   : num[1:100, 0 ]
# >   ..@ sigma   : num [1, 1:1000] 0.977 0.853 0.84 0.862 0.921 ...
# >
# > ##then I did the following which is not in the help file
# > > xyplot(x)##check
# >
# > > x <- mcmcsamp(obj = m41, n = 1e3)
# >
# > > summary(t(x at fixef))
# >   (Intercept)       emosympt          schprob        totalnetscr
# >  Min.   : 1.82   Min.   :-0.4772   Min.   :-0.206   Min.   :-0.529
# >  1st Qu.:22.11   1st Qu.:-0.1980   1st Qu.: 0.176   1st Qu.:-0.434
# >  Median :27.10   Median :-0.1144   Median : 0.268   Median :-0.408
# >  Mean   :27.20   Mean   :-0.1184   Mean   : 0.262   Mean   :-0.407
# >  3rd Qu.:32.15   3rd Qu.:-0.0416   3rd Qu.: 0.348   3rd Qu.:-0.381
# >  Max.   :51.48   Max.   : 0.2662   Max.   : 0.636   Max.   :-0.264
# >
# > > colMeans(t(x at fixef))
# > (Intercept)    emosympt     schprob totalnetscr
# >      27.200      -0.118       0.262      -0.407
# > ##UCL and LCL
# > > colMeans(t(x at fixef)) + 1.96*sqrt(colVars(t(x at fixef)))
# > (Intercept)    emosympt     schprob totalnetscr
# >      41.537       0.107       0.526      -0.330
# >
# > > colMeans(t(x at fixef)) - 1.96*sqrt(colVars(t(x at fixef)))
# > (Intercept)    emosympt     schprob totalnetscr
# >    12.86248    -0.34386    -0.00259    -0.48348
# >
# > Respectfully,
# >
# > Frank R. Lawrence
# >
# > # -----Original Message-----
# > # From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
# > # Sent: Saturday, December 06, 2008 2:45 PM
# > # To: Frank Lawrence
# > # Subject: Re: [R-sig-ME] mcmcsamp
# > #
# > # Hi Frank,
# > #
# > # can you provide a minimal, executable example?
# > #
# > # Cheers
# > #
# > # Andrew
# > #
# > # On Fri, Dec 05, 2008 at 02:53:34PM -0500, Frank Lawrence wrote:
# > # > I was attempting to run mcmcsamp on an lmer model without success.
# From
# > # the
# > # > archive I noted that some users had a similar difficulty a couple of
# > months
# > # > ago with obtaining fixed effect estimates.  I was wondering if there
is
# > any
# > # > new information on using mcmcsamp to obtain confidence intervals for
# > fixed
# > # > effects from an lmer object.
# > # >
# > # > Windows Vista, Home Premium. R-2.8
# > # >
# > # > Respectfully,
# > # >
# > # > Frank R. Lawrence
# > # >
# > # > _______________________________________________
# > # > R-sig-mixed-models at r-project.org mailing list
# > # > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
# > #
# > # --
# > # Andrew Robinson
# > # Department of Mathematics and Statistics            Tel:
+61-3-8344-6410
# > # University of Melbourne, VIC 3010 Australia         Fax:
+61-3-8344-4599
# > # http://www.ms.unimelb.edu.au/~andrewpr
# > # http://blogs.mbs.edu/fishing-in-the-bay/
# 
# --
# Andrew Robinson
# Department of Mathematics and Statistics            Tel: +61-3-8344-6410
# University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
# http://www.ms.unimelb.edu.au/~andrewpr
# http://blogs.mbs.edu/fishing-in-the-bay/



From HDoran at air.org  Tue Dec  9 15:01:44 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 Dec 2008 09:01:44 -0500
Subject: [R-sig-ME] Out of memory with spatial correlation.
In-Reply-To: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7E031@DC1EXCL01.air.org>

Thierry

One option is to switch to lmer rather than lme. Of course, with lmer
you don't have the same options for correlation structures. So, what you
might consider is to "pre-whiten" your data using the methods outlined
in Pinhiero and Bates and then run the model using lmer.

In fact, that is what lme does. It "pre-whitens" the data and then runs
the model under normal assumptions. The only difference here is that you
would need to pre-whiten manually. 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of ONKELINX, Thierry
> Sent: Tuesday, December 09, 2008 7:59 AM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Out of memory with spatial correlation.
> 
> Dear all,
> 
> My model runs fine with just the fixed and random effects. 
> But when I add a spatial correlation structure it runs out of 
> memory (Error: cannot allocate vector of size 185.6 Mb). The 
> problem is that the data is clearly spatially correlated. I 
> have tried the simplify the fixed effects and the random 
> effects with no avail. So the problem is probably in the 
> correlation structure (see code below). Any suggestion on how 
> to incorporate the spatial autocorrelation?
> 
> A description of the design.
> 
> We are testing a methodology to monitor bats. Basically 
> volunteers ride along a predefined route by car (30 km/h) or 
> by bike (15 km/h). They record the echolocation sounds of the 
> bats at fixed intervals. There position is tracked by GPS so 
> we know were each recording was made. An expert counts the 
> number of pulses in each recording.
> We predefined 10 routes, 5 for the cars and 5 for the bikes. 
> Each car route overlaps with one bike route. So we have 5 
> groups of routes.
> Within each group we have an longer car route that overlaps 
> with a shorter bike route. There is no overlap between 
> groups. All routes were driven three times, all vehicules 
> started their route simultanious.
> We have about 400 recordings per route of 10 routes at 3 
> occasions = 12000 rows.
> 
> Our nullhypothese is that the average number of recordings 
> does not depend on the type of vehicule.
> 
> The model that fails is:
> library(nlme)
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| 
> Group, correlation = corExp(form = ~ X + Y))
> 
> The model works if I omit the correlation structure:
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)
> 
> I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. 
> --mem-size is set at the maximum (2047 MB).
> 
> Regards,
> 
> Thierry
> 
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute 
> for Nature and Forest Cel biometrie, methodologie en 
> kwaliteitszorg / Section biometrics, methodology and quality 
> assurance Gaverstraat 4 9500 Geraardsbergen Belgium tel. + 32 
> 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be 
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit bericht niet bevestigd is door een geldig 
> ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be 
> regarded as stating an official position of INBO, as long as 
> the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From d.rizopoulos at erasmusmc.nl  Tue Dec  9 15:13:35 2008
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Tue, 09 Dec 2008 15:13:35 +0100
Subject: [R-sig-ME] Out of memory with spatial correlation.
In-Reply-To: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>
Message-ID: <493E7D0F.8090300@erasmusmc.nl>

Is it reasonable to assume that spatial correlation only exists within 
groups, e.g.,

lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1 | Group, 
correlation = corExp(form = ~ X + Y | Group))


Best,
Dimitris


ONKELINX, Thierry wrote:
> Dear all,
> 
> My model runs fine with just the fixed and random effects. But when I
> add a spatial correlation structure it runs out of memory (Error: cannot
> allocate vector of size 185.6 Mb). The problem is that the data is
> clearly spatially correlated. I have tried the simplify the fixed
> effects and the random effects with no avail. So the problem is probably
> in the correlation structure (see code below). Any suggestion on how to
> incorporate the spatial autocorrelation?
> 
> A description of the design.
> 
> We are testing a methodology to monitor bats. Basically volunteers ride
> along a predefined route by car (30 km/h) or by bike (15 km/h). They
> record the echolocation sounds of the bats at fixed intervals. There
> position is tracked by GPS so we know were each recording was made. An
> expert counts the number of pulses in each recording.
> We predefined 10 routes, 5 for the cars and 5 for the bikes. Each car
> route overlaps with one bike route. So we have 5 groups of routes.
> Within each group we have an longer car route that overlaps with a
> shorter bike route. There is no overlap between groups. All routes were
> driven three times, all vehicules started their route simultanious.
> We have about 400 recordings per route of 10 routes at 3 occasions =
> 12000 rows.
> 
> Our nullhypothese is that the average number of recordings does not
> depend on the type of vehicule.
> 
> The model that fails is:
> library(nlme)
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group,
> correlation = corExp(form = ~ X + Y))
> 
> The model works if I omit the correlation structure:
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)
> 
> I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. --mem-size is
> set at the maximum (2047 MB).
> 
> Regards,
> 
> Thierry
> 
> 
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be 
> www.inbo.be 
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be regarded as stating 
> an official position of INBO, as long as the message is not confirmed by a duly 
> signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014



From burg4401 at uni-trier.de  Wed Dec 10 10:07:12 2008
From: burg4401 at uni-trier.de (burg4401 at uni-trier.de)
Date: Wed, 10 Dec 2008 10:07:12 +0100
Subject: [R-sig-ME] Significant anova results for identical Models in glmer
Message-ID: <200812101007.12864.burg4401@uni-trier.de>

Dear List,

when fitting two identical lmer Models and comparing them with 
anova() one Model has a significant p-value 
although obviously all coefficients and variances and likelihoods remain the 
same.

I think this comes from line 1000 in lmer.R (Rev 266)
pchisq(0,0,lower=F) == 0

I'm not concerned about someone putting in twice the same model, but 
apparently if two models with same degree of freedom are compared the pvalues 
are calculated on a dchisq(df=0) basis...
e.g. factor1 = SEX , factor2 = (higher than 1.78m)

Maybe I was looking in the wrong books, but I couldn't find an argument 
against this comparison. Could it be that the Problem lies in non nested 
parameter spaces?

Not least I'ld like to thank everyone in the list upcoming with interesting 
questions and answers. Overall many thanks to the programmers of lme4. Without 
lme4 I would have had problems to use my large matrices. Great Work.

Best Regards,
Pablo

Working example:
gm1 <- glmer(cbind(incidence, size - incidence) ~0+ period + (1 | herd), 
family = binomial, data = cbpp)

gm2 <- glmer(cbind(incidence, size - incidence) ~ -1 + period + (1 | herd), 
family = binomial, data = cbpp)

anova(gm1,gm2)             
Data: cbpp                   
Models:                      
gm1: cbind(incidence, size - incidence) ~ 0 + period + (1 | herd)
gm2: cbind(incidence, size - incidence) ~ -1 + period + (1 | herd)
    Df     AIC     BIC  logLik Chisq Chi Df Pr(>Chisq)            
gm1  5 110.096 120.223 -50.048                                    
gm2  5 110.096 120.223 -50.048     0      0  < 2.2e-16 ***        
---                                                               
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1    



From cotter.rs at gmail.com  Wed Dec 10 10:24:23 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Wed, 10 Dec 2008 10:24:23 +0100
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
Message-ID: <742479270812100124j77555e56i6008915643ead1b3@mail.gmail.com>

Dear all,

Sorry if the question i stupid, I'm pretty new to this and have
googled, and tried the help in R without finding a answer.

I have sucsessfully used glmm, lmer {lme4}, family binomial. By using
the summary (mod), I get the parameter estimates, but when using anova
(mod) I get this error message: Error in anova(mod) :  single argument
anova for GLMMs not yet implemented.

I'm used to run lme {nlme} by using both summary () and anova (), is
that impossible when running glmm, lmer {lme4}?

Thanks for help

RS Cotter



From bolker at ufl.edu  Wed Dec 10 15:10:07 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Dec 2008 09:10:07 -0500
Subject: [R-sig-ME] Significant anova results for identical Models in
 glmer
In-Reply-To: <200812101007.12864.burg4401@uni-trier.de>
References: <200812101007.12864.burg4401@uni-trier.de>
Message-ID: <493FCDBF.5020100@ufl.edu>



burg4401 at uni-trier.de wrote:
> Dear List,
> 
> when fitting two identical lmer Models and comparing them with 
> anova() one Model has a significant p-value 
> although obviously all coefficients and variances and likelihoods remain the 
> same.
> 
> I think this comes from line 1000 in lmer.R (Rev 266)
> pchisq(0,0,lower=F) == 0
> 
> I'm not concerned about someone putting in twice the same model, but 
> apparently if two models with same degree of freedom are compared the pvalues 
> are calculated on a dchisq(df=0) basis...
> e.g. factor1 = SEX , factor2 = (higher than 1.78m)
> 
> Maybe I was looking in the wrong books, but I couldn't find an argument 
> against this comparison. Could it be that the Problem lies in non nested 
> parameter spaces?

  Yes.  If two models have the same df, they are either (1) identical
or (2) non-nested [and hence inappropriate for likelihood ratio tests,
which is what anova() implements].

  Whether one should try to catch these kinds of (arguably) user errors
depends on one's philosophy of software design ...

  cheers
    Ben Bolker



From bolker at ufl.edu  Wed Dec 10 16:56:38 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 10 Dec 2008 10:56:38 -0500
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
Message-ID: <493FE6B6.3000507@ufl.edu>


R.S. Cotter wrote:
> Dear all,
> 
> Sorry if the question i stupid, I'm pretty new to this and have
> googled, and tried the help in R without finding a answer.
> 
> I have sucsessfully used glmm, lmer {lme4}, family binomial. By using
> the summary (mod), I get the parameter estimates, but when using anova
> (mod) I get this error message: Error in anova(mod) :  single argument
> anova for GLMMs not yet implemented.
> 
> I'm used to run lme {nlme} by using both summary () and anova (), is
> that impossible when running glmm, lmer {lme4}?
> 
> Thanks for help
> 

  Not stupid.  (The only stupid questions are not-doing-your-homework
ones.)

  What information are you hoping to glean from anova(mod) ?
If it is p-values for individual predictors, or information
about "residual degrees of freedom", you're probably out of
luck: see the oft-repeated questions on this list and the FAQ entry
for why that's hard.

  (Feel free to write back to clarify what you have in mind --
but be warned that the answer is probably something along the
lines of "lme4 doesn't work that way, you're still thinking
in the classical sums-of-squares paradigm" ...)

  Ben Bolker



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From spencer.graves at pdf.com  Wed Dec 10 23:49:34 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 10 Dec 2008 14:49:34 -0800
Subject: [R-sig-ME] Testing if a variance component is zero?
Message-ID: <4940477E.1070906@pdf.com>

Hello All: 

      'anova' in 'lme4' to test a difference a zero variance component 
uses 'ML', at least in the following example: 


library(MEMSS)
fm1 <- lmer( score ~ Machine+(1|Worker), data = Machines )
fm2 <- lmer( score ~ Machine+(1|Worker/Machine), data = Machines )
anova( fm1, fm2 )
  
   fm1: score ~ Machine + (1 | Worker)
   fm2: score ~ Machine + (1 | Worker/Machine)
       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)   
   fm1  5  303.75  313.70 -146.88                            
   fm2  6  237.47  249.40 -112.73 68.289      1  < 2.2e-16 ***

fm1m <- lmer( score ~ Machine+(1|Worker), data = Machines, REML=FALSE )
logLik(fm1m)
   'log Lik.' -146.8516 (df=5)


      This surprised me, because I would have expected REML to be used 
in this case, at least according to my reading of Pinheiro and Bates 
(2000, Figure 2.4), which got very good agreement between simulation 
results and cutting in half the nominal REML-based p-values. 
     
      Has more recent work suggested that Pinheiro and Bates (2000, 
Figure 2.4) is too specialized to worry about -- and this kind of 
'anova' has largely been obsoleted by "mcmcsamp"? 

      Thanks,
      Spencer Graves
 sessionInfo()
R version 2.8.0 (2008-10-20)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] MEMSS_0.3-4        lme4_0.999375-27   Matrix_0.999375-16 
lattice_0.17-17  

loaded via a namespace (and not attached):
[1] grid_2.8.0



From epistat at gmail.com  Thu Dec 11 01:52:35 2008
From: epistat at gmail.com (zhijie zhang)
Date: Thu, 11 Dec 2008 08:52:35 +0800
Subject: [R-sig-ME] single argument anova for GLMMs not yet
Message-ID: <2fc17e30812101652m3e46463cx8e0856c60abdb167@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081211/35a1f5dc/attachment.pl>

From kmjamsen at unimelb.edu.au  Thu Dec 11 07:37:10 2008
From: kmjamsen at unimelb.edu.au (Kris Jamsen)
Date: Thu, 11 Dec 2008 17:37:10 +1100
Subject: [R-sig-ME] xtable question
Message-ID: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081211/6cda60b3/attachment.pl>

From HStevens at muohio.edu  Thu Dec 11 10:30:32 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Thu, 11 Dec 2008 04:30:32 -0500
Subject: [R-sig-ME] xtable question
In-Reply-To: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>
References: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>
Message-ID: <3D46FAE3-AA47-4620-ACAF-7E229E2EE928@muohio.edu>

Hi Kris,
I don't know which kind of nlme object your are trying to use, but  
can you coerce it to a data.frame? If you can't, then maybe the  
object is not amenable to use in xtable. Is the object matrix-like or  
dataframe-like?
Hank
On Dec 11, 2008, at 1:37 AM, Kris Jamsen wrote:

> Hi all,
>
>
>
> I am trying to use xtable with an nlme object, but it won't let  
> me.  The
> help menu says that I can extend the list of available classes by
> writing methods for the generic function xtable, but I don't know  
> how to
> do this.  Has anyone already done this?
>
>
>
> Cheers,
>
>
>
> Kris
>
>
>
> Kris Jamsen
>
> Research Fellow
>
> Centre for Molecular, Environmental,
>
> Genetic and Analytic (MEGA) Epidemiology
>
> Level 1, 723 Swanston St
>
> The University of Melbourne
>
> Victoria, 3010
>
> AUSTRALIA
>
>
>
> Email: kmjamsen at unimelb.edu.au <mailto:kmjamsen at unimelb.edu.au>
>
> Ph: +61 (0)3 8344 0700
>
> Fax: +61 (0)3 9349 5815
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From Thierry.ONKELINX at inbo.be  Thu Dec 11 14:10:08 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 11 Dec 2008 14:10:08 +0100
Subject: [R-sig-ME] Out of memory with spatial correlation.
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE01A7E031@DC1EXCL01.air.org>
References: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>
	<ED7B522EE00C9A4FA515AA71724D61EE01A7E031@DC1EXCL01.air.org>
Message-ID: <2E9C414912813E4EB981326983E0A10405D851FF@inboexch.inbo.be>

Dear Harold,

Could you point me to the relevant section in Pinheiro and Bates? I have
been looking for it, but can't find it.

Thanks,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Doran, Harold [mailto:HDoran at air.org] 
Verzonden: dinsdag 9 december 2008 15:02
Aan: ONKELINX, Thierry; R-sig-mixed-models at r-project.org
Onderwerp: RE: [R-sig-ME] Out of memory with spatial correlation.

Thierry

One option is to switch to lmer rather than lme. Of course, with lmer
you don't have the same options for correlation structures. So, what you
might consider is to "pre-whiten" your data using the methods outlined
in Pinhiero and Bates and then run the model using lmer.

In fact, that is what lme does. It "pre-whitens" the data and then runs
the model under normal assumptions. The only difference here is that you
would need to pre-whiten manually. 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of ONKELINX, Thierry
> Sent: Tuesday, December 09, 2008 7:59 AM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Out of memory with spatial correlation.
> 
> Dear all,
> 
> My model runs fine with just the fixed and random effects. 
> But when I add a spatial correlation structure it runs out of 
> memory (Error: cannot allocate vector of size 185.6 Mb). The 
> problem is that the data is clearly spatially correlated. I 
> have tried the simplify the fixed effects and the random 
> effects with no avail. So the problem is probably in the 
> correlation structure (see code below). Any suggestion on how 
> to incorporate the spatial autocorrelation?
> 
> A description of the design.
> 
> We are testing a methodology to monitor bats. Basically 
> volunteers ride along a predefined route by car (30 km/h) or 
> by bike (15 km/h). They record the echolocation sounds of the 
> bats at fixed intervals. There position is tracked by GPS so 
> we know were each recording was made. An expert counts the 
> number of pulses in each recording.
> We predefined 10 routes, 5 for the cars and 5 for the bikes. 
> Each car route overlaps with one bike route. So we have 5 
> groups of routes.
> Within each group we have an longer car route that overlaps 
> with a shorter bike route. There is no overlap between 
> groups. All routes were driven three times, all vehicules 
> started their route simultanious.
> We have about 400 recordings per route of 10 routes at 3 
> occasions = 12000 rows.
> 
> Our nullhypothese is that the average number of recordings 
> does not depend on the type of vehicule.
> 
> The model that fails is:
> library(nlme)
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| 
> Group, correlation = corExp(form = ~ X + Y))
> 
> The model works if I omit the correlation structure:
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)
> 
> I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. 
> --mem-size is set at the maximum (2047 MB).
> 
> Regards,
> 
> Thierry
> 
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute 
> for Nature and Forest Cel biometrie, methodologie en 
> kwaliteitszorg / Section biometrics, methodology and quality 
> assurance Gaverstraat 4 9500 Geraardsbergen Belgium tel. + 32 
> 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be 
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit bericht niet bevestigd is door een geldig
> ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be 
> regarded as stating an official position of INBO, as long as 
> the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Thierry.ONKELINX at inbo.be  Thu Dec 11 14:12:38 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 11 Dec 2008 14:12:38 +0100
Subject: [R-sig-ME] Out of memory with spatial correlation.
In-Reply-To: <493E7D0F.8090300@erasmusmc.nl>
References: <2E9C414912813E4EB981326983E0A10405D125A3@inboexch.inbo.be>
	<493E7D0F.8090300@erasmusmc.nl>
Message-ID: <2E9C414912813E4EB981326983E0A10405D85200@inboexch.inbo.be>

Dear Dimitris,

Restricting the correlation to the Group (and to Occasion nested in
Group) did not solve my problem. I even tried to subset the data to one
groep with no avail.

Regards,

Thierry 


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Dimitris Rizopoulos [mailto:d.rizopoulos at erasmusmc.nl] 
Verzonden: dinsdag 9 december 2008 15:14
Aan: ONKELINX, Thierry
CC: R-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Out of memory with spatial correlation.

Is it reasonable to assume that spatial correlation only exists within 
groups, e.g.,

lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1 | Group, 
correlation = corExp(form = ~ X + Y | Group))


Best,
Dimitris


ONKELINX, Thierry wrote:
> Dear all,
> 
> My model runs fine with just the fixed and random effects. But when I
> add a spatial correlation structure it runs out of memory (Error:
cannot
> allocate vector of size 185.6 Mb). The problem is that the data is
> clearly spatially correlated. I have tried the simplify the fixed
> effects and the random effects with no avail. So the problem is
probably
> in the correlation structure (see code below). Any suggestion on how
to
> incorporate the spatial autocorrelation?
> 
> A description of the design.
> 
> We are testing a methodology to monitor bats. Basically volunteers
ride
> along a predefined route by car (30 km/h) or by bike (15 km/h). They
> record the echolocation sounds of the bats at fixed intervals. There
> position is tracked by GPS so we know were each recording was made. An
> expert counts the number of pulses in each recording.
> We predefined 10 routes, 5 for the cars and 5 for the bikes. Each car
> route overlaps with one bike route. So we have 5 groups of routes.
> Within each group we have an longer car route that overlaps with a
> shorter bike route. There is no overlap between groups. All routes
were
> driven three times, all vehicules started their route simultanious.
> We have about 400 recordings per route of 10 routes at 3 occasions =
> 12000 rows.
> 
> Our nullhypothese is that the average number of recordings does not
> depend on the type of vehicule.
> 
> The model that fails is:
> library(nlme)
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group,
> correlation = corExp(form = ~ X + Y))
> 
> The model works if I omit the correlation structure:
> lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)
> 
> I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. --mem-size
is
> set at the maximum (2047 MB).
> 
> Regards,
> 
> Thierry
> 
> 
>
------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be 
> www.inbo.be 
> 
> To call in the statistician after the experiment is done may be no
more
> than asking him to perform a post-mortem examination: he may be able
to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does
not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de
schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit bericht niet
bevestigd is
> door een geldig ondertekend document. The views expressed in  this
message 
> and any annex are purely those of the writer and may not be regarded
as stating 
> an official position of INBO, as long as the message is not confirmed
by a duly 
> signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From HDoran at air.org  Thu Dec 11 14:55:12 2008
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Dec 2008 08:55:12 -0500
Subject: [R-sig-ME] Out of memory with spatial correlation.
In-Reply-To: <2E9C414912813E4EB981326983E0A10405D851FF@inboexch.inbo.be>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01A7E1A7@DC1EXCL01.air.org>

Refer to sections 5.1 et seq for the linear transformations 

> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
> Sent: Thursday, December 11, 2008 8:10 AM
> To: Doran, Harold; R-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Out of memory with spatial correlation.
> 
> Dear Harold,
> 
> Could you point me to the relevant section in Pinheiro and 
> Bates? I have been looking for it, but can't find it.
> 
> Thanks,
> 
> Thierry
> 
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute 
> for Nature and Forest Cel biometrie, methodologie en 
> kwaliteitszorg / Section biometrics, methodology and quality 
> assurance Gaverstraat 4 9500 Geraardsbergen Belgium tel. + 32 
> 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be 
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
> 
> -----Oorspronkelijk bericht-----
> Van: Doran, Harold [mailto:HDoran at air.org]
> Verzonden: dinsdag 9 december 2008 15:02
> Aan: ONKELINX, Thierry; R-sig-mixed-models at r-project.org
> Onderwerp: RE: [R-sig-ME] Out of memory with spatial correlation.
> 
> Thierry
> 
> One option is to switch to lmer rather than lme. Of course, 
> with lmer you don't have the same options for correlation 
> structures. So, what you might consider is to "pre-whiten" 
> your data using the methods outlined in Pinhiero and Bates 
> and then run the model using lmer.
> 
> In fact, that is what lme does. It "pre-whitens" the data and 
> then runs the model under normal assumptions. The only 
> difference here is that you would need to pre-whiten manually. 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of 
> > ONKELINX, Thierry
> > Sent: Tuesday, December 09, 2008 7:59 AM
> > To: R-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Out of memory with spatial correlation.
> > 
> > Dear all,
> > 
> > My model runs fine with just the fixed and random effects. 
> > But when I add a spatial correlation structure it runs out 
> of memory 
> > (Error: cannot allocate vector of size 185.6 Mb). The 
> problem is that 
> > the data is clearly spatially correlated. I have tried the simplify 
> > the fixed effects and the random effects with no avail. So 
> the problem 
> > is probably in the correlation structure (see code below). Any 
> > suggestion on how to incorporate the spatial autocorrelation?
> > 
> > A description of the design.
> > 
> > We are testing a methodology to monitor bats. Basically volunteers 
> > ride along a predefined route by car (30 km/h) or by bike 
> (15 km/h). 
> > They record the echolocation sounds of the bats at fixed intervals. 
> > There position is tracked by GPS so we know were each recording was 
> > made. An expert counts the number of pulses in each recording.
> > We predefined 10 routes, 5 for the cars and 5 for the bikes. 
> > Each car route overlaps with one bike route. So we have 5 groups of 
> > routes.
> > Within each group we have an longer car route that overlaps with a 
> > shorter bike route. There is no overlap between groups. All routes 
> > were driven three times, all vehicules started their route 
> > simultanious.
> > We have about 400 recordings per route of 10 routes at 3 
> occasions = 
> > 12000 rows.
> > 
> > Our nullhypothese is that the average number of recordings does not 
> > depend on the type of vehicule.
> > 
> > The model that fails is:
> > library(nlme)
> > lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group, 
> > correlation = corExp(form = ~ X + Y))
> > 
> > The model works if I omit the correlation structure:
> > lme(log(Pulses + 1) ~ Transport + Occasion, random = ~ 1| Group)
> > 
> > I'm using R 2.8.0 with nlme 3.1-89 on WinXP with 2GB RAM. 
> > --mem-size is set at the maximum (2047 MB).
> > 
> > Regards,
> > 
> > Thierry
> > 
> > 
> > --------------------------------------------------------------
> > ----------
> > ----
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute 
> for Nature 
> > and Forest Cel biometrie, methodologie en kwaliteitszorg / Section 
> > biometrics, methodology and quality assurance Gaverstraat 4 9500 
> > Geraardsbergen Belgium tel. + 32
> > 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be
> > 
> > To call in the statistician after the experiment is done may be no 
> > more than asking him to perform a post-mortem
> > examination: he may be able to say what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> > 
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> > 
> > The combination of some data and an aching desire for an 
> answer does 
> > not ensure that a reasonable answer can be extracted from a 
> given body 
> > of data.
> > ~ John Tukey
> > 
> > Dit bericht en eventuele bijlagen geven enkel de visie van de 
> > schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit 
> > bericht niet bevestigd is door een geldig ondertekend document. The 
> > views expressed in  this message and any annex are purely 
> those of the 
> > writer and may not be regarded as stating an official position of 
> > INBO, as long as the message is not confirmed by a duly signed 
> > document.
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit bericht niet bevestigd is door een geldig 
> ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be 
> regarded as stating an official position of INBO, as long as 
> the message is not confirmed by a duly signed document.
> 



From bates at stat.wisc.edu  Thu Dec 11 15:31:56 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Dec 2008 08:31:56 -0600
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <493FE6B6.3000507@ufl.edu>
References: <493FE6B6.3000507@ufl.edu>
Message-ID: <40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>

On Wed, Dec 10, 2008 at 9:56 AM, Ben Bolker <bolker at ufl.edu> wrote:
>
> R.S. Cotter wrote:
>> Dear all,
>>
>> Sorry if the question i stupid, I'm pretty new to this and have
>> googled, and tried the help in R without finding a answer.
>>
>> I have sucsessfully used glmm, lmer {lme4}, family binomial. By using
>> the summary (mod), I get the parameter estimates, but when using anova
>> (mod) I get this error message: Error in anova(mod) :  single argument
>> anova for GLMMs not yet implemented.
>>
>> I'm used to run lme {nlme} by using both summary () and anova (), is
>> that impossible when running glmm, lmer {lme4}?
>>
>> Thanks for help
>>
>
>  Not stupid.  (The only stupid questions are not-doing-your-homework
> ones.)
>
>  What information are you hoping to glean from anova(mod) ?
> If it is p-values for individual predictors, or information
> about "residual degrees of freedom", you're probably out of
> luck: see the oft-repeated questions on this list and the FAQ entry
> for why that's hard.
>
>  (Feel free to write back to clarify what you have in mind --
> but be warned that the answer is probably something along the
> lines of "lme4 doesn't work that way, you're still thinking
> in the classical sums-of-squares paradigm" ...)

I certainly agree with Ben that new users, or any users for that
matter, should feel free to ask questions about what does and doesn't
seem to work in the lme4 package.  The many kind users of the package
have been generous in allowing me to experiment in the code, sometimes
breaking features that were formerly working, while I try to come to
an understanding of mixed-effects models and computational methods for
them.  The process has worked in that I feel that I understand them
much better than I did in the past.  However, doing things the way I
do - creating and maintaining a software package that will allow for
fitting general versions of the model while I am still experimenting
with the overall design - is an intensive and, regrettably, slow way
of doing research.  My thanks to those who have had the tolerance to
take this journey with me.

The particular issue of not providing sequential anova summary for a
generalized linear mixed model is related to the "quasi" families of
conditional distributions.  Families like "binomial" or "poisson" or
"Gamma" or the default "gaussian" family (I find the capitalization of
those names to be interesting - the two proper nouns, Poisson and
Gaussian, are not capitalized and the common noun. gamma, is)
represent a probability distribution from which a likelihood can be
calculated.  The "quasi" families do not correspond to probability
distributions so they produce a quasi-likelihood which is used in the
GLM fitting.  I know how to add random effects to the linear predictor
for a model with a likelihood.  I'm not sure how it should be done for
the quasi families.  One can mimic the computations, but without a
sound theoretical basis, it is possible that the results could be
nonsense and I, at least, wouldn't know whether they were nonsense.

I may end up punting on the quasi families and simply provide some
parameter estimates without estimates of precision or, perhaps more
radically, not allow the quasi families to be used.  If you look at
the families provided in R you will see that the misleadingly named
"AIC" function in the family (it actually returns the deviance) is
only defined for binomial, Poisson, Gaussian and gamma families.
Those AIC functions evaluate probability densities or probability mass
functions and I can work with that.  I'm afraid I don't know enough
about the quasi families to make sense of them yet.



From bz73 at cornell.edu  Thu Dec 11 17:13:02 2008
From: bz73 at cornell.edu (Ben Zuckerberg)
Date: Thu, 11 Dec 2008 11:13:02 -0500
Subject: [R-sig-ME] Sample size and mixed models
Message-ID: <49413C0E.3070308@cornell.edu>

A very quick (and possibly silly) question for mixed modelers.  Certain 
metrics such as Nagelkerke's R2 and the sample size adjusted AICc 
require the user to specify the sample size.  What is the appropriate 
sample size to use in a mixed model where you might have hundreds of 
repeat samples on a smaller sample of sites (in this case, the sites are 
treated as the random factor)?  In my case, the lmer output will produce 
the following information: Number of obs: 10091, groups: ID, 444.  For 
calculating sample size adjusted statistics, would you use an effective 
sample size of 444?  Thank you.



From datkins at u.washington.edu  Thu Dec 11 16:52:40 2008
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 11 Dec 2008 07:52:40 -0800
Subject: [R-sig-ME] quasi,
 negbin in lmer (was: single argument anova for GLMMs not yet
 implemented)
Message-ID: <49413748.9070103@u.washington.edu>


Doug et al.--

For what it's worth -- and this is clearly just one opinion -- I don't 
see much need for qausi families in my own work or field (clinical 
psychology/psychiatry), though it would be great if we could get a 
negative binomial family to run -- even supplying theta, via the 
negative.binomial() family in MASS.  I think at one point that worked 
with glmer(), but recent listserv postings suggests it no longer does.

Again, just my personal opinion.

And, *many* thanks to Doug for putting together such a great piece of 
software.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu


On Wed, Dec 10, 2008 at 9:56 AM, Ben Bolker <bolker at ufl.edu> wrote:
 >
 > R.S. Cotter wrote:
 >> Dear all,
 >>
 >> Sorry if the question i stupid, I'm pretty new to this and have
 >> googled, and tried the help in R without finding a answer.
 >>
 >> I have sucsessfully used glmm, lmer {lme4}, family binomial. By using
 >> the summary (mod), I get the parameter estimates, but when using anova
 >> (mod) I get this error message: Error in anova(mod) :  single argument
 >> anova for GLMMs not yet implemented.
 >>
 >> I'm used to run lme {nlme} by using both summary () and anova (), is
 >> that impossible when running glmm, lmer {lme4}?
 >>
 >> Thanks for help
 >>
 >
 >  Not stupid.  (The only stupid questions are not-doing-your-homework
 > ones.)
 >
 >  What information are you hoping to glean from anova(mod) ?
 > If it is p-values for individual predictors, or information
 > about "residual degrees of freedom", you're probably out of
 > luck: see the oft-repeated questions on this list and the FAQ entry
 > for why that's hard.
 >
 >  (Feel free to write back to clarify what you have in mind --
 > but be warned that the answer is probably something along the
 > lines of "lme4 doesn't work that way, you're still thinking
 > in the classical sums-of-squares paradigm" ...)

I certainly agree with Ben that new users, or any users for that
matter, should feel free to ask questions about what does and doesn't
seem to work in the lme4 package.  The many kind users of the package
have been generous in allowing me to experiment in the code, sometimes
breaking features that were formerly working, while I try to come to
an understanding of mixed-effects models and computational methods for
them.  The process has worked in that I feel that I understand them
much better than I did in the past.  However, doing things the way I
do - creating and maintaining a software package that will allow for
fitting general versions of the model while I am still experimenting
with the overall design - is an intensive and, regrettably, slow way
of doing research.  My thanks to those who have had the tolerance to
take this journey with me.

The particular issue of not providing sequential anova summary for a
generalized linear mixed model is related to the "quasi" families of
conditional distributions.  Families like "binomial" or "poisson" or
"Gamma" or the default "gaussian" family (I find the capitalization of
those names to be interesting - the two proper nouns, Poisson and
Gaussian, are not capitalized and the common noun. gamma, is)
represent a probability distribution from which a likelihood can be
calculated.  The "quasi" families do not correspond to probability
distributions so they produce a quasi-likelihood which is used in the
GLM fitting.  I know how to add random effects to the linear predictor
for a model with a likelihood.  I'm not sure how it should be done for
the quasi families.  One can mimic the computations, but without a
sound theoretical basis, it is possible that the results could be
nonsense and I, at least, wouldn't know whether they were nonsense.

I may end up punting on the quasi families and simply provide some
parameter estimates without estimates of precision or, perhaps more
radically, not allow the quasi families to be used.  If you look at
the families provided in R you will see that the misleadingly named
"AIC" function in the family (it actually returns the deviance) is
only defined for binomial, Poisson, Gaussian and gamma families.
Those AIC functions evaluate probability densities or probability mass
functions and I can work with that.  I'm afraid I don't know enough
about the quasi families to make sense of them yet.



From martin.henery at unifr.ch  Thu Dec 11 18:47:33 2008
From: martin.henery at unifr.ch (HENERY Martin)
Date: Thu, 11 Dec 2008 18:47:33 +0100
Subject: [R-sig-ME] problem WITH mcmcsamp function in lme4 on Mac OSX
Message-ID: <220786D4-AC69-4E37-92AD-5DE707B1926D@unifr.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081211/99bd71f0/attachment.pl>

From maj at stats.waikato.ac.nz  Thu Dec 11 21:11:39 2008
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 12 Dec 2008 09:11:39 +1300
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
Message-ID: <494173FB.9040805@stats.waikato.ac.nz>

The following is how I think about this at the moment:

The quasi-likelihood approach is an attempt at a model-free approach to 
the problem of overdispersion in non-Gaussian regression situations 
where standard distributional assumptions fail to provide the observed 
mean-variance relationship.

The glmm approach, on the other hand, does not abandon models and 
likelihood but seeks to account for the observed mean-variance 
relationship by adding unobserved latent variables (random effects) to 
the model.

Seeking to combine the two approaches by using both quasilikelihood 
*and* random effects would seem to be asking for trouble as being able 
to use two tools on one problem would give a lot of flexibility to the 
parameter estimation; probably leading to a very flat quasilikelihood 
surface and ill-determined optima.

But all of the above is only thoughts without the benefit of either 
serious attempts at fitting real data or doing serious theory so I will 
defer to anyone who has done either!

Philosophically, at least, there seems to be clash between the two 
approaches and I doubt that attempts to combine them will be successful.

Murray Jorgensen


Douglas Bates wrote:
> On Wed, Dec 10, 2008 at 9:56 AM, Ben Bolker <bolker at ufl.edu> wrote:
>> R.S. Cotter wrote:
>>> Dear all,
>>>
>>> Sorry if the question i stupid, I'm pretty new to this and have
>>> googled, and tried the help in R without finding a answer.
>>>
>>> I have sucsessfully used glmm, lmer {lme4}, family binomial. By using
>>> the summary (mod), I get the parameter estimates, but when using anova
>>> (mod) I get this error message: Error in anova(mod) :  single argument
>>> anova for GLMMs not yet implemented.
>>>
>>> I'm used to run lme {nlme} by using both summary () and anova (), is
>>> that impossible when running glmm, lmer {lme4}?
>>>
>>> Thanks for help
>>>
>>  Not stupid.  (The only stupid questions are not-doing-your-homework
>> ones.)
>>
>>  What information are you hoping to glean from anova(mod) ?
>> If it is p-values for individual predictors, or information
>> about "residual degrees of freedom", you're probably out of
>> luck: see the oft-repeated questions on this list and the FAQ entry
>> for why that's hard.
>>
>>  (Feel free to write back to clarify what you have in mind --
>> but be warned that the answer is probably something along the
>> lines of "lme4 doesn't work that way, you're still thinking
>> in the classical sums-of-squares paradigm" ...)
> 
> I certainly agree with Ben that new users, or any users for that
> matter, should feel free to ask questions about what does and doesn't
> seem to work in the lme4 package.  The many kind users of the package
> have been generous in allowing me to experiment in the code, sometimes
> breaking features that were formerly working, while I try to come to
> an understanding of mixed-effects models and computational methods for
> them.  The process has worked in that I feel that I understand them
> much better than I did in the past.  However, doing things the way I
> do - creating and maintaining a software package that will allow for
> fitting general versions of the model while I am still experimenting
> with the overall design - is an intensive and, regrettably, slow way
> of doing research.  My thanks to those who have had the tolerance to
> take this journey with me.
> 
> The particular issue of not providing sequential anova summary for a
> generalized linear mixed model is related to the "quasi" families of
> conditional distributions.  Families like "binomial" or "poisson" or
> "Gamma" or the default "gaussian" family (I find the capitalization of
> those names to be interesting - the two proper nouns, Poisson and
> Gaussian, are not capitalized and the common noun. gamma, is)
> represent a probability distribution from which a likelihood can be
> calculated.  The "quasi" families do not correspond to probability
> distributions so they produce a quasi-likelihood which is used in the
> GLM fitting.  I know how to add random effects to the linear predictor
> for a model with a likelihood.  I'm not sure how it should be done for
> the quasi families.  One can mimic the computations, but without a
> sound theoretical basis, it is possible that the results could be
> nonsense and I, at least, wouldn't know whether they were nonsense.
> 
> I may end up punting on the quasi families and simply provide some
> parameter estimates without estimates of precision or, perhaps more
> radically, not allow the quasi families to be used.  If you look at
> the families provided in R you will see that the misleadingly named
> "AIC" function in the family (it actually returns the deviance) is
> only defined for binomial, Poisson, Gaussian and gamma families.
> Those AIC functions evaluate probability densities or probability mass
> functions and I can work with that.  I'm afraid I don't know enough
> about the quasi families to make sense of them yet.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 139 5862



From A.Robinson at ms.unimelb.edu.au  Thu Dec 11 21:52:00 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 12 Dec 2008 07:52:00 +1100
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <494173FB.9040805@stats.waikato.ac.nz>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
Message-ID: <20081211205200.GD1260@ms.unimelb.edu.au>

Echoing Murray's points here - nicely put, Murray - it seems to me
that the quasi-likelihood and the GLMM are different approaches to the
same problem.  

Can anyone provide a substantial example where random effects and
quasilikelihood have both been necessary?  

Best wishes,

Andrew


On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
> The following is how I think about this at the moment:
> 
> The quasi-likelihood approach is an attempt at a model-free approach to 
> the problem of overdispersion in non-Gaussian regression situations 
> where standard distributional assumptions fail to provide the observed 
> mean-variance relationship.
> 
> The glmm approach, on the other hand, does not abandon models and 
> likelihood but seeks to account for the observed mean-variance 
> relationship by adding unobserved latent variables (random effects) to 
> the model.
> 
> Seeking to combine the two approaches by using both quasilikelihood 
> *and* random effects would seem to be asking for trouble as being able 
> to use two tools on one problem would give a lot of flexibility to the 
> parameter estimation; probably leading to a very flat quasilikelihood 
> surface and ill-determined optima.
> 
> But all of the above is only thoughts without the benefit of either 
> serious attempts at fitting real data or doing serious theory so I will 
> defer to anyone who has done either!
> 
> Philosophically, at least, there seems to be clash between the two 
> approaches and I doubt that attempts to combine them will be successful.
> 
> Murray Jorgensen
> 
> 

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Thu Dec 11 21:58:39 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Dec 2008 14:58:39 -0600
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <20081211205200.GD1260@ms.unimelb.edu.au>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
Message-ID: <40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com>

On Thu, Dec 11, 2008 at 2:52 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> Echoing Murray's points here - nicely put, Murray - it seems to me
> that the quasi-likelihood and the GLMM are different approaches to the
> same problem.

I agree and I also appreciate Murray's elegant explanation.

> Can anyone provide a substantial example where random effects and
> quasilikelihood have both been necessary?

I'm kind of waiting for Ben Bolker to let us know how things look from
his perspective.  I seem to remember that Ben and others in ecological
fields were concerned about overdispersion, even after incorporating
random effects.


>
> Best wishes,
>
> Andrew
>
>
> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>> The following is how I think about this at the moment:
>>
>> The quasi-likelihood approach is an attempt at a model-free approach to
>> the problem of overdispersion in non-Gaussian regression situations
>> where standard distributional assumptions fail to provide the observed
>> mean-variance relationship.
>>
>> The glmm approach, on the other hand, does not abandon models and
>> likelihood but seeks to account for the observed mean-variance
>> relationship by adding unobserved latent variables (random effects) to
>> the model.
>>
>> Seeking to combine the two approaches by using both quasilikelihood
>> *and* random effects would seem to be asking for trouble as being able
>> to use two tools on one problem would give a lot of flexibility to the
>> parameter estimation; probably leading to a very flat quasilikelihood
>> surface and ill-determined optima.
>>
>> But all of the above is only thoughts without the benefit of either
>> serious attempts at fitting real data or doing serious theory so I will
>> defer to anyone who has done either!
>>
>> Philosophically, at least, there seems to be clash between the two
>> approaches and I doubt that attempts to combine them will be successful.
>>
>> Murray Jorgensen
>>
>>
>
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>



From jmblanco at ub.edu  Thu Dec 11 22:42:59 2008
From: jmblanco at ub.edu (=?ISO-8859-1?Q?Jos=E9_Manuel_Blanco_Moreno?=)
Date: Thu, 11 Dec 2008 22:42:59 +0100
Subject: [R-sig-ME] problem WITH mcmcsamp function in lme4 on Mac OSX
In-Reply-To: <220786D4-AC69-4E37-92AD-5DE707B1926D@unifr.ch>
References: <220786D4-AC69-4E37-92AD-5DE707B1926D@unifr.ch>
Message-ID: <49418963.9030507@ub.edu>

I had the very same problem today on a PC. I have updated lme4 (just in 
case) but it did not solve the problem.
Jos? M.

HENERY Martin escribi?:
> I was wondering if anyone else had experienced this problem and maybe  
> could identify it as a possible bug rather than a problem peculiar to  
> my particular computer.
> I have been trying to get confidence intervals via the mcmcsamp  
> function in lme4 package but cannot get it to work on a mac running  
> OS X. i ran exactly the same analyses on a PC with exactly the same  
> commands and data and it worked fine. I removed both the matrix and  
> lme4 packages from the library on the Mac (based on an unrelated  
> problem with the lme4 package that I read about in the mailing list)  
> and reinstalled them but to no avail. When I run the mcmcsamp  
> function I get this error message (sorry its partly in french)
>
>  > model.glmer4=glmer(leaves.eaten ~ Geocytotype+Cypho.origin + (1| 
> TEST), data = cyphoplantfeeding, family=poisson)
>  > summary(mcmcsamp(model.glmer4 , n = 10000))
> Erreur dans .local(object, n, verbose, ...) : Update not yet written
> Erreur dans summary(mcmcsamp(model.glmer4, n = 10000)) :
>    erreur lors de l'?valuation de l'argument 'object' lors de la  
> s?lection d'une m?thode pour la fonction 'summary'
>
> The same script runs fine on a PC so is what is the "update not yet  
> written" referring to?
>
>
> Martin Henery
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   


-- 
---------------------------------------
Jos? M. Blanco Moreno

Dept. de Biologia Vegetal (Bot?nica)
Universitat de Barcelona
Av. Diagonal 645 
08028 Barcelona SPAIN
---------------------------------------

phone: (+34) 934 039 863
fax: (+34) 934 112 842
e-mail: jmblanco at ub.edu 



From gavin.simpson at ucl.ac.uk  Thu Dec 11 22:43:15 2008
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 11 Dec 2008 21:43:15 +0000
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com>
Message-ID: <1229031795.3734.12.camel@localhost.localdomain>

On Thu, 2008-12-11 at 14:58 -0600, Douglas Bates wrote:
> On Thu, Dec 11, 2008 at 2:52 PM, Andrew Robinson
> <A.Robinson at ms.unimelb.edu.au> wrote:
> > Echoing Murray's points here - nicely put, Murray - it seems to me
> > that the quasi-likelihood and the GLMM are different approaches to the
> > same problem.
> 
> I agree and I also appreciate Murray's elegant explanation.
> 
> > Can anyone provide a substantial example where random effects and
> > quasilikelihood have both been necessary?
> 
> I'm kind of waiting for Ben Bolker to let us know how things look from
> his perspective.  I seem to remember that Ben and others in ecological
> fields were concerned about overdispersion, even after incorporating
> random effects.

Not wanting to preempt Ben or anything, but yes, we ecologists are very
concerned about overdispersion. However, and I say this as someone new
to this field (mixed models, not ecology), the quasilikelihood approach
seems far more of a fudge to avoid having to think about where the
overdispersion is coming from. I find the negative binomial far more
intuitive to deal with than working around the problems not having a
proper likelihood brings (inference, model selection, information
stats). Often, the course of overdispersion is of direct interest
itself.

In the GLM arena I find hurdle and ZIP and ZINB models far more
interpretable in ecological terms than fudging the problem with
quasilikelihood methods. And after-all, that is what I am interested in;
models I can interpret in ecological terms.

My two-penneth,

G

> 
> >
> > Best wishes,
> >
> > Andrew
> >
> >
> > On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
> >> The following is how I think about this at the moment:
> >>
> >> The quasi-likelihood approach is an attempt at a model-free approach to
> >> the problem of overdispersion in non-Gaussian regression situations
> >> where standard distributional assumptions fail to provide the observed
> >> mean-variance relationship.
> >>
> >> The glmm approach, on the other hand, does not abandon models and
> >> likelihood but seeks to account for the observed mean-variance
> >> relationship by adding unobserved latent variables (random effects) to
> >> the model.
> >>
> >> Seeking to combine the two approaches by using both quasilikelihood
> >> *and* random effects would seem to be asking for trouble as being able
> >> to use two tools on one problem would give a lot of flexibility to the
> >> parameter estimation; probably leading to a very flat quasilikelihood
> >> surface and ill-determined optima.
> >>
> >> But all of the above is only thoughts without the benefit of either
> >> serious attempts at fitting real data or doing serious theory so I will
> >> defer to anyone who has done either!
> >>
> >> Philosophically, at least, there seems to be clash between the two
> >> approaches and I doubt that attempts to combine them will be successful.
> >>
> >> Murray Jorgensen
> >>
> >>
> >
> > --
> > Andrew Robinson
> > Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> > University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> > http://www.ms.unimelb.edu.au/~andrewpr
> > http://blogs.mbs.edu/fishing-in-the-bay/
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From kmjamsen at unimelb.edu.au  Thu Dec 11 23:25:03 2008
From: kmjamsen at unimelb.edu.au (Kris Jamsen)
Date: Fri, 12 Dec 2008 09:25:03 +1100
Subject: [R-sig-ME] xtable question
In-Reply-To: <3D46FAE3-AA47-4620-ACAF-7E229E2EE928@muohio.edu>
References: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>
	<3D46FAE3-AA47-4620-ACAF-7E229E2EE928@muohio.edu>
Message-ID: <9C6F0C11872C98439322A20E9DB369F803D9F37E@IS-EX-BEV2.unimelb.edu.au>

Thanks Hank for your quick reply.  Yes, I tried to coerce my nlme object
into a data.frame object but xtable told me I couldn't do that.  The
nlme object is just an nlme model, so I would imagine it would be
similar in nature to an lm object, but with a few more bits.  It looks
like I might have to try to extend the list of available classes in
xtable (this might take some time!) or do something more manual.  Would
be glad to hear more suggestions!

Cheers,

Kris   

-----Original Message-----
From: Martin Henry H. Stevens [mailto:HStevens at muohio.edu] 
Sent: Thursday, 11 December 2008 8:31 PM
To: Kris Jamsen
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] xtable question

Hi Kris,
I don't know which kind of nlme object your are trying to use, but  
can you coerce it to a data.frame? If you can't, then maybe the  
object is not amenable to use in xtable. Is the object matrix-like or  
dataframe-like?
Hank
On Dec 11, 2008, at 1:37 AM, Kris Jamsen wrote:

> Hi all,
>
>
>
> I am trying to use xtable with an nlme object, but it won't let  
> me.  The
> help menu says that I can extend the list of available classes by
> writing methods for the generic function xtable, but I don't know  
> how to
> do this.  Has anyone already done this?
>
>
>
> Cheers,
>
>
>
> Kris
>
>
>
> Kris Jamsen
>
> Research Fellow
>
> Centre for Molecular, Environmental,
>
> Genetic and Analytic (MEGA) Epidemiology
>
> Level 1, 723 Swanston St
>
> The University of Melbourne
>
> Victoria, 3010
>
> AUSTRALIA
>
>
>
> Email: kmjamsen at unimelb.edu.au <mailto:kmjamsen at unimelb.edu.au>
>
> Ph: +61 (0)3 8344 0700
>
> Fax: +61 (0)3 9349 5815
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From atyre2 at unlnotes.unl.edu  Thu Dec 11 22:52:06 2008
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Thu, 11 Dec 2008 15:52:06 -0600
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com>
Message-ID: <OF8AFC4988.E54B748C-ON8625751C.00769E40-8625751C.00781304@unl.edu>

I also like the explanation of quasi-likelihood vs. glmm, but I can say 
from an ecological perspective I frequently encounter situations in which 
I have included all the random effects of blocks, plots, times etc, and 
still have massive amounts of overdispersion. A student in my Ecological 
Statistics class examined repeated counts of grasshoppers in plots that 
have or have not received nitrogen addition. A poisson family glmm gives a 
nice account of the effects of total veg biomass, date, and nitrogen 
addition, but the residual deviance  is  > 1700 for a sample size of about 
400. I would love to be able to fit a negative binomial model in that 
case; I typically resort to using WinBUGS and MCMC to do this, but that is 
beyond what I can get my students to do in a one semester course. 

I have encountered situations in which even using a negative binomial 
model (for counts) or beta-binomial type model ( for proportion of success 
data) are insufficient to explain the variability in ecological 
situations. In these cases I usually have reason to believe that there is 
a discrete mixture going on - ie the observations are coming from two or 
more distinct populations which have not been distinguished by anything 
the observer can record, or thought to record (immune status for parasite 
hosts, for example). I have tried quasi- family models in those cases, but 
always felt a little uncomfortable drawing much in the way of inference. I 
understand likelihood! 

Anyway, I appreciate the tool. It is very nice and continues to get 
better! Thanks,

Drew Tyre

School of Natural Resources
University of Nebraska-Lincoln
416 Hardin Hall, East Campus
3310 Holdrege Street
Lincoln, NE 68583-0974

phone: +1 402 472 4054 
fax: +1 402 472 2946
email: atyre2 at unl.edu
http://snr.unl.edu/tyre



"Douglas Bates" <bates at stat.wisc.edu> 
Sent by: r-sig-mixed-models-bounces at r-project.org
12/11/2008 03:00 PM

To
"Andrew Robinson" <A.Robinson at ms.unimelb.edu.au>
cc
R Mixed Models <r-sig-mixed-models at r-project.org>, Murray Jorgensen 
<maj at stats.waikato.ac.nz>
Subject
Re: [R-sig-ME] single argument anova for GLMMs not yet implemented






On Thu, Dec 11, 2008 at 2:52 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> Echoing Murray's points here - nicely put, Murray - it seems to me
> that the quasi-likelihood and the GLMM are different approaches to the
> same problem.

I agree and I also appreciate Murray's elegant explanation.

> Can anyone provide a substantial example where random effects and
> quasilikelihood have both been necessary?

I'm kind of waiting for Ben Bolker to let us know how things look from
his perspective.  I seem to remember that Ben and others in ecological
fields were concerned about overdispersion, even after incorporating
random effects.


>
> Best wishes,
>
> Andrew
>
>
> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>> The following is how I think about this at the moment:
>>
>> The quasi-likelihood approach is an attempt at a model-free approach to
>> the problem of overdispersion in non-Gaussian regression situations
>> where standard distributional assumptions fail to provide the observed
>> mean-variance relationship.
>>
>> The glmm approach, on the other hand, does not abandon models and
>> likelihood but seeks to account for the observed mean-variance
>> relationship by adding unobserved latent variables (random effects) to
>> the model.
>>
>> Seeking to combine the two approaches by using both quasilikelihood
>> *and* random effects would seem to be asking for trouble as being able
>> to use two tools on one problem would give a lot of flexibility to the
>> parameter estimation; probably leading to a very flat quasilikelihood
>> surface and ill-determined optima.
>>
>> But all of the above is only thoughts without the benefit of either
>> serious attempts at fitting real data or doing serious theory so I will
>> defer to anyone who has done either!
>>
>> Philosophically, at least, there seems to be clash between the two
>> approaches and I doubt that attempts to combine them will be 
successful.
>>
>> Murray Jorgensen
>>
>>
>
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Thu Dec 11 23:53:57 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Dec 2008 16:53:57 -0600
Subject: [R-sig-ME] xtable question
In-Reply-To: <9C6F0C11872C98439322A20E9DB369F803D9F37E@IS-EX-BEV2.unimelb.edu.au>
References: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>
	<3D46FAE3-AA47-4620-ACAF-7E229E2EE928@muohio.edu>
	<9C6F0C11872C98439322A20E9DB369F803D9F37E@IS-EX-BEV2.unimelb.edu.au>
Message-ID: <40e66e0b0812111453n69f120cayb9385084e8c0d1ac@mail.gmail.com>

On Thu, Dec 11, 2008 at 4:25 PM, Kris Jamsen <kmjamsen at unimelb.edu.au> wrote:
> Thanks Hank for your quick reply.  Yes, I tried to coerce my nlme object
> into a data.frame object but xtable told me I couldn't do that.  The
> nlme object is just an nlme model, so I would imagine it would be
> similar in nature to an lm object, but with a few more bits.  It looks
> like I might have to try to extend the list of available classes in
> xtable (this might take some time!) or do something more manual.  Would
> be glad to hear more suggestions!

An nlme object is not just an extension of an lm object.  There is a
lot more going on in nlme or lme than is the case in lm.

I expect that in creating a table from such an object you want the
table of estimates of the fixed-effects parameters, their approximate
standard errors and so on displayed as a table.  To get that table you
apply summary to the fitted model and save the result.  There is a
component of that object with a name like ttable which is the table of
fixed-effects estimates, etc.  Use

str(summary(lmeFittedModel))

to find the exact name and format.



From kmjamsen at unimelb.edu.au  Fri Dec 12 00:25:51 2008
From: kmjamsen at unimelb.edu.au (Kris Jamsen)
Date: Fri, 12 Dec 2008 10:25:51 +1100
Subject: [R-sig-ME] xtable question
In-Reply-To: <40e66e0b0812111453n69f120cayb9385084e8c0d1ac@mail.gmail.com>
References: <9C6F0C11872C98439322A20E9DB369F803D9F2BA@IS-EX-BEV2.unimelb.edu.au>
	<3D46FAE3-AA47-4620-ACAF-7E229E2EE928@muohio.edu>
	<9C6F0C11872C98439322A20E9DB369F803D9F37E@IS-EX-BEV2.unimelb.edu.au>
	<40e66e0b0812111453n69f120cayb9385084e8c0d1ac@mail.gmail.com>
Message-ID: <9C6F0C11872C98439322A20E9DB369F803D9F41B@IS-EX-BEV2.unimelb.edu.au>

This looks promising - I'll give it a go.

Cheers,

Kris

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Friday, 12 December 2008 9:54 AM
To: Kris Jamsen
Cc: Martin Henry H. Stevens; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] xtable question

On Thu, Dec 11, 2008 at 4:25 PM, Kris Jamsen <kmjamsen at unimelb.edu.au>
wrote:
> Thanks Hank for your quick reply.  Yes, I tried to coerce my nlme
object
> into a data.frame object but xtable told me I couldn't do that.  The
> nlme object is just an nlme model, so I would imagine it would be
> similar in nature to an lm object, but with a few more bits.  It looks
> like I might have to try to extend the list of available classes in
> xtable (this might take some time!) or do something more manual.
Would
> be glad to hear more suggestions!

An nlme object is not just an extension of an lm object.  There is a
lot more going on in nlme or lme than is the case in lm.

I expect that in creating a table from such an object you want the
table of estimates of the fixed-effects parameters, their approximate
standard errors and so on displayed as a table.  To get that table you
apply summary to the fitted model and save the result.  There is a
component of that object with a name like ttable which is the table of
fixed-effects estimates, etc.  Use

str(summary(lmeFittedModel))

to find the exact name and format.



From A.Robinson at ms.unimelb.edu.au  Fri Dec 12 01:00:46 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 12 Dec 2008 11:00:46 +1100
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <OF8AFC4988.E54B748C-ON8625751C.00769E40-8625751C.00781304@unl.edu>
References: <40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com>
	<OF8AFC4988.E54B748C-ON8625751C.00769E40-8625751C.00781304@unl.edu>
Message-ID: <20081212000046.GK1260@ms.unimelb.edu.au>

Hi Drew,

On Thu, Dec 11, 2008 at 03:52:06PM -0600, Andrew J Tyre wrote:
> I also like the explanation of quasi-likelihood vs. glmm, but I can say 
> from an ecological perspective I frequently encounter situations in which 
> I have included all the random effects of blocks, plots, times etc, and 
> still have massive amounts of overdispersion. A student in my Ecological 
> Statistics class examined repeated counts of grasshoppers in plots that 
> have or have not received nitrogen addition. A poisson family glmm gives a 
> nice account of the effects of total veg biomass, date, and nitrogen 
> addition, but the residual deviance  is  > 1700 for a sample size of about 
> 400. I would love to be able to fit a negative binomial model in that 
> case; I typically resort to using WinBUGS and MCMC to do this, but that is 
> beyond what I can get my students to do in a one semester course. 

This looks like a promising example (so to speak) ... have you tried
fitting a poisson family glmm and a negative binomial hierarchical
model to these data in WinBUGS?  if so, how do the models compare
within that framework?
 
> I have encountered situations in which even using a negative binomial 
> model (for counts) or beta-binomial type model ( for proportion of success 
> data) are insufficient to explain the variability in ecological 
> situations. In these cases I usually have reason to believe that there is 
> a discrete mixture going on - ie the observations are coming from two or 
> more distinct populations which have not been distinguished by anything 
> the observer can record, or thought to record (immune status for parasite 
> hosts, for example). I have tried quasi- family models in those cases, but 
> always felt a little uncomfortable drawing much in the way of inference. I 
> understand likelihood! 

I'd suggest that if you have reason to believe that you have an
underlying discrete mixture but no way to tease out the identity, then
any modelling should be treated with great caution!  Or maybe EM would
help?  Treat the population identity as a latent variable?  Simon
Blomberg told me about a really nice simple example in which he did
that kind of thing, over a beer a few months ago.  It might or might
not be relevant here.  

Cheers

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From David.Duffy at qimr.edu.au  Fri Dec 12 02:27:46 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 12 Dec 2008 11:27:46 +1000 (EST)
Subject: [R-sig-ME] single argument anova for GLMMs not yet implemented
In-Reply-To: <20081212000046.GK1260@ms.unimelb.edu.au>
References: <40e66e0b0812111258p265a3d9ey24d7ef760ea62115@mail.gmail.com><OF8AFC4988.E54B748C-ON8625751C.00769E40-8625751C.00781304@unl.edu>
	<20081212000046.GK1260@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0812121119060.4718@orpheus.qimr.edu.au>

On Fri, 12 Dec 2008, Andrew Robinson wrote:

> Hi Drew,
>
> On Thu, Dec 11, 2008 at 03:52:06PM -0600, Andrew J Tyre wrote:
>> I also like the explanation of quasi-likelihood vs. glmm, but I can say
>> from an ecological perspective I frequently encounter situations in which
>> I have included all the random effects of blocks, plots, times etc, and
>> still have massive amounts of overdispersion. A student in my Ecological
>> Statistics class examined repeated counts of grasshoppers in plots that
>> have or have not received nitrogen addition. A poisson family glmm gives a
>> nice account of the effects of total veg biomass, date, and nitrogen
>> addition, but the residual deviance  is  > 1700 for a sample size of about
>> 400. I would love to be able to fit a negative binomial model in that
>> case; I typically resort to using WinBUGS and MCMC to do this, but that is
>> beyond what I can get my students to do in a one semester course.
>
> This looks like a promising example (so to speak) ... have you tried
> fitting a poisson family glmm and a negative binomial hierarchical
> model to these data in WinBUGS?  if so, how do the models compare
> within that framework?
>
>> I have encountered situations in which even using a negative binomial
>> model (for counts) or beta-binomial type model ( for proportion of success
>> data) are insufficient to explain the variability in ecological
>> situations. In these cases I usually have reason to believe that there is
>> a discrete mixture going on - ie the observations are coming from two or
>> more distinct populations which have not been distinguished by anything
>> the observer can record, or thought to record (immune status for parasite
>> hosts, for example). I have tried quasi- family models in those cases, but
>> always felt a little uncomfortable drawing much in the way of inference. I
>> understand likelihood!
>
> I'd suggest that if you have reason to believe that you have an
> underlying discrete mixture but no way to tease out the identity, then
> any modelling should be treated with great caution!  Or maybe EM would
> help?
>

There has been a certain amount of work on models where the 
distribution of the random effects is unspecified -- modelled 
as a mixture which is estimated by nonparametric ML (a paper by Murray 
Aitken in Biometrics is the earliest I know of).  These could probably 
slurp up overdispersion of the type described.  I imagine they are only 
tractable for simple models for the random effects (eg group 
membership/clusters).

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From john.maindonald at anu.edu.au  Fri Dec 12 06:29:19 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 12 Dec 2008 16:29:19 +1100
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <20081211205200.GD1260@ms.unimelb.edu.au>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
Message-ID: <E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>

The approaches have the fundamental difference that the overdispersion  
model multiplies the theoretical variance by an amount that is  
constant (whether on the scale of the response [the binomial variance  
becomes \phi n p(1-p)], or on the scale of the linear predictor).

I have called overdispersion a model - actually it is not one model,  
but a range of possible models. I have no problem, in principle, with  
one fitting method that reflects multiple possible models once one  
gets down to detail.

GLMMs add to the theoretical variance, on the scale of the linear  
predictor. For binomial models with the usual link functions (logit,  
probit, cloglog), the scale spreads out close to p=0 or close to  
p=1,   With the glmm models the variances then increase more,  
relatively to the overdispersion model, at the  extremes of the  
scale.   (For the Poisson with a log link, there is just one relevant  
extreme, at 0.)

NB also, all variance assessments are conditional on getting the link  
right.  If the link is wrong in a way that matters, there will be  
apparent increases in variance in some parts of the scale that reflect  
biases that arise from the inappropriate choice of link.

There may be cases where overdispersion gives too small a variance  
(relatively) at the extremes, while glmer gives too high a variance.   
As there are an infinite number of possible ways in which the variance  
might vary with (in the binomial case) p, it would be surprising if  
(detectable with enough data, or enough historical experience), there  
were not such "intermediate" cases.

There might in principle be subplot designs, with a treatment at the  
subplot level, where the overdispersion model is required at the  
subplot level in order to get the treatment comparisons correct at  
that level.

As much of this discussion is focused around ecology, experience with  
fitting one or other model to large datasets is surely required that  
will help decide just how, in one or other practical context, 1) the  
variance is likely to change with p (or in the Poisson case, with the  
Poisson mean) and 2) what links seem preferable.

The best way to give the flexibility required for modeling the  
variance, as it seems to me, would be the ability to make the variance  
of p a fairly arbitrary function of p, with other variance components  
added on the scale of the linear predictor.  More radically, all  
variance components might be functions of p.  I am not sure that going  
that far would be a good idea - there'd be too many complaints that  
model fits will not converge!

The following shows a comparison that I did recently for a talk.  The  
p's are not sufficiently extreme to show much difference between the  
two models:

The dataset cbpp is from the lme4 package.
infect <- with(cbpp, cbind(incidence, size - incidence))
(gm1 <- glmer(infect ~ period + (1 | herd),
family = binomial, data = cbpp))
Random effects:
Groups Name Variance Std.Dev.
herd (Intercept) 0.412 0.642
Number of obs: 56, groups: herd, 15
Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.399 0.228 -6.14 8.4e-10
period2 -0.992 0.305 -3.25 0.00116
period3 -1.129 0.326 -3.46 0.00054
period4 -1.580 0.429 -3.69 0.00023

Here, use the ?sum? contrasts, and compare with the overall mean.
                             glmer                quasibinomial
                     Est  SE          z     Est SE (binomial SE)    t
(Intercept) -2.32 0.22 -10.5   -2.33 0.21 (.14)             -11.3
Period1     -0.66 0.32   -2.1   -0.72 0.45 (.31)               -1.6
Period2      0.93 0.18    5.0     1.06 0.26 (.17)                4.2
Period3     -0.07 0.23  -0.3    -0.11 0.34 (.23)               -0.3
Period4     -0.20 0.25  -0.8    -0.24 0.36 (.24)               -0.7

The SEs (really SEDs) are not much increased from the quasibinomial  
model. The estimates of treatment e?ects (di?erences from the  
overall mean) are substantially reduced (pulled in towards the overall  
mean). The net e?ect is that the z -statistic is smaller for the  
glmer model than the t for the quasibinomial model.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 12/12/2008, at 7:52 AM, Andrew Robinson wrote:

> Echoing Murray's points here - nicely put, Murray - it seems to me
> that the quasi-likelihood and the GLMM are different approaches to the
> same problem.
>
> Can anyone provide a substantial example where random effects and
> quasilikelihood have both been necessary?
>
> Best wishes,
>
> Andrew
>
>
> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>> The following is how I think about this at the moment:
>>
>> The quasi-likelihood approach is an attempt at a model-free  
>> approach to
>> the problem of overdispersion in non-Gaussian regression situations
>> where standard distributional assumptions fail to provide the  
>> observed
>> mean-variance relationship.
>>
>> The glmm approach, on the other hand, does not abandon models and
>> likelihood but seeks to account for the observed mean-variance
>> relationship by adding unobserved latent variables (random effects)  
>> to
>> the model.
>>
>> Seeking to combine the two approaches by using both quasilikelihood
>> *and* random effects would seem to be asking for trouble as being  
>> able
>> to use two tools on one problem would give a lot of flexibility to  
>> the
>> parameter estimation; probably leading to a very flat quasilikelihood
>> surface and ill-determined optima.
>>
>> But all of the above is only thoughts without the benefit of either
>> serious attempts at fitting real data or doing serious theory so I  
>> will
>> defer to anyone who has done either!
>>
>> Philosophically, at least, there seems to be clash between the two
>> approaches and I doubt that attempts to combine them will be  
>> successful.
>>
>> Murray Jorgensen
>>
>>
>
> -- 
> Andrew Robinson
> Department of Mathematics and Statistics            Tel:  
> +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax:  
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kushler at oakland.edu  Fri Dec 12 15:21:15 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Fri, 12 Dec 2008 09:21:15 -0500
Subject: [R-sig-ME] Sample size and mixed models
In-Reply-To: <49413C0E.3070308@cornell.edu>
References: <49413C0E.3070308@cornell.edu>
Message-ID: <4942735B.2060109@oakland.edu>


I would argue that the larger value (individuals) is always more appropriate
than the smaller value (clusters).  However, the more important issue is
that the "ungrouped" version of the likelihood should be used for these
calculations.  Using the "grouped data" likelihood omits the within cluster
variation and inflates the estimate of predictive power.

Regards,   Rob Kushler


Ben Zuckerberg wrote:
> A very quick (and possibly silly) question for mixed modelers.  Certain 
> metrics such as Nagelkerke's R2 and the sample size adjusted AICc 
> require the user to specify the sample size.  What is the appropriate 
> sample size to use in a mixed model where you might have hundreds of 
> repeat samples on a smaller sample of sites (in this case, the sites are 
> treated as the random factor)?  In my case, the lmer output will produce 
> the following information: Number of obs: 10091, groups: ID, 444.  For 
> calculating sample size adjusted statistics, would you use an effective 
> sample size of 444?  Thank you.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Fri Dec 12 15:49:45 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 12 Dec 2008 09:49:45 -0500
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
 or dispersion?)
Message-ID: <49427A09.1070006@ufl.edu>


  Jumping in late here, generally agreeing with the pther ecologists
(who say that the data are often overdispersed even after
accounting for known grouping factors via random effects).
I also agree that negative binomial models would be a great
addition to lmer (? could perhaps do beta-binomial at the
same time, without much additional cost?). [glmmADMB will
also do these, it's not as widely used, but certainly worth
further testing]  Testing and strengthening lmer's ability
to handle individual-level variation (as in lognormal-Poisson
or logit-normal-binomial models) would provide another alternative
to quasi() ...

David Duffy's example (variation left over after random effects and
negative binomial model) makes me kind of nervous, I would hope that
such effects would be jumping out of exploratory graphics, or graphical
analyses of residuals ...

  My advice to students is usually "do whatever is most feasible,
you probably don't have enough data to distinguish between
Var = phi*mu (quasi-) and Var = mu*(1+phi*mu) (neg binom)
anyway" -- supported by Liang and McCullagh and Richards,
to some extent ... although recent simulation studies with
big data sets have told a somewhat different story ...

  Bottom line -- ecologists *will* often have overdispersion
that can't be explained by known grouping factors, but they
are pragmatists -- if you give them some way to handle that
overdispersion (parametric models or individual-level variation)
they probably won't complain about the lack of quasi- ...

  cheers
   Ben Bolker

Liang, Kung-Yee, and Peter McCullagh. 1993. Case Studies in Binary
Dispersion. Biometrics 49, no. 2 (June): 623-630.

Richards, Shane A. 2008. Dealing with overdispersed count data in
applied ecology. Journal of Applied Ecology 45: 218-227.
doi:10.1111/j.1365-2664.2007.01377.x.

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bates at stat.wisc.edu  Fri Dec 12 16:29:20 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 12 Dec 2008 09:29:20 -0600
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
Message-ID: <40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>

I appreciate your thoughts on this, John, and especially the example.
There is a tendency in discussions of the theory to ignore the
practical applications and in discussion of the applications to ignore
the theoretical foundations.  Effective statistical analysis should,
of course, involve both.

I include some comments below.

On Thu, Dec 11, 2008 at 11:29 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> The approaches have the fundamental difference that the overdispersion model
> multiplies the theoretical variance by an amount that is constant (whether
> on the scale of the response [the binomial variance becomes \phi n p(1-p)],
> or on the scale of the linear predictor).

This highlights the problem that I have with the quasi families.  One
cannot choose the mean and variance separately in distributions like
the Bernoulli or Poisson.  (As the binomial is a sum of independent
Bernoulli distributions I will phrase this in terms of the Bernoulli
so I don't trip up on the n's.)  For a Gaussian distribution one has
the luxury of separately setting the mean and the variance.  For the
Bernoulli or Poisson you don't.  The choice of the mean completely
determines the distribution.  There is no such thing as a Bernoulli
distribution with variance \phi p(1-p) unless \phi is identically 1.

If you want to discuss generalizations of the Bernoulli or Poisson
distributions I could accept that but simply saying that we will base
a model on a distribution that is just like the Bernoulli except that
it has a tunable variance won't fly.  If we want to attribute
desirable statistical properties to estimates by saying, for example,
that they are maximum likelihood estimates or approximations to the
maximum likelihood estimates we must be able to define the likelihood
and to me that means that you must have a probability model.   That
is, you must be able to describe the probability distribution of the
response or, in the case of the generalized linear mixed models, the
conditional distribution of the response given the random effects.

If I can't define the probability distribution then how can I evaluate
the likelihood?  One can argue by analogy that the estimates based on
the Bernoulli have certain properties so we think that the estimates
from a hypothetical distribution that is just like the Bernoulli
except that it is overdispersed should have similar properties with an
extra parameter thrown in but that does not constitute a "sound
theoretical basis" and there is no justification for thinking that
such a procedure will allow for extensions to random effects.

> I have called overdispersion a model - actually it is not one model, but a
> range of possible models. I have no problem, in principle, with one fitting
> method that reflects multiple possible models once one gets down to detail.

> GLMMs add to the theoretical variance, on the scale of the linear predictor.
> For binomial models with the usual link functions (logit, probit, cloglog),
> the scale spreads out close to p=0 or close to p=1,   With the glmm models
> the variances then increase more, relatively to the overdispersion model, at
> the  extremes of the scale.   (For the Poisson with a log link, there is
> just one relevant extreme, at 0.)

Although you are not saying it explicitly it seems that you are
regarding the overdispersion and random effects approaches as a tool
for modeling the marginal variance of the responses.  It happens that
I don't think of the models that way, perhaps because I have
difficulty thinking of the marginal variance.  I'm enough of a
mathematician that I like to consider the simple cases which to me
means the unconditional distribution of the random effects and the
conditional distribution of the response.  In the way that I think of
the models those are both relatively simple distributions.

One of the things that trip people up when considering random effects
as ways of modifying the marginal variance structure of the response
is that techniques or modifications that will work for the Gaussian
distribution don't work for other distributions, because of the fact
that the mean and variance are separately specified in the Gaussian
but not in others.  In the nlme package Jose and I allowed for
correlation structures and variance functions for the response to be
specified separately from the random effects structure.  This is
legitimate in that we were only allowing models for which the
conditional distribution of Y given B = b is Gaussian.  Extending this
type of modeling to other families of conditional distribution is
conceptually very difficult.  Many people want to do this but, as that
noted philosopher Mick Jagger pointed out, "You can't always get what
you want.".  If you want to model binary or count data you have to
accept that the mean and the variance of the conditional distribution
cannot be modeled separately.  (Another noted philosopher, Ernie of
Sesame Street, pointed out that "You gotta put down the ducky if you
want to play the saxophone.")


> NB also, all variance assessments are conditional on getting the link right.
>  If the link is wrong in a way that matters, there will be apparent
> increases in variance in some parts of the scale that reflect biases that
> arise from the inappropriate choice of link.
>
> There may be cases where overdispersion gives too small a variance
> (relatively) at the extremes, while glmer gives too high a variance.  As
> there are an infinite number of possible ways in which the variance might
> vary with (in the binomial case) p, it would be surprising if (detectable
> with enough data, or enough historical experience), there were not such
> "intermediate" cases.
>
> There might in principle be subplot designs, with a treatment at the subplot
> level, where the overdispersion model is required at the subplot level in
> order to get the treatment comparisons correct at that level.
>
> As much of this discussion is focused around ecology, experience with
> fitting one or other model to large datasets is surely required that will
> help decide just how, in one or other practical context, 1) the variance is
> likely to change with p (or in the Poisson case, with the Poisson mean) and
> 2) what links seem preferable.
>
> The best way to give the flexibility required for modeling the variance, as
> it seems to me, would be the ability to make the variance of p a fairly
> arbitrary function of p, with other variance components added on the scale
> of the linear predictor.  More radically, all variance components might be
> functions of p.  I am not sure that going that far would be a good idea -
> there'd be too many complaints that model fits will not converge!
>
> The following shows a comparison that I did recently for a talk.  The p's
> are not sufficiently extreme to show much difference between the two models:
>
> The dataset cbpp is from the lme4 package.
> infect <- with(cbpp, cbind(incidence, size - incidence))
> (gm1 <- glmer(infect ~ period + (1 | herd),
> family = binomial, data = cbpp))
> Random effects:
> Groups Name Variance Std.Dev.
> herd (Intercept) 0.412 0.642
> Number of obs: 56, groups: herd, 15
> Fixed effects:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.399 0.228 -6.14 8.4e-10
> period2 -0.992 0.305 -3.25 0.00116
> period3 -1.129 0.326 -3.46 0.00054
> period4 -1.580 0.429 -3.69 0.00023
>
> Here, use the "sum" contrasts, and compare with the overall mean.
>                            glmer                quasibinomial
>                    Est  SE          z     Est SE (binomial SE)    t
> (Intercept) -2.32 0.22 -10.5   -2.33 0.21 (.14)             -11.3
> Period1     -0.66 0.32   -2.1   -0.72 0.45 (.31)               -1.6
> Period2      0.93 0.18    5.0     1.06 0.26 (.17)                4.2
> Period3     -0.07 0.23  -0.3    -0.11 0.34 (.23)               -0.3
> Period4     -0.20 0.25  -0.8    -0.24 0.36 (.24)               -0.7
>
> The SEs (really SEDs) are not much increased from the quasibinomial model.
> The estimates of treatment e?ects (di?erences from the overall mean) are
> substantially reduced (pulled in towards the overall mean). The net e?ect is
> that the z -statistic is smaller for the glmer model than the t for the
> quasibinomial model.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>
> On 12/12/2008, at 7:52 AM, Andrew Robinson wrote:
>
>> Echoing Murray's points here - nicely put, Murray - it seems to me
>> that the quasi-likelihood and the GLMM are different approaches to the
>> same problem.
>>
>> Can anyone provide a substantial example where random effects and
>> quasilikelihood have both been necessary?
>>
>> Best wishes,
>>
>> Andrew
>>
>>
>> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>>>
>>> The following is how I think about this at the moment:
>>>
>>> The quasi-likelihood approach is an attempt at a model-free approach to
>>> the problem of overdispersion in non-Gaussian regression situations
>>> where standard distributional assumptions fail to provide the observed
>>> mean-variance relationship.
>>>
>>> The glmm approach, on the other hand, does not abandon models and
>>> likelihood but seeks to account for the observed mean-variance
>>> relationship by adding unobserved latent variables (random effects) to
>>> the model.
>>>
>>> Seeking to combine the two approaches by using both quasilikelihood
>>> *and* random effects would seem to be asking for trouble as being able
>>> to use two tools on one problem would give a lot of flexibility to the
>>> parameter estimation; probably leading to a very flat quasilikelihood
>>> surface and ill-determined optima.
>>>
>>> But all of the above is only thoughts without the benefit of either
>>> serious attempts at fitting real data or doing serious theory so I will
>>> defer to anyone who has done either!
>>>
>>> Philosophically, at least, there seems to be clash between the two
>>> approaches and I doubt that attempts to combine them will be successful.
>>>
>>> Murray Jorgensen
>>>
>>>
>>
>> --
>> Andrew Robinson
>> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>> http://www.ms.unimelb.edu.au/~andrewpr
>> http://blogs.mbs.edu/fishing-in-the-bay/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From A.Robinson at ms.unimelb.edu.au  Fri Dec 12 23:11:44 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 13 Dec 2008 09:11:44 +1100
Subject: [R-sig-ME] Sample size and mixed models
In-Reply-To: <4942735B.2060109@oakland.edu>
References: <49413C0E.3070308@cornell.edu> <4942735B.2060109@oakland.edu>
Message-ID: <20081212221144.GB1295@ms.unimelb.edu.au>

Hi Rob,

On Fri, Dec 12, 2008 at 09:21:15AM -0500, Robert Kushler wrote:
> 
> I would argue that the larger value (individuals) is always more appropriate
> than the smaller value (clusters).  

That's interesting - I have the opposite response, or at least that
the truth lies somewhere in the middle.  Can you expand on why you
would argue that the larger value is always more appropriate than the
smaller value?

> However, the more important issue is that the "ungrouped" version of
> the likelihood should be used for these calculations.  Using the
> "grouped data" likelihood omits the within cluster variation and
> inflates the estimate of predictive power.

I don't follow what you mean by "grouped" and "ungrouped" versions of
the likelihood.  Can you clarify?

Cheers,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From spencer.graves at pdf.com  Fri Dec 12 23:24:03 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Dec 2008 14:24:03 -0800
Subject: [R-sig-ME] Sample size and mixed models
In-Reply-To: <49413C0E.3070308@cornell.edu>
References: <49413C0E.3070308@cornell.edu>
Message-ID: <4942E483.3080807@pdf.com>

Hi, Ben: 

      In your example with 100091 observations in 444 groups, I think 
the proper "n" depends on the variance components:  If the group 
variance dominants and the within-group variance is negligible, then you 
have only 444 "observations".  If the between-group variance is 
negligible relative to the with-group variance, your 100091 observations 
are practically independent, so you should use that number. 

      I think the formula you want to use is as follows: 


           IC = (-2)*log(likelihood at MLE) + 2*bias,


where IC = "Information Criterion", discussed by Sadanori Konishi and 
Genshiro Kitagawa (2007) Information Criteria and Statistical Modeling 
(Springer);  this formula appears on p. 55. 

      Later, they derive the following formula for the bias (p. 59): 


           bias = trace(solve(observed information, covariance of the 
score function)). 

    
      The book develops many variations on this theme, including the 
traditional AIC (sec. 3.4.4), BIC (ch. 9), AICc (p. 191), and a 
Bootstrap Information Criterion (ch. 8). 

      Hope this helps.
      Spencer     

Ben Zuckerberg wrote:
> A very quick (and possibly silly) question for mixed modelers.  
> Certain metrics such as Nagelkerke's R2 and the sample size adjusted 
> AICc require the user to specify the sample size.  What is the 
> appropriate sample size to use in a mixed model where you might have 
> hundreds of repeat samples on a smaller sample of sites (in this case, 
> the sites are treated as the random factor)?  In my case, the lmer 
> output will produce the following information: Number of obs: 10091, 
> groups: ID, 444.  For calculating sample size adjusted statistics, 
> would you use an effective sample size of 444?  Thank you.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From maj at stats.waikato.ac.nz  Sat Dec 13 08:51:41 2008
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Sat, 13 Dec 2008 20:51:41 +1300
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
 or dispersion?)
In-Reply-To: <40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
References: <493FE6B6.3000507@ufl.edu>	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>	<494173FB.9040805@stats.waikato.ac.nz>	<20081211205200.GD1260@ms.unimelb.edu.au>	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
Message-ID: <4943698D.7080109@stats.waikato.ac.nz>

I should have replied earlier to the kind comments Andrew and Doug made 
earlier on my contrast between quasilikelihood 'models' and GLMMs, 
however I am being invaded by sons, daughters in and out of law and a 
grandson.

I tried to be neutral in this comparison but I will 'come out' here and 
admit that my preference is for fully-explicit probability models for 
the data. It seems to me that without this you don't have a clear 
meaning for the parameters that you are estimating. John says "I have no 
problem, in principle, with one fitting method that reflects multiple 
possible models once one gets down to detail." This may be psychological 
  but I would have to say that I *do* have a problem with that.

Because data can be generated from fully-specified models it seems to me 
that there is scope for a computer experiment comparing the results of 
both fitting methods to data generated from a known model. Just because 
the data would be generated from a known GLMM it need not mean that the 
GLMM estimates from fitting the correct model would be superior. I 
imagine that quasi approaches might do well in small samples.

Clearly the design of such a computer experiment would need to be 
carefully thought out. It would probably better to design around a 
particular real situation than to try for great generality.



Douglas Bates wrote:
> I appreciate your thoughts on this, John, and especially the example.
> There is a tendency in discussions of the theory to ignore the
> practical applications and in discussion of the applications to ignore
> the theoretical foundations.  Effective statistical analysis should,
> of course, involve both.
> 
> I include some comments below.
> 
> On Thu, Dec 11, 2008 at 11:29 PM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> The approaches have the fundamental difference that the overdispersion model
>> multiplies the theoretical variance by an amount that is constant (whether
>> on the scale of the response [the binomial variance becomes \phi n p(1-p)],
>> or on the scale of the linear predictor).
> 
> This highlights the problem that I have with the quasi families.  One
> cannot choose the mean and variance separately in distributions like
> the Bernoulli or Poisson.  (As the binomial is a sum of independent
> Bernoulli distributions I will phrase this in terms of the Bernoulli
> so I don't trip up on the n's.)  For a Gaussian distribution one has
> the luxury of separately setting the mean and the variance.  For the
> Bernoulli or Poisson you don't.  The choice of the mean completely
> determines the distribution.  There is no such thing as a Bernoulli
> distribution with variance \phi p(1-p) unless \phi is identically 1.
> 
> If you want to discuss generalizations of the Bernoulli or Poisson
> distributions I could accept that but simply saying that we will base
> a model on a distribution that is just like the Bernoulli except that
> it has a tunable variance won't fly.  If we want to attribute
> desirable statistical properties to estimates by saying, for example,
> that they are maximum likelihood estimates or approximations to the
> maximum likelihood estimates we must be able to define the likelihood
> and to me that means that you must have a probability model.   That
> is, you must be able to describe the probability distribution of the
> response or, in the case of the generalized linear mixed models, the
> conditional distribution of the response given the random effects.
> 
> If I can't define the probability distribution then how can I evaluate
> the likelihood?  One can argue by analogy that the estimates based on
> the Bernoulli have certain properties so we think that the estimates
> from a hypothetical distribution that is just like the Bernoulli
> except that it is overdispersed should have similar properties with an
> extra parameter thrown in but that does not constitute a "sound
> theoretical basis" and there is no justification for thinking that
> such a procedure will allow for extensions to random effects.
> 
>> I have called overdispersion a model - actually it is not one model, but a
>> range of possible models. I have no problem, in principle, with one fitting
>> method that reflects multiple possible models once one gets down to detail.
> 
>> GLMMs add to the theoretical variance, on the scale of the linear predictor.
>> For binomial models with the usual link functions (logit, probit, cloglog),
>> the scale spreads out close to p=0 or close to p=1,   With the glmm models
>> the variances then increase more, relatively to the overdispersion model, at
>> the  extremes of the scale.   (For the Poisson with a log link, there is
>> just one relevant extreme, at 0.)
> 
> Although you are not saying it explicitly it seems that you are
> regarding the overdispersion and random effects approaches as a tool
> for modeling the marginal variance of the responses.  It happens that
> I don't think of the models that way, perhaps because I have
> difficulty thinking of the marginal variance.  I'm enough of a
> mathematician that I like to consider the simple cases which to me
> means the unconditional distribution of the random effects and the
> conditional distribution of the response.  In the way that I think of
> the models those are both relatively simple distributions.
> 
> One of the things that trip people up when considering random effects
> as ways of modifying the marginal variance structure of the response
> is that techniques or modifications that will work for the Gaussian
> distribution don't work for other distributions, because of the fact
> that the mean and variance are separately specified in the Gaussian
> but not in others.  In the nlme package Jose and I allowed for
> correlation structures and variance functions for the response to be
> specified separately from the random effects structure.  This is
> legitimate in that we were only allowing models for which the
> conditional distribution of Y given B = b is Gaussian.  Extending this
> type of modeling to other families of conditional distribution is
> conceptually very difficult.  Many people want to do this but, as that
> noted philosopher Mick Jagger pointed out, "You can't always get what
> you want.".  If you want to model binary or count data you have to
> accept that the mean and the variance of the conditional distribution
> cannot be modeled separately.  (Another noted philosopher, Ernie of
> Sesame Street, pointed out that "You gotta put down the ducky if you
> want to play the saxophone.")
> 
> 
>> NB also, all variance assessments are conditional on getting the link right.
>>  If the link is wrong in a way that matters, there will be apparent
>> increases in variance in some parts of the scale that reflect biases that
>> arise from the inappropriate choice of link.
>>
>> There may be cases where overdispersion gives too small a variance
>> (relatively) at the extremes, while glmer gives too high a variance.  As
>> there are an infinite number of possible ways in which the variance might
>> vary with (in the binomial case) p, it would be surprising if (detectable
>> with enough data, or enough historical experience), there were not such
>> "intermediate" cases.
>>
>> There might in principle be subplot designs, with a treatment at the subplot
>> level, where the overdispersion model is required at the subplot level in
>> order to get the treatment comparisons correct at that level.
>>
>> As much of this discussion is focused around ecology, experience with
>> fitting one or other model to large datasets is surely required that will
>> help decide just how, in one or other practical context, 1) the variance is
>> likely to change with p (or in the Poisson case, with the Poisson mean) and
>> 2) what links seem preferable.
>>
>> The best way to give the flexibility required for modeling the variance, as
>> it seems to me, would be the ability to make the variance of p a fairly
>> arbitrary function of p, with other variance components added on the scale
>> of the linear predictor.  More radically, all variance components might be
>> functions of p.  I am not sure that going that far would be a good idea -
>> there'd be too many complaints that model fits will not converge!
>>
>> The following shows a comparison that I did recently for a talk.  The p's
>> are not sufficiently extreme to show much difference between the two models:
>>
>> The dataset cbpp is from the lme4 package.
>> infect <- with(cbpp, cbind(incidence, size - incidence))
>> (gm1 <- glmer(infect ~ period + (1 | herd),
>> family = binomial, data = cbpp))
>> Random effects:
>> Groups Name Variance Std.Dev.
>> herd (Intercept) 0.412 0.642
>> Number of obs: 56, groups: herd, 15
>> Fixed effects:
>> Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -1.399 0.228 -6.14 8.4e-10
>> period2 -0.992 0.305 -3.25 0.00116
>> period3 -1.129 0.326 -3.46 0.00054
>> period4 -1.580 0.429 -3.69 0.00023
>>
>> Here, use the "sum" contrasts, and compare with the overall mean.
>>                            glmer                quasibinomial
>>                    Est  SE          z     Est SE (binomial SE)    t
>> (Intercept) -2.32 0.22 -10.5   -2.33 0.21 (.14)             -11.3
>> Period1     -0.66 0.32   -2.1   -0.72 0.45 (.31)               -1.6
>> Period2      0.93 0.18    5.0     1.06 0.26 (.17)                4.2
>> Period3     -0.07 0.23  -0.3    -0.11 0.34 (.23)               -0.3
>> Period4     -0.20 0.25  -0.8    -0.24 0.36 (.24)               -0.7
>>
>> The SEs (really SEDs) are not much increased from the quasibinomial model.
>> The estimates of treatment e?ects (di?erences from the overall mean) are
>> substantially reduced (pulled in towards the overall mean). The net e?ect is
>> that the z -statistic is smaller for the glmer model than the t for the
>> quasibinomial model.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 12/12/2008, at 7:52 AM, Andrew Robinson wrote:
>>
>>> Echoing Murray's points here - nicely put, Murray - it seems to me
>>> that the quasi-likelihood and the GLMM are different approaches to the
>>> same problem.
>>>
>>> Can anyone provide a substantial example where random effects and
>>> quasilikelihood have both been necessary?
>>>
>>> Best wishes,
>>>
>>> Andrew
>>>
>>>
>>> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>>>> The following is how I think about this at the moment:
>>>>
>>>> The quasi-likelihood approach is an attempt at a model-free approach to
>>>> the problem of overdispersion in non-Gaussian regression situations
>>>> where standard distributional assumptions fail to provide the observed
>>>> mean-variance relationship.
>>>>
>>>> The glmm approach, on the other hand, does not abandon models and
>>>> likelihood but seeks to account for the observed mean-variance
>>>> relationship by adding unobserved latent variables (random effects) to
>>>> the model.
>>>>
>>>> Seeking to combine the two approaches by using both quasilikelihood
>>>> *and* random effects would seem to be asking for trouble as being able
>>>> to use two tools on one problem would give a lot of flexibility to the
>>>> parameter estimation; probably leading to a very flat quasilikelihood
>>>> surface and ill-determined optima.
>>>>
>>>> But all of the above is only thoughts without the benefit of either
>>>> serious attempts at fitting real data or doing serious theory so I will
>>>> defer to anyone who has done either!
>>>>
>>>> Philosophically, at least, there seems to be clash between the two
>>>> approaches and I doubt that attempts to combine them will be successful.
>>>>
>>>> Murray Jorgensen
>>>>
>>>>
>>> --
>>> Andrew Robinson
>>> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>>> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>>> http://www.ms.unimelb.edu.au/~andrewpr
>>> http://blogs.mbs.edu/fishing-in-the-bay/
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 139 5862



From John.Maindonald at anu.edu.au  Sat Dec 13 10:08:11 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Sat, 13 Dec 2008 20:08:11 +1100
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <4943698D.7080109@stats.waikato.ac.nz>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
	<4943698D.7080109@stats.waikato.ac.nz>
Message-ID: <F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>

I certainly prefer fully specified models.  I will end up pretty much  
conceding Doug's point, but maybe not quite!

Equally, I am uneasy with glmer's restriction to models where the  
error family variance can only be modified by addition on the scale of  
the linear predictor.

There's an issue of what is a "fully specified model".  Sure one can  
sample from a negative binomial, but when one gets down to what  
processes might generate a negative binomial, there are several  
alternative mechanisms.  Rather than using a negative binomial as a  
way of modeling overdispersion, I'd prefer to be modeling the process  
at a more fundamental level -  maybe from applying a gamma mixing  
distribution to a Poisson rate.  That way, one can think about whether  
a gamma mixing distribution makes sense, whether something else might  
be more appropriate.  Direct entry into use of a negative binomial  
avoids exposure to such doubts.

I like to think of a quasibinomial with a dispersion equal to three as  
generated by a sequence of Bernoulli trials in which each event  
generates 3 repeats of itself.  This does not quite work (or I do not  
know how it works) if each event has to generate 2.5 repeats.

[I am reminded of Swedish mathematical educationalist Andrejs Dunkel's  
quip: "1.8 children per family! How can that be?" , with the reply  
"Statistics, my friends, statistics Seems to promote split  
personalities") Sadly, Andrejs is deceased]

It would I think be in the spirit of the direction in which lmer is  
moving, albeit for heterogeneous variances where the error is normal,  
to allow modeling at the level (a gamma mixture of Poissons) I have in  
mind.  Would this be enormously more computationally intensive than  
modeling the negative binomial or other such distributions?  I note,  
though, your comments Doug that suggest that this kind of thing is  
scarcely tractable.

I do think a lot more work is needed that looks at what seems to  
happen, in one or other type of application, with multiple real  
datasets from that area.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 13/12/2008, at 6:51 PM, Murray Jorgensen wrote:

> I should have replied earlier to the kind comments Andrew and Doug  
> made earlier on my contrast between quasilikelihood 'models' and  
> GLMMs, however I am being invaded by sons, daughters in and out of  
> law and a grandson.
>
> I tried to be neutral in this comparison but I will 'come out' here  
> and admit that my preference is for fully-explicit probability  
> models for the data. It seems to me that without this you don't have  
> a clear meaning for the parameters that you are estimating. John  
> says "I have no problem, in principle, with one fitting method that  
> reflects multiple possible models once one gets down to detail."  
> This may be psychological  but I would have to say that I *do* have  
> a problem with that.
>
> Because data can be generated from fully-specified models it seems  
> to me that there is scope for a computer experiment comparing the  
> results of both fitting methods to data generated from a known  
> model. Just because the data would be generated from a known GLMM it  
> need not mean that the GLMM estimates from fitting the correct model  
> would be superior. I imagine that quasi approaches might do well in  
> small samples.
>
> Clearly the design of such a computer experiment would need to be  
> carefully thought out. It would probably better to design around a  
> particular real situation than to try for great generality.
>
>
>
> Douglas Bates wrote:
>> I appreciate your thoughts on this, John, and especially the example.
>> There is a tendency in discussions of the theory to ignore the
>> practical applications and in discussion of the applications to  
>> ignore
>> the theoretical foundations.  Effective statistical analysis should,
>> of course, involve both.
>> I include some comments below.
>> On Thu, Dec 11, 2008 at 11:29 PM, John Maindonald
>> <john.maindonald at anu.edu.au> wrote:
>>> The approaches have the fundamental difference that the  
>>> overdispersion model
>>> multiplies the theoretical variance by an amount that is constant  
>>> (whether
>>> on the scale of the response [the binomial variance becomes \phi n  
>>> p(1-p)],
>>> or on the scale of the linear predictor).
>> This highlights the problem that I have with the quasi families.  One
>> cannot choose the mean and variance separately in distributions like
>> the Bernoulli or Poisson.  (As the binomial is a sum of independent
>> Bernoulli distributions I will phrase this in terms of the Bernoulli
>> so I don't trip up on the n's.)  For a Gaussian distribution one has
>> the luxury of separately setting the mean and the variance.  For the
>> Bernoulli or Poisson you don't.  The choice of the mean completely
>> determines the distribution.  There is no such thing as a Bernoulli
>> distribution with variance \phi p(1-p) unless \phi is identically 1.
>> If you want to discuss generalizations of the Bernoulli or Poisson
>> distributions I could accept that but simply saying that we will base
>> a model on a distribution that is just like the Bernoulli except that
>> it has a tunable variance won't fly.  If we want to attribute
>> desirable statistical properties to estimates by saying, for example,
>> that they are maximum likelihood estimates or approximations to the
>> maximum likelihood estimates we must be able to define the likelihood
>> and to me that means that you must have a probability model.   That
>> is, you must be able to describe the probability distribution of the
>> response or, in the case of the generalized linear mixed models, the
>> conditional distribution of the response given the random effects.
>> If I can't define the probability distribution then how can I  
>> evaluate
>> the likelihood?  One can argue by analogy that the estimates based on
>> the Bernoulli have certain properties so we think that the estimates
>> from a hypothetical distribution that is just like the Bernoulli
>> except that it is overdispersed should have similar properties with  
>> an
>> extra parameter thrown in but that does not constitute a "sound
>> theoretical basis" and there is no justification for thinking that
>> such a procedure will allow for extensions to random effects.
>>> I have called overdispersion a model - actually it is not one  
>>> model, but a
>>> range of possible models. I have no problem, in principle, with  
>>> one fitting
>>> method that reflects multiple possible models once one gets down  
>>> to detail.
>>> GLMMs add to the theoretical variance, on the scale of the linear  
>>> predictor.
>>> For binomial models with the usual link functions (logit, probit,  
>>> cloglog),
>>> the scale spreads out close to p=0 or close to p=1,   With the  
>>> glmm models
>>> the variances then increase more, relatively to the overdispersion  
>>> model, at
>>> the  extremes of the scale.   (For the Poisson with a log link,  
>>> there is
>>> just one relevant extreme, at 0.)
>> Although you are not saying it explicitly it seems that you are
>> regarding the overdispersion and random effects approaches as a tool
>> for modeling the marginal variance of the responses.  It happens that
>> I don't think of the models that way, perhaps because I have
>> difficulty thinking of the marginal variance.  I'm enough of a
>> mathematician that I like to consider the simple cases which to me
>> means the unconditional distribution of the random effects and the
>> conditional distribution of the response.  In the way that I think of
>> the models those are both relatively simple distributions.
>> One of the things that trip people up when considering random effects
>> as ways of modifying the marginal variance structure of the response
>> is that techniques or modifications that will work for the Gaussian
>> distribution don't work for other distributions, because of the fact
>> that the mean and variance are separately specified in the Gaussian
>> but not in others.  In the nlme package Jose and I allowed for
>> correlation structures and variance functions for the response to be
>> specified separately from the random effects structure.  This is
>> legitimate in that we were only allowing models for which the
>> conditional distribution of Y given B = b is Gaussian.  Extending  
>> this
>> type of modeling to other families of conditional distribution is
>> conceptually very difficult.  Many people want to do this but, as  
>> that
>> noted philosopher Mick Jagger pointed out, "You can't always get what
>> you want.".  If you want to model binary or count data you have to
>> accept that the mean and the variance of the conditional distribution
>> cannot be modeled separately.  (Another noted philosopher, Ernie of
>> Sesame Street, pointed out that "You gotta put down the ducky if you
>> want to play the saxophone.")
>>> NB also, all variance assessments are conditional on getting the  
>>> link right.
>>> If the link is wrong in a way that matters, there will be apparent
>>> increases in variance in some parts of the scale that reflect  
>>> biases that
>>> arise from the inappropriate choice of link.
>>>
>>> There may be cases where overdispersion gives too small a variance
>>> (relatively) at the extremes, while glmer gives too high a  
>>> variance.  As
>>> there are an infinite number of possible ways in which the  
>>> variance might
>>> vary with (in the binomial case) p, it would be surprising if  
>>> (detectable
>>> with enough data, or enough historical experience), there were not  
>>> such
>>> "intermediate" cases.
>>>
>>> There might in principle be subplot designs, with a treatment at  
>>> the subplot
>>> level, where the overdispersion model is required at the subplot  
>>> level in
>>> order to get the treatment comparisons correct at that level.
>>>
>>> As much of this discussion is focused around ecology, experience  
>>> with
>>> fitting one or other model to large datasets is surely required  
>>> that will
>>> help decide just how, in one or other practical context, 1) the  
>>> variance is
>>> likely to change with p (or in the Poisson case, with the Poisson  
>>> mean) and
>>> 2) what links seem preferable.
>>>
>>> The best way to give the flexibility required for modeling the  
>>> variance, as
>>> it seems to me, would be the ability to make the variance of p a  
>>> fairly
>>> arbitrary function of p, with other variance components added on  
>>> the scale
>>> of the linear predictor.  More radically, all variance components  
>>> might be
>>> functions of p.  I am not sure that going that far would be a good  
>>> idea -
>>> there'd be too many complaints that model fits will not converge!
>>>
>>> The following shows a comparison that I did recently for a talk.   
>>> The p's
>>> are not sufficiently extreme to show much difference between the  
>>> two models:
>>>
>>> The dataset cbpp is from the lme4 package.
>>> infect <- with(cbpp, cbind(incidence, size - incidence))
>>> (gm1 <- glmer(infect ~ period + (1 | herd),
>>> family = binomial, data = cbpp))
>>> Random effects:
>>> Groups Name Variance Std.Dev.
>>> herd (Intercept) 0.412 0.642
>>> Number of obs: 56, groups: herd, 15
>>> Fixed effects:
>>> Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) -1.399 0.228 -6.14 8.4e-10
>>> period2 -0.992 0.305 -3.25 0.00116
>>> period3 -1.129 0.326 -3.46 0.00054
>>> period4 -1.580 0.429 -3.69 0.00023
>>>
>>> Here, use the "sum" contrasts, and compare with the overall mean.
>>>                           glmer                quasibinomial
>>>                   Est  SE          z     Est SE (binomial SE)    t
>>> (Intercept) -2.32 0.22 -10.5   -2.33 0.21 (.14)             -11.3
>>> Period1     -0.66 0.32   -2.1   -0.72 0.45 (.31)               -1.6
>>> Period2      0.93 0.18    5.0     1.06 0.26 (.17)                4.2
>>> Period3     -0.07 0.23  -0.3    -0.11 0.34 (.23)               -0.3
>>> Period4     -0.20 0.25  -0.8    -0.24 0.36 (.24)               -0.7
>>>
>>> The SEs (really SEDs) are not much increased from the  
>>> quasibinomial model.
>>> The estimates of treatment e?ects (di?erences from the overall  
>>> mean) are
>>> substantially reduced (pulled in towards the overall mean). The  
>>> net e?ect is
>>> that the z -statistic is smaller for the glmer model than the t  
>>> for the
>>> quasibinomial model.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>>
>>> On 12/12/2008, at 7:52 AM, Andrew Robinson wrote:
>>>
>>>> Echoing Murray's points here - nicely put, Murray - it seems to me
>>>> that the quasi-likelihood and the GLMM are different approaches  
>>>> to the
>>>> same problem.
>>>>
>>>> Can anyone provide a substantial example where random effects and
>>>> quasilikelihood have both been necessary?
>>>>
>>>> Best wishes,
>>>>
>>>> Andrew
>>>>
>>>>
>>>> On Fri, Dec 12, 2008 at 09:11:39AM +1300, Murray Jorgensen wrote:
>>>>> The following is how I think about this at the moment:
>>>>>
>>>>> The quasi-likelihood approach is an attempt at a model-free  
>>>>> approach to
>>>>> the problem of overdispersion in non-Gaussian regression  
>>>>> situations
>>>>> where standard distributional assumptions fail to provide the  
>>>>> observed
>>>>> mean-variance relationship.
>>>>>
>>>>> The glmm approach, on the other hand, does not abandon models and
>>>>> likelihood but seeks to account for the observed mean-variance
>>>>> relationship by adding unobserved latent variables (random  
>>>>> effects) to
>>>>> the model.
>>>>>
>>>>> Seeking to combine the two approaches by using both  
>>>>> quasilikelihood
>>>>> *and* random effects would seem to be asking for trouble as  
>>>>> being able
>>>>> to use two tools on one problem would give a lot of flexibility  
>>>>> to the
>>>>> parameter estimation; probably leading to a very flat  
>>>>> quasilikelihood
>>>>> surface and ill-determined optima.
>>>>>
>>>>> But all of the above is only thoughts without the benefit of  
>>>>> either
>>>>> serious attempts at fitting real data or doing serious theory so  
>>>>> I will
>>>>> defer to anyone who has done either!
>>>>>
>>>>> Philosophically, at least, there seems to be clash between the two
>>>>> approaches and I doubt that attempts to combine them will be  
>>>>> successful.
>>>>>
>>>>> Murray Jorgensen
>>>>>
>>>>>
>>>> --
>>>> Andrew Robinson
>>>> Department of Mathematics and Statistics            Tel:  
>>>> +61-3-8344-6410
>>>> University of Melbourne, VIC 3010 Australia         Fax:  
>>>> +61-3-8344-4599
>>>> http://www.ms.unimelb.edu.au/~andrewpr
>>>> http://blogs.mbs.edu/fishing-in-the-bay/
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -- 
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
> Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 139 5862



From A.Robinson at ms.unimelb.edu.au  Sat Dec 13 12:53:47 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 13 Dec 2008 22:53:47 +1100
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
	<4943698D.7080109@stats.waikato.ac.nz>
	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
Message-ID: <20081213115347.GB1582@ms.unimelb.edu.au>

On Sat, Dec 13, 2008 at 08:08:11PM +1100, John Maindonald wrote:
> I certainly prefer fully specified models.  I will end up pretty much  
> conceding Doug's point, but maybe not quite!
> 
> Equally, I am uneasy with glmer's restriction to models where the  
> error family variance can only be modified by addition on the scale of  
> the linear predictor.

Yes, me too.

> There's an issue of what is a "fully specified model".  Sure one can  
> sample from a negative binomial, but when one gets down to what  
> processes might generate a negative binomial, there are several  
> alternative mechanisms.  Rather than using a negative binomial as a  
> way of modeling overdispersion, I'd prefer to be modeling the process  
> at a more fundamental level -  maybe from applying a gamma mixing  
> distribution to a Poisson rate.  That way, one can think about whether  
> a gamma mixing distribution makes sense, whether something else might  
> be more appropriate.  Direct entry into use of a negative binomial  
> avoids exposure to such doubts.

I think that this is fair enough and well put, John, but I'm going to
push back in the other direction with a hypothetical example.  Let's
say that you have your over-dispersed count data.  What do you lose if
you simply take some convenient and credible transformation of the
response variable and then use lme, paying close attention to your
conditional distribution plots?  

Let me pin that down a little: would you be reluctant to follow that
approach under any conditions?  If so, then under what conditions
would you be reluctant to follow that approach, and why?

(My experience has been that the judicious application of variance
models corrects for most of the variability problems that I have
encountered so far in practical work.)

> I like to think of a quasibinomial with a dispersion equal to three as  
> generated by a sequence of Bernoulli trials in which each event  
> generates 3 repeats of itself.  This does not quite work (or I do not  
> know how it works) if each event has to generate 2.5 repeats.

2 half the time and 3 half the time?

> It would I think be in the spirit of the direction in which lmer is  
> moving, albeit for heterogeneous variances where the error is normal,  
> to allow modeling at the level (a gamma mixture of Poissons) I have in  
> mind.  Would this be enormously more computationally intensive than  
> modeling the negative binomial or other such distributions?  I note,  
> though, your comments Doug that suggest that this kind of thing is  
> scarcely tractable.

On a side note, I believe that Lee and Nelder's approach to
mixed-effects modelling (as realized in Genstat) allows random effects
to come from certain non-normal distributions, including for example
the binomial-beta and the poisson-gamma combinations.  See Table 6.2
of their book.  The underlying theory still has some gaps in it, I
think. 

Greatly enjoying this conversation,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Gregor.Gorjanc at bfro.uni-lj.si  Sat Dec 13 15:13:12 2008
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Sat, 13 Dec 2008 15:13:12 +0100
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than fitting
	it
Message-ID: <F189E18BBAA8B6479F618B9044CF4E9C68D7BCC55F@REGULUS.bfro.uni-lj.si>

Dear lme4 developers,

I am a big fan/user of your lme4 package. Thank you very much for this package and
other R related work. I would like to report my experience that summarizing the fitted
model via summary() takes more RAM than fitting it with lmer(). I noticed this several
times. The model is quite large, but not that large. Am I doing something wrong or ...?

Bellow is an example of the model I am fitting along with the "necessary" code
to summarize the fitted model. I am currently using R 2.8.0 on MS Windows Vista on
Dell Inspiron I1520 laptop having Intel(R) Core(TM) Duo CPU T7500 @ 2.20GHz 2.20GHz
and 2046 MB of RAM. Version of lme4 is 0.999375-27 as of date 2008-09-27.

> ## Fit the model
> fit9b <- lmer(tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM +
>                                      (1 | rejec) + (1 | hy) + (1 | hys), data=podatki)
>
> summary(fit9b)
Error: cannot allocate vector of size 130.4 Mb
In addition: There were 22 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: In slot(from, what) <- slot(value, what) ... :
  Reached total allocation of 1535Mb: see help(memory.size)
>
> ## Make sure R can allocate enough memory
> memory.limit(size=1900)
>
> ## Sink the output - since correlation matrix of fixed effects hides
> sink(file="tmp.txt")
> summary(fit9b)
> sink()

## Linear mixed model fit by REML
## Formula: tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM + (1 | rejec) +      (1 | hy) + (1 | hys)
##    Data: podatki
##     AIC    BIC logLik deviance REMLdev
##  150646 152563 -75118   149507  150236
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  hys      (Intercept) 0.057519 0.23983
##  hy       (Intercept) 0.135671 0.36834
##  rejec    (Intercept) 0.268200 0.51788
##  Residual             0.297427 0.54537
## Number of obs: 85035, groups: hys, 9653; hy, 2036; rejec, 346
...

I also tried using the following things before calling summary():
- gc() and summary();

- removing all unnecessary objects in the workspace, gc() and summary();

- saving the object, starting new instance of R, loading the object and summary();

but could still not summarize the fitted object. I am really suprised that summarising the
fitted model consumes more memory than fittng it. Am I missing something?

Lep pozdrav / With regards,
    Gregor Gorjanc
----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty        www: http://gregor.gorjanc.googlepages.com
Animal Science Department   blog: http://ggorjan.blogspot.com
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe            tel: +386 (0)1 72 17 861



From bates at stat.wisc.edu  Sat Dec 13 16:18:02 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 13 Dec 2008 09:18:02 -0600
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
	fitting it
In-Reply-To: <F189E18BBAA8B6479F618B9044CF4E9C68D7BCC55F@REGULUS.bfro.uni-lj.si>
References: <F189E18BBAA8B6479F618B9044CF4E9C68D7BCC55F@REGULUS.bfro.uni-lj.si>
Message-ID: <40e66e0b0812130718x70afcc28hfd4c999c9b0f7f55@mail.gmail.com>

The summary object contains a copy of the original fitted model.  At
the time of return it must be an actual copy.  My guess is that it is
the need to create two copies of the fitted model object that is
causing the memory overflow.  You may want to set a trace on the
summary method for signature(object = "mer") and step through the
evaluation to see where the problem arises.  My guess is that it will
be at the point where the new "summary.mer" object is created.

The need to create copies of very large objects is a problem that I
have wrestled with in the design of the lme4 package.  To maintain the
functional language semantics of R  you cannot modify an argument to a
function, even a replacement function.  If your model-fitting function
is based on iterative optimization and the objects involved are very
large then the need to create copies often is a problem.  The current
version of lme4 gets around this problem by cheating and modifying the
arguments to certain .Call functions.  The development version (in the
allcoef branch of the SVN tree for lme4 at R-forge) is cleaner in that
it uses an environment to hold the objects representing the model
during the optimization.  Environments are special in that they are
never copied so they provide a legitimate way of implementing call by
reference semantics.

On Sat, Dec 13, 2008 at 8:13 AM, Gorjanc Gregor
<Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> Dear lme4 developers,
>
> I am a big fan/user of your lme4 package. Thank you very much for this package and
> other R related work. I would like to report my experience that summarizing the fitted
> model via summary() takes more RAM than fitting it with lmer(). I noticed this several
> times. The model is quite large, but not that large. Am I doing something wrong or ...?
>
> Bellow is an example of the model I am fitting along with the "necessary" code
> to summarize the fitted model. I am currently using R 2.8.0 on MS Windows Vista on
> Dell Inspiron I1520 laptop having Intel(R) Core(TM) Duo CPU T7500 @ 2.20GHz 2.20GHz
> and 2046 MB of RAM. Version of lme4 is 0.999375-27 as of date 2008-09-27.
>
>> ## Fit the model
>> fit9b <- lmer(tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM +
>>                                      (1 | rejec) + (1 | hy) + (1 | hys), data=podatki)
>>
>> summary(fit9b)
> Error: cannot allocate vector of size 130.4 Mb
> In addition: There were 22 warnings (use warnings() to see them)
>> warnings()
> Warning messages:
> 1: In slot(from, what) <- slot(value, what) ... :
>  Reached total allocation of 1535Mb: see help(memory.size)
>>
>> ## Make sure R can allocate enough memory
>> memory.limit(size=1900)
>>
>> ## Sink the output - since correlation matrix of fixed effects hides
>> sink(file="tmp.txt")
>> summary(fit9b)
>> sink()
>
> ## Linear mixed model fit by REML
> ## Formula: tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM + (1 | rejec) +      (1 | hy) + (1 | hys)
> ##    Data: podatki
> ##     AIC    BIC logLik deviance REMLdev
> ##  150646 152563 -75118   149507  150236
> ## Random effects:
> ##  Groups   Name        Variance Std.Dev.
> ##  hys      (Intercept) 0.057519 0.23983
> ##  hy       (Intercept) 0.135671 0.36834
> ##  rejec    (Intercept) 0.268200 0.51788
> ##  Residual             0.297427 0.54537
> ## Number of obs: 85035, groups: hys, 9653; hy, 2036; rejec, 346
> ...
>
> I also tried using the following things before calling summary():
> - gc() and summary();
>
> - removing all unnecessary objects in the workspace, gc() and summary();
>
> - saving the object, starting new instance of R, loading the object and summary();
>
> but could still not summarize the fitted object. I am really suprised that summarising the
> fitted model consumes more memory than fittng it. Am I missing something?
>
> Lep pozdrav / With regards,
>    Gregor Gorjanc
> ----------------------------------------------------------------------
> University of Ljubljana     PhD student
> Biotechnical Faculty        www: http://gregor.gorjanc.googlepages.com
> Animal Science Department   blog: http://ggorjan.blogspot.com
> Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si
> SI-1230 Domzale             fax: +386 (0)1 72 17 888
> Slovenia, Europe            tel: +386 (0)1 72 17 861
> ----------------------------------------------------------------------
>



From bolker at ufl.edu  Sat Dec 13 18:00:07 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 13 Dec 2008 12:00:07 -0500
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
 or dispersion?)
In-Reply-To: <20081213115347.GB1582@ms.unimelb.edu.au>
References: <493FE6B6.3000507@ufl.edu>	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>	<494173FB.9040805@stats.waikato.ac.nz>	<20081211205200.GD1260@ms.unimelb.edu.au>	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>	<4943698D.7080109@stats.waikato.ac.nz>	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
	<20081213115347.GB1582@ms.unimelb.edu.au>
Message-ID: <4943EA17.7030600@ufl.edu>

> 
> I think that this is fair enough and well put, John, but I'm going to
> push back in the other direction with a hypothetical example.  Let's
> say that you have your over-dispersed count data.  What do you lose if
> you simply take some convenient and credible transformation of the
> response variable and then use lme, paying close attention to your
> conditional distribution plots?  
> 

  Besides the aesthetic preference for fully specified models etc.
(although there's also the danger of forgetting that "all models
are wrong etc." and believing the model too much), the most common
reason in ecological contexts for not being able to get away with
transformation is that the data are zero-rich (someone mentioned
zero-inflated/hurdle models earlier in this discussion, which
basically amounts to modeling presence/absence [either of
"structural" zeros or of all zero values] and conditional
density separately).  There's nothing you can do to transform
a spike in the data (at zero or elsewhere) into anything
other than a spike ...

  Ben Bolker



From maj at stats.waikato.ac.nz  Sat Dec 13 19:46:15 2008
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Sun, 14 Dec 2008 07:46:15 +1300
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
 or dispersion?)
In-Reply-To: <4943EA17.7030600@ufl.edu>
References: <493FE6B6.3000507@ufl.edu>	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>	<494173FB.9040805@stats.waikato.ac.nz>	<20081211205200.GD1260@ms.unimelb.edu.au>	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>	<4943698D.7080109@stats.waikato.ac.nz>	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>	<20081213115347.GB1582@ms.unimelb.edu.au>
	<4943EA17.7030600@ufl.edu>
Message-ID: <494402F7.3090704@stats.waikato.ac.nz>

I thought I might note that zero-inflated count data and negative 
binomial data can both be seen as cases where the response variable 
follows a mixture distribution. In the ZIP case a mixture of a constant 
[ Poisson(0) or Poisson(tiny) with another Poisson], in the negative 
binomial case a gamma mixture of Poissons [which might be approximated 
by a finite mixture].

John is "uneasy with glmer's restriction to models where the error 
family variance can only be modified by addition on the scale of the 
linear predictor." Mixtures would be one mechanism for introducing other 
variance patterns into the model.

Murray Jorgensen

Ben Bolker wrote:
>> I think that this is fair enough and well put, John, but I'm going to
>> push back in the other direction with a hypothetical example.  Let's
>> say that you have your over-dispersed count data.  What do you lose if
>> you simply take some convenient and credible transformation of the
>> response variable and then use lme, paying close attention to your
>> conditional distribution plots?  
>>
> 
>   Besides the aesthetic preference for fully specified models etc.
> (although there's also the danger of forgetting that "all models
> are wrong etc." and believing the model too much), the most common
> reason in ecological contexts for not being able to get away with
> transformation is that the data are zero-rich (someone mentioned
> zero-inflated/hurdle models earlier in this discussion, which
> basically amounts to modeling presence/absence [either of
> "structural" zeros or of all zero values] and conditional
> density separately).  There's nothing you can do to transform
> a spike in the data (at zero or elsewhere) into anything
> other than a spike ...
> 
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 139 5862



From bates at stat.wisc.edu  Sat Dec 13 20:23:21 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 13 Dec 2008 13:23:21 -0600
Subject: [R-sig-ME] Plans for lme4-1.0
Message-ID: <40e66e0b0812131123j58158871gde57b77c36902fe4@mail.gmail.com>

The discussion of the quasi families in the thread "Re: [R-sig-ME]
single argument anova for GLMMs (really, glmer, or dispersion?)" has
helped to clarify my thinking about the types of models that I plan to
be able to fit in the 1.0 release of lme4.  I know this won't include
every model that users would like to be able to fit but I hope it will
include some useful models.  (Ben mentioned George Box's famous quote
about models.  The complete quote is "All models are wrong; some
models are useful.")

The model is defined by the conditional distribution of the response
given the random effects,  (Y|B=b) in my notation, and the
unconditional distribution of the random effects.  The
lmer/glmer/nlmer functions are based on a multivariate Gaussian
unconditional distribution of the random effects with E[B] = 0 and
Var(B) = \Sigma(\theta).  That is, the covariance matrix of the random
effects is a parameterized, positive semidefinite, symmetric matrix.
The parameters, \theta, determine the left Cholesky factor,
\Lambda(\theta), of \Sigma(\theta), for conditional distributions
without a common scale parameter, or \Sigma(\theta)/\sigma^2, for
conditional distributions, such as the Gaussian, with a common scale
parameter, \sigma.

The conditional distribution, (Y|B=b), must satisfy

 1) The scalar conditional distributions are independent and from the
same distribution family.

 2) The scalar conditional distributions are completely determined by
the conditional mean and, at most, one additional parameter which can
be expressed as a common scale parameter.

 3) The vector of conditional means, \mu, depends on b only through
the linear predictor \gamma = Z\beta+Xb

 4) The map from \gamma to \mu is multi-diagonal (explained below) and
can be expressed as

    \gamma -> \eta -> \mu

where \eta -> \mu is the vectorized inverse link function for a glm
family.  This is a diagonal map in the sense that the Jacobian matrix
for the map is diagonal because the i'th element of \mu depends only
on the i'th element of \eta.  Furthermore, the vector-valued link and
inverse link functions are based on a common scalar link or inverse
link.  (In other words, if you have a logit link for one element of
\mu, you must have the logit link for all elements of \mu.)

The map from \gamma to \eta has a similar property except that the
dimension of \gamma can be a multiple, s, of n, the dimension of \eta,
so the Jacobian matrix d\eta/d\gamma will be of dimension n by ns.
This matrix must be the horizontal concatenation of s diagonal
matrices and they must be generated by a single model function, m,
mapping an s-dimensional vector to a scalar.

The nonlinear model in nlmer defines the map from \gamma to \eta.  The
glm family defines the map from \eta to \mu and also defines the
conditional variance (up to a constant).  The conditional variance
determines the weights in the iteratively reweighted least squares
calculation.

By factoring the model this way it is clear what information must be
evaluated and retained and how one would define a generalized
nonlinear mixed model, which I think will have widespread application
in psychometrics and other areas.

The map shown above takes b to \mu through \gamma and \eta and allows
us to evaluate the Jacobian of this map.  However, that is not the
full story.  We introduce another vector of random effects called U
with a spherical Gaussian marginal distribution.  That is, E[U] = 0
and Var(U) = \sigma^2 I (the name "spherical" comes from the fact that
the contours of constant density are spheres) and define B =
\Lambda(\theta) P' U where P is a fixed permutation matrix derived
from the pattern of nonzeros in Z.  P has no effect on the statistical
theory but is very important in the computation.

Now the effects of all the parameters in the model are incorporated
into the map from u to \mu and we can evaluate the conditional modes
of U and the conditional estimates of \beta and \sigma, given \theta
through a penalized iteratively reweighted least squares (PIRLS)
algorithm.  This, linear or nonlinear, weighted least squares problem
may involve a huge number of variables but the penalty part makes it a
very well conditioned problem.   Furthermore, the Jacobian matrix
d\mu/d u is very sparse.  This is where the sparse matrix methods come
in.  The sparse Cholesky factor of a matrix derived from d\mu/d u
provides the conditional covariance matrix for U given Y from which
the Laplace approximation to the deviance is derived.

Although this may seem like a very long-winded explanation (I seem to
be prone to offering long-winded explanations) the point that I want
to highlight is that the restrictions on the model form, in particular
the assumption of a Gaussian unconditional distribution for the random
effects, B, are not made frivolously.  This assumption is central to
the computational method using PIRLS.  In models with many random
effects in potentially complex structures you must be able to deal
with the random effects efficiently and the PIRLS algorithm combined
with sparse Cholesky factorization does that.

The code in the allcoef branch makes the central role of PIRLS more
explicit.  The name "allcoef" comes from the fact that all the
coefficients (u and \beta) in the linear predictor, \gamma = Z
\Lambda(\theta)P'u + X\beta, are optimized in the PIRLS step.  In the
currently released version of lme4 u and \beta are jointly optimized
for linear mixed models but only u is optimized in this step for
generalized linear mixed models and nonlinear mixed models.

It is still the case that only the brave or foolhardy should try the
code in that branch.  I'm gradually cleaning it up but there are still
many parts that are not working.  In particular mcmcsamp is not
currently working in that branch.  My goal is to get mcmcsamp stable
and to get all the other parts working in this branch then release it
for testing and finally release lme4-1.0.  The subtext in that message
is that only the models I describe above will be fit by the lme4-1.0
package.



From bates at stat.wisc.edu  Sat Dec 13 20:36:47 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 13 Dec 2008 13:36:47 -0600
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <494402F7.3090704@stats.waikato.ac.nz>
References: <493FE6B6.3000507@ufl.edu> <494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
	<4943698D.7080109@stats.waikato.ac.nz>
	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
	<20081213115347.GB1582@ms.unimelb.edu.au> <4943EA17.7030600@ufl.edu>
	<494402F7.3090704@stats.waikato.ac.nz>
Message-ID: <40e66e0b0812131136u60b87e71ndf227faecc58e891@mail.gmail.com>

On Sat, Dec 13, 2008 at 12:46 PM, Murray Jorgensen
<maj at stats.waikato.ac.nz> wrote:
> I thought I might note that zero-inflated count data and negative binomial
> data can both be seen as cases where the response variable follows a mixture
> distribution. In the ZIP case a mixture of a constant [ Poisson(0) or
> Poisson(tiny) with another Poisson], in the negative binomial case a gamma
> mixture of Poissons [which might be approximated by a finite mixture].
>
> John is "uneasy with glmer's restriction to models where the error family
> variance can only be modified by addition on the scale of the linear
> predictor." Mixtures would be one mechanism for introducing other variance
> patterns into the model.

In another thread I posted a long-winded manifesto regarding the types
of models that will be fit by lme4-1.0

John, you may be uneasy but I need to get a completed version of this
code out some time (it is way overdue), so I am truncating the list of
possible models at the ones I describe there.

I appreciate all the contributions to this discussion.
>
> Murray Jorgensen
>
> Ben Bolker wrote:
>>>
>>> I think that this is fair enough and well put, John, but I'm going to
>>> push back in the other direction with a hypothetical example.  Let's
>>> say that you have your over-dispersed count data.  What do you lose if
>>> you simply take some convenient and credible transformation of the
>>> response variable and then use lme, paying close attention to your
>>> conditional distribution plots?
>>
>>  Besides the aesthetic preference for fully specified models etc.
>> (although there's also the danger of forgetting that "all models
>> are wrong etc." and believing the model too much), the most common
>> reason in ecological contexts for not being able to get away with
>> transformation is that the data are zero-rich (someone mentioned
>> zero-inflated/hurdle models earlier in this discussion, which
>> basically amounts to modeling presence/absence [either of
>> "structural" zeros or of all zero values] and conditional
>> density separately).  There's nothing you can do to transform
>> a spike in the data (at zero or elsewhere) into anything
>> other than a spike ...
>>
>>  Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
> Department of Statistics, University of Waikato, Hamilton, New Zealand
> Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
> Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 139 5862
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sat Dec 13 21:39:30 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 13 Dec 2008 14:39:30 -0600
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <494402F7.3090704@stats.waikato.ac.nz>
References: <493FE6B6.3000507@ufl.edu> <494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
	<4943698D.7080109@stats.waikato.ac.nz>
	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
	<20081213115347.GB1582@ms.unimelb.edu.au> <4943EA17.7030600@ufl.edu>
	<494402F7.3090704@stats.waikato.ac.nz>
Message-ID: <40e66e0b0812131239t515e18aqe2e601c31b83303f@mail.gmail.com>

On Sat, Dec 13, 2008 at 12:46 PM, Murray Jorgensen
<maj at stats.waikato.ac.nz> wrote:
> I thought I might note that zero-inflated count data and negative binomial
> data can both be seen as cases where the response variable follows a mixture
> distribution. In the ZIP case a mixture of a constant [ Poisson(0) or
> Poisson(tiny) with another Poisson], in the negative binomial case a gamma
> mixture of Poissons [which might be approximated by a finite mixture].

I was thinking a bit more about your suggestion of mixtures as a way
of incorporating overdispersion.  It is quite a reasonable suggestion
but I am afraid I don't know enough about methods of estimating the
parameters in a mixture model to decide if it is feasible to put such
models in the framework I plan to use.  My "bottom line" is that I
want to be able to determine the conditional modes of the random
effects given the data and parameter values by solving a penalized
iteratively reweighted least squares problem. If mixture models, or
even restricted forms of mixture models like the ZIP model, can be
expressed in that form then it is just a question of deciding how the
model can be specified and how the specification can be translated
into such a problem.  (This process is not trivial.  It is a lot
easier to write down a model than it is to decide how to define the
arguments and defaults for specifying such a model as an R function.)

My guess is that models like ZIP can't be expressed that way so it
would be necessary to condition on the mixture components, estimate
the conditional modes of the random effects and conditional estimates
of the parameters, then iterate.

One of the basic changes in the allcoef branch of the lme4 code is the
way that the "outer" optimization is performed (PIRLS is the "inner"
optimization in the Laplace or adaptive Gauss-Hermite approximation;
optimization of the profiled deviance with respect to \theta is the
outer optimization).  In the current lme4 this is done internally in C
code and hence is somewhat inaccessible to other programmers.  In the
allcoef branch this is done at the R level by calling nlminb.  In that
branch setting doFit = FALSE in a call to lmer/glmer/nlmer returns an
environment that is suitable for defining the optimization problem in
that it has methods for getPars, getBounds and setPars.  The latter
method sets new values of the parameters and returns the objective
function evaluated at the new parameters. Allowing access to this
environment is intended to be the hook that others can use to set up a
model that is almost what they want so they can then mold the
optimization process to fit the model that they do want.



From A.Robinson at ms.unimelb.edu.au  Sat Dec 13 22:14:16 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 14 Dec 2008 08:14:16 +1100
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
	or dispersion?)
In-Reply-To: <4943EA17.7030600@ufl.edu>
References: <493FE6B6.3000507@ufl.edu>
	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>
	<494173FB.9040805@stats.waikato.ac.nz>
	<20081211205200.GD1260@ms.unimelb.edu.au>
	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>
	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>
	<4943698D.7080109@stats.waikato.ac.nz>
	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>
	<20081213115347.GB1582@ms.unimelb.edu.au>
	<4943EA17.7030600@ufl.edu>
Message-ID: <20081213211416.GD1283@ms.unimelb.edu.au>

On Sat, Dec 13, 2008 at 12:00:07PM -0500, Ben Bolker wrote:
> > 
> > I think that this is fair enough and well put, John, but I'm going to
> > push back in the other direction with a hypothetical example.  Let's
> > say that you have your over-dispersed count data.  What do you lose if
> > you simply take some convenient and credible transformation of the
> > response variable and then use lme, paying close attention to your
> > conditional distribution plots?  
> 
>   Besides the aesthetic preference for fully specified models etc.
> (although there's also the danger of forgetting that "all models
> are wrong etc." and believing the model too much), the most common
> reason in ecological contexts for not being able to get away with
> transformation is that the data are zero-rich (someone mentioned
> zero-inflated/hurdle models earlier in this discussion, which
> basically amounts to modeling presence/absence [either of
> "structural" zeros or of all zero values] and conditional
> density separately).  There's nothing you can do to transform
> a spike in the data (at zero or elsewhere) into anything
> other than a spike ...

Yes indeed :), you are correct.  But, that's a problem that bedevils
glms too.  I was more thinking along the lines: when would it be
inadvisable to use a transformation and explicit variance model
instead of a glm?

Cheers,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From kushler at oakland.edu  Sun Dec 14 04:37:22 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Sat, 13 Dec 2008 22:37:22 -0500
Subject: [R-sig-ME] Sample size and mixed models
In-Reply-To: <20081212221144.GB1295@ms.unimelb.edu.au>
References: <49413C0E.3070308@cornell.edu> <4942735B.2060109@oakland.edu>
	<20081212221144.GB1295@ms.unimelb.edu.au>
Message-ID: <49447F72.1030200@oakland.edu>


Section 4.5.3 of Agresti's Categorical Data Analysis (pages 140-141 of the
second edition) discusses "grouped vs ungrouped" for the binomial case.
The same issue arises in Poisson models for count data.  All individuals
with the same "covariate pattern" can be collapsed to a single record, with
the sum of the counts as the response and an offset for the sample size, and
the same fitted model is obtained.

Agresti refers to two different versions of the "saturated" model, but I
like to reserve the term "saturated" for the model that fits the grouped
data perfectly and call the other the "perfect" model (since it predicts
all the individuals correctly).

Nagelkerke's R^2 will be larger when computed using the grouped data
likelihood, but that's because the "saturated" model is the definition
of perfection in that case.  This is analogous to defining the model
"y ~ factor(x)" as perfect when assessing "y ~ x" - you're throwing away
the "within groups" sum of squares and treating the "between groups" sum
of squares as the total.

Strictly speaking, the choice of which version of n to use should probably not
be made independently of this issue.  If the count of individuals is used with the
grouped data likelihood it reduces the amount by which the R^2 value is inflated,
which is my (admittedly weak) reason for the blanket recommendation.

Regards,   Rob


Andrew Robinson wrote:
> Hi Rob,
> 
> On Fri, Dec 12, 2008 at 09:21:15AM -0500, Robert Kushler wrote:
>> I would argue that the larger value (individuals) is always more appropriate
>> than the smaller value (clusters).  
> 
> That's interesting - I have the opposite response, or at least that
> the truth lies somewhere in the middle.  Can you expand on why you
> would argue that the larger value is always more appropriate than the
> smaller value?
> 
>> However, the more important issue is that the "ungrouped" version of
>> the likelihood should be used for these calculations.  Using the
>> "grouped data" likelihood omits the within cluster variation and
>> inflates the estimate of predictive power.
> 
> I don't follow what you mean by "grouped" and "ungrouped" versions of
> the likelihood.  Can you clarify?
> 
> Cheers,
> 
> Andrew
>



From kushler at oakland.edu  Sun Dec 14 04:59:36 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Sat, 13 Dec 2008 22:59:36 -0500
Subject: [R-sig-ME] single argument anova for GLMMs (really, glmer,
 or dispersion?)
In-Reply-To: <494402F7.3090704@stats.waikato.ac.nz>
References: <493FE6B6.3000507@ufl.edu>	<40e66e0b0812110631x1b8c709fh7cfa7b64e4fd1c2c@mail.gmail.com>	<494173FB.9040805@stats.waikato.ac.nz>	<20081211205200.GD1260@ms.unimelb.edu.au>	<E6F6A91B-BC35-4A67-9A24-186CB9732205@anu.edu.au>	<40e66e0b0812120729w30139b8fy4a9d0c8058882b29@mail.gmail.com>	<4943698D.7080109@stats.waikato.ac.nz>	<F07A8D5F-4342-4094-A2FF-973830E65710@anu.edu.au>	<20081213115347.GB1582@ms.unimelb.edu.au>	<4943EA17.7030600@ufl.edu>
	<494402F7.3090704@stats.waikato.ac.nz>
Message-ID: <494484A8.10506@oakland.edu>


Doesn't it make sense to think of the "gamma mixture of Poissons" as
a Poisson GLM with a gamma-distributed random (intercept) effect?  In other
words, it's a GLMM with a gamma distribution instead of gaussian.  Adding
another (gaussian) random effect to a negative binomial model seems a bit
redundant.

Regards,   Rob Kushler


Murray Jorgensen wrote:
> I thought I might note that zero-inflated count data and negative 
> binomial data can both be seen as cases where the response variable 
> follows a mixture distribution. In the ZIP case a mixture of a constant 
> [ Poisson(0) or Poisson(tiny) with another Poisson], in the negative 
> binomial case a gamma mixture of Poissons [which might be approximated 
> by a finite mixture].
> 
> John is "uneasy with glmer's restriction to models where the error 
> family variance can only be modified by addition on the scale of the 
> linear predictor." Mixtures would be one mechanism for introducing other 
> variance patterns into the model.
> 
> Murray Jorgensen
> 
> Ben Bolker wrote:
>>> I think that this is fair enough and well put, John, but I'm going to
>>> push back in the other direction with a hypothetical example.  Let's
>>> say that you have your over-dispersed count data.  What do you lose if
>>> you simply take some convenient and credible transformation of the
>>> response variable and then use lme, paying close attention to your
>>> conditional distribution plots? 
>>
>>   Besides the aesthetic preference for fully specified models etc.
>> (although there's also the danger of forgetting that "all models
>> are wrong etc." and believing the model too much), the most common
>> reason in ecological contexts for not being able to get away with
>> transformation is that the data are zero-rich (someone mentioned
>> zero-inflated/hurdle models earlier in this discussion, which
>> basically amounts to modeling presence/absence [either of
>> "structural" zeros or of all zero values] and conditional
>> density separately).  There's nothing you can do to transform
>> a spike in the data (at zero or elsewhere) into anything
>> other than a spike ...
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Sun Dec 14 05:25:24 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 14 Dec 2008 15:25:24 +1100
Subject: [R-sig-ME] Sample size and mixed models
In-Reply-To: <49447F72.1030200@oakland.edu>
References: <49413C0E.3070308@cornell.edu> <4942735B.2060109@oakland.edu>
	<20081212221144.GB1295@ms.unimelb.edu.au>
	<49447F72.1030200@oakland.edu>
Message-ID: <20081214042524.GA16331@ms.unimelb.edu.au>

On Sat, Dec 13, 2008 at 10:37:22PM -0500, Robert Kushler wrote:
> 
> Section 4.5.3 of Agresti's Categorical Data Analysis (pages 140-141 of the
> second edition) discusses "grouped vs ungrouped" for the binomial case.
> The same issue arises in Poisson models for count data.  All individuals
> with the same "covariate pattern" can be collapsed to a single record, with
> the sum of the counts as the response and an offset for the sample size, and
> the same fitted model is obtained.
> 
> Agresti refers to two different versions of the "saturated" model, but I
> like to reserve the term "saturated" for the model that fits the grouped
> data perfectly and call the other the "perfect" model (since it predicts
> all the individuals correctly).
> 
> Nagelkerke's R^2 will be larger when computed using the grouped data
> likelihood, but that's because the "saturated" model is the definition
> of perfection in that case.  This is analogous to defining the model
> "y ~ factor(x)" as perfect when assessing "y ~ x" - you're throwing away
> the "within groups" sum of squares and treating the "between groups" sum
> of squares as the total.

I see your logic, but the original question referred to the sample
size, rather than the likelihood.  That was why I was surprised: using
the ungrouped sample size fails to account for within-cluster
correlation.
 
> Strictly speaking, the choice of which version of n to use should
> probably not be made independently of this issue.  If the count of
> individuals is used with the grouped data likelihood it reduces the
> amount by which the R^2 value is inflated, which is my (admittedly
> weak) reason for the blanket recommendation.

My tentative prescription would be conservative: the ungrouped loss
function (however determined) and the grouped sample size.  It's a
pretty ugly hack, though.

Cheers,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Gregor.Gorjanc at bfro.uni-lj.si  Mon Dec 15 10:36:15 2008
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Mon, 15 Dec 2008 10:36:15 +0100
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
Message-ID: <F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>

> ## Fit the model
> fit9b <- lmer(tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM +(1 | rejec) + (1 | hy) + (1 | hys), data=podatki)
> From your fitting, i wonder what your theoretical model is.
> y=b0+uj+b1*pasma + b2*roj2 + b3*zj2 + b4*spol + b5*reja + b6*jagLM+b7*rejec+b8*hy+b9*hys
> uj represents the random intercept effects for rejec,hy and hys?
> I cannot see how to write your model and explain it.
> It seems that you have fitted three random intercepts in your model (rejec,hy and hys), are they all two-level factor or first-level factor?
> What is your model formula?

I simply have three random effects. The model specification (without indexes) would be

y ~ N(mu, sigma^2_e)

mu = alpha + ... + rejec + hy + hys

rejec ~ N(0 sigma^2_r)

hy ~ N(0 sigma^2_hy)

hys ~ N(0 sigma^2_hys)

gg



From bates at stat.wisc.edu  Mon Dec 15 16:19:03 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 15 Dec 2008 09:19:03 -0600
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
	<F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
Message-ID: <40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>

On Mon, Dec 15, 2008 at 3:36 AM, Gorjanc Gregor
<Gregor.Gorjanc at bfro.uni-lj.si> wrote:
>> ## Fit the model
>> fit9b <- lmer(tezaroj ~ pasma + roj2 + zj2 + spol + reja + jagLM +(1 | rejec) + (1 | hy) + (1 | hys), data=podatki)
>> From your fitting, i wonder what your theoretical model is.
>> y=b0+uj+b1*pasma + b2*roj2 + b3*zj2 + b4*spol + b5*reja + b6*jagLM+b7*rejec+b8*hy+b9*hys
>> uj represents the random intercept effects for rejec,hy and hys?
>> I cannot see how to write your model and explain it.
>> It seems that you have fitted three random intercepts in your model (rejec,hy and hys), are they all two-level factor or first-level factor?

I think you mean "second level factor" not "two-level factor", Zhijie.
 I know it is confusing but "two-level factor" means a factor which
has only two possible values, such as sex which has only two levels -
male and female.  Two-level factorial designs, for example, are
specialized experimental designs where all the experimental factors
are restricted to only two levels.

I believe you are using the terminology of multilevel modeling where
one characterizes factors as being at the first level, the second
level, etc.  One can fit multilevel models using lmer but one can also
fit models that do not fit into the multilevel framework - models with
crossed or partially crossed random effects.  Unfortunately, because
the terminology of multilevel models (also called hierarchical linear
models or HLMs) is so pervasive, many people believe that any model
with random effects must be hierarchical.  That is not true and it
leads to many misconceptions.

Even worse, the emphasis on levels in model specification for software
like MLWin and HLM causes confusion about fixed effects and random
effects.  These is a widespread belief that the level of a variable
affects its use in the fixed-effects specification, which is not true.

Gorjanc is correct in what he writes below.  He has three random
effects terms.  They are what I would call simple, scalar random
effects ("scalar" because there is one random effect associated with
each level of the factors rejec, hy and hys and "simple" because the
term on the left side of the "|" is "1", which means that each term
contributes a set of indicator columns to the model matrix for the
random effects). Whether the factors rejec, hy and hys happen to form
a nested sequence is irrelevant to the model specification and fitting
in lmer.  In the multilevel world it is mandatory.

>> What is your model formula?
>
> I simply have three random effects. The model specification (without indexes) would be
>
> y ~ N(mu, sigma^2_e)
>
> mu = alpha + ... + rejec + hy + hys
>
> rejec ~ N(0 sigma^2_r)
>
> hy ~ N(0 sigma^2_hy)
>
> hys ~ N(0 sigma^2_hys)
>
> gg
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ggrothendieck at gmail.com  Mon Dec 15 17:16:57 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Dec 2008 11:16:57 -0500
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
	<F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
	<40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
Message-ID: <971536df0812150816m358cb99cyd8191687520f86c3@mail.gmail.com>

Note that the fitted method in lme had a level= argument that is no
longer available in lmer presumably because lmer does not assume
a hierarchy -- but do we have or will we have an easy way to get the
same effect as fitted(..., level=) in lmer?

library(nlme)
# example from plot.lme
fm1 <- lme(distance ~ age, Orthodont, random = ~ age | Subject)

fit0 <- fitted(fm1, level = 0)
fit1 <- fitted(fm1, level = 1)

(Maybe this is a bad example since its actually not so hard:
   fitted(lmer(distance ~ age + (age|Subject), Orthodont))
gives level 1 and
  fitted(lm(distance ~ age, Orthodont))
gives level 0 but even here it involved the complexity of using different
approaches to get them whereas with lme one could do it in a
unified manner.)

On Mon, Dec 15, 2008 at 10:19 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I believe you are using the terminology of multilevel modeling where
> one characterizes factors as being at the first level, the second
> level, etc.  One can fit multilevel models using lmer but one can also



From bates at stat.wisc.edu  Mon Dec 15 17:35:45 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 15 Dec 2008 10:35:45 -0600
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <971536df0812150816m358cb99cyd8191687520f86c3@mail.gmail.com>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
	<F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
	<40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
	<971536df0812150816m358cb99cyd8191687520f86c3@mail.gmail.com>
Message-ID: <40e66e0b0812150835w79a8a7a6lcf7f90fdf491b6cb@mail.gmail.com>

On Mon, Dec 15, 2008 at 10:16 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Note that the fitted method in lme had a level= argument that is no
> longer available in lmer presumably because lmer does not assume
> a hierarchy -- but do we have or will we have an easy way to get the
> same effect as fitted(..., level=) in lmer?

One would need to define such a method carefully.  If the factors
defining random effects form a strictly nested sequence then there is
an interpretation of level.  If you do not have a strictly nested
sequence then I can only make sense of having all the random effects
defining fitted values (which is what the method for fitted returns
now) or having none of them.  The second is using the fixed-effects
coefficients only.

> library(nlme)
> # example from plot.lme
> fm1 <- lme(distance ~ age, Orthodont, random = ~ age | Subject)
>
> fit0 <- fitted(fm1, level = 0)
> fit1 <- fitted(fm1, level = 1)
>
> (Maybe this is a bad example since its actually not so hard:
>   fitted(lmer(distance ~ age + (age|Subject), Orthodont))
> gives level 1 and
>  fitted(lm(distance ~ age, Orthodont))
> gives level 0 but even here it involved the complexity of using different
> approaches to get them whereas with lme one could do it in a
> unified manner.)

I don't know if fitted(lm(distance ~ age, Orthodont)) produces the
desired result. Removing the random effects from the prediction is not
always the same as removing the random effects from the fit.  I would
get the fitted values for the fixed effects only using

as.vector(model.matrix(fm1) %*% fixef(fm1))



> On Mon, Dec 15, 2008 at 10:19 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> I believe you are using the terminology of multilevel modeling where
>> one characterizes factors as being at the first level, the second
>> level, etc.  One can fit multilevel models using lmer but one can also
>



From ggrothendieck at gmail.com  Mon Dec 15 17:46:42 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Dec 2008 11:46:42 -0500
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <40e66e0b0812150835w79a8a7a6lcf7f90fdf491b6cb@mail.gmail.com>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
	<F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
	<40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
	<971536df0812150816m358cb99cyd8191687520f86c3@mail.gmail.com>
	<40e66e0b0812150835w79a8a7a6lcf7f90fdf491b6cb@mail.gmail.com>
Message-ID: <971536df0812150846t5d1511b8hcc138a91ff4a8fe1@mail.gmail.com>

On Mon, Dec 15, 2008 at 11:35 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Mon, Dec 15, 2008 at 10:16 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> Note that the fitted method in lme had a level= argument that is no
>> longer available in lmer presumably because lmer does not assume
>> a hierarchy -- but do we have or will we have an easy way to get the
>> same effect as fitted(..., level=) in lmer?
>
> One would need to define such a method carefully.  If the factors
> defining random effects form a strictly nested sequence then there is
> an interpretation of level.  If you do not have a strictly nested
> sequence then I can only make sense of having all the random effects
> defining fitted values (which is what the method for fitted returns
> now) or having none of them.  The second is using the fixed-effects
> coefficients only.
>
>> library(nlme)
>> # example from plot.lme
>> fm1 <- lme(distance ~ age, Orthodont, random = ~ age | Subject)
>>
>> fit0 <- fitted(fm1, level = 0)
>> fit1 <- fitted(fm1, level = 1)
>>
>> (Maybe this is a bad example since its actually not so hard:
>>   fitted(lmer(distance ~ age + (age|Subject), Orthodont))
>> gives level 1 and
>>  fitted(lm(distance ~ age, Orthodont))
>> gives level 0 but even here it involved the complexity of using different
>> approaches to get them whereas with lme one could do it in a
>> unified manner.)
>
> I don't know if fitted(lm(distance ~ age, Orthodont)) produces the

> desired result. Removing the random effects from the prediction is not
> always the same as removing the random effects from the fit.  I would
> get the fitted values for the fixed effects only using
>
> as.vector(model.matrix(fm1) %*% fixef(fm1))
>

They do seem to be the same here:

> all.equal(fitted(fm1, level = 0), fitted(lm(distance ~ age, Orthodont)), check.attributes = FALSE)
[1] TRUE

but your idea is better since it seems more general allowing at least
fixed vs. all effects which in many cases many be sufficient.  Some
easy way of specifying just the fixed effects might be nice as arg to fitted.

By the way, one other annoyance is that one cannot write:

# fixed effects only
lmer(distance ~ age, Orthodont)

which would be nice when comparing models so that one stays in the same
function, lmer, rather than switching from lmer to lm when the model changes
slightly, and so one is sure that the various outputs are in consistent forms.




>
>
>> On Mon, Dec 15, 2008 at 10:19 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> I believe you are using the terminology of multilevel modeling where
>>> one characterizes factors as being at the first level, the second
>>> level, etc.  One can fit multilevel models using lmer but one can also
>>
>



From David.Grimardias at st-pee.inra.fr  Tue Dec 16 17:14:35 2008
From: David.Grimardias at st-pee.inra.fr (David Grimardias)
Date: Tue, 16 Dec 2008 17:14:35 +0100
Subject: [R-sig-ME] Likelihood Ratio tests and fixed effects with LMER
In-Reply-To: <493D1D37.2020506@st-pee.inra.fr>
References: <493D1D37.2020506@st-pee.inra.fr>
Message-ID: <4947D3EB.6080701@st-pee.inra.fr>

Sorry for sending twice, but I didn't receive any answer. If someone 
could help me please,

David
---------------

Hello,

I previously read this : 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001458.html
but I still have some questions about my statistical analysis.

Here is my problem :

We study the effect of habitat structure on the spawning behaviour in 
salmon. So we experimentally observed the behaviour of fish (we 
considered 6 types of behaviours) during the spawning season.

Then I want to analyse if the number of behaviour (for each type) we 
observed 1 hour before the spawn is influenced by 2 factors : the 
structure of habitat (2 experimental levels : homogeneous and 
heterogeneous habitat) and the presence of parr (2 experimental levels: 
0 (absence) or 1 (presence)).

As we have got several spawning events by female (because we can not use 
a lot of females), I have to use mixed models, with female as random 
effect (a female is used only in one type of habitat and in presence OR 
absence of parr, ).

 So for each type of behaviour, I want to know if fixed effects 
(habitat, parr and interaction) are significant or not. As previously 
requested, and answered by Mister Bates 
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001458.html), 
I tried to use Likelihood ratio tests to determine if these two factors 
are significant or not. Here are an example about one type of behaviour 
(Fprob = number of probings by female) :

/> Fprob.lmer.full<-lmer(Fprob ~habitat+parr+habitat: parr 
+(1|female),family=poisson)
 > Fprob.lmer.add<-lmer(Fprob ~habitat+ parr +(1|female),family=poisson)
 > Fprob.lmer.hab<-lmer(Fprob ~habitat+(1|female),family=poisson)
 > Fprob.lmer.parr<-lmer(Fprob ~ parr +(1|female),family=poisson)
 > Fprob.lmer.null<-lmer(Fprob ~1+(1|female),family=poisson)

 > anova(Fprob.lmer.full,Fprob.lmer.add)
Data:
Models:
Fprob.lmer.add: Fprob ~ habitat + parr + (1 | female)
Fprob.lmer.full: Fprob ~ habitat + parr + habitat:parr + (1 | female)
                Df     AIC     BIC  logLik Chisq Chi Df Pr(>Chisq)
Fprob.lmer.add   4  319.71  326.57 -155.86                       
Fprob.lmer.full  5  321.17  329.74 -155.58 0.545      1     0.4604

 > anova(Fprob.lmer.hab,Fprob.lmer.null)
Data:
Models:
Fprob.lmer.null: Fprob ~ 1 + (1 | female)
Fprob.lmer.hab: Fprob ~ habitat + (1 | female)
                Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
Fprob.lmer.null  2  319.11  322.54 -157.55                        
Fprob.lmer.hab   3  320.12  325.26 -157.06 0.9866      1     0.3206

 > anova(Fprob.lmer.parr,Fprob.lmer.null)
Data:
Models:
Fprob.lmer.null: Fprob ~ 1 + (1 | female)
Fprob.lmer.parr: Fprob ~ parr + (1 | female)
                Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
Fprob.lmer.null  2  319.11  322.54 -157.55                        
Fprob.lmer.parr  3  319.07  324.21 -156.54 2.0372      1     0.1535/

So, I considered as LR test for each effect :

Habitat : Chi2 = 0.9866; df = 1; p = 0.3206
Parr : Chi2 = 2.0372; df = 1; p = 0.1535
Interaction Habitat :parr : Chi2 = 0.545; df = 1; p = 0.4604

I first would like to know if I am wrong, or if I correctly analysed my 
data ?

Second, I guess that LMER function is optimizing REML by default (if I 
correctly read the help file), but I had understood that we need to 
optimize ML to compare fixed effects (from  Pinheiro J C & Bates D M, 
"Mixed-effects models in S and S-PLUS"). If right, what do I need to 
change to correctly analyzed my data with Likelihood ratio tests ?

I am finishing my PhD, and I have to finish to correctly analyze 
behavioural data (with Poisson distribution) and genetic data as well 
(binomial data) before publishing.
Thank you for all the help you can bring to me here.

Best regards,

David Grimardias


-- 
-------------------------------------
David GRIMARDIAS
Doctorant
UMR INRA-UPPA ECOBIOP
Quartier Ibarron
64310 SAINT PEe SUR NIVELLE

T?l.: 0559515979
Fax: 0559545152
mail: David.Grimardias at st-pee.inra.fr
http://www.st-pee.inra.fr



From burg4401 at uni-trier.de  Tue Dec 16 22:35:31 2008
From: burg4401 at uni-trier.de (Jan Pablo Burgard)
Date: Tue, 16 Dec 2008 22:35:31 +0100
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
	fitting it
In-Reply-To: <mailman.5430.1229196212.4348.r-sig-mixed-models@r-project.org>
References: <mailman.5430.1229196212.4348.r-sig-mixed-models@r-project.org>
Message-ID: <200812162235.31380.burg4401@uni-trier.de>

I encountered the same Problem and I solved it by inserting the summary into a 
database created by the filehash package.

The nicer solution though (iff the platform is accessible) is to use a 64bit 
Linux with a huge swap. As the summary is only dumped and not much computation 
is done on it it won't cost very much more time. Save it and load it again for 
further computations.

Pablo Burgard



From David.Duffy at qimr.edu.au  Tue Dec 16 23:03:19 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 17 Dec 2008 08:03:19 +1000 (EST)
Subject: [R-sig-ME] Likelihood Ratio tests and fixed effects with LMER
In-Reply-To: <4947D3EB.6080701@st-pee.inra.fr>
References: <493D1D37.2020506@st-pee.inra.fr> <4947D3EB.6080701@st-pee.inra.fr>
Message-ID: <Pine.LNX.4.64.0812170749130.8761@orpheus.qimr.edu.au>

On Tue, 16 Dec 2008, David Grimardias wrote:

>
> So for each type of behaviour, I want to know if fixed effects (habitat, parr 
> and interaction) are significant or not. As previously requested, and 
> answered by Mister Bates 
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001458.html), I 
> tried to use Likelihood ratio tests to determine if these two factors are 
> significant or not. Here are an example about one type of behaviour (Fprob = 
> number of probings by female) :
>
>> Fprob.lmer.full<-lmer(Fprob ~habitat+parr+habitat:parr +(1|female),family=poisson)
>> Fprob.lmer.add<-lmer(Fprob ~habitat+ parr +(1|female),family=poisson)
>> Fprob.lmer.hab<-lmer(Fprob ~habitat+(1|female),family=poisson)
>> Fprob.lmer.parr<-lmer(Fprob ~ parr +(1|female),family=poisson)
>> Fprob.lmer.null<-lmer(Fprob ~1+(1|female),family=poisson)
> So, I considered as LR test for each effect :
>
> Habitat : Chi2 = 0.9866; df = 1; p = 0.3206
> Parr : Chi2 = 2.0372; df = 1; p = 0.1535
> Interaction Habitat :parr : Chi2 = 0.545; df = 1; p = 0.4604
>
> I first would like to know if I am wrong, or if I correctly analysed my data?
>

Yes, though there has been some discussion on this list about the adequacy of
the chi-square approximation for the LRTS in these models.

You should also compare the results to those from simple models ignoring
the fact that females may appear more than once.  They should be broadly
similar.  How large is the variance due to the random effects anyway?


> Second, I guess that LMER function is optimizing REML by default (if I 
> correctly read the help file), but I had understood that we need to optimize 
> ML to compare fixed effects (from  Pinheiro J C & Bates D M, "Mixed-effects 
> models in S and S-PLUS"). If right, what do I need to change to correctly 
> analyzed my data with Likelihood ratio tests ?

REML is not done for GLMMs IIRC.

David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From queirozrafaelmv at yahoo.com.br  Wed Dec 17 01:38:18 2008
From: queirozrafaelmv at yahoo.com.br (Rafael Maia)
Date: Tue, 16 Dec 2008 22:38:18 -0200
Subject: [R-sig-ME] Likelihood Ratio tests and fixed effects with LMER
In-Reply-To: <Pine.LNX.4.64.0812170749130.8761@orpheus.qimr.edu.au>
References: <493D1D37.2020506@st-pee.inra.fr> <4947D3EB.6080701@st-pee.inra.fr>
	<Pine.LNX.4.64.0812170749130.8761@orpheus.qimr.edu.au>
Message-ID: <4FB5BED8-C7CA-49B4-8CA6-647C6155A0A1@yahoo.com.br>

Hello,

I am quite new to all this approach, but since it's somewhat different  
from what I've seen in classes and I have to rely on what I have been  
learning by myself and on lists such as this one, it's easy to get  
confused. Anyway, I have seen in several textbooks which take this  
anova table / LRT approach the opposite "direction" of effect testing:  
starting with the full model, removing terms (interactions first, then  
according to effect size, for example) and comparing to the previous  
one.

So, the example would go something like this:

Fprob.lmer.full x Fprob.lmer.add to test the interaction term
Fprob.lmer.add x Fprob.lmer.parr (just a guess, judging for the AIC  
value) to test for the habitat effect
Fprob.lmer.parr x Fprob.lmer.null to test for the parr effect

Only proceeding to the next step if the LRT is nonsignificant. If  
changes to the model are significant, individual terms which haven't  
been tested yet would be tested by removing them and comparing to that  
model.

In this case, only the habitat effect could have a different p value,  
but I can imagine when you are comparing models with more terms that  
results could differ. I've even seen cases in which terms are  
sequentially removed as long as they are nonsignificant, point in  
which single terms previously removed are "re-added" individually to  
see if there is improvement to the model.

This may even be kind of "off topic" for this list, but since  
considerable discussion has been going on here about hypothesis  
testing and LRT previously, and the question was originally asked  
here, I thought it wouldn't hurt to continue the discussion...

> You should also compare the results to those from simple models  
> ignoring
> the fact that females may appear more than once.  They should be  
> broadly
> similar.  How large is the variance due to the random effects anyway?

There was some discussion here previously about how it wouldn't be  
good to compare likelihoods of GLMM and GLM, because they are  
generated differently or something like that... Could this be done by  
generating a dummy identity variable with no repetitions (simulating  
non-repeating individual identities), using it as a random variable,  
and comparing the models? I don't know what this could do to the  
estimation of parameters and so on...

Many thanks in advance, and sorry for anything!

Abra?os,
Rafael Maia
---
"A little learning is a dangerous thing; drink deep, or taste not the  
Pierian spring." (A. Pope)
Animal Behavior Lab
Dept. of Zoology, Universidade de Brasilia
http://www.unb.br/ib/zoo/rhmacedo/

On 16 Dec 2008, at 20:03, David Duffy wrote:

> On Tue, 16 Dec 2008, David Grimardias wrote:
>
>>
>> So for each type of behaviour, I want to know if fixed effects  
>> (habitat, parr and interaction) are significant or not. As  
>> previously requested, and answered by Mister Bates (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001458.html 
>> ), I tried to use Likelihood ratio tests to determine if these two  
>> factors are significant or not. Here are an example about one type  
>> of behaviour (Fprob = number of probings by female) :
>>
>>> Fprob.lmer.full<-lmer(Fprob ~habitat+parr+habitat:parr +(1| 
>>> female),family=poisson)
>>> Fprob.lmer.add<-lmer(Fprob ~habitat+ parr +(1| 
>>> female),family=poisson)
>>> Fprob.lmer.hab<-lmer(Fprob ~habitat+(1|female),family=poisson)
>>> Fprob.lmer.parr<-lmer(Fprob ~ parr +(1|female),family=poisson)
>>> Fprob.lmer.null<-lmer(Fprob ~1+(1|female),family=poisson)
>> So, I considered as LR test for each effect :
>>
>> Habitat : Chi2 = 0.9866; df = 1; p = 0.3206
>> Parr : Chi2 = 2.0372; df = 1; p = 0.1535
>> Interaction Habitat :parr : Chi2 = 0.545; df = 1; p = 0.4604
>>
>> I first would like to know if I am wrong, or if I correctly  
>> analysed my data?
>>
>
> Yes, though there has been some discussion on this list about the  
> adequacy of
> the chi-square approximation for the LRTS in these models.
>
> You should also compare the results to those from simple models  
> ignoring
> the fact that females may appear more than once.  They should be  
> broadly
> similar.  How large is the variance due to the random effects anyway?
>
>
>> Second, I guess that LMER function is optimizing REML by default  
>> (if I correctly read the help file), but I had understood that we  
>> need to optimize ML to compare fixed effects (from  Pinheiro J C &  
>> Bates D M, "Mixed-effects models in S and S-PLUS"). If right, what  
>> do I need to change to correctly analyzed my data with Likelihood  
>> ratio tests ?
>
> REML is not done for GLMMs IIRC.
>
> David Duffy.
>
> -- 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax:  
> -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research    
> \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From epistat at gmail.com  Wed Dec 17 04:10:57 2008
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 17 Dec 2008 11:10:57 +0800
Subject: [R-sig-ME] Summarizing the fitted model takes more RAM than
In-Reply-To: <40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
References: <2fc17e30812131758w2354ac2bjb178bc72f111ba4e@mail.gmail.com>
	<F189E18BBAA8B6479F618B9044CF4E9C68D7BCC563@REGULUS.bfro.uni-lj.si>
	<40e66e0b0812150719w1a344f31i79f56719628df0fb@mail.gmail.com>
Message-ID: <2fc17e30812161910j6e50673ax69bb51446fb9dd47@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081217/10c2359c/attachment.pl>

From David.Duffy at qimr.edu.au  Wed Dec 17 04:24:45 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 17 Dec 2008 13:24:45 +1000 (EST)
Subject: [R-sig-ME] Likelihood Ratio tests and fixed effects with LMER
In-Reply-To: <4FB5BED8-C7CA-49B4-8CA6-647C6155A0A1@yahoo.com.br>
References: <493D1D37.2020506@st-pee.inra.fr> <4947D3EB.6080701@st-pee.inra.fr>
	<Pine.LNX.4.64.0812170749130.8761@orpheus.qimr.edu.au>
	<4FB5BED8-C7CA-49B4-8CA6-647C6155A0A1@yahoo.com.br>
Message-ID: <Pine.LNX.4.64.0812171259350.19063@orpheus.qimr.edu.au>

On Tue, 16 Dec 2008, Rafael Maia wrote:

> Hello,
>
> I am quite new to all this approach, but since it's somewhat different from 
> what I've seen in classes and I have to rely on what I have been learning by 
> myself and on lists such as this one, it's easy to get confused. Anyway, I 
> have seen in several textbooks which take this anova table / LRT approach the 
> opposite "direction" of effect testing: starting with the full model, 
> removing terms (interactions first, then according to effect size, for 
> example) and comparing to the previous one.
>
> This may even be kind of "off topic" for this list, but since considerable 
> discussion has been going on here about hypothesis testing and LRT 
> previously, and the question was originally asked here, I thought it wouldn't 
> hurt to continue the discussion...

It's a generic model building question.  If you have large numbers of 
variables, fitting the all K-way interactions model as a base model can be 
expensive, so people try to build upwards from simpler models.  I quite 
like the idea of Bayesian Model Averaging...

>
> There was some discussion here previously about how it wouldn't be good to 
> compare likelihoods of GLMM and GLM, because they are generated differently 
> or something like that...

That was just whether particular constants are included or excluded in the 
likelihood expressions used in the different codes.  My comment was 
to the effect that the parameter estimates and LRTs from simple fixed 
effects models are a reality check for the results coming from the GLMMs, 
especially if you are worried that something isn't working properly.

David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From danielezrajohnson at gmail.com  Wed Dec 17 14:07:39 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 17 Dec 2008 13:07:39 +0000
Subject: [R-sig-ME] logLik
Message-ID: <a46630750812170507y2cde9202m1f6f5ce59b7b9325@mail.gmail.com>

Hi,

This is from the help file for logLik():

> x <- 1:5
> lmx <- lm(x ~ 1)
> logLik(lmx)

log Lik.' -8.82756 (df=2)

Two questions:
1) doesn't the model lmx have one degree of freedom, not two?
2) how is this log-likelihood calculated?

If I have two nested linear models (say lm models, not worrying about
mixed models here), I know how to compare them using an F-test, but I
don't understand the difference (if there is one) between using an
F-test and using a likelihood-ratio test.

Thanks,
Dan



From bolker at ufl.edu  Wed Dec 17 15:13:31 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 17 Dec 2008 09:13:31 -0500
Subject: [R-sig-ME] logLik
Message-ID: <4949090B.5030107@ufl.edu>


  (previous post bounced due to GPG wrapper)

Daniel Ezra Johnson wrote:
> Hi,
> 
> This is from the help file for logLik():
> 
>> x <- 1:5
>> lmx <- lm(x ~ 1)
>> logLik(lmx)
> 
> log Lik.' -8.82756 (df=2)
> 
> Two questions:
> 1) doesn't the model lmx have one degree of freedom, not two?

  If you count the implicit variance, it has two.

> 2) how is this log-likelihood calculated?

see stats:::logLik.lm : the core is

  val <- 0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) +
        log(sum(w * res^2))))

where res are residuals, w are weights, N is the number of points

> 
> If I have two nested linear models (say lm models, not worrying about
> mixed models here), I know how to compare them using an F-test, but I
> don't understand the difference (if there is one) between using an
> F-test and using a likelihood-ratio test.

  The likelihood ratio test is asymptotic, so you should use an F test
if you're in a situation where it's appropriate.

x <- rnorm(100)
 > y <- 1+2*x+rnorm(100,sd=1)
> lm2 <- lm(y~x)
> lm1 <- lm(y~1)
> anova(lm2,lm1)
Analysis of Variance Table

Model 1: y ~ x
Model 2: y ~ 1
  Res.Df     RSS Df Sum of Sq      F    Pr(>F)
1     98   94.16
2     99  492.44 -1   -398.29 414.54 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


  str() shows that the actual p-value is 5.54e-37


> pchisq(2*(logLik(lm2)-logLik(lm1)),1,lower.tail=FALSE)
[1] 7.325424e-38
attr(,"nall")
[1] 100
attr(,"nobs")
[1] 100
attr(,"df")
[1] 3
attr(,"class")
[1] "logLik"





-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From danielezrajohnson at gmail.com  Wed Dec 17 20:11:46 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 17 Dec 2008 19:11:46 +0000
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <40e66e0b0811270739k7a29b000kb7b3c0041f0ddd31@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
	<DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>
	<40e66e0b0811270739k7a29b000kb7b3c0041f0ddd31@mail.gmail.com>
Message-ID: <a46630750812171111w6647c150j17c551a143572be2@mail.gmail.com>

Hello,

Sorry if the solution to this was already posted...

I'm getting this error:

> library(lme4)
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  function 'cholmod_start' not provided by package 'Matrix'
Error: package/namespace load failed for 'lme4'

trying to install lme4 version 0.999375-27 on top of Matrix
0.999375-17 (both from CRAN, not using R-Forge).

This is with R for Mac OS X 2.8.0.

Any suggestions would be appreciated.

Thanks,
Daniel

On Thu, Nov 27, 2008 at 3:39 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Is anyone else encountering this problem?  It looks like Mac OS X and
> apparently a problem with the Matrix package declarations.  It is a
> trivial-enough problem, a declaration of an argument as "const char*"
> in one case and "char*" in another but I don't know which installed
> version of the Matrix package this occurs in.
>
> On Thu, Nov 27, 2008 at 8:11 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>>
>>>> The issue is a bit more subtle than that.  You need to reinstall the
>>>> lme4 package after changing the version of the Matrix package.
>>>> There is a change in the internal code in the Matrix package between
>>>> -16 and -17.  The -16 version requires two versions of every function
>>>> in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
>>>> back to only one version.  However, lme4 must be reinstalled (in
>>>> particular, the C code must be recompiled) after a change in the
>>>> Matrix package.
>>
>> On 28 Oct 2008, at 10:12, ONKELINX, Thierry wrote:
>>>
>>> Dear Douglas,
>>>
>>> Reinstalling lme4 from R-forge after removing it from the harddisk
>>> worked.
>>>
>>> Thank you,
>>>
>>> Thierry
>>>
>>>
>>
>>
>> I have come up against the same issue as Thierry, but Prof Bates' solution
>> does not work for me. The problem seems to be at:
>>
>> Matrix_stubs.c:494: error: conflicting types for 'M_R_cholmod_error'
>> cholmod.h:798: error: previous declaration of 'M_R_cholmod_error' was here
>>
>> I have tried removing both lme4 and Matrix in a different order and by
>> various means (deleting the folder in library vs remove.packages()). Most
>> recently, I removed both lme4 and Matrix, emptied the trash then reinstalled
>> Matrix from r-forge before quitting R and restarting my machine. On
>> restarting R I tried:
>>
>>>
>>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>>
>> A full transcript of the session is attached.
>>
>> The attached is a full session history from the most recent attempt. I would
>> be grateful for any suggestions.
>> Best wishes, Nick
>>
>>
>>
>>
>>
>>
>>
>>> sessionInfo()
>> R version 2.8.0 (2008-10-20)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] Matrix_0.999375-17 lattice_0.17-15
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.8.0  tools_2.8.0
>>
>>>
>>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>>
>>>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at fuller.edu  Wed Dec 17 21:11:20 2008
From: datkins at fuller.edu (Dave Atkins)
Date: Wed, 17 Dec 2008 12:11:20 -0800
Subject: [R-sig-ME]  Something broken in lme4 after update?
Message-ID: <49495CE8.90808@fuller.edu>


Daniel--

This has to do with Macs and is a known issue (and currently not fixed 
as far as I can see).  See the recent exchange on the R MAC listserv:

https://stat.ethz.ch/pipermail/r-sig-mac/2008-December/date.html

cheers, Dave



From bates at stat.wisc.edu  Thu Dec 18 00:49:20 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 17 Dec 2008 17:49:20 -0600
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <a46630750812171111w6647c150j17c551a143572be2@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
	<DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>
	<40e66e0b0811270739k7a29b000kb7b3c0041f0ddd31@mail.gmail.com>
	<a46630750812171111w6647c150j17c551a143572be2@mail.gmail.com>
Message-ID: <40e66e0b0812171549h2af96acbo6f398b4c4df6ae97@mail.gmail.com>

The lme4 package has to be recompiled after the Matrix package was
updated.  Martin recently released a new version of lme4, 0.999375-29,
which depends on the version 0.999375-17 of the Matrix package.

On Wed, Dec 17, 2008 at 1:11 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> Hello,
>
> Sorry if the solution to this was already posted...
>
> I'm getting this error:
>
>> library(lme4)
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  function 'cholmod_start' not provided by package 'Matrix'
> Error: package/namespace load failed for 'lme4'
>
> trying to install lme4 version 0.999375-27 on top of Matrix
> 0.999375-17 (both from CRAN, not using R-Forge).
>
> This is with R for Mac OS X 2.8.0.
>
> Any suggestions would be appreciated.
>
> Thanks,
> Daniel
>
> On Thu, Nov 27, 2008 at 3:39 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> Is anyone else encountering this problem?  It looks like Mac OS X and
>> apparently a problem with the Matrix package declarations.  It is a
>> trivial-enough problem, a declaration of an argument as "const char*"
>> in one case and "char*" in another but I don't know which installed
>> version of the Matrix package this occurs in.
>>
>> On Thu, Nov 27, 2008 at 8:11 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>>>
>>>>> The issue is a bit more subtle than that.  You need to reinstall the
>>>>> lme4 package after changing the version of the Matrix package.
>>>>> There is a change in the internal code in the Matrix package between
>>>>> -16 and -17.  The -16 version requires two versions of every function
>>>>> in the CHOLMOD, AMD and COLAMD libraries whereas the -17 version is
>>>>> back to only one version.  However, lme4 must be reinstalled (in
>>>>> particular, the C code must be recompiled) after a change in the
>>>>> Matrix package.
>>>
>>> On 28 Oct 2008, at 10:12, ONKELINX, Thierry wrote:
>>>>
>>>> Dear Douglas,
>>>>
>>>> Reinstalling lme4 from R-forge after removing it from the harddisk
>>>> worked.
>>>>
>>>> Thank you,
>>>>
>>>> Thierry
>>>>
>>>>
>>>
>>>
>>> I have come up against the same issue as Thierry, but Prof Bates' solution
>>> does not work for me. The problem seems to be at:
>>>
>>> Matrix_stubs.c:494: error: conflicting types for 'M_R_cholmod_error'
>>> cholmod.h:798: error: previous declaration of 'M_R_cholmod_error' was here
>>>
>>> I have tried removing both lme4 and Matrix in a different order and by
>>> various means (deleting the folder in library vs remove.packages()). Most
>>> recently, I removed both lme4 and Matrix, emptied the trash then reinstalled
>>> Matrix from r-forge before quitting R and restarting my machine. On
>>> restarting R I tried:
>>>
>>>>
>>>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>>>
>>> A full transcript of the session is attached.
>>>
>>> The attached is a full session history from the most recent attempt. I would
>>> be grateful for any suggestions.
>>> Best wishes, Nick
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>> sessionInfo()
>>> R version 2.8.0 (2008-10-20)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] Matrix_0.999375-17 lattice_0.17-15
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.8.0  tools_2.8.0
>>>
>>>>
>>>> install.packages("lme4",type="source",repos="http://r-forge.r-project.org")
>>>
>>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From a.renwick at abdn.ac.uk  Thu Dec 18 12:23:46 2008
From: a.renwick at abdn.ac.uk (Renwick, A. R.)
Date: Thu, 18 Dec 2008 11:23:46 +0000
Subject: [R-sig-ME] heteroscedastic model in lme4
Message-ID: <B9D1301370916C44B5874AF340C18B9B28AE890D50@VMAILB.uoa.abdn.ac.uk>

I have been using the nlme package to run some LMM's, however I would like to try rerunning them using the lme4 package so that I can use mcmc sampling.  The data I am using shows some heteroscesdasticity of the within error group and so I have been using the 'weights' argument and the varIdent variance function structure to allow different variances for each level of my factor (patch width).

My problem is how to code for a heteroscedastic model in lme4 and any suggestion wouuld be much apprecaited.

The code I used in the nlme package:

# model fit using "REML"
mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess + crop + VegDensity + Group:sess + Group:VegDensity ,random=~1|Site, data=all,
       method="REML",correlation=NULL,weights=varIdent(form=~1|width))


Many thanks,
Anna

Anna Renwick
Institute of Biological & Environment Sciences
University of Aberdeen
Zoology Building
Tillydrone Avenue
Aberdeen
AB24 2TZ


The University of Aberdeen is a charity registered in Scotland, No SC013683.



From Stephani.Zador at noaa.gov  Thu Dec 18 21:59:31 2008
From: Stephani.Zador at noaa.gov (Stephani.Zador at noaa.gov)
Date: Thu, 18 Dec 2008 12:59:31 -0800
Subject: [R-sig-ME] Error implementing Gamma glmm with glmer
Message-ID: <77bded0d7b8ab46c.494a4933@noaa.gov>

Dear all,
I am testing the influence of bottom depth and temperature on the fish catch rates (cpue). This is a 26 year time series of zero-inflated data. Therefore, I first test the presence/absence of the fish:
m1<-glmer(presence~btemp+bdepth+(1|year),data=clus1cpuebt, family=binomial, nAGQ=10)

Then, I test the non-zero catch rates, which fit the assumptions of being either lognormal or gamma-distributed:
m2<-glmer(log(cpue)~btemp+bdepth+(1|year), data=clus1subset, family=gaussian, REML=F)
m3<-glmer(cpue~btemp+bdepth+(1|year), data=clus1subset, family=Gamma(link="log"))

However, I get the error message for m3: Error in asMethod(object) : matrix is not symmetric [1,2]
Could someone please explain this error to me and how to resolve it? Further information is below:

A similar glm without the random effect is successful. 
> gmmodel4<-glm(cpue~bdepth+btemp,data=clus1subset,family=Gamma(link="log"))
> summary(gmmodel4)

Call:
glm(formula = cpue ~ bdepth + btemp, family = Gamma(link = "log"), 
    data = clus1subset)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.3772  -0.8814  -0.3467   0.2165   5.8240  

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1.223159   0.223077   5.483 4.93e-08 ***
bdepth      0.006368   0.001638   3.887 0.000106 ***
btemp       0.343002   0.041323   8.301 2.37e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

(Dispersion parameter for Gamma family taken to be 1.534698)

    Null deviance: 1636.3  on 1434  degrees of freedom
Residual deviance: 1517.3  on 1432  degrees of freedom
AIC: 11950

Number of Fisher Scoring iterations: 8

The lognormal mixed model is also successful.
> m2<-glmer(log(cpue)~bdepth+btemp+(1|year),data=clus1subset,family=gaussian,REML=F)
> print(m2,digits=4)
Linear mixed model fit by maximum likelihood 
Formula: log(cpue) ~ bdepth + btemp + (1 | year) 
   Data: clus1subset 
  AIC  BIC logLik deviance REMLdev
 4122 4148  -2056     4112    4130
Random effects:
 Groups   Name        Variance Std.Dev.
 year     (Intercept) 0.37487  0.61227 
 Residual             0.97176  0.98578 
Number of obs: 1435, groups: year, 26

Fixed effects:
             Estimate Std. Error t value
(Intercept) -1.201085   0.220070  -5.458
bdepth       0.016921   0.001313  12.885
btemp        0.533073   0.037783  14.109

Correlation of Fixed Effects:
       (Intr) bdepth
bdepth -0.595       
btemp  -0.454 -0.191

> sessionInfo()
R version 2.8.0 (2008-10-20) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-28   Matrix_0.999375-17 lattice_0.17-17   

loaded via a namespace (and not attached):
[1] grid_2.8.0  tools_2.8.0

Many thanks,
Stephani Zador, PhD
Research Associate 
Alaska Fisheries Science Center



From byjung at gmail.com  Thu Dec 18 23:45:32 2008
From: byjung at gmail.com (Byju Govindan)
Date: Thu, 18 Dec 2008 17:45:32 -0500
Subject: [R-sig-ME] Something broken in lme4 after update?
In-Reply-To: <40e66e0b0812171549h2af96acbo6f398b4c4df6ae97@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A10405AB4E1C@inboexch.inbo.be>
	<2E9C414912813E4EB981326983E0A10405AB4FB8@inboexch.inbo.be>
	<40e66e0b0810270909u5f050c95sbf977470ae88926e@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10405AB509F@inboexch.inbo.be>
	<DDE4849F-6CE6-4CDE-AD80-DBCBA5D9E011@googlemail.com>
	<40e66e0b0811270739k7a29b000kb7b3c0041f0ddd31@mail.gmail.com>
	<a46630750812171111w6647c150j17c551a143572be2@mail.gmail.com>
	<40e66e0b0812171549h2af96acbo6f398b4c4df6ae97@mail.gmail.com>
Message-ID: <49d3454c0812181445w1b19ee80l8f72fb26a7aef0e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081218/804ec06d/attachment.pl>

From bz73 at cornell.edu  Fri Dec 19 18:06:32 2008
From: bz73 at cornell.edu (Ben Zuckerberg)
Date: Fri, 19 Dec 2008 12:06:32 -0500
Subject: [R-sig-ME] Problem updating to newer version of lme4
Message-ID: <494BD498.1070109@cornell.edu>

I just updated to the new lme4 (v28), but now it will not load the 
library and I get the following message:

Error in inDL(x, as.logical(local), as.logical(now), ...) :
  function 'cholmod_l_start' not provided by package 'Matrix'
In addition: Warning message:
package 'lme4' was built under R version 2.7.2
Error: package/namespace load failed for 'lme4'

-- 
Benjamin Zuckerberg, Ph.D.
Post-doctoral Associate
Spatial Ecologist, Citizen Science
Cornell Laboratory of Ornithology
159 Sapsucker Woods Road
Ithaca, NY 14850 
Tele: 607-254-2174
Fax: 607-254-2111



From alanc at umit.maine.edu  Fri Dec 19 17:19:38 2008
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Fri, 19 Dec 2008 11:19:38 -0500
Subject: [R-sig-ME] heteroscedastic model in lme4
In-Reply-To: <mailman.5.1229684401.6913.r-sig-mixed-models@r-project.org>
References: <mailman.5.1229684401.6913.r-sig-mixed-models@r-project.org>
Message-ID: <fc.004c4d193ab9516e3b9aca00882f2171.3ab97563@umit.maine.edu>


Anna,

lme4 cannot handle certain kinds of heteroscedasticity, but I believe it can handle the kind you have in mind. Search the r-sig-mixed-models archive for a discussion involving me and David Afshartous, especially the summary message titled
"[R-sig-ME] random effect variance per treatment group in lmer" that David posted 07/13/2007 04:18:08 PM

I can't be certain that the suggestion below would work without knowing more about your design, but if width were a factor with three levels then you might try setting up indicator variables Wind1, Wind2, and Wind3 (that each take on the value 1
when a site is at the indicator's target width and 0 otherwise) and then fit the model with something like
mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess + crop + VegDensity + Group:sess + Group:VegDensity + (0+Wind1|site) + (0+Wind2|site) + (0+Wind3|site), data=all, method="REML" )

alan


r-sig-mixed-models at r-project.org on Friday, December 19, 2008 at 6:00 AM -0500 wrote:
>Message: 1
>Date: Thu, 18 Dec 2008 11:23:46 +0000
>From: "Renwick, A. R." <a.renwick at abdn.ac.uk>
>Subject: [R-sig-ME] heteroscedastic model in lme4
>To: "'r-sig-mixed-models at r-project.org'"
>	<r-sig-mixed-models at r-project.org>
>Message-ID:
>	<B9D1301370916C44B5874AF340C18B9B28AE890D50 at VMAILB.uoa.abdn.ac.uk>
>Content-Type: text/plain; charset="us-ascii"
>
>I have been using the nlme package to run some LMM's, however I would like to try rerunning them using the lme4 package so that I can use mcmc sampling.  The data I am using shows some heteroscesdasticity of the within error group and so I have
>been using the 'weights' argument and the varIdent variance function structure to allow different variances for each level of my factor (patch width).
>
>My problem is how to code for a heteroscedastic model in lme4 and any suggestion wouuld be much apprecaited.
>
>The code I used in the nlme package:
>
># model fit using "REML"
>mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess + crop + VegDensity + Group:sess + Group:VegDensity ,random=~1|Site, data=all,
>       method="REML",correlation=NULL,weights=varIdent(form=~1|width))
>
>
>Many thanks,
>Anna
>
>Anna Renwick
>Institute of Biological & Environment Sciences
>University of Aberdeen
>Zoology Building
>Tillydrone Avenue
>Aberdeen
>AB24 2TZ
>
>
>The University of Aberdeen is a charity registered in Scotland, No SC013683.


--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From d.rizopoulos at erasmusmc.nl  Fri Dec 19 18:31:09 2008
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Fri, 19 Dec 2008 18:31:09 +0100
Subject: [R-sig-ME] heteroscedastic model in lme4
In-Reply-To: <fc.004c4d193ab9516e3b9aca00882f2171.3ab97563@umit.maine.edu>
References: <mailman.5.1229684401.6913.r-sig-mixed-models@r-project.org>
	<fc.004c4d193ab9516e3b9aca00882f2171.3ab97563@umit.maine.edu>
Message-ID: <494BDA5D.3030808@erasmusmc.nl>

I think not, because Anna wanted to model the variance of the within 
measurement error terms not the variance of the random effects.

As far as I know, the design philosophy of lme4 is to allow for flexible 
specifications of the random effects part of the mixed model that is 
assumed to account for the main part of variability in the data.

Best,
Dimitris


Alan Cobo-Lewis wrote:
> Anna,
> 
> lme4 cannot handle certain kinds of heteroscedasticity, but I believe it can handle the kind you have in mind. Search the r-sig-mixed-models archive for a discussion involving me and David Afshartous, especially the summary message titled
> "[R-sig-ME] random effect variance per treatment group in lmer" that David posted 07/13/2007 04:18:08 PM
> 
> I can't be certain that the suggestion below would work without knowing more about your design, but if width were a factor with three levels then you might try setting up indicator variables Wind1, Wind2, and Wind3 (that each take on the value 1
> when a site is at the indicator's target width and 0 otherwise) and then fit the model with something like
> mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess + crop + VegDensity + Group:sess + Group:VegDensity + (0+Wind1|site) + (0+Wind2|site) + (0+Wind3|site), data=all, method="REML" )
> 
> alan
> 
> 
> r-sig-mixed-models at r-project.org on Friday, December 19, 2008 at 6:00 AM -0500 wrote:
>> Message: 1
>> Date: Thu, 18 Dec 2008 11:23:46 +0000
>> From: "Renwick, A. R." <a.renwick at abdn.ac.uk>
>> Subject: [R-sig-ME] heteroscedastic model in lme4
>> To: "'r-sig-mixed-models at r-project.org'"
>> 	<r-sig-mixed-models at r-project.org>
>> Message-ID:
>> 	<B9D1301370916C44B5874AF340C18B9B28AE890D50 at VMAILB.uoa.abdn.ac.uk>
>> Content-Type: text/plain; charset="us-ascii"
>>
>> I have been using the nlme package to run some LMM's, however I would like to try rerunning them using the lme4 package so that I can use mcmc sampling.  The data I am using shows some heteroscesdasticity of the within error group and so I have
>> been using the 'weights' argument and the varIdent variance function structure to allow different variances for each level of my factor (patch width).
>>
>> My problem is how to code for a heteroscedastic model in lme4 and any suggestion wouuld be much apprecaited.
>>
>> The code I used in the nlme package:
>>
>> # model fit using "REML"
>> mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess + crop + VegDensity + Group:sess + Group:VegDensity ,random=~1|Site, data=all,
>>       method="REML",correlation=NULL,weights=varIdent(form=~1|width))
>>
>>
>> Many thanks,
>> Anna
>>
>> Anna Renwick
>> Institute of Biological & Environment Sciences
>> University of Aberdeen
>> Zoology Building
>> Tillydrone Avenue
>> Aberdeen
>> AB24 2TZ
>>
>>
>> The University of Aberdeen is a charity registered in Scotland, No SC013683.
> 
> 
> --
> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> Department of Psychology		(207) 581-6128 fax
> University of Maine
> Orono, ME 04469-5742     		alanc at maine.edu
> 
> http://www.umaine.edu/visualperception
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014



From lucianolasala at yahoo.com.ar  Fri Dec 19 20:28:44 2008
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Fri, 19 Dec 2008 11:28:44 -0800 (PST)
Subject: [R-sig-ME] naive questions about model building and error output
Message-ID: <447014.18802.qm@web59906.mail.ac4.yahoo.com>

Dear R-experts,
Quite new to R on this end, so I hope toy can help me out here: 
    
I am running version 2.7.1 on Windows Vista. I have small dataset which consists of: 
    
# NestID: nest indicator for each chicken. Siblings sharing the same nest have the same nest indicator. 
    
# Chick: chick indicator consisting of a unique ID for each single chick. 
    
# Year: 1, 2.
    
# ClutchSize: 1-, 2- , 3-eggs.  
    
# HO: hatching order within each clutch (1, 2, 3 [first, second and third-hatched chick]).
    
# SibComp: sibling competence: present/ absent (0, 1)
    
# Death10: death at ten days post-hatch (0, 1)
    
In order to account for lack of independence at the nest level (many
chicks are nested in nest... aha!), I'd like to run a GLMM with random slopes and intercepts for nests.
    
Using lmer, my model for survival at 10 days, for example, would read (or not!) as follows: 
    
model1 <- lmer(Death10 ~ HO + ClutchSize + Sibcomp + Year + (HO+0|NestID) + (1|NestID), family=binomial, 1)    
      
summary(model)

The output give me the following error: 

Error en mer_finalize(ans, verbose) : q = 416 > n = 198 

1. Whay does this error mean? I was told that my model fails to converge. 

2. If so, is there any solution to a lack of convergence?

3. Maybe I could use a model with only random intercept (See below)?

model2 <-lmer(Death10 ~ HO + ClutchSize + Sibcomp + Year + (1|NestID), family=binomial, 1)

I look forward to receiving your two cent?s worth. 

Best, Luciano   



      ____________________________________________________________________________________
?Busc? desde tu celular!

Yahoo! oneSEARCH ahora est? en Claro

http://ar.mobile.yahoo.com/onesearch



From HDoran at air.org  Fri Dec 19 20:52:14 2008
From: HDoran at air.org (Doran, Harold)
Date: Fri, 19 Dec 2008 14:52:14 -0500
Subject: [R-sig-ME] heteroscedastic model in lme4
References: <mailman.5.1229684401.6913.r-sig-mixed-models@r-project.org>
	<fc.004c4d193ab9516e3b9aca00882f2171.3ab97563@umit.maine.edu>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01C649D9@DC1EXCL01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081219/dbe73984/attachment.pl>

From maechler at stat.math.ethz.ch  Sat Dec 20 14:07:44 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Dec 2008 14:07:44 +0100
Subject: [R-sig-ME] Problem updating to newer version of lme4
In-Reply-To: <494BD498.1070109@cornell.edu>
References: <494BD498.1070109@cornell.edu>
Message-ID: <18764.60960.98307.456061@cmath-5.math.ethz.ch>

>>>>> "BZ" == Ben Zuckerberg <bz73 at cornell.edu>
>>>>>     on Fri, 19 Dec 2008 12:06:32 -0500 writes:

    BZ> I just updated to the new lme4 (v28), but now it will
    BZ> not load the library and I get the following message:

    BZ> Error in inDL(x, as.logical(local), as.logical(now),
    BZ> ...) : function 'cholmod_l_start' not provided by
    BZ> package 'Matrix' 

uh oh,... I think that means that your version of Matrix is 
outdated as well (or even more).

Have you tried  update.packages()
which should automatically update your version of Matrix, too?

Regards,
Martin

    BZ> In addition: Warning message: package 'lme4' was built under R version 2.7.2 Error:
    BZ> package/namespace load failed for 'lme4'



From s.ruiter at maw.ru.nl  Sun Dec 21 00:16:14 2008
From: s.ruiter at maw.ru.nl (Stijn Ruiter)
Date: Sun, 21 Dec 2008 00:16:14 +0100
Subject: [R-sig-ME] logistic model with exponential decay
Message-ID: <494D7CBE.5010801@maw.ru.nl>

Dear list,
In SAS I am using NLMIXED to estimate a logistic model that includes 
exponential decay. Since NLMIXED only allows for a single random 
statement, I would like to switch to R. Could anyone suggest how to 
estimate such a model? I cannot find a clear example for estimating 
these kinds of models with nlmer.
I'd like to estimate a logistic model for my dichotomous dependent 
variable that includes both linear terms and EXP(-Time/Beta).
Thanks,
Stijn

-- 
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter



From bolker at ufl.edu  Sun Dec 21 01:01:24 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 20 Dec 2008 19:01:24 -0500
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494D7CBE.5010801@maw.ru.nl>
References: <494D7CBE.5010801@maw.ru.nl>
Message-ID: <494D8754.6090006@ufl.edu>

Stijn Ruiter wrote:
> Dear list,
> In SAS I am using NLMIXED to estimate a logistic model that includes
> exponential decay. Since NLMIXED only allows for a single random
> statement, I would like to switch to R. Could anyone suggest how to
> estimate such a model? I cannot find a clear example for estimating
> these kinds of models with nlmer.
> I'd like to estimate a logistic model for my dichotomous dependent
> variable that includes both linear terms and EXP(-Time/Beta).
> Thanks,
> Stijn
> 

  it sounds like

lmer(...,family=binomial(link="log"))

 -- i.e., a GLMM rather than a NLMM

  Ben Bolker

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From laf.nilsson at gmail.com  Sun Dec 21 10:11:33 2008
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Sun, 21 Dec 2008 10:11:33 +0100
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494D8754.6090006@ufl.edu>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
Message-ID: <145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>

Dear Ben,

Does it? I interpret Stijn's model as:
logit(y) ~ alpha + beta*x + exp(-T/beta) + possibly multiple error
terms (sample within muscle within toad or some non-nested terms)

which I would find difficult to squeeze into the glmm framework.

Best regards,
Fredrik Nilsson

------------------------
Competence Centre for Clinical Research,
Lund University Hospital, 221 85 Lund, Sweden

2008/12/21 Ben Bolker <bolker at ufl.edu>:
> Stijn Ruiter wrote:
>> Dear list,
>> In SAS I am using NLMIXED to estimate a logistic model that includes
>> exponential decay. Since NLMIXED only allows for a single random
>> statement, I would like to switch to R. Could anyone suggest how to
>> estimate such a model? I cannot find a clear example for estimating
>> these kinds of models with nlmer.
>> I'd like to estimate a logistic model for my dichotomous dependent
>> variable that includes both linear terms and EXP(-Time/Beta).
>> Thanks,
>> Stijn
>>
>
>  it sounds like
>
> lmer(...,family=binomial(link="log"))
>
>  -- i.e., a GLMM rather than a NLMM
>
>  Ben Bolker
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lamprianou at yahoo.com  Sun Dec 21 10:55:40 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 21 Dec 2008 01:55:40 -0800 (PST)
Subject: [R-sig-ME] lmer stand dev of coefficients
In-Reply-To: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
Message-ID: <918579.78707.qm@web54104.mail.re2.yahoo.com>

Dear friends
when I use sd(coef(mymodel)$myvariable) I get 0.21
However, the summary of the model gives
Error terms:
 Groups      Name        Std.Dev.
 myvariable (Intercept) 0.33    
 Residual               0.76  

Why dont I get the same value (0.21 instead of 0.33)?
Thanks for the help.


Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Sat, 20/12/08, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 24, Issue 28
> To: r-sig-mixed-models at r-project.org
> Date: Saturday, 20 December, 2008, 11:00 AM
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body
> 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models
> digest..."
> 
> 
> Today's Topics:
> 
>    1. Problem updating to newer version of lme4 (Ben
> Zuckerberg)
>    2. Re: heteroscedastic model in lme4 (Alan Cobo-Lewis)
>    3. Re: heteroscedastic model in lme4 (Dimitris
> Rizopoulos)
>    4. naive questions about model building and error output
>       (Luciano La Sala)
>    5. Re: heteroscedastic model in lme4 (Doran, Harold)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Fri, 19 Dec 2008 12:06:32 -0500
> From: Ben Zuckerberg <bz73 at cornell.edu>
> Subject: [R-sig-ME] Problem updating to newer version of
> lme4
> To: r-sig-mixed-models at r-project.org
> Message-ID: <494BD498.1070109 at cornell.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> I just updated to the new lme4 (v28), but now it will not
> load the 
> library and I get the following message:
> 
> Error in inDL(x, as.logical(local), as.logical(now), ...) :
>   function 'cholmod_l_start' not provided by
> package 'Matrix'
> In addition: Warning message:
> package 'lme4' was built under R version 2.7.2
> Error: package/namespace load failed for 'lme4'
> 
> -- 
> Benjamin Zuckerberg, Ph.D.
> Post-doctoral Associate
> Spatial Ecologist, Citizen Science
> Cornell Laboratory of Ornithology
> 159 Sapsucker Woods Road
> Ithaca, NY 14850 
> Tele: 607-254-2174
> Fax: 607-254-2111
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Fri, 19 Dec 2008 11:19:38 -0500
> From: "Alan Cobo-Lewis"
> <alanc at umit.maine.edu>
> Subject: Re: [R-sig-ME] heteroscedastic model in lme4
> To: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<fc.004c4d193ab9516e3b9aca00882f2171.3ab97563 at umit.maine.edu>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> 
> Anna,
> 
> lme4 cannot handle certain kinds of heteroscedasticity, but
> I believe it can handle the kind you have in mind. Search
> the r-sig-mixed-models archive for a discussion involving me
> and David Afshartous, especially the summary message titled
> "[R-sig-ME] random effect variance per treatment group
> in lmer" that David posted 07/13/2007 04:18:08 PM
> 
> I can't be certain that the suggestion below would work
> without knowing more about your design, but if width were a
> factor with three levels then you might try setting up
> indicator variables Wind1, Wind2, and Wind3 (that each take
> on the value 1
> when a site is at the indicator's target width and 0
> otherwise) and then fit the model with something like
> mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess +
> crop + VegDensity + Group:sess + Group:VegDensity +
> (0+Wind1|site) + (0+Wind2|site) + (0+Wind3|site), data=all,
> method="REML" )
> 
> alan
> 
> 
> r-sig-mixed-models at r-project.org on Friday, December 19,
> 2008 at 6:00 AM -0500 wrote:
> >Message: 1
> >Date: Thu, 18 Dec 2008 11:23:46 +0000
> >From: "Renwick, A. R."
> <a.renwick at abdn.ac.uk>
> >Subject: [R-sig-ME] heteroscedastic model in lme4
> >To:
> "'r-sig-mixed-models at r-project.org'"
> >	<r-sig-mixed-models at r-project.org>
> >Message-ID:
> >	<B9D1301370916C44B5874AF340C18B9B28AE890D50 at VMAILB.uoa.abdn.ac.uk>
> >Content-Type: text/plain; charset="us-ascii"
> >
> >I have been using the nlme package to run some
> LMM's, however I would like to try rerunning them using
> the lme4 package so that I can use mcmc sampling.  The data
> I am using shows some heteroscesdasticity of the within
> error group and so I have
> >been using the 'weights' argument and the
> varIdent variance function structure to allow different
> variances for each level of my factor (patch width).
> >
> >My problem is how to code for a heteroscedastic model
> in lme4 and any suggestion wouuld be much apprecaited.
> >
> >The code I used in the nlme package:
> >
> ># model fit using "REML"
> >mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess +
> crop + VegDensity + Group:sess + Group:VegDensity
> ,random=~1|Site, data=all,
> >      
> method="REML",correlation=NULL,weights=varIdent(form=~1|width))
> >
> >
> >Many thanks,
> >Anna
> >
> >Anna Renwick
> >Institute of Biological & Environment Sciences
> >University of Aberdeen
> >Zoology Building
> >Tillydrone Avenue
> >Aberdeen
> >AB24 2TZ
> >
> >
> >The University of Aberdeen is a charity registered in
> Scotland, No SC013683.
> 
> 
> --
> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> Department of Psychology		(207) 581-6128 fax
> University of Maine
> Orono, ME 04469-5742     		alanc at maine.edu
> 
> http://www.umaine.edu/visualperception
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Fri, 19 Dec 2008 18:31:09 +0100
> From: Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl>
> Subject: Re: [R-sig-ME] heteroscedastic model in lme4
> To: Alan Cobo-Lewis <alanc at umit.maine.edu>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID: <494BDA5D.3030808 at erasmusmc.nl>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> I think not, because Anna wanted to model the variance of
> the within 
> measurement error terms not the variance of the random
> effects.
> 
> As far as I know, the design philosophy of lme4 is to allow
> for flexible 
> specifications of the random effects part of the mixed
> model that is 
> assumed to account for the main part of variability in the
> data.
> 
> Best,
> Dimitris
> 
> 
> Alan Cobo-Lewis wrote:
> > Anna,
> > 
> > lme4 cannot handle certain kinds of
> heteroscedasticity, but I believe it can handle the kind you
> have in mind. Search the r-sig-mixed-models archive for a
> discussion involving me and David Afshartous, especially the
> summary message titled
> > "[R-sig-ME] random effect variance per treatment
> group in lmer" that David posted 07/13/2007 04:18:08 PM
> > 
> > I can't be certain that the suggestion below would
> work without knowing more about your design, but if width
> were a factor with three levels then you might try setting
> up indicator variables Wind1, Wind2, and Wind3 (that each
> take on the value 1
> > when a site is at the indicator's target width and
> 0 otherwise) and then fit the model with something like
> > mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess
> + crop + VegDensity + Group:sess + Group:VegDensity +
> (0+Wind1|site) + (0+Wind2|site) + (0+Wind3|site), data=all,
> method="REML" )
> > 
> > alan
> > 
> > 
> > r-sig-mixed-models at r-project.org on Friday, December
> 19, 2008 at 6:00 AM -0500 wrote:
> >> Message: 1
> >> Date: Thu, 18 Dec 2008 11:23:46 +0000
> >> From: "Renwick, A. R."
> <a.renwick at abdn.ac.uk>
> >> Subject: [R-sig-ME] heteroscedastic model in lme4
> >> To:
> "'r-sig-mixed-models at r-project.org'"
> >> 	<r-sig-mixed-models at r-project.org>
> >> Message-ID:
> >>
> 	<B9D1301370916C44B5874AF340C18B9B28AE890D50 at VMAILB.uoa.abdn.ac.uk>
> >> Content-Type: text/plain;
> charset="us-ascii"
> >>
> >> I have been using the nlme package to run some
> LMM's, however I would like to try rerunning them using
> the lme4 package so that I can use mcmc sampling.  The data
> I am using shows some heteroscesdasticity of the within
> error group and so I have
> >> been using the 'weights' argument and the
> varIdent variance function structure to allow different
> variances for each level of my factor (patch width).
> >>
> >> My problem is how to code for a heteroscedastic
> model in lme4 and any suggestion wouuld be much apprecaited.
> >>
> >> The code I used in the nlme package:
> >>
> >> # model fit using "REML"
> >> mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess
> + crop + VegDensity + Group:sess + Group:VegDensity
> ,random=~1|Site, data=all,
> >>      
> method="REML",correlation=NULL,weights=varIdent(form=~1|width))
> >>
> >>
> >> Many thanks,
> >> Anna
> >>
> >> Anna Renwick
> >> Institute of Biological & Environment Sciences
> >> University of Aberdeen
> >> Zoology Building
> >> Tillydrone Avenue
> >> Aberdeen
> >> AB24 2TZ
> >>
> >>
> >> The University of Aberdeen is a charity registered
> in Scotland, No SC013683.
> > 
> > 
> > --
> > Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> > Department of Psychology		(207) 581-6128 fax
> > University of Maine
> > Orono, ME 04469-5742     		alanc at maine.edu
> > 
> > http://www.umaine.edu/visualperception
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> -- 
> Dimitris Rizopoulos
> Assistant Professor
> Department of Biostatistics
> Erasmus Medical Center
> 
> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> Tel: +31/(0)10/7043478
> Fax: +31/(0)10/7043014
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Fri, 19 Dec 2008 11:28:44 -0800 (PST)
> From: Luciano La Sala <lucianolasala at yahoo.com.ar>
> Subject: [R-sig-ME] naive questions about model building
> and error
> 	output
> To: r-sig-mixed-models at r-project.org
> Message-ID:
> <447014.18802.qm at web59906.mail.ac4.yahoo.com>
> Content-Type: text/plain; charset=utf-8
> 
> Dear R-experts,
> Quite new to R on this end, so I hope toy can help me out
> here: 
>     
> I am running version 2.7.1 on Windows Vista. I have small
> dataset which consists of: 
>     
> # NestID: nest indicator for each chicken. Siblings sharing
> the same nest have the same nest indicator. 
>     
> # Chick: chick indicator consisting of a unique ID for each
> single chick. 
>     
> # Year: 1, 2.
>     
> # ClutchSize: 1-, 2- , 3-eggs.  
>     
> # HO: hatching order within each clutch (1, 2, 3 [first,
> second and third-hatched chick]).
>     
> # SibComp: sibling competence: present/ absent (0, 1)
>     
> # Death10: death at ten days post-hatch (0, 1)
>     
> In order to account for lack of independence at the nest
> level (many
> chicks are nested in nest... aha!), I'd like to run a
> GLMM with random slopes and intercepts for nests.
>     
> Using lmer, my model for survival at 10 days, for example,
> would read (or not!) as follows: 
>     
> model1 <- lmer(Death10 ~ HO + ClutchSize + Sibcomp +
> Year + (HO+0|NestID) + (1|NestID), family=binomial, 1)    
>       
> summary(model)
> 
> The output give me the following error: 
> 
> Error en mer_finalize(ans, verbose) : q = 416 > n = 198 
> 
> 1. Whay does this error mean? I was told that my model
> fails to converge. 
> 
> 2. If so, is there any solution to a lack of convergence?
> 
> 3. Maybe I could use a model with only random intercept
> (See below)?
> 
> model2 <-lmer(Death10 ~ HO + ClutchSize + Sibcomp + Year
> + (1|NestID), family=binomial, 1)
> 
> I look forward to receiving your two cent?s worth. 
> 
> Best, Luciano   
> 
> 
> 
>      
> ____________________________________________________________________________________
> ?Busc? desde tu celular!
> 
> Yahoo! oneSEARCH ahora est? en Claro
> 
> http://ar.mobile.yahoo.com/onesearch
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Fri, 19 Dec 2008 14:52:14 -0500
> From: "Doran, Harold" <HDoran at air.org>
> Subject: Re: [R-sig-ME] heteroscedastic model in lme4
> To: "Alan Cobo-Lewis"
> <alanc at umit.maine.edu>,
> 	<r-sig-mixed-models at r-project.org>
> Message-ID:
> 	<ED7B522EE00C9A4FA515AA71724D61EE01C649D9 at DC1EXCL01.air.org>
> Content-Type: text/plain
> 
> This isn't an entirely accurate statement. nlme has
> built-in functions that implement the methods for
> correlational and variance structures as described in
> section 5 of Pinhiero and Bates. lme4 doesn't have these
> functions built in as does nlme, but those same methods can
> be implemented by the user and then the data can be analyzed
> using functions in lme4. So, functions in lme4 can
> "handle" the same issues as nlme, it just requires
> the user to perform the steps described in PB section 5 et
> seq on their own. 
> 
> 
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of
> Alan Cobo-Lewis
> Sent: Fri 12/19/2008 11:19 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] heteroscedastic model in lme4
>  
> 
> Anna,
> 
> lme4 cannot handle certain kinds of heteroscedasticity, but
> I believe it can handle the kind you have in mind. Search
> the r-sig-mixed-models archive for a discussion involving me
> and David Afshartous, especially the summary message titled
> "[R-sig-ME] random effect variance per treatment group
> in lmer" that David posted 07/13/2007 04:18:08 PM
> 
> I can't be certain that the suggestion below would work
> without knowing more about your design, but if width were a
> factor with three levels then you might try setting up
> indicator variables Wind1, Wind2, and Wind3 (that each take
> on the value 1
> when a site is at the indicator's target width and 0
> otherwise) and then fit the model with something like
> mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess +
> crop + VegDensity + Group:sess + Group:VegDensity +
> (0+Wind1|site) + (0+Wind2|site) + (0+Wind3|site), data=all,
> method="REML" )
> 
> alan
> 
> 
> r-sig-mixed-models at r-project.org on Friday, December 19,
> 2008 at 6:00 AM -0500 wrote:
> >Message: 1
> >Date: Thu, 18 Dec 2008 11:23:46 +0000
> >From: "Renwick, A. R."
> <a.renwick at abdn.ac.uk>
> >Subject: [R-sig-ME] heteroscedastic model in lme4
> >To:
> "'r-sig-mixed-models at r-project.org'"
> >	<r-sig-mixed-models at r-project.org>
> >Message-ID:
> >	<B9D1301370916C44B5874AF340C18B9B28AE890D50 at VMAILB.uoa.abdn.ac.uk>
> >Content-Type: text/plain; charset="us-ascii"
> >
> >I have been using the nlme package to run some
> LMM's, however I would like to try rerunning them using
> the lme4 package so that I can use mcmc sampling.  The data
> I am using shows some heteroscesdasticity of the within
> error group and so I have
> >been using the 'weights' argument and the
> varIdent variance function structure to allow different
> variances for each level of my factor (patch width).
> >
> >My problem is how to code for a heteroscedastic model
> in lme4 and any suggestion wouuld be much apprecaited.
> >
> >The code I used in the nlme package:
> >
> ># model fit using "REML"
> >mrem<-lme(log(Nhat+1)~Group + GreenPerc + sess +
> crop + VegDensity + Group:sess + Group:VegDensity
> ,random=~1|Site, data=all,
> >      
> method="REML",correlation=NULL,weights=varIdent(form=~1|width))
> >
> >
> >Many thanks,
> >Anna
> >
> >Anna Renwick
> >Institute of Biological & Environment Sciences
> >University of Aberdeen
> >Zoology Building
> >Tillydrone Avenue
> >Aberdeen
> >AB24 2TZ
> >
> >
> >The University of Aberdeen is a charity registered in
> Scotland, No SC013683.
> 
> 
> --
> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> Department of Psychology		(207) 581-6128 fax
> University of Maine
> Orono, ME 04469-5742     		alanc at maine.edu
> 
> http://www.umaine.edu/visualperception
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 24, Issue 28
> **************************************************






From s.ruiter at maw.ru.nl  Sun Dec 21 11:00:55 2008
From: s.ruiter at maw.ru.nl (Stijn Ruiter)
Date: Sun, 21 Dec 2008 11:00:55 +0100
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
Message-ID: <494E13D7.4010209@maw.ru.nl>

Hi all,
Frederik is right. Do you think such a model can be estimated using 
nlmer? How?
Stijn

-- 
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter



Fredrik Nilsson schreef:
> Dear Ben,
>
> Does it? I interpret Stijn's model as:
> logit(y) ~ alpha + beta*x + exp(-T/beta) + possibly multiple error
> terms (sample within muscle within toad or some non-nested terms)
>
> which I would find difficult to squeeze into the glmm framework.
>
> Best regards,
> Fredrik Nilsson
>
> ------------------------
> Competence Centre for Clinical Research,
> Lund University Hospital, 221 85 Lund, Sweden
>
> 2008/12/21 Ben Bolker <bolker at ufl.edu>:
>   
>> Stijn Ruiter wrote:
>>     
>>> Dear list,
>>> In SAS I am using NLMIXED to estimate a logistic model that includes
>>> exponential decay. Since NLMIXED only allows for a single random
>>> statement, I would like to switch to R. Could anyone suggest how to
>>> estimate such a model? I cannot find a clear example for estimating
>>> these kinds of models with nlmer.
>>> I'd like to estimate a logistic model for my dichotomous dependent
>>> variable that includes both linear terms and EXP(-Time/Beta).
>>> Thanks,
>>> Stijn
>>>
>>>       
>>  it sounds like
>>
>> lmer(...,family=binomial(link="log"))
>>
>>  -- i.e., a GLMM rather than a NLMM
>>
>>  Ben Bolker
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>



From bates at stat.wisc.edu  Sun Dec 21 16:32:22 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 21 Dec 2008 09:32:22 -0600
Subject: [R-sig-ME] lmer stand dev of coefficients
In-Reply-To: <918579.78707.qm@web54104.mail.re2.yahoo.com>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
Message-ID: <40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>

On Sun, Dec 21, 2008 at 3:55 AM, Iasonas Lamprianou
<lamprianou at yahoo.com> wrote:
> Dear friends
> when I use sd(coef(mymodel)$myvariable) I get 0.21
> However, the summary of the model gives
> Error terms:
>  Groups      Name        Std.Dev.
>  myvariable (Intercept) 0.33
>  Residual               0.76
>
> Why dont I get the same value (0.21 instead of 0.33)?

Because they are estimates of different quantities:
sd(coef(mymodel)$myvariable) is an estimate (although it is not
entirely clear what the properties of such an estimate would be) of
the conditional standard deviation of the random effects given the
data, whereas 0.33 is the maximum likelihood estimate or REML estimate
of the unconditional standard deviation of the random effects.  We
would expect the conditional standard deviation to be smaller than the
unconditional standard deviation.

P.S. If you are starting a new topic on the mailing list you don't
need to quote a previous message to the list and especially not an
entire digest message.



From hebeery at gmail.com  Sun Dec 21 16:11:44 2008
From: hebeery at gmail.com (lei chen)
Date: Sun, 21 Dec 2008 23:11:44 +0800
Subject: [R-sig-ME]  naive questions about model building
Message-ID: <e62a525d0812210711le719353r4318544c65a5f2f6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081221/a37e36ea/attachment.pl>

From danielezrajohnson at gmail.com  Sun Dec 21 16:40:22 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Sun, 21 Dec 2008 15:40:22 +0000
Subject: [R-sig-ME] Fwd:  lmer stand dev of coefficients
In-Reply-To: <a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
	<40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>
	<a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
Message-ID: <a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>

---------- Forwarded message ----------
From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
Date: Sun, Dec 21, 2008 at 3:39 PM
Subject: Re: [R-sig-ME] lmer stand dev of coefficients
To: Douglas Bates <bates at stat.wisc.edu>


Can you explain briefly what circumstances would lead these quantities
to be quite different?

Suppose the random effect grouping factor is Subject.

On what basis would the software estimate the unconditional SD of (the
population of) Subjects to be something quite different (and as you
say, usually larger) than that of the particular group of Subjects in
the data?

Dan

On Sun, Dec 21, 2008 at 3:32 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Sun, Dec 21, 2008 at 3:55 AM, Iasonas Lamprianou
> <lamprianou at yahoo.com> wrote:
>> Dear friends
>> when I use sd(coef(mymodel)$myvariable) I get 0.21
>> However, the summary of the model gives
>> Error terms:
>>  Groups      Name        Std.Dev.
>>  myvariable (Intercept) 0.33
>>  Residual               0.76
>>
>> Why dont I get the same value (0.21 instead of 0.33)?
>
> Because they are estimates of different quantities:
> sd(coef(mymodel)$myvariable) is an estimate (although it is not
> entirely clear what the properties of such an estimate would be) of
> the conditional standard deviation of the random effects given the
> data, whereas 0.33 is the maximum likelihood estimate or REML estimate
> of the unconditional standard deviation of the random effects.  We
> would expect the conditional standard deviation to be smaller than the
> unconditional standard deviation.
>
> P.S. If you are starting a new topic on the mailing list you don't
> need to quote a previous message to the list and especially not an
> entire digest message.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sun Dec 21 17:59:01 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 21 Dec 2008 10:59:01 -0600
Subject: [R-sig-ME] Fwd: lmer stand dev of coefficients
In-Reply-To: <a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
	<40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>
	<a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
	<a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>
Message-ID: <40e66e0b0812210859g45ae259cm7c623c7912fb7bc3@mail.gmail.com>

On Sun, Dec 21, 2008 at 9:40 AM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> ---------- Forwarded message ----------
> From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Date: Sun, Dec 21, 2008 at 3:39 PM
> Subject: Re: [R-sig-ME] lmer stand dev of coefficients
> To: Douglas Bates <bates at stat.wisc.edu>

> Can you explain briefly what circumstances would lead these quantities
> to be quite different?

First, I misspoke. (Note to self: Don't try to answer questions on
theory before the second cup of coffee.)  The standard deviation of
the BLUPs (or, as I prefer to call them, the conditional modes) of the
random effects are not an estimate of the conditional standard
deviation of the random effects given the data.  I can only make sense
of the conditional standard deviation of a particular random effect
and that would be much smaller than the observed standard deviation of
the conditional modes.

What I should have said is somewhat more subtle.  We know that the
conditional modes of the random effects have less variability than the
corresponding individual estimates of a parameter.  I enclose a script
and its output for a particularly simple example - a random-effects
model fit to the Dyestuff data from the lme4 package.  The design is a
balanced, one-way classification so the estimate of the mean yield is
simply the mean of the Yield variable.

We see that the conditional modes are always smaller in magnitude than
the deviations of the individual means from the overall mean.  The
fact that the ratio is constant is a consequence of the balanced
design.   We say that the conditional modes are shrunk towards zero
because the random effects have a finite variance.

The conditional modes are also shrunk relative to what would be
expected from the unconditional variance of the random effects, but I
find it more difficult to explain why.  It makes sense to me that the
mle of the unconditional standard deviation would be larger than the
standard deviation of the conditional modes but of the way the way the
likelihood criterion is formulated.

Perhaps someone else can explain why.

> Suppose the random effect grouping factor is Subject.
>
> On what basis would the software estimate the unconditional SD of (the
> population of) Subjects to be something quite different (and as you
> say, usually larger) than that of the particular group of Subjects in
> the data?
>
> Dan
>
> On Sun, Dec 21, 2008 at 3:32 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Sun, Dec 21, 2008 at 3:55 AM, Iasonas Lamprianou
>> <lamprianou at yahoo.com> wrote:
>>> Dear friends
>>> when I use sd(coef(mymodel)$myvariable) I get 0.21
>>> However, the summary of the model gives
>>> Error terms:
>>>  Groups      Name        Std.Dev.
>>>  myvariable (Intercept) 0.33
>>>  Residual               0.76
>>>
>>> Why dont I get the same value (0.21 instead of 0.33)?
>>
>> Because they are estimates of different quantities:
>> sd(coef(mymodel)$myvariable) is an estimate (although it is not
>> entirely clear what the properties of such an estimate would be) of
>> the conditional standard deviation of the random effects given the
>> data, whereas 0.33 is the maximum likelihood estimate or REML estimate
>> of the unconditional standard deviation of the random effects.  We
>> would expect the conditional standard deviation to be smaller than the
>> unconditional standard deviation.
>>
>> P.S. If you are starting a new topic on the mailing list you don't
>> need to quote a previous message to the list and especially not an
>> entire digest message.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From bates at stat.wisc.edu  Sun Dec 21 18:23:51 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 21 Dec 2008 11:23:51 -0600
Subject: [R-sig-ME] naive questions about model building and error output
In-Reply-To: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
References: <447014.18802.qm@web59906.mail.ac4.yahoo.com>
Message-ID: <40e66e0b0812210923h5f77c140m7e077d3dfb1863bd@mail.gmail.com>

On Fri, Dec 19, 2008 at 1:28 PM, Luciano La Sala
<lucianolasala at yahoo.com.ar> wrote:
> Dear R-experts,
> Quite new to R on this end, so I hope toy can help me out here:
>
> I am running version 2.7.1 on Windows Vista. I have small dataset which consists of:
>
> # NestID: nest indicator for each chicken. Siblings sharing the same nest have the same nest indicator.
>
> # Chick: chick indicator consisting of a unique ID for each single chick.
>
> # Year: 1, 2.
>
> # ClutchSize: 1-, 2- , 3-eggs.
>
> # HO: hatching order within each clutch (1, 2, 3 [first, second and third-hatched chick]).
>
> # SibComp: sibling competence: present/ absent (0, 1)
>
> # Death10: death at ten days post-hatch (0, 1)
>
> In order to account for lack of independence at the nest level (many
> chicks are nested in nest... aha!), I'd like to run a GLMM with random slopes and intercepts for nests.
>
> Using lmer, my model for survival at 10 days, for example, would read (or not!) as follows:
>
> model1 <- lmer(Death10 ~ HO + ClutchSize + Sibcomp + Year + (HO+0|NestID) + (1|NestID), family=binomial, 1)
>
> summary(model)
>
> The output give me the following error:
>
> Error en mer_finalize(ans, verbose) : q = 416 > n = 198
>
> 1. What does this error mean? I was told that my model fails to converge.

In my overly cryptic notation it means you have too many random
effects to be able to estimate them from the available data.  Your
model has a total of 416 random effects but only 198 observations from
which to estimate the parameters.

> 2. If so, is there any solution to a lack of convergence?

I think you will need to simplify the model.

> 3. Maybe I could use a model with only random intercept (See below)?

> model2 <-lmer(Death10 ~ HO + ClutchSize + Sibcomp + Year + (1|NestID), family=binomial, 1)

Yes, that seems more reasonable.

> I look forward to receiving your two cent's worth.
>
> Best, Luciano
>
>
>
>      ____________________________________________________________________________________
> ?Busc? desde tu celular!
>
> Yahoo! oneSEARCH ahora est? en Claro
>
> http://ar.mobile.yahoo.com/onesearch
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sun Dec 21 19:46:02 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 21 Dec 2008 12:46:02 -0600
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494E13D7.4010209@maw.ru.nl>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl>
Message-ID: <40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>

On Sun, Dec 21, 2008 at 4:00 AM, Stijn Ruiter <s.ruiter at maw.ru.nl> wrote:
> Hi all,
> Frederik is right. Do you think such a model can be estimated using nlmer?

> How?

We would need more detail about the data and the model to be able to answer.

Is the response on a continuous scale (i.e. not binary or a count)?

What are the covariates?

What is the model for the mean response?

How many random effects would be defined and how would they enter the
model for the mean response?



From s.ruiter at maw.ru.nl  Sun Dec 21 21:02:30 2008
From: s.ruiter at maw.ru.nl (Stijn Ruiter)
Date: Sun, 21 Dec 2008 21:02:30 +0100
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>	
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>	
	<494E13D7.4010209@maw.ru.nl>
	<40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
Message-ID: <494EA0D6.1080300@maw.ru.nl>

Hi,
I have official judicial data on criminal offending (dichotomous 
dependent variable=conviction(=Y)) of all (adult) children of fathers 
who differ with respect to their level of criminal behavior. These data 
were registered on a yearly basis. So, I am able to follow people over 
the course of their lives and model whether they get convicted. I intend 
to estimate a discrete-time logit model on a person-year file. Of 
course, because children are nested within their fathers, I need to take 
that into account. Furthermore, many subjects get convicted more than 
once during their lives, so I need to estimate a repeated events model.
I have several time-constant variables (e.g., gender) and several 
time-varying variables (e.g., number of years since father committed a 
crime(=T)). I would like to estimate something like this:

logit(Y) ~ alpha + beta1*GENDER + exp(-T/beta2) + ... + error term for nesting within fathers + error term for nesting within subject


Stijn


-- 
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter



Douglas Bates schreef:
> On Sun, Dec 21, 2008 at 4:00 AM, Stijn Ruiter <s.ruiter at maw.ru.nl> wrote:
>   
>> Hi all,
>> Frederik is right. Do you think such a model can be estimated using nlmer?
>>     
>
>   
>> How?
>>     
>
> We would need more detail about the data and the model to be able to answer.
>
> Is the response on a continuous scale (i.e. not binary or a count)?
>
> What are the covariates?
>
> What is the model for the mean response?
>
> How many random effects would be defined and how would they enter the
> model for the mean response?
>



From A.Robinson at ms.unimelb.edu.au  Sun Dec 21 21:12:41 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 22 Dec 2008 07:12:41 +1100
Subject: [R-sig-ME] Fwd: lmer stand dev of coefficients
In-Reply-To: <40e66e0b0812210859g45ae259cm7c623c7912fb7bc3@mail.gmail.com>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
	<40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>
	<a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
	<a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>
	<40e66e0b0812210859g45ae259cm7c623c7912fb7bc3@mail.gmail.com>
Message-ID: <20081221201241.GC45297@ms.unimelb.edu.au>

Hi all,

This article might help:

The BLUPs are not "best" when it comes to bootstrapping

Jeffrey S. Morris 

Statistics & Probability Letters 56 (2002) 425-430

In the setting of mixed models, some researchers may construct a
semiparametric bootstrap by sampling from the best linear unbiased
predictor residuals.  This paper demonstrates both mathematically and
by simulation that such a bootstrap will consistently underestimate
the variation in the data in finite samples.

Cheers,

Andrew


On Sun, Dec 21, 2008 at 10:59:01AM -0600, Douglas Bates wrote:
> On Sun, Dec 21, 2008 at 9:40 AM, Daniel Ezra Johnson
> <danielezrajohnson at gmail.com> wrote:
> > ---------- Forwarded message ----------
> > From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> > Date: Sun, Dec 21, 2008 at 3:39 PM
> > Subject: Re: [R-sig-ME] lmer stand dev of coefficients
> > To: Douglas Bates <bates at stat.wisc.edu>
> 
> > Can you explain briefly what circumstances would lead these quantities
> > to be quite different?
> 
> First, I misspoke. (Note to self: Don't try to answer questions on
> theory before the second cup of coffee.)  The standard deviation of
> the BLUPs (or, as I prefer to call them, the conditional modes) of the
> random effects are not an estimate of the conditional standard
> deviation of the random effects given the data.  I can only make sense
> of the conditional standard deviation of a particular random effect
> and that would be much smaller than the observed standard deviation of
> the conditional modes.
> 
> What I should have said is somewhat more subtle.  We know that the
> conditional modes of the random effects have less variability than the
> corresponding individual estimates of a parameter.  I enclose a script
> and its output for a particularly simple example - a random-effects
> model fit to the Dyestuff data from the lme4 package.  The design is a
> balanced, one-way classification so the estimate of the mean yield is
> simply the mean of the Yield variable.
> 
> We see that the conditional modes are always smaller in magnitude than
> the deviations of the individual means from the overall mean.  The
> fact that the ratio is constant is a consequence of the balanced
> design.   We say that the conditional modes are shrunk towards zero
> because the random effects have a finite variance.
> 
> The conditional modes are also shrunk relative to what would be
> expected from the unconditional variance of the random effects, but I
> find it more difficult to explain why.  It makes sense to me that the
> mle of the unconditional standard deviation would be larger than the
> standard deviation of the conditional modes but of the way the way the
> likelihood criterion is formulated.
> 
> Perhaps someone else can explain why.
> 
> > Suppose the random effect grouping factor is Subject.
> >
> > On what basis would the software estimate the unconditional SD of (the
> > population of) Subjects to be something quite different (and as you
> > say, usually larger) than that of the particular group of Subjects in
> > the data?
> >
> > Dan
> >
> > On Sun, Dec 21, 2008 at 3:32 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> >> On Sun, Dec 21, 2008 at 3:55 AM, Iasonas Lamprianou
> >> <lamprianou at yahoo.com> wrote:
> >>> Dear friends
> >>> when I use sd(coef(mymodel)$myvariable) I get 0.21
> >>> However, the summary of the model gives
> >>> Error terms:
> >>>  Groups      Name        Std.Dev.
> >>>  myvariable (Intercept) 0.33
> >>>  Residual               0.76
> >>>
> >>> Why dont I get the same value (0.21 instead of 0.33)?
> >>
> >> Because they are estimates of different quantities:
> >> sd(coef(mymodel)$myvariable) is an estimate (although it is not
> >> entirely clear what the properties of such an estimate would be) of
> >> the conditional standard deviation of the random effects given the
> >> data, whereas 0.33 is the maximum likelihood estimate or REML estimate
> >> of the unconditional standard deviation of the random effects.  We
> >> would expect the conditional standard deviation to be smaller than the
> >> unconditional standard deviation.
> >>
> >> P.S. If you are starting a new topic on the mailing list you don't
> >> need to quote a previous message to the list and especially not an
> >> entire digest message.
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Sun Dec 21 21:35:20 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 21 Dec 2008 14:35:20 -0600
Subject: [R-sig-ME] Fwd: lmer stand dev of coefficients
In-Reply-To: <20081221201241.GC45297@ms.unimelb.edu.au>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
	<40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>
	<a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
	<a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>
	<40e66e0b0812210859g45ae259cm7c623c7912fb7bc3@mail.gmail.com>
	<20081221201241.GC45297@ms.unimelb.edu.au>
Message-ID: <40e66e0b0812211235n26a48e90xb04173d5820849e3@mail.gmail.com>

On Sun, Dec 21, 2008 at 2:12 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> Hi all,
>
> This article might help:
>
> The BLUPs are not "best" when it comes to bootstrapping
>
> Jeffrey S. Morris
>
> Statistics & Probability Letters 56 (2002) 425-430
>
> In the setting of mixed models, some researchers may construct a
> semiparametric bootstrap by sampling from the best linear unbiased
> predictor residuals.  This paper demonstrates both mathematically and
> by simulation that such a bootstrap will consistently underestimate
> the variation in the data in finite samples.
>
> Cheers,
>
> Andrew

Thanks, Andrew.

It occurred to me after I wrote my response that simulation would be a
good way of seeing this effect.  In other words, simulate data from a
simple model with a known variance for the random effects and the
noise then check what the mle and REML estimates of the variance are
and what the variance or standard deviation of the conditional modes
are.

Also, are there formulas for the BLUPs in the case of a simple
one-factor balanced design like the Dyestuff data?  Can these be used
to show that the BLUPs will tend to have an empirical standard
deviation whose expectation is less than the standard deviation of the
random effects?

>
> On Sun, Dec 21, 2008 at 10:59:01AM -0600, Douglas Bates wrote:
>> On Sun, Dec 21, 2008 at 9:40 AM, Daniel Ezra Johnson
>> <danielezrajohnson at gmail.com> wrote:
>> > ---------- Forwarded message ----------
>> > From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
>> > Date: Sun, Dec 21, 2008 at 3:39 PM
>> > Subject: Re: [R-sig-ME] lmer stand dev of coefficients
>> > To: Douglas Bates <bates at stat.wisc.edu>
>>
>> > Can you explain briefly what circumstances would lead these quantities
>> > to be quite different?
>>
>> First, I misspoke. (Note to self: Don't try to answer questions on
>> theory before the second cup of coffee.)  The standard deviation of
>> the BLUPs (or, as I prefer to call them, the conditional modes) of the
>> random effects are not an estimate of the conditional standard
>> deviation of the random effects given the data.  I can only make sense
>> of the conditional standard deviation of a particular random effect
>> and that would be much smaller than the observed standard deviation of
>> the conditional modes.
>>
>> What I should have said is somewhat more subtle.  We know that the
>> conditional modes of the random effects have less variability than the
>> corresponding individual estimates of a parameter.  I enclose a script
>> and its output for a particularly simple example - a random-effects
>> model fit to the Dyestuff data from the lme4 package.  The design is a
>> balanced, one-way classification so the estimate of the mean yield is
>> simply the mean of the Yield variable.
>>
>> We see that the conditional modes are always smaller in magnitude than
>> the deviations of the individual means from the overall mean.  The
>> fact that the ratio is constant is a consequence of the balanced
>> design.   We say that the conditional modes are shrunk towards zero
>> because the random effects have a finite variance.
>>
>> The conditional modes are also shrunk relative to what would be
>> expected from the unconditional variance of the random effects, but I
>> find it more difficult to explain why.  It makes sense to me that the
>> mle of the unconditional standard deviation would be larger than the
>> standard deviation of the conditional modes but of the way the way the
>> likelihood criterion is formulated.
>>
>> Perhaps someone else can explain why.
>>
>> > Suppose the random effect grouping factor is Subject.
>> >
>> > On what basis would the software estimate the unconditional SD of (the
>> > population of) Subjects to be something quite different (and as you
>> > say, usually larger) than that of the particular group of Subjects in
>> > the data?
>> >
>> > Dan
>> >
>> > On Sun, Dec 21, 2008 at 3:32 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> >> On Sun, Dec 21, 2008 at 3:55 AM, Iasonas Lamprianou
>> >> <lamprianou at yahoo.com> wrote:
>> >>> Dear friends
>> >>> when I use sd(coef(mymodel)$myvariable) I get 0.21
>> >>> However, the summary of the model gives
>> >>> Error terms:
>> >>>  Groups      Name        Std.Dev.
>> >>>  myvariable (Intercept) 0.33
>> >>>  Residual               0.76
>> >>>
>> >>> Why dont I get the same value (0.21 instead of 0.33)?
>> >>
>> >> Because they are estimates of different quantities:
>> >> sd(coef(mymodel)$myvariable) is an estimate (although it is not
>> >> entirely clear what the properties of such an estimate would be) of
>> >> the conditional standard deviation of the random effects given the
>> >> data, whereas 0.33 is the maximum likelihood estimate or REML estimate
>> >> of the unconditional standard deviation of the random effects.  We
>> >> would expect the conditional standard deviation to be smaller than the
>> >> unconditional standard deviation.
>> >>
>> >> P.S. If you are starting a new topic on the mailing list you don't
>> >> need to quote a previous message to the list and especially not an
>> >> entire digest message.
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Andrew Robinson
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>



From A.Robinson at ms.unimelb.edu.au  Sun Dec 21 21:50:10 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 22 Dec 2008 07:50:10 +1100
Subject: [R-sig-ME] Fwd: lmer stand dev of coefficients
In-Reply-To: <40e66e0b0812211235n26a48e90xb04173d5820849e3@mail.gmail.com>
References: <mailman.5.1229770802.5728.r-sig-mixed-models@r-project.org>
	<918579.78707.qm@web54104.mail.re2.yahoo.com>
	<40e66e0b0812210732s33c988fcq42b17c328c678db2@mail.gmail.com>
	<a46630750812210739u7238e393ye786e29f36f33a65@mail.gmail.com>
	<a46630750812210740q1b9bdb70s9e34bb4ff772b6f8@mail.gmail.com>
	<40e66e0b0812210859g45ae259cm7c623c7912fb7bc3@mail.gmail.com>
	<20081221201241.GC45297@ms.unimelb.edu.au>
	<40e66e0b0812211235n26a48e90xb04173d5820849e3@mail.gmail.com>
Message-ID: <20081221205010.GF45297@ms.unimelb.edu.au>

On Sun, Dec 21, 2008 at 02:35:20PM -0600, Douglas Bates wrote:
> On Sun, Dec 21, 2008 at 2:12 PM, Andrew Robinson
> <A.Robinson at ms.unimelb.edu.au> wrote:
> > Hi all,
> >
> > This article might help:
> >
> > The BLUPs are not "best" when it comes to bootstrapping
> >
> > Jeffrey S. Morris
> >
> > Statistics & Probability Letters 56 (2002) 425-430
> >
> > In the setting of mixed models, some researchers may construct a
> > semiparametric bootstrap by sampling from the best linear unbiased
> > predictor residuals.  This paper demonstrates both mathematically and
> > by simulation that such a bootstrap will consistently underestimate
> > the variation in the data in finite samples.
> >
> > Cheers,
> >
> > Andrew
> 
> Thanks, Andrew.
> 
> It occurred to me after I wrote my response that simulation would be a
> good way of seeing this effect.  In other words, simulate data from a
> simple model with a known variance for the random effects and the
> noise then check what the mle and REML estimates of the variance are
> and what the variance or standard deviation of the conditional modes
> are.
> 
> Also, are there formulas for the BLUPs in the case of a simple
> one-factor balanced design like the Dyestuff data?  Can these be used
> to show that the BLUPs will tend to have an empirical standard
> deviation whose expectation is less than the standard deviation of the
> random effects?

Yes indeed - this is how I believe Morris proceeds.

Andrew
 
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From David.Duffy at qimr.edu.au  Sun Dec 21 22:03:46 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 22 Dec 2008 07:03:46 +1000 (EST)
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494EA0D6.1080300@maw.ru.nl>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl><40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
	<494EA0D6.1080300@maw.ru.nl>
Message-ID: <Pine.LNX.4.64.0812220647360.18108@orpheus.qimr.edu.au>

On Sun, 21 Dec 2008, Stijn Ruiter wrote:

> Hi,
> I have official judicial data on criminal offending (dichotomous dependent 
> variable=conviction(=Y)) of all (adult) children of fathers who differ with 
> respect to their level of criminal behavior. These data were registered on a 
> yearly basis. So, I am able to follow people over the course of their lives 
> and model whether they get convicted. I intend to estimate a discrete-time 
> logit model on a person-year file. Of course, because children are nested 
> within their fathers, I need to take that into account. Furthermore, many 
> subjects get convicted more than once during their lives, so I need to 
> estimate a repeated events model.
> I have several time-constant variables (e.g., gender) and several 
> time-varying variables (e.g., number of years since father committed a 
> crime(=T)). I would like to estimate something like this:
>
> logit(Y) ~ alpha + beta1*GENDER + exp(-T/beta2) + ... + error term for 
> nesting within fathers + error term for nesting within subject
>

You also want the person-years at risk as an offset too, don't you?  And 
do you have many families, so there are multiple individuals with the same 
father?  You may know that the R survival package implements frailty 
models that would be applicable, and that the kinship package specifically 
offers a Cox proportional hazards model (with gaussian random effects) 
that can incorporate two crossed variance components.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From s.ruiter at maw.ru.nl  Sun Dec 21 22:09:14 2008
From: s.ruiter at maw.ru.nl (Stijn Ruiter)
Date: Sun, 21 Dec 2008 22:09:14 +0100
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <Pine.LNX.4.64.0812220647360.18108@orpheus.qimr.edu.au>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl><40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
	<494EA0D6.1080300@maw.ru.nl>
	<Pine.LNX.4.64.0812220647360.18108@orpheus.qimr.edu.au>
Message-ID: <494EB07A.7080805@maw.ru.nl>

Hi,
Thanks David, I should look into that, but I usually estimate 
discrete-time models which are basically logistic regression models on 
person-years files with only the records included that are "at risk". 
Anyway, do these packages also allow for nonlinear effects the way I 
need them?
Stijn

-- 
Best regards,

Stijn Ruiter
Department of Sociology / ICS
Radboud University Nijmegen
P.O. Box 9104
6500 HE Nijmegen
Netherlands

Phone: + 31 24 361 2272
Fax:   + 31 24 361 2399

Visiting address:
Thomas van Aquinostraat 4.01.71
Nijmegen

website: http://oase.uci.ru.nl/~sruiter



David Duffy schreef:
> On Sun, 21 Dec 2008, Stijn Ruiter wrote:
>
>> Hi,
>> I have official judicial data on criminal offending (dichotomous 
>> dependent variable=conviction(=Y)) of all (adult) children of fathers 
>> who differ with respect to their level of criminal behavior. These 
>> data were registered on a yearly basis. So, I am able to follow 
>> people over the course of their lives and model whether they get 
>> convicted. I intend to estimate a discrete-time logit model on a 
>> person-year file. Of course, because children are nested within their 
>> fathers, I need to take that into account. Furthermore, many subjects 
>> get convicted more than once during their lives, so I need to 
>> estimate a repeated events model.
>> I have several time-constant variables (e.g., gender) and several 
>> time-varying variables (e.g., number of years since father committed 
>> a crime(=T)). I would like to estimate something like this:
>>
>> logit(Y) ~ alpha + beta1*GENDER + exp(-T/beta2) + ... + error term 
>> for nesting within fathers + error term for nesting within subject
>>
>
> You also want the person-years at risk as an offset too, don't you?  
> And do you have many families, so there are multiple individuals with 
> the same father?  You may know that the R survival package implements 
> frailty models that would be applicable, and that the kinship package 
> specifically offers a Cox proportional hazards model (with gaussian 
> random effects) that can incorporate two crossed variance components.
>
> Cheers, David Duffy.
>



From David.Duffy at qimr.edu.au  Sun Dec 21 22:35:31 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 22 Dec 2008 07:35:31 +1000 (EST)
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494EB07A.7080805@maw.ru.nl>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl><40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
	<494EA0D6.1080300@maw.ru.nl>
	<Pine.LNX.4.64.0812220647360.18108@orpheus.qimr.edu.au>
	<494EB07A.7080805@maw.ru.nl>
Message-ID: <Pine.LNX.4.64.0812220713300.18108@orpheus.qimr.edu.au>

On Sun, 21 Dec 2008, Stijn Ruiter wrote:

> Hi,
> Thanks David, I should look into that, but I usually estimate discrete-time 
> models which are basically logistic regression models on person-years files 
> with only the records included that are "at risk". Anyway, do these packages 
> also allow for nonlinear effects the way I need them?
> Stijn
>

Well, your setup is pretty similar to "standard" bivariate survival 
problems, with your "nonlinear term" being simply time since the first 
event (the father's offence) -- there is a correlation between years at 
risk of the index person and years since his/her father offended. Your 
assumption of an exponential decay is going to induce a particular 
survivor curve.  That is, if you included number of years between the 
paternal offence and birth of the index person as a 
non-time-varying covariate, and instead changed the survival model from a 
non-proportional-hazards to say an accelerated failure time model, you may 
model the results just as well.

My $0.02, cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bates at stat.wisc.edu  Mon Dec 22 10:59:51 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 22 Dec 2008 03:59:51 -0600
Subject: [R-sig-ME] logistic model with exponential decay
In-Reply-To: <494EA0D6.1080300@maw.ru.nl>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl>
	<40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
	<494EA0D6.1080300@maw.ru.nl>
Message-ID: <40e66e0b0812220159q23ed195l26769c6c81d3ec@mail.gmail.com>

On Sun, Dec 21, 2008 at 2:02 PM, Stijn Ruiter <s.ruiter at maw.ru.nl> wrote:
> Hi,
> I have official judicial data on criminal offending (dichotomous dependent
> variable=conviction(=Y)) of all (adult) children of fathers who differ with
> respect to their level of criminal behavior. These data were registered on a
> yearly basis. So, I am able to follow people over the course of their lives
> and model whether they get convicted. I intend to estimate a discrete-time
> logit model on a person-year file. Of course, because children are nested
> within their fathers, I need to take that into account. Furthermore, many
> subjects get convicted more than once during their lives, so I need to
> estimate a repeated events model.
> I have several time-constant variables (e.g., gender) and several
> time-varying variables (e.g., number of years since father committed a
> crime(=T)). I would like to estimate something like this:
>
> logit(Y) ~ alpha + beta1*GENDER + exp(-T/beta2) + ... + error term for
> nesting within fathers + error term for nesting within subject

At present nlmer does not allow families other than gaussian for the
conditional distribution of the response given the random effects.  I
do plan to combine nonlinear model functions and glm families to allow
for generalized nonlinear mixed models but must finish a couple of
other projects first.

> Douglas Bates schreef:
>>
>> On Sun, Dec 21, 2008 at 4:00 AM, Stijn Ruiter <s.ruiter at maw.ru.nl> wrote:
>>
>>>
>>> Hi all,
>>> Frederik is right. Do you think such a model can be estimated using
>>> nlmer?
>>>
>>
>>
>>>
>>> How?
>>>
>>
>> We would need more detail about the data and the model to be able to
>> answer.
>>
>> Is the response on a continuous scale (i.e. not binary or a count)?
>>
>> What are the covariates?
>>
>> What is the model for the mean response?
>>
>> How many random effects would be defined and how would they enter the
>> model for the mean response?
>>
>



From leog at anicca-vijja.de  Mon Dec 22 12:50:54 2008
From: leog at anicca-vijja.de (=?ISO-8859-1?Q?Leo_G=FCrtler?=)
Date: Mon, 22 Dec 2008 12:50:54 +0100
Subject: [R-sig-ME] heteroscedastic model in lme4
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE01C649D9@DC1EXCL01.air.org>
References: <mailman.5.1229684401.6913.r-sig-mixed-models@r-project.org>	<fc.004c4d193ab9516e3b9aca00882f2171.3ab97563@umit.maine.edu>
	<ED7B522EE00C9A4FA515AA71724D61EE01C649D9@DC1EXCL01.air.org>
Message-ID: <494F7F1E.4080409@anicca-vijja.de>

Doran, Harold schrieb:

Dear SIG-ME,

> This isn't an entirely accurate statement. nlme has built-in
> functions that implement the methods for correlational and variance
> structures as described in section 5 of Pinhiero and Bates. lme4
> doesn't have these functions built in as does nlme, but those same
> methods can be implemented by the user and then the data can be
> analyzed using functions in lme4. So, functions in lme4 can "handle"
> the same issues as nlme, it just requires the user to perform the
> steps described in PB section 5 et seq on their own.

has someone did this and can provide some R-code or references with
R-Code to learn how to do that?

thx,
leo

> 
> 
> 
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org on behalf of Alan Cobo-Lewis
>  Sent: Fri 12/19/2008 11:19 AM To: r-sig-mixed-models at r-project.org 
> Subject: Re: [R-sig-ME] heteroscedastic model in lme4
> 
> 
> Anna,
> 
> lme4 cannot handle certain kinds of heteroscedasticity, but I believe
> it can handle the kind you have in mind. Search the
> r-sig-mixed-models archive for a discussion involving me and David
> Afshartous, especially the summary message titled "[R-sig-ME] random
> effect variance per treatment group in lmer" that David posted
> 07/13/2007 04:18:08 PM
> 
> I can't be certain that the suggestion below would work without
> knowing more about your design, but if width were a factor with three
> levels then you might try setting up indicator variables Wind1,
> Wind2, and Wind3 (that each take on the value 1 when a site is at the
> indicator's target width and 0 otherwise) and then fit the model with
> something like mrem <- lmer( log(Nhat+1)~Group + GreenPerc + sess +
> crop + VegDensity + Group:sess + Group:VegDensity + (0+Wind1|site) +
> (0+Wind2|site) + (0+Wind3|site), data=all, method="REML" )
> 
> alan
> 
>



From danielezrajohnson at gmail.com  Mon Dec 22 12:54:50 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Mon, 22 Dec 2008 11:54:50 +0000
Subject: [R-sig-ME] mixed model with non-continuous numeric response
Message-ID: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>

Dear all,

I have survey results where the response is 1, 2, 3, or 4. These can
be thought of as equally-spaced points on a scale, I don't have a
problem with that. (They're actually more like "not at all", "some",
"mostly", "totally"; the subject is judging a stimulus.)

I want to model crossed random effects for Subject and Item. Am I way
off base in modeling this data with a lmer(family="gaussian") model? I
know it's not perfect, but is it really bad? If so, what could I do
instead? (The error certainly wouldn't be binomial, right?)

Thanks,
Daniel



From reinhold.kliegl at gmail.com  Mon Dec 22 13:40:29 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 22 Dec 2008 13:40:29 +0100
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
Message-ID: <aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>

( ...,  family="poisson")  is the most used option for count data

Reinhold Kliegl

On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> Dear all,
>
> I have survey results where the response is 1, 2, 3, or 4. These can
> be thought of as equally-spaced points on a scale, I don't have a
> problem with that. (They're actually more like "not at all", "some",
> "mostly", "totally"; the subject is judging a stimulus.)
>
> I want to model crossed random effects for Subject and Item. Am I way
> off base in modeling this data with a lmer(family="gaussian") model? I
> know it's not perfect, but is it really bad? If so, what could I do
> instead? (The error certainly wouldn't be binomial, right?)
>
> Thanks,
> Daniel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From danielezrajohnson at gmail.com  Mon Dec 22 13:41:41 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Mon, 22 Dec 2008 12:41:41 +0000
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
Message-ID: <a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>

I don't think this is count data, is it???

On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> ( ...,  family="poisson")  is the most used option for count data
>
> Reinhold Kliegl
>
> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
> <danielezrajohnson at gmail.com> wrote:
>> Dear all,
>>
>> I have survey results where the response is 1, 2, 3, or 4. These can
>> be thought of as equally-spaced points on a scale, I don't have a
>> problem with that. (They're actually more like "not at all", "some",
>> "mostly", "totally"; the subject is judging a stimulus.)
>>
>> I want to model crossed random effects for Subject and Item. Am I way
>> off base in modeling this data with a lmer(family="gaussian") model? I
>> know it's not perfect, but is it really bad? If so, what could I do
>> instead? (The error certainly wouldn't be binomial, right?)
>>
>> Thanks,
>> Daniel
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From reinhold.kliegl at gmail.com  Mon Dec 22 15:04:19 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 22 Dec 2008 15:04:19 +0100
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
	<a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
Message-ID: <aefe4d0a0812220604k6efcb37r333e77b13bd85a64@mail.gmail.com>

See Venables and Ripley (2002, p.200) for an example modeling
three-levels of satisfaction (low, medium, high) as a surrogate
Poisson model. They also provide the technical justification. The
alternative is to fit it as multinomial model--not sure how, if it at
all, this can be done with glmer in its current implementation.

Reinhold Kliegl

On Mon, Dec 22, 2008 at 1:41 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> I don't think this is count data, is it???
>
> On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> ( ...,  family="poisson")  is the most used option for count data
>>
>> Reinhold Kliegl
>>
>> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
>> <danielezrajohnson at gmail.com> wrote:
>>> Dear all,
>>>
>>> I have survey results where the response is 1, 2, 3, or 4. These can
>>> be thought of as equally-spaced points on a scale, I don't have a
>>> problem with that. (They're actually more like "not at all", "some",
>>> "mostly", "totally"; the subject is judging a stimulus.)
>>>
>>> I want to model crossed random effects for Subject and Item. Am I way
>>> off base in modeling this data with a lmer(family="gaussian") model? I
>>> know it's not perfect, but is it really bad? If so, what could I do
>>> instead? (The error certainly wouldn't be binomial, right?)
>>>
>>> Thanks,
>>> Daniel
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



From baron at psych.upenn.edu  Mon Dec 22 16:06:57 2008
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Mon, 22 Dec 2008 10:06:57 -0500
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <aefe4d0a0812220604k6efcb37r333e77b13bd85a64@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
	<a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
	<aefe4d0a0812220604k6efcb37r333e77b13bd85a64@mail.gmail.com>
Message-ID: <20081222150657.GA32325@psych.upenn.edu>

On 12/22/08 15:04, Reinhold Kliegl wrote:
> See Venables and Ripley (2002, p.200) for an example modeling
> three-levels of satisfaction (low, medium, high) as a surrogate
> Poisson model. They also provide the technical justification. The
> alternative is to fit it as multinomial model--not sure how, if it at
> all, this can be done with glmer in its current implementation.

Johnson (the original poster) said that the responses can be thought
of as equally spaced points, i.e., linear with the underlying variable
of interest.  I think that this is often a reasonable assumption, so
another alternative is to do what he said.  Psychologists -- perhaps
because we have read Dawes, R. M., & Corrigan, B. (1974). Linear
models in decision making. Psychological Bulletin, 81, 97?106 -- are
often willing to assume that linear models are good fits even when
they are technically wrong.

(I also couldn't find VR's rationale for the surrogate Poisson model,
but I'm not questioning that possibility.)

The question is about how serious is the violation of the assumed
error distribution when we have only 4 categories.  When I do this -
which I admit is usually when I'm using lm() and not lmer() - I look
at the error distributions (from the default plot()) and do an eyeball
test.  If the result is barely "significant" at the outset, I worry.

Jon

> Reinhold Kliegl
> 
> On Mon, Dec 22, 2008 at 1:41 PM, Daniel Ezra Johnson
> <danielezrajohnson at gmail.com> wrote:
> > I don't think this is count data, is it???
> >
> > On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
> > <reinhold.kliegl at gmail.com> wrote:
> >> ( ...,  family="poisson")  is the most used option for count data
> >>
> >> Reinhold Kliegl
> >>
> >> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
> >> <danielezrajohnson at gmail.com> wrote:
> >>> Dear all,
> >>>
> >>> I have survey results where the response is 1, 2, 3, or 4. These can
> >>> be thought of as equally-spaced points on a scale, I don't have a
> >>> problem with that. (They're actually more like "not at all", "some",
> >>> "mostly", "totally"; the subject is judging a stimulus.)
> >>>
> >>> I want to model crossed random effects for Subject and Item. Am I way
> >>> off base in modeling this data with a lmer(family="gaussian") model? I
> >>> know it's not perfect, but is it really bad? If so, what could I do
> >>> instead? (The error certainly wouldn't be binomial, right?)
> >>>
> >>> Thanks,
> >>> Daniel
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From reinhold.kliegl at gmail.com  Mon Dec 22 17:25:04 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 22 Dec 2008 17:25:04 +0100
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <20081222150657.GA32325@psych.upenn.edu>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
	<a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
	<aefe4d0a0812220604k6efcb37r333e77b13bd85a64@mail.gmail.com>
	<20081222150657.GA32325@psych.upenn.edu>
Message-ID: <aefe4d0a0812220825s415bf620k484c24fac4ced69b@mail.gmail.com>

The VR paragraphs I was referring to are on page 199.   Anyway, if one
is willing to make the assumption of linear spacing, then responses 1,
2, 3, 4 can surely also be interpreted as count data; sort of the
number of latent pieces of evidence you need to move up one  response
category; subtract 1 if you want "0" as part of the scale.

Then, indeed, the distribution or responses matters. If the
distribution looks roughly "normal" (e.g., if categories 2 and 3 are
more frequent than 1 and 4), it probably does not matter whether you
use the Gaussian or the Poisson family. If they are bi-modal, I would
definitely prefer the latter. (Of course, it does matter if you have a
substantive theory.)

Reinhold Kliegl

On Mon, Dec 22, 2008 at 4:06 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> On 12/22/08 15:04, Reinhold Kliegl wrote:
>> See Venables and Ripley (2002, p.200) for an example modeling
>> three-levels of satisfaction (low, medium, high) as a surrogate
>> Poisson model. They also provide the technical justification. The
>> alternative is to fit it as multinomial model--not sure how, if it at
>> all, this can be done with glmer in its current implementation.
>
> Johnson (the original poster) said that the responses can be thought
> of as equally spaced points, i.e., linear with the underlying variable
> of interest.  I think that this is often a reasonable assumption, so
> another alternative is to do what he said.  Psychologists -- perhaps
> because we have read Dawes, R. M., & Corrigan, B. (1974). Linear
> models in decision making. Psychological Bulletin, 81, 97?106 -- are
> often willing to assume that linear models are good fits even when
> they are technically wrong.
>
> (I also couldn't find VR's rationale for the surrogate Poisson model,
> but I'm not questioning that possibility.)
>
> The question is about how serious is the violation of the assumed
> error distribution when we have only 4 categories.  When I do this -
> which I admit is usually when I'm using lm() and not lmer() - I look
> at the error distributions (from the default plot()) and do an eyeball
> test.  If the result is barely "significant" at the outset, I worry.
>
> Jon
>
>> Reinhold Kliegl
>>
>> On Mon, Dec 22, 2008 at 1:41 PM, Daniel Ezra Johnson
>> <danielezrajohnson at gmail.com> wrote:
>> > I don't think this is count data, is it???
>> >
>> > On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
>> > <reinhold.kliegl at gmail.com> wrote:
>> >> ( ...,  family="poisson")  is the most used option for count data
>> >>
>> >> Reinhold Kliegl
>> >>
>> >> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
>> >> <danielezrajohnson at gmail.com> wrote:
>> >>> Dear all,
>> >>>
>> >>> I have survey results where the response is 1, 2, 3, or 4. These can
>> >>> be thought of as equally-spaced points on a scale, I don't have a
>> >>> problem with that. (They're actually more like "not at all", "some",
>> >>> "mostly", "totally"; the subject is judging a stimulus.)
>> >>>
>> >>> I want to model crossed random effects for Subject and Item. Am I way
>> >>> off base in modeling this data with a lmer(family="gaussian") model? I
>> >>> know it's not perfect, but is it really bad? If so, what could I do
>> >>> instead? (The error certainly wouldn't be binomial, right?)
>> >>>
>> >>> Thanks,
>> >>> Daniel
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>



From reinhold.kliegl at gmail.com  Mon Dec 22 17:56:42 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 22 Dec 2008 17:56:42 +0100
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <aefe4d0a0812220825s415bf620k484c24fac4ced69b@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>
	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
	<a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
	<aefe4d0a0812220604k6efcb37r333e77b13bd85a64@mail.gmail.com>
	<20081222150657.GA32325@psych.upenn.edu>
	<aefe4d0a0812220825s415bf620k484c24fac4ced69b@mail.gmail.com>
Message-ID: <aefe4d0a0812220856x22889315x2467f9ead1238c4e@mail.gmail.com>

Line 1 in the paragraph 2 below should read: "Then, indeed, the
distribution of errors matters. ..."
Reinhold Kliegl

On Mon, Dec 22, 2008 at 5:25 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> The VR paragraphs I was referring to are on page 199.   Anyway, if one
> is willing to make the assumption of linear spacing, then responses 1,
> 2, 3, 4 can surely also be interpreted as count data; sort of the
> number of latent pieces of evidence you need to move up one  response
> category; subtract 1 if you want "0" as part of the scale.
>
> Then, indeed, the distribution or responses matters. If the
> distribution looks roughly "normal" (e.g., if categories 2 and 3 are
> more frequent than 1 and 4), it probably does not matter whether you
> use the Gaussian or the Poisson family. If they are bi-modal, I would
> definitely prefer the latter. (Of course, it does matter if you have a
> substantive theory.)
>
> Reinhold Kliegl
>
> On Mon, Dec 22, 2008 at 4:06 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
>> On 12/22/08 15:04, Reinhold Kliegl wrote:
>>> See Venables and Ripley (2002, p.200) for an example modeling
>>> three-levels of satisfaction (low, medium, high) as a surrogate
>>> Poisson model. They also provide the technical justification. The
>>> alternative is to fit it as multinomial model--not sure how, if it at
>>> all, this can be done with glmer in its current implementation.
>>
>> Johnson (the original poster) said that the responses can be thought
>> of as equally spaced points, i.e., linear with the underlying variable
>> of interest.  I think that this is often a reasonable assumption, so
>> another alternative is to do what he said.  Psychologists -- perhaps
>> because we have read Dawes, R. M., & Corrigan, B. (1974). Linear
>> models in decision making. Psychological Bulletin, 81, 97?106 -- are
>> often willing to assume that linear models are good fits even when
>> they are technically wrong.
>>
>> (I also couldn't find VR's rationale for the surrogate Poisson model,
>> but I'm not questioning that possibility.)
>>
>> The question is about how serious is the violation of the assumed
>> error distribution when we have only 4 categories.  When I do this -
>> which I admit is usually when I'm using lm() and not lmer() - I look
>> at the error distributions (from the default plot()) and do an eyeball
>> test.  If the result is barely "significant" at the outset, I worry.
>>
>> Jon
>>
>>> Reinhold Kliegl
>>>
>>> On Mon, Dec 22, 2008 at 1:41 PM, Daniel Ezra Johnson
>>> <danielezrajohnson at gmail.com> wrote:
>>> > I don't think this is count data, is it???
>>> >
>>> > On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
>>> > <reinhold.kliegl at gmail.com> wrote:
>>> >> ( ...,  family="poisson")  is the most used option for count data
>>> >>
>>> >> Reinhold Kliegl
>>> >>
>>> >> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
>>> >> <danielezrajohnson at gmail.com> wrote:
>>> >>> Dear all,
>>> >>>
>>> >>> I have survey results where the response is 1, 2, 3, or 4. These can
>>> >>> be thought of as equally-spaced points on a scale, I don't have a
>>> >>> problem with that. (They're actually more like "not at all", "some",
>>> >>> "mostly", "totally"; the subject is judging a stimulus.)
>>> >>>
>>> >>> I want to model crossed random effects for Subject and Item. Am I way
>>> >>> off base in modeling this data with a lmer(family="gaussian") model? I
>>> >>> know it's not perfect, but is it really bad? If so, what could I do
>>> >>> instead? (The error certainly wouldn't be binomial, right?)
>>> >>>
>>> >>> Thanks,
>>> >>> Daniel
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-mixed-models at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>>
>>> >>
>>> >
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> Jonathan Baron, Professor of Psychology, University of Pennsylvania
>> Home page: http://www.sas.upenn.edu/~baron
>> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>>
>



From kushler at oakland.edu  Mon Dec 22 23:15:49 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Mon, 22 Dec 2008 17:15:49 -0500
Subject: [R-sig-ME] mixed model with non-continuous numeric response
In-Reply-To: <a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
References: <a46630750812220354x593cc3f4of35ff5846fe6c90e@mail.gmail.com>	<aefe4d0a0812220440k6f7a063fpa2a981fb951e01d5@mail.gmail.com>
	<a46630750812220441i29d19541kcfab6703a8404c7f@mail.gmail.com>
Message-ID: <49501195.5020500@oakland.edu>


Daniel,

I think one of the ordinal response models discussed in sections 2-4
of chapter 7 of Agresti's "Categorical Data Analysis" (second edition)
would be appropriate here.  Section 12.4 briefly discusses adding random
effects to such models.  It's not clear to me how to accomplish this
using the lme4 package (but of course "This is R.  There is no if. ...").

A fallback strategy would be to run various mixed-effect binary response
models (using different cut points on the ordinal scale) separately, and see
how consistent the results are.

You may find the "lrm" function in Frank Harrell's Design package useful
for some of the alternatives to the cumulative logit model (though it doesn't
handle random effects).

Regards,   Rob Kushler


Daniel Ezra Johnson wrote:
> I don't think this is count data, is it???
> 
> On Mon, Dec 22, 2008 at 12:40 PM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> ( ...,  family="poisson")  is the most used option for count data
>>
>> Reinhold Kliegl
>>
>> On Mon, Dec 22, 2008 at 12:54 PM, Daniel Ezra Johnson
>> <danielezrajohnson at gmail.com> wrote:
>>> Dear all,
>>>
>>> I have survey results where the response is 1, 2, 3, or 4. These can
>>> be thought of as equally-spaced points on a scale, I don't have a
>>> problem with that. (They're actually more like "not at all", "some",
>>> "mostly", "totally"; the subject is judging a stimulus.)
>>>
>>> I want to model crossed random effects for Subject and Item. Am I way
>>> off base in modeling this data with a lmer(family="gaussian") model? I
>>> know it's not perfect, but is it really bad? If so, what could I do
>>> instead? (The error certainly wouldn't be binomial, right?)
>>>
>>> Thanks,
>>> Daniel
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From desja004 at umn.edu  Wed Dec 24 00:10:07 2008
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 23 Dec 2008 17:10:07 -0600
Subject: [R-sig-ME] Bayesian model averaging with lme4?
In-Reply-To: <40e66e0b0812220159q23ed195l26769c6c81d3ec@mail.gmail.com>
References: <494D7CBE.5010801@maw.ru.nl> <494D8754.6090006@ufl.edu>
	<145548a40812210111k5540ea07o29e6f34a037e336e@mail.gmail.com>
	<494E13D7.4010209@maw.ru.nl>
	<40e66e0b0812211046y50577beanbfdcfdf3d3eacf49@mail.gmail.com>
	<494EA0D6.1080300@maw.ru.nl>
	<40e66e0b0812220159q23ed195l26769c6c81d3ec@mail.gmail.com>
Message-ID: <3C460977-3EC2-48AA-8298-766278E9F84D@umn.edu>

Hi,
I was wondering if it's possible to perform Bayesian model averaging  
with linear mixed models with the lme4 package? If not could anyone  
suggest a package that is capable of this.
Cheers,
Chris



From lucianolasala at yahoo.com.ar  Sat Dec 27 03:39:42 2008
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Fri, 26 Dec 2008 18:39:42 -0800 (PST)
Subject: [R-sig-ME] Commonly observed error message in lmer
Message-ID: <340282.82803.qm@web59902.mail.ac4.yahoo.com>

Dear R-people,

It's me again with, maybe, one more silly question for you. As a remainder, I am running version 2.7.1 on Windows Vista. I have small dataset which consists of:

# NestID: nest indicator for each chicken. Siblings sharing the same nest have the same nest indicator.
# Chick: chick indicator consisting of a unique ID for each single chick.
# Year: 1, 2.
# ClutchSize: 1-, 2- , 3-eggs.
# HO: hatching order within each clutch (1, 2, 3?[first, second and third-hatched chick]).
# SibComp: sibling competence: present/ absent (0, 1)
# Death10: death at ten days post-hatch (0, 1)

In order to account for lack of independence at the nest level (many chicks are nested in nest), I'd like to run a GLMM with random slopes and intercepts for nests.

Using lmer, whenever I try to model two-way interaction like specified below: 
 
model1 <- lmer(Death10~HO*ClutchSize+(1|NestID),family=binomial,1)


.... the following error message pops up:  

In mer_finalize(ans, verbose) : gr cannot be computed at initial par (65)

1. What does this error mean? 
 
I look forward to hearing from you soon! 

Best, Luciano



      ____________________________________________________________________________________
?Busc? desde tu celular!

Yahoo! oneSEARCH ahora est? en Claro

http://ar.mobile.yahoo.com/onesearch



From danielezrajohnson at gmail.com  Sat Dec 27 12:22:04 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Sat, 27 Dec 2008 11:22:04 +0000
Subject: [R-sig-ME] Commonly observed error message in lmer
In-Reply-To: <340282.82803.qm@web59902.mail.ac4.yahoo.com>
References: <340282.82803.qm@web59902.mail.ac4.yahoo.com>
Message-ID: <a46630750812270322t333fc0dcg88f4039bc642caaf@mail.gmail.com>

This error came up earlier in the year and Doug Bates wrote:

>This call is returning a warning about evaluation of the gradient at
>the initial values of the parameters.  I'm not sure if it then goes on
>to optimize the approximated deviance.

>If the approximated deviance is not being minimized for this model you
>may want to start with a simpler model, omitting some of the terms in
>the fixed effects.

Your fixed effects don't seem too complicated but there is a certain
inherent non-independence between ClutchSize and HO (hatching order).
For example if ClutchSize is 1 then HO must be 1. I wonder if that's
what's causing the problem?

Maybe you could try fitting separate models for each ClutchSize and
observe the HO effect separately (when ClutchSize > 1)?

You could also add a random slope as you said you wanted, that would
be done with a term (HO|NestID).

Hope this helps,
Dan

On Sat, Dec 27, 2008 at 2:39 AM, Luciano La Sala
<lucianolasala at yahoo.com.ar> wrote:
> Dear R-people,
>
> It's me again with, maybe, one more silly question for you. As a remainder, I am running version 2.7.1 on Windows Vista. I have small dataset which consists of:
>
> # NestID: nest indicator for each chicken. Siblings sharing the same nest have the same nest indicator.
> # Chick: chick indicator consisting of a unique ID for each single chick.
> # Year: 1, 2.
> # ClutchSize: 1-, 2- , 3-eggs.
> # HO: hatching order within each clutch (1, 2, 3 [first, second and third-hatched chick]).
> # SibComp: sibling competence: present/ absent (0, 1)
> # Death10: death at ten days post-hatch (0, 1)
>
> In order to account for lack of independence at the nest level (many chicks are nested in nest), I'd like to run a GLMM with random slopes and intercepts for nests.
>
> Using lmer, whenever I try to model two-way interaction like specified below:
>
> model1 <- lmer(Death10~HO*ClutchSize+(1|NestID),family=binomial,1)
>
>
> .... the following error message pops up:
>
> In mer_finalize(ans, verbose) : gr cannot be computed at initial par (65)
>
> 1. What does this error mean?
>
> I look forward to hearing from you soon!
>
> Best, Luciano
>
>
>
>      ____________________________________________________________________________________
> ?Busc? desde tu celular!
>
> Yahoo! oneSEARCH ahora est? en Claro
>
> http://ar.mobile.yahoo.com/onesearch
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From desja004 at umn.edu  Sat Dec 27 19:40:20 2008
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Sat, 27 Dec 2008 12:40:20 -0600
Subject: [R-sig-ME] Matrix messages when loading lme4
Message-ID: <756D40D9-AD56-4ADE-AFEF-A6CD65145B4E@umn.edu>

Hi,
I presume these messages are benign but I thought I'd find out what  
they are referring to ...

 > library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 xtabs


	The following object(s) are masked from package:base :

	 colMeans,
	 colSums,
	 rcond,
	 rowMeans,
	 rowSums



-----------------
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://blog.lib.umn.edu/desja004/educationalpsychology/



From danielezrajohnson at gmail.com  Sat Dec 27 20:06:49 2008
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Sat, 27 Dec 2008 19:06:49 +0000
Subject: [R-sig-ME] Matrix messages when loading lme4
In-Reply-To: <756D40D9-AD56-4ADE-AFEF-A6CD65145B4E@umn.edu>
References: <756D40D9-AD56-4ADE-AFEF-A6CD65145B4E@umn.edu>
Message-ID: <a46630750812271106s3aa096a1kef32e1fcd6021cd3@mail.gmail.com>

It means that the Matrix package includes functions with the names
listed, which as long as Matrix is loaded, supersede the original
versions of those functions in the base and stats packages.

If you look at one of the help pages, it should explain the change to
the function. Usually this is some additional functionality and the
function should be usable as before, if desired.

For example, ?xtabs (or ?Matrix::xtabs) gives this notice: "This is a
fully compatible extension of the standard stats package xtabs()
function with the added option to produce a sparse matrix result via
sparse = TRUE."

Hope this helps,
Dan



From desja004 at umn.edu  Sat Dec 27 22:18:43 2008
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Sat, 27 Dec 2008 15:18:43 -0600
Subject: [R-sig-ME] Matrix messages when loading lme4
In-Reply-To: <a46630750812271106s3aa096a1kef32e1fcd6021cd3@mail.gmail.com>
References: <756D40D9-AD56-4ADE-AFEF-A6CD65145B4E@umn.edu>
	<a46630750812271106s3aa096a1kef32e1fcd6021cd3@mail.gmail.com>
Message-ID: <05A96BCA-4D14-46DA-B557-763D2AF5B747@umn.edu>

Thanks that's very helpful.
Chris

On Dec 27, 2008, at 1:06 PM, Daniel Ezra Johnson wrote:

> It means that the Matrix package includes functions with the names
> listed, which as long as Matrix is loaded, supersede the original
> versions of those functions in the base and stats packages.
>
> If you look at one of the help pages, it should explain the change to
> the function. Usually this is some additional functionality and the
> function should be usable as before, if desired.
>
> For example, ?xtabs (or ?Matrix::xtabs) gives this notice: "This is a
> fully compatible extension of the standard stats package xtabs()
> function with the added option to produce a sparse matrix result via
> sparse = TRUE."
>
> Hope this helps,
> Dan

-----------------
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://blog.lib.umn.edu/desja004/educationalpsychology/



From lucianolasala at yahoo.com.ar  Sun Dec 28 17:41:33 2008
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sun, 28 Dec 2008 08:41:33 -0800 (PST)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 24, Issue 38
In-Reply-To: <mailman.3.1230462001.17612.r-sig-mixed-models@r-project.org>
Message-ID: <469965.72621.qm@web59902.mail.ac4.yahoo.com>

Dan, 
Thank you very much for your time and assistance. I think you may be right about lack of independence between ClutchSize and HO being the problem here.. I tried random slopes already, but my model fails to converge due to small sample size. I should try different models for different clutch sizes and see what happens.

Cheers!

Lucho      

--- El dom 28-dic-08, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> escribi?:

> De: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Asunto: R-sig-mixed-models Digest, Vol 24, Issue 38
> Para: r-sig-mixed-models at r-project.org
> Fecha: domingo, 28 de diciembre de 2008, 11:00 am
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body
> 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models
> digest..."
> 
> 
> Today's Topics:
> 
>    1. Re: Commonly observed error message in lmer (Daniel
> Ezra Johnson)
>    2. Matrix messages when loading lme4 (Christopher David
> Desjardins)
>    3. Re: Matrix messages when loading lme4 (Daniel Ezra
> Johnson)
>    4. Re: Matrix messages when loading lme4
>       (Christopher David Desjardins)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Sat, 27 Dec 2008 11:22:04 +0000
> From: "Daniel Ezra Johnson"
> <danielezrajohnson at gmail.com>
> Subject: Re: [R-sig-ME] Commonly observed error message in
> lmer
> To: "Luciano La Sala"
> <lucianolasala at yahoo.com.ar>
> Cc: R-mixed models mailing list
> <r-sig-mixed-models at r-project.org>
> Message-ID:
> 	<a46630750812270322t333fc0dcg88f4039bc642caaf at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> This error came up earlier in the year and Doug Bates
> wrote:
> 
> >This call is returning a warning about evaluation of
> the gradient at
> >the initial values of the parameters.  I'm not sure
> if it then goes on
> >to optimize the approximated deviance.
> 
> >If the approximated deviance is not being minimized for
> this model you
> >may want to start with a simpler model, omitting some
> of the terms in
> >the fixed effects.
> 
> Your fixed effects don't seem too complicated but there
> is a certain
> inherent non-independence between ClutchSize and HO
> (hatching order).
> For example if ClutchSize is 1 then HO must be 1. I wonder
> if that's
> what's causing the problem?
> 
> Maybe you could try fitting separate models for each
> ClutchSize and
> observe the HO effect separately (when ClutchSize > 1)?
> 
> You could also add a random slope as you said you wanted,
> that would
> be done with a term (HO|NestID).
> 
> Hope this helps,
> Dan
> 
> On Sat, Dec 27, 2008 at 2:39 AM, Luciano La Sala
> <lucianolasala at yahoo.com.ar> wrote:
> > Dear R-people,
> >
> > It's me again with, maybe, one more silly question
> for you. As a remainder, I am running version 2.7.1 on
> Windows Vista. I have small dataset which consists of:
> >
> > # NestID: nest indicator for each chicken. Siblings
> sharing the same nest have the same nest indicator.
> > # Chick: chick indicator consisting of a unique ID for
> each single chick.
> > # Year: 1, 2.
> > # ClutchSize: 1-, 2- , 3-eggs.
> > # HO: hatching order within each clutch (1, 2, 3
> [first, second and third-hatched chick]).
> > # SibComp: sibling competence: present/ absent (0, 1)
> > # Death10: death at ten days post-hatch (0, 1)
> >
> > In order to account for lack of independence at the
> nest level (many chicks are nested in nest), I'd like to
> run a GLMM with random slopes and intercepts for nests.
> >
> > Using lmer, whenever I try to model two-way
> interaction like specified below:
> >
> > model1 <-
> lmer(Death10~HO*ClutchSize+(1|NestID),family=binomial,1)
> >
> >
> > .... the following error message pops up:
> >
> > In mer_finalize(ans, verbose) : gr cannot be computed
> at initial par (65)
> >
> > 1. What does this error mean?
> >
> > I look forward to hearing from you soon!
> >
> > Best, Luciano
> >
> >
> >
> >     
> ____________________________________________________________________________________
> > ?Busc? desde tu celular!
> >
> > Yahoo! oneSEARCH ahora est? en Claro
> >
> > http://ar.mobile.yahoo.com/onesearch
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Sat, 27 Dec 2008 12:40:20 -0600
> From: Christopher David Desjardins <desja004 at umn.edu>
> Subject: [R-sig-ME] Matrix messages when loading lme4
> To: R-mixed models mailing list
> <r-sig-mixed-models at r-project.org>
> Message-ID:
> <756D40D9-AD56-4ADE-AFEF-A6CD65145B4E at umn.edu>
> Content-Type: text/plain; charset=US-ASCII; format=flowed;
> delsp=yes
> 
> Hi,
> I presume these messages are benign but I thought I'd
> find out what  
> they are referring to ...
> 
>  > library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
> 
> Attaching package: 'Matrix'
> 
> 
> 	The following object(s) are masked from package:stats :
> 
> 	 xtabs
> 
> 
> 	The following object(s) are masked from package:base :
> 
> 	 colMeans,
> 	 colSums,
> 	 rcond,
> 	 rowMeans,
> 	 rowSums
> 
> 
> 
> -----------------
> Christopher David Desjardins
> Ph.D. Student
> Quantitative Methods in Education
> Department of Educational Psychology
> University of  Minnesota
> http://blog.lib.umn.edu/desja004/educationalpsychology/
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Sat, 27 Dec 2008 19:06:49 +0000
> From: "Daniel Ezra Johnson"
> <danielezrajohnson at gmail.com>
> Subject: Re: [R-sig-ME] Matrix messages when loading lme4
> To: "Christopher David Desjardins"
> <desja004 at umn.edu>
> Cc: R-mixed models mailing list
> <r-sig-mixed-models at r-project.org>
> Message-ID:
> 	<a46630750812271106s3aa096a1kef32e1fcd6021cd3 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> It means that the Matrix package includes functions with
> the names
> listed, which as long as Matrix is loaded, supersede the
> original
> versions of those functions in the base and stats packages.
> 
> If you look at one of the help pages, it should explain the
> change to
> the function. Usually this is some additional functionality
> and the
> function should be usable as before, if desired.
> 
> For example, ?xtabs (or ?Matrix::xtabs) gives this notice:
> "This is a
> fully compatible extension of the standard stats package
> xtabs()
> function with the added option to produce a sparse matrix
> result via
> sparse = TRUE."
> 
> Hope this helps,
> Dan
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Sat, 27 Dec 2008 15:18:43 -0600
> From: Christopher David Desjardins <desja004 at umn.edu>
> Subject: Re: [R-sig-ME] Matrix messages when loading lme4
> To: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Cc: R-mixed models mailing list
> <r-sig-mixed-models at r-project.org>
> Message-ID:
> <05A96BCA-4D14-46DA-B557-763D2AF5B747 at umn.edu>
> Content-Type: text/plain; charset=US-ASCII; format=flowed
> 
> Thanks that's very helpful.
> Chris
> 
> On Dec 27, 2008, at 1:06 PM, Daniel Ezra Johnson wrote:
> 
> > It means that the Matrix package includes functions
> with the names
> > listed, which as long as Matrix is loaded, supersede
> the original
> > versions of those functions in the base and stats
> packages.
> >
> > If you look at one of the help pages, it should
> explain the change to
> > the function. Usually this is some additional
> functionality and the
> > function should be usable as before, if desired.
> >
> > For example, ?xtabs (or ?Matrix::xtabs) gives this
> notice: "This is a
> > fully compatible extension of the standard stats
> package xtabs()
> > function with the added option to produce a sparse
> matrix result via
> > sparse = TRUE."
> >
> > Hope this helps,
> > Dan
> 
> -----------------
> Christopher David Desjardins
> Ph.D. Student
> Quantitative Methods in Education
> Department of Educational Psychology
> University of  Minnesota
> http://blog.lib.umn.edu/desja004/educationalpsychology/
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 24, Issue 38
> **************************************************


      Yahoo! Cocina
Recetas pr?cticas y comida saludable
http://ar.mujer.yahoo.com/cocina/



From berkeley3 at gmail.com  Mon Dec 29 09:19:54 2008
From: berkeley3 at gmail.com (paola berchialla)
Date: Mon, 29 Dec 2008 09:19:54 +0100
Subject: [R-sig-ME] error with glmer
Message-ID: <4958882A.9030902@gmail.com>

Dear all, I have some troubles in using lme4 package, glmer function.
Here it is the code I am trying to ran unsuccessfully:

mod.glmer=glmer(Cmis~X_Igruppo_2+X_Igruppo_3+X_Igruppo_4+(1|mon),data=p4,family=Gamma(link='log'))
summary(mod.glmer)

The problem is I get the following error message: Error in 
asMethod(object) : matrix is not symmetric [1,2]
Could someone please explain this error to me? I am using R version 2.7.2



From HStevens at MUOhio.edu  Mon Dec 29 20:29:10 2008
From: HStevens at MUOhio.edu (Hank Stevens)
Date: Mon, 29 Dec 2008 14:29:10 -0500
Subject: [R-sig-ME] error with glmer
In-Reply-To: <4958882A.9030902@gmail.com>
References: <4958882A.9030902@gmail.com>
Message-ID: <DDED50B6-A59A-4884-838E-7CA57797F414@MUOhio.edu>

Hi Paola,
I think you might get more helpful info if you *provide* more info.
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hank


On Dec 29, 2008, at 3:19 AM, paola berchialla wrote:

> Dear all, I have some troubles in using lme4 package, glmer function.
> Here it is the code I am trying to ran unsuccessfully:
>
> mod.glmer=glmer(Cmis~X_Igruppo_2+X_Igruppo_3+X_Igruppo_4+(1| 
> mon),data=p4,family=Gamma(link='log'))
> summary(mod.glmer)
>
> The problem is I get the following error message: Error in
> asMethod(object) : matrix is not symmetric [1,2]
> Could someone please explain this error to me? I am using R version  
> 2.7.2
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/botany/
http://www.cas.muohio.edu/ecology/
http://www.muohio.edu/ecoreu/

"E Pluribus Unum"



From paola.berchialla at unito.it  Mon Dec 29 22:49:18 2008
From: paola.berchialla at unito.it (paola berchialla)
Date: Mon, 29 Dec 2008 22:49:18 +0100
Subject: [R-sig-ME] error with glmer
In-Reply-To: <DDED50B6-A59A-4884-838E-7CA57797F414@MUOhio.edu>
References: <4958882A.9030902@gmail.com>
	<DDED50B6-A59A-4884-838E-7CA57797F414@MUOhio.edu>
Message-ID: <495945DE.3080104@unito.it>

Hi Hank,
I hope to be more clear now.

I am testing the influence of some dental restoration materials
Data, which are positively skewed and clustered, fit the assumption of 
being gamma distributed.

I tried glmer()
 >mod.glmer=glmer(mis~X_Igruppo_2+X_Igruppo_3+X_Igruppo_4+(1|mon),data=p4,family=Gamma(link='log'))

However,
 >summary(mod.glmer)
gives me back the following error message:
Error in asMethod(object) : matrix is not symmetric [1,2]

The same happens when I use lmer() with gamma family. It seems both 
glmer() and lmer() don't work when using gamma family. Did someone else 
experience this problem?

 >sessionInfo()
R version 2.7.2 (2008-08-25)
i386-pc-mingw32

locale:
LC_COLLATE=Italian_Italy.1252;LC_CTYPE=Italian_Italy.1252;LC_MONETARY=Italian_Italy.1252;LC_NUMERIC=C;LC_TIME=Italian_Italy.1252

attached base packages:
[1] stats     graphics  grDevices datasets  tcltk     utils     
methods   base    

other attached packages:
[1] lme4_0.999375-20   Matrix_0.999375-10 lattice_0.17-13    
xlsReadWrite_1.3.2 svSocket_0.9-42    svMisc_0.9-5       
TinnR_1.0.2        R2HTML_1.59      
[9] Hmisc_3.4-3      

loaded via a namespace (and not attached):
[1] cluster_1.11.11 grid_2.7.2      tools_2.7.2  

 > traceback()
15: .Call(dense_to_symmetric, from, "U", TRUE)
14: asMethod(object)
13: as(from, "symmetricMatrix")
12: .class1(object)
11: as(as(from, "symmetricMatrix"), "dMatrix")
10: .class1(object)
9: as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix")
8: .class1(object)
7: as(as(as(as(from, "symmetricMatrix"), "dMatrix"), "denseMatrix"),
       "dpoMatrix")
6: asMethod(object)
5: as(sigma(object)^2 * chol2inv(object at RX, size = object at dims["p"]),
       "dpoMatrix")
4: vcov(object)
3: vcov(object)
2: summary(mod.glmer)
1: summary(mod.glmer)


Hank Stevens wrote:
> Hi Paola,
> I think you might get more helpful info if you *provide* more info.
>>
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hank
>
>
> On Dec 29, 2008, at 3:19 AM, paola berchialla wrote:
>
>> Dear all, I have some troubles in using lme4 package, glmer function.
>> Here it is the code I am trying to ran unsuccessfully:
>>
>> mod.glmer=glmer(Cmis~X_Igruppo_2+X_Igruppo_3+X_Igruppo_4+(1|mon),data=p4,family=Gamma(link='log')) 
>>
>> summary(mod.glmer)
>>
>> The problem is I get the following error message: Error in
>> asMethod(object) : matrix is not symmetric [1,2]
>> Could someone please explain this error to me? I am using R version 
>> 2.7.2
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> Dr. Hank Stevens, Associate Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/botany/
> http://www.cas.muohio.edu/ecology/
> http://www.muohio.edu/ecoreu/
>
> "E Pluribus Unum"
>
>

-- 
------------------------------------------------------------------------------------
Paola Berchialla, PhD
Dept. of Public Health and Microbiology - University of Torino
Mobile: +39 3478768532
E-mail: paola.berchialla at unito.it



From bolker at ufl.edu  Tue Dec 30 17:44:29 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 30 Dec 2008 11:44:29 -0500
Subject: [R-sig-ME] extracting coefficient standard errors
Message-ID: <495A4FED.5030008@ufl.edu>


  Does anyone happen to know a more elegant/robust way
to extract the (approximate) standard errors of fixed
effect parameters than

vcov(mm)@factors$correlation at sd

  ?

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From HDoran at air.org  Tue Dec 30 20:10:32 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 30 Dec 2008 14:10:32 -0500
Subject: [R-sig-ME] extracting coefficient standard errors
References: <495A4FED.5030008@ufl.edu>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE01C649DF@DC1EXCL01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081230/2af5d5e6/attachment.pl>

From bolker at ufl.edu  Tue Dec 30 20:31:55 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 30 Dec 2008 14:31:55 -0500
Subject: [R-sig-ME] extracting coefficient standard errors
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE01C649DF@DC1EXCL01.air.org>
References: <495A4FED.5030008@ufl.edu>
	<ED7B522EE00C9A4FA515AA71724D61EE01C649DF@DC1EXCL01.air.org>
Message-ID: <495A772B.3040101@ufl.edu>


  doh.
  I looked at all the fancy stuff in the summary method
and overlooked the obvious (well, sort of obvious)

  cheers
    Ben

Doran, Harold wrote:
> sqrt(diag(vcov(mm)))
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of Ben Bolker
> Sent: Tue 12/30/2008 11:44 AM
> To: R Mixed Models
> Subject: [R-sig-ME] extracting coefficient standard errors
>  
> 
>   Does anyone happen to know a more elegant/robust way
> to extract the (approximate) standard errors of fixed
> effect parameters than
> 
> vcov(mm)@factors$correlation at sd
> 
>   ?
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From kari.ruohonen at utu.fi  Wed Dec 31 08:57:29 2008
From: kari.ruohonen at utu.fi (Kari Ruohonen)
Date: Wed, 31 Dec 2008 09:57:29 +0200
Subject: [R-sig-ME] extracting coefficient standard errors
In-Reply-To: <495A772B.3040101@ufl.edu>
References: <495A4FED.5030008@ufl.edu>
	<ED7B522EE00C9A4FA515AA71724D61EE01C649DF@DC1EXCL01.air.org>
	<495A772B.3040101@ufl.edu>
Message-ID: <1230710249.23535.7.camel@hume>

There is se.coef() method in the arm package. A special case is
se.fixef().

regards, Kari


On Tue, 2008-12-30 at 14:31 -0500, Ben Bolker wrote:
> doh.
>   I looked at all the fancy stuff in the summary method
> and overlooked the obvious (well, sort of obvious)
> 
>   cheers
>     Ben
> 
> Doran, Harold wrote:
> > sqrt(diag(vcov(mm)))
> > 
> > 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org on behalf of Ben Bolker
> > Sent: Tue 12/30/2008 11:44 AM
> > To: R Mixed Models
> > Subject: [R-sig-ME] extracting coefficient standard errors
> >  
> > 
> >   Does anyone happen to know a more elegant/robust way
> > to extract the (approximate) standard errors of fixed
> > effect parameters than
> > 
> > vcov(mm)@factors$correlation at sd
> > 
> >   ?
> > 
> 
>



From epistat at gmail.com  Wed Dec 31 09:45:41 2008
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 31 Dec 2008 16:45:41 +0800
Subject: [R-sig-ME] Is it right to specify a random slope for the dummy
	variables
Message-ID: <2fc17e30812310045w1c65af69n61878f5468b4f644@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20081231/b8dc35a9/attachment.pl>

From reinhold.kliegl at gmail.com  Wed Dec 31 12:35:21 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 31 Dec 2008 12:35:21 +0100
Subject: [R-sig-ME] Is it right to specify a random slope for the dummy
	variables
In-Reply-To: <2fc17e30812310045w1c65af69n61878f5468b4f644@mail.gmail.com>
References: <2fc17e30812310045w1c65af69n61878f5468b4f644@mail.gmail.com>
Message-ID: <aefe4d0a0812310335p1f454836p7f68ea108b2062ad@mail.gmail.com>

By default, a categorical variable (factor) with n levels comes with
n-1 treatment contrasts. Therefore, in the fixed-effect part of the
model the intercept represents the reference level and the n-1
contrasts represent the mean differences between the other levels and
the reference level, assuming a balanced design. You can check your
specification with contrasts(factor). Of course, you should change
from treatment to other contrasts as required by your hypotheses. See
?contrasts.

Now suppose you have the variable group as random factor in the model
and you include the variable factor also in the random effects part:

lmer(y ~  factor + (factor|group))

Then, you can estimate the variance of the intercept (i.e., variance
of reference level for groups), variances of the n-1  difference
scores for group,  and correlations between intercept and difference
scores as random effects (i.e., you estimate varying intercepts and
varying differences and the correlations between them).

Thus, with categorical variables you are mostly looking at the
variance and correlation of difference scores between levels of a
factor rather than variance and correlation of slopes (which are also
a kind of difference score, of course).

Reinhold Kliegl

On Wed, Dec 31, 2008 at 9:45 AM, zhijie zhang <epistat at gmail.com> wrote:
> Dear all,
>  Today, i was thinking the following question.
> We know the variables may be classified into continuous, ordinal, and
> categorical variables. I was confused about how to handle with
> the categorical variables in the multi-level models.
> For fixed effects,  the categorical variables were always treated as dummy
> variables, my questions are:
> 1. Could the random slope be specified for categorical variables that was
> always changed into the form of  dummy variables?
> 2. If  the random slope could be specified for categorical variables, how to
> explain it? It seems a little different from the continuous variables.
>  I tried the GLIMMIX Procedure in SAS. It seems that SAS treats categorical
> variables as  continuous variables. While in MLWin, it seems that random
> slope could be specified for the dummy variables .
>  Any ideas on it are greatly appreciated.
>
> --
> With Kind Regards,
>
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> [***********************************************************************]
> ZhiJie Zhang ,PhD
> Dept.of Epidemiology, School of Public Health,Fudan University
> Office:Room 443, Building 8
> Office Tel./Fax.:+86-21-54237410
> Address:No. 138 Yi Xue Yuan Road,Shanghai,China
> Postcode:200032
> Email:epistat at gmail.com <Email%3Aepistat at gmail.com>
> Website: www.statABC.com
> [***********************************************************************]
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



