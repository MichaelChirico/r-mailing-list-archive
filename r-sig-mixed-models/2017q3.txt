From jdelia82 at gmail.com  Mon Jul  3 19:52:41 2017
From: jdelia82 at gmail.com (Jesse Delia)
Date: Mon, 3 Jul 2017 13:52:41 -0400
Subject: [R-sig-ME] multinominal2 MCMCglmm: predicted estimates are not
	bounded
Message-ID: <CA+LOm6HeXs+dD91+107Sd++SVf72_HYdvhrErMauPhZqiep44Q@mail.gmail.com>

Dear list,

I'm having issues predicting and plotting values from a model estimated
using MCMCglmm, and was hoping I might be able to trouble someone for help?

My model uses cbind to calculate a proportional response (proportion of an
egg-clutch w/ dry eggs), which should be bounded 0?1. However, I get really
large predicted values (+30) and negative values using a multinomial2
MCMCglmm. I am not sure if this is because of my model specifications, or
how I am using the predict function. I've tried googling, reading course
notes, and meeting with stats folks at my U without any luck.

I have the model results and data sheet saved in an R file, but its too big
to upload to this list. If you think you can have a look let me know and
Ill send it along.

I greatly appreciate any help.

Jesse
PhD student

####
Code:

inv.phylo<-inverseA(tree,nodes="TIPS",scale=TRUE)

priorT<-list(R=list(V=1e-10,nu=-1), G=list(G1=list(V=1,nu=1,alpha.mu=0,
alpha.V=100), G2=list(V=1,nu=1,alpha.mu=0,alpha.V=100)))

modelT<-MCMCglmm(cbind(dry, clutchsize - dry)~careduration*AVErainS17,
random= ~species+animal, family= "multinomial2", ginverse=list(animal=
inv.phylo$Ainv), prior=priorT, data=data, nitt=1000000, burnin=50000, thin
= 300, pr=TRUE, saveX=TRUE, saveZ= TRUE)

predictions <- as.data.frame(predict(modelT, interval="confidence", type=
"response"))

ggplot(data, aes(x = AVErainS17, y = propdry, color = careduration)) +

  ylab("mortality") + xlab("rain")+

  geom_smooth(data=data, aes(x = AVErainS17, y = predictions[,1]))+

  geom_point(aes(shape=species), size=4)

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sun Jul  9 20:38:24 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 9 Jul 2017 19:38:24 +0100
Subject: [R-sig-ME] multinominal2 MCMCglmm: predicted estimates are not
 bounded
In-Reply-To: <CA+LOm6HeXs+dD91+107Sd++SVf72_HYdvhrErMauPhZqiep44Q@mail.gmail.com>
References: <CA+LOm6HeXs+dD91+107Sd++SVf72_HYdvhrErMauPhZqiep44Q@mail.gmail.com>
Message-ID: <343e8d08-79b7-059c-5060-1b6fd863b942@ed.ac.uk>

Hi Jesse,

This behaviour sounds unexpected - can you email me the data and I will 
take a look?

Cheers,

Jarrod


On 03/07/2017 18:52, Jesse Delia wrote:
> Dear list,
>
> I'm having issues predicting and plotting values from a model estimated
> using MCMCglmm, and was hoping I might be able to trouble someone for help?
>
> My model uses cbind to calculate a proportional response (proportion of an
> egg-clutch w/ dry eggs), which should be bounded 0?1. However, I get really
> large predicted values (+30) and negative values using a multinomial2
> MCMCglmm. I am not sure if this is because of my model specifications, or
> how I am using the predict function. I've tried googling, reading course
> notes, and meeting with stats folks at my U without any luck.
>
> I have the model results and data sheet saved in an R file, but its too big
> to upload to this list. If you think you can have a look let me know and
> Ill send it along.
>
> I greatly appreciate any help.
>
> Jesse
> PhD student
>
> ####
> Code:
>
> inv.phylo<-inverseA(tree,nodes="TIPS",scale=TRUE)
>
> priorT<-list(R=list(V=1e-10,nu=-1), G=list(G1=list(V=1,nu=1,alpha.mu=0,
> alpha.V=100), G2=list(V=1,nu=1,alpha.mu=0,alpha.V=100)))
>
> modelT<-MCMCglmm(cbind(dry, clutchsize - dry)~careduration*AVErainS17,
> random= ~species+animal, family= "multinomial2", ginverse=list(animal=
> inv.phylo$Ainv), prior=priorT, data=data, nitt=1000000, burnin=50000, thin
> = 300, pr=TRUE, saveX=TRUE, saveZ= TRUE)
>
> predictions <- as.data.frame(predict(modelT, interval="confidence", type=
> "response"))
>
> ggplot(data, aes(x = AVErainS17, y = propdry, color = careduration)) +
>
>    ylab("mortality") + xlab("rain")+
>
>    geom_smooth(data=data, aes(x = AVErainS17, y = predictions[,1]))+
>
>    geom_point(aes(shape=species), size=4)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From joaquin.aldabe at gmail.com  Tue Jul 11 13:14:42 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 11 Jul 2017 08:14:42 -0300
Subject: [R-sig-ME] Question on random effect
Message-ID: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>

Hi all, when working with mixed models, do the levels of the random effect
have to be independent? For example, if my random effect is the identity of
sites and it is associated to the intercept, do sites have to be
independent?

I appreciate comments and bibliographic references.

Thank you very much in advanced,

Joaquin

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>




<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Libre
de virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jul 11 13:22:00 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 11 Jul 2017 07:22:00 -0400
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
Message-ID: <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>

Yes, the assumption is that the random effects are (conditionally)
independent.  It can help to specify covariates  (such as
latitude/longitude or eastings/northings, or environmental conditions
[temperature, elevation, etc.]) for sites to mop up some of the
independence. It is theoretically possible, although I don't know of
an easy off-the-shelf way to do it, to impose (e.g.) spatial
correlation structures at the level of the random effects ...  or you
could examine the spatial dependence of the conditional modes/random
effects and try to convince yourself it was weak ...

On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:
> Hi all, when working with mixed models, do the levels of the random effect
> have to be independent? For example, if my random effect is the identity of
> sites and it is associated to the intercept, do sites have to be
> independent?
>
> I appreciate comments and bibliographic references.
>
> Thank you very much in advanced,
>
> Joaquin
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Libre
> de virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Tue Jul 11 13:28:13 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 11 Jul 2017 08:28:13 -0300
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
Message-ID: <CAMM93=LTUk9xWA9GhLA7rxMca9R59+BgfVYKJEFwhOGNRoYhQQ@mail.gmail.com>

Thank you Ben. Another question: is there any kind of R2 in mixed models
that allow me to estimate the explanatory power of the model?
Thanks again. Joaquin

2017-07-11 8:22 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> Yes, the assumption is that the random effects are (conditionally)
> independent.  It can help to specify covariates  (such as
> latitude/longitude or eastings/northings, or environmental conditions
> [temperature, elevation, etc.]) for sites to mop up some of the
> independence. It is theoretically possible, although I don't know of
> an easy off-the-shelf way to do it, to impose (e.g.) spatial
> correlation structures at the level of the random effects ...  or you
> could examine the spatial dependence of the conditional modes/random
> effects and try to convince yourself it was weak ...
>
> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Hi all, when working with mixed models, do the levels of the random
> effect
> > have to be independent? For example, if my random effect is the identity
> of
> > sites and it is associated to the intercept, do sites have to be
> > independent?
> >
> > I appreciate comments and bibliographic references.
> >
> > Thank you very much in advanced,
> >
> > Joaquin
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Libre
> > de virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From mervat_moh2006 at yahoo.com  Tue Jul 11 13:28:49 2017
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Tue, 11 Jul 2017 11:28:49 +0000 (UTC)
Subject: [R-sig-ME] Fw: Fw: simulating a linear random intercept model with
 exogeneity assumption
In-Reply-To: <798664270.2713607.1498966782924@mail.yahoo.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
 <66313752.629683.1498069664156@mail.yahoo.com>
 <798664270.2713607.1498966782924@mail.yahoo.com>
Message-ID: <80276192.2660925.1499772529110@mail.yahoo.com>




----- Forwarded Message -----From: mervat mohamed <mervat_moh2006 at yahoo.com>To: mailman-owner at r-project.org <mailman-owner at r-project.org>Sent: Sunday, July 2, 2017, 5:39:42 AM GMT+2Subject: Fw: [R-sig-ME] Fw: simulating a linear random intercept model with exogeneity assumption


     On Wednesday, June 21, 2017 8:27 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
 

 

? Show original message? ? On Monday, June 19, 2017 1:36 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
 

 Hi r-sig group
I want to know how to write the code of simulating a linear random intercept model with following assumptions using R programing:
the model:
yij=b.+b1 xij + u.j + eij, ?where j refer to the group number and i refer to the observation number in the j group
model assumptions:
? 1- xij ~ N (3,1.5)? 2- u.j ~ N (0,1)? 3 - eij ~ N (0,1)? 4 - cov (xij , u.j)=0? 5 - cov (xij , eij)=0
? 6- cov (u.j , eij)= 0
thnx for help
mervat
??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

? _______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Untitled
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170711/0eb71670/attachment.ksh>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Untitled
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170711/0eb71670/attachment-0001.ksh>

From joaquin.aldabe at gmail.com  Tue Jul 11 14:32:25 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 11 Jul 2017 09:32:25 -0300
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
Message-ID: <CAMM93=LVY4SYMn7EZ_WkSa1rx5zAAbcvLwvbQoi_TJ5xDN1TxQ@mail.gmail.com>

Going back to the independence assumption, see your comment and below my
comment (thanks):

Joaqu?n asked: do the levels of the random effect have to be independent?
For example, if my random effect is the identity of sites and it is
associated to the intercept, do sites have to be independent?

Ben said:
Yes, the assumption is that the random effects are (conditionally)
independent.  It can help to specify covariates  (such as
latitude/longitude or eastings/northings, or environmental conditions
[temperature, elevation, etc.]) for sites to mop up some of the
independence. It is theoretically possible, although I don't know of
an easy off-the-shelf way to do it, to impose (e.g.) spatial
correlation structures at the level of the random effects ...  or you
could examine the spatial dependence of the conditional modes/random
effects and try to convince yourself it was weak ...

Joaqu?n current comment: However, I?ve seen that response observations
inside a random effect variable may be correlated, and this can be
quantified by Intraclass Correlation Coefficients (ICCs). Is this lack of
independence among random effect levels?

On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:

2017-07-11 8:22 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> Yes, the assumption is that the random effects are (conditionally)
> independent.  It can help to specify covariates  (such as
> latitude/longitude or eastings/northings, or environmental conditions
> [temperature, elevation, etc.]) for sites to mop up some of the
> independence. It is theoretically possible, although I don't know of
> an easy off-the-shelf way to do it, to impose (e.g.) spatial
> correlation structures at the level of the random effects ...  or you
> could examine the spatial dependence of the conditional modes/random
> effects and try to convince yourself it was weak ...
>
> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Hi all, when working with mixed models, do the levels of the random
> effect
> > have to be independent? For example, if my random effect is the identity
> of
> > sites and it is associated to the intercept, do sites have to be
> > independent?
> >
> > I appreciate comments and bibliographic references.
> >
> > Thank you very much in advanced,
> >
> > Joaquin
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Libre
> > de virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From pierces1 at msu.edu  Tue Jul 11 14:47:42 2017
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 11 Jul 2017 08:47:42 -0400
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CAMM93=LTUk9xWA9GhLA7rxMca9R59+BgfVYKJEFwhOGNRoYhQQ@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
 <CAMM93=LTUk9xWA9GhLA7rxMca9R59+BgfVYKJEFwhOGNRoYhQQ@mail.gmail.com>
Message-ID: <000201d2fa43$e321c640$a96552c0$@msu.edu>

Joaqu?n,

There are a very large number of R2 formulas for mixed models, but they are not all doing the same thing and do not always agree. Be prepared to defend any choice you make. Here are some references. 

Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., & Schabenberger, O. (2008). An R2 statistic for fixed effects in the linear mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:10.1002/sim.3429

Jaeger, B. C., Edwards, L. J., Das, K., & Sen, P. K. (2017). An R2 statistic for fixed effects in the generalized linear mixed model. Journal of Applied Statistics, 44(6), 1086-1105. doi:10.1080/02664763.02662016.01193725

Johnson, P. C. D. (2014). Extension of Nakagawa & Schielzeth's R2 GLMM to random slopes models. Methods in Ecology and Evolution, 5(9), 944-946. doi:10.1111/2041-210X.12225

Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the Conference on Applied Statistics in Agriculture, 17, 148-160. Retrieved from https://urldefense.proofpoint.com/v2/url?u=http-3A__www.ars.usda.gov_sp2UserFiles_ad-5Fhoc_12000000SpatialWorkshop_19KramerSupplRsq.pdf&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=dEfYO8VG_HWacfGbkUWF38w6kNYYVHYjNQca-3cvt28&m=xAL238UzZyrNK2ncSfWTTCX6WI2RUEcC-_31bAF5_1A&s=iRjwqX5RGOT3CuzuRcm_J3Do-EH1F_0eZsOA9afygec&e= 

LaHuis, D. M., Hartman, M. J., Hakoyama, S., & Clark, P. C. (2014). Explained variance measures for multilevel models. Organizational Research Methods, 17(4), 433-451. doi:10.1177/1094428114541701

Liu, H., Zheng, Y., & Shen, J. (2008). Goodness-of-fit measures of R2 for repeated measures mixed effect models. Journal of Applied Statistics, 35, 1081?1092. 

Nakagawa, S., & Schielzeth, H. (2013). A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution, 4(2), 133-142. doi:10.1111/j.2041-210x.2012.00261.x

Nakagawa, S., & Schielzeth, H. (2016). Extending R2 and intra-class correlation coefficient from generalized linear mixed-effects models: capturing and characterizing biological variation. bioRxiv. doi:10.1101/095851

Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable selection in linear mixed models using R2 statistics. Computational Statistics & Data Analysis, 52(4), 1896-1907. doi:10.1016/j.csda.2007.06.006

Roberts, J. K., Monaco, J. P., Stovall, H., & Foster, V. (2011). Explained variance in multilevel models. In J. J. Hox & J. K. Roberts (Eds.), Handbook of advanced multilevel analysis (pp. 219-230). New York, NY: Routledge.

Snijders, T. A. B., & Bosker, R. J. (2012). Multilevel analysis: An introduction to basic and advanced multilevel modeling (2nd ed.). London, UK: Sage.

Xu, R. (2003). Measuring explained variation in linear mixed effects models. Statistics in Medicine, 22(22), 3527-3541. doi:10.1002/sim.1572

Steven J. Pierce
E-mail: pierces1 at msu.edu




-----Original Message-----
From: Joaqu?n Aldabe [mailto:joaquin.aldabe at gmail.com] 
Sent: Tuesday, July 11, 2017 7:28 AM
To: Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Question on random effect

Thank you Ben. Another question: is there any kind of R2 in mixed models
that allow me to estimate the explanatory power of the model?
Thanks again. Joaquin

2017-07-11 8:22 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> Yes, the assumption is that the random effects are (conditionally)
> independent.  It can help to specify covariates  (such as
> latitude/longitude or eastings/northings, or environmental conditions
> [temperature, elevation, etc.]) for sites to mop up some of the
> independence. It is theoretically possible, although I don't know of
> an easy off-the-shelf way to do it, to impose (e.g.) spatial
> correlation structures at the level of the random effects ...  or you
> could examine the spatial dependence of the conditional modes/random
> effects and try to convince yourself it was weak ...
>
> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Hi all, when working with mixed models, do the levels of the random
> effect
> > have to be independent? For example, if my random effect is the identity
> of
> > sites and it is associated to the intercept, do sites have to be
> > independent?
> >
> > I appreciate comments and bibliographic references.
> >
> > Thank you very much in advanced,
> >
> > Joaquin
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.google.com_site_joaquin.aldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=4E2GabsH0uYNzgi6KwKJm21VOed_CDUrndKLvZsFMfU&e= 
> > <https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.google.com_site_perfilprofesionaljoaquinaldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xyFmjWSHFvVOSNRzvUArI_0JOu7EX0JXpv1RAD47-Ko&e=>
> >
> >
> >
> >
> > <https://urldefense.proofpoint.com/v2/url?u=https-3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-5F&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=GOiXl0TYqddzaMmUoHXnK0oDKCy03yPUDeTrxeqyu0s&e=> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Libre
> > de virus. www.avast.com
> > <https://urldefense.proofpoint.com/v2/url?u=https-3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-5F&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=GOiXl0TYqddzaMmUoHXnK0oDKCy03yPUDeTrxeqyu0s&e=> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xOY180VimZZ1_V44Ek9uIWIcWC9oUEj5gdhqDFEDtJo&e= 
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.google.com_site_joaquin.aldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=4E2GabsH0uYNzgi6KwKJm21VOed_CDUrndKLvZsFMfU&e= 
<https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.google.com_site_perfilprofesionaljoaquinaldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xyFmjWSHFvVOSNRzvUArI_0JOu7EX0JXpv1RAD47-Ko&e=>

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Tue Jul 11 14:53:21 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 11 Jul 2017 09:53:21 -0300
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <000201d2fa43$e321c640$a96552c0$@msu.edu>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
 <CAMM93=LTUk9xWA9GhLA7rxMca9R59+BgfVYKJEFwhOGNRoYhQQ@mail.gmail.com>
 <000201d2fa43$e321c640$a96552c0$@msu.edu>
Message-ID: <CAMM93=J5wxek8Q2NNSX_S0FpabVjEss9wkQ__6=X-0GMB1s0Yg@mail.gmail.com>

Thankyou very much Steven! this is great help.
Cheers,
Joaqu?n.

2017-07-11 9:47 GMT-03:00 Steven J. Pierce <pierces1 at msu.edu>:

> Joaqu?n,
>
> There are a very large number of R2 formulas for mixed models, but they
> are not all doing the same thing and do not always agree. Be prepared to
> defend any choice you make. Here are some references.
>
> Edwards, L. J., Muller, K. E., Wolfinger, R. D., Qaqish, B. F., &
> Schabenberger, O. (2008). An R2 statistic for fixed effects in the linear
> mixed model. Statistics in Medicine, 27(29), 6137-6157. doi:10.1002/sim.3429
>
> Jaeger, B. C., Edwards, L. J., Das, K., & Sen, P. K. (2017). An R2
> statistic for fixed effects in the generalized linear mixed model. Journal
> of Applied Statistics, 44(6), 1086-1105. doi:10.1080/02664763.02662016.
> 01193725
>
> Johnson, P. C. D. (2014). Extension of Nakagawa & Schielzeth's R2 GLMM to
> random slopes models. Methods in Ecology and Evolution, 5(9), 944-946.
> doi:10.1111/2041-210X.12225
>
> Kramer, M. (2005). R2 statistics for mixed models. Proceedings of the
> Conference on Applied Statistics in Agriculture, 17, 148-160. Retrieved
> from https://urldefense.proofpoint.com/v2/url?u=http-3A__www.ars.
> usda.gov_sp2UserFiles_ad-5Fhoc_12000000SpatialWorkshop_
> 19KramerSupplRsq.pdf&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=oWPX5qlfffXiVV_
> GUw6XfiFzgvZaW1Z21RgAeOJfW1A&m=Uc04YW3KXsYZCbVsPoWqHdWzhNglmq
> 0ndvtDjCKLF9I&s=6qqs7Vr-WbE2YW1X6OE7_35mJ09siJR077ygMnE2hr0&e=
>
> LaHuis, D. M., Hartman, M. J., Hakoyama, S., & Clark, P. C. (2014).
> Explained variance measures for multilevel models. Organizational Research
> Methods, 17(4), 433-451. doi:10.1177/1094428114541701
>
> Liu, H., Zheng, Y., & Shen, J. (2008). Goodness-of-fit measures of R2 for
> repeated measures mixed effect models. Journal of Applied Statistics, 35,
> 1081?1092.
>
> Nakagawa, S., & Schielzeth, H. (2013). A general and simple method for
> obtaining R2 from generalized linear mixed-effects models. Methods in
> Ecology and Evolution, 4(2), 133-142. doi:10.1111/j.2041-210x.2012.00261.x
>
> Nakagawa, S., & Schielzeth, H. (2016). Extending R2 and intra-class
> correlation coefficient from generalized linear mixed-effects models:
> capturing and characterizing biological variation. bioRxiv.
> doi:10.1101/095851
>
> Orelien, J. G., & Edwards, L. J. (2008). Fixed-effect variable selection
> in linear mixed models using R2 statistics. Computational Statistics & Data
> Analysis, 52(4), 1896-1907. doi:10.1016/j.csda.2007.06.006
>
> Roberts, J. K., Monaco, J. P., Stovall, H., & Foster, V. (2011). Explained
> variance in multilevel models. In J. J. Hox & J. K. Roberts (Eds.),
> Handbook of advanced multilevel analysis (pp. 219-230). New York, NY:
> Routledge.
>
> Snijders, T. A. B., & Bosker, R. J. (2012). Multilevel analysis: An
> introduction to basic and advanced multilevel modeling (2nd ed.). London,
> UK: Sage.
>
> Xu, R. (2003). Measuring explained variation in linear mixed effects
> models. Statistics in Medicine, 22(22), 3527-3541. doi:10.1002/sim.1572
>
> Steven J. Pierce
> E-mail: pierces1 at msu.edu
>
>
>
>
> -----Original Message-----
> From: Joaqu?n Aldabe [mailto:joaquin.aldabe at gmail.com]
> Sent: Tuesday, July 11, 2017 7:28 AM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Question on random effect
>
> Thank you Ben. Another question: is there any kind of R2 in mixed models
> that allow me to estimate the explanatory power of the model?
> Thanks again. Joaquin
>
> 2017-07-11 8:22 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>
> > Yes, the assumption is that the random effects are (conditionally)
> > independent.  It can help to specify covariates  (such as
> > latitude/longitude or eastings/northings, or environmental conditions
> > [temperature, elevation, etc.]) for sites to mop up some of the
> > independence. It is theoretically possible, although I don't know of
> > an easy off-the-shelf way to do it, to impose (e.g.) spatial
> > correlation structures at the level of the random effects ...  or you
> > could examine the spatial dependence of the conditional modes/random
> > effects and try to convince yourself it was weak ...
> >
> > On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
> > <joaquin.aldabe at gmail.com> wrote:
> > > Hi all, when working with mixed models, do the levels of the random
> > effect
> > > have to be independent? For example, if my random effect is the
> identity
> > of
> > > sites and it is associated to the intercept, do sites have to be
> > > independent?
> > >
> > > I appreciate comments and bibliographic references.
> > >
> > > Thank you very much in advanced,
> > >
> > > Joaquin
> > >
> > > --
> > > *Joaqu?n Aldabe*
> > >
> > > *Grupo Biodiversidad, Ambiente y Sociedad*
> > > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> > >
> > > *Departamento de Conservaci?n*
> > > Aves Uruguay
> > > BirdLife International
> > > Canelones 1164, Montevideo
> > >
> > > https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.
> google.com_site_joaquin.aldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=
> 91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=
> 4E2GabsH0uYNzgi6KwKJm21VOed_CDUrndKLvZsFMfU&e=
> > > <https://urldefense.proofpoint.com/v2/url?u=https-
> 3A__sites.google.com_site_perfilprofesionaljoaquinaldabe
> &d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_
> CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xyFmjWSHFvVOSNRzvUArI_
> 0JOu7EX0JXpv1RAD47-Ko&e=>
> > >
> > >
> > >
> > >
> > > <https://urldefense.proofpoint.com/v2/url?u=https-
> 3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-
> 5F&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_
> CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=GOiXl0TYqddzaMmUoHXnK0oDKCy03y
> PUDeTrxeqyu0s&e=> source=link&utm_campaign=sig-email&utm_content=webmail>
> > > Libre
> > > de virus. www.avast.com
> > > <https://urldefense.proofpoint.com/v2/url?u=https-
> 3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-
> 5F&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_
> CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=GOiXl0TYqddzaMmUoHXnK0oDKCy03y
> PUDeTrxeqyu0s&e=> source=link&utm_campaign=sig-email&utm_content=webmail>
> > > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
> ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwIFaQ&c=nE__W8dFE-
> shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_
> CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xOY180VimZZ1_
> V44Ek9uIWIcWC9oUEj5gdhqDFEDtJo&e=
> >
>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__sites.
> google.com_site_joaquin.aldabe&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=
> 91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=
> 4E2GabsH0uYNzgi6KwKJm21VOed_CDUrndKLvZsFMfU&e=
> <https://urldefense.proofpoint.com/v2/url?u=https-
> 3A__sites.google.com_site_perfilprofesionaljoaquinaldabe
> &d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=24dsaoDyY_
> CXfDoG4FHJ8uJTg6EfLMmvkb3_YnSkDEU&s=xyFmjWSHFvVOSNRzvUArI_
> 0JOu7EX0JXpv1RAD47-Ko&e=>
>
>         [[alternative HTML version deleted]]
>
>
>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jul 11 18:14:32 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 11 Jul 2017 12:14:32 -0400
Subject: [R-sig-ME] Can you solve a debate between colleagues?
In-Reply-To: <65271CEC-477D-482A-9C71-EE7F2440C8A7@cardiff.ac.uk>
References: <65271CEC-477D-482A-9C71-EE7F2440C8A7@cardiff.ac.uk>
Message-ID: <c77cae7a-5fec-ac5f-9fe7-989ec4fb3294@mcmaster.ca>


  Hi Joanne (please call me Ben),

  I'm going to take the liberty of cc'ing this to the
r-sig-mixed-model at r-project.org list, since it's of general interest
(that's usually a good venue for this kind of question -- you do need to
subscribe to post easily, at
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models ).

The key clause below is "that are fitted by REML".  Since lme4 doesn't
use REML for *generalized* linear mixed models as fitted by glmer
(indeed, there is not a universally accepted definition of REML for
GLMMs: see
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#reml-for-glmms),
the statement you give doesn't apply to GLMMs.

  cheers
   Ben Bolker

On 17-07-10 10:33 AM, Joanne Lello wrote:
> Dear Prof Bolker, 
> 
> I am a lecturer in Biosciences at Cardiff University where (along with
> my colleague mentioned below) we do a fair amount of statistics
> teaching, but we ourselves are not statisticians and have learned ?on
> the job? as it were. I would like to think we have a reasonable depth of
> understanding but it is gleaned from many different places and of course
> sometimes the sources contradict one another. I have recently moved to
> using glmer in R (previously I used ASREML for my mixed modelling). As a
> result of reading around the use of this package I came across a number
> of sources, including your own quote below, which state that using AIC
> to compare the fixed model is useless. 
> 
>  ?...using likelihood-based methods (including AIC) to compare two
> models with different fixed effects that are fitted by REML will
> generally lead to nonsense.?
> 
> I have been debating this point with my colleague; she is convinced that
> this does not apply if the fixed models being compared are nested. 
> 
> e.g. glmer(y ~ a + b + (1|d), data = dframe1) 
> 
> may be compared via AIC with 
> 
> glmer(y ~ a  + (1|d), data = dframe1)  
> 
> but could not be compared with 
> 
> glmer(y ~ a + f + (1|d), data = dframe1) 
> 
> I had read your comments (and others) to mean that AIC could not be used
> to assess the fixed terms in either scenario. 
> 
> We would be very grateful if you could advise on which interpretation is
> correct
> 
> Sincerely
> 
> Joanne Lello


From thierry.onkelinx at inbo.be  Wed Jul 12 09:46:08 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 12 Jul 2017 09:46:08 +0200
Subject: [R-sig-ME] Fw: Fw: simulating a linear random intercept model
 with exogeneity assumption
In-Reply-To: <80276192.2660925.1499772529110@mail.yahoo.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
 <66313752.629683.1498069664156@mail.yahoo.com>
 <798664270.2713607.1498966782924@mail.yahoo.com>
 <80276192.2660925.1499772529110@mail.yahoo.com>
Message-ID: <CAJuCY5wsO7bsLqBSFAVvnOqkN6UkROHqqoA-Xbyais7h1mmaNw@mail.gmail.com>

Dear Mervat,

This the r-sig-mixed-models mailing list. Not the write-code-for-me mailing
list. Please show us what you have tried. This can easily be solved using
expand.grid() and rnorm().

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-11 13:28 GMT+02:00 mervat mohamed via R-sig-mixed-models <
r-sig-mixed-models at r-project.org>:

>
>
>
> ----- Forwarded Message -----From: mervat mohamed <
> mervat_moh2006 at yahoo.com>To: mailman-owner at r-project.org <
> mailman-owner at r-project.org>Sent: Sunday, July 2, 2017, 5:39:42 AM
> GMT+2Subject: Fw: [R-sig-ME] Fw: simulating a linear random intercept model
> with exogeneity assumption
>
>
>      On Wednesday, June 21, 2017 8:27 PM, mervat mohamed via
> R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
>
>
>
>
>   Show original message    On Monday, June 19, 2017 1:36 PM, mervat
> mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
>
>
>  Hi r-sig group
> I want to know how to write the code of simulating a linear random
> intercept model with following assumptions using R programing:
> the model:
> yij=b.+b1 xij + u.j + eij,  where j refer to the group number and i refer
> to the observation number in the j group
> model assumptions:
>   1- xij ~ N (3,1.5)  2- u.j ~ N (0,1)  3 - eij ~ N (0,1)  4 - cov (xij ,
> u.j)=0  5 - cov (xij , eij)=0
>   6- cov (u.j , eij)= 0
> thnx for help
> mervat
>     [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>   _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jul 12 10:02:50 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 12 Jul 2017 10:02:50 +0200
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
Message-ID: <CAJuCY5zmn3PY=9aGFYp5yEnzoCAB7EBtca1gRxxGY1iqWrwHdw@mail.gmail.com>

Dear Joaquin and Ben,

AFAIK have most random effects a term which is i.i.d. The random effects in
nlme and lme4 directly use the i.i.d. term: x_i ~ N(0, \sigma), hence the
random effect itself is i.i.d. INLA has some other constructs available.
e.g. a first order random walk where x_i - x_{i-1} ~ N(0, \sigma). Here the
difference between to consecutive random effects is i.i.d. but the random
effect itself isn't. The available options are listed at
http://www.r-inla.org/models/latent-models

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-11 13:22 GMT+02:00 Ben Bolker <bbolker at gmail.com>:

> Yes, the assumption is that the random effects are (conditionally)
> independent.  It can help to specify covariates  (such as
> latitude/longitude or eastings/northings, or environmental conditions
> [temperature, elevation, etc.]) for sites to mop up some of the
> independence. It is theoretically possible, although I don't know of
> an easy off-the-shelf way to do it, to impose (e.g.) spatial
> correlation structures at the level of the random effects ...  or you
> could examine the spatial dependence of the conditional modes/random
> effects and try to convince yourself it was weak ...
>
> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
> <joaquin.aldabe at gmail.com> wrote:
> > Hi all, when working with mixed models, do the levels of the random
> effect
> > have to be independent? For example, if my random effect is the identity
> of
> > sites and it is associated to the intercept, do sites have to be
> > independent?
> >
> > I appreciate comments and bibliographic references.
> >
> > Thank you very much in advanced,
> >
> > Joaquin
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Libre
> > de virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jul 12 10:43:09 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Wed, 12 Jul 2017 08:43:09 +0000
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <CAJuCY5zmn3PY=9aGFYp5yEnzoCAB7EBtca1gRxxGY1iqWrwHdw@mail.gmail.com>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
 <CAJuCY5zmn3PY=9aGFYp5yEnzoCAB7EBtca1gRxxGY1iqWrwHdw@mail.gmail.com>
Message-ID: <2b1938c28b7b4daea0af5b750dd5f1d0@UM-MAIL3216.unimaas.nl>

Another example where random effects are not assumed to be independent is phylogenetic models. Based on a phylogeny, we can construct a correlation matrix that indicates the phylogenetic relatedness of the species. Random effects for species are then assumed to be correlated accordingly.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>On Behalf Of Thierry Onkelinx
>Sent: Wednesday, July 12, 2017 10:03
>To: Ben Bolker
>Cc: r-sig-mixed-models
>Subject: Re: [R-sig-ME] Question on random effect
>
>Dear Joaquin and Ben,
>
>AFAIK have most random effects a term which is i.i.d. The random effects
>in
>nlme and lme4 directly use the i.i.d. term: x_i ~ N(0, \sigma), hence the
>random effect itself is i.i.d. INLA has some other constructs available.
>e.g. a first order random walk where x_i - x_{i-1} ~ N(0, \sigma). Here
>the
>difference between to consecutive random effects is i.i.d. but the random
>effect itself isn't. The available options are listed at
>http://www.r-inla.org/models/latent-models
>
>Best regards,
>
>ir. Thierry Onkelinx
>Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>Forest
>team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>Kliniekstraat 25
>1070 Anderlecht
>Belgium
>
>To call in the statistician after the experiment is done may be no more
>than asking him to perform a post-mortem examination: he may be able to
>say
>what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner
>The combination of some data and an aching desire for an answer does not
>ensure that a reasonable answer can be extracted from a given body of
>data.
>~ John Tukey
>
>2017-07-11 13:22 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
>
>> Yes, the assumption is that the random effects are (conditionally)
>> independent.  It can help to specify covariates  (such as
>> latitude/longitude or eastings/northings, or environmental conditions
>> [temperature, elevation, etc.]) for sites to mop up some of the
>> independence. It is theoretically possible, although I don't know of
>> an easy off-the-shelf way to do it, to impose (e.g.) spatial
>> correlation structures at the level of the random effects ...  or you
>> could examine the spatial dependence of the conditional modes/random
>> effects and try to convince yourself it was weak ...
>>
>> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
>> <joaquin.aldabe at gmail.com> wrote:
>> > Hi all, when working with mixed models, do the levels of the random
>> effect
>> > have to be independent? For example, if my random effect is the
>identity
>> of
>> > sites and it is associated to the intercept, do sites have to be
>> > independent?
>> >
>> > I appreciate comments and bibliographic references.
>> >
>> > Thank you very much in advanced,
>> >
>> > Joaquin
>> >
>> > --
>> > *Joaqu?n Aldabe*
>> >
>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >
>> > *Departamento de Conservaci?n*
>> > Aves Uruguay
>> > BirdLife International
>> > Canelones 1164, Montevideo
>> >
>> > https://sites.google.com/site/joaquin.aldabe
>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From mervat_moh2006 at yahoo.com  Wed Jul 12 10:51:23 2017
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Wed, 12 Jul 2017 08:51:23 +0000 (UTC)
Subject: [R-sig-ME] Fw: Fw: simulating a linear random intercept model
 with exogeneity assumption
In-Reply-To: <CAJuCY5wsO7bsLqBSFAVvnOqkN6UkROHqqoA-Xbyais7h1mmaNw@mail.gmail.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
 <66313752.629683.1498069664156@mail.yahoo.com>
 <798664270.2713607.1498966782924@mail.yahoo.com>
 <80276192.2660925.1499772529110@mail.yahoo.com>
 <CAJuCY5wsO7bsLqBSFAVvnOqkN6UkROHqqoA-Xbyais7h1mmaNw@mail.gmail.com>
Message-ID: <1222277500.3337899.1499849483450@mail.yahoo.com>

dear ir. Thierry Onkelinx
thank you for your advise , my program code is as follows:
## The code of the program

# yj[i] = b0j+ b1*xj[i]+ej[i]
# b0j = b0 + u0j, u0j ~ N(0,1)??????????????random intercept
# b1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ????? ? ? ? ? ?????? fixed slope
# -- load the used package
library(lme4)

set.seed(1)

????n=200000????? ?? ? ? ? ? ? ? ? ? ? ?? ? ##??the total size of the simulated population
????grp=100??????? ? ? ? ? ? ? ? ? ? ? ? ? ?? ##??the number of groups of the simulated population
????nindiv=2000??????????????????????????? ##??the number of observations in each group
????b0=2?????????? ? ? ? ? ? ? ? ? ? ? ? ??? ? ##??intercept
????b1=0.2?????? ? ? ? ? ? ? ? ? ?? ? ? ?? ?? ##??slope of X
??? u = rnorm(grp,0,0.05)
????e = rnorm(nindiv*grp,1)
????M.x=rnorm(grp,3,0.05)
????sigma<-diag(grp)????? ? ? ? ? ???? ## identity matrix
????require(MASS)
????x=mvrnorm(nindiv,M.x,sigma)
????X=as.vector(x)
????data.set = data.frame(group.id = rep(1:grp, each=nindiv),
??????????????????u = rep(u, each=nindiv),
??????????????????M.x = rep(M.x, each=nindiv),
??????????????????indiv.id = 1:(nindiv*grp),
??????????????????X = X,
??????????????????e = e)
??? data.set$Y = b0 + b1*data.set$X + b2*data.set$mean.X+ data.set$u + data.set$e

????indiv<- data.frame(data.set$group.id,data.set$X,data.set$Y)????? ??? names(indiv)<-c("group.id","X","Y")
my problem is i do not know how can i write the command of the independence between X and the error terms of the two levels of the model (e and u ) in my program code.
and i appreciate your help
thanks mervat? 

On Wednesday, July 12, 2017, 9:46:10 AM GMT+2, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

Dear Mervat,
This the r-sig-mixed-models mailing list. Not the write-code-for-me mailing list. Please show us what you have tried. This can easily be solved using expand.grid() and rnorm().
Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
2017-07-11 13:28 GMT+02:00 mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:




----- Forwarded Message -----From: mervat mohamed <mervat_moh2006 at yahoo.com>To: mailman-owner at r-project.org <mailman-owner at r-project.org> Sent: Sunday, July 2, 2017, 5:39:42 AM GMT+2Subject: Fw: [R-sig-ME] Fw: simulating a linear random intercept model with exogeneity assumption


? ? ?On Wednesday, June 21, 2017 8:27 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org> wrote:




? Show original message? ? On Monday, June 19, 2017 1:36 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org> wrote:


?Hi r-sig group
I want to know how to write the code of simulating a linear random intercept model with following assumptions using R programing:
the model:
yij=b.+b1 xij + u.j + eij, ?where j refer to the group number and i refer to the observation number in the j group
model assumptions:
? 1- xij ~ N (3,1.5)? 2- u.j ~ N (0,1)? 3 - eij ~ N (0,1)? 4 - cov (xij , u.j)=0? 5 - cov (xij , eij)=0
? 6- cov (u.j , eij)= 0
thnx for help
mervat
??? [[alternative HTML version deleted]]

______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models

? ______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models

? ?
______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From arives at wisc.edu  Wed Jul 12 13:07:26 2017
From: arives at wisc.edu (Anthony R. Ives)
Date: Wed, 12 Jul 2017 11:07:26 +0000
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <2b1938c28b7b4daea0af5b750dd5f1d0@UM-MAIL3216.unimaas.nl>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
 <CAJuCY5zmn3PY=9aGFYp5yEnzoCAB7EBtca1gRxxGY1iqWrwHdw@mail.gmail.com>
 <2b1938c28b7b4daea0af5b750dd5f1d0@UM-MAIL3216.unimaas.nl>
Message-ID: <9C8B4575-BD22-4FA4-AB18-474F464A1C19@wisc.edu>

I find that the easiest way to think about this is in terms of the covariance matrix of the residuals. For LMMs, the random effects (which themselves are independent) produce block-diagonal covariance matrices, with positive covariances among residuals within the same level of a random effect. Phylogenetic relationships will also produce positive off-diagonal elements in the covariance matrix. Focusing on the structure of the covariance matrix of residuals often gives the clearest picture of the overall assumptions of a model.

Cheers, Tony

On 7/12/17, 3:43 AM, "R-sig-mixed-models on behalf of Viechtbauer Wolfgang (SP)" <r-sig-mixed-models-bounces at r-project.org on behalf of wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

    Another example where random effects are not assumed to be independent is phylogenetic models. Based on a phylogeny, we can construct a correlation matrix that indicates the phylogenetic relatedness of the species. Random effects for species are then assumed to be correlated accordingly.
    
    Best,
    Wolfgang
    
    -- 
    Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
    Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
    Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    
    
    >-----Original Message-----
    >From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
    >On Behalf Of Thierry Onkelinx
    >Sent: Wednesday, July 12, 2017 10:03
    >To: Ben Bolker
    >Cc: r-sig-mixed-models
    >Subject: Re: [R-sig-ME] Question on random effect
    >
    >Dear Joaquin and Ben,
    >
    >AFAIK have most random effects a term which is i.i.d. The random effects
    >in
    >nlme and lme4 directly use the i.i.d. term: x_i ~ N(0, \sigma), hence the
    >random effect itself is i.i.d. INLA has some other constructs available.
    >e.g. a first order random walk where x_i - x_{i-1} ~ N(0, \sigma). Here
    >the
    >difference between to consecutive random effects is i.i.d. but the random
    >effect itself isn't. The available options are listed at
    >http://www.r-inla.org/models/latent-models
    >
    >Best regards,
    >
    >ir. Thierry Onkelinx
    >Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
    >Forest
    >team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
    >Kliniekstraat 25
    >1070 Anderlecht
    >Belgium
    >
    >To call in the statistician after the experiment is done may be no more
    >than asking him to perform a post-mortem examination: he may be able to
    >say
    >what the experiment died of. ~ Sir Ronald Aylmer Fisher
    >The plural of anecdote is not data. ~ Roger Brinner
    >The combination of some data and an aching desire for an answer does not
    >ensure that a reasonable answer can be extracted from a given body of
    >data.
    >~ John Tukey
    >
    >2017-07-11 13:22 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
    >
    >> Yes, the assumption is that the random effects are (conditionally)
    >> independent.  It can help to specify covariates  (such as
    >> latitude/longitude or eastings/northings, or environmental conditions
    >> [temperature, elevation, etc.]) for sites to mop up some of the
    >> independence. It is theoretically possible, although I don't know of
    >> an easy off-the-shelf way to do it, to impose (e.g.) spatial
    >> correlation structures at the level of the random effects ...  or you
    >> could examine the spatial dependence of the conditional modes/random
    >> effects and try to convince yourself it was weak ...
    >>
    >> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
    >> <joaquin.aldabe at gmail.com> wrote:
    >> > Hi all, when working with mixed models, do the levels of the random
    >> effect
    >> > have to be independent? For example, if my random effect is the
    >identity
    >> of
    >> > sites and it is associated to the intercept, do sites have to be
    >> > independent?
    >> >
    >> > I appreciate comments and bibliographic references.
    >> >
    >> > Thank you very much in advanced,
    >> >
    >> > Joaquin
    >> >
    >> > --
    >> > *Joaqu?n Aldabe*
    >> >
    >> > *Grupo Biodiversidad, Ambiente y Sociedad*
    >> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
    >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
    >> >
    >> > *Departamento de Conservaci?n*
    >> > Aves Uruguay
    >> > BirdLife International
    >> > Canelones 1164, Montevideo
    >> >
    >> > https://sites.google.com/site/joaquin.aldabe
    >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Wed Jul 12 16:01:59 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 12 Jul 2017 16:01:59 +0200
Subject: [R-sig-ME] Fw: Fw: simulating a linear random intercept model
 with exogeneity assumption
In-Reply-To: <1222277500.3337899.1499849483450@mail.yahoo.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
 <66313752.629683.1498069664156@mail.yahoo.com>
 <798664270.2713607.1498966782924@mail.yahoo.com>
 <80276192.2660925.1499772529110@mail.yahoo.com>
 <CAJuCY5wsO7bsLqBSFAVvnOqkN6UkROHqqoA-Xbyais7h1mmaNw@mail.gmail.com>
 <1222277500.3337899.1499849483450@mail.yahoo.com>
Message-ID: <CAJuCY5xzvMWKOpG7fVXfwkOwoiMn+6raaOyHBWdXAahWmLrgOg@mail.gmail.com>

Dear Mervat,

Here is how I would write it. No need for the multivariate rnorm since you
set all covariances are zero, making them independent. All rnorm() are by
default independent so need for a special command to make them independent.

library(dplyr)
grp <- 10
nindiv <- 20
b0 <- 2
b <- 0.2
u <- rnorm(grp, mean = 0, sd = 0.05)
e <- rnorm(grp * nindiv, mean = 0, sd = 1)
expand.grid(
  group = seq_len(grp),
  individual = seq_len(nindiv)
) %>%
  mutate(
    X = rnorm(n(), mean = 0, sd = 1),
    id = interaction(group, individual),
    mu = b0 + b * X + u[group],
    y = mu + e
  )

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-12 10:51 GMT+02:00 mervat mohamed <mervat_moh2006 at yahoo.com>:

> dear ir. Thierry Onkelinx
>
> thank you for your advise , my program code is as follows:
>
> ## The code of the program
>
> # yj[i] = b0j+ b1*xj[i]+ej[i]
> # b0j = b0 + u0j, u0j ~ N(0,1)              random intercept
> # b1                                                    fixed slope
> # -- load the used package
> library(lme4)
>
> set.seed(1)
>
>     n=200000                                ##  the total size of the
> simulated population
>     grp=100                                   ##  the number of groups of
> the simulated population
>     nindiv=2000                            ##  the number of observations
> in each group
>     b0=2                                       ##  intercept
>     b1=0.2                                    ##  slope of X
>     u = rnorm(grp,0,0.05)
>     e = rnorm(nindiv*grp,1)
>     M.x=rnorm(grp,3,0.05)
>     sigma<-diag(grp)                   ## identity matrix
>     require(MASS)
>     x=mvrnorm(nindiv,M.x,sigma)
>     X=as.vector(x)
>     data.set = data.frame(group.id = rep(1:grp, each=nindiv),
>                   u = rep(u, each=nindiv),
>                   M.x = rep(M.x, each=nindiv),
>                   indiv.id = 1:(nindiv*grp),
>                   X = X,
>                   e = e)
>     data.set$Y = b0 + b1*data.set$X + b2*data.set$mean.X+ data.set$u +
> data.set$e
>
>     indiv<- data.frame(data.set$group.id,data.set$X,data.set$Y)
>     names(indiv)<-c("group.id","X","Y")
>
> my problem is i do not know how can i write the command of the
> independence between X and the error terms of the two levels of the model
> (e and u ) in my program code.
>
> and i appreciate your help
>
> thanks mervat
>
> On Wednesday, July 12, 2017, 9:46:10 AM GMT+2, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>
> Dear Mervat,
>
> This the r-sig-mixed-models mailing list. Not the write-code-for-me
> mailing list. Please show us what you have tried. This can easily be solved
> using expand.grid() and rnorm().
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-07-11 13:28 GMT+02:00 mervat mohamed via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org>:
>
>
>
>
> ----- Forwarded Message -----From: mervat mohamed <
> mervat_moh2006 at yahoo.com>To: mailman-owner at r-project.org <
> mailman-owner at r-project.org> Sent: Sunday, July 2, 2017, 5:39:42 AM
> GMT+2Subject: Fw: [R-sig-ME] Fw: simulating a linear random intercept model
> with exogeneity assumption
>
>
>      On Wednesday, June 21, 2017 8:27 PM, mervat mohamed via
> R-sig-mixed-models <r-sig-mixed-models at r-project. org
> <r-sig-mixed-models at r-project.org>> wrote:
>
>
>
>
>   Show original message    On Monday, June 19, 2017 1:36 PM, mervat
> mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org
> <r-sig-mixed-models at r-project.org>> wrote:
>
>
>  Hi r-sig group
> I want to know how to write the code of simulating a linear random
> intercept model with following assumptions using R programing:
> the model:
> yij=b.+b1 xij + u.j + eij,  where j refer to the group number and i refer
> to the observation number in the j group
> model assumptions:
>   1- xij ~ N (3,1.5)  2- u.j ~ N (0,1)  3 - eij ~ N (0,1)  4 - cov (xij ,
> u.j)=0  5 - cov (xij , eij)=0
>   6- cov (u.j , eij)= 0
> thnx for help
> mervat
>     [[alternative HTML version deleted]]
>
> ______________________________ _________________
> R-sig-mixed-models at r-project. org <R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>   ______________________________ _________________
> R-sig-mixed-models at r-project. org <R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
> ______________________________ _________________
> R-sig-mixed-models at r-project. org <R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Wed Jul 12 21:38:16 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 12 Jul 2017 16:38:16 -0300
Subject: [R-sig-ME] Question on random effect
In-Reply-To: <9C8B4575-BD22-4FA4-AB18-474F464A1C19@wisc.edu>
References: <CAMM93=J+rwdBGAcujE61AL8KjibRCxzhOy5JYdb8SLkZ-aJ7vg@mail.gmail.com>
 <CABghstT2tAwa+_giHn+J+m=KJvBqHwF71_1_dt-xBwsxyknXUg@mail.gmail.com>
 <CAJuCY5zmn3PY=9aGFYp5yEnzoCAB7EBtca1gRxxGY1iqWrwHdw@mail.gmail.com>
 <2b1938c28b7b4daea0af5b750dd5f1d0@UM-MAIL3216.unimaas.nl>
 <9C8B4575-BD22-4FA4-AB18-474F464A1C19@wisc.edu>
Message-ID: <CAMM93=Jn3sTD2+swQKJQxnNSe=HdXQ5zj9cq8K9N9bbsqDe8Uw@mail.gmail.com>

Thankyou all for your valious comments.
All the best,
Joaqu?n.

2017-07-12 8:07 GMT-03:00 Anthony R. Ives <arives at wisc.edu>:

> I find that the easiest way to think about this is in terms of the
> covariance matrix of the residuals. For LMMs, the random effects (which
> themselves are independent) produce block-diagonal covariance matrices,
> with positive covariances among residuals within the same level of a random
> effect. Phylogenetic relationships will also produce positive off-diagonal
> elements in the covariance matrix. Focusing on the structure of the
> covariance matrix of residuals often gives the clearest picture of the
> overall assumptions of a model.
>
> Cheers, Tony
>
> On 7/12/17, 3:43 AM, "R-sig-mixed-models on behalf of Viechtbauer Wolfgang
> (SP)" <r-sig-mixed-models-bounces at r-project.org on behalf of
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
>     Another example where random effects are not assumed to be independent
> is phylogenetic models. Based on a phylogeny, we can construct a
> correlation matrix that indicates the phylogenetic relatedness of the
> species. Random effects for species are then assumed to be correlated
> accordingly.
>
>     Best,
>     Wolfgang
>
>     --
>     Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry
> and
>     Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200
> MD
>     Maastricht, The Netherlands | +31 (43) 388-4170 |
> http://www.wvbauer.com
>
>     >-----Original Message-----
>     >From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
>     >On Behalf Of Thierry Onkelinx
>     >Sent: Wednesday, July 12, 2017 10:03
>     >To: Ben Bolker
>     >Cc: r-sig-mixed-models
>     >Subject: Re: [R-sig-ME] Question on random effect
>     >
>     >Dear Joaquin and Ben,
>     >
>     >AFAIK have most random effects a term which is i.i.d. The random
> effects
>     >in
>     >nlme and lme4 directly use the i.i.d. term: x_i ~ N(0, \sigma), hence
> the
>     >random effect itself is i.i.d. INLA has some other constructs
> available.
>     >e.g. a first order random walk where x_i - x_{i-1} ~ N(0, \sigma).
> Here
>     >the
>     >difference between to consecutive random effects is i.i.d. but the
> random
>     >effect itself isn't. The available options are listed at
>     >http://www.r-inla.org/models/latent-models
>     >
>     >Best regards,
>     >
>     >ir. Thierry Onkelinx
>     >Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and
>     >Forest
>     >team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>     >Kliniekstraat 25
>     >1070 Anderlecht
>     >Belgium
>     >
>     >To call in the statistician after the experiment is done may be no
> more
>     >than asking him to perform a post-mortem examination: he may be able
> to
>     >say
>     >what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     >The plural of anecdote is not data. ~ Roger Brinner
>     >The combination of some data and an aching desire for an answer does
> not
>     >ensure that a reasonable answer can be extracted from a given body of
>     >data.
>     >~ John Tukey
>     >
>     >2017-07-11 13:22 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
>     >
>     >> Yes, the assumption is that the random effects are (conditionally)
>     >> independent.  It can help to specify covariates  (such as
>     >> latitude/longitude or eastings/northings, or environmental
> conditions
>     >> [temperature, elevation, etc.]) for sites to mop up some of the
>     >> independence. It is theoretically possible, although I don't know of
>     >> an easy off-the-shelf way to do it, to impose (e.g.) spatial
>     >> correlation structures at the level of the random effects ...  or
> you
>     >> could examine the spatial dependence of the conditional modes/random
>     >> effects and try to convince yourself it was weak ...
>     >>
>     >> On Tue, Jul 11, 2017 at 7:14 AM, Joaqu?n Aldabe
>     >> <joaquin.aldabe at gmail.com> wrote:
>     >> > Hi all, when working with mixed models, do the levels of the
> random
>     >> effect
>     >> > have to be independent? For example, if my random effect is the
>     >identity
>     >> of
>     >> > sites and it is associated to the intercept, do sites have to be
>     >> > independent?
>     >> >
>     >> > I appreciate comments and bibliographic references.
>     >> >
>     >> > Thank you very much in advanced,
>     >> >
>     >> > Joaquin
>     >> >
>     >> > --
>     >> > *Joaqu?n Aldabe*
>     >> >
>     >> > *Grupo Biodiversidad, Ambiente y Sociedad*
>     >> > Centro Universitario de la Regi?n Este, Universidad de la
> Rep?blica
>     >> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >> >
>     >> > *Departamento de Conservaci?n*
>     >> > Aves Uruguay
>     >> > BirdLife International
>     >> > Canelones 1164, Montevideo
>     >> >
>     >> > https://sites.google.com/site/joaquin.aldabe
>     >> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From mervat_moh2006 at yahoo.com  Thu Jul 13 13:24:30 2017
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Thu, 13 Jul 2017 11:24:30 +0000 (UTC)
Subject: [R-sig-ME] Fw: Fw: simulating a linear random intercept model
 with exogeneity assumption
In-Reply-To: <CAJuCY5xzvMWKOpG7fVXfwkOwoiMn+6raaOyHBWdXAahWmLrgOg@mail.gmail.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
 <66313752.629683.1498069664156@mail.yahoo.com>
 <798664270.2713607.1498966782924@mail.yahoo.com>
 <80276192.2660925.1499772529110@mail.yahoo.com>
 <CAJuCY5wsO7bsLqBSFAVvnOqkN6UkROHqqoA-Xbyais7h1mmaNw@mail.gmail.com>
 <1222277500.3337899.1499849483450@mail.yahoo.com>
 <CAJuCY5xzvMWKOpG7fVXfwkOwoiMn+6raaOyHBWdXAahWmLrgOg@mail.gmail.com>
Message-ID: <1510854869.4118910.1499945070952@mail.yahoo.com>

dear ir. Thierry Onkelinx
thank you very much  ir. Thierry Onkelinx?i appreciate your help 
mervat



On Wednesday, July 12, 2017, 4:02:03 PM GMT+2, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

Dear Mervat,
Here is how I would write it. No need for the multivariate rnorm since you set all covariances are zero, making them independent. All rnorm() are by default independent so need for a special command to make them independent.?
library(dplyr)grp <- 10nindiv <- 20b0 <- 2b <- 0.2u <- rnorm(grp, mean = 0, sd = 0.05)e <- rnorm(grp * nindiv, mean = 0, sd = 1)expand.grid(? group = seq_len(grp),? individual = seq_len(nindiv)) %>%? mutate(? ? X = rnorm(n(), mean = 0, sd = 1),? ? id = interaction(group, individual),? ? mu = b0 + b * X + u[group],? ? y = mu + e? )
Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
2017-07-12 10:51 GMT+02:00 mervat mohamed <mervat_moh2006 at yahoo.com>:

dear ir. Thierry Onkelinx
thank you for your advise , my program code is as follows:
## The code of the program

# yj[i] = b0j+ b1*xj[i]+ej[i]
# b0j = b0 + u0j, u0j ~ N(0,1)??????????????random intercept
# b1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ????? ? ? ? ? ?????? fixed slope
# -- load the used package
library(lme4)

set.seed(1)

????n=200000????? ?? ? ? ? ? ? ? ? ? ? ?? ? ##??the total size of the simulated population
????grp=100??????? ? ? ? ? ? ? ? ? ? ? ? ? ?? ##??the number of groups of the simulated population
????nindiv=2000??????????????? ???????????? ##??the number of observations in each group
????b0=2?????????? ? ? ? ? ? ? ? ? ? ? ? ??? ? ##??intercept
????b1=0.2?????? ? ? ? ? ? ? ? ? ?? ? ? ?? ?? ##??slope of X
??? u = rnorm(grp,0,0.05)
????e = rnorm(nindiv*grp,1)
????M.x=rnorm(grp,3,0.05)
????sigma<-diag(grp)????? ? ? ? ? ???? ## identity matrix
????require(MASS)
????x=mvrnorm(nindiv,M.x, sigma)
????X=as.vector(x)
????data.set = data.frame(group.id = rep(1:grp, each=nindiv),
??????????????????u = rep(u, each=nindiv),
??????????????????M.x = rep(M.x, each=nindiv),
??????????????????indiv.id = 1:(nindiv*grp),
??????????????????X = X,
??????????????????e = e)
??? data.set$Y = b0 + b1*data.set$X + b2*data.set$mean.X+ data.set$u + data.set$e

????indiv<- data.frame(data.set$group.id, data.set$X,data.set$Y)????? ??? names(indiv)<-c("group.id","X" ,"Y")
my problem is i do not know how can i write the command of the independence between X and the error terms of the two levels of the model (e and u ) in my program code.
and i appreciate your help
thanks mervat? 

On Wednesday, July 12, 2017, 9:46:10 AM GMT+2, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:

Dear Mervat,
This the r-sig-mixed-models mailing list. Not the write-code-for-me mailing list. Please show us what you have tried. This can easily be solved using expand.grid() and rnorm().
Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner 
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
2017-07-11 13:28 GMT+02:00 mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org>:




----- Forwarded Message -----From: mervat mohamed <mervat_moh2006 at yahoo.com>To: mailman-owner at r-project.org <mailman-owner at r-project.org> Sent: Sunday, July 2, 2017, 5:39:42 AM GMT+2Subject: Fw: [R-sig-ME] Fw: simulating a linear random intercept model with exogeneity assumption


? ? ?On Wednesday, June 21, 2017 8:27 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org> wrote:




? Show original message? ? On Monday, June 19, 2017 1:36 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project. org> wrote:


?Hi r-sig group
I want to know how to write the code of simulating a linear random intercept model with following assumptions using R programing:
the model:
yij=b.+b1 xij + u.j + eij, ?where j refer to the group number and i refer to the observation number in the j group
model assumptions:
? 1- xij ~ N (3,1.5)? 2- u.j ~ N (0,1)? 3 - eij ~ N (0,1)? 4 - cov (xij , u.j)=0? 5 - cov (xij , eij)=0
? 6- cov (u.j , eij)= 0
thnx for help
mervat
??? [[alternative HTML version deleted]]

______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models

? ______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models

? ?
______________________________ _________________
R-sig-mixed-models at r-project. org mailing list
https://stat.ethz.ch/mailman/ listinfo/r-sig-mixed-models





	[[alternative HTML version deleted]]


From danselechnik at gmail.com  Sat Jul 15 03:26:42 2017
From: danselechnik at gmail.com (Dan Selechnik)
Date: Sat, 15 Jul 2017 11:26:42 +1000
Subject: [R-sig-ME] lme4
Message-ID: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>

Hello,

My name is Dan and I'm a PhD student in Australia. I was hoping that I
could ask you for some help with using lme4. I have a dataset in which I
have PC1 as a response variable. Population, treatment, RBC, and
population*treatment are my explanatory variables. ID is a random factor.
(I have attached the CSV file here)...

I am trying to run a power analysis, and first to fit my data using lmer.

First I read my data into R:
pc1=read.csv("R-PowerAnalysis.csv", header=TRUE)

Then I attempt to fit:
fm1=lmer(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1, REML=FALSE)

However, this fails, returning the message:
Error: number of levels of each grouping factor must be < number of
observations

My number of populations and treatments is much less than my number of
observations, so I am not sure why I am getting this error... Also, when I
run this, it works fine:
fm1=lm(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1)

I was hoping I could ask for your assistance in figuring out what may be
the problem. Thank you very much.

Cheers,
Dan

From bbolker at gmail.com  Sat Jul 15 04:10:27 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 14 Jul 2017 22:10:27 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>
References: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>
Message-ID: <d904c353-94d7-e7d0-da69-4db2a1b3d32c@gmail.com>



On 17-07-14 09:26 PM, Dan Selechnik wrote:
> Hello,
> 
> My name is Dan and I'm a PhD student in Australia. I was hoping that I
> could ask you for some help with using lme4. I have a dataset in which I
> have PC1 as a response variable. Population, treatment, RBC, and
> population*treatment are my explanatory variables. ID is a random factor.
> (I have attached the CSV file here)...
> 
> I am trying to run a power analysis, and first to fit my data using lmer.
> 
> First I read my data into R:
> pc1=read.csv("R-PowerAnalysis.csv", header=TRUE)
> 
> Then I attempt to fit:
> fm1=lmer(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1, REML=FALSE)

   A small point, but in general you should *not* use pc1$ in specifying
your formula: instead,

fm1=lmer(PC1 ~ RBC + Population*Treatment + (1|ID), data=pc1,
    REML=FALSE)

(also, the * operator includes both the main effects of Population and
Treatment and their interaction). But that should be tangential to your
problem.

> 
> However, this fails, returning the message:
> Error: number of levels of each grouping factor must be < number of
> observations
> 
> My number of populations and treatments is much less than my number of
> observations, so I am not sure why I am getting this error... 

  That's not your problem.  lme4 is referring to the number of levels of
the *grouping factor*, which is ID (not Population or Treatment).  Your
ID variable must contain a single observation per group (cheating and
looking at the data you sent me offline, I can see that's true).

If you had sent the results of summary(pc1), we could have guessed this:
ID is coded as an integer so we don't know for sure that it consists of
the values 1..20, but since the min is 1 and the max is 20 and mean is
10.5, we can guess that that's the case ...

       ID        Population         Treatment       RBC
 Min.   : 1.00   QLD:10     LPS-Injection:10   Min.   :-113.00
 1st Qu.: 5.75   WA :10     PBS-Injection:10   1st Qu.:  22.00
 Median :10.50                                 Median :  49.00
 Mean   :10.50                                 Mean   :  53.55
 3rd Qu.:15.25                                 3rd Qu.: 107.00
 Max.   :20.00                                 Max.   : 181.00
      PC1
 Min.   :-4.5411
 1st Qu.: 0.1017
 Median : 1.1470
 Mean   : 0.6258
 3rd Qu.: 1.9251
 Max.   : 3.2004


Also, when I
> run this, it works fine:
> fm1=lm(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1)

If you look at the results of this model:

Coefficients:
                        (Intercept)                                  RBC
                            1.47759                              0.01318
                       PopulationWA               TreatmentPBS-Injection
                           -1.38234                             -1.85619
                         1 | IDTRUE  PopulationWA:TreatmentPBS-Injection
                                 NA                              0.24754

you can see that something funny is happening to the (1|ID) term ...

> 
> I was hoping I could ask for your assistance in figuring out what may be
> the problem. Thank you very much.
> 
> Cheers,
> Dan
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dexter.locke at gmail.com  Sat Jul 15 15:34:02 2017
From: dexter.locke at gmail.com (Dexter Locke)
Date: Sat, 15 Jul 2017 09:34:02 -0400
Subject: [R-sig-ME] dyads nested: confused on interpretation
Message-ID: <CAA=SVwGQT0ZFGP-EcQaGp4vJqL4-4MGYdmRPmz2xTZuYEZGQfA@mail.gmail.com>

Greetings mixed modelers,

I'm fitting a three-level mixed model with lme4::lmer and struggling with
the interpretation.

The dependent variable is species richness. There are zeros, and its not
normal, so I've added one and then logged it. Observations are collected as
pairs at sites, and therefore not independent. As Wickham (2014) notes -
referencing Bolker - there is an equivalence between a t-test a mixed model
in this type of case. Sites are also uniquely nested within one of two
cities, hence the third level. My syntax is:

AAA <- lmer(log(richness + 1) ~fb*City + (1 | Site / City),
data=wy_GardenC, REML = F)

"fb" indicates the location of the observation within the site: either
front (Front) or back (Back).

Using sjPlot::sjt.lmer the p-values are calculated and formatted neatly in
a table (I do understand the controversies and assumptions around using
t-stats as Walk Z-stats..)

The estimated intercept is 2.77 (or 15.96 once back-transformed), the fb
variable becomes "fbBack", its beta is 0.42 (or 1.52 once
back-transformed). The City and fb*City interaction terms are not
significant.

Can I conclude that back yards are on average ~10% (1.52/ 15.92 =  0.095)
more species-rich? My confusion is that I'd think R takes b as in Back
first as the base case and makes f as in Front the contrast. Plotting the
data suggests that indeed back yards in Los Angeles (one of the two cities
is higher):

http://dexterlocke.com/wp-content/uploads/2017/07/unnamed-1.png


I'm not interested in if all backs (on average) are greater than all fronts
(on average). I'm interested in if at each site, the back is generally
greater than the front. Am I specifying a corresponding model to this
question? Is the front being taken as the referent, and back as reference?
Given the factors, what is being contrasted with what base-case?

Thank you for your consideration,
Dexter


Wickham, H. (2014). Tidy Data. Journal Of Statistical Software, 59(10).
Retrieved from https://www.jstatsoft.org/article/view/v059i10/v59i10.pdf

	[[alternative HTML version deleted]]


From Tom.Wilding at sams.ac.uk  Sat Jul 15 18:50:56 2017
From: Tom.Wilding at sams.ac.uk (Tom Wilding)
Date: Sat, 15 Jul 2017 16:50:56 +0000
Subject: [R-sig-ME] dyads nested: confused on interpretation
In-Reply-To: <CAA=SVwGQT0ZFGP-EcQaGp4vJqL4-4MGYdmRPmz2xTZuYEZGQfA@mail.gmail.com>
References: <CAA=SVwGQT0ZFGP-EcQaGp4vJqL4-4MGYdmRPmz2xTZuYEZGQfA@mail.gmail.com>
Message-ID: <HE1PR0201MB14994AAAF7391AA3EEA3792AC4A20@HE1PR0201MB1499.eurprd02.prod.outlook.com>

Hi Dexter - is there a good reason why you are not using a Poisson /quasi-Poisson or negative binomial regression model?  This would be a much more elegant solution to your count-date analysis (regardless of anything else).  If you Google 'why not log-transform count data' you'll find plenty of evidence to that effect.

Best

Tom.

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dexter Locke
Sent: 15 July 2017 14:34
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] dyads nested: confused on interpretation

Greetings mixed modelers,

I'm fitting a three-level mixed model with lme4::lmer and struggling with the interpretation.

The dependent variable is species richness. There are zeros, and its not normal, so I've added one and then logged it. Observations are collected as pairs at sites, and therefore not independent. As Wickham (2014) notes - referencing Bolker - there is an equivalence between a t-test a mixed model in this type of case. Sites are also uniquely nested within one of two cities, hence the third level. My syntax is:

AAA <- lmer(log(richness + 1) ~fb*City + (1 | Site / City), data=wy_GardenC, REML = F)

"fb" indicates the location of the observation within the site: either front (Front) or back (Back).

Using sjPlot::sjt.lmer the p-values are calculated and formatted neatly in a table (I do understand the controversies and assumptions around using t-stats as Walk Z-stats..)

The estimated intercept is 2.77 (or 15.96 once back-transformed), the fb variable becomes "fbBack", its beta is 0.42 (or 1.52 once back-transformed). The City and fb*City interaction terms are not significant.

Can I conclude that back yards are on average ~10% (1.52/ 15.92 =  0.095) more species-rich? My confusion is that I'd think R takes b as in Back first as the base case and makes f as in Front the contrast. Plotting the data suggests that indeed back yards in Los Angeles (one of the two cities is higher):

http://dexterlocke.com/wp-content/uploads/2017/07/unnamed-1.png


I'm not interested in if all backs (on average) are greater than all fronts (on average). I'm interested in if at each site, the back is generally greater than the front. Am I specifying a corresponding model to this question? Is the front being taken as the referent, and back as reference?
Given the factors, what is being contrasted with what base-case?

Thank you for your consideration,
Dexter


Wickham, H. (2014). Tidy Data. Journal Of Statistical Software, 59(10).
Retrieved from https://www.jstatsoft.org/article/view/v059i10/v59i10.pdf

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has two actively trading wholly owned subsidiary companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.


From dexter.locke at gmail.com  Sat Jul 15 19:05:15 2017
From: dexter.locke at gmail.com (Dexter Locke)
Date: Sat, 15 Jul 2017 13:05:15 -0400
Subject: [R-sig-ME] dyads nested: confused on interpretation
In-Reply-To: <HE1PR0201MB14994AAAF7391AA3EEA3792AC4A20@HE1PR0201MB1499.eurprd02.prod.outlook.com>
References: <CAA=SVwGQT0ZFGP-EcQaGp4vJqL4-4MGYdmRPmz2xTZuYEZGQfA@mail.gmail.com>
 <HE1PR0201MB14994AAAF7391AA3EEA3792AC4A20@HE1PR0201MB1499.eurprd02.prod.outlook.com>
Message-ID: <CAA=SVwFiiOb7i75VQ0mVHaDrZtd4R489Te_269ceWCaTkVa=Tg@mail.gmail.com>

Dear Tom, Thank you.  I have seen O?Hara and  Kotze's (2010) Methods in
Ecology and Evolution piece. Thank you for reminding me about that with
respect to the left-hand side of the model.

I am also fitting parallel models for different soils measures, which are
normally distributed and are bonafide continuous variables.

Dear List (including Tom), am I interpreting the right-hand side correctly?
I'm still confused about the contrasts, their interpretation, and how the
tabular (regression-derived) results and the plotting of the raw data seem
to suggest the opposite relationships.

All the best,
Dexter



On Sat, Jul 15, 2017 at 12:50 PM, Tom Wilding <Tom.Wilding at sams.ac.uk>
wrote:

> Hi Dexter - is there a good reason why you are not using a Poisson
> /quasi-Poisson or negative binomial regression model?  This would be a much
> more elegant solution to your count-date analysis (regardless of anything
> else).  If you Google 'why not log-transform count data' you'll find plenty
> of evidence to that effect.
>
> Best
>
> Tom.
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Dexter Locke
> Sent: 15 July 2017 14:34
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] dyads nested: confused on interpretation
>
> Greetings mixed modelers,
>
> I'm fitting a three-level mixed model with lme4::lmer and struggling with
> the interpretation.
>
> The dependent variable is species richness. There are zeros, and its not
> normal, so I've added one and then logged it. Observations are collected as
> pairs at sites, and therefore not independent. As Wickham (2014) notes -
> referencing Bolker - there is an equivalence between a t-test a mixed model
> in this type of case. Sites are also uniquely nested within one of two
> cities, hence the third level. My syntax is:
>
> AAA <- lmer(log(richness + 1) ~fb*City + (1 | Site / City),
> data=wy_GardenC, REML = F)
>
> "fb" indicates the location of the observation within the site: either
> front (Front) or back (Back).
>
> Using sjPlot::sjt.lmer the p-values are calculated and formatted neatly in
> a table (I do understand the controversies and assumptions around using
> t-stats as Walk Z-stats..)
>
> The estimated intercept is 2.77 (or 15.96 once back-transformed), the fb
> variable becomes "fbBack", its beta is 0.42 (or 1.52 once
> back-transformed). The City and fb*City interaction terms are not
> significant.
>
> Can I conclude that back yards are on average ~10% (1.52/ 15.92 =  0.095)
> more species-rich? My confusion is that I'd think R takes b as in Back
> first as the base case and makes f as in Front the contrast. Plotting the
> data suggests that indeed back yards in Los Angeles (one of the two cities
> is higher):
>
> http://dexterlocke.com/wp-content/uploads/2017/07/unnamed-1.png
>
>
> I'm not interested in if all backs (on average) are greater than all
> fronts (on average). I'm interested in if at each site, the back is
> generally greater than the front. Am I specifying a corresponding model to
> this question? Is the front being taken as the referent, and back as
> reference?
> Given the factors, what is being contrasted with what base-case?
>
> Thank you for your consideration,
> Dexter
>
>
> Wickham, H. (2014). Tidy Data. Journal Of Statistical Software, 59(10).
> Retrieved from https://www.jstatsoft.org/article/view/v059i10/v59i10.pdf
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> The Scottish Association for Marine Science (SAMS) is registered in
> Scotland as a Company Limited by Guarantee (SC009292) and is a registered
> charity (9206). SAMS has two actively trading wholly owned subsidiary
> companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912).
> All Companies in the group are registered in Scotland and share a
> registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The
> content of this message may contain personal views which are not the views
> of SAMS unless specifically stated. Please note that all email traffic is
> monitored for purposes of security and spam filtering. As such individual
> emails may be examined in more detail.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Jul 16 11:57:07 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 16 Jul 2017 21:57:07 +1200
Subject: [R-sig-ME] Struggle with glmer().
Message-ID: <93962af2-8fce-aa56-d5ba-de3599a60149@auckland.ac.nz>


To all and sundry, near and far,
Ben Bolker in particular :-) .... [1]

For a considerable time I have been struggling with a problem that would 
appear to require application of the glmer() function from lme4.  The 
main thrust of the problem involves estimation of lethal dose levels 
(e.g. LD99) for a certain pest elimination treatment.  It seems to be 
impossible to get glmer() to return a fit of the relevant model without 
producing a number of dire and ominous warnings.

The principal investigator on the problem has managed to get a 
linearisation of the model to produce an almost-satisfactory fit, but 
that's an "almost", but not quite.  I won't go into details about this 
now, because it's mostly off the point.

The data involved are confidential, so I can't show you those; instead I 
have written a function to generate artificial data (which are 
superficially similar to the real data but are much tidier and without 
the quirks and peculiarities of the real data). The artificial data are 
nicely balanced (unlike the real data).

The simulated data set has 1080 records [2].  I would not have thought 
this to be an overwhelmingly large data set.

I have attached the code of my data generating function "artSim()".
The coefficients of the fixed effects ("beta0" and "beta1") and the
variance components ("Sigma") are designed to be roughly similar to 
estimates obtained from the "linearisation" mentioned above.

Having written "artSim()" I tried:

set.seed(42)
X <- artSim()
library(lme4)
fit <- glmer(cbind(Dead,Alive) ~ (Trt + 0)/x + (x | Rep),
              family=binomial(link="cloglog"),data=X)

After a fairly lengthy wait, I was not too surprised to get the same 
ominous warnings that I got with the real data:

> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

Could I prevail upon you wise and knowledgeable people to have a look at
my simulation function and the fitting procedure and let me know if I am 
doing something silly?

One last comment --- with the real data, I have tried using estimates 
obtained from the "linearised" model as starting values for glmer(). 
This simply made matters worse!  In addition to the foregoing warnings I 
got a warning about "failure to converge in 10000 evaluations".

I haven't bothered to try this device with the simulated data ....

Thanks for any avuncular (or materteral!) advice that anyone can provide.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


[1] Cf. "King John's Christmas" by A. A. Milne

[2] The pest elimination treatment under study is *not* 1080!!! The 
presence of that number is purely coincidental!!! :-)
-------------- next part --------------
artSim <- function(){
#
# Function to simulate "artificial" data which is at least superficially
# similar to some real data.
#
require(MASS)

link    <- "cloglog"
B       <- binomial(link=link)
linkfun <- B$linkfun
linkinv <- B$linkinv

# Construct (artificial) treatment factor, covariate, and
# (random) replicate factor.
x    <- seq(0,28,by=2)
Trt  <- LETTERS[1:24]
Rep  <- 1:3 # Three reps per treatment.
Xdat <- expand.grid(x=x,Trt=Trt,Rep=Rep)
uRep <- with(Xdat,factor(paste0(Rep,Trt)))
Xdat$Rep <- with(Xdat,factor(as.numeric(uRep)))

beta0 <- seq(-3,0.45,by=0.15)
beta1 <- rep(seq(0.05,0.3,by=0.05),4)
names(beta0) <- Trt
names(beta1) <- Trt
Sigma <- matrix(c(0.06,-0.001,-0.001,0.0001),nrow=2)

lb0   <- beta0[match(Xdat$Trt,names(beta0))]
lb1   <- beta1[match(Xdat$Trt,names(beta1))]
nrep  <- 72
imat  <- match(Xdat$Rep,1:nrep)
Z     <- mvrnorm(nrep,c(0,0),Sigma)[imat,]
linpr <- lb0 + Z[,1] + (lb1 + Z[,2])*Xdat$x
p     <- linkinv(linpr)
nsize <- 25
Dead  <- rbinom(nrow(Xdat),nsize,p)
Alive <- nsize - Dead
x0    <- (linkfun(0.99) - beta0)/beta1
Xdat$Dead  <- Dead
Xdat$Alive <- Alive
attr(Xdat,"trueLD99") <- x0
return(Xdat)
}

From arives at wisc.edu  Sun Jul 16 14:14:52 2017
From: arives at wisc.edu (Anthony R. Ives)
Date: Sun, 16 Jul 2017 12:14:52 +0000
Subject: [R-sig-ME] Struggle with glmer().
In-Reply-To: <93962af2-8fce-aa56-d5ba-de3599a60149@auckland.ac.nz>
References: <93962af2-8fce-aa56-d5ba-de3599a60149@auckland.ac.nz>
Message-ID: <AB771CC3-FCE8-4C5B-82C9-FAA7F76B4D07@wisc.edu>

Rolf,

To make sure somebody speaks to you ? but probably no big India rubber ball [1].

I tried your code with the "nAGQ=0" option, and it fit quickly. The "non-converged" fit under the default was very similar for the point estimates of the fixed effects. Ben should confirm this, but in my experience the nAGQ=0 option is normally pretty good, and it also handles pathological cases when the random effects estimates explode.

Cheers, Tony

On 7/16/17, 4:57 AM, "R-sig-mixed-models on behalf of Rolf Turner" <r-sig-mixed-models-bounces at r-project.org on behalf of r.turner at auckland.ac.nz> wrote:

    
    To all and sundry, near and far,
    Ben Bolker in particular :-) .... [1]
    
    For a considerable time I have been struggling with a problem that would 
    appear to require application of the glmer() function from lme4.  The 
    main thrust of the problem involves estimation of lethal dose levels 
    (e.g. LD99) for a certain pest elimination treatment.  It seems to be 
    impossible to get glmer() to return a fit of the relevant model without 
    producing a number of dire and ominous warnings.
    
    The principal investigator on the problem has managed to get a 
    linearisation of the model to produce an almost-satisfactory fit, but 
    that's an "almost", but not quite.  I won't go into details about this 
    now, because it's mostly off the point.
    
    The data involved are confidential, so I can't show you those; instead I 
    have written a function to generate artificial data (which are 
    superficially similar to the real data but are much tidier and without 
    the quirks and peculiarities of the real data). The artificial data are 
    nicely balanced (unlike the real data).
    
    The simulated data set has 1080 records [2].  I would not have thought 
    this to be an overwhelmingly large data set.
    
    I have attached the code of my data generating function "artSim()".
    The coefficients of the fixed effects ("beta0" and "beta1") and the
    variance components ("Sigma") are designed to be roughly similar to 
    estimates obtained from the "linearisation" mentioned above.
    
    Having written "artSim()" I tried:
    
    set.seed(42)
    X <- artSim()
    library(lme4)
    fit <- glmer(cbind(Dead,Alive) ~ (Trt + 0)/x + (x | Rep),
                  family=binomial(link="cloglog"),data=X)
    
    After a fairly lengthy wait, I was not too surprised to get the same 
    ominous warnings that I got with the real data:
    
    > Warning messages:
    > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
    >   unable to evaluate scaled gradient
    > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
    >   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
    
    Could I prevail upon you wise and knowledgeable people to have a look at
    my simulation function and the fitting procedure and let me know if I am 
    doing something silly?
    
    One last comment --- with the real data, I have tried using estimates 
    obtained from the "linearised" model as starting values for glmer(). 
    This simply made matters worse!  In addition to the foregoing warnings I 
    got a warning about "failure to converge in 10000 evaluations".
    
    I haven't bothered to try this device with the simulated data ....
    
    Thanks for any avuncular (or materteral!) advice that anyone can provide.
    
    cheers,
    
    Rolf Turner
    
    -- 
    Technical Editor ANZJS
    Department of Statistics
    University of Auckland
    Phone: +64-9-373-7599 ext. 88276
    
    
    [1] Cf. "King John's Christmas" by A. A. Milne
    
    [2] The pest elimination treatment under study is *not* 1080!!! The 
    presence of that number is purely coincidental!!! :-)
    


From r.turner at auckland.ac.nz  Sun Jul 16 23:09:33 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 17 Jul 2017 09:09:33 +1200
Subject: [R-sig-ME] Struggle with glmer().
In-Reply-To: <AB771CC3-FCE8-4C5B-82C9-FAA7F76B4D07@wisc.edu>
References: <93962af2-8fce-aa56-d5ba-de3599a60149@auckland.ac.nz>
 <AB771CC3-FCE8-4C5B-82C9-FAA7F76B4D07@wisc.edu>
Message-ID: <612fd1a5-a0ba-cc53-d5d9-0a5524cf1368@auckland.ac.nz>

On 17/07/17 00:14, Anthony R. Ives wrote:
> Rolf,
> 
> To make sure somebody speaks to you ? but probably no big India
> rubber ball [1].
> 
> I tried your code with the "nAGQ=0" option, and it fit quickly. The
> "non-converged" fit under the default was very similar for the point
> estimates of the fixed effects. Ben should confirm this, but in my
> experience the nAGQ=0 option is normally pretty good, and it also
> handles pathological cases when the random effects estimates
> explode.
Dear Tony,

Wow.  That does indeed seem to me to be a big red India rubber ball!!!
Rapid fit, and the ominous warnings go away.

I tried it with the real data --- likewise rapid fit and no warnings.
Haven't done any thorough checking of results yet, but it sure looks 
like progress to me.

Thanks hugely!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thierry.onkelinx at inbo.be  Mon Jul 17 09:31:52 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 17 Jul 2017 09:31:52 +0200
Subject: [R-sig-ME] dyads nested: confused on interpretation
In-Reply-To: <CAA=SVwFiiOb7i75VQ0mVHaDrZtd4R489Te_269ceWCaTkVa=Tg@mail.gmail.com>
References: <CAA=SVwGQT0ZFGP-EcQaGp4vJqL4-4MGYdmRPmz2xTZuYEZGQfA@mail.gmail.com>
 <HE1PR0201MB14994AAAF7391AA3EEA3792AC4A20@HE1PR0201MB1499.eurprd02.prod.outlook.com>
 <CAA=SVwFiiOb7i75VQ0mVHaDrZtd4R489Te_269ceWCaTkVa=Tg@mail.gmail.com>
Message-ID: <CAJuCY5zX7Jrb9dxuNTE03Wd56pZ4+rqOv2UcScX7zAvJMZTMUg@mail.gmail.com>

Dear Dexter,

(1 | Site / City) is City nested in Site. In you case it is better to give
each site a unique id and the just use (1|Site).

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-15 19:05 GMT+02:00 Dexter Locke <dexter.locke at gmail.com>:

> Dear Tom, Thank you.  I have seen O?Hara and  Kotze's (2010) Methods in
> Ecology and Evolution piece. Thank you for reminding me about that with
> respect to the left-hand side of the model.
>
> I am also fitting parallel models for different soils measures, which are
> normally distributed and are bonafide continuous variables.
>
> Dear List (including Tom), am I interpreting the right-hand side correctly?
> I'm still confused about the contrasts, their interpretation, and how the
> tabular (regression-derived) results and the plotting of the raw data seem
> to suggest the opposite relationships.
>
> All the best,
> Dexter
>
>
>
> On Sat, Jul 15, 2017 at 12:50 PM, Tom Wilding <Tom.Wilding at sams.ac.uk>
> wrote:
>
> > Hi Dexter - is there a good reason why you are not using a Poisson
> > /quasi-Poisson or negative binomial regression model?  This would be a
> much
> > more elegant solution to your count-date analysis (regardless of anything
> > else).  If you Google 'why not log-transform count data' you'll find
> plenty
> > of evidence to that effect.
> >
> > Best
> >
> > Tom.
> >
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
> > On Behalf Of Dexter Locke
> > Sent: 15 July 2017 14:34
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] dyads nested: confused on interpretation
> >
> > Greetings mixed modelers,
> >
> > I'm fitting a three-level mixed model with lme4::lmer and struggling with
> > the interpretation.
> >
> > The dependent variable is species richness. There are zeros, and its not
> > normal, so I've added one and then logged it. Observations are collected
> as
> > pairs at sites, and therefore not independent. As Wickham (2014) notes -
> > referencing Bolker - there is an equivalence between a t-test a mixed
> model
> > in this type of case. Sites are also uniquely nested within one of two
> > cities, hence the third level. My syntax is:
> >
> > AAA <- lmer(log(richness + 1) ~fb*City + (1 | Site / City),
> > data=wy_GardenC, REML = F)
> >
> > "fb" indicates the location of the observation within the site: either
> > front (Front) or back (Back).
> >
> > Using sjPlot::sjt.lmer the p-values are calculated and formatted neatly
> in
> > a table (I do understand the controversies and assumptions around using
> > t-stats as Walk Z-stats..)
> >
> > The estimated intercept is 2.77 (or 15.96 once back-transformed), the fb
> > variable becomes "fbBack", its beta is 0.42 (or 1.52 once
> > back-transformed). The City and fb*City interaction terms are not
> > significant.
> >
> > Can I conclude that back yards are on average ~10% (1.52/ 15.92 =  0.095)
> > more species-rich? My confusion is that I'd think R takes b as in Back
> > first as the base case and makes f as in Front the contrast. Plotting the
> > data suggests that indeed back yards in Los Angeles (one of the two
> cities
> > is higher):
> >
> > http://dexterlocke.com/wp-content/uploads/2017/07/unnamed-1.png
> >
> >
> > I'm not interested in if all backs (on average) are greater than all
> > fronts (on average). I'm interested in if at each site, the back is
> > generally greater than the front. Am I specifying a corresponding model
> to
> > this question? Is the front being taken as the referent, and back as
> > reference?
> > Given the factors, what is being contrasted with what base-case?
> >
> > Thank you for your consideration,
> > Dexter
> >
> >
> > Wickham, H. (2014). Tidy Data. Journal Of Statistical Software, 59(10).
> > Retrieved from https://www.jstatsoft.org/article/view/v059i10/v59i10.pdf
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > The Scottish Association for Marine Science (SAMS) is registered in
> > Scotland as a Company Limited by Guarantee (SC009292) and is a registered
> > charity (9206). SAMS has two actively trading wholly owned subsidiary
> > companies: SAMS Research Services Ltd (SC224404) and SAMS Ltd (SC306912).
> > All Companies in the group are registered in Scotland and share a
> > registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The
> > content of this message may contain personal views which are not the
> views
> > of SAMS unless specifically stated. Please note that all email traffic is
> > monitored for purposes of security and spam filtering. As such individual
> > emails may be examined in more detail.
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sun Jul 16 10:04:01 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 16 Jul 2017 09:04:01 +0100
Subject: [R-sig-ME] Fwd: Re: [R-sig-phylo] How to incorporate intraspecific
 variation in MCMCglmm
In-Reply-To: <CALJB7JRsOeXnMdb6+Bh4upgMSH9QkQGf3yz61gnCO1Vbj4HVYg@mail.gmail.com>
References: <CALJB7JRsOeXnMdb6+Bh4upgMSH9QkQGf3yz61gnCO1Vbj4HVYg@mail.gmail.com>
Message-ID: <aab5a719-49a0-fd61-b41d-c0b396526541@ed.ac.uk>

cc-ed back to the list....

Some observations seem to have no sampling variation and so have a 
residual variance of zero - which is not allowed, and doesn't make much 
sense.

Cheers,

Jarrod



-------- Forwarded Message --------
Subject: 	Re: [R-sig-phylo] How to incorporate intraspecific variation 
in MCMCglmm
Date: 	Sat, 15 Jul 2017 23:16:12 +0000
From: 	Diogo B. Provete <dbprovete at gmail.com>
To: 	Jarrod Hadfield <j.hadfield at ed.ac.uk>



Hi Jarrod,
I have tried all the suggestions for specifying the random effects. 
However, your last suggestion of making the residual covariance seems 
more appropriated in my case, since I have the standard error calculated 
already (in terms of jumped distance) and it's interpreted as 
intraspecific variance due to sampling error. But when I make my model as:

model1<-MCMCglmm(mean_distance~type_arena*type_of_stimulus,
*random=~Species, rcov=~idh(units):units*, data=df_spe, 
family="gaussian",  ginverse = list(Especie=treeAinv), nodes="ALL", 
prior=ve_priors, nitt=300000, burnin=25000, thin = 100, verbose=FALSE)

with priors:

ve_priors = list(R = list(V = diag(df_spe$se_distance^2), fix=1),
                  G=list(G1=list(V=1, nu=0.02)))

I get the following error message:

Error in priorformat(if (NOpriorG) { :
   V is not positive definite for some prior$G/prior$R elements .

I tried to google it and looked at your course notes ch. 3 and 4, but 
couldn't find anything helpful to understand it.

I'm attaching the first few lines of the prior V matrix.

Thanks once again,
Diogo

Em sex, 14 de jul de 2017 ?s 18:47, Diogo B. Provete 
<dbprovete at gmail.com <mailto:dbprovete at gmail.com>> escreveu:

    Dear Jarrod,
    Thanks very much for the quick reply.

    I'll try to implement the changes in the model.

    Have a nice weekend,
    Diogo


    Em Sex, 14 de jul de 2017 17:48, Jarrod Hadfield
    <j.hadfield at ed.ac.uk <mailto:j.hadfield at ed.ac.uk>> escreveu:

        Hi Diogo,

        First, your model1 is unlikely to be valid unless the residual
        variance
        happens to be 1. You should not fix it at one, and use a prior like:

        prior = list(R = list(V = 1, nu = 0.02), G=list(G1=list(V=1,
        nu=0.02)))

        Note that the residual variance (Ve) is the intra-specific variance,
        assumed constant over species, as in Lynch's h2/Pagels Lambda.
        If you
        have the standard error (se) of each observation you can also allow
        heterogeneity between observations as in random-effect
        meta-analysis:

        random=~Specie+idh(se)

        If you fix the variance associated with se at 1 in the prior

        prior = list(R = list(V = 1, nu = 0.02), G=list(G1=list(V=1,
        nu=0.02), G2=list(V=1, fix=1)))

        Then the intraspecific variance for species i is se^2_i+Ve

        If you do not fix the variance associated with se at 1, for
        example with

        prior = list(R = list(V = 1, nu = 0.02), G=list(G1=list(V=1,
        nu=0.02), G2=list(V=1, nu=0.02)))

        and estimate the associated variance (Vse). Then the
        intraspecific variance
           for species i is Vse*se^2_i+Ve. This is useful if you only
        know the standard error up to proportionality.

        Alternatively you can fit fixed-effect meta-analysis where all
        the intraspecific variance is presumed to be due to sampling error:

        random=~Specie, rcov=~idh(units):units

        with prior:

        prior = list(R = list(V = diag(se^2), fix=1),
        G=list(G1=list(V=1, nu=0.02)))

        The intraspecific variance for species i is se^2_i. This is
        quite an inefficient way of doing fixed-effect meta-analysis,
        and one day I will make such analyses easier to fit, and quicker
        to fit......

        Also, don't use nodes="TIPS" in the call to inverseA. I only
        allowed this option because its the parameterisation used by
        most other software, but its a really bad way of doing it. Stick
        with the default, node="ALL".

        Cheers,

        Jarrod









        On 14/07/2017 14:26, Diogo B. Provete wrote:
         > treeAinv<-inverseA(phylo,nodes="TIPS",scale=TRUE)$Ainv
         >
         > I included the following priors:
         >
         > prior = list(R = list(V = 1, fix = 1), G=list(G1=list(V=1,
        nu=0.02)))


        --
        The University of Edinburgh is a charitable body, registered in
        Scotland, with registration number SC005336.

    -- 
    *Diogo B. Provete, PhD.*
    FAPESP Post-doctoral fellow
    Department of Environmental Sciences
    Centre for Sciences and Technologies for Sustainability
    Federal University of S?o Carlos
    Sorocaba

    Gothenburg Global Biodiversity Centre
    Box 462   SE-405 30
    G?teborg, Sverige

    diogoprovete.weebly.com <http://diogoprovete.weebly.com>

    Cell phone: +5515981022137 <tel:%2815%29%2098102-2137>
    Skype: diogoprovete

    Editor: Amphibia-Reptilia | Biodiversity Data Journal

-- 
*Diogo B. Provete, PhD.*
FAPESP Post-doctoral fellow
Department of Environmental Sciences
Centre for Sciences and Technologies for Sustainability
Federal University of S?o Carlos
Sorocaba

Gothenburg Global Biodiversity Centre
Box 462   SE-405 30
G?teborg, Sverige

diogoprovete.weebly.com <http://diogoprovete.weebly.com>

Cell phone: +5515981022137 <tel:%2815%29%2098102-2137>
Skype: diogoprovete

Editor: Amphibia-Reptilia | Biodiversity Data Journal
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170716/475ee5f3/attachment.ksh>

From bbolker at gmail.com  Tue Jul 18 00:00:54 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 17 Jul 2017 18:00:54 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <CAOSYXnmvpVXMXL9p61p8dPq2ryb-Hrd11sU+iVgM9KhJtRKKjw@mail.gmail.com>
References: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>
 <d904c353-94d7-e7d0-da69-4db2a1b3d32c@gmail.com>
 <CAOSYXnmvpVXMXL9p61p8dPq2ryb-Hrd11sU+iVgM9KhJtRKKjw@mail.gmail.com>
Message-ID: <CABghstR_fC9QE=XL9DuSto+Ks=fRsAMJ8sejZXLHDnKv3Zg1_w@mail.gmail.com>

(please keep r-sig-mixed-models at r-project.org in the cc: list ... I've
been busy the last couple of days, and there's a good chance that
someone else will pop in and answer questions ...)

On Fri, Jul 14, 2017 at 11:48 PM, Dan Selechnik <danselechnik at gmail.com> wrote:
> Hi Ben,
>
> Thank you very much for the reply, but I'm still not sure what exactly is
> the fix here? Every sample has a single ID. Is this my issue...?

 Yes, that's right.

  If you have a single observation per level of the grouping factor
("observation-level random effects") in a *linear* mixed models, the
random-effect variance would be completely confounded with the
residual variance, so there's no point in using a LMM. (However,
observation-level random effects can be useful in GLMMs with binomial
or Poisson response distributions, as a way of measuring
overdispersion.)

>
> Cheers,
> Dan
>
> On Sat, Jul 15, 2017 at 12:10 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>
>> On 17-07-14 09:26 PM, Dan Selechnik wrote:
>> > Hello,
>> >
>> > My name is Dan and I'm a PhD student in Australia. I was hoping that I
>> > could ask you for some help with using lme4. I have a dataset in which I
>> > have PC1 as a response variable. Population, treatment, RBC, and
>> > population*treatment are my explanatory variables. ID is a random
>> > factor.
>> > (I have attached the CSV file here)...
>> >
>> > I am trying to run a power analysis, and first to fit my data using
>> > lmer.
>> >
>> > First I read my data into R:
>> > pc1=read.csv("R-PowerAnalysis.csv", header=TRUE)
>> >
>> > Then I attempt to fit:
>> > fm1=lmer(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
>> > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1, REML=FALSE)
>>
>>    A small point, but in general you should *not* use pc1$ in specifying
>> your formula: instead,
>>
>> fm1=lmer(PC1 ~ RBC + Population*Treatment + (1|ID), data=pc1,
>>     REML=FALSE)
>>
>> (also, the * operator includes both the main effects of Population and
>> Treatment and their interaction). But that should be tangential to your
>> problem.
>>
>> >
>> > However, this fails, returning the message:
>> > Error: number of levels of each grouping factor must be < number of
>> > observations
>> >
>> > My number of populations and treatments is much less than my number of
>> > observations, so I am not sure why I am getting this error...
>>
>>   That's not your problem.  lme4 is referring to the number of levels of
>> the *grouping factor*, which is ID (not Population or Treatment).  Your
>> ID variable must contain a single observation per group (cheating and
>> looking at the data you sent me offline, I can see that's true).
>>
>> If you had sent the results of summary(pc1), we could have guessed this:
>> ID is coded as an integer so we don't know for sure that it consists of
>> the values 1..20, but since the min is 1 and the max is 20 and mean is
>> 10.5, we can guess that that's the case ...
>>
>>        ID        Population         Treatment       RBC
>>  Min.   : 1.00   QLD:10     LPS-Injection:10   Min.   :-113.00
>>  1st Qu.: 5.75   WA :10     PBS-Injection:10   1st Qu.:  22.00
>>  Median :10.50                                 Median :  49.00
>>  Mean   :10.50                                 Mean   :  53.55
>>  3rd Qu.:15.25                                 3rd Qu.: 107.00
>>  Max.   :20.00                                 Max.   : 181.00
>>       PC1
>>  Min.   :-4.5411
>>  1st Qu.: 0.1017
>>  Median : 1.1470
>>  Mean   : 0.6258
>>  3rd Qu.: 1.9251
>>  Max.   : 3.2004
>>
>>
>> Also, when I
>> > run this, it works fine:
>> > fm1=lm(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
>> > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1)
>>
>> If you look at the results of this model:
>>
>> Coefficients:
>>                         (Intercept)                                  RBC
>>                             1.47759                              0.01318
>>                        PopulationWA               TreatmentPBS-Injection
>>                            -1.38234                             -1.85619
>>                          1 | IDTRUE  PopulationWA:TreatmentPBS-Injection
>>                                  NA                              0.24754
>>
>> you can see that something funny is happening to the (1|ID) term ...
>>
>> >
>> > I was hoping I could ask for your assistance in figuring out what may be
>> > the problem. Thank you very much.
>> >
>> > Cheers,
>> > Dan
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From danselechnik at gmail.com  Tue Jul 18 01:33:33 2017
From: danselechnik at gmail.com (Dan Selechnik)
Date: Tue, 18 Jul 2017 09:33:33 +1000
Subject: [R-sig-ME] lme4
In-Reply-To: <d904c353-94d7-e7d0-da69-4db2a1b3d32c@gmail.com>
References: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>
 <d904c353-94d7-e7d0-da69-4db2a1b3d32c@gmail.com>
Message-ID: <CAOSYXn=37Wt6RHhgQoBs98n_L+4+5GsBecpcNZ_KNBzDeC2XXQ@mail.gmail.com>

Hi Ben,

Thank you very much for the reply, but I'm still not sure what exactly is
the fix here? Every sample has a single ID. Is this my issue...?

Cheers,
Dan

On Sat, Jul 15, 2017 at 12:10 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 17-07-14 09:26 PM, Dan Selechnik wrote:
> > Hello,
> >
> > My name is Dan and I'm a PhD student in Australia. I was hoping that I
> > could ask you for some help with using lme4. I have a dataset in which I
> > have PC1 as a response variable. Population, treatment, RBC, and
> > population*treatment are my explanatory variables. ID is a random factor.
> > (I have attached the CSV file here)...
> >
> > I am trying to run a power analysis, and first to fit my data using lmer.
> >
> > First I read my data into R:
> > pc1=read.csv("R-PowerAnalysis.csv", header=TRUE)
> >
> > Then I attempt to fit:
> > fm1=lmer(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1, REML=FALSE)
>
>    A small point, but in general you should *not* use pc1$ in specifying
> your formula: instead,
>
> fm1=lmer(PC1 ~ RBC + Population*Treatment + (1|ID), data=pc1,
>     REML=FALSE)
>
> (also, the * operator includes both the main effects of Population and
> Treatment and their interaction). But that should be tangential to your
> problem.
>
> >
> > However, this fails, returning the message:
> > Error: number of levels of each grouping factor must be < number of
> > observations
> >
> > My number of populations and treatments is much less than my number of
> > observations, so I am not sure why I am getting this error...
>
>   That's not your problem.  lme4 is referring to the number of levels of
> the *grouping factor*, which is ID (not Population or Treatment).  Your
> ID variable must contain a single observation per group (cheating and
> looking at the data you sent me offline, I can see that's true).
>
> If you had sent the results of summary(pc1), we could have guessed this:
> ID is coded as an integer so we don't know for sure that it consists of
> the values 1..20, but since the min is 1 and the max is 20 and mean is
> 10.5, we can guess that that's the case ...
>
>        ID        Population         Treatment       RBC
>  Min.   : 1.00   QLD:10     LPS-Injection:10   Min.   :-113.00
>  1st Qu.: 5.75   WA :10     PBS-Injection:10   1st Qu.:  22.00
>  Median :10.50                                 Median :  49.00
>  Mean   :10.50                                 Mean   :  53.55
>  3rd Qu.:15.25                                 3rd Qu.: 107.00
>  Max.   :20.00                                 Max.   : 181.00
>       PC1
>  Min.   :-4.5411
>  1st Qu.: 0.1017
>  Median : 1.1470
>  Mean   : 0.6258
>  3rd Qu.: 1.9251
>  Max.   : 3.2004
>
>
> Also, when I
> > run this, it works fine:
> > fm1=lm(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1)
>
> If you look at the results of this model:
>
> Coefficients:
>                         (Intercept)                                  RBC
>                             1.47759                              0.01318
>                        PopulationWA               TreatmentPBS-Injection
>                            -1.38234                             -1.85619
>                          1 | IDTRUE  PopulationWA:TreatmentPBS-Injection
>                                  NA                              0.24754
>
> you can see that something funny is happening to the (1|ID) term ...
>
> >
> > I was hoping I could ask for your assistance in figuring out what may be
> > the problem. Thank you very much.
> >
> > Cheers,
> > Dan
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jul 18 09:45:00 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 18 Jul 2017 09:45:00 +0200
Subject: [R-sig-ME] lme4
In-Reply-To: <CAOSYXn=37Wt6RHhgQoBs98n_L+4+5GsBecpcNZ_KNBzDeC2XXQ@mail.gmail.com>
References: <CAOSYXn=BfVcz7Cdf5fu_wRABR4=MYxxLP9tRSvKRBRpppSG7-g@mail.gmail.com>
 <d904c353-94d7-e7d0-da69-4db2a1b3d32c@gmail.com>
 <CAOSYXn=37Wt6RHhgQoBs98n_L+4+5GsBecpcNZ_KNBzDeC2XXQ@mail.gmail.com>
Message-ID: <CAJuCY5wN=BC3fvMrO5pYcG4-sWh+_2xOWMT4RR=d3-XCxhUHEg@mail.gmail.com>

Dear Dan,

It looks like you need to do some reading about the theory on mixed models.
The random effects are use to account for a grouping effect which a) we
must take into account and b) are not really interested in the actual
effect. E.g. repeated measurements on the same individual. The measurement
from the same individual are not independent. So solve this by using the
individual id as a random effect.

So you need to think about the grouping in your dataset. One observation
isn't a group ;-)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-18 1:33 GMT+02:00 Dan Selechnik <danselechnik at gmail.com>:

> Hi Ben,
>
> Thank you very much for the reply, but I'm still not sure what exactly is
> the fix here? Every sample has a single ID. Is this my issue...?
>
> Cheers,
> Dan
>
> On Sat, Jul 15, 2017 at 12:10 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> >
> >
> > On 17-07-14 09:26 PM, Dan Selechnik wrote:
> > > Hello,
> > >
> > > My name is Dan and I'm a PhD student in Australia. I was hoping that I
> > > could ask you for some help with using lme4. I have a dataset in which
> I
> > > have PC1 as a response variable. Population, treatment, RBC, and
> > > population*treatment are my explanatory variables. ID is a random
> factor.
> > > (I have attached the CSV file here)...
> > >
> > > I am trying to run a power analysis, and first to fit my data using
> lmer.
> > >
> > > First I read my data into R:
> > > pc1=read.csv("R-PowerAnalysis.csv", header=TRUE)
> > >
> > > Then I attempt to fit:
> > > fm1=lmer(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> > > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1, REML=FALSE)
> >
> >    A small point, but in general you should *not* use pc1$ in specifying
> > your formula: instead,
> >
> > fm1=lmer(PC1 ~ RBC + Population*Treatment + (1|ID), data=pc1,
> >     REML=FALSE)
> >
> > (also, the * operator includes both the main effects of Population and
> > Treatment and their interaction). But that should be tangential to your
> > problem.
> >
> > >
> > > However, this fails, returning the message:
> > > Error: number of levels of each grouping factor must be < number of
> > > observations
> > >
> > > My number of populations and treatments is much less than my number of
> > > observations, so I am not sure why I am getting this error...
> >
> >   That's not your problem.  lme4 is referring to the number of levels of
> > the *grouping factor*, which is ID (not Population or Treatment).  Your
> > ID variable must contain a single observation per group (cheating and
> > looking at the data you sent me offline, I can see that's true).
> >
> > If you had sent the results of summary(pc1), we could have guessed this:
> > ID is coded as an integer so we don't know for sure that it consists of
> > the values 1..20, but since the min is 1 and the max is 20 and mean is
> > 10.5, we can guess that that's the case ...
> >
> >        ID        Population         Treatment       RBC
> >  Min.   : 1.00   QLD:10     LPS-Injection:10   Min.   :-113.00
> >  1st Qu.: 5.75   WA :10     PBS-Injection:10   1st Qu.:  22.00
> >  Median :10.50                                 Median :  49.00
> >  Mean   :10.50                                 Mean   :  53.55
> >  3rd Qu.:15.25                                 3rd Qu.: 107.00
> >  Max.   :20.00                                 Max.   : 181.00
> >       PC1
> >  Min.   :-4.5411
> >  1st Qu.: 0.1017
> >  Median : 1.1470
> >  Mean   : 0.6258
> >  3rd Qu.: 1.9251
> >  Max.   : 3.2004
> >
> >
> > Also, when I
> > > run this, it works fine:
> > > fm1=lm(pc1$PC1 ~ pc1$RBC + pc1$Population + pc1$Treatment +
> > > pc1$Population*pc1$Treatment + (1|pc1$ID), data=pc1)
> >
> > If you look at the results of this model:
> >
> > Coefficients:
> >                         (Intercept)                                  RBC
> >                             1.47759                              0.01318
> >                        PopulationWA               TreatmentPBS-Injection
> >                            -1.38234                             -1.85619
> >                          1 | IDTRUE  PopulationWA:TreatmentPBS-Injection
> >                                  NA                              0.24754
> >
> > you can see that something funny is happening to the (1|ID) term ...
> >
> > >
> > > I was hoping I could ask for your assistance in figuring out what may
> be
> > > the problem. Thank you very much.
> > >
> > > Cheers,
> > > Dan
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From RChiruka at ufh.ac.za  Tue Jul 18 00:15:52 2017
From: RChiruka at ufh.ac.za (Chiruka, Raymond)
Date: Mon, 17 Jul 2017 22:15:52 +0000
Subject: [R-sig-ME] nlme issue
Message-ID: <df87c642581a46dc83e919776db6aea8@AL-EXMB01.ufh-domain.local>

Good day

I am using R 3.4.1 on Rstudio on windows
I was trying the examples for fitting sitar growth models.I am getting the following error when run  examples in package sitar and package gmusim.

The code I tried is the following.

> library("gmusim", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")
Loading required package: lattice
Loading required package: nlme
Loading required package: splines

I get the following error.


> x <- immigrant$age

> y <- immigrant$height

> id <- immigrant$id

> df <- 5

> resu1 <- gmusim(x,y,id,df)

Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found





When I tried running the following sitar example I got the same error



> library("sitar", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")

> data(heights)

> (m1 <- sitar(x=age, y=height, id=id, data=heights, df=5))

Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found

> m1 <- sitar(x=age, y=height, id=id, data=heights, df=7)

Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found



I don't know what is wrong. Any help would be appreciated.





Regards



Raymond












This communication is subject to the University of Fort Hare e-Mail Disclaimer<http://www.ufh.ac.za/policies/UFH_E-mail_Disclaimer.pdf>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jul 18 14:43:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 18 Jul 2017 14:43:58 +0200
Subject: [R-sig-ME] nlme issue
In-Reply-To: <df87c642581a46dc83e919776db6aea8@AL-EXMB01.ufh-domain.local>
References: <df87c642581a46dc83e919776db6aea8@AL-EXMB01.ufh-domain.local>
Message-ID: <CAJuCY5ye3TwEBEJFGOX7PTjVmh4M+z5njdxQXa45AwQEc4OG1A@mail.gmail.com>

Dear Raymond,

I would recommend to contact the maintainers of those packages. Maybe
something changed in nlme and did not percolate into those packages.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-18 0:15 GMT+02:00 Chiruka, Raymond <RChiruka at ufh.ac.za>:

> Good day
>
> I am using R 3.4.1 on Rstudio on windows
> I was trying the examples for fitting sitar growth models.I am getting the
> following error when run  examples in package sitar and package gmusim.
>
> The code I tried is the following.
>
> > library("gmusim", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")
> Loading required package: lattice
> Loading required package: nlme
> Loading required package: splines
>
> I get the following error.
>
>
> > x <- immigrant$age
>
> > y <- immigrant$height
>
> > id <- immigrant$id
>
> > df <- 5
>
> > resu1 <- gmusim(x,y,id,df)
>
> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
>
>
>
>
>
> When I tried running the following sitar example I got the same error
>
>
>
> > library("sitar", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")
>
> > data(heights)
>
> > (m1 <- sitar(x=age, y=height, id=id, data=heights, df=5))
>
> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
>
> > m1 <- sitar(x=age, y=height, id=id, data=heights, df=7)
>
> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
>
>
>
> I don't know what is wrong. Any help would be appreciated.
>
>
>
>
>
> Regards
>
>
>
> Raymond
>
>
>
>
>
>
>
>
>
>
>
>
> This communication is subject to the University of Fort Hare e-Mail
> Disclaimer<http://www.ufh.ac.za/policies/UFH_E-mail_Disclaimer.pdf>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Jul 18 16:50:11 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Jul 2017 16:50:11 +0200
Subject: [R-sig-ME] nlme issue
In-Reply-To: <CAJuCY5ye3TwEBEJFGOX7PTjVmh4M+z5njdxQXa45AwQEc4OG1A@mail.gmail.com>
References: <df87c642581a46dc83e919776db6aea8@AL-EXMB01.ufh-domain.local>
 <CAJuCY5ye3TwEBEJFGOX7PTjVmh4M+z5njdxQXa45AwQEc4OG1A@mail.gmail.com>
Message-ID: <22894.8227.866738.597392@stat.math.ethz.ch>

>>>>> Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>>>>     on Tue, 18 Jul 2017 14:43:58 +0200 writes:

    > Dear Raymond,
    > I would recommend to contact the maintainers of those packages. Maybe
    > something changed in nlme and did not percolate into those packages.

Well, I think rather:
One of the packages you use,  it could well be  nlme or Matrix
must be re-installed in your R version 3.4.1

Typically, you just do (once)

    update.packages(checkBuilt = TRUE)

and wait a while for it to be finished.

Then (restart R and) everything should work fine.

Martin Maechler
ETH Zurich  &  R Core Team

  
  [................]

    > 2017-07-18 0:15 GMT+02:00 Chiruka, Raymond <RChiruka at ufh.ac.za>:

    >> Good day
    >> 
    >> I am using R 3.4.1 on Rstudio on windows
    >> I was trying the examples for fitting sitar growth models.I am getting the
    >> following error when run  examples in package sitar and package gmusim.
    >> 
    >> The code I tried is the following.
    >> 
    >> > library("gmusim", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")
    >> Loading required package: lattice
    >> Loading required package: nlme
    >> Loading required package: splines
    >> 
    >> I get the following error.
    >> 
    >> 
    >> > x <- immigrant$age
    >> 
    >> > y <- immigrant$height
    >> 
    >> > id <- immigrant$id
    >> 
    >> > df <- 5
    >> 
    >> > resu1 <- gmusim(x,y,id,df)
    >> 
    >> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
    >> 
    >> 
    >> 
    >> 
    >> 
    >> When I tried running the following sitar example I got the same error
    >> 
    >> 
    >> 
    >> > library("sitar", lib.loc="C:/Users/RChiruka/Documents/R/rpackages")
    >> 
    >> > data(heights)
    >> 
    >> > (m1 <- sitar(x=age, y=height, id=id, data=heights, df=5))
    >> 
    >> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
    >> 
    >> > m1 <- sitar(x=age, y=height, id=id, data=heights, df=7)
    >> 
    >> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
    >> 
    >> 
    >> 
    >> I don't know what is wrong. Any help would be appreciated.
    >> 
    >> 
    >> 
    >> 
    >> 
    >> Regards
    >> 
    >> 
    >> 
    >> Raymond
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> 
    >> This communication is subject to the University of Fort Hare e-Mail
    >> Disclaimer<http://www.ufh.ac.za/policies/UFH_E-mail_Disclaimer.pdf>
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 

    > [[alternative HTML version deleted]]

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ikponmwosa.egbon at uniben.edu  Tue Jul 18 16:08:51 2017
From: ikponmwosa.egbon at uniben.edu (Ikponmwosa Egbon)
Date: Tue, 18 Jul 2017 16:08:51 +0200
Subject: [R-sig-ME] Posthoc for the glmmTMB package
Message-ID: <CAAuMJtZA_-bFc1PaP28BjTeJtOmZNa7W-hDHHL1hj06KBTVofw@mail.gmail.com>

Hello All,

Please, I am a novice to 'glm with mixed effects (glmm)' and need the
guidance of mixed-model experts on how to conduct a posthoc test after
using the glmmTMB (http://www.biorxiv.org/content/biorxiv/early/
2017/05/01/132753.full.pdf) for a zero-inflated (Poisson) model for a
count data with repeated measures (over different times, hence time was
built in as a random effect).

Although I have run the model, I could not separate the different levels
(or treatments) within a factor (Genotypes) to know which is similar or
different, as often seen in the traditional ANOVAs or linear models,
wherein posthoc family-wise comparisons are usually conducted. Or perhaps
there are things I am not seeing with the novice spectacles.

*Please, see the script/output for statistical context below*:

> multiple<-read.delim("Multiplechoice.txt")
> str(multiple)
'data.frame': 1440 obs. of  3 variables:
 $ Genotypes: Factor w/ 8 levels "AR3","BR6","BR7",..: 2 2 2 2 2 2 2 2 2 2
...
 $ Time     : Factor w/ 18 levels "10m","15m","20m",..: 16 16 16 16 16 16
16 16 16 16 ...
 $ Insects  : int  2 0 0 0 1 0 0 0 0 0 ...
> head(multiple)
  Genotypes Time Insects
1       BR6   5m       2
2       BR6   5m       0
3       BR6   5m       0
4       BR6   5m       0
5       BR6   5m       1
6       BR6   5m       0
> library("glmmTMB")
> zipm0 <- glmmTMB(Insects~Genotypes + (1 | Time),
+                  zi = ~Genotypes,
+                  data = multiple, family = poisson)
> summary(zipm0)
 Family: poisson  ( log )
Formula:          Insects ~ Genotypes + (1 | Time)
Zero inflation:           ~Genotypes
Data: multiple

     AIC      BIC   logLik deviance df.resid
  2363.3   2453.0  -1164.7   2329.3     1423

Random effects:

Conditional model:
 Groups Name        Variance Std.Dev.
 Time   (Intercept) 0.7921   0.89
Number of obs: 1440, groups:  Time, 18

Conditional model:
                        Estimate Std. Error z value Pr(>|z|)
(Intercept)             -0.05931    0.23378  -0.254 0.799747
GenotypesBR6            -0.09546    0.13452  -0.710 0.477939
GenotypesBR7            -1.02963    0.19379  -5.313 1.08e-07 ***
GenotypesDR3            -0.34788    0.17393  -2.000 0.045491 *
GenotypesOut group      -0.21968    0.55045  -0.399 0.689827
GenotypesP. grandifolia -1.64415    0.40947  -4.015 5.94e-05 ***
GenotypesSA1            -0.57111    0.16067  -3.555 0.000378 ***
GenotypesVZ2            -0.43942    0.15825  -2.777 0.005492 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
                        Estimate Std. Error z value Pr(>|z|)
(Intercept)              -0.7956     0.2453  -3.244  0.00118 **
GenotypesBR6             -0.7542     0.5047  -1.494  0.13509
GenotypesBR7             -2.5021     3.5578  -0.703  0.48189
GenotypesDR3              1.5065     0.3695   4.077 4.55e-05 ***
GenotypesOut group        2.8023     0.4860   5.766 8.14e-09 ***
GenotypesP. grandifolia   1.4009     0.6815   2.056  0.03983 *
GenotypesSA1             -0.5077     0.5662  -0.897  0.36987
GenotypesVZ2             -0.3105     0.4580  -0.678  0.49779
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I look forward to having some feedbacks, and any other assistance that is
deemed necessary would be highly appreciated. Thank you for your time and
your assistance.


Kind
regards,


Ik.

-- 
"Disclaimer"
??This communication is intended for the above named person and is 
confidential and / or legally privileged. Any opinion(s) expressed in this 
communication are not necessarily those of UniBen (University of Benin). If 
it has come to you in error you must take no action based upon it, nor must 
you print it, copy it, forward it, or show it to anyone. Please delete and 
destroy the e-mail and any attachments and inform the sender immediately. 
Thank you.
UniBen is not responsible for the political, religious, racial or partisan 
opinion in any correspondence conducted by its domain users. Therefore, any 
such opinion expressed, whether explicitly or implicitly, in any said 
correspondence is not to be interpreted as that of UniBen.
UniBen may monitor all incoming and outgoing e-mails in line with UniBen 
business practice. Although UniBen has taken steps to ensure that e-mails 
and attachments are free from any virus, we advise that, in keeping with 
best business practice, the recipient must ensure they are actually virus 
free.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jul 19 04:49:44 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 18 Jul 2017 22:49:44 -0400
Subject: [R-sig-ME] Posthoc for the glmmTMB package
In-Reply-To: <CAAuMJtZA_-bFc1PaP28BjTeJtOmZNa7W-hDHHL1hj06KBTVofw@mail.gmail.com>
References: <CAAuMJtZA_-bFc1PaP28BjTeJtOmZNa7W-hDHHL1hj06KBTVofw@mail.gmail.com>
Message-ID: <4a000e32-a748-f4a6-401b-79f3a23fbe0d@gmail.com>


  I think the easiest way to do this is with lsmeans

https://stats.stackexchange.com/questions/145765/post-hoc-testing-in-multcompglht-for-mixed-effects-models-lme4-with-interact

  You *should* be able to use lsmeans with glmmTMB objects after running
 source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))

  I believe this is all operating/making comparisons based on the
conditional model, not the zero-inflation model ...

On 17-07-18 10:08 AM, Ikponmwosa Egbon wrote:
> Hello All,
> 
> Please, I am a novice to 'glm with mixed effects (glmm)' and need the
> guidance of mixed-model experts on how to conduct a posthoc test after
> using the glmmTMB (http://www.biorxiv.org/content/biorxiv/early/
> 2017/05/01/132753.full.pdf) for a zero-inflated (Poisson) model for a
> count data with repeated measures (over different times, hence time was
> built in as a random effect).
> 
> Although I have run the model, I could not separate the different levels
> (or treatments) within a factor (Genotypes) to know which is similar or
> different, as often seen in the traditional ANOVAs or linear models,
> wherein posthoc family-wise comparisons are usually conducted. Or perhaps
> there are things I am not seeing with the novice spectacles.
> 
> *Please, see the script/output for statistical context below*:
> 
>> multiple<-read.delim("Multiplechoice.txt")
>> str(multiple)
> 'data.frame': 1440 obs. of  3 variables:
>  $ Genotypes: Factor w/ 8 levels "AR3","BR6","BR7",..: 2 2 2 2 2 2 2 2 2 2
> ...
>  $ Time     : Factor w/ 18 levels "10m","15m","20m",..: 16 16 16 16 16 16
> 16 16 16 16 ...
>  $ Insects  : int  2 0 0 0 1 0 0 0 0 0 ...
>> head(multiple)
>   Genotypes Time Insects
> 1       BR6   5m       2
> 2       BR6   5m       0
> 3       BR6   5m       0
> 4       BR6   5m       0
> 5       BR6   5m       1
> 6       BR6   5m       0
>> library("glmmTMB")
>> zipm0 <- glmmTMB(Insects~Genotypes + (1 | Time),
> +                  zi = ~Genotypes,
> +                  data = multiple, family = poisson)
>> summary(zipm0)
>  Family: poisson  ( log )
> Formula:          Insects ~ Genotypes + (1 | Time)
> Zero inflation:           ~Genotypes
> Data: multiple
> 
>      AIC      BIC   logLik deviance df.resid
>   2363.3   2453.0  -1164.7   2329.3     1423
> 
> Random effects:
> 
> Conditional model:
>  Groups Name        Variance Std.Dev.
>  Time   (Intercept) 0.7921   0.89
> Number of obs: 1440, groups:  Time, 18
> 
> Conditional model:
>                         Estimate Std. Error z value Pr(>|z|)
> (Intercept)             -0.05931    0.23378  -0.254 0.799747
> GenotypesBR6            -0.09546    0.13452  -0.710 0.477939
> GenotypesBR7            -1.02963    0.19379  -5.313 1.08e-07 ***
> GenotypesDR3            -0.34788    0.17393  -2.000 0.045491 *
> GenotypesOut group      -0.21968    0.55045  -0.399 0.689827
> GenotypesP. grandifolia -1.64415    0.40947  -4.015 5.94e-05 ***
> GenotypesSA1            -0.57111    0.16067  -3.555 0.000378 ***
> GenotypesVZ2            -0.43942    0.15825  -2.777 0.005492 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Zero-inflation model:
>                         Estimate Std. Error z value Pr(>|z|)
> (Intercept)              -0.7956     0.2453  -3.244  0.00118 **
> GenotypesBR6             -0.7542     0.5047  -1.494  0.13509
> GenotypesBR7             -2.5021     3.5578  -0.703  0.48189
> GenotypesDR3              1.5065     0.3695   4.077 4.55e-05 ***
> GenotypesOut group        2.8023     0.4860   5.766 8.14e-09 ***
> GenotypesP. grandifolia   1.4009     0.6815   2.056  0.03983 *
> GenotypesSA1             -0.5077     0.5662  -0.897  0.36987
> GenotypesVZ2             -0.3105     0.4580  -0.678  0.49779
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> I look forward to having some feedbacks, and any other assistance that is
> deemed necessary would be highly appreciated. Thank you for your time and
> your assistance.
> 
> 
> Kind
> regards,
> 
> 
> Ik.
>


From Leen.Catrysse at uantwerpen.be  Wed Jul 19 13:21:19 2017
From: Leen.Catrysse at uantwerpen.be (Catrysse Leen)
Date: Wed, 19 Jul 2017 11:21:19 +0000
Subject: [R-sig-ME] p-values glmer in lme4
Message-ID: <D5950D4E.36BA%leen.catrysse@uantwerpen.be>

Dear,

I used GLMM to analyse eye-tracking data with the gamma distribution and the log link. P-values were automatically computed in the output (based on the asymptotic Wald tests).
We received a comment of a reviewer that the output of our GLMM is inconsistent, as we report a t-value from the output and the p-value based on the asymptotic Wald tests.
Does anyone has some feedback on how we can deal with this comment?

Thanks in advance,
Leen Catrysse

	[[alternative HTML version deleted]]


From amaengwork at gmail.com  Wed Jul 19 14:21:46 2017
From: amaengwork at gmail.com (Ahreum Maeng)
Date: Wed, 19 Jul 2017 07:21:46 -0500
Subject: [R-sig-ME] lme4 question
Message-ID: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>

Hello,

I am trying to run the following model:

DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))

As you see on the following sample data structure, "type" is repeated
measure where 0=A, 1=B. There are 4 ids within each type A and B.
Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as "0"
when type is 0 (B).
Would it be a right way to deal with this repeated measure issue?

?id type    A_id B_id IV    DV
1  1   0   1 1     3.14
2  1   0   2 2     4.67
3  1   0   3 3     4.23
4  1   0   4 1     7.00 ?
?1  0   1   0 2     3.00
2  0   2   0 3     4.77
3  0   3   0 1     4.25
4  0   4   0 2     7.12 ??

T?hank you so much for your help in advance!
-------------- next part --------------
Hello,

I am trying to run the following model:

DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))

As you see on the following sample data structure, "type" is repeated measure where 0=A, 1=B. There are 4 ids within each type A and B.  
Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as "0" when type is 0 (B).
Would it be a right way to deal with this repeated measure issue?

?id	type    A_id	B_id	IV    DV	
1	  1	   0	   1	1     3.14	
2	  1	   0	   2	2     4.67	
3	  1	   0	   3	3     4.23	
4	  1	   0	   4	1     7.00	?
?1	  0	   1	   0	2     3.00	
2	  0	   2	   0	3     4.77	
3	  0	   3	   0	1     4.25	
4	  0	   4	   0	2     7.12	??

T?hank you so much for your help in advance! 


From thierry.onkelinx at inbo.be  Wed Jul 19 14:52:19 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 19 Jul 2017 14:52:19 +0200
Subject: [R-sig-ME] lme4 question
In-Reply-To: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>
References: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>
Message-ID: <CAJuCY5yeevrARdG9+-VfsuRgnbGULdyp4P536yo_9YffJF7Cnw@mail.gmail.com>

Dear Ahream,

You need to tell us more about the data set. Is this the complete data?
What variable indicates the grouping?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-19 14:21 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:

> Hello,
>
> I am trying to run the following model:
>
> DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))
>
> As you see on the following sample data structure, "type" is repeated
> measure where 0=A, 1=B. There are 4 ids within each type A and B.
> Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as "0"
> when type is 0 (B).
> Would it be a right way to deal with this repeated measure issue?
>
> ?id type    A_id B_id IV    DV
> 1  1   0   1 1     3.14
> 2  1   0   2 2     4.67
> 3  1   0   3 3     4.23
> 4  1   0   4 1     7.00 ?
> ?1  0   1   0 2     3.00
> 2  0   2   0 3     4.77
> 3  0   3   0 1     4.25
> 4  0   4   0 2     7.12 ??
>
> T?hank you so much for your help in advance!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jul 19 16:19:23 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 19 Jul 2017 16:19:23 +0200
Subject: [R-sig-ME] lme4 question
In-Reply-To: <CAGNwpw2-BsRrKROM60GMJ_Jrr48V65At3O45D7nkJSmoaaX3oQ@mail.gmail.com>
References: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>
 <CAJuCY5yeevrARdG9+-VfsuRgnbGULdyp4P536yo_9YffJF7Cnw@mail.gmail.com>
 <CAGNwpw2-BsRrKROM60GMJ_Jrr48V65At3O45D7nkJSmoaaX3oQ@mail.gmail.com>
Message-ID: <CAJuCY5yycm+c1+QM6=SYduzJc1NE26DSqJ+Eqe0g7xAV6xkf1Q@mail.gmail.com>

Dear Ahreum,

Keep the mailinglist in cc.

Your coding is wrong. Look at the model output. You'll see 5 groups for A
and B instead of 4. You need all stimuli in a single variable (e.g. A1, A2,
A2, A4, B1, ...). The model becomes DV ~ type*IV+(1|id)+(0+type|id)+(
1|stimulus)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-19 15:58 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:

> No it is not a complete data. I show just part of it as an example.
> The grouping variable is "type": there are two types A (coded as 1) and B
> (coded as 0).
>
> id: individuals
> type: 2 types of stimuli nested within id. repeated within individual
> A_id: there are 4 different stimuli within each type (A and B). This
> variable indicates 4 different stimuli within type A. coded as 1, 2, 3, 4.
> B_id: there are 4 different stimuli within B.coded as 1, 2, 3, 4.
> IV: this variables is characteristics of each stimuli.
> DV: responses of individuals for stimuli.
>
> Please let me know if you need further information about the data set.
>
> Thank you so much for your kind help in advance,
> Ahreum
>
>
> On Wed, Jul 19, 2017 at 7:52 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Ahream,
>>
>> You need to tell us more about the data set. Is this the complete data?
>> What variable indicates the grouping?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2017-07-19 14:21 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:
>>
>>> Hello,
>>>
>>> I am trying to run the following model:
>>>
>>> DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))
>>>
>>> As you see on the following sample data structure, "type" is repeated
>>> measure where 0=A, 1=B. There are 4 ids within each type A and B.
>>> Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as
>>> "0"
>>> when type is 0 (B).
>>> Would it be a right way to deal with this repeated measure issue?
>>>
>>> ?id type    A_id B_id IV    DV
>>> 1  1   0   1 1     3.14
>>> 2  1   0   2 2     4.67
>>> 3  1   0   3 3     4.23
>>> 4  1   0   4 1     7.00 ?
>>> ?1  0   1   0 2     3.00
>>> 2  0   2   0 3     4.77
>>> 3  0   3   0 1     4.25
>>> 4  0   4   0 2     7.12 ??
>>>
>>> T?hank you so much for your help in advance!
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Ahreum Maeng
> Assistant Professor in Marketing
> KU School of Business
> University of Kansas
> #2183 Capitol Federal Hall
> 1654 Naismith Drive.
> Lawrence, KS 66045
> https://sites.google.com/site/ahreummaeng1/research
> <https://sites.google.com/site/ahreummaeng1/home>
>

	[[alternative HTML version deleted]]


From amaengwork at gmail.com  Wed Jul 19 16:26:34 2017
From: amaengwork at gmail.com (Ahreum Maeng)
Date: Wed, 19 Jul 2017 09:26:34 -0500
Subject: [R-sig-ME] lme4 question
In-Reply-To: <CAJuCY5yycm+c1+QM6=SYduzJc1NE26DSqJ+Eqe0g7xAV6xkf1Q@mail.gmail.com>
References: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>
 <CAJuCY5yeevrARdG9+-VfsuRgnbGULdyp4P536yo_9YffJF7Cnw@mail.gmail.com>
 <CAGNwpw2-BsRrKROM60GMJ_Jrr48V65At3O45D7nkJSmoaaX3oQ@mail.gmail.com>
 <CAJuCY5yycm+c1+QM6=SYduzJc1NE26DSqJ+Eqe0g7xAV6xkf1Q@mail.gmail.com>
Message-ID: <CAGNwpw19wmNvhoNBdeNk61s8f=eQ9Wkc9wzp6sX5fEfOZ+dwfg@mail.gmail.com>

Thank you so much for your reply! Just one more question -- would the model
still be able to account for the fact that the 4 stimuli were sampled from
population A and B respectively?

Thanks again,
Ahreum

On Wed, Jul 19, 2017 at 9:19 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Ahreum,
>
> Keep the mailinglist in cc.
>
> Your coding is wrong. Look at the model output. You'll see 5 groups for A
> and B instead of 4. You need all stimuli in a single variable (e.g. A1, A2,
> A2, A4, B1, ...). The model becomes DV ~ type*IV+(1|id)+(0+type|id)+(1|
> stimulus)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-07-19 15:58 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:
>
>> No it is not a complete data. I show just part of it as an example.
>> The grouping variable is "type": there are two types A (coded as 1) and B
>> (coded as 0).
>>
>> id: individuals
>> type: 2 types of stimuli nested within id. repeated within individual
>> A_id: there are 4 different stimuli within each type (A and B). This
>> variable indicates 4 different stimuli within type A. coded as 1, 2, 3, 4.
>> B_id: there are 4 different stimuli within B.coded as 1, 2, 3, 4.
>> IV: this variables is characteristics of each stimuli.
>> DV: responses of individuals for stimuli.
>>
>> Please let me know if you need further information about the data set.
>>
>> Thank you so much for your kind help in advance,
>> Ahreum
>>
>>
>> On Wed, Jul 19, 2017 at 7:52 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Ahream,
>>>
>>> You need to tell us more about the data set. Is this the complete data?
>>> What variable indicates the grouping?
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2017-07-19 14:21 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:
>>>
>>>> Hello,
>>>>
>>>> I am trying to run the following model:
>>>>
>>>> DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))
>>>>
>>>> As you see on the following sample data structure, "type" is repeated
>>>> measure where 0=A, 1=B. There are 4 ids within each type A and B.
>>>> Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as
>>>> "0"
>>>> when type is 0 (B).
>>>> Would it be a right way to deal with this repeated measure issue?
>>>>
>>>> ?id type    A_id B_id IV    DV
>>>> 1  1   0   1 1     3.14
>>>> 2  1   0   2 2     4.67
>>>> 3  1   0   3 3     4.23
>>>> 4  1   0   4 1     7.00 ?
>>>> ?1  0   1   0 2     3.00
>>>> 2  0   2   0 3     4.77
>>>> 3  0   3   0 1     4.25
>>>> 4  0   4   0 2     7.12 ??
>>>>
>>>> T?hank you so much for your help in advance!
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>> --
>> Ahreum Maeng
>> Assistant Professor in Marketing
>> KU School of Business
>> University of Kansas
>> #2183 Capitol Federal Hall
>> 1654 Naismith Drive.
>> Lawrence, KS 66045
>> https://sites.google.com/site/ahreummaeng1/research
>> <https://sites.google.com/site/ahreummaeng1/home>
>>
>
>


-- 
Ahreum Maeng
Assistant Professor in Marketing
KU School of Business
University of Kansas
#2183 Capitol Federal Hall
1654 Naismith Drive.
Lawrence, KS 66045
https://sites.google.com/site/ahreummaeng1/research
<https://sites.google.com/site/ahreummaeng1/home>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jul 19 16:32:58 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 19 Jul 2017 16:32:58 +0200
Subject: [R-sig-ME] lme4 question
In-Reply-To: <CAGNwpw19wmNvhoNBdeNk61s8f=eQ9Wkc9wzp6sX5fEfOZ+dwfg@mail.gmail.com>
References: <CAGNwpw1B5q-LXKAqbP2oVqM5c1tmNpu3V0YCkr_7XnLw5KwZYQ@mail.gmail.com>
 <CAJuCY5yeevrARdG9+-VfsuRgnbGULdyp4P536yo_9YffJF7Cnw@mail.gmail.com>
 <CAGNwpw2-BsRrKROM60GMJ_Jrr48V65At3O45D7nkJSmoaaX3oQ@mail.gmail.com>
 <CAJuCY5yycm+c1+QM6=SYduzJc1NE26DSqJ+Eqe0g7xAV6xkf1Q@mail.gmail.com>
 <CAGNwpw19wmNvhoNBdeNk61s8f=eQ9Wkc9wzp6sX5fEfOZ+dwfg@mail.gmail.com>
Message-ID: <CAJuCY5zzGX1Yqon+M5bwwtSEx+DbnphnGuGba-j+xFYFVTEfzQ@mail.gmail.com>

No, This would assume that both stimuli originate from the same
distribution.  DV ~ type*IV+(1|id)+(0+type|id)+(0+factor(type)|stimulus)
would allow a differente variance for each type of stimulus. Note however
that you have only 4 stimuli from each type. You can get reasonable
variance estimates from only 4 groups...

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-19 16:26 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:

> Thank you so much for your reply! Just one more question -- would the
> model still be able to account for the fact that the 4 stimuli were sampled
> from population A and B respectively?
>
> Thanks again,
> Ahreum
>
> On Wed, Jul 19, 2017 at 9:19 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Ahreum,
>>
>> Keep the mailinglist in cc.
>>
>> Your coding is wrong. Look at the model output. You'll see 5 groups for A
>> and B instead of 4. You need all stimuli in a single variable (e.g. A1, A2,
>> A2, A4, B1, ...). The model becomes DV ~ type*IV+(1|id)+(0+type|id)+(1|
>> stimulus)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2017-07-19 15:58 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:
>>
>>> No it is not a complete data. I show just part of it as an example.
>>> The grouping variable is "type": there are two types A (coded as 1) and
>>> B (coded as 0).
>>>
>>> id: individuals
>>> type: 2 types of stimuli nested within id. repeated within individual
>>> A_id: there are 4 different stimuli within each type (A and B). This
>>> variable indicates 4 different stimuli within type A. coded as 1, 2, 3, 4.
>>> B_id: there are 4 different stimuli within B.coded as 1, 2, 3, 4.
>>> IV: this variables is characteristics of each stimuli.
>>> DV: responses of individuals for stimuli.
>>>
>>> Please let me know if you need further information about the data set.
>>>
>>> Thank you so much for your kind help in advance,
>>> Ahreum
>>>
>>>
>>> On Wed, Jul 19, 2017 at 7:52 AM, Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be> wrote:
>>>
>>>> Dear Ahream,
>>>>
>>>> You need to tell us more about the data set. Is this the complete data?
>>>> What variable indicates the grouping?
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2017-07-19 14:21 GMT+02:00 Ahreum Maeng <amaengwork at gmail.com>:
>>>>
>>>>> Hello,
>>>>>
>>>>> I am trying to run the following model:
>>>>>
>>>>> DV ~ type*IV+((1|id)+(0+type|id)+(1|A_id)+(1|B_id))
>>>>>
>>>>> As you see on the following sample data structure, "type" is repeated
>>>>> measure where 0=A, 1=B. There are 4 ids within each type A and B.
>>>>> Thus, I coded "B_id" as "0" when the type is 1 (A) and coded "A_id" as
>>>>> "0"
>>>>> when type is 0 (B).
>>>>> Would it be a right way to deal with this repeated measure issue?
>>>>>
>>>>> ?id type    A_id B_id IV    DV
>>>>> 1  1   0   1 1     3.14
>>>>> 2  1   0   2 2     4.67
>>>>> 3  1   0   3 3     4.23
>>>>> 4  1   0   4 1     7.00 ?
>>>>> ?1  0   1   0 2     3.00
>>>>> 2  0   2   0 3     4.77
>>>>> 3  0   3   0 1     4.25
>>>>> 4  0   4   0 2     7.12 ??
>>>>>
>>>>> T?hank you so much for your help in advance!
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> Ahreum Maeng
>>> Assistant Professor in Marketing
>>> KU School of Business
>>> University of Kansas
>>> #2183 Capitol Federal Hall
>>> 1654 Naismith Drive.
>>> Lawrence, KS 66045
>>> https://sites.google.com/site/ahreummaeng1/research
>>> <https://sites.google.com/site/ahreummaeng1/home>
>>>
>>
>>
>
>
> --
> Ahreum Maeng
> Assistant Professor in Marketing
> KU School of Business
> University of Kansas
> #2183 Capitol Federal Hall
> 1654 Naismith Drive.
> Lawrence, KS 66045
> https://sites.google.com/site/ahreummaeng1/research
> <https://sites.google.com/site/ahreummaeng1/home>
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Jul 19 20:50:21 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 19 Jul 2017 18:50:21 +0000
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>

Dear Leen Catrysse,

I'm going to assume that you used the glmer() function in the lme4 package to fit your gamma GLMM. I notice that the summary() for a gamma model fit by glmer() reports a "t value" for each fixed-effect coefficient  -- simply the Wald statistics given by the ratio of the estimated coefficient to its estimated asymptotic standard error -- followed by a "Pr(>|z|)". 

I suspect that the Wald statistic is labelled as a "t value" because the gamma GLMM has an estimated dispersion parameter, but because there are no degrees of freedom calculated for the estimated dispersion (as there could be, for example, for a LMM fit by REML), I think that it would probably be preferable to call the Wald statistic a "z value." In any event, the notation "Pr(>|z|)" suggests that the standard normal distribution is used to obtain a p-value.

So, to satisfy the reviewer, why not just call the Wald statistics "z-values" rather than a "t-values"?

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Catrysse Leen
> Sent: Wednesday, July 19, 2017 7:21 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] p-values glmer in lme4
> 
> Dear,
> 
> I used GLMM to analyse eye-tracking data with the gamma distribution and the
> log link. P-values were automatically computed in the output (based on the
> asymptotic Wald tests).
> We received a comment of a reviewer that the output of our GLMM is
> inconsistent, as we report a t-value from the output and the p-value based on
> the asymptotic Wald tests.
> Does anyone has some feedback on how we can deal with this comment?
> 
> Thanks in advance,
> Leen Catrysse
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jul 19 21:28:48 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 19 Jul 2017 15:28:48 -0400
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
 <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>


  This diagnosis sounds correct, and I agree that calling these numbers
"z values" is probably the best way to make the reviewers happy.

It opens an interesting terminological can of worms.  My initial
reaction to John's post was "oh, I guess glmer should print 'z value'
rather than 't value' even for fits using families with an estimated
dispersion parameter". Then I thought "but if that's true shouldn't lmer
also print 'z value' rather than 't value', since it provides
essentially the same numbers?" Then I thought "if we switch lmer to
printing 'z value' will everyone start asking 'why does lmer provide z
values rather than t values?"  Sigh.

  The point is that most of this, while unfairly confusing, is just
convention.  "z values" and "t values" are the same thing - MLEs (or
REML estimates) of the parameters divided by their estimated standard
deviations. Of the common (G)LMM applications, the *only* case in which
these values are actually known to follow a t distribution exactly is
for linear mixed models (Gaussian conditional distribution), in the
classic case of a balanced, nested design (and, implied by John below,
that the fit uses REML). Otherwise it becomes a question of which
approximations you're happy with.

  And the sampling distributions of these values are never Normal (even
in the perfect theoretical world where all model assumptions are true),
except asymptotically.


On 17-07-19 02:50 PM, Fox, John wrote:
> Dear Leen Catrysse,
> 
> I'm going to assume that you used the glmer() function in the lme4 package to fit your gamma GLMM. I notice that the summary() for a gamma model fit by glmer() reports a "t value" for each fixed-effect coefficient  -- simply the Wald statistics given by the ratio of the estimated coefficient to its estimated asymptotic standard error -- followed by a "Pr(>|z|)". 
> 
> I suspect that the Wald statistic is labelled as a "t value" because the gamma GLMM has an estimated dispersion parameter, but because there are no degrees of freedom calculated for the estimated dispersion (as there could be, for example, for a LMM fit by REML), I think that it would probably be preferable to call the Wald statistic a "z value." In any event, the notation "Pr(>|z|)" suggests that the standard normal distribution is used to obtain a p-value.
> 
> So, to satisfy the reviewer, why not just call the Wald statistics "z-values" rather than a "t-values"?
> 
> I hope this helps,
>  John
> 
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>> On Behalf Of Catrysse Leen
>> Sent: Wednesday, July 19, 2017 7:21 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] p-values glmer in lme4
>>
>> Dear,
>>
>> I used GLMM to analyse eye-tracking data with the gamma distribution and the
>> log link. P-values were automatically computed in the output (based on the
>> asymptotic Wald tests).
>> We received a comment of a reviewer that the output of our GLMM is
>> inconsistent, as we report a t-value from the output and the p-value based on
>> the asymptotic Wald tests.
>> Does anyone has some feedback on how we can deal with this comment?
>>
>> Thanks in advance,
>> Leen Catrysse
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jfox at mcmaster.ca  Wed Jul 19 21:58:05 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 19 Jul 2017 19:58:05 +0000
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <23841_1500492542_v6JJT24i017618_c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
 <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
 <23841_1500492542_v6JJT24i017618_c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83669BB39@FHSDB4H16-2.csu.mcmaster.ca>

Hi Ben,

I'm glad that you chimed in on this question.

Of course, what you say about (virtually) all the p-values being approximations is correct. My own preference would be to use "t-value" when you look up a p-value (approximate or not) for a Wald statistic in a t-distribution and "z-value" when you look up (an asymptotic approximation to) a p-value in the standard-normal distribution. Frankly, however, this seems a bit like splitting hairs, and so I think that what you do now is fine.

Best,
 John

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, July 19, 2017 3:29 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] p-values glmer in lme4
> 
> 
>   This diagnosis sounds correct, and I agree that calling these numbers "z
> values" is probably the best way to make the reviewers happy.
> 
> It opens an interesting terminological can of worms.  My initial reaction to
> John's post was "oh, I guess glmer should print 'z value'
> rather than 't value' even for fits using families with an estimated dispersion
> parameter". Then I thought "but if that's true shouldn't lmer also print 'z value'
> rather than 't value', since it provides essentially the same numbers?" Then I
> thought "if we switch lmer to printing 'z value' will everyone start asking 'why
> does lmer provide z values rather than t values?"  Sigh.
> 
>   The point is that most of this, while unfairly confusing, is just convention.  "z
> values" and "t values" are the same thing - MLEs (or REML estimates) of the
> parameters divided by their estimated standard deviations. Of the common
> (G)LMM applications, the *only* case in which these values are actually known
> to follow a t distribution exactly is for linear mixed models (Gaussian
> conditional distribution), in the classic case of a balanced, nested design (and,
> implied by John below, that the fit uses REML). Otherwise it becomes a
> question of which approximations you're happy with.
> 
>   And the sampling distributions of these values are never Normal (even in the
> perfect theoretical world where all model assumptions are true), except
> asymptotically.
> 
> 
> On 17-07-19 02:50 PM, Fox, John wrote:
> > Dear Leen Catrysse,
> >
> > I'm going to assume that you used the glmer() function in the lme4 package
> to fit your gamma GLMM. I notice that the summary() for a gamma model fit by
> glmer() reports a "t value" for each fixed-effect coefficient  -- simply the Wald
> statistics given by the ratio of the estimated coefficient to its estimated
> asymptotic standard error -- followed by a "Pr(>|z|)".
> >
> > I suspect that the Wald statistic is labelled as a "t value" because the gamma
> GLMM has an estimated dispersion parameter, but because there are no
> degrees of freedom calculated for the estimated dispersion (as there could be,
> for example, for a LMM fit by REML), I think that it would probably be
> preferable to call the Wald statistic a "z value." In any event, the notation
> "Pr(>|z|)" suggests that the standard normal distribution is used to obtain a p-
> value.
> >
> > So, to satisfy the reviewer, why not just call the Wald statistics "z-values"
> rather than a "t-values"?
> >
> > I hope this helps,
> >  John
> >
> > -----------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models
> >> [mailto:r-sig-mixed-models-bounces at r-project.org]
> >> On Behalf Of Catrysse Leen
> >> Sent: Wednesday, July 19, 2017 7:21 AM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] p-values glmer in lme4
> >>
> >> Dear,
> >>
> >> I used GLMM to analyse eye-tracking data with the gamma distribution
> >> and the log link. P-values were automatically computed in the output
> >> (based on the asymptotic Wald tests).
> >> We received a comment of a reviewer that the output of our GLMM is
> >> inconsistent, as we report a t-value from the output and the p-value
> >> based on the asymptotic Wald tests.
> >> Does anyone has some feedback on how we can deal with this comment?
> >>
> >> Thanks in advance,
> >> Leen Catrysse
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jul 19 23:18:18 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 19 Jul 2017 17:18:18 -0400
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83669BB39@FHSDB4H16-2.csu.mcmaster.ca>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
 <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
 <23841_1500492542_v6JJT24i017618_c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83669BB39@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <f4fdab18-cc6c-1856-5fe1-a37b152afffe@gmail.com>



   I agree that the label should go according to the inference used. The
funny (??) thing is that in base lmer (not in the lmerTest extension
package) *the summary doesn't print p-values at all*, so according to
the rubric above we can't tell whether the (mean/stderr) column should
be labeled 'z' or 't'. (We could label that column 'mean/std.err.', but
then some users would ask "why doesn't the summary print either z or t
values?" :-( )


On 17-07-19 03:58 PM, Fox, John wrote:
> Hi Ben,
> 
> I'm glad that you chimed in on this question.
> 
> Of course, what you say about (virtually) all the p-values being
> approximations is correct. My own preference would be to use
> "t-value" when you look up a p-value (approximate or not) for a Wald
> statistic in a t-distribution and "z-value" when you look up (an
> asymptotic approximation to) a p-value in the standard-normal
> distribution. Frankly, however, this seems a bit like splitting
> hairs, and so I think that what you do now is fine.
> 
> Best, John


> 
>> -----Original Message----- From: R-sig-mixed-models
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
>> Bolker Sent: Wednesday, July 19, 2017 3:29 PM To:
>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] p-values
>> glmer in lme4
>> 
>> 
>> This diagnosis sounds correct, and I agree that calling these
>> numbers "z values" is probably the best way to make the reviewers
>> happy.
>> 
>> It opens an interesting terminological can of worms.  My initial
>> reaction to John's post was "oh, I guess glmer should print 'z
>> value' rather than 't value' even for fits using families with an
>> estimated dispersion parameter". Then I thought "but if that's true
>> shouldn't lmer also print 'z value' rather than 't value', since it
>> provides essentially the same numbers?" Then I thought "if we
>> switch lmer to printing 'z value' will everyone start asking 'why 
>> does lmer provide z values rather than t values?"  Sigh.
>> 
>> The point is that most of this, while unfairly confusing, is just
>> convention.  "z values" and "t values" are the same thing - MLEs
>> (or REML estimates) of the parameters divided by their estimated
>> standard deviations. Of the common (G)LMM applications, the *only*
>> case in which these values are actually known to follow a t
>> distribution exactly is for linear mixed models (Gaussian 
>> conditional distribution), in the classic case of a balanced,
>> nested design (and, implied by John below, that the fit uses REML).
>> Otherwise it becomes a question of which approximations you're
>> happy with.
>> 
>> And the sampling distributions of these values are never Normal
>> (even in the perfect theoretical world where all model assumptions
>> are true), except asymptotically.
>> 
>> 
>> On 17-07-19 02:50 PM, Fox, John wrote:
>>> Dear Leen Catrysse,
>>> 
>>> I'm going to assume that you used the glmer() function in the
>>> lme4 package
>> to fit your gamma GLMM. I notice that the summary() for a gamma
>> model fit by glmer() reports a "t value" for each fixed-effect
>> coefficient  -- simply the Wald statistics given by the ratio of
>> the estimated coefficient to its estimated asymptotic standard
>> error -- followed by a "Pr(>|z|)".
>>> 
>>> I suspect that the Wald statistic is labelled as a "t value"
>>> because the gamma
>> GLMM has an estimated dispersion parameter, but because there are
>> no degrees of freedom calculated for the estimated dispersion (as
>> there could be, for example, for a LMM fit by REML), I think that
>> it would probably be preferable to call the Wald statistic a "z
>> value." In any event, the notation "Pr(>|z|)" suggests that the
>> standard normal distribution is used to obtain a p- value.
>>> 
>>> So, to satisfy the reviewer, why not just call the Wald
>>> statistics "z-values"
>> rather than a "t-values"?
>>> 
>>> I hope this helps, John
>>> 
>>> ----------------------------- John Fox, Professor Emeritus 
>>> McMaster University Hamilton, Ontario, Canada Web:
>>> socserv.mcmaster.ca/jfox
>>> 
>>> 
>>> 
>>>> -----Original Message----- From: R-sig-mixed-models 
>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
>>>> Catrysse Leen Sent: Wednesday, July 19, 2017 7:21 AM To:
>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] p-values
>>>> glmer in lme4
>>>> 
>>>> Dear,
>>>> 
>>>> I used GLMM to analyse eye-tracking data with the gamma
>>>> distribution and the log link. P-values were automatically
>>>> computed in the output (based on the asymptotic Wald tests). We
>>>> received a comment of a reviewer that the output of our GLMM
>>>> is inconsistent, as we report a t-value from the output and the
>>>> p-value based on the asymptotic Wald tests. Does anyone has
>>>> some feedback on how we can deal with this comment?
>>>> 
>>>> Thanks in advance, Leen Catrysse
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From phillip.alday at mpi.nl  Wed Jul 19 23:53:30 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 19 Jul 2017 23:53:30 +0200
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <f4fdab18-cc6c-1856-5fe1-a37b152afffe@gmail.com>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
 <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
 <23841_1500492542_v6JJT24i017618_c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83669BB39@FHSDB4H16-2.csu.mcmaster.ca>
 <f4fdab18-cc6c-1856-5fe1-a37b152afffe@gmail.com>
Message-ID: <6b5224e0-a2b5-5cf5-215f-2dad9ff0ad39@mpi.nl>

And to add to the mix: MixedModels.jl labels the the (mean/stderr)
column 'z' for LMM and provides p-values, which is an interesting
development from the Doug Bates' R FAQ entry on the lack of p-values in
lme4. (And the default estimation is once again ML and not REML.) None
of it terribly surprising based on DB's comments here and elsewhere over
the years, but an interesting course nonetheless.

Phillip

On 07/19/2017 11:18 PM, Ben Bolker wrote:
>
>    I agree that the label should go according to the inference used. The
> funny (??) thing is that in base lmer (not in the lmerTest extension
> package) *the summary doesn't print p-values at all*, so according to
> the rubric above we can't tell whether the (mean/stderr) column should
> be labeled 'z' or 't'. (We could label that column 'mean/std.err.', but
> then some users would ask "why doesn't the summary print either z or t
> values?" :-( )
>
>
> On 17-07-19 03:58 PM, Fox, John wrote:
>> Hi Ben,
>>
>> I'm glad that you chimed in on this question.
>>
>> Of course, what you say about (virtually) all the p-values being
>> approximations is correct. My own preference would be to use
>> "t-value" when you look up a p-value (approximate or not) for a Wald
>> statistic in a t-distribution and "z-value" when you look up (an
>> asymptotic approximation to) a p-value in the standard-normal
>> distribution. Frankly, however, this seems a bit like splitting
>> hairs, and so I think that what you do now is fine.
>>
>> Best, John
>
>>> -----Original Message----- From: R-sig-mixed-models
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
>>> Bolker Sent: Wednesday, July 19, 2017 3:29 PM To:
>>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] p-values
>>> glmer in lme4
>>>
>>>
>>> This diagnosis sounds correct, and I agree that calling these
>>> numbers "z values" is probably the best way to make the reviewers
>>> happy.
>>>
>>> It opens an interesting terminological can of worms.  My initial
>>> reaction to John's post was "oh, I guess glmer should print 'z
>>> value' rather than 't value' even for fits using families with an
>>> estimated dispersion parameter". Then I thought "but if that's true
>>> shouldn't lmer also print 'z value' rather than 't value', since it
>>> provides essentially the same numbers?" Then I thought "if we
>>> switch lmer to printing 'z value' will everyone start asking 'why 
>>> does lmer provide z values rather than t values?"  Sigh.
>>>
>>> The point is that most of this, while unfairly confusing, is just
>>> convention.  "z values" and "t values" are the same thing - MLEs
>>> (or REML estimates) of the parameters divided by their estimated
>>> standard deviations. Of the common (G)LMM applications, the *only*
>>> case in which these values are actually known to follow a t
>>> distribution exactly is for linear mixed models (Gaussian 
>>> conditional distribution), in the classic case of a balanced,
>>> nested design (and, implied by John below, that the fit uses REML).
>>> Otherwise it becomes a question of which approximations you're
>>> happy with.
>>>
>>> And the sampling distributions of these values are never Normal
>>> (even in the perfect theoretical world where all model assumptions
>>> are true), except asymptotically.
>>>
>>>
>>> On 17-07-19 02:50 PM, Fox, John wrote:
>>>> Dear Leen Catrysse,
>>>>
>>>> I'm going to assume that you used the glmer() function in the
>>>> lme4 package
>>> to fit your gamma GLMM. I notice that the summary() for a gamma
>>> model fit by glmer() reports a "t value" for each fixed-effect
>>> coefficient  -- simply the Wald statistics given by the ratio of
>>> the estimated coefficient to its estimated asymptotic standard
>>> error -- followed by a "Pr(>|z|)".
>>>> I suspect that the Wald statistic is labelled as a "t value"
>>>> because the gamma
>>> GLMM has an estimated dispersion parameter, but because there are
>>> no degrees of freedom calculated for the estimated dispersion (as
>>> there could be, for example, for a LMM fit by REML), I think that
>>> it would probably be preferable to call the Wald statistic a "z
>>> value." In any event, the notation "Pr(>|z|)" suggests that the
>>> standard normal distribution is used to obtain a p- value.
>>>> So, to satisfy the reviewer, why not just call the Wald
>>>> statistics "z-values"
>>> rather than a "t-values"?
>>>> I hope this helps, John
>>>>
>>>> ----------------------------- John Fox, Professor Emeritus 
>>>> McMaster University Hamilton, Ontario, Canada Web:
>>>> socserv.mcmaster.ca/jfox
>>>>
>>>>
>>>>
>>>>> -----Original Message----- From: R-sig-mixed-models 
>>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
>>>>> Catrysse Leen Sent: Wednesday, July 19, 2017 7:21 AM To:
>>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] p-values
>>>>> glmer in lme4
>>>>>
>>>>> Dear,
>>>>>
>>>>> I used GLMM to analyse eye-tracking data with the gamma
>>>>> distribution and the log link. P-values were automatically
>>>>> computed in the output (based on the asymptotic Wald tests). We
>>>>> received a comment of a reviewer that the output of our GLMM
>>>>> is inconsistent, as we report a t-value from the output and the
>>>>> p-value based on the asymptotic Wald tests. Does anyone has
>>>>> some feedback on how we can deal with this comment?
>>>>>
>>>>> Thanks in advance, Leen Catrysse
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________ 
>>>>> R-sig-mixed-models at r-project.org mailing list 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> _______________________________________________ 
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Jul 21 04:53:27 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 20 Jul 2017 22:53:27 -0400
Subject: [R-sig-ME] cloglog models (Rolf's question from a few days ago)
Message-ID: <84d98763-fc07-c57c-f9c2-d478e3bf3f55@gmail.com>


  I got a little carried away.

 cloglog examples here with various glmer settings, glmmTMB,
MixedModels.jl (thanks to Doug Bates for troubleshooting) ...

 http://bbolker.github.io/mixedmodels-misc/notes/cloglogsim.html

 https://github.com/bbolker/mixedmodels-misc/blob/master/notes/cloglogsim.rmd


From r.turner at auckland.ac.nz  Fri Jul 21 07:09:21 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 21 Jul 2017 17:09:21 +1200
Subject: [R-sig-ME] [FORGED] cloglog models (Rolf's question from a few
 days ago)
In-Reply-To: <84d98763-fc07-c57c-f9c2-d478e3bf3f55@gmail.com>
References: <84d98763-fc07-c57c-f9c2-d478e3bf3f55@gmail.com>
Message-ID: <d9aa7636-0476-3e45-1ed3-55acfff09e9a@auckland.ac.nz>


On 21/07/17 14:53, Ben Bolker wrote:

> 
>    I got a little carried away.
> 
>   cloglog examples here with various glmer settings, glmmTMB,
> MixedModels.jl (thanks to Doug Bates for troubleshooting) ...
> 
>   http://bbolker.github.io/mixedmodels-misc/notes/cloglogsim.html
> 
>   https://github.com/bbolker/mixedmodels-misc/blob/master/notes/cloglogsim.rmd

Dear Ben,

Holy Ramoles!!!  Did you *ever* get carried away!  There's a lot there 
for me to digest; probably deeper than I am *able* to digest, but I'll try.

Thanks hugely for the time and effort that you've put into this.  I hope 
that it was rewarding from your pov.

I will very likely be coming back to you/this list with more questions, 
once I've thought things over for a while.

Thanks again.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bates at stat.wisc.edu  Sat Jul 22 21:58:17 2017
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 22 Jul 2017 19:58:17 +0000
Subject: [R-sig-ME] [FORGED] cloglog models (Rolf's question from a few
 days ago)
In-Reply-To: <d9aa7636-0476-3e45-1ed3-55acfff09e9a@auckland.ac.nz>
References: <84d98763-fc07-c57c-f9c2-d478e3bf3f55@gmail.com>
 <d9aa7636-0476-3e45-1ed3-55acfff09e9a@auckland.ac.nz>
Message-ID: <CAO7JsnRjj19So5jzLCURYiQRLdMAfgB0e+93s5uzRc3CK-JvWQ@mail.gmail.com>

Just a note about the Julia version.  Ben and I have been discussing it in
https://github.com/dmbates/MixedModels.jl/issues/92.  This example turned
up a couple of issues with the code.  Having fixed those the Julia version
is now the one of the fastest and produces a log-likelihood value in excess
of the others.  Ben says he will modify his writeup accordingly.

On Fri, Jul 21, 2017 at 12:09 AM Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> On 21/07/17 14:53, Ben Bolker wrote:
>
> >
> >    I got a little carried away.
> >
> >   cloglog examples here with various glmer settings, glmmTMB,
> > MixedModels.jl (thanks to Doug Bates for troubleshooting) ...
> >
> >   http://bbolker.github.io/mixedmodels-misc/notes/cloglogsim.html
> >
> >
> https://github.com/bbolker/mixedmodels-misc/blob/master/notes/cloglogsim.rmd
>
> Dear Ben,
>
> Holy Ramoles!!!  Did you *ever* get carried away!  There's a lot there
> for me to digest; probably deeper than I am *able* to digest, but I'll try.
>
> Thanks hugely for the time and effort that you've put into this.  I hope
> that it was rewarding from your pov.
>
> I will very likely be coming back to you/this list with more questions,
> once I've thought things over for a while.
>
> Thanks again.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276 <+64%209-373%207599>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Sat Jul 22 22:03:12 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Sat, 22 Jul 2017 22:03:12 +0200
Subject: [R-sig-ME] [FORGED] cloglog models (Rolf's question from a few
 days ago)
In-Reply-To: <CAO7JsnRjj19So5jzLCURYiQRLdMAfgB0e+93s5uzRc3CK-JvWQ@mail.gmail.com>
References: <84d98763-fc07-c57c-f9c2-d478e3bf3f55@gmail.com>
 <d9aa7636-0476-3e45-1ed3-55acfff09e9a@auckland.ac.nz>
 <CAO7JsnRjj19So5jzLCURYiQRLdMAfgB0e+93s5uzRc3CK-JvWQ@mail.gmail.com>
Message-ID: <CAGoSky-91sBfSNgWHEbaVdZN5TCWeVJHZimc9O6J5C0bkovEMw@mail.gmail.com>

brms shows some strange behavior as well. I will look into it and see what
can be improved.

2017-07-22 21:58 GMT+02:00 Douglas Bates <bates at stat.wisc.edu>:

> Just a note about the Julia version.  Ben and I have been discussing it in
> https://github.com/dmbates/MixedModels.jl/issues/92.  This example turned
> up a couple of issues with the code.  Having fixed those the Julia version
> is now the one of the fastest and produces a log-likelihood value in excess
> of the others.  Ben says he will modify his writeup accordingly.
>
> On Fri, Jul 21, 2017 at 12:09 AM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> >
> > On 21/07/17 14:53, Ben Bolker wrote:
> >
> > >
> > >    I got a little carried away.
> > >
> > >   cloglog examples here with various glmer settings, glmmTMB,
> > > MixedModels.jl (thanks to Doug Bates for troubleshooting) ...
> > >
> > >   http://bbolker.github.io/mixedmodels-misc/notes/cloglogsim.html
> > >
> > >
> > https://github.com/bbolker/mixedmodels-misc/blob/master/
> notes/cloglogsim.rmd
> >
> > Dear Ben,
> >
> > Holy Ramoles!!!  Did you *ever* get carried away!  There's a lot there
> > for me to digest; probably deeper than I am *able* to digest, but I'll
> try.
> >
> > Thanks hugely for the time and effort that you've put into this.  I hope
> > that it was rewarding from your pov.
> >
> > I will very likely be coming back to you/this list with more questions,
> > once I've thought things over for a while.
> >
> > Thanks again.
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276 <+64%209-373%207599>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Tue Jul 25 17:52:11 2017
From: Ramgad82 at gmx.net (Dagmar)
Date: Tue, 25 Jul 2017 17:52:11 +0200
Subject: [R-sig-ME] glmer.nb offset problem
Message-ID: <0f436b65-8d6e-6498-3c83-dd54f3bf4966@gmx.net>

Dear all,

I am having a problem with a negative binomial GLMM using an offset.

I have GPS fixes from animals and calculated their homerange. Now I want 
to test if there are differences in the size of the homeranges between 
seasons of the year.

I did a simple linear regression analysis between size of home range and 
sample size (number of GPS fixes) and unfortunately found a slight 
positive relationship: The bigger my samle size the larger is the 
homerange. That is why I thought to use sample size as an offset in my 
negative binomial glmm.

My code is:

glmer.nb (Homerangearea ~SeasonOfYear 
+(1|AnimalID)+offset(log(NumberOfGPSfixes)), data=mydataframe)

Without an offset I get a wonderful result with totaly nice fitted 
values. My problem is: When I include the offset my fitted values go 
towards 0. Why is that?

The number of GPS fixes is very different between animals. In one case I 
do only have 60 fixes, in another case I do have 12800. Maybe this 
difference is too big? I do not totally understand what the offset is 
doing to the data. As far as I understood it adds some weighting to some 
data. Is that correct?

In other examples which I found online an offset is only used for small 
numbers. Or is an offset even not the right tool for my problem?

Help would be very much (!!) appreciated.

Tagmarie


From bates at stat.wisc.edu  Tue Jul 25 18:38:07 2017
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 25 Jul 2017 16:38:07 +0000
Subject: [R-sig-ME] p-values glmer in lme4
In-Reply-To: <6b5224e0-a2b5-5cf5-215f-2dad9ff0ad39@mpi.nl>
References: <10026_1500467210_v6JCQnFV001147_D5950D4E.36BA%leen.catrysse@uantwerpen.be>
 <ACD1644AA6C67E4FBD0C350625508EC83669BAF1@FHSDB4H16-2.csu.mcmaster.ca>
 <23841_1500492542_v6JJT24i017618_c352640a-e07c-0178-fcc3-39c770ac25ab@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83669BB39@FHSDB4H16-2.csu.mcmaster.ca>
 <f4fdab18-cc6c-1856-5fe1-a37b152afffe@gmail.com>
 <6b5224e0-a2b5-5cf5-215f-2dad9ff0ad39@mpi.nl>
Message-ID: <CAO7JsnQnNba-+BCW1fNF0BnrjEHa31edZv3-E7S-GgQHEgOL+w@mail.gmail.com>

My favorite Oscar Wilde quote is "Consistency is the last refuge of the
unimaginative".

On Wed, Jul 19, 2017 at 4:53 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> And to add to the mix: MixedModels.jl labels the the (mean/stderr)
> column 'z' for LMM and provides p-values, which is an interesting
> development from the Doug Bates' R FAQ entry on the lack of p-values in
> lme4. (And the default estimation is once again ML and not REML.) None
> of it terribly surprising based on DB's comments here and elsewhere over
> the years, but an interesting course nonetheless.
>
> Phillip
>
> On 07/19/2017 11:18 PM, Ben Bolker wrote:
> >
> >    I agree that the label should go according to the inference used. The
> > funny (??) thing is that in base lmer (not in the lmerTest extension
> > package) *the summary doesn't print p-values at all*, so according to
> > the rubric above we can't tell whether the (mean/stderr) column should
> > be labeled 'z' or 't'. (We could label that column 'mean/std.err.', but
> > then some users would ask "why doesn't the summary print either z or t
> > values?" :-( )
> >
> >
> > On 17-07-19 03:58 PM, Fox, John wrote:
> >> Hi Ben,
> >>
> >> I'm glad that you chimed in on this question.
> >>
> >> Of course, what you say about (virtually) all the p-values being
> >> approximations is correct. My own preference would be to use
> >> "t-value" when you look up a p-value (approximate or not) for a Wald
> >> statistic in a t-distribution and "z-value" when you look up (an
> >> asymptotic approximation to) a p-value in the standard-normal
> >> distribution. Frankly, however, this seems a bit like splitting
> >> hairs, and so I think that what you do now is fine.
> >>
> >> Best, John
> >
> >>> -----Original Message----- From: R-sig-mixed-models
> >>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
> >>> Bolker Sent: Wednesday, July 19, 2017 3:29 PM To:
> >>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] p-values
> >>> glmer in lme4
> >>>
> >>>
> >>> This diagnosis sounds correct, and I agree that calling these
> >>> numbers "z values" is probably the best way to make the reviewers
> >>> happy.
> >>>
> >>> It opens an interesting terminological can of worms.  My initial
> >>> reaction to John's post was "oh, I guess glmer should print 'z
> >>> value' rather than 't value' even for fits using families with an
> >>> estimated dispersion parameter". Then I thought "but if that's true
> >>> shouldn't lmer also print 'z value' rather than 't value', since it
> >>> provides essentially the same numbers?" Then I thought "if we
> >>> switch lmer to printing 'z value' will everyone start asking 'why
> >>> does lmer provide z values rather than t values?"  Sigh.
> >>>
> >>> The point is that most of this, while unfairly confusing, is just
> >>> convention.  "z values" and "t values" are the same thing - MLEs
> >>> (or REML estimates) of the parameters divided by their estimated
> >>> standard deviations. Of the common (G)LMM applications, the *only*
> >>> case in which these values are actually known to follow a t
> >>> distribution exactly is for linear mixed models (Gaussian
> >>> conditional distribution), in the classic case of a balanced,
> >>> nested design (and, implied by John below, that the fit uses REML).
> >>> Otherwise it becomes a question of which approximations you're
> >>> happy with.
> >>>
> >>> And the sampling distributions of these values are never Normal
> >>> (even in the perfect theoretical world where all model assumptions
> >>> are true), except asymptotically.
> >>>
> >>>
> >>> On 17-07-19 02:50 PM, Fox, John wrote:
> >>>> Dear Leen Catrysse,
> >>>>
> >>>> I'm going to assume that you used the glmer() function in the
> >>>> lme4 package
> >>> to fit your gamma GLMM. I notice that the summary() for a gamma
> >>> model fit by glmer() reports a "t value" for each fixed-effect
> >>> coefficient  -- simply the Wald statistics given by the ratio of
> >>> the estimated coefficient to its estimated asymptotic standard
> >>> error -- followed by a "Pr(>|z|)".
> >>>> I suspect that the Wald statistic is labelled as a "t value"
> >>>> because the gamma
> >>> GLMM has an estimated dispersion parameter, but because there are
> >>> no degrees of freedom calculated for the estimated dispersion (as
> >>> there could be, for example, for a LMM fit by REML), I think that
> >>> it would probably be preferable to call the Wald statistic a "z
> >>> value." In any event, the notation "Pr(>|z|)" suggests that the
> >>> standard normal distribution is used to obtain a p- value.
> >>>> So, to satisfy the reviewer, why not just call the Wald
> >>>> statistics "z-values"
> >>> rather than a "t-values"?
> >>>> I hope this helps, John
> >>>>
> >>>> ----------------------------- John Fox, Professor Emeritus
> >>>> McMaster University Hamilton, Ontario, Canada Web:
> >>>> socserv.mcmaster.ca/jfox
> >>>>
> >>>>
> >>>>
> >>>>> -----Original Message----- From: R-sig-mixed-models
> >>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> >>>>> Catrysse Leen Sent: Wednesday, July 19, 2017 7:21 AM To:
> >>>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] p-values
> >>>>> glmer in lme4
> >>>>>
> >>>>> Dear,
> >>>>>
> >>>>> I used GLMM to analyse eye-tracking data with the gamma
> >>>>> distribution and the log link. P-values were automatically
> >>>>> computed in the output (based on the asymptotic Wald tests). We
> >>>>> received a comment of a reviewer that the output of our GLMM
> >>>>> is inconsistent, as we report a t-value from the output and the
> >>>>> p-value based on the asymptotic Wald tests. Does anyone has
> >>>>> some feedback on how we can deal with this comment?
> >>>>>
> >>>>> Thanks in advance, Leen Catrysse
> >>>>>
> >>>>> [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jul 25 19:14:21 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 25 Jul 2017 13:14:21 -0400
Subject: [R-sig-ME] glmer.nb offset problem
In-Reply-To: <0f436b65-8d6e-6498-3c83-dd54f3bf4966@gmx.net>
References: <0f436b65-8d6e-6498-3c83-dd54f3bf4966@gmx.net>
Message-ID: <CABghstR_+13PQvBG4GpD20a63b2OTTuY8CRqAn9OZcMv33kJEg@mail.gmail.com>

  I suspect that the problem is that your fitted (predicted) values
are now being calibrated for an animal with a *single* fix (i.e. an
offset of zero).  Try multiplying your fitted values by a "typical"
number of fixes to see if the answers are reasonable.

  This strategy does worry me a little bit because it implies that the
home range is *strictly proportional* to the number of fixes.  It
might be slightly better to use log(NumberofGPSfixes) as a predictor
rather than an offset, which will correspond to assuming that the
homerange size is proportional to a NumberofGPSfixes^b, where b is not
necessarily 1. (I would guess b<1, which means that the relationship
will be decelerating. It still implies that the homerange increases to
infinity as the number of GPS fixes increases to infinity (rather than
reaching an asymptote), but the results might not be too bad.)

See https://stats.stackexchange.com/questions/237963/how-to-formulate-the-offset-of-a-glm
for a little more discussion of offsets.

On Tue, Jul 25, 2017 at 11:52 AM, Dagmar <Ramgad82 at gmx.net> wrote:
> Dear all,
>
> I am having a problem with a negative binomial GLMM using an offset.
>
> I have GPS fixes from animals and calculated their homerange. Now I want to
> test if there are differences in the size of the homeranges between seasons
> of the year.
>
> I did a simple linear regression analysis between size of home range and
> sample size (number of GPS fixes) and unfortunately found a slight positive
> relationship: The bigger my samle size the larger is the homerange. That is
> why I thought to use sample size as an offset in my negative binomial glmm.
>
> My code is:
>
> glmer.nb (Homerangearea ~SeasonOfYear
> +(1|AnimalID)+offset(log(NumberOfGPSfixes)), data=mydataframe)
>
> Without an offset I get a wonderful result with totaly nice fitted values.
> My problem is: When I include the offset my fitted values go towards 0. Why
> is that?
>
> The number of GPS fixes is very different between animals. In one case I do
> only have 60 fixes, in another case I do have 12800. Maybe this difference
> is too big? I do not totally understand what the offset is doing to the
> data. As far as I understood it adds some weighting to some data. Is that
> correct?
>
> In other examples which I found online an offset is only used for small
> numbers. Or is an offset even not the right tool for my problem?
>
> Help would be very much (!!) appreciated.
>
> Tagmarie
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.pelzer at maw.ru.nl  Wed Jul 26 13:36:35 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 26 Jul 2017 13:36:35 +0200
Subject: [R-sig-ME] using lme for cov structures?
Message-ID: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>

Dear list,

With longitudinal data, the package nlme offers the possibility to 
specify particular covariance structures for the residuals. In the 
examples below I used data from 35 individuals measured at 4 time 
points, so we have 4 observations nested in each of 35 individuals. 
These data are discussed in Singer and Willett, Applied Longitudinal 
Data Analysis, chapter 7.

In several sources I found that e.g. compound symmetry can easily be 
obtained with gls from package nlme, by using the correlation structure 
corCompSymm, as in:

     comsym <- gls(opp~1,opposites,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML")

where id is subject-identifier for the individual. With gls however one 
cannot specify random effects, as opposed to lme. To have lme estimate 
compound symmetry is simple, one would not even need have to specify a 
particular correlation structure, it would suffice to say 
"random=~1|id". However, for more complex covariance structures, e.g. 
heterogeneous compound symmetry, I was only able to find syntax for gls, 
but not for lme.

Then I thought that tricking lme might be an option by having a kind of 
"fake" random effect. That is, I constructed a variable "one" which 
takes value 1 for all cases, and let the intercept be random across "all 
one groups". This led to the following lme model:


     comsym.lme <- lme(opp~1,opposites, random= ~1|one,
                       correlation=corCompSymm(form = ~ 1 |one/id), 
method="REML")

And actually to my surprise, the results of this lme are highly similar 
to those of the gls above.
The output of both is attached below. The loglik's are identical, the 
AIC and BIC are not, which I can understand, as the lme has an extra 
variance to be estimated, compared to the gls. Also, the fixed 
intercept's standard error is different, the one of the lme being about 
twice as large.

I added some independent variables (not shown below) but the 
similarities between gls and lme remain, with only the AIC and BIC and 
the standard error of the fixed intercept being different for the two 
models.

My question is threefold.
1) Suppose the individuals (say pupils) would be nested in schools, then 
I assume that with lme I could add school as a random effect, and run a 
"usual" model, with pupils nested in schools and observations in pupils, 
and then use any of the possible residual covariance structures for the 
observations in pupils. Would you agree with this? (with gls one cannot 
use an additional random effect, like e.g. school)
2) Are the lme results indeed to be trusted when using this "fake" 
random effect, apart from the differences with gls mentioned? Could you 
imagine a situation where lme with this trick would produce wrong results?
3) I don't understand the variance of the intercept in the lme output. 
Even when I specify a very simple model: lme(opp ~ 1, random = ~1|one, 
opposites, method="REML")
lme is able to estimate the intercept variance...but what is this 
variance estimate expressing?

Thanks a lot for any help!!!

Ben.





*----------------- gls ---------------------------------------------------

 > comsym <- gls(opp~1,opposites,
                 correlation=corCompSymm(form = ~ 1 |id), method="REML")
 > summary(comsym)

Generalized least squares fit by REML
Model: opp ~ 1
Data: opposites
      AIC      BIC    logLik
1460.954 1469.757 -727.4769

Correlation Structure: Compound symmetry
Formula: ~1 | id
Parameter estimate(s):
   Rho
0.2757052

Coefficients:
                Value Std.Error  t-value p-value
(Intercept) 204.8143  5.341965 38.34063       0

Standardized residuals:
   Min          Q1         Med          Q3         Max
-2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156

Residual standard error: 46.76081
Degrees of freedom: 140 total; 139 residual


#------------------ lme ---------------------------------------------------

 > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
                 correlation=corCompSymm(form = ~ 1 |one/id), method="REML")
 > summary(comsym.lme)

Linear mixed-effects model fit by REML
Data: opposites
      AIC      BIC    logLik
1462.954 1474.692 -727.4769

Random effects:
   Formula: ~1 | one
         (Intercept) Residual
StdDev:    10.53875 46.76081

Correlation Structure: Compound symmetry
Formula: ~1 | one/id
Parameter estimate(s):
   Rho
0.2757052
Fixed effects: opp ~ 1
                Value Std.Error  DF  t-value p-value
(Intercept) 204.8143  11.81532 139 17.33463       0

Standardized Within-Group Residuals:
   Min          Q1         Med          Q3         Max
-2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156

Number of Observations: 140
Number of Groups: 1


	[[alternative HTML version deleted]]


From simonakf at gmail.com  Wed Jul 26 14:33:14 2017
From: simonakf at gmail.com (Simona Kralj Fiser)
Date: Wed, 26 Jul 2017 14:33:14 +0200
Subject: [R-sig-ME] cross-sex genetic correlation
Message-ID: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>

Hi!


We are trying to estimate body mass (W) heritability and cross-sex genetic
correlation using MCMCglmm. Our data matrix consists of three columns: ID,
sex, and W. Body mass data is NOT normally distributed.

Following previous advice, we first separated weight data into two columns,
WF and WM. WF listed weight data for female specimens and ?NA? for males,
and vice-versa in the WM column. We used the following prior and model
combination:



prior1 <- list(R=list(V=diag(2)/2, nu=2), G=list(G1=list(V=diag(2)/2,
nu=2)))

modelmulti <- MCMCglmm(cbind(WF,WM)~trait-1, random=~us(trait):animal,
rcov=~us(trait):units, prior=prior1, pedigree=Ped, data=Data1, nitt=100000,
burnin=10000, thin=10)



The resulting posterior means of posterior distribution were suspiciously
low (e.g. 0.00002). We calculated heritability values anyway, using the
following:



herit1 <- modelmulti$VCV[,'traitWF:traitWF.animal']/

(modelmulti$VCV[,'traitWF:traitWF.animal']+modelmulti$
VCV[,'traitWF:traitWF.units'])

herit2 <- modelmulti$VCV[,'traitWM:traitWM.animal']/

(modelmulti$VCV[,'traitWM:traitWM.animal']+modelmulti$
VCV[,'traitWM:traitWM.units'])

corr.gen <- modelmulti$VCV[,traitWF.traitWM.animal']/

sqrt(modelmulti$VCV[,'traitWF:traitWF.animal']*modelmulti$
VCV[,'traitWM:traitWM.animal'])



We get heritability estimates of about 50%, which is reasonable, but
correlation estimates were extremely low, about 0.04%.



Suspecting the model was wrong, we used the original dataset with all
weight data in a single column and tried the following model:



prior2 <- list(R=list(V=1, nu=0.02), G=list(G1=list(V=1, nu=1, alpha.mu=0,
alpha.V=1000)))

model <- MCMCglmm(W~sex, random=~us(sex):animal, rcov=~us(sex):units,
prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000, thin=10)



The model runs, but it refuses to calculate ?herit? values, with the error
message ?subscript out of bounds?. We?d also add that in this case, the
posterior density graph for sex2:sex.animal is not shaped like a bell.



What are we doing wrong? Are we even using the correct models?


Eva and Simona

--

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Jul 26 14:42:35 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 26 Jul 2017 13:42:35 +0100
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
Message-ID: <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>

Hi,

The second way is a *much* better way of doing it but should give the 
same answer. However, in both cases the residual covariance is not 
identifiable (no individual is both male and female) and so you should 
use idh rather than us.

The "subscript out of bounds" error is to do with your code that 
post-processes the model output not an issue with MCMCglmm. Probably you 
have used the wrong names for the (co)variance components.

Also, you haven't passed the prior to MCMCglmm, nor is the prior a valid 
one for the problem as it specifies scalar variances rather than 2x2 
covariance matrices. You could try

prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),alpha.V=diag(2)*1000)))

Cheers,

Jarrod



On 26/07/2017 13:33, Simona Kralj Fiser wrote:
> model <- MCMCglmm(W~sex, random=~us(sex):animal, rcov=~us(sex):units,
> prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000, thin=10)


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Wed Jul 26 14:44:14 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 26 Jul 2017 14:44:14 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
Message-ID: <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>

Dear Ben,

Please be more specific on the kind of model you want to fit. That would
lead to a more relevant discussion that your potential misuse of lme. A
reproducible example is always useful...

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:

> Dear list,
>
> With longitudinal data, the package nlme offers the possibility to
> specify particular covariance structures for the residuals. In the
> examples below I used data from 35 individuals measured at 4 time
> points, so we have 4 observations nested in each of 35 individuals.
> These data are discussed in Singer and Willett, Applied Longitudinal
> Data Analysis, chapter 7.
>
> In several sources I found that e.g. compound symmetry can easily be
> obtained with gls from package nlme, by using the correlation structure
> corCompSymm, as in:
>
>      comsym <- gls(opp~1,opposites,
>                    correlation=corCompSymm(form = ~ 1 |id), method="REML")
>
> where id is subject-identifier for the individual. With gls however one
> cannot specify random effects, as opposed to lme. To have lme estimate
> compound symmetry is simple, one would not even need have to specify a
> particular correlation structure, it would suffice to say
> "random=~1|id". However, for more complex covariance structures, e.g.
> heterogeneous compound symmetry, I was only able to find syntax for gls,
> but not for lme.
>
> Then I thought that tricking lme might be an option by having a kind of
> "fake" random effect. That is, I constructed a variable "one" which
> takes value 1 for all cases, and let the intercept be random across "all
> one groups". This led to the following lme model:
>
>
>      comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>                        correlation=corCompSymm(form = ~ 1 |one/id),
> method="REML")
>
> And actually to my surprise, the results of this lme are highly similar
> to those of the gls above.
> The output of both is attached below. The loglik's are identical, the
> AIC and BIC are not, which I can understand, as the lme has an extra
> variance to be estimated, compared to the gls. Also, the fixed
> intercept's standard error is different, the one of the lme being about
> twice as large.
>
> I added some independent variables (not shown below) but the
> similarities between gls and lme remain, with only the AIC and BIC and
> the standard error of the fixed intercept being different for the two
> models.
>
> My question is threefold.
> 1) Suppose the individuals (say pupils) would be nested in schools, then
> I assume that with lme I could add school as a random effect, and run a
> "usual" model, with pupils nested in schools and observations in pupils,
> and then use any of the possible residual covariance structures for the
> observations in pupils. Would you agree with this? (with gls one cannot
> use an additional random effect, like e.g. school)
> 2) Are the lme results indeed to be trusted when using this "fake"
> random effect, apart from the differences with gls mentioned? Could you
> imagine a situation where lme with this trick would produce wrong results?
> 3) I don't understand the variance of the intercept in the lme output.
> Even when I specify a very simple model: lme(opp ~ 1, random = ~1|one,
> opposites, method="REML")
> lme is able to estimate the intercept variance...but what is this
> variance estimate expressing?
>
> Thanks a lot for any help!!!
>
> Ben.
>
>
>
>
>
> *----------------- gls ---------------------------------------------------
>
>  > comsym <- gls(opp~1,opposites,
>                  correlation=corCompSymm(form = ~ 1 |id), method="REML")
>  > summary(comsym)
>
> Generalized least squares fit by REML
> Model: opp ~ 1
> Data: opposites
>       AIC      BIC    logLik
> 1460.954 1469.757 -727.4769
>
> Correlation Structure: Compound symmetry
> Formula: ~1 | id
> Parameter estimate(s):
>    Rho
> 0.2757052
>
> Coefficients:
>                 Value Std.Error  t-value p-value
> (Intercept) 204.8143  5.341965 38.34063       0
>
> Standardized residuals:
>    Min          Q1         Med          Q3         Max
> -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
>
> Residual standard error: 46.76081
> Degrees of freedom: 140 total; 139 residual
>
>
> #------------------ lme ------------------------------
> ---------------------
>
>  > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>                  correlation=corCompSymm(form = ~ 1 |one/id),
> method="REML")
>  > summary(comsym.lme)
>
> Linear mixed-effects model fit by REML
> Data: opposites
>       AIC      BIC    logLik
> 1462.954 1474.692 -727.4769
>
> Random effects:
>    Formula: ~1 | one
>          (Intercept) Residual
> StdDev:    10.53875 46.76081
>
> Correlation Structure: Compound symmetry
> Formula: ~1 | one/id
> Parameter estimate(s):
>    Rho
> 0.2757052
> Fixed effects: opp ~ 1
>                 Value Std.Error  DF  t-value p-value
> (Intercept) 204.8143  11.81532 139 17.33463       0
>
> Standardized Within-Group Residuals:
>    Min          Q1         Med          Q3         Max
> -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
>
> Number of Observations: 140
> Number of Groups: 1
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jul 26 15:43:17 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Wed, 26 Jul 2017 13:43:17 +0000
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
Message-ID: <075deea0399c40b39df0c2c2f8ee68ec@UM-MAIL3216.unimaas.nl>

Quick note:

gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id))

and

lme(opp ~ 1, random = ~ 1 | id)

are not exactly the same. Marginally, the two models are only identical when the variance component for 'id' in lme() is >= 0 (which implies that the correlation in the gls() model is >= 0). The gls() model however also allows for negative correlation.

For a heterogeneous CS structure, you would use:

gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id), weights = varIdent(form = ~ 1 | timepoint))

where 'timepoint' is obviously a variable that indicates the time point for the 4 observations per individual.

lme(opp ~ 1, random = ~ 1 | id)

I don't understand why you want to use use 'random= ~1|one' in the first place.

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Pelzer
Sent: Wednesday, July 26, 2017 13:37
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] using lme for cov structures?

Dear list,

With longitudinal data, the package nlme offers the possibility to 
specify particular covariance structures for the residuals. In the 
examples below I used data from 35 individuals measured at 4 time 
points, so we have 4 observations nested in each of 35 individuals. 
These data are discussed in Singer and Willett, Applied Longitudinal 
Data Analysis, chapter 7.

In several sources I found that e.g. compound symmetry can easily be 
obtained with gls from package nlme, by using the correlation structure 
corCompSymm, as in:

     comsym <- gls(opp~1,opposites,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML")

where id is subject-identifier for the individual. With gls however one 
cannot specify random effects, as opposed to lme. To have lme estimate 
compound symmetry is simple, one would not even need have to specify a 
particular correlation structure, it would suffice to say 
"random=~1|id". However, for more complex covariance structures, e.g. 
heterogeneous compound symmetry, I was only able to find syntax for gls, 
but not for lme.

Then I thought that tricking lme might be an option by having a kind of 
"fake" random effect. That is, I constructed a variable "one" which 
takes value 1 for all cases, and let the intercept be random across "all 
one groups". This led to the following lme model:

     comsym.lme <- lme(opp~1,opposites, random= ~1|one,
                       correlation=corCompSymm(form = ~ 1 |one/id), 
method="REML")

And actually to my surprise, the results of this lme are highly similar 
to those of the gls above.
The output of both is attached below. The loglik's are identical, the 
AIC and BIC are not, which I can understand, as the lme has an extra 
variance to be estimated, compared to the gls. Also, the fixed 
intercept's standard error is different, the one of the lme being about 
twice as large.

I added some independent variables (not shown below) but the 
similarities between gls and lme remain, with only the AIC and BIC and 
the standard error of the fixed intercept being different for the two 
models.

My question is threefold.
1) Suppose the individuals (say pupils) would be nested in schools, then 
I assume that with lme I could add school as a random effect, and run a 
"usual" model, with pupils nested in schools and observations in pupils, 
and then use any of the possible residual covariance structures for the 
observations in pupils. Would you agree with this? (with gls one cannot 
use an additional random effect, like e.g. school)
2) Are the lme results indeed to be trusted when using this "fake" 
random effect, apart from the differences with gls mentioned? Could you 
imagine a situation where lme with this trick would produce wrong results?
3) I don't understand the variance of the intercept in the lme output. 
Even when I specify a very simple model: lme(opp ~ 1, random = ~1|one, 
opposites, method="REML")
lme is able to estimate the intercept variance...but what is this 
variance estimate expressing?

Thanks a lot for any help!!!

Ben.

*----------------- gls ---------------------------------------------------

 > comsym <- gls(opp~1,opposites,
                 correlation=corCompSymm(form = ~ 1 |id), method="REML")
 > summary(comsym)

Generalized least squares fit by REML
Model: opp ~ 1
Data: opposites
      AIC      BIC    logLik
1460.954 1469.757 -727.4769

Correlation Structure: Compound symmetry
Formula: ~1 | id
Parameter estimate(s):
   Rho
0.2757052

Coefficients:
                Value Std.Error  t-value p-value
(Intercept) 204.8143  5.341965 38.34063       0

Standardized residuals:
   Min          Q1         Med          Q3         Max
-2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156

Residual standard error: 46.76081
Degrees of freedom: 140 total; 139 residual


#------------------ lme ---------------------------------------------------

 > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
                 correlation=corCompSymm(form = ~ 1 |one/id), method="REML")
 > summary(comsym.lme)

Linear mixed-effects model fit by REML
Data: opposites
      AIC      BIC    logLik
1462.954 1474.692 -727.4769

Random effects:
   Formula: ~1 | one
         (Intercept) Residual
StdDev:    10.53875 46.76081

Correlation Structure: Compound symmetry
Formula: ~1 | one/id
Parameter estimate(s):
   Rho
0.2757052
Fixed effects: opp ~ 1
                Value Std.Error  DF  t-value p-value
(Intercept) 204.8143  11.81532 139 17.33463       0

Standardized Within-Group Residuals:
   Min          Q1         Med          Q3         Max
-2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156

Number of Observations: 140
Number of Groups: 1


From b.pelzer at maw.ru.nl  Wed Jul 26 21:45:45 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 26 Jul 2017 21:45:45 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
Message-ID: <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>

Dear Thierry and Wolfgang,

Thanks for responding so quickly. Here is the reproducible example of 
the two models that I'm interested in.

# Read data.
opposites <- 
read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt",header=TRUE,sep=",")

# Open library.
library(nlme)

# Define group "one" with value 1 for all cases.
one <- rep(1, 140)

#----- Model estimated with gls.
comsym.gls <- gls(opp~1,opposites,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML")
summary(comsym.gls)


#----- Same model estimated with lme.
comsym.lme <- lme(opp~1,opposites,
                   random= ~1|one,
                   correlation=corCompSymm(form = ~ 1 |one/id), 
method="REML")
summary(comsym.lme)


#----- Wolfgang's gls suggestion for heterogeneous CS.

summary(gls(opp ~ 1, opposites, correlation = corCompSymm(form = ~ 1 | 
id), weights = varIdent(form = ~ 1 | wave)))

# Does not work with lme.
summary(hetercom <- lme(opp ~ 1,opposites,
                 correlation=corCompSymm(form = ~ 1 |id),
                 weights=varIdent(form = ~1|wave), method="REML"))

# But does work with the "one" trick.
summary(lme(opp ~ 1,opposites,
     random = ~1|one,
     correlation=corCompSymm(form = ~ 1 |one/id),
     weights=varIdent(form = ~1|wave), method="REML"))



The main reason of my mailing to the list is this. I was wondering 
whether with lme it is possible to also estimate models with the 
individuals nested in higher levels like schools or hospitals etc and at 
the same time letting the residuals correlate within individuals over 
time with one of the nice covar structures. However, I do NOT have a 
reproducible example of such more complex models at the moment. I only 
hoped that if the lme version of the model presented above has no 
further problems than a (slightly) different AIC, BIC and std. error of 
the fixed intercept, it would be meaningful to proceed in this way, i.e. 
using lme instead of gls, since lme provides the important possibility 
of additional random effects in the model.

As to Wolfgang's suggestion for heretogeneous CS using:

gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id), weights = 
varIdent(form = ~ 1 | timepoint))

I didn't find a way to estimate such a model with lme, except for the 
method with the "trick". Using:

lme(opp ~ 1,opposites,
             correlation=corCompSymm(form = ~ 1 |id),
             weights=varIdent(form = ~1|wave), method="REML")

leads to error-message:

Error in lme.formula(opp ~ 1, opposites, correlation = corCompSymm(form 
= ~1 | : incompatible formulas for groups in 'random' and 'correlation'


whereas

lme(opp ~ 1,opposites,
             random = ~1|one,
             correlation=corCompSymm(form = ~ 1 |one/id),
             weights=varIdent(form = ~1|wave), method="REML")

leads to similar results as your gls suggestion.


Best regards, Ben.


On 26-7-2017 14:44, Thierry Onkelinx wrote:
> Dear Ben,
>
> Please be more specific on the kind of model you want to fit. That 
> would lead to a more relevant discussion that your potential misuse of 
> lme. A reproducible example is always useful...
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>>:
>
>     Dear list,
>
>     With longitudinal data, the package nlme offers the possibility to
>     specify particular covariance structures for the residuals. In the
>     examples below I used data from 35 individuals measured at 4 time
>     points, so we have 4 observations nested in each of 35 individuals.
>     These data are discussed in Singer and Willett, Applied Longitudinal
>     Data Analysis, chapter 7.
>
>     In several sources I found that e.g. compound symmetry can easily be
>     obtained with gls from package nlme, by using the correlation
>     structure
>     corCompSymm, as in:
>
>          comsym <- gls(opp~1,opposites,
>                        correlation=corCompSymm(form = ~ 1 |id),
>     method="REML")
>
>     where id is subject-identifier for the individual. With gls
>     however one
>     cannot specify random effects, as opposed to lme. To have lme estimate
>     compound symmetry is simple, one would not even need have to specify a
>     particular correlation structure, it would suffice to say
>     "random=~1|id". However, for more complex covariance structures, e.g.
>     heterogeneous compound symmetry, I was only able to find syntax
>     for gls,
>     but not for lme.
>
>     Then I thought that tricking lme might be an option by having a
>     kind of
>     "fake" random effect. That is, I constructed a variable "one" which
>     takes value 1 for all cases, and let the intercept be random
>     across "all
>     one groups". This led to the following lme model:
>
>
>          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>                            correlation=corCompSymm(form = ~ 1 |one/id),
>     method="REML")
>
>     And actually to my surprise, the results of this lme are highly
>     similar
>     to those of the gls above.
>     The output of both is attached below. The loglik's are identical, the
>     AIC and BIC are not, which I can understand, as the lme has an extra
>     variance to be estimated, compared to the gls. Also, the fixed
>     intercept's standard error is different, the one of the lme being
>     about
>     twice as large.
>
>     I added some independent variables (not shown below) but the
>     similarities between gls and lme remain, with only the AIC and BIC and
>     the standard error of the fixed intercept being different for the two
>     models.
>
>     My question is threefold.
>     1) Suppose the individuals (say pupils) would be nested in
>     schools, then
>     I assume that with lme I could add school as a random effect, and
>     run a
>     "usual" model, with pupils nested in schools and observations in
>     pupils,
>     and then use any of the possible residual covariance structures
>     for the
>     observations in pupils. Would you agree with this? (with gls one
>     cannot
>     use an additional random effect, like e.g. school)
>     2) Are the lme results indeed to be trusted when using this "fake"
>     random effect, apart from the differences with gls mentioned?
>     Could you
>     imagine a situation where lme with this trick would produce wrong
>     results?
>     3) I don't understand the variance of the intercept in the lme output.
>     Even when I specify a very simple model: lme(opp ~ 1, random = ~1|one,
>     opposites, method="REML")
>     lme is able to estimate the intercept variance...but what is this
>     variance estimate expressing?
>
>     Thanks a lot for any help!!!
>
>     Ben.
>
>
>
>
>
>     *----------------- gls
>     ---------------------------------------------------
>
>      > comsym <- gls(opp~1,opposites,
>                      correlation=corCompSymm(form = ~ 1 |id),
>     method="REML")
>      > summary(comsym)
>
>     Generalized least squares fit by REML
>     Model: opp ~ 1
>     Data: opposites
>           AIC      BIC    logLik
>     1460.954 1469.757 -727.4769
>
>     Correlation Structure: Compound symmetry
>     Formula: ~1 | id
>     Parameter estimate(s):
>        Rho
>     0.2757052
>
>     Coefficients:
>                     Value Std.Error  t-value p-value
>     (Intercept) 204.8143  5.341965 38.34063       0
>
>     Standardized residuals:
>        Min          Q1         Med          Q3         Max
>     -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
>
>     Residual standard error: 46.76081
>     Degrees of freedom: 140 total; 139 residual
>
>
>     #------------------ lme
>     ---------------------------------------------------
>
>      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>                      correlation=corCompSymm(form = ~ 1 |one/id),
>     method="REML")
>      > summary(comsym.lme)
>
>     Linear mixed-effects model fit by REML
>     Data: opposites
>           AIC      BIC    logLik
>     1462.954 1474.692 -727.4769
>
>     Random effects:
>        Formula: ~1 | one
>              (Intercept) Residual
>     StdDev:    10.53875 46.76081
>
>     Correlation Structure: Compound symmetry
>     Formula: ~1 | one/id
>     Parameter estimate(s):
>        Rho
>     0.2757052
>     Fixed effects: opp ~ 1
>                     Value Std.Error  DF  t-value p-value
>     (Intercept) 204.8143  11.81532 139 17.33463       0
>
>     Standardized Within-Group Residuals:
>        Min          Q1         Med          Q3         Max
>     -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
>
>     Number of Observations: 140
>     Number of Groups: 1
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Jul 26 22:05:20 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 26 Jul 2017 22:05:20 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
 <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
Message-ID: <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>

Dear Ben,

The correlation structure always works at the most detailed level of the
random effects. E.g. at the id level in the example below, not at the group
level. The correlation is only effective among observations from the same
id. Two observation within the same group but different id have
uncorrelated residuals by definition. Likewise are two residuals from
different groups uncorrelated. The correlation matrix of the residuals is
hence always a block diagonal matrix, with blocks defined by the most
detailed level of the random effects.

opposites <- read.table("
https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt
",header=TRUE,sep=",")
opposites$group <- opposites$id %% 6
library(nlme)
lme(opp ~ 1, random = ~1|group/id, data = opposites)
lme(opp ~ 1, random = ~1|group/id, data = opposites, correlation =
corAR1(form = ~wave))

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-26 21:45 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:

> Dear Thierry and Wolfgang,
>
> Thanks for responding so quickly. Here is the reproducible example of
> the two models that I'm interested in.
>
> # Read data.
> opposites <-
> read.table("https://stats.idre.ucla.edu/stat/r/examples/
> alda/dat/opposites_pp.txt",header=TRUE,sep=",")
>
> # Open library.
> library(nlme)
>
> # Define group "one" with value 1 for all cases.
> one <- rep(1, 140)
>
> #----- Model estimated with gls.
> comsym.gls <- gls(opp~1,opposites,
>                    correlation=corCompSymm(form = ~ 1 |id), method="REML")
> summary(comsym.gls)
>
>
> #----- Same model estimated with lme.
> comsym.lme <- lme(opp~1,opposites,
>                    random= ~1|one,
>                    correlation=corCompSymm(form = ~ 1 |one/id),
> method="REML")
> summary(comsym.lme)
>
>
> #----- Wolfgang's gls suggestion for heterogeneous CS.
>
> summary(gls(opp ~ 1, opposites, correlation = corCompSymm(form = ~ 1 |
> id), weights = varIdent(form = ~ 1 | wave)))
>
> # Does not work with lme.
> summary(hetercom <- lme(opp ~ 1,opposites,
>                  correlation=corCompSymm(form = ~ 1 |id),
>                  weights=varIdent(form = ~1|wave), method="REML"))
>
> # But does work with the "one" trick.
> summary(lme(opp ~ 1,opposites,
>      random = ~1|one,
>      correlation=corCompSymm(form = ~ 1 |one/id),
>      weights=varIdent(form = ~1|wave), method="REML"))
>
>
>
> The main reason of my mailing to the list is this. I was wondering
> whether with lme it is possible to also estimate models with the
> individuals nested in higher levels like schools or hospitals etc and at
> the same time letting the residuals correlate within individuals over
> time with one of the nice covar structures. However, I do NOT have a
> reproducible example of such more complex models at the moment. I only
> hoped that if the lme version of the model presented above has no
> further problems than a (slightly) different AIC, BIC and std. error of
> the fixed intercept, it would be meaningful to proceed in this way, i.e.
> using lme instead of gls, since lme provides the important possibility
> of additional random effects in the model.
>
> As to Wolfgang's suggestion for heretogeneous CS using:
>
> gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id), weights =
> varIdent(form = ~ 1 | timepoint))
>
> I didn't find a way to estimate such a model with lme, except for the
> method with the "trick". Using:
>
> lme(opp ~ 1,opposites,
>              correlation=corCompSymm(form = ~ 1 |id),
>              weights=varIdent(form = ~1|wave), method="REML")
>
> leads to error-message:
>
> Error in lme.formula(opp ~ 1, opposites, correlation = corCompSymm(form
> = ~1 | : incompatible formulas for groups in 'random' and 'correlation'
>
>
> whereas
>
> lme(opp ~ 1,opposites,
>              random = ~1|one,
>              correlation=corCompSymm(form = ~ 1 |one/id),
>              weights=varIdent(form = ~1|wave), method="REML")
>
> leads to similar results as your gls suggestion.
>
>
> Best regards, Ben.
>
>
> On 26-7-2017 14:44, Thierry Onkelinx wrote:
> > Dear Ben,
> >
> > Please be more specific on the kind of model you want to fit. That
> > would lead to a more relevant discussion that your potential misuse of
> > lme. A reproducible example is always useful...
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> > <mailto:b.pelzer at maw.ru.nl>>:
> >
> >     Dear list,
> >
> >     With longitudinal data, the package nlme offers the possibility to
> >     specify particular covariance structures for the residuals. In the
> >     examples below I used data from 35 individuals measured at 4 time
> >     points, so we have 4 observations nested in each of 35 individuals.
> >     These data are discussed in Singer and Willett, Applied Longitudinal
> >     Data Analysis, chapter 7.
> >
> >     In several sources I found that e.g. compound symmetry can easily be
> >     obtained with gls from package nlme, by using the correlation
> >     structure
> >     corCompSymm, as in:
> >
> >          comsym <- gls(opp~1,opposites,
> >                        correlation=corCompSymm(form = ~ 1 |id),
> >     method="REML")
> >
> >     where id is subject-identifier for the individual. With gls
> >     however one
> >     cannot specify random effects, as opposed to lme. To have lme
> estimate
> >     compound symmetry is simple, one would not even need have to specify
> a
> >     particular correlation structure, it would suffice to say
> >     "random=~1|id". However, for more complex covariance structures, e.g.
> >     heterogeneous compound symmetry, I was only able to find syntax
> >     for gls,
> >     but not for lme.
> >
> >     Then I thought that tricking lme might be an option by having a
> >     kind of
> >     "fake" random effect. That is, I constructed a variable "one" which
> >     takes value 1 for all cases, and let the intercept be random
> >     across "all
> >     one groups". This led to the following lme model:
> >
> >
> >          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >                            correlation=corCompSymm(form = ~ 1 |one/id),
> >     method="REML")
> >
> >     And actually to my surprise, the results of this lme are highly
> >     similar
> >     to those of the gls above.
> >     The output of both is attached below. The loglik's are identical, the
> >     AIC and BIC are not, which I can understand, as the lme has an extra
> >     variance to be estimated, compared to the gls. Also, the fixed
> >     intercept's standard error is different, the one of the lme being
> >     about
> >     twice as large.
> >
> >     I added some independent variables (not shown below) but the
> >     similarities between gls and lme remain, with only the AIC and BIC
> and
> >     the standard error of the fixed intercept being different for the two
> >     models.
> >
> >     My question is threefold.
> >     1) Suppose the individuals (say pupils) would be nested in
> >     schools, then
> >     I assume that with lme I could add school as a random effect, and
> >     run a
> >     "usual" model, with pupils nested in schools and observations in
> >     pupils,
> >     and then use any of the possible residual covariance structures
> >     for the
> >     observations in pupils. Would you agree with this? (with gls one
> >     cannot
> >     use an additional random effect, like e.g. school)
> >     2) Are the lme results indeed to be trusted when using this "fake"
> >     random effect, apart from the differences with gls mentioned?
> >     Could you
> >     imagine a situation where lme with this trick would produce wrong
> >     results?
> >     3) I don't understand the variance of the intercept in the lme
> output.
> >     Even when I specify a very simple model: lme(opp ~ 1, random =
> ~1|one,
> >     opposites, method="REML")
> >     lme is able to estimate the intercept variance...but what is this
> >     variance estimate expressing?
> >
> >     Thanks a lot for any help!!!
> >
> >     Ben.
> >
> >
> >
> >
> >
> >     *----------------- gls
> >     ---------------------------------------------------
> >
> >      > comsym <- gls(opp~1,opposites,
> >                      correlation=corCompSymm(form = ~ 1 |id),
> >     method="REML")
> >      > summary(comsym)
> >
> >     Generalized least squares fit by REML
> >     Model: opp ~ 1
> >     Data: opposites
> >           AIC      BIC    logLik
> >     1460.954 1469.757 -727.4769
> >
> >     Correlation Structure: Compound symmetry
> >     Formula: ~1 | id
> >     Parameter estimate(s):
> >        Rho
> >     0.2757052
> >
> >     Coefficients:
> >                     Value Std.Error  t-value p-value
> >     (Intercept) 204.8143  5.341965 38.34063       0
> >
> >     Standardized residuals:
> >        Min          Q1         Med          Q3         Max
> >     -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
> >
> >     Residual standard error: 46.76081
> >     Degrees of freedom: 140 total; 139 residual
> >
> >
> >     #------------------ lme
> >     ---------------------------------------------------
> >
> >      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >                      correlation=corCompSymm(form = ~ 1 |one/id),
> >     method="REML")
> >      > summary(comsym.lme)
> >
> >     Linear mixed-effects model fit by REML
> >     Data: opposites
> >           AIC      BIC    logLik
> >     1462.954 1474.692 -727.4769
> >
> >     Random effects:
> >        Formula: ~1 | one
> >              (Intercept) Residual
> >     StdDev:    10.53875 46.76081
> >
> >     Correlation Structure: Compound symmetry
> >     Formula: ~1 | one/id
> >     Parameter estimate(s):
> >        Rho
> >     0.2757052
> >     Fixed effects: opp ~ 1
> >                     Value Std.Error  DF  t-value p-value
> >     (Intercept) 204.8143  11.81532 139 17.33463       0
> >
> >     Standardized Within-Group Residuals:
> >        Min          Q1         Med          Q3         Max
> >     -2.75474868 -0.71244027  0.00397158  0.56533908  2.24944156
> >
> >     Number of Observations: 140
> >     Number of Groups: 1
> >
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Jul 27 11:16:38 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 27 Jul 2017 11:16:38 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
 <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
 <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>
Message-ID: <eba39df9-d98e-aea2-2841-f171465d51c4@maw.ru.nl>

Dear Thierry,

Thanks for your help with these models. I wasn't sure how to formulate 
them. At the department of sciology where I work (Radboud University) 
longitudinal data are getting more common bussiness. And very often, 
we'd like to estimate random country or municipality influences for 
repeated measures on the same person. This is not a big problem as long 
as we use growth modelling with random intercept and random time 
influence, but the covariance structure implied by such models is, say, 
limited. Knowing how to specify the cov. structures in R is really 
helpful and broadens prespective.

After fiddling around with all the possibilities, the picture is slowly 
getting clearer here. I was puzzled by the heterogeneous compound 
symmetry structure and how to specify this. With specification:

heteroCS1 <- lme(opp ~ 1,opposites,
     random = ~1|id,
     correlation=corCompSymm(form = ~ wave),
     weights=varIdent(form = ~1|wave), method="REML")

the random person effect is estimated apart from the residuals. On the 
other hand, with:

heteroCS2 <- lme(opp ~ 1,opposites,
     random = ~1|one,
     correlation=corCompSymm(form = ~wave | one/id),
     weights=varIdent(form = ~1|wave), method="REML"))

the random person effect is kept part of the residuals, because it is 
not estimated explicitly. As a result, heteroCS2 gives the same results 
as obtained with the more straightforward gls specification:

hetroCS3 <- gls(opp ~ 1, opposites,
     correlation = corCompSymm(form = ~ wave|id),
     weights = varIdent(form = ~ 1 | wave))

In general, I think I would prefer to have the random person effect as 
part the residual term instead of seperating it from the residual. That 
is, by cutting the random person effect away from the residual, you 
remove the very part that causes correlation between the observations 
over time. The only specification (I could think of) that keeps the 
random person effect IN the residual is heteroCS2. But maybe something 
less artificial can be found....

And the strange thing that remains is: how can lme estimate a random 
effect variance in case of one single group, as in:

strangemodel <- lme(opp ~1, random = ~1|one, opposites)

which produces the summary:

Linear mixed-effects model fit by REML
  Data: opposites
      AIC      BIC    logLik
   1473.5 1482.303 -733.7498

Random effects:
  Formula: ~1 | one
         (Intercept) Residual
StdDev:    10.50729 46.62148

Fixed effects: opp ~ 1
                Value Std.Error  DF  t-value p-value
(Intercept) 204.8143  11.22179 139 18.25148       0


Do you have any thoughts about this strange model's estimate of the 
intercept variance 10.50729?

Best regards, Ben.


On 26-7-2017 22:05, Thierry Onkelinx wrote:
> Dear Ben,
>
> The correlation structure always works at the most detailed level of 
> the random effects. E.g. at the id level in the example below, not at 
> the group level. The correlation is only effective among observations 
> from the same id. Two observation within the same group but different 
> id have uncorrelated residuals by definition. Likewise are two 
> residuals from different groups uncorrelated. The correlation matrix 
> of the residuals is hence always a block diagonal matrix, with blocks 
> defined by the most detailed level of the random effects.
>
> opposites <- 
> read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
> opposites$group <- opposites$id %% 6
> library(nlme)
> lme(opp ~ 1, random = ~1|group/id, data = opposites)
> lme(opp ~ 1, random = ~1|group/id, data = opposites, correlation = 
> corAR1(form = ~wave))
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2017-07-26 21:45 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>>:
>
>     Dear Thierry and Wolfgang,
>
>     Thanks for responding so quickly. Here is the reproducible example of
>     the two models that I'm interested in.
>
>     # Read data.
>     opposites <-
>     read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt
>     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt>",header=TRUE,sep=",")
>
>     # Open library.
>     library(nlme)
>
>     # Define group "one" with value 1 for all cases.
>     one <- rep(1, 140)
>
>     #----- Model estimated with gls.
>     comsym.gls <- gls(opp~1,opposites,
>                        correlation=corCompSymm(form = ~ 1 |id),
>     method="REML")
>     summary(comsym.gls)
>
>
>     #----- Same model estimated with lme.
>     comsym.lme <- lme(opp~1,opposites,
>                        random= ~1|one,
>                        correlation=corCompSymm(form = ~ 1 |one/id),
>     method="REML")
>     summary(comsym.lme)
>
>
>     #----- Wolfgang's gls suggestion for heterogeneous CS.
>
>     summary(gls(opp ~ 1, opposites, correlation = corCompSymm(form = ~ 1 |
>     id), weights = varIdent(form = ~ 1 | wave)))
>
>     # Does not work with lme.
>     summary(hetercom <- lme(opp ~ 1,opposites,
>                      correlation=corCompSymm(form = ~ 1 |id),
>                      weights=varIdent(form = ~1|wave), method="REML"))
>
>     # But does work with the "one" trick.
>     summary(lme(opp ~ 1,opposites,
>          random = ~1|one,
>          correlation=corCompSymm(form = ~ 1 |one/id),
>          weights=varIdent(form = ~1|wave), method="REML"))
>
>
>
>     The main reason of my mailing to the list is this. I was wondering
>     whether with lme it is possible to also estimate models with the
>     individuals nested in higher levels like schools or hospitals etc
>     and at
>     the same time letting the residuals correlate within individuals over
>     time with one of the nice covar structures. However, I do NOT have a
>     reproducible example of such more complex models at the moment. I only
>     hoped that if the lme version of the model presented above has no
>     further problems than a (slightly) different AIC, BIC and std.
>     error of
>     the fixed intercept, it would be meaningful to proceed in this
>     way, i.e.
>     using lme instead of gls, since lme provides the important possibility
>     of additional random effects in the model.
>
>     As to Wolfgang's suggestion for heretogeneous CS using:
>
>     gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id), weights =
>     varIdent(form = ~ 1 | timepoint))
>
>     I didn't find a way to estimate such a model with lme, except for the
>     method with the "trick". Using:
>
>     lme(opp ~ 1,opposites,
>                  correlation=corCompSymm(form = ~ 1 |id),
>                  weights=varIdent(form = ~1|wave), method="REML")
>
>     leads to error-message:
>
>     Error in lme.formula(opp ~ 1, opposites, correlation =
>     corCompSymm(form
>     = ~1 | : incompatible formulas for groups in 'random' and
>     'correlation'
>
>
>     whereas
>
>     lme(opp ~ 1,opposites,
>                  random = ~1|one,
>                  correlation=corCompSymm(form = ~ 1 |one/id),
>                  weights=varIdent(form = ~1|wave), method="REML")
>
>     leads to similar results as your gls suggestion.
>
>
>     Best regards, Ben.
>
>
>     On 26-7-2017 14:44, Thierry Onkelinx wrote:
>     > Dear Ben,
>     >
>     > Please be more specific on the kind of model you want to fit. That
>     > would lead to a more relevant discussion that your potential
>     misuse of
>     > lme. A reproducible example is always useful...
>     >
>     > Best regards,
>     >
>     >
>     > ir. Thierry Onkelinx
>     > Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature
>     > and Forest
>     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>     Assurance
>     > Kliniekstraat 25
>     > 1070 Anderlecht
>     > Belgium
>     >
>     > To call in the statistician after the experiment is done may be no
>     > more than asking him to perform a post-mortem examination: he may be
>     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer does
>     > not ensure that a reasonable answer can be extracted from a
>     given body
>     > of data. ~ John Tukey
>     >
>     > 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>:
>     >
>     >     Dear list,
>     >
>     >     With longitudinal data, the package nlme offers the
>     possibility to
>     >     specify particular covariance structures for the residuals.
>     In the
>     >     examples below I used data from 35 individuals measured at 4
>     time
>     >     points, so we have 4 observations nested in each of 35
>     individuals.
>     >     These data are discussed in Singer and Willett, Applied
>     Longitudinal
>     >     Data Analysis, chapter 7.
>     >
>     >     In several sources I found that e.g. compound symmetry can
>     easily be
>     >     obtained with gls from package nlme, by using the correlation
>     >     structure
>     >     corCompSymm, as in:
>     >
>     >          comsym <- gls(opp~1,opposites,
>     >                        correlation=corCompSymm(form = ~ 1 |id),
>     >     method="REML")
>     >
>     >     where id is subject-identifier for the individual. With gls
>     >     however one
>     >     cannot specify random effects, as opposed to lme. To have
>     lme estimate
>     >     compound symmetry is simple, one would not even need have to
>     specify a
>     >     particular correlation structure, it would suffice to say
>     >     "random=~1|id". However, for more complex covariance
>     structures, e.g.
>     >     heterogeneous compound symmetry, I was only able to find syntax
>     >     for gls,
>     >     but not for lme.
>     >
>     >     Then I thought that tricking lme might be an option by having a
>     >     kind of
>     >     "fake" random effect. That is, I constructed a variable
>     "one" which
>     >     takes value 1 for all cases, and let the intercept be random
>     >     across "all
>     >     one groups". This led to the following lme model:
>     >
>     >
>     >          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>     >                            correlation=corCompSymm(form = ~ 1
>     |one/id),
>     >     method="REML")
>     >
>     >     And actually to my surprise, the results of this lme are highly
>     >     similar
>     >     to those of the gls above.
>     >     The output of both is attached below. The loglik's are
>     identical, the
>     >     AIC and BIC are not, which I can understand, as the lme has
>     an extra
>     >     variance to be estimated, compared to the gls. Also, the fixed
>     >     intercept's standard error is different, the one of the lme
>     being
>     >     about
>     >     twice as large.
>     >
>     >     I added some independent variables (not shown below) but the
>     >     similarities between gls and lme remain, with only the AIC
>     and BIC and
>     >     the standard error of the fixed intercept being different
>     for the two
>     >     models.
>     >
>     >     My question is threefold.
>     >     1) Suppose the individuals (say pupils) would be nested in
>     >     schools, then
>     >     I assume that with lme I could add school as a random
>     effect, and
>     >     run a
>     >     "usual" model, with pupils nested in schools and observations in
>     >     pupils,
>     >     and then use any of the possible residual covariance structures
>     >     for the
>     >     observations in pupils. Would you agree with this? (with gls one
>     >     cannot
>     >     use an additional random effect, like e.g. school)
>     >     2) Are the lme results indeed to be trusted when using this
>     "fake"
>     >     random effect, apart from the differences with gls mentioned?
>     >     Could you
>     >     imagine a situation where lme with this trick would produce
>     wrong
>     >     results?
>     >     3) I don't understand the variance of the intercept in the
>     lme output.
>     >     Even when I specify a very simple model: lme(opp ~ 1, random
>     = ~1|one,
>     >     opposites, method="REML")
>     >     lme is able to estimate the intercept variance...but what is
>     this
>     >     variance estimate expressing?
>     >
>     >     Thanks a lot for any help!!!
>     >
>     >     Ben.
>     >
>     >
>     >
>     >
>     >
>     >     *----------------- gls
>     >     ---------------------------------------------------
>     >
>     >      > comsym <- gls(opp~1,opposites,
>     >                      correlation=corCompSymm(form = ~ 1 |id),
>     >     method="REML")
>     >      > summary(comsym)
>     >
>     >     Generalized least squares fit by REML
>     >     Model: opp ~ 1
>     >     Data: opposites
>     >           AIC      BIC    logLik
>     >     1460.954 1469.757 -727.4769
>     >
>     >     Correlation Structure: Compound symmetry
>     >     Formula: ~1 | id
>     >     Parameter estimate(s):
>     >        Rho
>     >     0.2757052
>     >
>     >     Coefficients:
>     >                     Value Std.Error  t-value p-value
>     >     (Intercept) 204.8143  5.341965 38.34063       0
>     >
>     >     Standardized residuals:
>     >        Min          Q1         Med          Q3  Max
>     >     -2.75474868 -0.71244027  0.00397158  0.56533908 2.24944156
>     >
>     >     Residual standard error: 46.76081
>     >     Degrees of freedom: 140 total; 139 residual
>     >
>     >
>     >     #------------------ lme
>     >     ---------------------------------------------------
>     >
>     >      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>     >                      correlation=corCompSymm(form = ~ 1 |one/id),
>     >     method="REML")
>     >      > summary(comsym.lme)
>     >
>     >     Linear mixed-effects model fit by REML
>     >     Data: opposites
>     >           AIC      BIC    logLik
>     >     1462.954 1474.692 -727.4769
>     >
>     >     Random effects:
>     >        Formula: ~1 | one
>     >              (Intercept) Residual
>     >     StdDev:    10.53875 46.76081
>     >
>     >     Correlation Structure: Compound symmetry
>     >     Formula: ~1 | one/id
>     >     Parameter estimate(s):
>     >        Rho
>     >     0.2757052
>     >     Fixed effects: opp ~ 1
>     >                     Value Std.Error  DF  t-value p-value
>     >     (Intercept) 204.8143  11.81532 139 17.33463       0
>     >
>     >     Standardized Within-Group Residuals:
>     >        Min          Q1         Med          Q3  Max
>     >     -2.75474868 -0.71244027  0.00397158  0.56533908 2.24944156
>     >
>     >     Number of Observations: 140
>     >     Number of Groups: 1
>     >
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From simonakf at gmail.com  Thu Jul 27 11:38:20 2017
From: simonakf at gmail.com (Simona Kralj Fiser)
Date: Thu, 27 Jul 2017 11:38:20 +0200
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
 <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
Message-ID: <CAPkBqk=O2Nyxdfx+_Ke_oyqz7-f6p6yN2DUx0tx_dedNwYQpbg@mail.gmail.com>

Dear Jarrod and Paul,



Thank you for your reply. We used the suggested prior and model
specifications, but we also LOG transformed our weight data (L). The new
values are mostly negative. We ran:



prior <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
alpha.mu=c(0,0),alpha.V=diag(2)*1000)))

model14 <- MCMCglmm(L~sex, random=~us(sex):animal, rcov=~idh(sex):units,
prior=prior, pedigree=Ped, data=Data1, nitt=100000, burnin=10000, thin=10)



The resulting summary is:



*Iterations = 10001:99991*

* Thinning interval  = 10*

* Sample size  = 9000 *



* DIC: -466.781 *



* G-structure:  ~us(sex):animal*



*                 post.mean   l-95% CI u-95% CI eff.samp*

*sex1:sex1.animal  0.003846  4.515e-10 0.009540     4761*

*sex2:sex1.animal  0.001122 -6.715e-04 0.003216     1436*

*sex1:sex2.animal  0.001122 -6.715e-04 0.003216     1436*

*sex2:sex2.animal  0.002096  1.310e-11 0.004439     5447*



* R-structure:  ~idh(sex):units*



*           post.mean l-95% CI u-95% CI eff.samp*

*sex1.units  0.019094 0.012842 0.025643     5700*

*sex2.units  0.007019 0.004553 0.009551     6510*



* Location effects: L ~ sex *



*            post.mean l-95% CI u-95% CI eff.samp  pMCMC    *

*(Intercept)   -0.9866  -1.0150  -0.9599     9521 <1e-04 ****

*sex2          -0.2536  -0.2843  -0.2227     9000 <1e-04 ****

*---*

*Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*





With LOG values, the ?subscript out of bounds? problem in gone, herit()
analyses run and the resulting heritability and correlation values are
reasonable. However, the HPD interval is extremely wide.



*> **herit14<-model14$VCV[,'sex1:sex1.animal']/(model14$VCV[,'sex1:sex1.animal']+model14$VCV[,'sex1.units'])*

*> **herit15<-model14$VCV[,'sex2:sex2.animal']/(model14$VCV[,'sex2:sex2.animal']+model14$VCV[,'sex2.units'])*

*> **mean(herit14)*

*[1] 0.1643911*

*> **mean(herit15)*

*[1] 0.226494*

*> **corr.gen <- model14$VCV[,
'sex1:sex2.animal']/sqrt(model14$VCV[,'sex1:sex1.animal']*model14$VCV[,'sex2:sex2.animal'])*

*> **mean(corr.gen)*

*[1] 0.4729393*

*> **HPDinterval(herit14)*

*            lower     upper*

*var1 2.149316e-08 0.3883343*

*attr(,"Probability")*

*[1] 0.95*

*> **HPDinterval(herit15)*

*            lower     upper*

*var1 1.539724e-09 0.4509762*

*attr(,"Probability")*

*[1] 0.95*

*> **HPDinterval(corr.gen)*

*          lower    upper*

*var1 -0.1849416 0.999439*

*attr(,"Probability")*

*[1] 0.95*



We are starting to run out of ideas on why this is happening or where the
problem lies. We?d appreciate any further advice!



Eva and Simona

On 26 July 2017 at 14:42, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> The second way is a *much* better way of doing it but should give the same
> answer. However, in both cases the residual covariance is not identifiable
> (no individual is both male and female) and so you should use idh rather
> than us.
>
> The "subscript out of bounds" error is to do with your code that
> post-processes the model output not an issue with MCMCglmm. Probably you
> have used the wrong names for the (co)variance components.
>
> Also, you haven't passed the prior to MCMCglmm, nor is the prior a valid
> one for the problem as it specifies scalar variances rather than 2x2
> covariance matrices. You could try
>
> prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
> alpha.mu=c(0,0),alpha.V=diag(2)*1000)))
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 26/07/2017 13:33, Simona Kralj Fiser wrote:
>
>> model <- MCMCglmm(W~sex, random=~us(sex):animal, rcov=~us(sex):units,
>> prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000,
>> thin=10)
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


-- 
Doc. Dr. Simona Kralj-Fi?er

Institute of Biology
Scientific Research Centre of the Slovenian Academy of Sciences and Arts
Novi trg 2, P. O. Box 306, SI-1001 Ljubljana.
Phone: ++38614706333; fax: ++38614257797

http://ezlab.zrc-sazu.si/

http://bijh.zrc-sazu.si/sl/sodelavci/simona-kralj-fi%C5%A1er-sl#v

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Jul 27 12:10:44 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 27 Jul 2017 11:10:44 +0100
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <CAPkBqk=O2Nyxdfx+_Ke_oyqz7-f6p6yN2DUx0tx_dedNwYQpbg@mail.gmail.com>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
 <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
 <CAPkBqk=O2Nyxdfx+_Ke_oyqz7-f6p6yN2DUx0tx_dedNwYQpbg@mail.gmail.com>
Message-ID: <7a51ed19-512e-a381-3efc-ff880dde575d@ed.ac.uk>

Hi Simona,

I'm not sure what the problem is? The h2 have very high uncertainty 
ranging from 0 to 0.4, and as a consequence the genetic correlation 
spans a large range. Accurate estimates of h2 require 1000's of 
individuals from 100's of families, genetic correlations even more.

Cheers,

Jarrod


On 27/07/2017 10:38, Simona Kralj Fiser wrote:
>
> Dear Jarrod and Paul,
>
> Thank you for your reply. We used the suggested prior and model 
> specifications, but we also LOG transformed our weight data (L). The 
> new values are mostly negative. We ran:
>
> prior <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), 
> nu=2, alpha.mu <http://alpha.mu/>=c(0,0),alpha.V=diag(2)*1000)))
>
> model14 <- MCMCglmm(L~sex, random=~us(sex):animal, 
> rcov=~idh(sex):units, prior=prior, pedigree=Ped, data=Data1, 
> nitt=100000, burnin=10000, thin=10)
>
> The resulting summary is:
>
> *Iterations = 10001:99991*
> *Thinning interval  = 10*
> *Sample size  = 9000 *
> **
> *DIC: -466.781 *
> **
> *G-structure:  ~us(sex):animal*
> **
> *                 post.mean   l-95% CI u-95% CI eff.samp*
> *sex1:sex1.animal  0.003846  4.515e-10 0.009540     4761*
> *sex2:sex1.animal  0.001122 -6.715e-04 0.003216     1436*
> *sex1:sex2.animal  0.001122 -6.715e-04 0.003216     1436*
> *sex2:sex2.animal  0.002096  1.310e-11 0.004439     5447*
> **
> *R-structure:  ~idh(sex):units*
> **
> *           post.mean l-95% CI u-95% CI eff.samp*
> *sex1.units  0.019094 0.012842 0.025643     5700*
> *sex2.units  0.007019 0.004553 0.009551     6510*
> **
> *Location effects: L ~ sex *
> **
> *            post.mean l-95% CI u-95% CI eff.samp  pMCMC *
> *(Intercept)   -0.9866  -1.0150  -0.9599     9521 <1e-04 ****
> *sex2          -0.2536  -0.2843  -0.2227     9000 <1e-04 ****
> *---*
> *Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>
> With LOG values, the ?subscript out of bounds? problem in gone, 
> herit() analyses run and the resulting heritability and correlation 
> values are reasonable. However, the HPD interval is extremely wide.
>
> *> 
> **herit14<-model14$VCV[,'sex1:sex1.animal']/(model14$VCV[,'sex1:sex1.animal']+model14$VCV[,'sex1.units'])*
> *> 
> **herit15<-model14$VCV[,'sex2:sex2.animal']/(model14$VCV[,'sex2:sex2.animal']+model14$VCV[,'sex2.units'])*
> *> **mean(herit14)*
> *[1] 0.1643911*
> *> **mean(herit15)*
> *[1] 0.226494*
> *> **corr.gen <- model14$VCV[, 
> 'sex1:sex2.animal']/sqrt(model14$VCV[,'sex1:sex1.animal']*model14$VCV[,'sex2:sex2.animal'])*
> *> **mean(corr.gen)*
> *[1] 0.4729393*
> *> **HPDinterval(herit14)*
> *            lower     upper*
> *var1 2.149316e-08 0.3883343*
> *attr(,"Probability")*
> *[1] 0.95*
> *> **HPDinterval(herit15)*
> *            lower     upper*
> *var1 1.539724e-09 0.4509762*
> *attr(,"Probability")*
> *[1] 0.95*
> *> **HPDinterval(corr.gen)*
> *          lower    upper*
> *var1 -0.1849416 0.999439*
> *attr(,"Probability")*
> *[1] 0.95*
>
> We are starting to run out of ideas on why this is happening or where 
> the problem lies. We?d appreciate any further advice!
>
> Eva and Simona
>
>
> On 26 July 2017 at 14:42, Jarrod Hadfield <j.hadfield at ed.ac.uk 
> <mailto:j.hadfield at ed.ac.uk>> wrote:
>
>     Hi,
>
>     The second way is a *much* better way of doing it but should give
>     the same answer. However, in both cases the residual covariance is
>     not identifiable (no individual is both male and female) and so
>     you should use idh rather than us.
>
>     The "subscript out of bounds" error is to do with your code that
>     post-processes the model output not an issue with MCMCglmm.
>     Probably you have used the wrong names for the (co)variance
>     components.
>
>     Also, you haven't passed the prior to MCMCglmm, nor is the prior a
>     valid one for the problem as it specifies scalar variances rather
>     than 2x2 covariance matrices. You could try
>
>     prior2 <- list(R=list(V=diag(2), nu=0.02),
>     G=list(G1=list(V=diag(2), nu=2, alpha.mu
>     <http://alpha.mu>=c(0,0),alpha.V=diag(2)*1000)))
>
>     Cheers,
>
>     Jarrod
>
>
>
>
>     On 26/07/2017 13:33, Simona Kralj Fiser wrote:
>
>         model <- MCMCglmm(W~sex, random=~us(sex):animal,
>         rcov=~us(sex):units,
>         prior=prior2, pedigree=Ped, data=Data1, nitt=100000,
>         burnin=10000, thin=10)
>
>
>
>     -- 
>     The University of Edinburgh is a charitable body, registered in
>     Scotland, with registration number SC005336.
>
>
>
>
> -- 
> Doc. Dr. Simona Kralj-Fi?er
>
> Institute of Biology
> Scientific Research Centre of the Slovenian Academy of Sciences and Arts
> Novi trg 2, P. O. Box 306, SI-1001 Ljubljana.
> Phone: ++38614706333; fax: ++38614257797
>
> http://ezlab.zrc-sazu.si/
>
> http://bijh.zrc-sazu.si/sl/sodelavci/simona-kralj-fi%C5%A1er-sl#v

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170727/87c10e5d/attachment.ksh>

From simonakf at gmail.com  Thu Jul 27 13:06:36 2017
From: simonakf at gmail.com (Simona Kralj Fiser)
Date: Thu, 27 Jul 2017 13:06:36 +0200
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <7a51ed19-512e-a381-3efc-ff880dde575d@ed.ac.uk>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
 <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
 <CAPkBqk=O2Nyxdfx+_Ke_oyqz7-f6p6yN2DUx0tx_dedNwYQpbg@mail.gmail.com>
 <7a51ed19-512e-a381-3efc-ff880dde575d@ed.ac.uk>
Message-ID: <CAPkBqkmvc3T1URhs3jWwT=E2JpsvwgE-bJJ55ZWS2a60qjgmvA@mail.gmail.com>

I see :-(

Thanks a lot for your help.

Simona

On 27 July 2017 at 12:10, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Simona,
>
> I'm not sure what the problem is? The h2 have very high uncertainty
> ranging from 0 to 0.4, and as a consequence the genetic correlation spans a
> large range. Accurate estimates of h2 require 1000's of individuals from
> 100's of families, genetic correlations even more.
>
> Cheers,
>
> Jarrod
>
> On 27/07/2017 10:38, Simona Kralj Fiser wrote:
>
> Dear Jarrod and Paul,
>
>
>
> Thank you for your reply. We used the suggested prior and model
> specifications, but we also LOG transformed our weight data (L). The new
> values are mostly negative. We ran:
>
>
>
> prior <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
> alpha.mu=c(0,0),alpha.V=diag(2)*1000)))
>
> model14 <- MCMCglmm(L~sex, random=~us(sex):animal, rcov=~idh(sex):units,
> prior=prior, pedigree=Ped, data=Data1, nitt=100000, burnin=10000, thin=10)
>
>
>
> The resulting summary is:
>
>
>
> *Iterations = 10001:99991*
>
> * Thinning interval  = 10*
>
> * Sample size  = 9000 *
>
>
>
> * DIC: -466.781 *
>
>
>
> * G-structure:  ~us(sex):animal*
>
>
>
> *                 post.mean   l-95% CI u-95% CI eff.samp*
>
> *sex1:sex1.animal  0.003846  4.515e-10 0.009540     4761*
>
> *sex2:sex1.animal  0.001122 -6.715e-04 0.003216     1436*
>
> *sex1:sex2.animal  0.001122 -6.715e-04 0.003216     1436*
>
> *sex2:sex2.animal  0.002096  1.310e-11 0.004439     5447*
>
>
>
> * R-structure:  ~idh(sex):units*
>
>
>
> *           post.mean l-95% CI u-95% CI eff.samp*
>
> *sex1.units  0.019094 0.012842 0.025643     5700*
>
> *sex2.units  0.007019 0.004553 0.009551     6510*
>
>
>
> * Location effects: L ~ sex *
>
>
>
> *            post.mean l-95% CI u-95% CI eff.samp  pMCMC    *
>
> *(Intercept)   -0.9866  -1.0150  -0.9599     9521 <1e-04 ****
>
> *sex2          -0.2536  -0.2843  -0.2227     9000 <1e-04 ****
>
> *---*
>
> *Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1*
>
>
>
>
>
> With LOG values, the ?subscript out of bounds? problem in gone, herit()
> analyses run and the resulting heritability and correlation values are
> reasonable. However, the HPD interval is extremely wide.
>
>
>
> *> **herit14<-model14$VCV[,'sex1:sex1.animal']/(model14$VCV[,'sex1:sex1.animal']+model14$VCV[,'sex1.units'])*
>
> *> **herit15<-model14$VCV[,'sex2:sex2.animal']/(model14$VCV[,'sex2:sex2.animal']+model14$VCV[,'sex2.units'])*
>
> *> **mean(herit14)*
>
> *[1] 0.1643911*
>
> *> **mean(herit15)*
>
> *[1] 0.226494*
>
> *> **corr.gen <- model14$VCV[, 'sex1:sex2.animal']/sqrt(model14$VCV[,'sex1:sex1.animal']*model14$VCV[,'sex2:sex2.animal'])*
>
> *> **mean(corr.gen)*
>
> *[1] 0.4729393*
>
> *> **HPDinterval(herit14)*
>
> *            lower     upper*
>
> *var1 2.149316e-08 0.3883343*
>
> *attr(,"Probability")*
>
> *[1] 0.95*
>
> *> **HPDinterval(herit15)*
>
> *            lower     upper*
>
> *var1 1.539724e-09 0.4509762*
>
> *attr(,"Probability")*
>
> *[1] 0.95*
>
> *> **HPDinterval(corr.gen)*
>
> *          lower    upper*
>
> *var1 -0.1849416 0.999439*
>
> *attr(,"Probability")*
>
> *[1] 0.95*
>
>
>
> We are starting to run out of ideas on why this is happening or where the
> problem lies. We?d appreciate any further advice!
>
>
>
> Eva and Simona
>
> On 26 July 2017 at 14:42, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> The second way is a *much* better way of doing it but should give the
>> same answer. However, in both cases the residual covariance is not
>> identifiable (no individual is both male and female) and so you should use
>> idh rather than us.
>>
>> The "subscript out of bounds" error is to do with your code that
>> post-processes the model output not an issue with MCMCglmm. Probably you
>> have used the wrong names for the (co)variance components.
>>
>> Also, you haven't passed the prior to MCMCglmm, nor is the prior a valid
>> one for the problem as it specifies scalar variances rather than 2x2
>> covariance matrices. You could try
>>
>> prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2),
>> nu=2, alpha.mu=c(0,0),alpha.V=diag(2)*1000)))
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> On 26/07/2017 13:33, Simona Kralj Fiser wrote:
>>
>>> model <- MCMCglmm(W~sex, random=~us(sex):animal, rcov=~us(sex):units,
>>> prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000,
>>> thin=10)
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
> --
> Doc. Dr. Simona Kralj-Fi?er
>
> Institute of Biology
> Scientific Research Centre of the Slovenian Academy of Sciences and Arts
> Novi trg 2, P. O. Box 306, SI-1001 Ljubljana.
> Phone: ++38614706333 <(01)%20470%2063%2033>; fax: ++38614257797
> <(01)%20425%2077%2097>
>
> http://ezlab.zrc-sazu.si/
>
> http://bijh.zrc-sazu.si/sl/sodelavci/simona-kralj-fi%C5%A1er-sl#v
>
>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


-- 
Doc. Dr. Simona Kralj-Fi?er

Institute of Biology
Scientific Research Centre of the Slovenian Academy of Sciences and Arts
Novi trg 2, P. O. Box 306, SI-1001 Ljubljana.
Phone: ++38614706333; fax: ++38614257797

http://ezlab.zrc-sazu.si/

http://bijh.zrc-sazu.si/sl/sodelavci/simona-kralj-fi%C5%A1er-sl#v

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Jul 27 15:13:45 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 27 Jul 2017 15:13:45 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <eba39df9-d98e-aea2-2841-f171465d51c4@maw.ru.nl>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
 <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
 <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>
 <eba39df9-d98e-aea2-2841-f171465d51c4@maw.ru.nl>
Message-ID: <CAJuCY5wwaZ0Su1+j7udSWrpV9Py4e9nL2HPYAB_ktTfvdCq4jg@mail.gmail.com>

Dear Ben,

I would look at the variance-covariance matrix of the model. Below is the
var-covar matrix for the model lme(opp ~ 1, random = ~1|id,
correlation=corCompSymm(form = ~ wave), weights=varIdent(form = ~1|wave)).
I worked it out for 3 id groups with each 3 waves. The submatrices indicate
the grouping by the random effect.

Is this the structure you are looking for? If not please provide the
required structure.

Having a random effect with only one level is nonsense. IMHO it should
yield an error, or at least a warning. I have no idea how lme estimates the
reported variance.

Best regards,

Thierry

$\sigma^2_i$: random effect variance
$\sigma^2_e$: variance of the noise
$\rho$: correlation of the compound symmetry
$w_2$ and $w_3$: relative variance of the 2nd and 3th wave compared to the
1st wave

$$
\begin{pmatrix}
  \begin{bmatrix}
    \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
\sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
  \end{bmatrix} &
  \begin{bmatrix}
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i
  \end{bmatrix} &
  \begin{bmatrix}
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i
  \end{bmatrix}
  \\
  \begin{bmatrix}
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i
  \end{bmatrix} &
  \begin{bmatrix}
    \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
\sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
  \end{bmatrix} \\
    \begin{bmatrix}
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i
  \end{bmatrix} &
  \begin{bmatrix}
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i\\
    \sigma^2_i & \sigma^2_i & \sigma^2_i
  \end{bmatrix} &
  \begin{bmatrix}
    \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
\sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
    \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
\sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
  \end{bmatrix}
\end{pmatrix}
$$


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-27 11:16 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:

> Dear Thierry,
>
> Thanks for your help with these models. I wasn't sure how to formulate
> them. At the department of sciology where I work (Radboud University)
> longitudinal data are getting more common bussiness. And very often,
> we'd like to estimate random country or municipality influences for
> repeated measures on the same person. This is not a big problem as long
> as we use growth modelling with random intercept and random time
> influence, but the covariance structure implied by such models is, say,
> limited. Knowing how to specify the cov. structures in R is really
> helpful and broadens prespective.
>
> After fiddling around with all the possibilities, the picture is slowly
> getting clearer here. I was puzzled by the heterogeneous compound
> symmetry structure and how to specify this. With specification:
>
> heteroCS1 <- lme(opp ~ 1,opposites,
>      random = ~1|id,
>      correlation=corCompSymm(form = ~ wave),
>      weights=varIdent(form = ~1|wave), method="REML")
>
> the random person effect is estimated apart from the residuals. On the
> other hand, with:
>
> heteroCS2 <- lme(opp ~ 1,opposites,
>      random = ~1|one,
>      correlation=corCompSymm(form = ~wave | one/id),
>      weights=varIdent(form = ~1|wave), method="REML"))
>
> the random person effect is kept part of the residuals, because it is
> not estimated explicitly. As a result, heteroCS2 gives the same results
> as obtained with the more straightforward gls specification:
>
> hetroCS3 <- gls(opp ~ 1, opposites,
>      correlation = corCompSymm(form = ~ wave|id),
>      weights = varIdent(form = ~ 1 | wave))
>
> In general, I think I would prefer to have the random person effect as
> part the residual term instead of seperating it from the residual. That
> is, by cutting the random person effect away from the residual, you
> remove the very part that causes correlation between the observations
> over time. The only specification (I could think of) that keeps the
> random person effect IN the residual is heteroCS2. But maybe something
> less artificial can be found....
>
> And the strange thing that remains is: how can lme estimate a random
> effect variance in case of one single group, as in:
>
> strangemodel <- lme(opp ~1, random = ~1|one, opposites)
>
> which produces the summary:
>
> Linear mixed-effects model fit by REML
>   Data: opposites
>       AIC      BIC    logLik
>    1473.5 1482.303 -733.7498
>
> Random effects:
>   Formula: ~1 | one
>          (Intercept) Residual
> StdDev:    10.50729 46.62148
>
> Fixed effects: opp ~ 1
>                 Value Std.Error  DF  t-value p-value
> (Intercept) 204.8143  11.22179 139 18.25148       0
>
>
> Do you have any thoughts about this strange model's estimate of the
> intercept variance 10.50729?
>
> Best regards, Ben.
>
>
> On 26-7-2017 22:05, Thierry Onkelinx wrote:
> > Dear Ben,
> >
> > The correlation structure always works at the most detailed level of
> > the random effects. E.g. at the id level in the example below, not at
> > the group level. The correlation is only effective among observations
> > from the same id. Two observation within the same group but different
> > id have uncorrelated residuals by definition. Likewise are two
> > residuals from different groups uncorrelated. The correlation matrix
> > of the residuals is hence always a block diagonal matrix, with blocks
> > defined by the most detailed level of the random effects.
> >
> > opposites <-
> > read.table("https://stats.idre.ucla.edu/stat/r/examples/
> alda/data/opposites_pp.txt",header=TRUE,sep=",")
> > opposites$group <- opposites$id %% 6
> > library(nlme)
> > lme(opp ~ 1, random = ~1|group/id, data = opposites)
> > lme(opp ~ 1, random = ~1|group/id, data = opposites, correlation =
> > corAR1(form = ~wave))
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2017-07-26 21:45 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> > <mailto:b.pelzer at maw.ru.nl>>:
> >
> >     Dear Thierry and Wolfgang,
> >
> >     Thanks for responding so quickly. Here is the reproducible example of
> >     the two models that I'm interested in.
> >
> >     # Read data.
> >     opposites <-
> >     read.table("https://stats.idre.ucla.edu/stat/r/examples/
> alda/dat/opposites_pp.txt
> >     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/
> opposites_pp.txt>",header=TRUE,sep=",")
> >
> >     # Open library.
> >     library(nlme)
> >
> >     # Define group "one" with value 1 for all cases.
> >     one <- rep(1, 140)
> >
> >     #----- Model estimated with gls.
> >     comsym.gls <- gls(opp~1,opposites,
> >                        correlation=corCompSymm(form = ~ 1 |id),
> >     method="REML")
> >     summary(comsym.gls)
> >
> >
> >     #----- Same model estimated with lme.
> >     comsym.lme <- lme(opp~1,opposites,
> >                        random= ~1|one,
> >                        correlation=corCompSymm(form = ~ 1 |one/id),
> >     method="REML")
> >     summary(comsym.lme)
> >
> >
> >     #----- Wolfgang's gls suggestion for heterogeneous CS.
> >
> >     summary(gls(opp ~ 1, opposites, correlation = corCompSymm(form = ~ 1
> |
> >     id), weights = varIdent(form = ~ 1 | wave)))
> >
> >     # Does not work with lme.
> >     summary(hetercom <- lme(opp ~ 1,opposites,
> >                      correlation=corCompSymm(form = ~ 1 |id),
> >                      weights=varIdent(form = ~1|wave), method="REML"))
> >
> >     # But does work with the "one" trick.
> >     summary(lme(opp ~ 1,opposites,
> >          random = ~1|one,
> >          correlation=corCompSymm(form = ~ 1 |one/id),
> >          weights=varIdent(form = ~1|wave), method="REML"))
> >
> >
> >
> >     The main reason of my mailing to the list is this. I was wondering
> >     whether with lme it is possible to also estimate models with the
> >     individuals nested in higher levels like schools or hospitals etc
> >     and at
> >     the same time letting the residuals correlate within individuals over
> >     time with one of the nice covar structures. However, I do NOT have a
> >     reproducible example of such more complex models at the moment. I
> only
> >     hoped that if the lme version of the model presented above has no
> >     further problems than a (slightly) different AIC, BIC and std.
> >     error of
> >     the fixed intercept, it would be meaningful to proceed in this
> >     way, i.e.
> >     using lme instead of gls, since lme provides the important
> possibility
> >     of additional random effects in the model.
> >
> >     As to Wolfgang's suggestion for heretogeneous CS using:
> >
> >     gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id), weights =
> >     varIdent(form = ~ 1 | timepoint))
> >
> >     I didn't find a way to estimate such a model with lme, except for the
> >     method with the "trick". Using:
> >
> >     lme(opp ~ 1,opposites,
> >                  correlation=corCompSymm(form = ~ 1 |id),
> >                  weights=varIdent(form = ~1|wave), method="REML")
> >
> >     leads to error-message:
> >
> >     Error in lme.formula(opp ~ 1, opposites, correlation =
> >     corCompSymm(form
> >     = ~1 | : incompatible formulas for groups in 'random' and
> >     'correlation'
> >
> >
> >     whereas
> >
> >     lme(opp ~ 1,opposites,
> >                  random = ~1|one,
> >                  correlation=corCompSymm(form = ~ 1 |one/id),
> >                  weights=varIdent(form = ~1|wave), method="REML")
> >
> >     leads to similar results as your gls suggestion.
> >
> >
> >     Best regards, Ben.
> >
> >
> >     On 26-7-2017 14:44, Thierry Onkelinx wrote:
> >     > Dear Ben,
> >     >
> >     > Please be more specific on the kind of model you want to fit. That
> >     > would lead to a more relevant discussion that your potential
> >     misuse of
> >     > lme. A reproducible example is always useful...
> >     >
> >     > Best regards,
> >     >
> >     >
> >     > ir. Thierry Onkelinx
> >     > Instituut voor natuur- en bosonderzoek / Research Institute for
> >     Nature
> >     > and Forest
> >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> >     Assurance
> >     > Kliniekstraat 25
> >     > 1070 Anderlecht
> >     > Belgium
> >     >
> >     > To call in the statistician after the experiment is done may be no
> >     > more than asking him to perform a post-mortem examination: he may
> be
> >     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >     > The plural of anecdote is not data. ~ Roger Brinner
> >     > The combination of some data and an aching desire for an answer
> does
> >     > not ensure that a reasonable answer can be extracted from a
> >     given body
> >     > of data. ~ John Tukey
> >     >
> >     > 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>:
> >     >
> >     >     Dear list,
> >     >
> >     >     With longitudinal data, the package nlme offers the
> >     possibility to
> >     >     specify particular covariance structures for the residuals.
> >     In the
> >     >     examples below I used data from 35 individuals measured at 4
> >     time
> >     >     points, so we have 4 observations nested in each of 35
> >     individuals.
> >     >     These data are discussed in Singer and Willett, Applied
> >     Longitudinal
> >     >     Data Analysis, chapter 7.
> >     >
> >     >     In several sources I found that e.g. compound symmetry can
> >     easily be
> >     >     obtained with gls from package nlme, by using the correlation
> >     >     structure
> >     >     corCompSymm, as in:
> >     >
> >     >          comsym <- gls(opp~1,opposites,
> >     >                        correlation=corCompSymm(form = ~ 1 |id),
> >     >     method="REML")
> >     >
> >     >     where id is subject-identifier for the individual. With gls
> >     >     however one
> >     >     cannot specify random effects, as opposed to lme. To have
> >     lme estimate
> >     >     compound symmetry is simple, one would not even need have to
> >     specify a
> >     >     particular correlation structure, it would suffice to say
> >     >     "random=~1|id". However, for more complex covariance
> >     structures, e.g.
> >     >     heterogeneous compound symmetry, I was only able to find syntax
> >     >     for gls,
> >     >     but not for lme.
> >     >
> >     >     Then I thought that tricking lme might be an option by having a
> >     >     kind of
> >     >     "fake" random effect. That is, I constructed a variable
> >     "one" which
> >     >     takes value 1 for all cases, and let the intercept be random
> >     >     across "all
> >     >     one groups". This led to the following lme model:
> >     >
> >     >
> >     >          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >     >                            correlation=corCompSymm(form = ~ 1
> >     |one/id),
> >     >     method="REML")
> >     >
> >     >     And actually to my surprise, the results of this lme are highly
> >     >     similar
> >     >     to those of the gls above.
> >     >     The output of both is attached below. The loglik's are
> >     identical, the
> >     >     AIC and BIC are not, which I can understand, as the lme has
> >     an extra
> >     >     variance to be estimated, compared to the gls. Also, the fixed
> >     >     intercept's standard error is different, the one of the lme
> >     being
> >     >     about
> >     >     twice as large.
> >     >
> >     >     I added some independent variables (not shown below) but the
> >     >     similarities between gls and lme remain, with only the AIC
> >     and BIC and
> >     >     the standard error of the fixed intercept being different
> >     for the two
> >     >     models.
> >     >
> >     >     My question is threefold.
> >     >     1) Suppose the individuals (say pupils) would be nested in
> >     >     schools, then
> >     >     I assume that with lme I could add school as a random
> >     effect, and
> >     >     run a
> >     >     "usual" model, with pupils nested in schools and observations
> in
> >     >     pupils,
> >     >     and then use any of the possible residual covariance structures
> >     >     for the
> >     >     observations in pupils. Would you agree with this? (with gls
> one
> >     >     cannot
> >     >     use an additional random effect, like e.g. school)
> >     >     2) Are the lme results indeed to be trusted when using this
> >     "fake"
> >     >     random effect, apart from the differences with gls mentioned?
> >     >     Could you
> >     >     imagine a situation where lme with this trick would produce
> >     wrong
> >     >     results?
> >     >     3) I don't understand the variance of the intercept in the
> >     lme output.
> >     >     Even when I specify a very simple model: lme(opp ~ 1, random
> >     = ~1|one,
> >     >     opposites, method="REML")
> >     >     lme is able to estimate the intercept variance...but what is
> >     this
> >     >     variance estimate expressing?
> >     >
> >     >     Thanks a lot for any help!!!
> >     >
> >     >     Ben.
> >     >
> >     >
> >     >
> >     >
> >     >
> >     >     *----------------- gls
> >     >     ---------------------------------------------------
> >     >
> >     >      > comsym <- gls(opp~1,opposites,
> >     >                      correlation=corCompSymm(form = ~ 1 |id),
> >     >     method="REML")
> >     >      > summary(comsym)
> >     >
> >     >     Generalized least squares fit by REML
> >     >     Model: opp ~ 1
> >     >     Data: opposites
> >     >           AIC      BIC    logLik
> >     >     1460.954 1469.757 -727.4769
> >     >
> >     >     Correlation Structure: Compound symmetry
> >     >     Formula: ~1 | id
> >     >     Parameter estimate(s):
> >     >        Rho
> >     >     0.2757052
> >     >
> >     >     Coefficients:
> >     >                     Value Std.Error  t-value p-value
> >     >     (Intercept) 204.8143  5.341965 38.34063       0
> >     >
> >     >     Standardized residuals:
> >     >        Min          Q1         Med          Q3  Max
> >     >     -2.75474868 -0.71244027  0.00397158  0.56533908 2.24944156
> >     >
> >     >     Residual standard error: 46.76081
> >     >     Degrees of freedom: 140 total; 139 residual
> >     >
> >     >
> >     >     #------------------ lme
> >     >     ---------------------------------------------------
> >     >
> >     >      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >     >                      correlation=corCompSymm(form = ~ 1 |one/id),
> >     >     method="REML")
> >     >      > summary(comsym.lme)
> >     >
> >     >     Linear mixed-effects model fit by REML
> >     >     Data: opposites
> >     >           AIC      BIC    logLik
> >     >     1462.954 1474.692 -727.4769
> >     >
> >     >     Random effects:
> >     >        Formula: ~1 | one
> >     >              (Intercept) Residual
> >     >     StdDev:    10.53875 46.76081
> >     >
> >     >     Correlation Structure: Compound symmetry
> >     >     Formula: ~1 | one/id
> >     >     Parameter estimate(s):
> >     >        Rho
> >     >     0.2757052
> >     >     Fixed effects: opp ~ 1
> >     >                     Value Std.Error  DF  t-value p-value
> >     >     (Intercept) 204.8143  11.81532 139 17.33463       0
> >     >
> >     >     Standardized Within-Group Residuals:
> >     >        Min          Q1         Med          Q3  Max
> >     >     -2.75474868 -0.71244027  0.00397158  0.56533908 2.24944156
> >     >
> >     >     Number of Observations: 140
> >     >     Number of Groups: 1
> >     >
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >
> >     >
> >
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Fri Jul 28 10:51:54 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 28 Jul 2017 10:51:54 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <CAJuCY5wwaZ0Su1+j7udSWrpV9Py4e9nL2HPYAB_ktTfvdCq4jg@mail.gmail.com>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
 <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
 <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>
 <eba39df9-d98e-aea2-2841-f171465d51c4@maw.ru.nl>
 <CAJuCY5wwaZ0Su1+j7udSWrpV9Py4e9nL2HPYAB_ktTfvdCq4jg@mail.gmail.com>
Message-ID: <bdb2b62a-9816-4ad3-45a2-9b6ac42dca87@maw.ru.nl>

Dear Thierry,

After all effort and thinking about the trick with the "one" variable, I 
realised (but only after your previous mail with the syntax for the 
"group" variable) that I do not need the trick at all. With a 
grouping/context variable, lme can be used and without such 
grouping/context, gls will do. Why didn't I realize this earlier???

As to your last mail, the syntax you included looks very intriguing, 
which language did you use to evaluate the cov matrix?

Best regards, Ben.

On 27-7-2017 15:13, Thierry Onkelinx wrote:
> Dear Ben,
>
> I would look at the variance-covariance matrix of the model. Below is 
> the var-covar matrix for the model lme(opp ~ 1, random = ~1|id, 
> correlation=corCompSymm(form = ~ wave), weights=varIdent(form = 
> ~1|wave)). I worked it out for 3 id groups with each 3 waves. The 
> submatrices indicate the grouping by the random effect.
>
> Is this the structure you are looking for? If not please provide the 
> required structure.
>
> Having a random effect with only one level is nonsense. IMHO it should 
> yield an error, or at least a warning. I have no idea how lme 
> estimates the reported variance.
>
> Best regards,
>
> Thierry
>
> $\sigma^2_i$: random effect variance
> $\sigma^2_e$: variance of the noise
> $\rho$: correlation of the compound symmetry
> $w_2$ and $w_3$: relative variance of the 2nd and 3th wave compared to 
> the 1st wave
>
> $$
> \begin{pmatrix}
>   \begin{bmatrix}
>     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e & 
> \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
>   \end{bmatrix} &
>   \begin{bmatrix}
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i
>   \end{bmatrix} &
>   \begin{bmatrix}
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i
>   \end{bmatrix}
>   \\
>   \begin{bmatrix}
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i
>   \end{bmatrix} &
>   \begin{bmatrix}
>     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e & 
> \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
>   \end{bmatrix} \\
>     \begin{bmatrix}
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i
>   \end{bmatrix} &
>   \begin{bmatrix}
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
>     \sigma^2_i & \sigma^2_i & \sigma^2_i
>   \end{bmatrix} &
>   \begin{bmatrix}
>     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e & 
> \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
>     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e & 
> \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
>   \end{bmatrix}
> \end{pmatrix}
> $$
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2017-07-27 11:16 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>>:
>
>     Dear Thierry,
>
>     Thanks for your help with these models. I wasn't sure how to formulate
>     them. At the department of sciology where I work (Radboud University)
>     longitudinal data are getting more common bussiness. And very often,
>     we'd like to estimate random country or municipality influences for
>     repeated measures on the same person. This is not a big problem as
>     long
>     as we use growth modelling with random intercept and random time
>     influence, but the covariance structure implied by such models is,
>     say,
>     limited. Knowing how to specify the cov. structures in R is really
>     helpful and broadens prespective.
>
>     After fiddling around with all the possibilities, the picture is
>     slowly
>     getting clearer here. I was puzzled by the heterogeneous compound
>     symmetry structure and how to specify this. With specification:
>
>     heteroCS1 <- lme(opp ~ 1,opposites,
>          random = ~1|id,
>          correlation=corCompSymm(form = ~ wave),
>          weights=varIdent(form = ~1|wave), method="REML")
>
>     the random person effect is estimated apart from the residuals. On the
>     other hand, with:
>
>     heteroCS2 <- lme(opp ~ 1,opposites,
>          random = ~1|one,
>          correlation=corCompSymm(form = ~wave | one/id),
>          weights=varIdent(form = ~1|wave), method="REML"))
>
>     the random person effect is kept part of the residuals, because it is
>     not estimated explicitly. As a result, heteroCS2 gives the same
>     results
>     as obtained with the more straightforward gls specification:
>
>     hetroCS3 <- gls(opp ~ 1, opposites,
>          correlation = corCompSymm(form = ~ wave|id),
>          weights = varIdent(form = ~ 1 | wave))
>
>     In general, I think I would prefer to have the random person effect as
>     part the residual term instead of seperating it from the residual.
>     That
>     is, by cutting the random person effect away from the residual, you
>     remove the very part that causes correlation between the observations
>     over time. The only specification (I could think of) that keeps the
>     random person effect IN the residual is heteroCS2. But maybe something
>     less artificial can be found....
>
>     And the strange thing that remains is: how can lme estimate a random
>     effect variance in case of one single group, as in:
>
>     strangemodel <- lme(opp ~1, random = ~1|one, opposites)
>
>     which produces the summary:
>
>     Linear mixed-effects model fit by REML
>       Data: opposites
>           AIC      BIC    logLik
>        1473.5 1482.303 -733.7498
>
>     Random effects:
>       Formula: ~1 | one
>              (Intercept) Residual
>     StdDev:    10.50729 46.62148
>
>     Fixed effects: opp ~ 1
>                     Value Std.Error  DF  t-value p-value
>     (Intercept) 204.8143  11.22179 139 18.25148       0
>
>
>     Do you have any thoughts about this strange model's estimate of the
>     intercept variance 10.50729?
>
>     Best regards, Ben.
>
>
>     On 26-7-2017 22:05, Thierry Onkelinx wrote:
>     > Dear Ben,
>     >
>     > The correlation structure always works at the most detailed level of
>     > the random effects. E.g. at the id level in the example below,
>     not at
>     > the group level. The correlation is only effective among
>     observations
>     > from the same id. Two observation within the same group but
>     different
>     > id have uncorrelated residuals by definition. Likewise are two
>     > residuals from different groups uncorrelated. The correlation matrix
>     > of the residuals is hence always a block diagonal matrix, with
>     blocks
>     > defined by the most detailed level of the random effects.
>     >
>     > opposites <-
>     >
>     read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt
>     <https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt>",header=TRUE,sep=",")
>     > opposites$group <- opposites$id %% 6
>     > library(nlme)
>     > lme(opp ~ 1, random = ~1|group/id, data = opposites)
>     > lme(opp ~ 1, random = ~1|group/id, data = opposites, correlation =
>     > corAR1(form = ~wave))
>     >
>     > Best regards,
>     >
>     >
>     > ir. Thierry Onkelinx
>     > Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature
>     > and Forest
>     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>     Assurance
>     > Kliniekstraat 25
>     > 1070 Anderlecht
>     > Belgium
>     >
>     > To call in the statistician after the experiment is done may be no
>     > more than asking him to perform a post-mortem examination: he may be
>     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer does
>     > not ensure that a reasonable answer can be extracted from a
>     given body
>     > of data. ~ John Tukey
>     >
>     > 2017-07-26 21:45 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>:
>     >
>     >     Dear Thierry and Wolfgang,
>     >
>     >     Thanks for responding so quickly. Here is the reproducible
>     example of
>     >     the two models that I'm interested in.
>     >
>     >     # Read data.
>     >     opposites <-
>     >   
>      read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt
>     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt>
>     >   
>      <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt
>     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/opposites_pp.txt>>",header=TRUE,sep=",")
>     >
>     >     # Open library.
>     >     library(nlme)
>     >
>     >     # Define group "one" with value 1 for all cases.
>     >     one <- rep(1, 140)
>     >
>     >     #----- Model estimated with gls.
>     >     comsym.gls <- gls(opp~1,opposites,
>     >                        correlation=corCompSymm(form = ~ 1 |id),
>     >     method="REML")
>     >     summary(comsym.gls)
>     >
>     >
>     >     #----- Same model estimated with lme.
>     >     comsym.lme <- lme(opp~1,opposites,
>     >                        random= ~1|one,
>     >                        correlation=corCompSymm(form = ~ 1 |one/id),
>     >     method="REML")
>     >     summary(comsym.lme)
>     >
>     >
>     >     #----- Wolfgang's gls suggestion for heterogeneous CS.
>     >
>     >     summary(gls(opp ~ 1, opposites, correlation =
>     corCompSymm(form = ~ 1 |
>     >     id), weights = varIdent(form = ~ 1 | wave)))
>     >
>     >     # Does not work with lme.
>     >     summary(hetercom <- lme(opp ~ 1,opposites,
>     >                      correlation=corCompSymm(form = ~ 1 |id),
>     >                      weights=varIdent(form = ~1|wave),
>     method="REML"))
>     >
>     >     # But does work with the "one" trick.
>     >     summary(lme(opp ~ 1,opposites,
>     >          random = ~1|one,
>     >          correlation=corCompSymm(form = ~ 1 |one/id),
>     >          weights=varIdent(form = ~1|wave), method="REML"))
>     >
>     >
>     >
>     >     The main reason of my mailing to the list is this. I was
>     wondering
>     >     whether with lme it is possible to also estimate models with the
>     >     individuals nested in higher levels like schools or
>     hospitals etc
>     >     and at
>     >     the same time letting the residuals correlate within
>     individuals over
>     >     time with one of the nice covar structures. However, I do
>     NOT have a
>     >     reproducible example of such more complex models at the
>     moment. I only
>     >     hoped that if the lme version of the model presented above
>     has no
>     >     further problems than a (slightly) different AIC, BIC and std.
>     >     error of
>     >     the fixed intercept, it would be meaningful to proceed in this
>     >     way, i.e.
>     >     using lme instead of gls, since lme provides the important
>     possibility
>     >     of additional random effects in the model.
>     >
>     >     As to Wolfgang's suggestion for heretogeneous CS using:
>     >
>     >     gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id),
>     weights =
>     >     varIdent(form = ~ 1 | timepoint))
>     >
>     >     I didn't find a way to estimate such a model with lme,
>     except for the
>     >     method with the "trick". Using:
>     >
>     >     lme(opp ~ 1,opposites,
>     >                  correlation=corCompSymm(form = ~ 1 |id),
>     >                  weights=varIdent(form = ~1|wave), method="REML")
>     >
>     >     leads to error-message:
>     >
>     >     Error in lme.formula(opp ~ 1, opposites, correlation =
>     >     corCompSymm(form
>     >     = ~1 | : incompatible formulas for groups in 'random' and
>     >     'correlation'
>     >
>     >
>     >     whereas
>     >
>     >     lme(opp ~ 1,opposites,
>     >                  random = ~1|one,
>     >                  correlation=corCompSymm(form = ~ 1 |one/id),
>     >                  weights=varIdent(form = ~1|wave), method="REML")
>     >
>     >     leads to similar results as your gls suggestion.
>     >
>     >
>     >     Best regards, Ben.
>     >
>     >
>     >     On 26-7-2017 14:44, Thierry Onkelinx wrote:
>     >     > Dear Ben,
>     >     >
>     >     > Please be more specific on the kind of model you want to
>     fit. That
>     >     > would lead to a more relevant discussion that your potential
>     >     misuse of
>     >     > lme. A reproducible example is always useful...
>     >     >
>     >     > Best regards,
>     >     >
>     >     >
>     >     > ir. Thierry Onkelinx
>     >     > Instituut voor natuur- en bosonderzoek / Research
>     Institute for
>     >     Nature
>     >     > and Forest
>     >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>     >     Assurance
>     >     > Kliniekstraat 25
>     >     > 1070 Anderlecht
>     >     > Belgium
>     >     >
>     >     > To call in the statistician after the experiment is done
>     may be no
>     >     > more than asking him to perform a post-mortem examination:
>     he may be
>     >     > able to say what the experiment died of. ~ Sir Ronald
>     Aylmer Fisher
>     >     > The plural of anecdote is not data. ~ Roger Brinner
>     >     > The combination of some data and an aching desire for an
>     answer does
>     >     > not ensure that a reasonable answer can be extracted from a
>     >     given body
>     >     > of data. ~ John Tukey
>     >     >
>     >     > 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>:
>     >     >
>     >     >     Dear list,
>     >     >
>     >     >     With longitudinal data, the package nlme offers the
>     >     possibility to
>     >     >     specify particular covariance structures for the
>     residuals.
>     >     In the
>     >     >     examples below I used data from 35 individuals
>     measured at 4
>     >     time
>     >     >     points, so we have 4 observations nested in each of 35
>     >     individuals.
>     >     >     These data are discussed in Singer and Willett, Applied
>     >     Longitudinal
>     >     >     Data Analysis, chapter 7.
>     >     >
>     >     >     In several sources I found that e.g. compound symmetry can
>     >     easily be
>     >     >     obtained with gls from package nlme, by using the
>     correlation
>     >     >     structure
>     >     >     corCompSymm, as in:
>     >     >
>     >     >          comsym <- gls(opp~1,opposites,
>     >     > correlation=corCompSymm(form = ~ 1 |id),
>     >     >     method="REML")
>     >     >
>     >     >     where id is subject-identifier for the individual.
>     With gls
>     >     >     however one
>     >     >     cannot specify random effects, as opposed to lme. To have
>     >     lme estimate
>     >     >     compound symmetry is simple, one would not even need
>     have to
>     >     specify a
>     >     >     particular correlation structure, it would suffice to say
>     >     >     "random=~1|id". However, for more complex covariance
>     >     structures, e.g.
>     >     >     heterogeneous compound symmetry, I was only able to
>     find syntax
>     >     >     for gls,
>     >     >     but not for lme.
>     >     >
>     >     >     Then I thought that tricking lme might be an option by
>     having a
>     >     >     kind of
>     >     >     "fake" random effect. That is, I constructed a variable
>     >     "one" which
>     >     >     takes value 1 for all cases, and let the intercept be
>     random
>     >     >     across "all
>     >     >     one groups". This led to the following lme model:
>     >     >
>     >     >
>     >     >          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>     >     > correlation=corCompSymm(form = ~ 1
>     >     |one/id),
>     >     >     method="REML")
>     >     >
>     >     >     And actually to my surprise, the results of this lme
>     are highly
>     >     >     similar
>     >     >     to those of the gls above.
>     >     >     The output of both is attached below. The loglik's are
>     >     identical, the
>     >     >     AIC and BIC are not, which I can understand, as the
>     lme has
>     >     an extra
>     >     >     variance to be estimated, compared to the gls. Also,
>     the fixed
>     >     >     intercept's standard error is different, the one of
>     the lme
>     >     being
>     >     >     about
>     >     >     twice as large.
>     >     >
>     >     >     I added some independent variables (not shown below)
>     but the
>     >     >     similarities between gls and lme remain, with only the AIC
>     >     and BIC and
>     >     >     the standard error of the fixed intercept being different
>     >     for the two
>     >     >     models.
>     >     >
>     >     >     My question is threefold.
>     >     >     1) Suppose the individuals (say pupils) would be nested in
>     >     >     schools, then
>     >     >     I assume that with lme I could add school as a random
>     >     effect, and
>     >     >     run a
>     >     >     "usual" model, with pupils nested in schools and
>     observations in
>     >     >     pupils,
>     >     >     and then use any of the possible residual covariance
>     structures
>     >     >     for the
>     >     >     observations in pupils. Would you agree with this?
>     (with gls one
>     >     >     cannot
>     >     >     use an additional random effect, like e.g. school)
>     >     >     2) Are the lme results indeed to be trusted when using
>     this
>     >     "fake"
>     >     >     random effect, apart from the differences with gls
>     mentioned?
>     >     >     Could you
>     >     >     imagine a situation where lme with this trick would
>     produce
>     >     wrong
>     >     >     results?
>     >     >     3) I don't understand the variance of the intercept in the
>     >     lme output.
>     >     >     Even when I specify a very simple model: lme(opp ~ 1,
>     random
>     >     = ~1|one,
>     >     >     opposites, method="REML")
>     >     >     lme is able to estimate the intercept variance...but
>     what is
>     >     this
>     >     >     variance estimate expressing?
>     >     >
>     >     >     Thanks a lot for any help!!!
>     >     >
>     >     >     Ben.
>     >     >
>     >     >
>     >     >
>     >     >
>     >     >
>     >     >     *----------------- gls
>     >     >     ---------------------------------------------------
>     >     >
>     >     >      > comsym <- gls(opp~1,opposites,
>     >     > correlation=corCompSymm(form = ~ 1 |id),
>     >     >     method="REML")
>     >     >      > summary(comsym)
>     >     >
>     >     >     Generalized least squares fit by REML
>     >     >     Model: opp ~ 1
>     >     >     Data: opposites
>     >     >           AIC      BIC    logLik
>     >     >     1460.954 1469.757 -727.4769
>     >     >
>     >     >     Correlation Structure: Compound symmetry
>     >     >     Formula: ~1 | id
>     >     >     Parameter estimate(s):
>     >     >        Rho
>     >     >     0.2757052
>     >     >
>     >     >     Coefficients:
>     >     >                     Value Std.Error t-value p-value
>     >     >     (Intercept) 204.8143  5.341965 38.34063       0
>     >     >
>     >     >     Standardized residuals:
>     >     >        Min          Q1         Med   Q3  Max
>     >     >     -2.75474868 -0.71244027  0.00397158 0.56533908 2.24944156
>     >     >
>     >     >     Residual standard error: 46.76081
>     >     >     Degrees of freedom: 140 total; 139 residual
>     >     >
>     >     >
>     >     >     #------------------ lme
>     >     >     ---------------------------------------------------
>     >     >
>     >     >      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
>     >     > correlation=corCompSymm(form = ~ 1 |one/id),
>     >     >     method="REML")
>     >     >      > summary(comsym.lme)
>     >     >
>     >     >     Linear mixed-effects model fit by REML
>     >     >     Data: opposites
>     >     >           AIC      BIC    logLik
>     >     >     1462.954 1474.692 -727.4769
>     >     >
>     >     >     Random effects:
>     >     >        Formula: ~1 | one
>     >     >              (Intercept) Residual
>     >     >     StdDev:    10.53875 46.76081
>     >     >
>     >     >     Correlation Structure: Compound symmetry
>     >     >     Formula: ~1 | one/id
>     >     >     Parameter estimate(s):
>     >     >        Rho
>     >     >     0.2757052
>     >     >     Fixed effects: opp ~ 1
>     >     >                     Value Std.Error  DF t-value p-value
>     >     >     (Intercept) 204.8143  11.81532 139 17.33463       0
>     >     >
>     >     >     Standardized Within-Group Residuals:
>     >     >        Min          Q1         Med   Q3  Max
>     >     >     -2.75474868 -0.71244027  0.00397158 0.56533908 2.24944156
>     >     >
>     >     >     Number of Observations: 140
>     >     >     Number of Groups: 1
>     >     >
>     >     >
>     >     >             [[alternative HTML version deleted]]
>     >     >
>     >     >     _______________________________________________
>     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >
>     >     >
>     >
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Jul 28 11:45:51 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 28 Jul 2017 11:45:51 +0200
Subject: [R-sig-ME] using lme for cov structures?
In-Reply-To: <bdb2b62a-9816-4ad3-45a2-9b6ac42dca87@maw.ru.nl>
References: <e88bbb5d-bd34-fbd8-14b6-4dcac489868e@maw.ru.nl>
 <CAJuCY5wRe59rSFOp6FAEkxpuWENz5bF7kpNmHNJWKtwk_jURXg@mail.gmail.com>
 <57d103b3-1d25-2823-2f34-615e08107a7c@maw.ru.nl>
 <CAJuCY5xp4H3_EmsPL8gMYKQwJq673ZCW1kMkEzQJcBCntBxgyQ@mail.gmail.com>
 <eba39df9-d98e-aea2-2841-f171465d51c4@maw.ru.nl>
 <CAJuCY5wwaZ0Su1+j7udSWrpV9Py4e9nL2HPYAB_ktTfvdCq4jg@mail.gmail.com>
 <bdb2b62a-9816-4ad3-45a2-9b6ac42dca87@maw.ru.nl>
Message-ID: <CAJuCY5zDk9aRz5At1uwY4b=n0EN6p2KgL4w_pfPSmbVbuaZtWQ@mail.gmail.com>

Dear Ben,

The syntax of the matrix is LaTeX. You can use is to render math in
RMarkdown files. E.g.
https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html#equations

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-07-28 10:51 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:

> Dear Thierry,
>
> After all effort and thinking about the trick with the "one" variable, I
> realised (but only after your previous mail with the syntax for the
> "group" variable) that I do not need the trick at all. With a
> grouping/context variable, lme can be used and without such
> grouping/context, gls will do. Why didn't I realize this earlier???
>
> As to your last mail, the syntax you included looks very intriguing,
> which language did you use to evaluate the cov matrix?
>
> Best regards, Ben.
>
> On 27-7-2017 15:13, Thierry Onkelinx wrote:
> > Dear Ben,
> >
> > I would look at the variance-covariance matrix of the model. Below is
> > the var-covar matrix for the model lme(opp ~ 1, random = ~1|id,
> > correlation=corCompSymm(form = ~ wave), weights=varIdent(form =
> > ~1|wave)). I worked it out for 3 id groups with each 3 waves. The
> > submatrices indicate the grouping by the random effect.
> >
> > Is this the structure you are looking for? If not please provide the
> > required structure.
> >
> > Having a random effect with only one level is nonsense. IMHO it should
> > yield an error, or at least a warning. I have no idea how lme
> > estimates the reported variance.
> >
> > Best regards,
> >
> > Thierry
> >
> > $\sigma^2_i$: random effect variance
> > $\sigma^2_e$: variance of the noise
> > $\rho$: correlation of the compound symmetry
> > $w_2$ and $w_3$: relative variance of the 2nd and 3th wave compared to
> > the 1st wave
> >
> > $$
> > \begin{pmatrix}
> >   \begin{bmatrix}
> >     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
> > \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
> >   \end{bmatrix} &
> >   \begin{bmatrix}
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i
> >   \end{bmatrix} &
> >   \begin{bmatrix}
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i
> >   \end{bmatrix}
> >   \\
> >   \begin{bmatrix}
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i
> >   \end{bmatrix} &
> >   \begin{bmatrix}
> >     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
> > \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
> >   \end{bmatrix} \\
> >     \begin{bmatrix}
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i
> >   \end{bmatrix} &
> >   \begin{bmatrix}
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i\\
> >     \sigma^2_i & \sigma^2_i & \sigma^2_i
> >   \end{bmatrix} &
> >   \begin{bmatrix}
> >     \sigma^2_i+\sigma^2_e & \sqrt{w_2}\sigma^2_i+\rho\sigma^2_e &
> > \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_2}\rho\sigma^2_e & w_2\sigma^2_i+\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+\rho\sigma^2_e \\
> >     \sigma^2_i+\sqrt{w_3}\rho\sigma^2_e &
> > \sqrt{w_2w_3}\sigma^2_i+w_3\rho\sigma^2_e & \sigma^2_i+\sigma^2_e
> >   \end{bmatrix}
> > \end{pmatrix}
> > $$
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2017-07-27 11:16 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> > <mailto:b.pelzer at maw.ru.nl>>:
> >
> >     Dear Thierry,
> >
> >     Thanks for your help with these models. I wasn't sure how to
> formulate
> >     them. At the department of sciology where I work (Radboud University)
> >     longitudinal data are getting more common bussiness. And very often,
> >     we'd like to estimate random country or municipality influences for
> >     repeated measures on the same person. This is not a big problem as
> >     long
> >     as we use growth modelling with random intercept and random time
> >     influence, but the covariance structure implied by such models is,
> >     say,
> >     limited. Knowing how to specify the cov. structures in R is really
> >     helpful and broadens prespective.
> >
> >     After fiddling around with all the possibilities, the picture is
> >     slowly
> >     getting clearer here. I was puzzled by the heterogeneous compound
> >     symmetry structure and how to specify this. With specification:
> >
> >     heteroCS1 <- lme(opp ~ 1,opposites,
> >          random = ~1|id,
> >          correlation=corCompSymm(form = ~ wave),
> >          weights=varIdent(form = ~1|wave), method="REML")
> >
> >     the random person effect is estimated apart from the residuals. On
> the
> >     other hand, with:
> >
> >     heteroCS2 <- lme(opp ~ 1,opposites,
> >          random = ~1|one,
> >          correlation=corCompSymm(form = ~wave | one/id),
> >          weights=varIdent(form = ~1|wave), method="REML"))
> >
> >     the random person effect is kept part of the residuals, because it is
> >     not estimated explicitly. As a result, heteroCS2 gives the same
> >     results
> >     as obtained with the more straightforward gls specification:
> >
> >     hetroCS3 <- gls(opp ~ 1, opposites,
> >          correlation = corCompSymm(form = ~ wave|id),
> >          weights = varIdent(form = ~ 1 | wave))
> >
> >     In general, I think I would prefer to have the random person effect
> as
> >     part the residual term instead of seperating it from the residual.
> >     That
> >     is, by cutting the random person effect away from the residual, you
> >     remove the very part that causes correlation between the observations
> >     over time. The only specification (I could think of) that keeps the
> >     random person effect IN the residual is heteroCS2. But maybe
> something
> >     less artificial can be found....
> >
> >     And the strange thing that remains is: how can lme estimate a random
> >     effect variance in case of one single group, as in:
> >
> >     strangemodel <- lme(opp ~1, random = ~1|one, opposites)
> >
> >     which produces the summary:
> >
> >     Linear mixed-effects model fit by REML
> >       Data: opposites
> >           AIC      BIC    logLik
> >        1473.5 1482.303 -733.7498
> >
> >     Random effects:
> >       Formula: ~1 | one
> >              (Intercept) Residual
> >     StdDev:    10.50729 46.62148
> >
> >     Fixed effects: opp ~ 1
> >                     Value Std.Error  DF  t-value p-value
> >     (Intercept) 204.8143  11.22179 139 18.25148       0
> >
> >
> >     Do you have any thoughts about this strange model's estimate of the
> >     intercept variance 10.50729?
> >
> >     Best regards, Ben.
> >
> >
> >     On 26-7-2017 22:05, Thierry Onkelinx wrote:
> >     > Dear Ben,
> >     >
> >     > The correlation structure always works at the most detailed level
> of
> >     > the random effects. E.g. at the id level in the example below,
> >     not at
> >     > the group level. The correlation is only effective among
> >     observations
> >     > from the same id. Two observation within the same group but
> >     different
> >     > id have uncorrelated residuals by definition. Likewise are two
> >     > residuals from different groups uncorrelated. The correlation
> matrix
> >     > of the residuals is hence always a block diagonal matrix, with
> >     blocks
> >     > defined by the most detailed level of the random effects.
> >     >
> >     > opposites <-
> >     >
> >     read.table("https://stats.idre.ucla.edu/stat/r/examples/
> alda/data/opposites_pp.txt
> >     <https://stats.idre.ucla.edu/stat/r/examples/alda/data/
> opposites_pp.txt>",header=TRUE,sep=",")
> >     > opposites$group <- opposites$id %% 6
> >     > library(nlme)
> >     > lme(opp ~ 1, random = ~1|group/id, data = opposites)
> >     > lme(opp ~ 1, random = ~1|group/id, data = opposites, correlation =
> >     > corAR1(form = ~wave))
> >     >
> >     > Best regards,
> >     >
> >     >
> >     > ir. Thierry Onkelinx
> >     > Instituut voor natuur- en bosonderzoek / Research Institute for
> >     Nature
> >     > and Forest
> >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> >     Assurance
> >     > Kliniekstraat 25
> >     > 1070 Anderlecht
> >     > Belgium
> >     >
> >     > To call in the statistician after the experiment is done may be no
> >     > more than asking him to perform a post-mortem examination: he may
> be
> >     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >     > The plural of anecdote is not data. ~ Roger Brinner
> >     > The combination of some data and an aching desire for an answer
> does
> >     > not ensure that a reasonable answer can be extracted from a
> >     given body
> >     > of data. ~ John Tukey
> >     >
> >     > 2017-07-26 21:45 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>:
> >     >
> >     >     Dear Thierry and Wolfgang,
> >     >
> >     >     Thanks for responding so quickly. Here is the reproducible
> >     example of
> >     >     the two models that I'm interested in.
> >     >
> >     >     # Read data.
> >     >     opposites <-
> >     >
> >      read.table("https://stats.idre.ucla.edu/stat/r/examples/
> alda/dat/opposites_pp.txt
> >     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/
> opposites_pp.txt>
> >     >
> >      <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/
> opposites_pp.txt
> >     <https://stats.idre.ucla.edu/stat/r/examples/alda/dat/
> opposites_pp.txt>>",header=TRUE,sep=",")
> >     >
> >     >     # Open library.
> >     >     library(nlme)
> >     >
> >     >     # Define group "one" with value 1 for all cases.
> >     >     one <- rep(1, 140)
> >     >
> >     >     #----- Model estimated with gls.
> >     >     comsym.gls <- gls(opp~1,opposites,
> >     >                        correlation=corCompSymm(form = ~ 1 |id),
> >     >     method="REML")
> >     >     summary(comsym.gls)
> >     >
> >     >
> >     >     #----- Same model estimated with lme.
> >     >     comsym.lme <- lme(opp~1,opposites,
> >     >                        random= ~1|one,
> >     >                        correlation=corCompSymm(form = ~ 1 |one/id),
> >     >     method="REML")
> >     >     summary(comsym.lme)
> >     >
> >     >
> >     >     #----- Wolfgang's gls suggestion for heterogeneous CS.
> >     >
> >     >     summary(gls(opp ~ 1, opposites, correlation =
> >     corCompSymm(form = ~ 1 |
> >     >     id), weights = varIdent(form = ~ 1 | wave)))
> >     >
> >     >     # Does not work with lme.
> >     >     summary(hetercom <- lme(opp ~ 1,opposites,
> >     >                      correlation=corCompSymm(form = ~ 1 |id),
> >     >                      weights=varIdent(form = ~1|wave),
> >     method="REML"))
> >     >
> >     >     # But does work with the "one" trick.
> >     >     summary(lme(opp ~ 1,opposites,
> >     >          random = ~1|one,
> >     >          correlation=corCompSymm(form = ~ 1 |one/id),
> >     >          weights=varIdent(form = ~1|wave), method="REML"))
> >     >
> >     >
> >     >
> >     >     The main reason of my mailing to the list is this. I was
> >     wondering
> >     >     whether with lme it is possible to also estimate models with
> the
> >     >     individuals nested in higher levels like schools or
> >     hospitals etc
> >     >     and at
> >     >     the same time letting the residuals correlate within
> >     individuals over
> >     >     time with one of the nice covar structures. However, I do
> >     NOT have a
> >     >     reproducible example of such more complex models at the
> >     moment. I only
> >     >     hoped that if the lme version of the model presented above
> >     has no
> >     >     further problems than a (slightly) different AIC, BIC and std.
> >     >     error of
> >     >     the fixed intercept, it would be meaningful to proceed in this
> >     >     way, i.e.
> >     >     using lme instead of gls, since lme provides the important
> >     possibility
> >     >     of additional random effects in the model.
> >     >
> >     >     As to Wolfgang's suggestion for heretogeneous CS using:
> >     >
> >     >     gls(opp ~ 1, correlation = corCompSymm(form = ~ 1 | id),
> >     weights =
> >     >     varIdent(form = ~ 1 | timepoint))
> >     >
> >     >     I didn't find a way to estimate such a model with lme,
> >     except for the
> >     >     method with the "trick". Using:
> >     >
> >     >     lme(opp ~ 1,opposites,
> >     >                  correlation=corCompSymm(form = ~ 1 |id),
> >     >                  weights=varIdent(form = ~1|wave), method="REML")
> >     >
> >     >     leads to error-message:
> >     >
> >     >     Error in lme.formula(opp ~ 1, opposites, correlation =
> >     >     corCompSymm(form
> >     >     = ~1 | : incompatible formulas for groups in 'random' and
> >     >     'correlation'
> >     >
> >     >
> >     >     whereas
> >     >
> >     >     lme(opp ~ 1,opposites,
> >     >                  random = ~1|one,
> >     >                  correlation=corCompSymm(form = ~ 1 |one/id),
> >     >                  weights=varIdent(form = ~1|wave), method="REML")
> >     >
> >     >     leads to similar results as your gls suggestion.
> >     >
> >     >
> >     >     Best regards, Ben.
> >     >
> >     >
> >     >     On 26-7-2017 14:44, Thierry Onkelinx wrote:
> >     >     > Dear Ben,
> >     >     >
> >     >     > Please be more specific on the kind of model you want to
> >     fit. That
> >     >     > would lead to a more relevant discussion that your potential
> >     >     misuse of
> >     >     > lme. A reproducible example is always useful...
> >     >     >
> >     >     > Best regards,
> >     >     >
> >     >     >
> >     >     > ir. Thierry Onkelinx
> >     >     > Instituut voor natuur- en bosonderzoek / Research
> >     Institute for
> >     >     Nature
> >     >     > and Forest
> >     >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> >     >     Assurance
> >     >     > Kliniekstraat 25
> >     >     > 1070 Anderlecht
> >     >     > Belgium
> >     >     >
> >     >     > To call in the statistician after the experiment is done
> >     may be no
> >     >     > more than asking him to perform a post-mortem examination:
> >     he may be
> >     >     > able to say what the experiment died of. ~ Sir Ronald
> >     Aylmer Fisher
> >     >     > The plural of anecdote is not data. ~ Roger Brinner
> >     >     > The combination of some data and an aching desire for an
> >     answer does
> >     >     > not ensure that a reasonable answer can be extracted from a
> >     >     given body
> >     >     > of data. ~ John Tukey
> >     >     >
> >     >     > 2017-07-26 13:36 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>:
> >     >     >
> >     >     >     Dear list,
> >     >     >
> >     >     >     With longitudinal data, the package nlme offers the
> >     >     possibility to
> >     >     >     specify particular covariance structures for the
> >     residuals.
> >     >     In the
> >     >     >     examples below I used data from 35 individuals
> >     measured at 4
> >     >     time
> >     >     >     points, so we have 4 observations nested in each of 35
> >     >     individuals.
> >     >     >     These data are discussed in Singer and Willett, Applied
> >     >     Longitudinal
> >     >     >     Data Analysis, chapter 7.
> >     >     >
> >     >     >     In several sources I found that e.g. compound symmetry
> can
> >     >     easily be
> >     >     >     obtained with gls from package nlme, by using the
> >     correlation
> >     >     >     structure
> >     >     >     corCompSymm, as in:
> >     >     >
> >     >     >          comsym <- gls(opp~1,opposites,
> >     >     > correlation=corCompSymm(form = ~ 1 |id),
> >     >     >     method="REML")
> >     >     >
> >     >     >     where id is subject-identifier for the individual.
> >     With gls
> >     >     >     however one
> >     >     >     cannot specify random effects, as opposed to lme. To have
> >     >     lme estimate
> >     >     >     compound symmetry is simple, one would not even need
> >     have to
> >     >     specify a
> >     >     >     particular correlation structure, it would suffice to say
> >     >     >     "random=~1|id". However, for more complex covariance
> >     >     structures, e.g.
> >     >     >     heterogeneous compound symmetry, I was only able to
> >     find syntax
> >     >     >     for gls,
> >     >     >     but not for lme.
> >     >     >
> >     >     >     Then I thought that tricking lme might be an option by
> >     having a
> >     >     >     kind of
> >     >     >     "fake" random effect. That is, I constructed a variable
> >     >     "one" which
> >     >     >     takes value 1 for all cases, and let the intercept be
> >     random
> >     >     >     across "all
> >     >     >     one groups". This led to the following lme model:
> >     >     >
> >     >     >
> >     >     >          comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >     >     > correlation=corCompSymm(form = ~ 1
> >     >     |one/id),
> >     >     >     method="REML")
> >     >     >
> >     >     >     And actually to my surprise, the results of this lme
> >     are highly
> >     >     >     similar
> >     >     >     to those of the gls above.
> >     >     >     The output of both is attached below. The loglik's are
> >     >     identical, the
> >     >     >     AIC and BIC are not, which I can understand, as the
> >     lme has
> >     >     an extra
> >     >     >     variance to be estimated, compared to the gls. Also,
> >     the fixed
> >     >     >     intercept's standard error is different, the one of
> >     the lme
> >     >     being
> >     >     >     about
> >     >     >     twice as large.
> >     >     >
> >     >     >     I added some independent variables (not shown below)
> >     but the
> >     >     >     similarities between gls and lme remain, with only the
> AIC
> >     >     and BIC and
> >     >     >     the standard error of the fixed intercept being different
> >     >     for the two
> >     >     >     models.
> >     >     >
> >     >     >     My question is threefold.
> >     >     >     1) Suppose the individuals (say pupils) would be nested
> in
> >     >     >     schools, then
> >     >     >     I assume that with lme I could add school as a random
> >     >     effect, and
> >     >     >     run a
> >     >     >     "usual" model, with pupils nested in schools and
> >     observations in
> >     >     >     pupils,
> >     >     >     and then use any of the possible residual covariance
> >     structures
> >     >     >     for the
> >     >     >     observations in pupils. Would you agree with this?
> >     (with gls one
> >     >     >     cannot
> >     >     >     use an additional random effect, like e.g. school)
> >     >     >     2) Are the lme results indeed to be trusted when using
> >     this
> >     >     "fake"
> >     >     >     random effect, apart from the differences with gls
> >     mentioned?
> >     >     >     Could you
> >     >     >     imagine a situation where lme with this trick would
> >     produce
> >     >     wrong
> >     >     >     results?
> >     >     >     3) I don't understand the variance of the intercept in
> the
> >     >     lme output.
> >     >     >     Even when I specify a very simple model: lme(opp ~ 1,
> >     random
> >     >     = ~1|one,
> >     >     >     opposites, method="REML")
> >     >     >     lme is able to estimate the intercept variance...but
> >     what is
> >     >     this
> >     >     >     variance estimate expressing?
> >     >     >
> >     >     >     Thanks a lot for any help!!!
> >     >     >
> >     >     >     Ben.
> >     >     >
> >     >     >
> >     >     >
> >     >     >
> >     >     >
> >     >     >     *----------------- gls
> >     >     >     ---------------------------------------------------
> >     >     >
> >     >     >      > comsym <- gls(opp~1,opposites,
> >     >     > correlation=corCompSymm(form = ~ 1 |id),
> >     >     >     method="REML")
> >     >     >      > summary(comsym)
> >     >     >
> >     >     >     Generalized least squares fit by REML
> >     >     >     Model: opp ~ 1
> >     >     >     Data: opposites
> >     >     >           AIC      BIC    logLik
> >     >     >     1460.954 1469.757 -727.4769
> >     >     >
> >     >     >     Correlation Structure: Compound symmetry
> >     >     >     Formula: ~1 | id
> >     >     >     Parameter estimate(s):
> >     >     >        Rho
> >     >     >     0.2757052
> >     >     >
> >     >     >     Coefficients:
> >     >     >                     Value Std.Error t-value p-value
> >     >     >     (Intercept) 204.8143  5.341965 38.34063       0
> >     >     >
> >     >     >     Standardized residuals:
> >     >     >        Min          Q1         Med   Q3  Max
> >     >     >     -2.75474868 -0.71244027  0.00397158 0.56533908 2.24944156
> >     >     >
> >     >     >     Residual standard error: 46.76081
> >     >     >     Degrees of freedom: 140 total; 139 residual
> >     >     >
> >     >     >
> >     >     >     #------------------ lme
> >     >     >     ---------------------------------------------------
> >     >     >
> >     >     >      > comsym.lme <- lme(opp~1,opposites, random= ~1|one,
> >     >     > correlation=corCompSymm(form = ~ 1 |one/id),
> >     >     >     method="REML")
> >     >     >      > summary(comsym.lme)
> >     >     >
> >     >     >     Linear mixed-effects model fit by REML
> >     >     >     Data: opposites
> >     >     >           AIC      BIC    logLik
> >     >     >     1462.954 1474.692 -727.4769
> >     >     >
> >     >     >     Random effects:
> >     >     >        Formula: ~1 | one
> >     >     >              (Intercept) Residual
> >     >     >     StdDev:    10.53875 46.76081
> >     >     >
> >     >     >     Correlation Structure: Compound symmetry
> >     >     >     Formula: ~1 | one/id
> >     >     >     Parameter estimate(s):
> >     >     >        Rho
> >     >     >     0.2757052
> >     >     >     Fixed effects: opp ~ 1
> >     >     >                     Value Std.Error  DF t-value p-value
> >     >     >     (Intercept) 204.8143  11.81532 139 17.33463       0
> >     >     >
> >     >     >     Standardized Within-Group Residuals:
> >     >     >        Min          Q1         Med   Q3  Max
> >     >     >     -2.75474868 -0.71244027  0.00397158 0.56533908 2.24944156
> >     >     >
> >     >     >     Number of Observations: 140
> >     >     >     Number of Groups: 1
> >     >     >
> >     >     >
> >     >     >             [[alternative HTML version deleted]]
> >     >     >
> >     >     >     _______________________________________________
> >     >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >
> >     >     >
> >     >
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >
> >     >
> >
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From javiermoreira at gmail.com  Wed Aug  2 03:43:30 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Tue, 1 Aug 2017 22:43:30 -0300
Subject: [R-sig-ME] spatial correlation with nlme
Message-ID: <CAEyHP-0=TXAbK-fpFH=otmJ0Tzkk_yJ_86K6-8L5MbxtbLQovw@mail.gmail.com>

hi,
im trying to generate different models to account for spatial correlation.
Im using nlme package, and mixed models, in order to compare two models,
one that doesnt include the spatial correlation and one that does.

Its a nested design, one that has 4 leves,
BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
Its a harvest set data, with multiple point of data/ treatment, so the last
level account for another term in the error for "sub-muestreo".

My first problem its, when i try to add de correlation term to the model, i
cant, when the random effects are taken to the level /SUBMUESTREO, and i
have to leave it to the level of TRATAMIENTO.
When i do that, i have 2 differences between models, the term accounting
for sub-muestreo, and the spatial correlation.

#MODELO 2##
attach(base_modelo3)
str(base_modelo3)
data1=base_modelo3
str(data1)
data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
data=data1, units=list(y="(ton/ha)"))
data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
data1$BLOQUE =factor(data1$BLOQUE)
data1$AMBIENTE =factor(data1$AMBIENTE)

modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
                random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
                weights=varComb(varIdent(form=~1|TRATAMIENTO)),
                data=data1,
                control=lmeControl(niterEM=150,msMaxIter=200))
summary(modelo2_MM)
anova(modelo2_MM)

##MODELO 4##

modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
                random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
                weights=varComb(varIdent(form=~1|TRATAMIENTO)),
                correlation=corExp(form=~X+Y,nugget=T),
                data=data1,
                control=lmeControl(niterEM=150,msMaxIter=200))
summary(modelo4_MM)
anova(modelo4_MM)

Sorry, the error is

Error in corFactor.corSpatial(object) :
  NA/NaN/Inf in foreign function call (arg 1)
In addition: Warning messages:
1: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf
2: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf

?
My second problem is, that i need to get the specific parameter for the
error term that belongs to the spatial correlation, in order to map it. For
what i watch, what lme does is send it to the general error, and so, what i
could do is make the differences between the residuals of these two models.
so, its essetial to get the exact same model, except for the correlation
structure.
If anybody knows how to get the specific term of error accounting for the
correlation, it would be wonderful.

E24=residuals(modelo24_3,type = "response")
E40=residuals(modelo4_MM,type = "response")
EE=E24-E40
post=data.frame(E24,E40,EE,data1$X,data1$Y)

coordinates(post)<-c("data1.X","data1.Y")
coor_post<-coordinates(post)

bubble(post,"E24",main="residuos modelo 2")
bubble(post,"E40",main="residuos modelo 4")
bubble(post,"EE",main="Est.espacial removida por Modelo 4")


here its the data set
?
 base_modelo3.csv
<https://drive.google.com/file/d/0B6YImu-ZATe4bEFKTlAxci1PNW8/view?usp=drive_web>
?
thanks!

-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Aug  2 10:54:55 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 2 Aug 2017 10:54:55 +0200
Subject: [R-sig-ME] spatial correlation with nlme
In-Reply-To: <CAEyHP-0=TXAbK-fpFH=otmJ0Tzkk_yJ_86K6-8L5MbxtbLQovw@mail.gmail.com>
References: <CAEyHP-0=TXAbK-fpFH=otmJ0Tzkk_yJ_86K6-8L5MbxtbLQovw@mail.gmail.com>
Message-ID: <CAJuCY5y0LdnRYdwYxVKzb9pqpQBQ7J5tH+F5N+_+rW_qvTh8Eg@mail.gmail.com>

Dear Javier,

Please don't cross post unless you are asked to or in case your questions
isn't answered after a few days. I've answered in the original thread:
https://stat.ethz.ch/pipermail/r-sig-geo/2017-August/025877.html

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-02 3:43 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:

> hi,
> im trying to generate different models to account for spatial correlation.
> Im using nlme package, and mixed models, in order to compare two models,
> one that doesnt include the spatial correlation and one that does.
>
> Its a nested design, one that has 4 leves,
> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
> Its a harvest set data, with multiple point of data/ treatment, so the last
> level account for another term in the error for "sub-muestreo".
>
> My first problem its, when i try to add de correlation term to the model, i
> cant, when the random effects are taken to the level /SUBMUESTREO, and i
> have to leave it to the level of TRATAMIENTO.
> When i do that, i have 2 differences between models, the term accounting
> for sub-muestreo, and the spatial correlation.
>
> #MODELO 2##
> attach(base_modelo3)
> str(base_modelo3)
> data1=base_modelo3
> str(data1)
> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
> data=data1, units=list(y="(ton/ha)"))
> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
> data1$BLOQUE =factor(data1$BLOQUE)
> data1$AMBIENTE =factor(data1$AMBIENTE)
>
> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo2_MM)
> anova(modelo2_MM)
>
> ##MODELO 4##
>
> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 correlation=corExp(form=~X+Y,nugget=T),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo4_MM)
> anova(modelo4_MM)
>
> Sorry, the error is
>
> Error in corFactor.corSpatial(object) :
>   NA/NaN/Inf in foreign function call (arg 1)
> In addition: Warning messages:
> 1: In min(unlist(attr(object, "covariate"))) :
>   no non-missing arguments to min; returning Inf
> 2: In min(unlist(attr(object, "covariate"))) :
>   no non-missing arguments to min; returning Inf
>
> ?
> My second problem is, that i need to get the specific parameter for the
> error term that belongs to the spatial correlation, in order to map it. For
> what i watch, what lme does is send it to the general error, and so, what i
> could do is make the differences between the residuals of these two models.
> so, its essetial to get the exact same model, except for the correlation
> structure.
> If anybody knows how to get the specific term of error accounting for the
> correlation, it would be wonderful.
>
> E24=residuals(modelo24_3,type = "response")
> E40=residuals(modelo4_MM,type = "response")
> EE=E24-E40
> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>
> coordinates(post)<-c("data1.X","data1.Y")
> coor_post<-coordinates(post)
>
> bubble(post,"E24",main="residuos modelo 2")
> bubble(post,"E40",main="residuos modelo 4")
> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>
>
> here its the data set
> ?
>  base_modelo3.csv
> <https://drive.google.com/file/d/0B6YImu-ZATe4bEFKTlAxci1PNW8/view?usp=
> drive_web>
> ?
> thanks!
>
> --
> Javier Moreira de Souza
> Ingeniero Agr?nomo
> 099 406 006
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Aug  2 15:51:33 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 2 Aug 2017 14:51:33 +0100
Subject: [R-sig-ME] spatial correlation with nlme (Javier Moreira)
In-Reply-To: <mailman.9.1501668001.42523.r-sig-mixed-models@r-project.org>
References: <mailman.9.1501668001.42523.r-sig-mixed-models@r-project.org>
Message-ID: <2315d5c6-b509-cbaf-df7a-0a2b2529e85d@highstat.com>


> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 1 Aug 2017 22:43:30 -0300
> From: Javier Moreira <javiermoreira at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] spatial correlation with nlme
> Message-ID:
> 	<CAEyHP-0=TXAbK-fpFH=otmJ0Tzkk_yJ_86K6-8L5MbxtbLQovw at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> hi,
> im trying to generate different models to account for spatial correlation.
> Im using nlme package, and mixed models, in order to compare two models,
> one that doesnt include the spatial correlation and one that does.

As already indicated by Thierry...try R-INLA.

Alain


> Its a nested design, one that has 4 leves,
> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
> Its a harvest set data, with multiple point of data/ treatment, so the last
> level account for another term in the error for "sub-muestreo".
>
> My first problem its, when i try to add de correlation term to the model, i
> cant, when the random effects are taken to the level /SUBMUESTREO, and i
> have to leave it to the level of TRATAMIENTO.
> When i do that, i have 2 differences between models, the term accounting
> for sub-muestreo, and the spatial correlation.
>
> #MODELO 2##
> attach(base_modelo3)
> str(base_modelo3)
> data1=base_modelo3
> str(data1)
> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
> data=data1, units=list(y="(ton/ha)"))
> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
> data1$BLOQUE =factor(data1$BLOQUE)
> data1$AMBIENTE =factor(data1$AMBIENTE)
>
> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                  random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>                  weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                  data=data1,
>                  control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo2_MM)
> anova(modelo2_MM)
>
> ##MODELO 4##
>
> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                  random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>                  weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                  correlation=corExp(form=~X+Y,nugget=T),
>                  data=data1,
>                  control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo4_MM)
> anova(modelo4_MM)
>

-- 

Dr. Alain F. Zuur



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From javiermoreira at gmail.com  Wed Aug  2 15:55:35 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Wed, 2 Aug 2017 10:55:35 -0300
Subject: [R-sig-ME] spatial correlation with nlme (Javier Moreira)
In-Reply-To: <2315d5c6-b509-cbaf-df7a-0a2b2529e85d@highstat.com>
References: <mailman.9.1501668001.42523.r-sig-mixed-models@r-project.org>
 <2315d5c6-b509-cbaf-df7a-0a2b2529e85d@highstat.com>
Message-ID: <CAEyHP-29cOc-d4XUREPwA=-DyWzV_zZ1UXdRp21oWiWqwOo_vg@mail.gmail.com>

Thanks, i try again in this group because, until yesterday i didnt know
that exist.


El 2 ago. 2017 10:52 a. m., "Highland Statistics Ltd" <highstat at highstat.com>
escribi?:

>
> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 1 Aug 2017 22:43:30 -0300
>> From: Javier Moreira <javiermoreira at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] spatial correlation with nlme
>> Message-ID:
>>         <CAEyHP-0=TXAbK-fpFH=otmJ0Tzkk_yJ_86K6-8L5MbxtbLQovw at mail.gm
>> ail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> hi,
>> im trying to generate different models to account for spatial correlation.
>> Im using nlme package, and mixed models, in order to compare two models,
>> one that doesnt include the spatial correlation and one that does.
>>
>
> As already indicated by Thierry...try R-INLA.
>
> Alain
>
>
> Its a nested design, one that has 4 leves,
>> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
>> Its a harvest set data, with multiple point of data/ treatment, so the
>> last
>> level account for another term in the error for "sub-muestreo".
>>
>> My first problem its, when i try to add de correlation term to the model,
>> i
>> cant, when the random effects are taken to the level /SUBMUESTREO, and i
>> have to leave it to the level of TRATAMIENTO.
>> When i do that, i have 2 differences between models, the term accounting
>> for sub-muestreo, and the spatial correlation.
>>
>> #MODELO 2##
>> attach(base_modelo3)
>> str(base_modelo3)
>> data1=base_modelo3
>> str(data1)
>> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>> data=data1, units=list(y="(ton/ha)"))
>> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
>> data1$BLOQUE =factor(data1$BLOQUE)
>> data1$AMBIENTE =factor(data1$AMBIENTE)
>>
>> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>                  random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>                  weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>                  data=data1,
>>                  control=lmeControl(niterEM=150,msMaxIter=200))
>> summary(modelo2_MM)
>> anova(modelo2_MM)
>>
>> ##MODELO 4##
>>
>> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>                  random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>>                  weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>                  correlation=corExp(form=~X+Y,nugget=T),
>>                  data=data1,
>>                  control=lmeControl(niterEM=150,msMaxIter=200))
>> summary(modelo4_MM)
>> anova(modelo4_MM)
>>
>>
> --
>
> Dr. Alain F. Zuur
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological
> Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:   0044 1358 788177
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karistaeh at gmail.com  Wed Aug  2 19:54:03 2017
From: karistaeh at gmail.com (Karista Hudelson)
Date: Wed, 2 Aug 2017 13:54:03 -0400
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report p
	values?
Message-ID: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>

Hello All,

I am comparing the fit of a mixed model on different time periods of a data
set.  For the first time period I have 113 observations and only one of the
fixed effects is significant.  For the second time period I have 322
observations and all of the fixed effects are significant.  Because n is
important in the calculation of p, I'm not sure how or even if to interpret
the differences in p values for the model terms in the two time periods.
Does anyone have advice on how to compare the fit of the variables in the
mixed model for the two data sets in a way that is less impacted by the
difference in the number of observations?  Or is a difference of 209
observations enough to drive these differences in p values?

Time period 1 output:
Fixed effects:
                  Estimate Std. Error         df t value Pr(>|t|)
(Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
Length            0.024371   0.003536 106.650000   6.892 4.01e-10 ***
Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159


Time period 2 output:
Fixed effects:
                  Estimate Std. Error         df t value Pr(>|t|)
(Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281 **
Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16 ***
Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235 ***
Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929 ***




Thanks in advance for your time and consideration of this question.
Karista

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Aug  3 10:20:04 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 3 Aug 2017 10:20:04 +0200
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report
	p values?
In-Reply-To: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
References: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
Message-ID: <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>

Dear Karista,

Much depends on what you want to compare between the models. The parameter
estimates? The predicted values? The goodness of fit? You 'll need to make
that clear.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-02 19:54 GMT+02:00 Karista Hudelson <karistaeh at gmail.com>:

> Hello All,
>
> I am comparing the fit of a mixed model on different time periods of a data
> set.  For the first time period I have 113 observations and only one of the
> fixed effects is significant.  For the second time period I have 322
> observations and all of the fixed effects are significant.  Because n is
> important in the calculation of p, I'm not sure how or even if to interpret
> the differences in p values for the model terms in the two time periods.
> Does anyone have advice on how to compare the fit of the variables in the
> mixed model for the two data sets in a way that is less impacted by the
> difference in the number of observations?  Or is a difference of 209
> observations enough to drive these differences in p values?
>
> Time period 1 output:
> Fixed effects:
>                   Estimate Std. Error         df t value Pr(>|t|)
> (Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
> Length            0.024371   0.003536 106.650000   6.892 4.01e-10 ***
> Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
> Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
> Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159
>
>
> Time period 2 output:
> Fixed effects:
>                   Estimate Std. Error         df t value Pr(>|t|)
> (Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281 **
> Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16 ***
> Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235 ***
> Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
> Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929 ***
>
>
>
>
> Thanks in advance for your time and consideration of this question.
> Karista
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Thu Aug  3 10:40:39 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 3 Aug 2017 10:40:39 +0200
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report
 p values?
In-Reply-To: <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>
References: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
 <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>
Message-ID: <5982E187.6010901@mpi.nl>

Dear Karista,

as Thierry said, knowing more about the inferences you want to make will
get you better advice here. That said, I do have two suggestions in the
meantime:

1. Don't focus on significance, especially of individual predictors, as
much as estimates and overall model fit / predictive ability. (cf. The
New Statistics, The Difference between Significant and Insignificant is
not itself Significant, Choosing prediction over explanation in
psychology, etc.)

2. Put all your data into one model and include time period as a fixed
effect. Such pooling will generally help all your estimates; moreover,
it gives you a more principled way to compare time periods (both in the
main effect of time period and in its interactions with individual
variables).

Best,
Phillip

On 08/03/2017 10:20 AM, Thierry Onkelinx wrote:
> Dear Karista,
> 
> Much depends on what you want to compare between the models. The parameter
> estimates? The predicted values? The goodness of fit? You 'll need to make
> that clear.
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2017-08-02 19:54 GMT+02:00 Karista Hudelson <karistaeh at gmail.com>:
> 
>> Hello All,
>>
>> I am comparing the fit of a mixed model on different time periods of a data
>> set.  For the first time period I have 113 observations and only one of the
>> fixed effects is significant.  For the second time period I have 322
>> observations and all of the fixed effects are significant.  Because n is
>> important in the calculation of p, I'm not sure how or even if to interpret
>> the differences in p values for the model terms in the two time periods.
>> Does anyone have advice on how to compare the fit of the variables in the
>> mixed model for the two data sets in a way that is less impacted by the
>> difference in the number of observations?  Or is a difference of 209
>> observations enough to drive these differences in p values?
>>
>> Time period 1 output:
>> Fixed effects:
>>                   Estimate Std. Error         df t value Pr(>|t|)
>> (Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
>> Length            0.024371   0.003536 106.650000   6.892 4.01e-10 ***
>> Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
>> Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
>> Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159
>>
>>
>> Time period 2 output:
>> Fixed effects:
>>                   Estimate Std. Error         df t value Pr(>|t|)
>> (Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281 **
>> Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16 ***
>> Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235 ***
>> Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
>> Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929 ***
>>
>>
>>
>>
>> Thanks in advance for your time and consideration of this question.
>> Karista
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b.pelzer at maw.ru.nl  Thu Aug  3 13:43:12 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 3 Aug 2017 13:43:12 +0200
Subject: [R-sig-ME] corAR1 question
Message-ID: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>

Dear list,

In dataframe "opposites" there are data from 35 individuals observed at 
each of 4 consecutive timepoints, leading to 140 cases in total. The 
time variable is called "wave", which takes values  1, 2, 3 and 4 for 
each individual.

With the folowing syntax, I've tried to estimate a model with the corr. 
matrix of the residuals having a AR1 structure:

opposites <- 
read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
library(nlme)

table(opposites$wave)
auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
method="REML")
summary(auto1)
corMatrix(auto1$modelStruct$corStruct)[[5]]

This seems to work fine, and produces as output:

> table(opposites$wave2)
  1  3  5  7
35 35 35 35

> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
method="REML") > summary(auto1)
Generalized least squares fit by REML
   Model: opp ~ 1
   Data: opposites
        AIC      BIC    logLik
   1405.478 1414.282 -699.7392

Correlation Structure: AR(1)
  Formula: ~wave | id
  Parameter estimate(s):
     Phi
0.75515

Coefficients:
                Value Std.Error  t-value p-value
(Intercept) 205.0916  7.153622 28.66962       0

Standardized residuals:
          Min           Q1          Med           Q3          Max
-2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002

Residual standard error: 50.40533
Degrees of freedom: 140 total; 139 residual

> corMatrix(auto1$modelStruct$corStruct)[[5]]
           [,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.7551500 0.5702515 0.4306254
[2,] 0.7551500 1.0000000 0.7551500 0.5702515
[3,] 0.5702515 0.7551500 1.0000000 0.7551500
[4,] 0.4306254 0.5702515 0.7551500 1.0000000


Next, I multiplied the "wave" variable by 2 to try to understand which 
influence this would have on the estimate of phi parameter. This 
resulted in:

> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
  2  4  6  8
35 35 35 35
> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id), 
method="REML") > summary(auto2)
Generalized least squares fit by REML
   Model: opp ~ 1
   Data: opposites
      AIC      BIC    logLik
   1473.5 1482.303 -733.7498

Correlation Structure: ARMA(1,0)
  Formula: ~wave2 | id
  Parameter estimate(s):
Phi1
    0

Coefficients:
                Value Std.Error  t-value p-value
(Intercept) 204.8143  3.940234 51.98023       0

Standardized residuals:
          Min           Q1          Med           Q3          Max
-2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210

Residual standard error: 46.62148
Degrees of freedom: 140 total; 139 residual
> corMatrix(auto2$modelStruct$corStruct)[[5]]
      [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    0    1    0    0
[3,]    0    0    1    0
[4,]    0    0    0    1

My question is about this second output with wave2 as the time 
indicator. I do not see why the Phi1 estimate has now changed to zero, 
as if there would be no residual correlation at all between the time 
points. I must admit that I was not sure which value to expect for phi1.

A related question is about using corAR1 in case the individuals in my 
data would have been observed at different timepoints. E.g. person A at 
day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used 
given such unequally spaced data? Some documents on the internet say 
that in such situation corCAR1 should be used? From Bates and Pinhiero's 
book it seems to me that corCAR1 is applicable in case of continuously 
code time points, like 1.7, 2.5 etc., while for integer coded time the 
corAR1 method can still be used (this apart form the fact that corAR1 
can also give negative phi values in contrast with corCAR1).

Thanks for any help!

Ben Pelzer.

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Aug  3 13:59:17 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 3 Aug 2017 13:59:17 +0200
Subject: [R-sig-ME] corAR1 question
In-Reply-To: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
References: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
Message-ID: <4a140b4b-1922-862c-3d4e-fcf194193f16@maw.ru.nl>

Dear list,

There was a typo in my previous mail, regarding the frequency table of wave2 at the top. Here is my question once again. Sorry!!

Ben.


*--------------------

Dear list,

In dataframe "opposites" there are data from 35 individuals observed at
each of 4 consecutive timepoints, leading to 140 cases in total. The
time variable is called "wave", which takes values  1, 2, 3 and 4 for
each individual.

With the folowing syntax, I've tried to estimate a model with the corr.
matrix of the residuals having a AR1 structure:

opposites <-
read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
library(nlme)

table(opposites$wave)
auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
method="REML")
summary(auto1)
corMatrix(auto1$modelStruct$corStruct)[[5]]

This seems to work fine, and produces as output:

> table(opposites$wave)
   1  3  5  4
35 35 35 35

> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
method="REML") > summary(auto1)
Generalized least squares fit by REML
    Model: opp ~ 1
    Data: opposites
         AIC      BIC    logLik
    1405.478 1414.282 -699.7392

Correlation Structure: AR(1)
   Formula: ~wave | id
   Parameter estimate(s):
      Phi
0.75515

Coefficients:
                 Value Std.Error  t-value p-value
(Intercept) 205.0916  7.153622 28.66962       0

Standardized residuals:
           Min           Q1          Med           Q3          Max
-2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002

Residual standard error: 50.40533
Degrees of freedom: 140 total; 139 residual

> corMatrix(auto1$modelStruct$corStruct)[[5]]
            [,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.7551500 0.5702515 0.4306254
[2,] 0.7551500 1.0000000 0.7551500 0.5702515
[3,] 0.5702515 0.7551500 1.0000000 0.7551500
[4,] 0.4306254 0.5702515 0.7551500 1.0000000


Next, I multiplied the "wave" variable by 2 to try to understand which
influence this would have on the estimate of phi parameter. This
resulted in:

> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
   2  4  6  8
35 35 35 35
> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id), 
method="REML") > summary(auto2)
Generalized least squares fit by REML
    Model: opp ~ 1
    Data: opposites
       AIC      BIC    logLik
    1473.5 1482.303 -733.7498

Correlation Structure: ARMA(1,0)
   Formula: ~wave2 | id
   Parameter estimate(s):
Phi1
     0

Coefficients:
                 Value Std.Error  t-value p-value
(Intercept) 204.8143  3.940234 51.98023       0

Standardized residuals:
           Min           Q1          Med           Q3          Max
-2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210

Residual standard error: 46.62148
Degrees of freedom: 140 total; 139 residual
> corMatrix(auto2$modelStruct$corStruct)[[5]]
       [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    0    1    0    0
[3,]    0    0    1    0
[4,]    0    0    0    1

My question is about this second output with wave2 as the time
indicator. I do not see why the Phi1 estimate has now changed to zero,
as if there would be no residual correlation at all between the time
points. I must admit that I was not sure which value to expect for phi1.

A related question is about using corAR1 in case the individuals in my
data would have been observed at different timepoints. E.g. person A at
day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used
given such unequally spaced data? Some documents on the internet say
that in such situation corCAR1 should be used? From Bates and Pinhiero's
book it seems to me that corCAR1 is applicable in case of continuously
code time points, like 1.7, 2.5 etc., while for integer coded time the
corAR1 method can still be used (this apart form the fact that corAR1
can also give negative phi values in contrast with corCAR1).

Thanks for any help!

Ben Pelzer.


From b.pelzer at maw.ru.nl  Thu Aug  3 14:07:41 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 3 Aug 2017 14:07:41 +0200
Subject: [R-sig-ME] corAR1 question
In-Reply-To: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
References: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
Message-ID: <f41cd892-c66e-f5ca-b68f-f6a256a0741b@maw.ru.nl>

Sorry list, stupid me, again a mistake, I've been working too long I 
guess....
Below, I'll give it a new try....

The frequency table of "wave"  was again incorrect, as it should have 
n=35 for each of its values 1, 2, 3, 4.

Thansk for your patience.

*-----------------------------

Dear list,

In dataframe "opposites" there are data from 35 individuals observed at
each of 4 consecutive timepoints, leading to 140 cases in total. The
time variable is called "wave", which takes values  1, 2, 3 and 4 for
each individual.

With the folowing syntax, I've tried to estimate a model with the corr.
matrix of the residuals having a AR1 structure:

opposites <-
read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
library(nlme)

table(opposites$wave)
auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
method="REML")
summary(auto1)
corMatrix(auto1$modelStruct$corStruct)[[5]]

This seems to work fine, and produces as output:

> table(opposites$wave)
   1  2  3  4
35 35 35 35

> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
method="REML") > summary(auto1)
Generalized least squares fit by REML
    Model: opp ~ 1
    Data: opposites
         AIC      BIC    logLik
    1405.478 1414.282 -699.7392

Correlation Structure: AR(1)
   Formula: ~wave | id
   Parameter estimate(s):
      Phi
0.75515

Coefficients:
                 Value Std.Error  t-value p-value
(Intercept) 205.0916  7.153622 28.66962       0

Standardized residuals:
           Min           Q1          Med           Q3          Max
-2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002

Residual standard error: 50.40533
Degrees of freedom: 140 total; 139 residual

> corMatrix(auto1$modelStruct$corStruct)[[5]]
            [,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.7551500 0.5702515 0.4306254
[2,] 0.7551500 1.0000000 0.7551500 0.5702515
[3,] 0.5702515 0.7551500 1.0000000 0.7551500
[4,] 0.4306254 0.5702515 0.7551500 1.0000000


Next, I multiplied the "wave" variable by 2 to try to understand which
influence this would have on the estimate of phi parameter. This
resulted in:

> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
   2  4  6  8
35 35 35 35

> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id), 
method="REML") > summary(auto2)
Generalized least squares fit by REML
    Model: opp ~ 1
    Data: opposites
       AIC      BIC    logLik
    1473.5 1482.303 -733.7498

Correlation Structure: ARMA(1,0)
   Formula: ~wave2 | id
   Parameter estimate(s):
Phi1
     0

Coefficients:
                 Value Std.Error  t-value p-value
(Intercept) 204.8143  3.940234 51.98023       0

Standardized residuals:
           Min           Q1          Med           Q3          Max
-2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210

Residual standard error: 46.62148
Degrees of freedom: 140 total; 139 residual
> corMatrix(auto2$modelStruct$corStruct)[[5]]
       [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    0    1    0    0
[3,]    0    0    1    0
[4,]    0    0    0    1

My question is about this second output with wave2 as the time
indicator. I do not see why the Phi1 estimate has now changed to zero,
as if there would be no residual correlation at all between the time
points. I must admit that I was not sure which value to expect for phi1.

A related question is about using corAR1 in case the individuals in my
data would have been observed at different timepoints. E.g. person A at
day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used
given such unequally spaced data? Some documents on the internet say
that in such situation corCAR1 should be used? From Bates and Pinhiero's
book it seems to me that corCAR1 is applicable in case of continuously
code time points, like 1.7, 2.5 etc., while for integer coded time the
corAR1 method can still be used (this apart form the fact that corAR1
can also give negative phi values in contrast with corCAR1).

Thanks for any help!

Ben Pelzer.


From javiermoreira at gmail.com  Thu Aug  3 16:24:22 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Thu, 3 Aug 2017 11:24:22 -0300
Subject: [R-sig-ME] specifing "error b" to a split plot design in a GLS model
Message-ID: <CAEyHP-2umVWNy_RCdByKzXrNZSy+EV52fotJy4nQ6ewAyT9TPg@mail.gmail.com>

hi,
i have a split plot design with the bigger plot set as "AMBIENTE", i had
been working with mlm but, in order to campare, im trying a model with no
random effects.
So, in that case, at least en nlme package have to be fit with GLS.

i copy the model,


but, what i need to do is that the sum of squares of AMBIENTE had to be
compare not with the general error, but with the one represented by the
BLOQUE*AMBIENTE interaction.
Can anybody help?

thanks so much for your time.

library(nlme)

attach(BASE_MODELO1_1_1)
str(BASE_MODELO1_1_1)
data2=BASE_MODELO1_1_1

names(data2)=c("ID","BLOQUE","TRATAMIENTO","AMBIENTE","RTO","Ntot","POBLACION","SPAD")

modelo1<-gls(RTO~1+TRATAMIENTO*AMBIENTE+BLOQUE:AMBIENTE,
                  data=data2,
                  method="ML")
summary(modelo1)
anova(modelo1)

?
 BASE_MODELO1_1.1.csv
<https://drive.google.com/file/d/0B6YImu-ZATe4bkRRblRpODFQMXc/view?usp=drive_web>
?
-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Aug  3 19:40:35 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 3 Aug 2017 19:40:35 +0200
Subject: [R-sig-ME] corAR1 question
In-Reply-To: <f41cd892-c66e-f5ca-b68f-f6a256a0741b@maw.ru.nl>
References: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
 <f41cd892-c66e-f5ca-b68f-f6a256a0741b@maw.ru.nl>
Message-ID: <16a895fb-8ca9-215b-42bb-bb414327f409@maw.ru.nl>

Dear list,

After some searching  I think I know which coding of the time covariate 
corAR1 expects ... and where the strange results come from in case a 
coding system like 2, 4, 6, 8 is used.

For anyone interested, here are my findings.

The thing is that in Pinheiro and Bates, it is not very explicitly told 
(and for anywhone familiar with AR1 models, this might not be necessary 
at all...) how the time variable one uses has to coded, in case of corAR1.

Suppose we have 4 time points. Then one would normally code: 1, 2, 3, 4 
(or 1, 2, 4 if a person has a missing for the third time point). One 
could also use 10,11,12,13 as time values, this would lead to exactly 
the same results. Note that adjacent integer values must be used, no 
gaps in between are allowed.

However, with the "wave2" values 2, 4, 6, 8 for each person, there are 
no observations in the data for the intermediate timepoints 3, 5, 7! And 
this probably causes a problem and unexpected results like a different 
loglikelihood and a correlation phi1=0.

My initial idea was that with the time intervals being twice as large 
for "wave2" ("wave2" is coded as 2, 4, 6, 8, whereas  "wave" was coded 
as 1, 2, 3, 4) than for "wave", the only difference between using 
"wave2" and "wave" in

correlation=corAR1(form = ~ wave|id)

versus

correlation=corAR1(form = ~ wave|id)

would be another value for the estimated correlation phi, but that both 
specification would have the same loglikelihood and fixed effects (only 
the intercept in my example). Now this is exactly what is found when 
running:

correlation=corCAR1(form = ~ wave2|id)

With this continuous-time corCAR1 specification, the loglikelihood is 
exactly equal to the one of the corAR1(form = ~wave|id) and what is 
more: the estimated phi value equals the square root of the phi value 
corAR1(form = ~wave|id). And this makes sense! If "wave3" would be coded 
as 3, 6, 9, 12
then corCAR1(form= ~wave3|id) would again lead to the same loglikelihood 
as for corAR1(form=~wave|id) and the phi value now equals the third root 
of the phi in corAR1(form = ~wave|id).

Kind regards,

Ben.




On 3-8-2017 14:07, Ben Pelzer wrote:
> Sorry list, stupid me, again a mistake, I've been working too long I 
> guess....
> Below, I'll give it a new try....
>
> The frequency table of "wave"  was again incorrect, as it should have 
> n=35 for each of its values 1, 2, 3, 4.
>
> Thansk for your patience.
>
> *-----------------------------
>
> Dear list,
>
> In dataframe "opposites" there are data from 35 individuals observed at
> each of 4 consecutive timepoints, leading to 140 cases in total. The
> time variable is called "wave", which takes values  1, 2, 3 and 4 for
> each individual.
>
> With the folowing syntax, I've tried to estimate a model with the corr.
> matrix of the residuals having a AR1 structure:
>
> opposites <-
> read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",") 
>
> library(nlme)
>
> table(opposites$wave)
> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
> method="REML")
> summary(auto1)
> corMatrix(auto1$modelStruct$corStruct)[[5]]
>
> This seems to work fine, and produces as output:
>
>> table(opposites$wave)
>   1  2  3  4
> 35 35 35 35
>
>> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
> method="REML") > summary(auto1)
> Generalized least squares fit by REML
>    Model: opp ~ 1
>    Data: opposites
>         AIC      BIC    logLik
>    1405.478 1414.282 -699.7392
>
> Correlation Structure: AR(1)
>   Formula: ~wave | id
>   Parameter estimate(s):
>      Phi
> 0.75515
>
> Coefficients:
>                 Value Std.Error  t-value p-value
> (Intercept) 205.0916  7.153622 28.66962       0
>
> Standardized residuals:
>           Min           Q1          Med           Q3          Max
> -2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002
>
> Residual standard error: 50.40533
> Degrees of freedom: 140 total; 139 residual
>
>> corMatrix(auto1$modelStruct$corStruct)[[5]]
>            [,1]      [,2]      [,3]      [,4]
> [1,] 1.0000000 0.7551500 0.5702515 0.4306254
> [2,] 0.7551500 1.0000000 0.7551500 0.5702515
> [3,] 0.5702515 0.7551500 1.0000000 0.7551500
> [4,] 0.4306254 0.5702515 0.7551500 1.0000000
>
>
> Next, I multiplied the "wave" variable by 2 to try to understand which
> influence this would have on the estimate of phi parameter. This
> resulted in:
>
>> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
>   2  4  6  8
> 35 35 35 35
>
>> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id), 
> method="REML") > summary(auto2)
> Generalized least squares fit by REML
>    Model: opp ~ 1
>    Data: opposites
>       AIC      BIC    logLik
>    1473.5 1482.303 -733.7498
>
> Correlation Structure: ARMA(1,0)
>   Formula: ~wave2 | id
>   Parameter estimate(s):
> Phi1
>     0
>
> Coefficients:
>                 Value Std.Error  t-value p-value
> (Intercept) 204.8143  3.940234 51.98023       0
>
> Standardized residuals:
>           Min           Q1          Med           Q3          Max
> -2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210
>
> Residual standard error: 46.62148
> Degrees of freedom: 140 total; 139 residual
>> corMatrix(auto2$modelStruct$corStruct)[[5]]
>       [,1] [,2] [,3] [,4]
> [1,]    1    0    0    0
> [2,]    0    1    0    0
> [3,]    0    0    1    0
> [4,]    0    0    0    1
>
> My question is about this second output with wave2 as the time
> indicator. I do not see why the Phi1 estimate has now changed to zero,
> as if there would be no residual correlation at all between the time
> points. I must admit that I was not sure which value to expect for phi1.
>
> A related question is about using corAR1 in case the individuals in my
> data would have been observed at different timepoints. E.g. person A at
> day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used
> given such unequally spaced data? Some documents on the internet say
> that in such situation corCAR1 should be used? From Bates and Pinhiero's
> book it seems to me that corCAR1 is applicable in case of continuously
> code time points, like 1.7, 2.5 etc., while for integer coded time the
> corAR1 method can still be used (this apart form the fact that corAR1
> can also give negative phi values in contrast with corCAR1).
>
> Thanks for any help!
>
> Ben Pelzer.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Aug  3 19:23:27 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 Aug 2017 13:23:27 -0400
Subject: [R-sig-ME] corAR1 question
In-Reply-To: <16a895fb-8ca9-215b-42bb-bb414327f409@maw.ru.nl>
References: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
 <f41cd892-c66e-f5ca-b68f-f6a256a0741b@maw.ru.nl>
 <16a895fb-8ca9-215b-42bb-bb414327f409@maw.ru.nl>
Message-ID: <ec464851-10c1-a386-dfd3-d185d712d954@gmail.com>


  Good point.  If you want to use non-adjacent time points you might try
corCAR1 (continuous-time first-order autoregressive ...)

On 17-08-03 01:40 PM, Ben Pelzer wrote:
> Dear list,
> 
> After some searching  I think I know which coding of the time covariate
> corAR1 expects ... and where the strange results come from in case a
> coding system like 2, 4, 6, 8 is used.
> 
> For anyone interested, here are my findings.
> 
> The thing is that in Pinheiro and Bates, it is not very explicitly told
> (and for anywhone familiar with AR1 models, this might not be necessary
> at all...) how the time variable one uses has to coded, in case of corAR1.
> 
> Suppose we have 4 time points. Then one would normally code: 1, 2, 3, 4
> (or 1, 2, 4 if a person has a missing for the third time point). One
> could also use 10,11,12,13 as time values, this would lead to exactly
> the same results. Note that adjacent integer values must be used, no
> gaps in between are allowed.
> 
> However, with the "wave2" values 2, 4, 6, 8 for each person, there are
> no observations in the data for the intermediate timepoints 3, 5, 7! And
> this probably causes a problem and unexpected results like a different
> loglikelihood and a correlation phi1=0.
> 
> My initial idea was that with the time intervals being twice as large
> for "wave2" ("wave2" is coded as 2, 4, 6, 8, whereas  "wave" was coded
> as 1, 2, 3, 4) than for "wave", the only difference between using
> "wave2" and "wave" in
> 
> correlation=corAR1(form = ~ wave|id)
> 
> versus
> 
> correlation=corAR1(form = ~ wave|id)
> 
> would be another value for the estimated correlation phi, but that both
> specification would have the same loglikelihood and fixed effects (only
> the intercept in my example). Now this is exactly what is found when
> running:
> 
> correlation=corCAR1(form = ~ wave2|id)
> 
> With this continuous-time corCAR1 specification, the loglikelihood is
> exactly equal to the one of the corAR1(form = ~wave|id) and what is
> more: the estimated phi value equals the square root of the phi value
> corAR1(form = ~wave|id). And this makes sense! If "wave3" would be coded
> as 3, 6, 9, 12
> then corCAR1(form= ~wave3|id) would again lead to the same loglikelihood
> as for corAR1(form=~wave|id) and the phi value now equals the third root
> of the phi in corAR1(form = ~wave|id).
> 
> Kind regards,
> 
> Ben.
> 
> 
> 
> 
> On 3-8-2017 14:07, Ben Pelzer wrote:
>> Sorry list, stupid me, again a mistake, I've been working too long I
>> guess....
>> Below, I'll give it a new try....
>>
>> The frequency table of "wave"  was again incorrect, as it should have
>> n=35 for each of its values 1, 2, 3, 4.
>>
>> Thansk for your patience.
>>
>> *-----------------------------
>>
>> Dear list,
>>
>> In dataframe "opposites" there are data from 35 individuals observed at
>> each of 4 consecutive timepoints, leading to 140 cases in total. The
>> time variable is called "wave", which takes values  1, 2, 3 and 4 for
>> each individual.
>>
>> With the folowing syntax, I've tried to estimate a model with the corr.
>> matrix of the residuals having a AR1 structure:
>>
>> opposites <-
>> read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
>>
>> library(nlme)
>>
>> table(opposites$wave)
>> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
>> method="REML")
>> summary(auto1)
>> corMatrix(auto1$modelStruct$corStruct)[[5]]
>>
>> This seems to work fine, and produces as output:
>>
>>> table(opposites$wave)
>>   1  2  3  4
>> 35 35 35 35
>>
>>> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id), 
>> method="REML") > summary(auto1)
>> Generalized least squares fit by REML
>>    Model: opp ~ 1
>>    Data: opposites
>>         AIC      BIC    logLik
>>    1405.478 1414.282 -699.7392
>>
>> Correlation Structure: AR(1)
>>   Formula: ~wave | id
>>   Parameter estimate(s):
>>      Phi
>> 0.75515
>>
>> Coefficients:
>>                 Value Std.Error  t-value p-value
>> (Intercept) 205.0916  7.153622 28.66962       0
>>
>> Standardized residuals:
>>           Min           Q1          Med           Q3          Max
>> -2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002
>>
>> Residual standard error: 50.40533
>> Degrees of freedom: 140 total; 139 residual
>>
>>> corMatrix(auto1$modelStruct$corStruct)[[5]]
>>            [,1]      [,2]      [,3]      [,4]
>> [1,] 1.0000000 0.7551500 0.5702515 0.4306254
>> [2,] 0.7551500 1.0000000 0.7551500 0.5702515
>> [3,] 0.5702515 0.7551500 1.0000000 0.7551500
>> [4,] 0.4306254 0.5702515 0.7551500 1.0000000
>>
>>
>> Next, I multiplied the "wave" variable by 2 to try to understand which
>> influence this would have on the estimate of phi parameter. This
>> resulted in:
>>
>>> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
>>   2  4  6  8
>> 35 35 35 35
>>
>>> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id), 
>> method="REML") > summary(auto2)
>> Generalized least squares fit by REML
>>    Model: opp ~ 1
>>    Data: opposites
>>       AIC      BIC    logLik
>>    1473.5 1482.303 -733.7498
>>
>> Correlation Structure: ARMA(1,0)
>>   Formula: ~wave2 | id
>>   Parameter estimate(s):
>> Phi1
>>     0
>>
>> Coefficients:
>>                 Value Std.Error  t-value p-value
>> (Intercept) 204.8143  3.940234 51.98023       0
>>
>> Standardized residuals:
>>           Min           Q1          Med           Q3          Max
>> -2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210
>>
>> Residual standard error: 46.62148
>> Degrees of freedom: 140 total; 139 residual
>>> corMatrix(auto2$modelStruct$corStruct)[[5]]
>>       [,1] [,2] [,3] [,4]
>> [1,]    1    0    0    0
>> [2,]    0    1    0    0
>> [3,]    0    0    1    0
>> [4,]    0    0    0    1
>>
>> My question is about this second output with wave2 as the time
>> indicator. I do not see why the Phi1 estimate has now changed to zero,
>> as if there would be no residual correlation at all between the time
>> points. I must admit that I was not sure which value to expect for phi1.
>>
>> A related question is about using corAR1 in case the individuals in my
>> data would have been observed at different timepoints. E.g. person A at
>> day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used
>> given such unequally spaced data? Some documents on the internet say
>> that in such situation corCAR1 should be used? From Bates and Pinhiero's
>> book it seems to me that corCAR1 is applicable in case of continuously
>> code time points, like 1.7, 2.5 etc., while for integer coded time the
>> corAR1 method can still be used (this apart form the fact that corAR1
>> can also give negative phi values in contrast with corCAR1).
>>
>> Thanks for any help!
>>
>> Ben Pelzer.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From nicolas.fanin at hotmail.fr  Thu Aug  3 21:05:18 2017
From: nicolas.fanin at hotmail.fr (Nicolas Fanin)
Date: Thu, 3 Aug 2017 19:05:18 +0000
Subject: [R-sig-ME] corAR1 question and df
In-Reply-To: <ec464851-10c1-a386-dfd3-d185d712d954@gmail.com>
References: <4252f5bc-5fa9-6d67-f278-4bc646a1db6a@maw.ru.nl>
 <f41cd892-c66e-f5ca-b68f-f6a256a0741b@maw.ru.nl>
 <16a895fb-8ca9-215b-42bb-bb414327f409@maw.ru.nl>,
 <ec464851-10c1-a386-dfd3-d185d712d954@gmail.com>
Message-ID: <AM4PR05MB3235691D7C146C350AFBF37C8FB10@AM4PR05MB3235.eurprd05.prod.outlook.com>

Hey everyone,


Thank you for your example, this is interesting.

I have a question related to corAR and the inclusion of Time as a fixed factor and its effect on the degree of freedom.


Here is a classic model:

model= lme (VarX ~ Tr*Eco, random = ~1|Subject,  correlation = corAR1 (form=~as.numeric(Time)|Subject))


                    nDF  dDF  F-value p-value
(Intercept)     1  3349  878.7115  <.0001
Tr                    6   149   23.2416  <.0001
Eco                 2    27     0.3317  0.7206
Tr:Eco           12   149    6.1074  <.0001


Denominator DF is of 149 and 27 respectively, and that's OK.

But if I use time as a fixed factor, it seems that it does not consider the autocorrelation structure.


model= lme (VarX ~ Tr*Eco*Time, random = ~1|Subject,  correlation = corAR1 (form=~as.numeric(Time)|Subject))


                     nDF dDF  F-value p-value
(Intercept)          1  3300 966.2113  <.0001
Tr                         6   149  23.3076  <.0001
Eco                       2    27   0.5112  0.6055
Time                    1  3300 584.3890  <.0001
Tr:Eco                  12   149   6.5223  <.0001
Tr:Time               6  3300  17.7468  <.0001
Eco:Time             2  3300  0.3548  0.7013
Tr:Eco:Time       12  3300   3.6850  <.0001


The explanation is likely logic, but I do not know if this is correct even though the results are similar for Tr and Eco.

If you have any idea or thoughts about this topic, I'd be greatful.


And good vacation for the lucky ones.






________________________________
De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de la part de Ben Bolker <bbolker at gmail.com>
Envoy? : jeudi 3 ao?t 2017 19:23
? : r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] corAR1 question


  Good point.  If you want to use non-adjacent time points you might try
corCAR1 (continuous-time first-order autoregressive ...)

On 17-08-03 01:40 PM, Ben Pelzer wrote:
> Dear list,
>
> After some searching  I think I know which coding of the time covariate
> corAR1 expects ... and where the strange results come from in case a
> coding system like 2, 4, 6, 8 is used.
>
> For anyone interested, here are my findings.
>
> The thing is that in Pinheiro and Bates, it is not very explicitly told
> (and for anywhone familiar with AR1 models, this might not be necessary
> at all...) how the time variable one uses has to coded, in case of corAR1.
>
> Suppose we have 4 time points. Then one would normally code: 1, 2, 3, 4
> (or 1, 2, 4 if a person has a missing for the third time point). One
> could also use 10,11,12,13 as time values, this would lead to exactly
> the same results. Note that adjacent integer values must be used, no
> gaps in between are allowed.
>
> However, with the "wave2" values 2, 4, 6, 8 for each person, there are
> no observations in the data for the intermediate timepoints 3, 5, 7! And
> this probably causes a problem and unexpected results like a different
> loglikelihood and a correlation phi1=0.
>
> My initial idea was that with the time intervals being twice as large
> for "wave2" ("wave2" is coded as 2, 4, 6, 8, whereas  "wave" was coded
> as 1, 2, 3, 4) than for "wave", the only difference between using
> "wave2" and "wave" in
>
> correlation=corAR1(form = ~ wave|id)
>
> versus
>
> correlation=corAR1(form = ~ wave|id)
>
> would be another value for the estimated correlation phi, but that both
> specification would have the same loglikelihood and fixed effects (only
> the intercept in my example). Now this is exactly what is found when
> running:
>
> correlation=corCAR1(form = ~ wave2|id)
>
> With this continuous-time corCAR1 specification, the loglikelihood is
> exactly equal to the one of the corAR1(form = ~wave|id) and what is
> more: the estimated phi value equals the square root of the phi value
> corAR1(form = ~wave|id). And this makes sense! If "wave3" would be coded
> as 3, 6, 9, 12
> then corCAR1(form= ~wave3|id) would again lead to the same loglikelihood
> as for corAR1(form=~wave|id) and the phi value now equals the third root
> of the phi in corAR1(form = ~wave|id).
>
> Kind regards,
>
> Ben.
>
>
>
>
> On 3-8-2017 14:07, Ben Pelzer wrote:
>> Sorry list, stupid me, again a mistake, I've been working too long I
>> guess....
>> Below, I'll give it a new try....
>>
>> The frequency table of "wave"  was again incorrect, as it should have
>> n=35 for each of its values 1, 2, 3, 4.
>>
>> Thansk for your patience.
>>
>> *-----------------------------
>>
>> Dear list,
>>
>> In dataframe "opposites" there are data from 35 individuals observed at
>> each of 4 consecutive timepoints, leading to 140 cases in total. The
>> time variable is called "wave", which takes values  1, 2, 3 and 4 for
>> each individual.
>>
>> With the folowing syntax, I've tried to estimate a model with the corr.
>> matrix of the residuals having a AR1 structure:
>>
>> opposites <-
>> read.table("https://stats.idre.ucla.edu/stat/r/examples/alda/data/opposites_pp.txt",header=TRUE,sep=",")
>>
>> library(nlme)
>>
>> table(opposites$wave)
>> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
>> method="REML")
>> summary(auto1)
>> corMatrix(auto1$modelStruct$corStruct)[[5]]
>>
>> This seems to work fine, and produces as output:
>>
>>> table(opposites$wave)
>>   1  2  3  4
>> 35 35 35 35
>>
>>> auto1 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave|id),
>> method="REML") > summary(auto1)
>> Generalized least squares fit by REML
>>    Model: opp ~ 1
>>    Data: opposites
>>         AIC      BIC    logLik
>>    1405.478 1414.282 -699.7392
>>
>> Correlation Structure: AR(1)
>>   Formula: ~wave | id
>>   Parameter estimate(s):
>>      Phi
>> 0.75515
>>
>> Coefficients:
>>                 Value Std.Error  t-value p-value
>> (Intercept) 205.0916  7.153622 28.66962       0
>>
>> Standardized residuals:
>>           Min           Q1          Med           Q3          Max
>> -2.561070599 -0.666429529 -0.001817216  0.518961088  2.081296002
>>
>> Residual standard error: 50.40533
>> Degrees of freedom: 140 total; 139 residual
>>
>>> corMatrix(auto1$modelStruct$corStruct)[[5]]
>>            [,1]      [,2]      [,3]      [,4]
>> [1,] 1.0000000 0.7551500 0.5702515 0.4306254
>> [2,] 0.7551500 1.0000000 0.7551500 0.5702515
>> [3,] 0.5702515 0.7551500 1.0000000 0.7551500
>> [4,] 0.4306254 0.5702515 0.7551500 1.0000000
>>
>>
>> Next, I multiplied the "wave" variable by 2 to try to understand which
>> influence this would have on the estimate of phi parameter. This
>> resulted in:
>>
>>> opposites$wave2 <- 2*opposites$wave > table(opposites$wave2)
>>   2  4  6  8
>> 35 35 35 35
>>
>>> auto2 <- gls(opp~1,opposites, correlation=corAR1(form = ~ wave2|id),
>> method="REML") > summary(auto2)
>> Generalized least squares fit by REML
>>    Model: opp ~ 1
>>    Data: opposites
>>       AIC      BIC    logLik
>>    1473.5 1482.303 -733.7498
>>
>> Correlation Structure: ARMA(1,0)
>>   Formula: ~wave2 | id
>>   Parameter estimate(s):
>> Phi1
>>     0
>>
>> Coefficients:
>>                 Value Std.Error  t-value p-value
>> (Intercept) 204.8143  3.940234 51.98023       0
>>
>> Standardized residuals:
>>           Min           Q1          Med           Q3          Max
>> -2.762981486 -0.714569461  0.003983449  0.567028639  2.256164210
>>
>> Residual standard error: 46.62148
>> Degrees of freedom: 140 total; 139 residual
>>> corMatrix(auto2$modelStruct$corStruct)[[5]]
>>       [,1] [,2] [,3] [,4]
>> [1,]    1    0    0    0
>> [2,]    0    1    0    0
>> [3,]    0    0    1    0
>> [4,]    0    0    0    1
>>
>> My question is about this second output with wave2 as the time
>> indicator. I do not see why the Phi1 estimate has now changed to zero,
>> as if there would be no residual correlation at all between the time
>> points. I must admit that I was not sure which value to expect for phi1.
>>
>> A related question is about using corAR1 in case the individuals in my
>> data would have been observed at different timepoints. E.g. person A at
>> day 1, 2, 3, 4 but person B at day 1 , 4, 5, 8. Can corAR1 still be used
>> given such unequally spaced data? Some documents on the internet say
>> that in such situation corCAR1 should be used? From Bates and Pinhiero's
>> book it seems to me that corCAR1 is applicable in case of continuously
>> code time points, like 1.7, 2.5 etc., while for integer coded time the
>> corAR1 method can still be used (this apart form the fact that corAR1
>> can also give negative phi values in contrast with corCAR1).
>>
[[elided Hotmail spam]]
>>
>> Ben Pelzer.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From joao.santiago at uni-tuebingen.de  Fri Aug  4 08:52:09 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Fri, 04 Aug 2017 08:52:09 +0200
Subject: [R-sig-ME] Residuals look "mirrored" when using lmer with imputed
	data
Message-ID: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>

I'm trying to assess if a treatment had any effect on the levels of a  
hormone. To do this I need to calculate the area under the curve and  
then adjust it for sex (a known confounder) and smoking status (not  
included in the demo data below to keep things simpler).

Here's a dput of the data: https://pastebin.com/VYcQGkwb

There's some missing values, so first step is to impute them using the  
mice package, then calculate AUC and finally fit the model:

library(dplyr)
library(lme4)
library(mice)
library(zoo)

## Impute missing values
dfMids <- mice(df, m = 10, maxit = 15, seed = 2535)
dfImp  <- complete(dfMids)

## Calculate AUC
dfImpAUC <- dfImp %>%
   arrange(sampleNum) %>%
   group_by(ID, treatment) %>%
   mutate(AUC = sum(diff(sampleNum)*rollmean(value,2)))

## Fit model
fit <- lmer(AUC ~ sex * treatment + (1|ID), data = dfImpAUC)

## Plot residuals
plot(fit)  # output: https://imgur.com/a/vfL1R
qqnorm(resid(fit))



I know it's possible to fit a model to each iteration of mids model,  
but then I can't calculate the AUC, which is what I actually need. Any  
ideas why the residuals look like that?

Best
Santiago




-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From Phillip.Alday at mpi.nl  Sat Aug  5 08:41:11 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Sat, 5 Aug 2017 06:41:11 +0000
Subject: [R-sig-ME] Residuals look "mirrored" when using lmer with
 imputed data
In-Reply-To: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>
References: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>
Message-ID: <1501915270.11496.2.camel@mpi.nl>

You're fitting a normal/Gaussian LMM to data bounded on [0, 1]. The
model assumptions about the residuals simply won't hold for bounded,
binomial-like values.?

Why not fit a binomial model to the data and then use fitted(model) to
compute AUC of the entire model??

Phillip ?

On Fri, 2017-08-04 at 08:52 +0200, Jo?o C P Santiago wrote:
> I'm trying to assess if a treatment had any effect on the levels of
> a??
> hormone. To do this I need to calculate the area under the curve
> and??
> then adjust it for sex (a known confounder) and smoking status (not??
> included in the demo data below to keep things simpler).
> 
> Here's a dput of the data: https://pastebin.com/VYcQGkwb
> 
> There's some missing values, so first step is to impute them using
> the??
> mice package, then calculate AUC and finally fit the model:
> 
> library(dplyr)
> library(lme4)
> library(mice)
> library(zoo)
> 
> ## Impute missing values
> dfMids <- mice(df, m = 10, maxit = 15, seed = 2535)
> dfImp??<- complete(dfMids)
> 
> ## Calculate AUC
> dfImpAUC <- dfImp %>%
> ???arrange(sampleNum) %>%
> ???group_by(ID, treatment) %>%
> ???mutate(AUC = sum(diff(sampleNum)*rollmean(value,2)))
> 
> ## Fit model
> fit <- lmer(AUC ~ sex * treatment + (1|ID), data = dfImpAUC)
> 
> ## Plot residuals
> plot(fit)??# output: https://imgur.com/a/vfL1R
> qqnorm(resid(fit))
> 
> 
> 
> I know it's possible to fit a model to each iteration of mids
> model,??
> but then I can't calculate the AUC, which is what I actually need.
> Any??
> ideas why the residuals look like that?
> 
> Best
> Santiago
> 
> 
> 
> 

From Phillip.Alday at mpi.nl  Sun Aug  6 15:00:47 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Sun, 6 Aug 2017 13:00:47 +0000
Subject: [R-sig-ME] Residuals look "mirrored" when using lmer with
 imputed data
In-Reply-To: <1502024353.16729.30.camel@mpi.nl>
References: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>
 <1501915270.11496.2.camel@mpi.nl>
 <20170805175923.Horde.LQ8t_V_kENCEJoCJTq04ziE@webmail.uni-tuebingen.de>
 <1502024353.16729.30.camel@mpi.nl>
Message-ID: <1502024447.16729.32.camel@mpi.nl>

Uh ... part of my problem is the term "AUC". Without some very explicit
note to the contrary, AUC on a stats forum often refers to a cumulative
probability or the Receiver Operating Characteristic (ROC AUC).
Remember, we're doing this in our free time, so I am often quick and
don't read every line of code ....

You're effectively using a rectangular approximation for your integral
and that's something else to be careful with in terms of approximation.
But why impute separately here? You might be able to use a suitable
integral approximation to skip imputation:

>??dfAUC <- subset(df,!is.na(value)) %>% arrange(sampleNum) %>%
group_by(ID, treatment) %>%??mutate(AUC =
sum(diff(sampleNum)*rollmean(value,2)))
> fit2 <- lmer(AUC ~ sex * treatment + (1|ID), data = dfAUC)
> qqnorm(resid(fit2))

yields similarly flat tails on the qqplot. (Okay, maybe don't use the
rectangular approximation without proper imputation; this didn't work
as well as I'd hoped.)

In both cases, the residual plot looks not horrible to me, but the
qqnorm plot suggests some issues with bounding -- those flat tails look
you're running into some minimal/maximal value. At the lower end, the
obvious answer is "zero"; at the upper end, maybe you're hitting the
limits of your measurement device? We see which values actually occur,
both with the imputed data and the implicit-imputation-via-integral-
approximation data:

> xtabs(~AUC,dfImpAUC)
> xtabs(~AUC,dfAUC)

In both cases, we see that the data only take on a relatively small
number of values and indeed there are lots of repetitions at the
bounds.

Phillip

> On Sat, 2017-08-05 at 17:59 +0200, Jo?o C P Santiago wrote:
> > 
> > I'm sorry I may be misunderstanding, but why do you say my data
> > is??
> > bounded between 0 and 1? The data I shared is from multiple??
> > measurements of a blood hormone, which can be 0, but is certainly
> > not??
> > bounded at 1. Next I calculated the AUC i.e. the "total exposure"
> > of??
> > that hormone. X is time and y is the value of the hormone at each
> > time??
> > point. The AUC is also not bounded at 0 and 1.
> > 
> > Am I missing something?
> > 
> > Thanks for your reply!
> > Santiago
> > 
> > 
> > Quoting "Alday, Phillip" <Phillip.Alday at mpi.nl>:
> > 
> > > 
> > > 
> > > You're fitting a normal/Gaussian LMM to data bounded on [0, 1].
> > > The
> > > model assumptions about the residuals simply won't hold for
> > > bounded,
> > > binomial-like values.?
> > > 
> > > Why not fit a binomial model to the data and then use
> > > fitted(model)
> > > to
> > > compute AUC of the entire model??
> > > 
> > > Phillip ?
> > > 
> > > On Fri, 2017-08-04 at 08:52 +0200, Jo?o C P Santiago wrote:
> > > > 
> > > > 
> > > > I'm trying to assess if a treatment had any effect on the
> > > > levels
> > > > of
> > > > a??
> > > > hormone. To do this I need to calculate the area under the
> > > > curve
> > > > and??
> > > > then adjust it for sex (a known confounder) and smoking status
> > > > (not??
> > > > included in the demo data below to keep things simpler).
> > > > 
> > > > Here's a dput of the data: https://pastebin.com/VYcQGkwb
> > > > 
> > > > There's some missing values, so first step is to impute them
> > > > using
> > > > the??
> > > > mice package, then calculate AUC and finally fit the model:
> > > > 
> > > > library(dplyr)
> > > > library(lme4)
> > > > library(mice)
> > > > library(zoo)
> > > > 
> > > > ## Impute missing values
> > > > dfMids <- mice(df, m = 10, maxit = 15, seed = 2535)
> > > > dfImp??<- complete(dfMids)
> > > > 
> > > > ## Calculate AUC
> > > > dfImpAUC <- dfImp %>%
> > > > ???arrange(sampleNum) %>%
> > > > ???group_by(ID, treatment) %>%
> > > > ???mutate(AUC = sum(diff(sampleNum)*rollmean(value,2)))
> > > > 
> > > > ## Fit model
> > > > fit <- lmer(AUC ~ sex * treatment + (1|ID), data = dfImpAUC)
> > > > 
> > > > ## Plot residuals
> > > > plot(fit)??# output: https://imgur.com/a/vfL1R
> > > > qqnorm(resid(fit))
> > > > 
> > > > 
> > > > 
> > > > I know it's possible to fit a model to each iteration of mids
> > > > model,??
> > > > but then I can't calculate the AUC, which is what I actually
> > > > need.
> > > > Any??
> > > > ideas why the residuals look like that?
> > > > 
> > > > Best
> > > > Santiago
> > > > 
> > > > 
> > > > 
> > > > 

From joao.santiago at uni-tuebingen.de  Sat Aug  5 17:59:23 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Sat, 05 Aug 2017 17:59:23 +0200
Subject: [R-sig-ME] Residuals look "mirrored" when using lmer with
 imputed data
In-Reply-To: <1501915270.11496.2.camel@mpi.nl>
References: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>
 <1501915270.11496.2.camel@mpi.nl>
Message-ID: <20170805175923.Horde.LQ8t_V_kENCEJoCJTq04ziE@webmail.uni-tuebingen.de>

I'm sorry I may be misunderstanding, but why do you say my data is  
bounded between 0 and 1? The data I shared is from multiple  
measurements of a blood hormone, which can be 0, but is certainly not  
bounded at 1. Next I calculated the AUC i.e. the "total exposure" of  
that hormone. X is time and y is the value of the hormone at each time  
point. The AUC is also not bounded at 0 and 1.

Am I missing something?

Thanks for your reply!
Santiago


Quoting "Alday, Phillip" <Phillip.Alday at mpi.nl>:

> You're fitting a normal/Gaussian LMM to data bounded on [0, 1]. The
> model assumptions about the residuals simply won't hold for bounded,
> binomial-like values.?
>
> Why not fit a binomial model to the data and then use fitted(model) to
> compute AUC of the entire model??
>
> Phillip ?
>
> On Fri, 2017-08-04 at 08:52 +0200, Jo?o C P Santiago wrote:
>> I'm trying to assess if a treatment had any effect on the levels of
>> a??
>> hormone. To do this I need to calculate the area under the curve
>> and??
>> then adjust it for sex (a known confounder) and smoking status (not??
>> included in the demo data below to keep things simpler).
>>
>> Here's a dput of the data: https://pastebin.com/VYcQGkwb
>>
>> There's some missing values, so first step is to impute them using
>> the??
>> mice package, then calculate AUC and finally fit the model:
>>
>> library(dplyr)
>> library(lme4)
>> library(mice)
>> library(zoo)
>>
>> ## Impute missing values
>> dfMids <- mice(df, m = 10, maxit = 15, seed = 2535)
>> dfImp??<- complete(dfMids)
>>
>> ## Calculate AUC
>> dfImpAUC <- dfImp %>%
>> ???arrange(sampleNum) %>%
>> ???group_by(ID, treatment) %>%
>> ???mutate(AUC = sum(diff(sampleNum)*rollmean(value,2)))
>>
>> ## Fit model
>> fit <- lmer(AUC ~ sex * treatment + (1|ID), data = dfImpAUC)
>>
>> ## Plot residuals
>> plot(fit)??# output: https://imgur.com/a/vfL1R
>> qqnorm(resid(fit))
>>
>>
>>
>> I know it's possible to fit a model to each iteration of mids
>> model,??
>> but then I can't calculate the AUC, which is what I actually need.
>> Any??
>> ideas why the residuals look like that?
>>
>> Best
>> Santiago
>>
>>
>>
>>



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From joao.santiago at uni-tuebingen.de  Mon Aug  7 12:29:14 2017
From: joao.santiago at uni-tuebingen.de (=?utf-8?b?Sm/Do28=?= C P Santiago)
Date: Mon, 07 Aug 2017 12:29:14 +0200
Subject: [R-sig-ME] Residuals look "mirrored" when using lmer with
 imputed data
In-Reply-To: <20170806153024.GA32505@info124.pharmacie.univ-paris5.fr>
References: <20170804085209.Horde.HEi79TkP3mTQ_uSGcFb1Hsb@webmail.uni-tuebingen.de>
 <1501915270.11496.2.camel@mpi.nl>
 <20170805175923.Horde.LQ8t_V_kENCEJoCJTq04ziE@webmail.uni-tuebingen.de>
 <1502024353.16729.30.camel@mpi.nl> <1502024447.16729.32.camel@mpi.nl>
 <20170806153024.GA32505@info124.pharmacie.univ-paris5.fr>
Message-ID: <20170807122914.Horde.Pg0avpL8yPUvixLi0bCMtQa@webmail.uni-tuebingen.de>


@Phillip: Thank you for the tip, I'll be sure to be more explicit in  
the future regarding the term AUC.

I guess you are right, the data is indeed bounded because of the  
measuring method's own limits, I didn't think of that.

@Emmanuel: I log transforming did not help, because as Phillip  
mentioned, there are too many repeated values.

I guess the question then is, is this data usable at all? It seems  
it's impossible to get safe results from lmer, probably simple ttests  
won't be much better either.

Thank you both for taking the time to look into this.

Best Joao Santiago


Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:

> Just a complement on this: in a pharmacokinetics context, which seems
> the one of Joao, AUC is most often estimated using the trapeze rules
> than using a rectangular approximation. So that would be a first
> improvment for Joao's computation.
>
> Most often also, these data are log-transformed before analysis,
> because of the > 0 constraint of the concentrations. This may (or not)
> improve the models?.
>
> I'm not sure if imputation is relevant here, if a few data points are
> missing for some patients: after all, in a way, a tremendous amount of
> points are missing since a very few set of times is sampled on the
> continuous time axis. And the trapeze method in the case of a missing
> point is equivalent to having a linear interpolation for the missing
> point, using the two surrounding points. But that neglects the noises
> effects, of course. However, would it improve the final conclusions?
> If anyone has references...
>
> Except in one case: if the missing point is the last one (or the first
> one), because then the AUC are difficult to compare since the X spans
> differ. Unless there is an approximation for ??last point to
> infinity??, which I did not saw in Joao's code.
>
> By the way, if it is an hormon, you may have to include a term for the
> baseline before comparing AUC if there is both internal and external
> origin of the hormon ? but it depends on the experiment. Removing the
> baseline by substraction is a way, but I guess tend to neglect the
> associated uncertainty.
>
> On Sun, Aug 06, 2017 at 01:00:47PM +0000, Alday, Phillip wrote:
> ? Uh ... part of my problem is the term "AUC". Without some very explicit
> ? note to the contrary, AUC on a stats forum often refers to a cumulative
> ? probability or the Receiver Operating Characteristic (ROC AUC).
> ? Remember, we're doing this in our free time, so I am often quick and
> ? don't read every line of code ....
> ?
> ? You're effectively using a rectangular approximation for your integral
> ? and that's something else to be careful with in terms of approximation.
> ? But why impute separately here? You might be able to use a suitable
> ? integral approximation to skip imputation:
> ?
> ? >??dfAUC <- subset(df,!is.na(value)) %>% arrange(sampleNum) %>%
> ? group_by(ID, treatment) %>%??mutate(AUC =
> ? sum(diff(sampleNum)*rollmean(value,2)))
> ? > fit2 <- lmer(AUC ~ sex * treatment + (1|ID), data = dfAUC)
> ? > qqnorm(resid(fit2))
> ?
> ? yields similarly flat tails on the qqplot. (Okay, maybe don't use the
> ? rectangular approximation without proper imputation; this didn't work
> ? as well as I'd hoped.)
> ?
> ? In both cases, the residual plot looks not horrible to me, but the
> ? qqnorm plot suggests some issues with bounding -- those flat tails look
> ? you're running into some minimal/maximal value. At the lower end, the
> ? obvious answer is "zero"; at the upper end, maybe you're hitting the
> ? limits of your measurement device? We see which values actually occur,
> ? both with the imputed data and the implicit-imputation-via-integral-
> ? approximation data:
> ?
> ? > xtabs(~AUC,dfImpAUC)
> ? > xtabs(~AUC,dfAUC)
> ?
> ? In both cases, we see that the data only take on a relatively small
> ? number of values and indeed there are lots of repetitions at the
> ? bounds.
> ?
> ? Phillip
> ?
> ? > On Sat, 2017-08-05 at 17:59 +0200, Jo?o C P Santiago wrote:
> ? > >
> ? > > I'm sorry I may be misunderstanding, but why do you say my data
> ? > > is??
> ? > > bounded between 0 and 1? The data I shared is from multiple??
> ? > > measurements of a blood hormone, which can be 0, but is certainly
> ? > > not??
> ? > > bounded at 1. Next I calculated the AUC i.e. the "total exposure"
> ? > > of??
> ? > > that hormone. X is time and y is the value of the hormone at each
> ? > > time??
> ? > > point. The AUC is also not bounded at 0 and 1.
> ? > >
> ? > > Am I missing something?
> ? > >
> ? > > Thanks for your reply!
> ? > > Santiago
> ? > >
> ? > >
> ? > > Quoting "Alday, Phillip" <Phillip.Alday at mpi.nl>:
> ? > >
> ? > > >
> ? > > >
> ? > > > You're fitting a normal/Gaussian LMM to data bounded on [0, 1].
> ? > > > The
> ? > > > model assumptions about the residuals simply won't hold for
> ? > > > bounded,
> ? > > > binomial-like values.?
> ? > > >
> ? > > > Why not fit a binomial model to the data and then use
> ? > > > fitted(model)
> ? > > > to
> ? > > > compute AUC of the entire model??
> ? > > >
> ? > > > Phillip ?
> ? > > >
> ? > > > On Fri, 2017-08-04 at 08:52 +0200, Jo?o C P Santiago wrote:
> ? > > > >
> ? > > > >
> ? > > > > I'm trying to assess if a treatment had any effect on the
> ? > > > > levels
> ? > > > > of
> ? > > > > a??
> ? > > > > hormone. To do this I need to calculate the area under the
> ? > > > > curve
> ? > > > > and??
> ? > > > > then adjust it for sex (a known confounder) and smoking status
> ? > > > > (not??
> ? > > > > included in the demo data below to keep things simpler).
> ? > > > >
> ? > > > > Here's a dput of the data: https://pastebin.com/VYcQGkwb
> ? > > > >
> ? > > > > There's some missing values, so first step is to impute them
> ? > > > > using
> ? > > > > the??
> ? > > > > mice package, then calculate AUC and finally fit the model:
> ? > > > >
> ? > > > > library(dplyr)
> ? > > > > library(lme4)
> ? > > > > library(mice)
> ? > > > > library(zoo)
> ? > > > >
> ? > > > > ## Impute missing values
> ? > > > > dfMids <- mice(df, m = 10, maxit = 15, seed = 2535)
> ? > > > > dfImp??<- complete(dfMids)
> ? > > > >
> ? > > > > ## Calculate AUC
> ? > > > > dfImpAUC <- dfImp %>%
> ? > > > > ???arrange(sampleNum) %>%
> ? > > > > ???group_by(ID, treatment) %>%
> ? > > > > ???mutate(AUC = sum(diff(sampleNum)*rollmean(value,2)))
> ? > > > >
> ? > > > > ## Fit model
> ? > > > > fit <- lmer(AUC ~ sex * treatment + (1|ID), data = dfImpAUC)
> ? > > > >
> ? > > > > ## Plot residuals
> ? > > > > plot(fit)??# output: https://imgur.com/a/vfL1R
> ? > > > > qqnorm(resid(fit))
> ? > > > >
> ? > > > >
> ? > > > >
> ? > > > > I know it's possible to fit a model to each iteration of mids
> ? > > > > model,??
> ? > > > > but then I can't calculate the AUC, which is what I actually
> ? > > > > need.
> ? > > > > Any??
> ? > > > > ideas why the residuals look like that?
> ? > > > >
> ? > > > > Best
> ? > > > > Santiago
> ? > > > >
> ? > > > >
> ? > > > >
> ? > > > >
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html



-- 
Jo?o C. P. Santiago
Institute for Medical Psychology & Behavioral Neurobiology
Center of Integrative Neuroscience
University of Tuebingen
Otfried-Mueller-Str. 25
72076 Tuebingen, Germany

Phone: +49 7071 29 88981
Fax: +49 7071 29 25016


From karistaeh at gmail.com  Tue Aug  8 18:38:20 2017
From: karistaeh at gmail.com (Karista Hudelson)
Date: Tue, 8 Aug 2017 12:38:20 -0400
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report
	p values?
In-Reply-To: <5982E187.6010901@mpi.nl>
References: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
 <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>
 <5982E187.6010901@mpi.nl>
Message-ID: <CAKeD0ujPLa7NJLWNL8996=MLaa+R7X8WFGxgPmOV8DQQ=Uf+Kg@mail.gmail.com>

Hello again List,

Thanks for the clarification question Thierry.  I want to compare the
predictive ability of the model terms between the two phases.  For
instance, is Sea Ice more important in phase 1?  This comparison is
confounded somewhat by the unequal sample sizes in the phases I think, but
am not sure.  Maybe that is part of my question: should I focus less on the
p values (as Phillip recommends in his first point I think) and instead
look at the overall model fit for each phase?

Phillip, thank you for your second suggestion!  I followed your advice and
included Phase in the model and also tried running it with interactions
between the fixed effects and phase.

*Here is the model without phase:*

FSVlmer1a<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2)

REML criterion at convergence: -389.3

Scaled residuals:
    Min      1Q  Median      3Q     Max
-6.1650 -0.6235 -0.0447  0.6380  3.0889

Random effects:
 Groups   Name        Variance Std.Dev.
 WA       (Intercept) 0.11493  0.3390
 Residual             0.03244  0.1801
Number of obs: 790, groups:  WA, 5

Fixed effects:
                  Estimate Std. Error         df t value Pr(>|t|)
(Intercept)     -1.064e+00  1.971e-01  1.130e+01  -5.399 0.000195 ***
Length           2.204e-02  1.105e-03  7.817e+02  19.952  < 2e-16 ***
Res_Sea_Ice_Dur  7.917e-04  2.977e-04  7.813e+02   2.660 0.007978 **
Spring_MST       1.892e-02  4.514e-03  7.812e+02   4.190 3.11e-05 ***
Summer_Rain     -2.194e-03  3.650e-04  7.811e+02  -6.011 2.82e-09 ***
---
> sem.model.fits(FSVlmer1a)
           Class   Family     Link   n Marginal Conditional
1 merModLmerTest gaussian identity 790 0.127793   0.8080115

> AIC(FSVlmer1a)
[1] -375.2507

*Same model with Phase interactions:*

>
FSV2lmer1bi<-lmer(logHg~Length*Phase+Res_Sea_Ice_Dur*Phase+Spring_MST*Phase+Summer_Rain*Phase+(1|WA),data=FSV2)

REML criterion at convergence: -360.9

Scaled residuals:
    Min      1Q  Median      3Q     Max
-6.2490 -0.6285 -0.0176  0.6076  3.1211

Random effects:
 Groups   Name        Variance Std.Dev.
 WA       (Intercept) 0.11988  0.3462
 Residual             0.03195  0.1788
Number of obs: 790, groups:  WA, 5

Fixed effects:
                           Estimate Std. Error         df t value Pr(>|t|)

(Intercept)              -1.179e+00  2.122e-01  1.400e+01  -5.556 7.10e-05
***
Length                    2.146e-02  1.204e-03  7.767e+02  17.827  < 2e-16
***
*Phasepre                  8.858e-01  3.945e-01  7.765e+02   2.246 0.025014
*  *
Res_Sea_Ice_Dur           1.389e-03  3.963e-04  7.763e+02   3.504 0.000484
***
Spring_MST                1.680e-02  4.924e-03  7.761e+02   3.411 0.000681
***
Summer_Rain              -2.254e-03  3.980e-04  7.760e+02  -5.664 2.08e-08
***
*Length:Phasepre           2.582e-03  2.917e-03  7.762e+02   0.885 0.376294
   *
*Phasepre:Res_Sea_Ice_Dur -4.806e-03  1.607e-03  7.764e+02  -2.990 0.002876
** *
*Phasepre:Spring_MST      -8.681e-03  2.147e-02  7.760e+02  -0.404 0.686088
   *
*Phasepre:Summer_Rain     -4.634e-03  2.072e-03  7.764e+02  -2.236 0.025636
*  *

> AIC(FSV2lmer1bi)
[1] -336.8567

> sem.model.fits(FSV2lmer1bi,aicc=T)
           Class   Family     Link   n Marginal Conditional
1 merModLmerTest gaussian identity 790 0.126233   0.8161111

So the overall fit metrics for these two models are not so different, and
the simpler one is a bit better.

And in case it would be helpful/interesting, here are the fits of the
models for phase 1 and phase 2 (which were described in my first question):

FSV2lmer1apre<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2pre)
# AIC 10.06269, R2s:0.1508716   0.7681201

FSV2lmer1apost<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2post)
# AIC -335.1748, R2s: 0.1233518   0.8228584

Thank you Phillip and Thierry for your kind and encouraging attention to
this question.  I hope I can trouble you and the rest of the list for a bit
more instruction on this/these questions, as this issue is the crux of the
interpretation of this data.

Looking forward to your thoughts and suggestions,
Karista


On Thu, Aug 3, 2017 at 4:40 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:

> Dear Karista,
>
> as Thierry said, knowing more about the inferences you want to make will
> get you better advice here. That said, I do have two suggestions in the
> meantime:
>
> 1. Don't focus on significance, especially of individual predictors, as
> much as estimates and overall model fit / predictive ability. (cf. The
> New Statistics, The Difference between Significant and Insignificant is
> not itself Significant, Choosing prediction over explanation in
> psychology, etc.)
>
> 2. Put all your data into one model and include time period as a fixed
> effect. Such pooling will generally help all your estimates; moreover,
> it gives you a more principled way to compare time periods (both in the
> main effect of time period and in its interactions with individual
> variables).
>
> Best,
> Phillip
>
> On 08/03/2017 10:20 AM, Thierry Onkelinx wrote:
> > Dear Karista,
> >
> > Much depends on what you want to compare between the models. The
> parameter
> > estimates? The predicted values? The goodness of fit? You 'll need to
> make
> > that clear.
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2017-08-02 19:54 GMT+02:00 Karista Hudelson <karistaeh at gmail.com>:
> >
> >> Hello All,
> >>
> >> I am comparing the fit of a mixed model on different time periods of a
> data
> >> set.  For the first time period I have 113 observations and only one of
> the
> >> fixed effects is significant.  For the second time period I have 322
> >> observations and all of the fixed effects are significant.  Because n is
> >> important in the calculation of p, I'm not sure how or even if to
> interpret
> >> the differences in p values for the model terms in the two time periods.
> >> Does anyone have advice on how to compare the fit of the variables in
> the
> >> mixed model for the two data sets in a way that is less impacted by the
> >> difference in the number of observations?  Or is a difference of 209
> >> observations enough to drive these differences in p values?
> >>
> >> Time period 1 output:
> >> Fixed effects:
> >>                   Estimate Std. Error         df t value Pr(>|t|)
> >> (Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
> >> Length            0.024371   0.003536 106.650000   6.892 4.01e-10 ***
> >> Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
> >> Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
> >> Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159
> >>
> >>
> >> Time period 2 output:
> >> Fixed effects:
> >>                   Estimate Std. Error         df t value Pr(>|t|)
> >> (Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281 **
> >> Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16 ***
> >> Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235 ***
> >> Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
> >> Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929 ***
> >>
> >>
> >>
> >>
> >> Thanks in advance for your time and consideration of this question.
> >> Karista
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>



-- 
Karista

	[[alternative HTML version deleted]]


From newboch at auburn.edu  Tue Aug  8 19:25:12 2017
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 8 Aug 2017 17:25:12 +0000
Subject: [R-sig-ME] Question about inclusion of a random effect
Message-ID: <1502213112728.41417@auburn.edu>

All,



I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.



My basic model is shown below for reference:



  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)



Thanks in advance for the help

	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Tue Aug  8 19:43:34 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Tue, 8 Aug 2017 17:43:34 +0000
Subject: [R-sig-ME] Question about inclusion of a random effect
Message-ID: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>


Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).

Phillip
________________________________
From: Chad Newbolt <newboch at auburn.edu>
Sent: Aug 8, 2017 7:25 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question about inclusion of a random effect


All,



I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.



My basic model is shown below for reference:



  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)



Thanks in advance for the help

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Tue Aug  8 19:43:43 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Tue, 8 Aug 2017 17:43:43 +0000
Subject: [R-sig-ME] Question about inclusion of a random effect
Message-ID: <ac3d5799-93c7-49a1-9764-06003098c0cf@mpi.nl>


Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).

Phillip
________________________________
From: Chad Newbolt <newboch at auburn.edu>
Sent: Aug 8, 2017 7:25 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question about inclusion of a random effect


All,



I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.



My basic model is shown below for reference:



  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)



Thanks in advance for the help

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From newboch at auburn.edu  Tue Aug  8 19:50:57 2017
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 8 Aug 2017 17:50:57 +0000
Subject: [R-sig-ME] Question about inclusion of a random effect
In-Reply-To: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>
References: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>
Message-ID: <1502214657864.35169@auburn.edu>

Thanks to everyone for the clarification and quick responses!!!

________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: Tuesday, August 8, 2017 12:43 PM
To: Chad Newbolt; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question about inclusion of a random effect


Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).

Phillip
________________________________
From: Chad Newbolt <newboch at auburn.edu>
Sent: Aug 8, 2017 7:25 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question about inclusion of a random effect


All,



I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.



My basic model is shown below for reference:



  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)



Thanks in advance for the help

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From newboch at auburn.edu  Tue Aug  8 20:06:48 2017
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 8 Aug 2017 18:06:48 +0000
Subject: [R-sig-ME] Question about inclusion of a random effect
In-Reply-To: <1502214657864.35169@auburn.edu>
References: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>,
 <1502214657864.35169@auburn.edu>
Message-ID: <1502215609118.36260@auburn.edu>

When I include  (1|Question) I receive the dreaded convergence warning...

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00303355 (tol = 0.001, component 1)

If I remove (1|Question) there is no convergence warning.  Is this an indication that the variance of this random effect is 0 thereby creating a problem with the optimizer?  Does this warrant removing this random effect?  If not, any suggestions on how to proceed with the convergence issues?  

 

Chad Newbolt

Research Associate

School of Forestry And Wildlife Sciences

Auburn University

334-332-4864

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
Sent: Tuesday, August 8, 2017 12:50 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question about inclusion of a random effect

Thanks to everyone for the clarification and quick responses!!!

________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: Tuesday, August 8, 2017 12:43 PM
To: Chad Newbolt; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question about inclusion of a random effect


Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).

Phillip
________________________________
From: Chad Newbolt <newboch at auburn.edu>
Sent: Aug 8, 2017 7:25 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question about inclusion of a random effect


All,



I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.



My basic model is shown below for reference:



  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)



Thanks in advance for the help

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From newboch at auburn.edu  Tue Aug  8 20:57:11 2017
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 8 Aug 2017 18:57:11 +0000
Subject: [R-sig-ME] Fw:  Question about inclusion of a random effect
In-Reply-To: <1502218567384.34297@auburn.edu>
References: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>
 <1502214657864.35169@auburn.edu> <1502215609118.36260@auburn.edu>,
 <5CB516F9-03C8-4073-B8DF-BE1E71E882D3@stanford.edu>,
 <1502218567384.34297@auburn.edu>
Message-ID: <1502218632202.18544@auburn.edu>



So might help out to give more specifics...here is my model with explanations of effects and associated levels

results=glmer(Status2~Group+Distance+Type+Biologist+Sex+Experience+(1|ID)+(1|Question),data=datum,family=binomial)

Status2 = Binomial response where 0 is incorrect response and 1 is correct response
Distance (Outside, Inside) = Image contains an animal  inside or outside a specified distance
Type (Night, Day) = Image is taken during day or night
Group (Male, Female, Juvenille) = Image contains an animal that is male, female or juvenille
Biologist (Yes, No) = Respondent is/is not a Biologist
Sex (Male Female) = Sex of respondent
Experience (High, moderate, low, none) = experience looking at images of species of animal in images


As you can see my fixed effects can be broken down into two broad categories 1) those that categorize the image, 2) those that categorize the respondent...both of which may influence their ability to correctly answer questions.  I made sure during study planning that I have roughly equal numbers of each possible "category" of image represented in the survey.  These were chosen at random from larger pools of each possible image category.  In light of the previous response, since I have fixed effects that categorize the images, or questions, would it still make sense to include (1|Question) or create (1|Category) with n levels to account for variation not associated with my fixed effects?

For reference, I evaluated VIF of the fixed effects and found little evidence of multicollinearity, and I'm interested in the effects of each of these so I would prefer to keep them in the model in this case.


Chad Newbolt

Research Associate

School of Forestry And Wildlife Sciences

Auburn University

334-332-4864

________________________________________
From: Ewart A C Thomas <ethomas at stanford.edu>
Sent: Tuesday, August 8, 2017 1:19 PM
To: Chad Newbolt
Subject: Re: [R-sig-ME] Question about inclusion of a random effect

chad, lmer() and its optimisation is a computationally complex undertaking, and one shd always keep the ?size? of the model in mind.

you have 94 items.  might you reduce this to ?categories? of items (e.g., ?faces?, ?people?, ?houses?, ?), such that you have a much smaller number (e.g., 10) of categories.  you wd replace each respondent?s string of 94 responses by a string of 10 categ-responses, and the random effect term wd be (1 | category).  does this make theoretical sense, given the nature of your material?

also, including x1 thru x6 feels a little like a shopping expedition.  maybe some exploratory anal (factor anal?) wd suggest either (i) using 2 or 3 composites based on x1-x6, or (ii) omitting about 3 of the x?s, because they don?t explain anything.

you didn?t raise this possibility, but it cd be that some questions/categories are more ?sensitive? to x1 than other questions.  in this case, you might try to fit a model with (1 + x1 | category), and see if it fits sig better than the ?intercept only? model with (1 | category) - using anova(model1, model2).  good luck!
ewart

> On Aug 8, 2017, at 11:06 AM, Chad Newbolt <newboch at auburn.edu> wrote:
>
> When I include  (1|Question) I receive the dreaded convergence warning...
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>  Model failed to converge with max|grad| = 0.00303355 (tol = 0.001, component 1)
>
> If I remove (1|Question) there is no convergence warning.  Is this an indication that the variance of this random effect is 0 thereby creating a problem with the optimizer?  Does this warrant removing this random effect?  If not, any suggestions on how to proceed with the convergence issues?
>
>
>
> Chad Newbolt
>
> Research Associate
>
> School of Forestry And Wildlife Sciences
>
> Auburn University
>
> 334-332-4864
>
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
> Sent: Tuesday, August 8, 2017 12:50 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question about inclusion of a random effect
>
> Thanks to everyone for the clarification and quick responses!!!
>
> ________________________________
> From: Alday, Phillip <Phillip.Alday at mpi.nl>
> Sent: Tuesday, August 8, 2017 12:43 PM
> To: Chad Newbolt; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question about inclusion of a random effect
>
>
> Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).
>
> Phillip
> ________________________________
> From: Chad Newbolt <newboch at auburn.edu>
> Sent: Aug 8, 2017 7:25 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Question about inclusion of a random effect
>
>
> All,
>
>
>
> I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.
>
>
>
> My basic model is shown below for reference:
>
>
>
>  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)
>
>
>
> Thanks in advance for the help
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From mmaciasgonzalez at ucdavis.edu  Wed Aug  9 02:01:00 2017
From: mmaciasgonzalez at ucdavis.edu (Miguel Macias)
Date: Tue, 8 Aug 2017 17:01:00 -0700
Subject: [R-sig-ME] MCMCglmm and Contrast Part 2
Message-ID: <CAJi3DRAvonUeCpwYVCswuGwRJgNCPxHNRTe5KM9d10yAX5iD0w@mail.gmail.com>

Hello,

I would like to run some custom contrast on MCMCglmm. I have read how to do
this in the link <https://www.nceas.ucsb.edu/system/files/mixedlab.pdf> and
I have read previous posting about this issue <
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/012415.html> but
the suggestions given have not resolved the problem I am having. I will
refer to data from <
https://github.com/bbolker/asaglmm/blob/master/data/culcitalogreg.csv> and
follow Ben Bolker's example <
https://www.nceas.ucsb.edu/system/files/mixedlab.pdf> to explain my problem.

I am using MCMCglmm version 2.24 and R version 3.4.1

My problem is that when I try to run a model with contrast I don't get back
the contrast results in the fixed effects summary. Please see below.

1) Running the Model without contrast

# setting seed to get reproducible results
set.seed(1)

# Running model with 'singular.ok = FALSE'
culcmod4 <-
MCMCglmm(cbind(predation,nopred)~ttt,random=~block,family="multinomial2",
                     data=culcdat,verbose=FALSE, singular.ok = FALSE)

# getting the summary results
#                 post.mean  l-95% CI u-95% CI   eff.samp    pMCMC
#  (Intercept)     228.11      43.33      408.20       340.0        0.008
**
#   ttt2              -196.65   -340.14       -62.33       224.0
 <0.001 ***
#   ttt3              -164.87   -314.63       -22.33       246.5
 0.016 *
#   ttt4              -253.51   -397.38       -99.90       132.1
 <0.001 ***
#   ---
#   Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

2) The contrast are constructed and assigned to the factor:

# Setting contrast to ttt which has levels 1, 2, 3, and 4
contrasts(culcdat$ttt) <- matrix(c(3,-1,-1,-1,
                                                     0, 1,-1, 0,
                                                     0, 1, 1,-2),
                                                  nrow=4,

dimnames=list(c("none","C","S","CS"), c("symb","C.vs.S","twosymb")))

3) Running the model with the contrast

# setting seed to get reproducible results
set.seed(1)

# Running model with 'singular.ok = TRUE'
culcmod4v2 <-
MCMCglmm(cbind(predation,nopred)~ttt,random=~block,family="multinomial2",
                     data=culcdat,verbose=FALSE, singular.ok = TRUE)

# getting the summary results: I get the same results as without the
contrasts

Why aren't the contrast working? I do not get any error messages indicating
that contrast were dropped from the model.
I can get the procedure above to work with glmer from the lme4 package but
my data has complete separation and I would like to use a bayesian model to
get around complete separation.

Thank you in advance,



-- 
Miguel Macias Gonz?lez

451 E. Health Sciences Dr.
4212A UC Davis Genome Center,
Davis, CA, 95616
Work: 530-752-8889
Cell: 530-760-7205

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Wed Aug  9 11:05:05 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 11:05:05 +0200
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report
 p values?
In-Reply-To: <CAKeD0ujPLa7NJLWNL8996=MLaa+R7X8WFGxgPmOV8DQQ=Uf+Kg@mail.gmail.com>
References: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
 <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>
 <5982E187.6010901@mpi.nl>
 <CAKeD0ujPLa7NJLWNL8996=MLaa+R7X8WFGxgPmOV8DQQ=Uf+Kg@mail.gmail.com>
Message-ID: <598AD041.60000@mpi.nl>

Hi Karista,

it is not surprising that the combined model has a poorer overall fit
than the separate models, for two reasons:

1. It has to model more data.
2. In some sense, it has fewer "independent" (I'm not using this word in
a rigorous sense!) parameters than two distinct models because the two
phases share a common set of parameters and thus the two distinct phases
bias each other.

The latter point is an example of the variance-bias tradeoff (which
really came to light with the Stein paradox for OLS) or equivalently the
overfitting-underfitting continuum. There are lots of good resources on
this, but I particularly like McElreath's discussion in his book
Statistical Rethinking.

The tl;dr version is that the combination model will often have a poorer
fit on the current data (bias away from observed means,etc.) but
generalize better to new data (less variance). Or expressed in terms of
"fitting", the two within-phase models tend to overfit a little bit to
particular details of the data within each phase and thus will
generalize less well the combination model, which will tend to underfit
the data within each phase but generalize better to new data because it
doesn't capture as much noisy detail.

I would modify your combination model in one way though: I would include
a main effect for phase.

Also, when comparing models with different fixed-effects structures, it
is important to use ML, i.e. set REML=FALSE, because the REML criterion
is dependent on the fixed-effects parameterisation.

This doesn't answer your questions directly, but hopefully gives you
more food for thought. :)

Best,
Phillip

On 08/08/2017 06:38 PM, Karista Hudelson wrote:
> Hello again List, 
> 
> Thanks for the clarification question Thierry.  I want to compare the
> predictive ability of the model terms between the two phases.  For
> instance, is Sea Ice more important in phase 1?  This comparison is
> confounded somewhat by the unequal sample sizes in the phases I think,
> but am not sure.  Maybe that is part of my question: should I focus less
> on the p values (as Phillip recommends in his first point I think) and
> instead look at the overall model fit for each phase?
> 
> Phillip, thank you for your second suggestion!  I followed your advice
> and included Phase in the model and also tried running it with
> interactions between the fixed effects and phase.  
> 
> *_Here is the model without phase:_*
> 
> FSVlmer1a<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2)
> 
> REML criterion at convergence: -389.3
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -6.1650 -0.6235 -0.0447  0.6380  3.0889 
> 
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  WA       (Intercept) 0.11493  0.3390  
>  Residual             0.03244  0.1801  
> Number of obs: 790, groups:  WA, 5
> 
> Fixed effects:
>                   Estimate Std. Error         df t value Pr(>|t|)    
> (Intercept)     -1.064e+00  1.971e-01  1.130e+01  -5.399 0.000195 ***
> Length           2.204e-02  1.105e-03  7.817e+02  19.952  < 2e-16 ***
> Res_Sea_Ice_Dur  7.917e-04  2.977e-04  7.813e+02   2.660 0.007978 ** 
> Spring_MST       1.892e-02  4.514e-03  7.812e+02   4.190 3.11e-05 ***
> Summer_Rain     -2.194e-03  3.650e-04  7.811e+02  -6.011 2.82e-09 ***
> ---
>> sem.model.fits(FSVlmer1a)
>            Class   Family     Link   n Marginal Conditional
> 1 merModLmerTest gaussian identity 790 0.127793   0.8080115
> 
>> AIC(FSVlmer1a)
> [1] -375.2507
> 
> *_Same model with Phase interactions:_*
> 
>>
> FSV2lmer1bi<-lmer(logHg~Length*Phase+Res_Sea_Ice_Dur*Phase+Spring_MST*Phase+Summer_Rain*Phase+(1|WA),data=FSV2)
> 
> REML criterion at convergence: -360.9
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -6.2490 -0.6285 -0.0176  0.6076  3.1211 
> 
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  WA       (Intercept) 0.11988  0.3462  
>  Residual             0.03195  0.1788  
> Number of obs: 790, groups:  WA, 5
> 
> Fixed effects:
>                            Estimate Std. Error         df t value
> Pr(>|t|)    
> (Intercept)              -1.179e+00  2.122e-01  1.400e+01  -5.556
> 7.10e-05 ***
> Length                    2.146e-02  1.204e-03  7.767e+02  17.827  <
> 2e-16 ***
> *Phasepre                  8.858e-01  3.945e-01  7.765e+02   2.246
> 0.025014 *  *
> Res_Sea_Ice_Dur           1.389e-03  3.963e-04  7.763e+02   3.504
> 0.000484 ***
> Spring_MST                1.680e-02  4.924e-03  7.761e+02   3.411
> 0.000681 ***
> Summer_Rain              -2.254e-03  3.980e-04  7.760e+02  -5.664
> 2.08e-08 ***
> *Length:Phasepre           2.582e-03  2.917e-03  7.762e+02   0.885
> 0.376294    *
> *Phasepre:Res_Sea_Ice_Dur -4.806e-03  1.607e-03  7.764e+02  -2.990
> 0.002876 ** *
> *Phasepre:Spring_MST      -8.681e-03  2.147e-02  7.760e+02  -0.404
> 0.686088    *
> *Phasepre:Summer_Rain     -4.634e-03  2.072e-03  7.764e+02  -2.236
> 0.025636 *  *
> 
>> AIC(FSV2lmer1bi)
> [1] -336.8567
> 
>> sem.model.fits(FSV2lmer1bi,aicc=T)
>            Class   Family     Link   n Marginal Conditional
> 1 merModLmerTest gaussian identity 790 0.126233   0.8161111
> 
> So the overall fit metrics for these two models are not so different,
> and the simpler one is a bit better.  
> 
> And in case it would be helpful/interesting, here are the fits of the
> models for phase 1 and phase 2 (which were described in my first question):
> 
> FSV2lmer1apre<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2pre)
> # AIC 10.06269, R2s:0.1508716   0.7681201
> 
> FSV2lmer1apost<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+Summer_Rain+(1|WA),data=FSV2post)
> # AIC -335.1748, R2s: 0.1233518   0.8228584
> 
> Thank you Phillip and Thierry for your kind and encouraging attention to
> this question.  I hope I can trouble you and the rest of the list for a
> bit more instruction on this/these questions, as this issue is the crux
> of the interpretation of this data.  
> 
> Looking forward to your thoughts and suggestions,
> Karista
> 
> 
> On Thu, Aug 3, 2017 at 4:40 AM, Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
>     Dear Karista,
> 
>     as Thierry said, knowing more about the inferences you want to make will
>     get you better advice here. That said, I do have two suggestions in the
>     meantime:
> 
>     1. Don't focus on significance, especially of individual predictors, as
>     much as estimates and overall model fit / predictive ability. (cf. The
>     New Statistics, The Difference between Significant and Insignificant is
>     not itself Significant, Choosing prediction over explanation in
>     psychology, etc.)
> 
>     2. Put all your data into one model and include time period as a fixed
>     effect. Such pooling will generally help all your estimates; moreover,
>     it gives you a more principled way to compare time periods (both in the
>     main effect of time period and in its interactions with individual
>     variables).
> 
>     Best,
>     Phillip
> 
>     On 08/03/2017 10:20 AM, Thierry Onkelinx wrote:
>     > Dear Karista,
>     >
>     > Much depends on what you want to compare between the models. The
>     parameter
>     > estimates? The predicted values? The goodness of fit? You 'll need
>     to make
>     > that clear.
>     >
>     > Best regards,
>     >
>     >
>     > ir. Thierry Onkelinx
>     > Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature and
>     > Forest
>     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>     > Kliniekstraat 25
>     > 1070 Anderlecht
>     > Belgium
>     >
>     > To call in the statistician after the experiment is done may be no
>     more
>     > than asking him to perform a post-mortem examination: he may be
>     able to say
>     > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer
>     does not
>     > ensure that a reasonable answer can be extracted from a given body
>     of data.
>     > ~ John Tukey
>     >
>     > 2017-08-02 19:54 GMT+02:00 Karista Hudelson <karistaeh at gmail.com
>     <mailto:karistaeh at gmail.com>>:
>     >
>     >> Hello All,
>     >>
>     >> I am comparing the fit of a mixed model on different time periods
>     of a data
>     >> set.  For the first time period I have 113 observations and only
>     one of the
>     >> fixed effects is significant.  For the second time period I have 322
>     >> observations and all of the fixed effects are significant. 
>     Because n is
>     >> important in the calculation of p, I'm not sure how or even if to
>     interpret
>     >> the differences in p values for the model terms in the two time
>     periods.
>     >> Does anyone have advice on how to compare the fit of the
>     variables in the
>     >> mixed model for the two data sets in a way that is less impacted
>     by the
>     >> difference in the number of observations?  Or is a difference of 209
>     >> observations enough to drive these differences in p values?
>     >>
>     >> Time period 1 output:
>     >> Fixed effects:
>     >>                   Estimate Std. Error         df t value Pr(>|t|)
>     >> (Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
>     >> Length            0.024371   0.003536 106.650000   6.892 4.01e-10 ***
>     >> Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
>     >> Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
>     >> Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159
>     >>
>     >>
>     >> Time period 2 output:
>     >> Fixed effects:
>     >>                   Estimate Std. Error         df t value Pr(>|t|)
>     >> (Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281 **
>     >> Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16 ***
>     >> Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235 ***
>     >> Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
>     >> Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929 ***
>     >>
>     >>
>     >>
>     >>
>     >> Thanks in advance for your time and consideration of this question.
>     >> Karista
>     >>
>     >>         [[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >
> 
> 
> 
> 
> -- 
> Karista


From phillip.alday at mpi.nl  Wed Aug  9 11:29:11 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 11:29:11 +0200
Subject: [R-sig-ME] Fw: Question about inclusion of a random effect
In-Reply-To: <1502218632202.18544@auburn.edu>
References: <8a42d4c4-8747-42f9-9abb-b1578333f587@mpi.nl>
 <1502214657864.35169@auburn.edu> <1502215609118.36260@auburn.edu>
 <5CB516F9-03C8-4073-B8DF-BE1E71E882D3@stanford.edu>
 <1502218567384.34297@auburn.edu> <1502218632202.18544@auburn.edu>
Message-ID: <598AD5E7.5050501@mpi.nl>

Let me address your first question:

> If I remove (1|Question) there is no convergence warning.  Is this an
indication that the variance of this random effect is 0 thereby creating
a problem with the optimizer?  Does this warrant removing this random
effect?  If not, any suggestions on how to proceed with the convergence
issues?

No, this does not in general indicate that the variance of that random
effect is zero, which the optimiser can often find on its own. You can
see this by replacing the different subjects in the lme4 sleepstudy
example with copies of a single subject:

> rep(subset(sleepstudy, Subject == 308),10)
> n <- length(levels(sleepstudy$Subject))
> novar <- do.call(rbind, replicate(n, subset(sleepstudy, Subject ==
308), simplify=FALSE))
> novar$Subject <- sleepstudy$Subject
> summary(lmer(Reaction ~ 1 + Days + (1|Subject),novar))

Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept)    0      0.00
 Residual             1847     42.97
Number of obs: 180, groups:  Subject, 18

(That said, there may be valid reasons to drop the additional random
effect, but that's based on particulars of your dataset and
predictive/inferential goals, so only you can make that determination.)

The usual first steps in working on model convergence are scaling your
variables, but that's not an option with categorical variables. You
state that your variables have no trouble with collinearity, but are you
sure? Unfortunately, things like Sex and <X-Scientist> (for various X)
often do correlate.

The next step is try out different optimisers and up the number of
iterations. There is no free lunch and there is no optimiser that is
always best. See

> ?convergence

after loading lme4.

You can also try the worse but potentially good enough Laplace
approximation in glmer with nAGQ=0. There has been some discussion on
the list lately about this option.

Finally, if all that fails, you can try out other mixed-models packages
in R. Both MCMCglmm and brms are excellent, if you're willing to go
Bayesian. (And if you're going Bayesian, then weakly informative
regularizing priors may help a lot with convergence!)

Phillip


On 08/08/2017 08:57 PM, Chad Newbolt wrote:
> 
> 
> So might help out to give more specifics...here is my model with explanations of effects and associated levels
> 
> results=glmer(Status2~Group+Distance+Type+Biologist+Sex+Experience+(1|ID)+(1|Question),data=datum,family=binomial)
> 
> Status2 = Binomial response where 0 is incorrect response and 1 is correct response
> Distance (Outside, Inside) = Image contains an animal  inside or outside a specified distance
> Type (Night, Day) = Image is taken during day or night
> Group (Male, Female, Juvenille) = Image contains an animal that is male, female or juvenille
> Biologist (Yes, No) = Respondent is/is not a Biologist
> Sex (Male Female) = Sex of respondent
> Experience (High, moderate, low, none) = experience looking at images of species of animal in images
> 
> 
> As you can see my fixed effects can be broken down into two broad categories 1) those that categorize the image, 2) those that categorize the respondent...both of which may influence their ability to correctly answer questions.  I made sure during study planning that I have roughly equal numbers of each possible "category" of image represented in the survey.  These were chosen at random from larger pools of each possible image category.  In light of the previous response, since I have fixed effects that categorize the images, or questions, would it still make sense to include (1|Question) or create (1|Category) with n levels to account for variation not associated with my fixed effects?
> 
> For reference, I evaluated VIF of the fixed effects and found little evidence of multicollinearity, and I'm interested in the effects of each of these so I would prefer to keep them in the model in this case.
> 
> 
> Chad Newbolt
> 
> Research Associate
> 
> School of Forestry And Wildlife Sciences
> 
> Auburn University
> 
> 334-332-4864
> 
> ________________________________________
> From: Ewart A C Thomas <ethomas at stanford.edu>
> Sent: Tuesday, August 8, 2017 1:19 PM
> To: Chad Newbolt
> Subject: Re: [R-sig-ME] Question about inclusion of a random effect
> 
> chad, lmer() and its optimisation is a computationally complex undertaking, and one shd always keep the ?size? of the model in mind.
> 
> you have 94 items.  might you reduce this to ?categories? of items (e.g., ?faces?, ?people?, ?houses?, ?), such that you have a much smaller number (e.g., 10) of categories.  you wd replace each respondent?s string of 94 responses by a string of 10 categ-responses, and the random effect term wd be (1 | category).  does this make theoretical sense, given the nature of your material?
> 
> also, including x1 thru x6 feels a little like a shopping expedition.  maybe some exploratory anal (factor anal?) wd suggest either (i) using 2 or 3 composites based on x1-x6, or (ii) omitting about 3 of the x?s, because they don?t explain anything.
> 
> you didn?t raise this possibility, but it cd be that some questions/categories are more ?sensitive? to x1 than other questions.  in this case, you might try to fit a model with (1 + x1 | category), and see if it fits sig better than the ?intercept only? model with (1 | category) - using anova(model1, model2).  good luck!
> ewart
> 
>> On Aug 8, 2017, at 11:06 AM, Chad Newbolt <newboch at auburn.edu> wrote:
>>
>> When I include  (1|Question) I receive the dreaded convergence warning...
>>
>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>  Model failed to converge with max|grad| = 0.00303355 (tol = 0.001, component 1)
>>
>> If I remove (1|Question) there is no convergence warning.  Is this an indication that the variance of this random effect is 0 thereby creating a problem with the optimizer?  Does this warrant removing this random effect?  If not, any suggestions on how to proceed with the convergence issues?
>>
>>
>>
>> Chad Newbolt
>>
>> Research Associate
>>
>> School of Forestry And Wildlife Sciences
>>
>> Auburn University
>>
>> 334-332-4864
>>
>> ________________________________________
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
>> Sent: Tuesday, August 8, 2017 12:50 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Question about inclusion of a random effect
>>
>> Thanks to everyone for the clarification and quick responses!!!
>>
>> ________________________________
>> From: Alday, Phillip <Phillip.Alday at mpi.nl>
>> Sent: Tuesday, August 8, 2017 12:43 PM
>> To: Chad Newbolt; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Question about inclusion of a random effect
>>
>>
>> Yes, it makes sense. This is what is often called an "item" in the discussion on crossed random effects and leaving it out can distort inferences - see Clark 1974 "Language as a fixed effect fallacy" and more recent work by  Westfall and Judd (I'm thinking of their 2012 paper on this, but I can't think of the title or author order and I'm not at my desk to look it up).
>>
>> Phillip
>> ________________________________
>> From: Chad Newbolt <newboch at auburn.edu>
>> Sent: Aug 8, 2017 7:25 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Question about inclusion of a random effect
>>
>>
>> All,
>>
>>
>>
>> I'm working on analyzing a data set from a survey.  In the survey, I asked a group of respondents to view a series of 94 images, or test questions, and I'm in process of evaluating the influence of various factors on their ability to correctly identify an item in an image.  The test questions likely show a considerable amount of variation in difficulty, with some being harder to correctly answer than others.  I understand that I clearly should include a random effect for each respondent (ID), however, I'm not sure if it is appropriate to include a random effect for question (1|Question) to account for variation.  I may be overthinking this one, but, including and removing (1|Question) dramatically changes my results so I want to make sure to get this one right.
>>
>>
>>
>> My basic model is shown below for reference:
>>
>>
>>
>>  results=glmer(Y~X1+X2+X3+X4+X5+X6+(1|ID)+(1|Question),data=datum,na.action = na.omit,family=binomial)
>>
>>
>>
>> Thanks in advance for the help
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at mpi.nl  Wed Aug  9 15:24:35 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 15:24:35 +0200
Subject: [R-sig-ME] variable-and person-centered approaches and
 multilevel models
In-Reply-To: <009801d24ee1$31d02b60$95708220$@uni-jena.de>
References: <009801d24ee1$31d02b60$95708220$@uni-jena.de>
Message-ID: <598B0D13.4050500@mpi.nl>

Following up on an unanswered (I think) old post:

I had not heard the term "person-centred approach" before, but after
searching a bit, it seems to refer to focus on clustering under a
specific grouping term instead of a specific co-variate. I think this
distinction is somewhat blurred in mixed-effects models. While the fixed
effects are more or less what is called "variable centered" (indeed, the
canonical examples in the psych literature are things like linear
regression and ANOVA), the random effects allow for variation to follow
the grouping variables, which is more like (although maybe not exactly
the same) as the "person-centred" approach. The covariance matrix / the
correlations between random effects is more difficult to comprehend, but
is actually the part that perhaps best captures "person centering", as
it shows the relationship between the by-person regression slopes.

As a side note, I'm not sure it makes sense to include the personal mean
as a separate covariate, as depending on the exact structure of your
data, it may already be captured in random intercept by participant.

Phillip

On 12/05/2016 11:20 AM, Elisabeth Schubach wrote:
> Dear all,
> I am currently trying to figure out which parts of a multilevel model are
> person-centered and which ones are variable-centered.
> I have a three-level structure, with assessment points (Level 1) nested
> in relationships (Level 2) nested in individuals (Level 3). And I model
> closeness to relationship partner r of individual i at time t as a function
> of PERSSONALITY-withinti 
> (i.e., a time-varying covariate that was centered within individuals,
> representing within-person deviations from an
> individual's own mean level across time. To account for between-person
> differences in the
> respective PERSONALITY trait, I included personal mean (i.e., mean across
> time points for
> each specific individual, centered on the grand mean) as a time-invariant
> covariate. I now wonder whether the within part is person-centered and
> whether the between-part is variable-centered or whether 
> the parameters ?0 and ?1 are variable-centered (because they represent
> average associations) and the parameters b0i, b0ri, b1ri are person-centered
> (because they are specific for each individual).
> I would be very happy if you can tell me which specific parts in mlm are
> person-centered and which ones variable-centered.
> Best,
> Elisabeth
> 
> 
> 
> CLOSENESS tri = (?0 + b0i + b0ri) 
> 	+ ?1 (TIMEtri)
> 	+ (?1 + b1ri)  (PERSONALITY-withinti) 
> 	+ ?2 (PERSONALITY-betweeni)
> 	+?tri
> 
>  with i = individual i
>         r = relationship partner r 
>         t = time t
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at mpi.nl  Wed Aug  9 15:27:40 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 15:27:40 +0200
Subject: [R-sig-ME] Related fixed and random factors and planned
 comparisons in a 2x2 design
In-Reply-To: <CALS4JYcBy+bVLZt+ACJzVRQ6y6L4qprbVE6-mmXx8z5Bzsz96g@mail.gmail.com>
References: <mailman.1.1465034401.21395.r-sig-mixed-models@r-project.org>
 <DB6PR0301MB23112A3EED4FF8C98B6DAD94D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
 <CALS4JYeNMMNeA4pD89BKeKBWMcFoKG2x1z6XJaAq3Oa2Xxb1Gg@mail.gmail.com>
 <DB6PR0301MB23116F63CE3C4C84D77D2733D25C0@DB6PR0301MB2311.eurprd03.prod.outlook.com>
 <CALS4JYdbr_2SiM2AdKEOM14CpcSKsWXe0S09TAkXQ=awBJzOiw@mail.gmail.com>
 <a867be4c547740e1a7b8d47ab8ffb85b@ITUPW-EXMBOX2C.UniNet.unisa.edu.au>
 <CALS4JYcBy+bVLZt+ACJzVRQ6y6L4qprbVE6-mmXx8z5Bzsz96g@mail.gmail.com>
Message-ID: <598B0DCC.6040502@mpi.nl>

Another old post ...

I wouldn't subset models as a rule of thumb because overarching models
tend to fall on my preferred side of the bias-variance /
underfitting-overfitting tradeoff.

For posthoc comparisons between groups, you can use techniques like
marginal / least-square means, implemented in R in packages like lsmeans.

Phillip

On 06/07/2016 10:27 AM, paul wrote:
> Dear Phillip,
> 
> Many thanks for these resources and replies. They are indeed very
> helpful. I suppose after I've done the contrast coding, I still have to
> subset the data (e.g., singling out the data for P) to do planned
> comparisons between groups, using a reduced mixed model as illustrated
> earlier, then? Or are there any alternative ways to do so?
> 
> Best regards,
> 
> Paul
> 
> 2016-06-07 2:57 GMT+02:00 Phillip Alday <Phillip.Alday at unisa.edu.au
> <mailto:Phillip.Alday at unisa.edu.au>>:
> 
>     In terms of contrast coding, two more helpful resources are:
> 
>     http://talklab.psy.gla.ac.uk/tvw/catpred/
> 
>     http://palday.bitbucket.org/stats/coding.html
> 
>     Channel makes sense as a random effect / grouping term for your
>     particular design, *not* nested within participant. The implicit
>     crossing given by (1|Participant) + (1|Channel) models [omitting any
>     slope terms to focus on the grouping variables] (1) interindividual
>     differences in the EEG and (2) differences between electrodes
>     because closely located electrodes can be thought of as samples from
>     a population consisting of a given Region of Interest (ROI),
>     especially if the electrode placement is somewhat symmetric. The
>     differences resulting from variance in electrode placement between
>     participants will be covered by the implicit crossing of these two
>     random effects.
> 
>     Note that using channel as a random effect is somewhat more
>     difficult if you're doing a whole scalp analysis as sampling across
>     the whole scalp can be viewed as sampling from multiple ROIs, i.e.
>     multiple populations. Two possible solutions are (1) to include ROI
>     in the fixed effects and keep channel in the random effects and (2)
>     model channel as a two or three continuous spatial variables (e.g.
>     displacement from midline or displacement from center based on 10-20
>     coordinates, or spatial coordinates of the sort used in source
>     localisation) in the fixed effects.  In the case of (1), the channel
>     random effect would then be modelling the typical variance within
>     ROIs (because that's hopefully the major source of variance
>     structured  by channel left over after modelling ROI and your
>     experimental manipulation). If this within-variance differs greatly
>     between between ROIs, then this may be a sub-optimal modelling
>     choice. In the case of (2), it might still make sense to
>     additionally model channel as a random effect (i.e. the RE with the
>     factor consisting of channel names, the FE with the continuous
>     coordinates), see Thierry Onkelinx's posts on the subject and
>     http://rpubs.com/INBOstats/both_fixed_random , but I haven't thought
>     about this enough nor examined the resulting model fits.
> 
>     Best,
>     Phillip
> 
>     -----Original Message-----
>     From: R-sig-mixed-models
>     [mailto:r-sig-mixed-models-bounces at r-project.org
>     <mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf Of paul
>     Sent: Tuesday, 7 June 2016 5:27 AM
>     To: Houslay, Tom <T.Houslay at exeter.ac.uk
>     <mailto:T.Houslay at exeter.ac.uk>>
>     Cc: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     Subject: Re: [R-sig-ME] Related fixed and random factors and planned
>     comparisons in a 2x2 design
> 
>     Dear Tom,
> 
>     Thank you so much for these detailed replies and I appreciate your help!
> 
>     Sincerely,
> 
>     Paul
> 
>     2016-06-06 21:51 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk
>     <mailto:T.Houslay at exeter.ac.uk>>:
> 
>     > Hi Paul,
>     >
>     >
>     > I think you're right here in that actually you don't want to nest
>     > channel inside participant (which led to that error message - sorry,
>     > should have seen that coming!).
>     >
>     >
>     > It's hard to know without seeing data plotted, but my guess from your
>     > email is that you probably see some clustering both at individual
>     > level and at channel level? Perhaps separate random effects, ie
>     > (1|Participant) + (1|Channel), is the way to go (and then you
>     > shouldn't have the problem as regards number of observations - instead
>     > you'll have an intercept deviation for each of your N individuals, and
>     > also intercept deviations for each of your 9 channels). You certainly
>     > want to keep the participant intercept in though, as each individual
>     > gets both items (right?), so you need to model that association. You
>     > can use your variance components output from lmer to determine what
>     > proportion of the phenotypic variance (conditional on your fixed
>     > effects) is explained by each of these components, eg
>     > V(individual)/(V(individual) + V(channel) + V(residual) would give you
>     > the proportion explained by differences among individuals in their
>     > voltage. It would be cool to know if differences among individuals, or
>     > among channels, is driving the variation that you find. I think using
>     > the sjplot function for lmer would be useful to look at the levels of
>     > your random
>     > effects:
>     >
>     >
>     > http://strengejacke.de/sjPlot/sjp.lmer/
>     >
>     >
>     > As for 'contrasts', again I haven't used that particular package, but
>     > from a brief glance it looks like you're on the right track - binary
>     > coding is the 'simple coding' as set out here:
>     >
>     >
>     > http://www.ats.ucla.edu/stat/r/library/contrast_coding.htm
>     >
>     >
>     > Good luck!
>     >
>     >
>     > Tom
>     >
>     >
>     > ------------------------------
>     > *From:* paul <graftedlife at gmail.com <mailto:graftedlife at gmail.com>>
>     > *Sent:* 06 June 2016 20:06:02
>     > *To:* Houslay, Tom
>     > *Cc:* r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     > *Subject:* Re: Related fixed and random factors and planned
>     > comparisons in a 2x2 design
>     >
>     > Dear Tom,
>     >
>     > Many thanks for these very helpful comments and suggestions! Would you
>     > just allow me to ask some further questions:
>     >
>     > 1. I've been considering whether to cross or to nest the random
>     > effects for quite a while. Data from the same channel across
>     > participants do show corresponding trends (thus a bit different from
>     > the case when, e.g., sampling nine neurons from the same individual).
>     > Would nesting channel within participant deal with that relationship?
>     >
>     > 2. I actually also tried nesting channel within participant. However,
>     > when I proceeded to run planned comparisons (I guess I'd better have
>     > them done because of their theoretical significance) based on this
>     > mixed-effect modeling approach (as illustrated in the earlier mail but
>     > with the random factor as (1|participant/channel), to maintain
>     > consistency of analytical methods), R gave me an error message:
>     >
>     > Error: number of levels of each grouping factor must be < number of
>     > observations
>     >
>     >
>     > I think this is because in my data, each participant only contributes
>     > one data point per channel and thus the data points are not enough. I
>     > guess that probably means I can't go on in this direction to run the
>     > planned comparisons... (?) I'm not pretty sure how contrasts based on
>     > binary dummy variables may be done and will try to further explore
>     > that. But before I establish the mixed model I already set up
>     > orthogonal contrasts for group and item in the dataset using the
>     > function contrasts(). Does this have anything to do with what you
>     meant?
>     >
>     > 3. I worried about pseudoreplicability when participant ID is not
>     > included. Concerning this point, later it came to me that
>     > pseudoreplicability usually occurred in cases when multiple responses
>     > from the same individual are grouped in the same cell, rendering the
>     > data within the same cell non-independent (similar to the case of
>     > repeated-measure ANOVA? sorry if I got a wrong understanding...). But
>     > as mentioned earlier in my data, each participant only contributes one
>     > data point per channel, when channel alone is already modeled as a
>     > random factor, would that mean all data points within a cell all come
>     > from different participants and thus in this case may deal with the
>     > independence assumption? (Again I'm sorry if my concept is wrong and
>     > would appreciate instructions on this point...)
>     >
>     > Many, many thanks!
>     >
>     > Paul
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     >
>     > 2016-06-06 19:10 GMT+02:00 Houslay, Tom <T.Houslay at exeter.ac.uk
>     <mailto:T.Houslay at exeter.ac.uk>>:
>     >
>     >> Hi Paul,
>     >>
>     >> I don't think anyone's responded to this yet, but my main point would
>     >> be that you should check out Schielzeth & Nakagawa's 2012 paper
>     >> 'Nested by design' (
>     >> http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210x.2012.00251.x/a
>     >> bstract
>     >> ) for a nice rundown on structuring your model for this type of data.
>     >>
>     >> It may also be worth thinking about how random intercepts work in a
>     >> visual sense; there are a variety of tools that help you do this from
>     >> a model (packages sjplot, visreg, broom), or you can just plot
>     >> different levels yourself (eg consider plotting the means for AP, AQ,
>     >> BP, BQ; the same with mean values from each individual overplotted
>     >> around these group means; and even the group means with all points
>     >> shown, perhaps coloured by individual - ggplot is really useful for
>     >> getting this type of figure together quickly).
>     >>
>     >> As to some of your other questions:
>     >>
>     >> 1) You need to keep participant ID in. I'm not 100% on your data
>     >> structure from the question, but you certainly seem to have repeated
>     >> measures for individuals (I'm assuming that groups A and B each
>     >> contain multiple individuals, none of whom were in both groups, and
>     >> each of which were shown both objects P and Q, in a random order).
>     >> It's not surprising that the effects of group are weakened if you
>     >> remove participant ID, because you're then effectively entering
>     >> pseudoreplication into your model (ie, telling your model that all
>     >> the data points within a group are independent, when that isn't
>     the case).
>     >>
>     >> 2) I think channel should be nested within individual, with a model
>     >> something like model <- lmer(voltage ~ group * item +
>     >> (1|participant/channel), data = ...)
>     >>
>     >> 3) This really depends on what your interest is. If you simply want
>     >> to show that there is an overall interaction effect, then your
>     >> p-value from a likelihood ratio test of the model with/without the
>     >> interaction term gives significance of this interaction, and then a
>     >> plot of predicted values for the fixed effects (w/ data
>     overplotted if possible) should show the trends.
>     >> You could also use binary dummy variables to make more explicit
>     >> contrasts, but it's worth reading up on these a bit more. I don't
>     >> really use these type of comparisons very much, so I can't
>     comment further I'm afraid.
>     >>
>     >> 4) Your item is like treatment in this case - you appear to be more
>     >> interested in the effect of different items (rather than how much
>     >> variation 'item' explains), so keep this as a fixed effect and
>     not as random.
>     >>
>     >> Hope some of this is useful,
>     >>
>     >> Tom
>     >>
>     >>
>     >> ________________________________________
>     >>
>     >>
>     >> Message: 1
>     >> Date: Fri, 3 Jun 2016 14:28:59 +0200
>     >> From: paul <graftedlife at gmail.com <mailto:graftedlife at gmail.com>>
>     >> To: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     >> Subject: [R-sig-ME] Related fixed and random factors and planned
>     >>         comparisons     in a 2x2 design
>     >> Message-ID:
>     >>         <
>     >>
>     CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com
>     <mailto:CALS4JYfoTbhwhy8S0kHePuw9pPv-NTkrsLrB2Z2YO5ks5gnnOA at mail.gmail.com>>
>     >> Content-Type: text/plain; charset="UTF-8"
>     >>
>     >> Dear All,
>     >>
>     >> I am trying to use mixed-effect modeling to analyze brain wave data
>     >> from two groups of participants when they were presented with two
>     >> distinct stimulus. The data points (scalp voltage) were gathered from
>     >> the same set of 9 nearby channels from each participant. And so I
>     >> have the following
>     >> factors:
>     >>
>     >>    - voltage: the dependent variable
>     >>    - group: the between-participant/within-item variable for groups A
>     >> and B
>     >>    - item: the within-participant variable (note there are
>     exactly only 2
>     >>    items, P and Q)
>     >>    - participant: identifying each participant across the two groups
>     >>    - channel: identifying each channel (note that data from these
>     channels
>     >>    in a nearby region tend to display similar, thus correlated,
>     >> patterns in
>     >>    the same participant)
>     >>
>     >> The hypothesis is that only group B will show difference between P
>     >> and Q (i.e., there should be an interaction effect). So I established
>     >> a mixed-effect model using the lme4 package in R:
>     >>
>     >> model <-
>     >> lmer(voltage~1+group+item+(group:item)+(1|participant)+(1|channel),
>     >>               data=data, REML=FALSE)
>     >>
>     >> Questions:
>     >>
>     >>    1.
>     >>
>     >>    I'm not sure if it is reasonable to add in participant as a random
>     >>    effect, because it is related to group and seems to weaken the
>     >> effects of
>     >>    group. Would it be all right if I don't add it in?
>     >>    2.
>     >>
>     >>    Because the data from nearby channels of the same participant tend
>     >> to be
>     >>    correlated, I'm not sure if modeling participant and channel
>     as crossed
>     >>    random effects is all right. But meanwhile it seems also strange
>     >> if I treat
>     >>    channel as nested within participant, because they are the
>     same set of
>     >>    channels across participants.
>     >>    3.
>     >>
>     >>    The interaction term is significant. But how should planned
>     comparisons
>     >>    be done (e.g., differences between groups A and B for P) or is
>     it even
>     >>    necessary to run planned comparisons? I saw suggestions for
>     t-tests,
>     >>    lsmeans, glht, or for more complicated methods such as breaking
>     >> down the
>     >>    model and subsetting the data:
>     >>
>     >>    data[, P_True:=(item=="P")]
>     >>    posthoc<-lmer(voltage~1+group
>     >>        +(1|participant)+1|channel)
>     >>        , data=data[item=="P"]
>     >>        , subset=data$P_True
>     >>        , REML=FALSE)
>     >>
>     >>    But especially here comparing only between two groups while
>     modeling
>     >>    participant as a random effect seems detrimental to the group
>     effects.
>     >> And
>     >>    I'm not sure if it is really OK to do so. On the other hand,
>     >> because the
>     >>    data still contain non-independent data points (from nearby
>     >> channels), I'm
>     >>    not sure if simply using t-tests is all right. Will non-parametric
>     >> tests
>     >>    (e.g., Wilcoxon tests) do in such cases?
>     >>    4.
>     >>
>     >>    I suppose I don't need to model item as a random effect
>     because there
>     >>    are only two of them, one for each level, right?
>     >>
>     >> I would really appreciate your help!!
>     >>
>     >> Best regards,
>     >>
>     >> Paul
>     >>
>     >>         [[alternative HTML version deleted]]
>     >>
>     >>
>     >>
>     >
> 
>             [[alternative HTML version deleted]]
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>


From phillip.alday at mpi.nl  Wed Aug  9 16:08:11 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 16:08:11 +0200
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <DB5PR04MB14625C2A380ADE88080CB9C68B520@DB5PR04MB1462.eurprd04.prod.outlook.com>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
 <1465720272.24053.96.camel@loki>
 <CAJ6ui+OyB_-KQ6B7oTPQ=NGRs_OV=o7DR9S=EG0vb_R-zbKAGg@mail.gmail.com>
 <DB5PR04MB14625C2A380ADE88080CB9C68B520@DB5PR04MB1462.eurprd04.prod.outlook.com>
Message-ID: <598B174B.1040708@mpi.nl>

Today is apparently the day for me to follow up on zombie threads:

While Alex is right that mixed-effects models are difficult with small
sample sizes, there seems to be an implicit assumption that a large
number of grouping levels and thus a large number of random intercepts
increases the number of model parameters. This isn't correct. The
variance of the intercepts is a model parameter, not the intercepts
themselves -- the individual intercepts are BLUPs / predictions /
conditional models and not estimates / model parameters. This is the
difference to including subject-id as a covariate in a classical
fixed-effects regression. Indeed, increasing the number of groups
generally helps in mixed-effects regression because variance estimates
are quite sensitive to small sample sizes. (@Ben Bolker and others if
I've messed this up, please correct me!)

Your sample size is still nonetheless quite small if you want to model
e.g. the variance for playback type (which I think could be important in
your model). Using rmANOVA isn't really better than a mixed-effects
model here, because rmANOVA *is* an intercepts-only mixed-effects model
with additional symmetry assumptions (sphericity)!

Compare the output of
> summary(aov(Reaction ~ Days + Error(Subject),sleepstudy))

Error: Subject
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 17 250618   14742

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Days        1 162703  162703   169.4 <2e-16 ***
Residuals 161 154634     960

and

> anova(lmer(Reaction ~ Days + (1|Subject),sleepstudy))
Analysis of Variance Table
     Df Sum Sq Mean Sq F value
Days  1 162703  162703   169.4

You can get the residual Mean Sq F in the mixed model by looking at the
variance column of the Residual grouping under Random effects in
summary()-output.

The advantage to mixed-effects models in this case is that you're doing
the regression explicitly.

Best,
Phillip



On 06/13/2016 01:43 AM, Sam Hardman [sah74] wrote:
> Hi Alex,
> 
> 
> The reason I was looking at using mixed models is because I have
> repeated measures for indivuals (i.e. each bird was tested three times
> with three different playback treatments). As far as I know ANOVA can't
> control for this. I am wrong about this?
> 
> 
> You are correct that I have 40 animals in the experiment, with three
> treatments each that makes 120 measurements per response behaviour. I
> agree with you that the sample size is small which could cause problems
> with reliability of results. If ANOVA could work then I will certainly
> look at that. How would I control for repeated measures?
> 
> 
> Thanks for your help, I appreciate it.
> 
> Sam
> 
> ------------------------------------------------------------------------
> *Von:* Alex Fine <abfine at gmail.com>
> *Gesendet:* Sonntag, 12. Juni 2016 23:10:59
> *An:* Phillip Alday
> *Cc:* Sam Hardman [sah74]; r-sig-mixed-models at r-project.org
> *Betreff:* Re: [R-sig-ME] P-values from interaction terms using lme4
>  
> Hey Sam,
> 
> I actually think mixed effects regression might be inappropriate in this
> case.  Do I have it right that you have 40 total animals in the
> experiment?  You said you had 1 bird in the city center and 1 outside
> the city in 20 cities.
> 
> If that's right, then the model you described (to take one of your
> examples) would be:
> 
> Approach ~ PlayBack * UrbanRural + (1|ID)
> 
> That's 3 * 2 - 1 = 5 coefficients in your model, plus a random intercept
> for 20 different cities.  I don't think you have enough data to fit such
> a model and trust the results.
> 
> If you have a balanced design and you have clear a priori predictions
> about each of the contrasts in your design, I'd recommend just using
> ANOVA.  I don't think you gain very much from using MEMs in this case. 
> You could use vanilla linear regression, but setting up the coding
> schemes for your two predictors is going to be so complicated that it'll
> actually be much simpler to just do ANOVA + t-tests.
> 
> Alex
> 
> On Sun, Jun 12, 2016 at 4:31 AM, Phillip Alday
> <Phillip.Alday at unisa.edu.au <mailto:Phillip.Alday at unisa.edu.au>> wrote:
> 
>     Hi Sam,
> 
>     if you're getting p-values from lmer outside of a likelihood-ratio test,
>     then you're using lmerTest, not lme4. lmerTest is designed to be a
>     drop-in replacement for lme4, but it does bring some extra
>     features/'complications' in the form of the denominator degrees of
>     freedom.
> 
>     There are two easy options for getting ANOVA-style p-values:
> 
>     1. Using lmerTest, you can just do
>     anova(mod1,ddf="Satterthwaite",type=2)
> 
>     If you're using vanilla lme4, then you need to do this first:
> 
>     library(lmerTest)
>     mod1 <- as(mod1,"merModLmerTest")
> 
>     which will cast your model to an lmerTest model.
> 
>     2. Using the car package:
> 
>     library(car)
>     Anova(mod1,test.statistic="F",type=2)
> 
>     If you fitted your model with maximum likelihood, i.e. with REML=FALSE,
>     then you need to refit your model using REML first:
> 
>     mod1 <- update(mod1,REML=TRUE)
> 
>     For both options, you need to specify the types of test you're doing. I
>     highly recommend Type 2, but there is a lot of material on that debate,
>     search for e.g. Venables' "Exegeses on linear models", or look at the
>     documentation for car::Anova(). Please note that the distinction for
>     Type 2 vs Type 3 is *very* relevant for your question since you're
>     concerned about interaction terms.
> 
>     For the lmerTest route, you can specify the approximation to use for the
>     denominator degrees of freedom: Satterthwaite is much faster, but
>     Kenward-Roger is more accurate. For car::Anova(), the F-statistic is
>     always computed with  Kenward-Roger (and only works for REML-fitted
>     models for reasons that I can't explain quickly), but you have the
>     option of using a Chisq test statistic, which is equivalent to assuming
>     that the denominator degrees of freedom are infinite, or equivalently,
>     that your t-values for the coefficients are z-values.
> 
>     These ANOVA-style tests are Wald tests and are asymptotically equivalent
>     to the LR-tests, but are less conservative for finite samples.
> 
>     Now, since you care about particular contrasts within the model, you may
>     also just want to look at your model coefficients. Depending on which
>     coding scheme you're using, the contrasts represented by your model
>     coefficients might not be the ones you want, but packages like lsmeans
>     (a regular mention on the list here and very well documented) can
>     compute all types of contrasts post-hoc. Rereading your question, this
>     may be the best way to go for your target conclusion/result statements.
> 
>     Best,
>     Phillip
> 
> 
>     On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
>     > Dear all,
>     >
>     >
>     > I have some data which I would like to analyse using lme4 and I
>     would really appreciate some help deciding what the best method is.
>     >
>     >
>     > My experiment is as follows:
>     >
>     >
>     > I tested the responses of urban and rural great tits to playbacks
>     of great tit song from a loud speaker within their territories.
>     >
>     >
>     > I created three playback song types:
>     >
>     > -undegraded
>     >
>     > -degraded
>     >
>     > -very degraded
>     >
>     >
>     > I played these to birds in 20 different cities. In each city I
>     tested one bird in the city centre and one bird in a rural location
>     outside of the city (i.e. paired samples). Each bird received all
>     three playback types.
>     >
>     >
>     > I measured five different responses to these playbacks:
>     >
>     > -Time to sing back to playback (in seconds)
>     >
>     > -Time to sing back to playback (in seconds)
>     >
>     > -Time the bird spent within five metres of the speaker (in seconds)
>     >
>     > -Number of times the bird flew over the speaker (count)
>     >
>     > -The closest approach the bird made to the speaker (in metres)
>     >
>     >
>     > For each of these five repsonses I would like to know if there is
>     an interaction between habitat and playback type.
>     >
>     >
>     > So, I have a model which looks like this:
>     >
>     >
>     > mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
>     >
>     >
>     > Where response is one of the five repsonse behaviours, playback is
>     the playback type, UR is habitat type (urban or rural) and ID is the
>     ID of the bird.
>     >
>     >
>     > This gives me results and P-Values but am not sure these P-values
>     are valid and I think I should compare this model to a null model to
>     get a valid P-values.
>     >
>     >
>     > So I can use a likelihood ratio tests to test for differences in
>     response by habitat type alone:
>     >
>     >
>     > mod1<-lmer(approach ~ UR + (1|Location))
>     > mod2<-lmer(approach ~ 1 + (1|Location))
>     > anova(mod1, mod2)
>     >
>     > or for differences in response according tom playback type alone:
>     >
>     > mod1<-lmer(approach ~ Playback + (1|Location))
>     > mod2<-lmer(approach ~ 1 + (1|Location))
>     > anova(mod1, mod2)
>     >
>     > But how should I do this when there is an interaction term? I
>     deally I would like P-values for each playback type in interaction
>     with habitat. e.g.
>     >
>     > Undregraded playback * Habitat (urban/rural
>     > Degraded playback * Habitat (urban/rural)
>     > Very degraded playback * Habitat (urban/rural)
>     >
>     > This would allow me to say, for example, something like "urban
>     birds approached the speaker more closely than rural birds in
>     response to undegraded playbacks". I would like to do this with each
>     of the five response behaviours.
>     >
>     > I would really appreciate any suggestions for the best way forward
>     with this and apologies if this question is too simple for this group.
>     >
>     > Best wishes,
>     > Sam
>     >
>     >
>     > --------------------------------------------------------------------
>     > Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
>     >
>     > Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> -- 
> Alex Fine
> Ph. (336) 302-3251
> web:  http://internal.psychology.illinois.edu/~abfine/
> <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
> 
> 
> --------------------------------------------------------------------
> Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
> 
> Aberystwyth ? Wales? First University https://www.aber.ac.uk/en/


From phillip.alday at mpi.nl  Wed Aug  9 16:56:52 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 16:56:52 +0200
Subject: [R-sig-ME] A question on setting up a generalized additive
 mixed effect model
In-Reply-To: <CAJDdXgbxVWJeYrPNdU4OoP-6=h=uPWEjxrNOy=NBQw43G663gQ@mail.gmail.com>
References: <CAJDdXgbxVWJeYrPNdU4OoP-6=h=uPWEjxrNOy=NBQw43G663gQ@mail.gmail.com>
Message-ID: <598B22B4.1000109@mpi.nl>

Hi Leon,

I agree that it makes sense to have both a by-subject intercept and
slope, but you will needs lots of data to estimate that for GAMM because
the smoothers "eat" a lot of data. Based on your model structure and
error message, I'm guessing that you have around 20 subjects or less.
Both for computational and inferential purposes, you need closer to 40
or preferably 100+ subjects for this study. See e.g. Button et al. 2013
(Nature Neuroscience) or Button's more recent paper in eNeuro. I know
that's a lot for scanner data, especially of infants. :(

Two other quick notes:

1. don't name your fitted model "gam" as this then shadows the function
"gam()" and can lead to a world of pain full of subtle bugs and weird
error messages.

2. You can also fit your model with a more mixed-model like syntax (e.g.
1|subjeIndex ) via the package gamm4. It turns out that you can express
random effects as smoothers (the mgcv approach) or smoothers as random
effects (the gamm4) approach. Depending on your exact model structure,
one or the other may be faster. See

?mgcv::random.effects

for more info.

Phillip

On 04/04/2017 12:18 AM, Leon Lee wrote:
> Dear R experts
> 
> I am new to R & generalized additive models and wonder whether I could get
> some help from you all. The question I have is as follows:
> 
> I have 30 subjects with each subject being scanned one to three times in
> the first year of life.
> 
> The brain volume (BrainVolume) from each scan was measured.
> 
> The scan time was randomly distributed from birth to 1 year, indexed by
> subjIndexF. i.e., first three scans are from the same subject, the fourth
> is from the second, subjIndexF=1,1,1,2...
> 
> Each subject has chronological age (age) from birth to 1 year old.
> 
> Now, I want to look at how predictors, such as subject's age will explain
> the changes in brain volume. I also want to model both random slope and
> intercept for random effects within each subject in the model. My model
> ends up like this:
> 
> 
> gam=gam(brainVolume~ s(age) + s(subjIndexF, bs=?re?) +  s(subjIndexF, age,
> bs="re"), method="REML", data=mydata)
> 
> 
> In which, s(subjeIndexF, bs=?re?) is for modeling random intercepts and
> s(subjIndexF, age, bs=?re?) is for modeling different slopes. When I tried
> to run the model, I was given a ?coefficients more than the data? error. So
> my questions are as follows:
> 
> 
> (1) Does this model make sense, especially the part dealing with the
> repeated measures within subjects as random effects?
> 
> (2) If it does, what I can do to reduce the required parameters? The model
> runs if I only model random intercepts without interaction term, but a more
> realistic scenario would be each subject has random slope for smooths as
> well.
> 
> 
> Your help will be greatly appreciated!
> 
> 
> I set up the model by raining following the suggestions in the following
> two links:
> 
> http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html
> 
> http://r.789695.n4.nabble.com/Random-effects-in-package-mgcv-td4720162.html
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at mpi.nl  Wed Aug  9 16:58:23 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 16:58:23 +0200
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <598B2214.5000907@mpi.nl>
References: <598B2214.5000907@mpi.nl>
Message-ID: <598B230F.9090507@mpi.nl>

Re'CCing the list after being bounced due to PGP signature.


On 08/09/2017 04:46 PM, Douglas Bates wrote:
> I think you mean "conditional modes", i.e. the point where the
> conditional density of the random effects is maximized, not "conditional
> models".

Yes, that was a typo.


> Technically it is true that the number of parameters does not depend on
> the number of random effects, only on the number of unique values in the
> covariance matrices for the random effects.  However, I think that leads
> to an undercount of the effective number of parameters when, say,
> performing a likelihood ratio test of models that differ in their random
> effects specification.

This is related to the more general issue of degrees of freedom in mixed
models, right?

But in terms of estimation (especially as implemented in
lme4/MixedModels.jl), increasing the levels of a random effect will
generally provide better estimates, right?

Phillip

> 
> On Wed, Aug 9, 2017 at 9:08 AM Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
>     Today is apparently the day for me to follow up on zombie threads:
> 
>     While Alex is right that mixed-effects models are difficult with small
>     sample sizes, there seems to be an implicit assumption that a large
>     number of grouping levels and thus a large number of random intercepts
>     increases the number of model parameters. This isn't correct. The
>     variance of the intercepts is a model parameter, not the intercepts
>     themselves -- the individual intercepts are BLUPs / predictions /
>     conditional models and not estimates / model parameters. This is the
>     difference to including subject-id as a covariate in a classical
>     fixed-effects regression. Indeed, increasing the number of groups
>     generally helps in mixed-effects regression because variance estimates
>     are quite sensitive to small sample sizes. (@Ben Bolker and others if
>     I've messed this up, please correct me!)
> 
>     Your sample size is still nonetheless quite small if you want to model
>     e.g. the variance for playback type (which I think could be important in
>     your model). Using rmANOVA isn't really better than a mixed-effects
>     model here, because rmANOVA *is* an intercepts-only mixed-effects model
>     with additional symmetry assumptions (sphericity)!
> 
>     Compare the output of
>     > summary(aov(Reaction ~ Days + Error(Subject),sleepstudy))
> 
>     Error: Subject
>               Df Sum Sq Mean Sq F value Pr(>F)
>     Residuals 17 250618   14742
> 
>     Error: Within
>                Df Sum Sq Mean Sq F value Pr(>F)
>     Days        1 162703  162703   169.4 <2e-16 ***
>     Residuals 161 154634     960
> 
>     and
> 
>     > anova(lmer(Reaction ~ Days + (1|Subject),sleepstudy))
>     Analysis of Variance Table
>          Df Sum Sq Mean Sq F value
>     Days  1 162703  162703   169.4
> 
>     You can get the residual Mean Sq F in the mixed model by looking at the
>     variance column of the Residual grouping under Random effects in
>     summary()-output.
> 
>     The advantage to mixed-effects models in this case is that you're doing
>     the regression explicitly.
> 
>     Best,
>     Phillip
> 
> 
> 
>     On 06/13/2016 01:43 AM, Sam Hardman [sah74] wrote:
>     > Hi Alex,
>     >
>     >
>     > The reason I was looking at using mixed models is because I have
>     > repeated measures for indivuals (i.e. each bird was tested three times
>     > with three different playback treatments). As far as I know ANOVA
>     can't
>     > control for this. I am wrong about this?
>     >
>     >
>     > You are correct that I have 40 animals in the experiment, with three
>     > treatments each that makes 120 measurements per response behaviour. I
>     > agree with you that the sample size is small which could cause
>     problems
>     > with reliability of results. If ANOVA could work then I will certainly
>     > look at that. How would I control for repeated measures?
>     >
>     >
>     > Thanks for your help, I appreciate it.
>     >
>     > Sam
>     >
>     >
>     ------------------------------------------------------------------------
>     > *Von:* Alex Fine <abfine at gmail.com <mailto:abfine at gmail.com>>
>     > *Gesendet:* Sonntag, 12. Juni 2016 23:10:59
>     > *An:* Phillip Alday
>     > *Cc:* Sam Hardman [sah74]; r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     > *Betreff:* Re: [R-sig-ME] P-values from interaction terms using lme4
>     >
>     > Hey Sam,
>     >
>     > I actually think mixed effects regression might be inappropriate
>     in this
>     > case.  Do I have it right that you have 40 total animals in the
>     > experiment?  You said you had 1 bird in the city center and 1 outside
>     > the city in 20 cities.
>     >
>     > If that's right, then the model you described (to take one of your
>     > examples) would be:
>     >
>     > Approach ~ PlayBack * UrbanRural + (1|ID)
>     >
>     > That's 3 * 2 - 1 = 5 coefficients in your model, plus a random
>     intercept
>     > for 20 different cities.  I don't think you have enough data to
>     fit such
>     > a model and trust the results.
>     >
>     > If you have a balanced design and you have clear a priori predictions
>     > about each of the contrasts in your design, I'd recommend just using
>     > ANOVA.  I don't think you gain very much from using MEMs in this case.
>     > You could use vanilla linear regression, but setting up the coding
>     > schemes for your two predictors is going to be so complicated that
>     it'll
>     > actually be much simpler to just do ANOVA + t-tests.
>     >
>     > Alex
>     >
>     > On Sun, Jun 12, 2016 at 4:31 AM, Phillip Alday
>     > <Phillip.Alday at unisa.edu.au <mailto:Phillip.Alday at unisa.edu.au>
>     <mailto:Phillip.Alday at unisa.edu.au
>     <mailto:Phillip.Alday at unisa.edu.au>>> wrote:
>     >
>     >     Hi Sam,
>     >
>     >     if you're getting p-values from lmer outside of a
>     likelihood-ratio test,
>     >     then you're using lmerTest, not lme4. lmerTest is designed to be a
>     >     drop-in replacement for lme4, but it does bring some extra
>     >     features/'complications' in the form of the denominator degrees of
>     >     freedom.
>     >
>     >     There are two easy options for getting ANOVA-style p-values:
>     >
>     >     1. Using lmerTest, you can just do
>     >     anova(mod1,ddf="Satterthwaite",type=2)
>     >
>     >     If you're using vanilla lme4, then you need to do this first:
>     >
>     >     library(lmerTest)
>     >     mod1 <- as(mod1,"merModLmerTest")
>     >
>     >     which will cast your model to an lmerTest model.
>     >
>     >     2. Using the car package:
>     >
>     >     library(car)
>     >     Anova(mod1,test.statistic="F",type=2)
>     >
>     >     If you fitted your model with maximum likelihood, i.e. with
>     REML=FALSE,
>     >     then you need to refit your model using REML first:
>     >
>     >     mod1 <- update(mod1,REML=TRUE)
>     >
>     >     For both options, you need to specify the types of test you're
>     doing. I
>     >     highly recommend Type 2, but there is a lot of material on
>     that debate,
>     >     search for e.g. Venables' "Exegeses on linear models", or look
>     at the
>     >     documentation for car::Anova(). Please note that the
>     distinction for
>     >     Type 2 vs Type 3 is *very* relevant for your question since you're
>     >     concerned about interaction terms.
>     >
>     >     For the lmerTest route, you can specify the approximation to
>     use for the
>     >     denominator degrees of freedom: Satterthwaite is much faster, but
>     >     Kenward-Roger is more accurate. For car::Anova(), the
>     F-statistic is
>     >     always computed with  Kenward-Roger (and only works for
>     REML-fitted
>     >     models for reasons that I can't explain quickly), but you have the
>     >     option of using a Chisq test statistic, which is equivalent to
>     assuming
>     >     that the denominator degrees of freedom are infinite, or
>     equivalently,
>     >     that your t-values for the coefficients are z-values.
>     >
>     >     These ANOVA-style tests are Wald tests and are asymptotically
>     equivalent
>     >     to the LR-tests, but are less conservative for finite samples.
>     >
>     >     Now, since you care about particular contrasts within the
>     model, you may
>     >     also just want to look at your model coefficients. Depending
>     on which
>     >     coding scheme you're using, the contrasts represented by your
>     model
>     >     coefficients might not be the ones you want, but packages like
>     lsmeans
>     >     (a regular mention on the list here and very well documented) can
>     >     compute all types of contrasts post-hoc. Rereading your
>     question, this
>     >     may be the best way to go for your target conclusion/result
>     statements.
>     >
>     >     Best,
>     >     Phillip
>     >
>     >
>     >     On Sat, 2016-06-11 at 16:41 +0000, Sam Hardman [sah74] wrote:
>     >     > Dear all,
>     >     >
>     >     >
>     >     > I have some data which I would like to analyse using lme4 and I
>     >     would really appreciate some help deciding what the best
>     method is.
>     >     >
>     >     >
>     >     > My experiment is as follows:
>     >     >
>     >     >
>     >     > I tested the responses of urban and rural great tits to
>     playbacks
>     >     of great tit song from a loud speaker within their territories.
>     >     >
>     >     >
>     >     > I created three playback song types:
>     >     >
>     >     > -undegraded
>     >     >
>     >     > -degraded
>     >     >
>     >     > -very degraded
>     >     >
>     >     >
>     >     > I played these to birds in 20 different cities. In each city I
>     >     tested one bird in the city centre and one bird in a rural
>     location
>     >     outside of the city (i.e. paired samples). Each bird received all
>     >     three playback types.
>     >     >
>     >     >
>     >     > I measured five different responses to these playbacks:
>     >     >
>     >     > -Time to sing back to playback (in seconds)
>     >     >
>     >     > -Time to sing back to playback (in seconds)
>     >     >
>     >     > -Time the bird spent within five metres of the speaker (in
>     seconds)
>     >     >
>     >     > -Number of times the bird flew over the speaker (count)
>     >     >
>     >     > -The closest approach the bird made to the speaker (in metres)
>     >     >
>     >     >
>     >     > For each of these five repsonses I would like to know if
>     there is
>     >     an interaction between habitat and playback type.
>     >     >
>     >     >
>     >     > So, I have a model which looks like this:
>     >     >
>     >     >
>     >     > mod1<-lmer(repsonse ~ Playback*UR + (1|ID))
>     >     >
>     >     >
>     >     > Where response is one of the five repsonse behaviours,
>     playback is
>     >     the playback type, UR is habitat type (urban or rural) and ID
>     is the
>     >     ID of the bird.
>     >     >
>     >     >
>     >     > This gives me results and P-Values but am not sure these
>     P-values
>     >     are valid and I think I should compare this model to a null
>     model to
>     >     get a valid P-values.
>     >     >
>     >     >
>     >     > So I can use a likelihood ratio tests to test for differences in
>     >     response by habitat type alone:
>     >     >
>     >     >
>     >     > mod1<-lmer(approach ~ UR + (1|Location))
>     >     > mod2<-lmer(approach ~ 1 + (1|Location))
>     >     > anova(mod1, mod2)
>     >     >
>     >     > or for differences in response according tom playback type
>     alone:
>     >     >
>     >     > mod1<-lmer(approach ~ Playback + (1|Location))
>     >     > mod2<-lmer(approach ~ 1 + (1|Location))
>     >     > anova(mod1, mod2)
>     >     >
>     >     > But how should I do this when there is an interaction term? I
>     >     deally I would like P-values for each playback type in interaction
>     >     with habitat. e.g.
>     >     >
>     >     > Undregraded playback * Habitat (urban/rural
>     >     > Degraded playback * Habitat (urban/rural)
>     >     > Very degraded playback * Habitat (urban/rural)
>     >     >
>     >     > This would allow me to say, for example, something like "urban
>     >     birds approached the speaker more closely than rural birds in
>     >     response to undegraded playbacks". I would like to do this
>     with each
>     >     of the five response behaviours.
>     >     >
>     >     > I would really appreciate any suggestions for the best way
>     forward
>     >     with this and apologies if this question is too simple for
>     this group.
>     >     >
>     >     > Best wishes,
>     >     > Sam
>     >     >
>     >     >
>     >     >
>     --------------------------------------------------------------------
>     >     > Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
>     >     >
>     >     > Aberystwyth - Wales' First University https://www.aber.ac.uk/en/
>     >     >
>     >     >       [[alternative HTML version deleted]]
>     >     >
>     >     > _______________________________________________
>     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     >     _______________________________________________
>     >     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     >
>     >
>     >
>     > --
>     > Alex Fine
>     > Ph. (336) 302-3251 <tel:(336)%20302-3251>
>     > web:  http://internal.psychology.illinois.edu/~abfine/
>     > <http://internal.psychology.illinois.edu/~abfine/AlexFineHome.html>
>     >
>     >
>     > --------------------------------------------------------------------
>     > Aberystwyth - Prifysgol Gyntaf Cymru https://www.aber.ac.uk/cy/
>     >
>     > Aberystwyth ? Wales? First University https://www.aber.ac.uk/en/
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bates at stat.wisc.edu  Wed Aug  9 16:59:32 2017
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 09 Aug 2017 14:59:32 +0000
Subject: [R-sig-ME] P-values from interaction terms using lme4
In-Reply-To: <598B2214.5000907@mpi.nl>
References: <DB5PR04MB14621A89AF305FEB4EDC7FE38B510@DB5PR04MB1462.eurprd04.prod.outlook.com>
 <1465720272.24053.96.camel@loki>
 <CAJ6ui+OyB_-KQ6B7oTPQ=NGRs_OV=o7DR9S=EG0vb_R-zbKAGg@mail.gmail.com>
 <DB5PR04MB14625C2A380ADE88080CB9C68B520@DB5PR04MB1462.eurprd04.prod.outlook.com>
 <598B174B.1040708@mpi.nl>
 <CAO7JsnRG8zTEVFamyaeu70E0HsGMKx6UaLZheUTgEN-_E6N3dA@mail.gmail.com>
 <598B2214.5000907@mpi.nl>
Message-ID: <CAO7JsnTzwD53PiU0Bqfos55bSx_yBUyRk0W+4ieip7T3K8vEgg@mail.gmail.com>

On Wed, Aug 9, 2017 at 9:54 AM Phillip Alday <phillip.alday at mpi.nl> wrote:

> On 08/09/2017 04:46 PM, Douglas Bates wrote:
>


> > Technically it is true that the number of parameters does not depend on
> > the number of random effects, only on the number of unique values in the
> > covariance matrices for the random effects.  However, I think that leads
> > to an undercount of the effective number of parameters when, say,
> > performing a likelihood ratio test of models that differ in their random
> > effects specification.
>
> This is related to the more general issue of degrees of freedom in mixed
> models, right?
>

Yes.

But in terms of estimation (especially as implemented in
> lme4/MixedModels.jl), increasing the levels of a random effect will
> generally provide better estimates, right?
>

Yes.  Or, to put it the other way, it is unrealistic to expect to obtain
precise estimates of variance components unless there is(are) a large
number of levels in the grouping factor(s) for the random effects.

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Wed Aug  9 17:14:30 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 17:14:30 +0200
Subject: [R-sig-ME] ERPs lme covariates
In-Reply-To: <598B26A5.5070608@mpi.nl>
References: <598B26A5.5070608@mpi.nl>
Message-ID: <598B26D6.6080500@mpi.nl>

Yes, this is one of the advantages of using mixed-effects models
compared to classical rmANOVA. But there are all sorts of subtle issues
with controlling co-variates:

http://www.johnmyleswhite.com/notebook/2016/02/25/a-variant-on-statistically-controlling-for-confounding-constructs-is-harder-than-you-think/
(and make sure to read the Westfall and Yarkoni paper linked there)

http://www.johnmyleswhite.com/notebook/2017/04/06/covariate-based-diagnostics-for-randomized-experiments-are-often-misleading/

although I do recommend including these covariates in general and
especially in psycholinguistic studies: https://arxiv.org/abs/1602.04565

Note, however, that lme is in the nlme package, while lmer is the
corresponding function from lme4. See
https://stats.stackexchange.com/q/5344/26743 for a comparison.

Phillip

On 05/12/2017 04:05 PM, Alexandre Obert wrote:
> Dear all,
> 
> I'm working on ERPs data from a language comprehension study and I'm
> confronting to some problems with items' features.
> Briefly, participants saw words on a screen and have to decide if
> they're meaningful or not.
> Some of them were meaningful (condition 1), others not (condition 2) and
> others were ambiguous (condition 3).
> Using classical ANOVA, I observed significant differences.
> However, words came with characteristics such as frequency, number of
> letters and so on...that I would like to control for.
> In other words, I would like to test the effect of the condition and
> control the words' features in a same analysis.
> 
> I think that lme from lme4() could compute such analysis, is-this right?
> 
> Regards,
>


From phillip.alday at mpi.nl  Wed Aug  9 17:41:32 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 17:41:32 +0200
Subject: [R-sig-ME] A mixed effect regression tool based on bayesian
 priors like bayesglm
In-Reply-To: <CALcwahN41htOSqF_E3LwyuaxqVuSFyW=Zx9Q-cW5x37rN4Eddw@mail.gmail.com>
References: <CALcwahN41htOSqF_E3LwyuaxqVuSFyW=Zx9Q-cW5x37rN4Eddw@mail.gmail.com>
Message-ID: <598B2D2C.7060407@mpi.nl>

Sidestepping your question a bit, you might want to consider the
rstanarm package instead of blme because it is more directly in the
Gelman/arm tradition/school of thought. You can move your arm::bayesglm
models to rstanarm::stan_glm and then use rstanarm:stan_glmer for the
mixed model. But only *you* can know / justify which priors you should
use -- default priors are just that, default and they may not always be
sensible for every case.

Phillip

On 05/17/2017 10:46 AM, Angelo D'Ambrosio wrote:
> I use extensively Gelman's bayesglm for the every day use due to the great
> stability of the estimates especially in the case of separation.
> 
> I needed an equivalent of empirical bayesian regularization for glm mixed
> effect models. These models are strongly influenced by extreme conditions
> (like conditional probabilities of zero and separation) and like usual
> logistic regression model they fail in these cases.
> 
> I found the blme package that does exactly what I need, solving the
> separation problem. Now the problem is to set it up in order to be work
> exactly as bayesglm, in order to achieve consistency in my analysis.
> Reading Gelman paper on bayesglm() I understood I should use a t
> distribution with 1 df (eg. Cauchy) and 2.5 scale, rescaling inputs:
> 
>     bglmer(Out ~ arm::rescale(Pred) + (1 | PatientID), family = binomial,
> Data.events, fixef.prior = t(df = 1, scale = 2.5))
> 
> Is it correct? My doubt is what to do with the cov.prior parameter; should
> I leave it as default (wishart) or should I put it to NULL? Also in
> Gelman's paper it is said that the intercept should have the same prior
> distribution but with scale 10, and I don't know how to specify a different
> prior for it.
> 
> Also, I'm starting to think that bayesglm doesn't rescale the inputs
> directly but scales the prior distribution according to the inputs. Am I
> right?
> 
> Can you help me with this?
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at mpi.nl  Wed Aug  9 17:53:05 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 17:53:05 +0200
Subject: [R-sig-ME] Mixed models for repeated measures with missing
	values
In-Reply-To: <fc7a4bb4-aa93-0ed5-6ade-330c2fd07ba1@uni-leipzig.de>
References: <fc7a4bb4-aa93-0ed5-6ade-330c2fd07ba1@uni-leipzig.de>
Message-ID: <598B2FE1.7010408@mpi.nl>

Instead of trying to determine the correct polynomial degree, why not
use a GAM and let the smoother do that work for you? If you absolutely
need to use a polynomial model, you can pick the degree via
cross-validation, but this is computationally expensive and only works
if you have enough data to be able to do cross-validation. For doing
this as a GAM, you can use either mgcv::gam() or gamm4::gamm().

Depending on how well that works, the heteroskedacity issue may solve
itself. But otherwise, I don't know if weights are really the correct
way to address that issue -- do you have a principled reason for saying
that some observations are more reliable / important than others? If
not, weights don't really make sense.

Finally, it is possible but a bit weird to have something as a fixed
effect and a grouping term in the random effects. Thierry Onkelinx has
posted an example online: https://rpubs.com/INBOstats/both_fixed_random
but again, I would see if using a GAMM makes all this moot.

Best,
Phillip

On 05/19/2017 12:06 PM, Hongmei Chen wrote:
> Dear mixed model users,
> 
> I have a question concerning using mixed models for repeated measures
> with missing values. I would like to test the effects of plant diversity
> (Div., continuous) on root growth rate (Y, continuous) over time (Time).
> However, time is not evenly spaced, thus I think it is better to use
> Time as a continuous term. In addition, the root growth rate - time
> relationship was not linear. Thus I used poly (Time, N) to account for
> the non-linear relationship.  Besides, the plots were randomly arranged
> in the 4 blocks, I would also like to account for the potential block
> effect.
> 
> I use lme from nlme for the data analyses.
> I first tested the polynomial order by increasing n from 2 to 3.
> However, AIC suggest that I should use 5 or 6. I am afraid I will over
> fit the data. thus I chose ploy(Time, 3).
> Mod1 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot, method="ML")
> 
> Because of repeated measurement, I included e.g. correlation= corRatio
> (form=~Time, nugget=T) to account for the dependence. I tested different
> correlation structures and chose the one with lowest AIC.
> Mod2 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot,
> method="REML", correlation=  corRatio (form=~Time, nugget=T))
> 
> After checking the residuals, I still could see some trend in time, and
> heterogeneity in residuals e.g. at different time. I further included
> "weights" argument in the model.
> Mod3 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot,
> method="REML", correlation=  corRatio (form=~Time, nugget=T),
> weights=varIdent(form=~1|plot))
> 
> My questions are
> 1) Should I go for higher order in polynomial term? For example 4
> 2) For the random term, I used the simplest one. Would you consider
> other options e.g. random = ~ploy(Time, 3)|block/plot
> 3) Can I use time as a continuous term in fixed part but as a factor in
> the random part or in the weights argument  like:
> weights=varIdent(form=~1|as.factor(Time))
> 
> Because of the missing observation values, I could only used mixed
> models for my data. I have googled this is for quite a long time but
> could not find a good example or solution. Any suggestions are welcome.
> 
> Kind regards,
> Hongmei Chen
>


From phillip.alday at mpi.nl  Wed Aug  9 18:26:09 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Wed, 9 Aug 2017 18:26:09 +0200
Subject: [R-sig-ME] Power calculations for lmer mixed designs
In-Reply-To: <5a5e6b68-9642-2251-2e22-60836fecc9c1@uni-potsdam.de>
References: <5947D210.7040508@mpi.nl> <5947D24E.3090207@mpi.nl>
 <5a5e6b68-9642-2251-2e22-60836fecc9c1@uni-potsdam.de>
Message-ID: <598B37A1.5000305@mpi.nl>


On 06/22/2017 01:43 PM, Diana Michl wrote:
::snip::

> My intercept and effect size is already on the logit scale - the
> intercept is 7.2. But whenever I enter it directly into the qlogis
> function, I'm warned that NaNs are produced. This happens whenever I
> enter anything over 1.0. Does this mean I actually need to enter a
> percentage rather than the absolute value...? Or is the problem an
> entirely different one?

I'm not sure this makes sense. Unfortunately, the terminology in
statistics for things like "link" and "response" scale is rather
confusing and unintuitive at times and it's easy to get mixed up which
scale we're talking about at the moment (0s and 1s in the dependent
variable? the scale of the coefficients, whatever that is called?). Any
of the q*() functions will return NAs if you give it something bigger
than 1.0 because 1.0 is per definition the maximum probability. So
you're asking for the value where the cumulative probability exceeds the
maximum probability, which is of course "huh, what?" or in R terms, NA.

If you know your coefficient is supposed to be 7.2 based on a previous
model, then it's already on the correct scale and you don't need to
convert it to logit scale. If you're starting off from percentages, then
you need to convert it.

(I had a mistake in my previous message -- the q*() functions don't give
the density, it gives the place where the cumulative probability. So
qlogis(0.5) give 0 because the probability of having a value between
-Inf and 0 on a logistic distribution is 0.5)

>
::snip::
>> So the redline represents the "ground truth", i.e. the real parameter
>> value (because you chose it) and the other plots tell your simulated
>> estimates -- how close they were (see esp. the CI plot).
> So if I'm seeing this correctly, this way of calculating power is not a
> direct one, but you're rather meant to draw your own conclusions from
> looking at the graphs of the simulations and get a general feel of how
> far off or on your effect size is?

More or less. You can also use the simulation results to directly give
you a power estimate without a graphical presentation. But yes, it's a
simulation based approach and not an analytic (formula-based) one.


>>> Is there a way to give power as a number between 0 and 1?
>>> - How to do this for more than 1 treatment (my attempts to do it for 4 
>>> all failed, I seem to miss places in the exampe I need to change. For 
>>> example, I tried adding values to the beta-qlogis line above and others, 
>>> but it gave errors)
>> You calculate your power based on the ability of models you fit to the
>> simulated datasets to detect the effect. The general work flow is:
>>
>> 1. define "ground truth" model based on some theoretical assumptions
>> 2. simulate lots of datasets of a certain size
>> 3. fit models to those datasets.
>> 4. number of models able to detect effect / number of models = power
>> 5. if power to low, repeat with bigger simulated datasets
> So you can't properly attempt this very way with 4 effects? The author
> implies that you can, but I'm getting the impression it'd be quite
> complicated... I'm not sure running each effect separately would be
> correct.

The interaction of main effects is just another effect from the model's
perspective, so you can model these separately. Each simulation includes
random draws from all of the model terms, so in that sense, you're
modelling everything at once. The CRAN version of the simr package
(which makes simulation-based power analyses a lot easier) unfortunately
requires a separate set of simulation runs for each model term. I had
been working on simultaneous testing, i.e. re-using simulation runs for
all the terms, but for various reasons never got around to making it
stable enough for the CRAN version. You can install it with devtools:

> devtools::install_github("palday/simr",ref="simultaneous")
> library(simr)
> ?powerSimSimultaneous
> ?powerSimMultiple


Best,
Phillip

>> There are also "analytic" tools that try to compute power without
>> simulation, see for exmaple Jake Westfall's Shiny apps (and read his
>> papers on power issues in mixed effects models!):
>>
>> https://jakewestfall.shinyapps.io/pangea/
>> https://jakewestfall.shinyapps.io/crossedpower/
> I'll try those, thanks very much!
> 
> Best
> Diana


From iss3ngard at gmail.com  Wed Aug  9 21:26:23 2017
From: iss3ngard at gmail.com (Tamara R)
Date: Wed, 9 Aug 2017 16:26:23 -0300
Subject: [R-sig-ME] is a mixed effect model appropiate?
Message-ID: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>

Hi, i'm working with survey data regarding leptospirosis knowledge,
attitudes and practices on residents from three slum settlements and i'm
using socio-demographic indicators, knowledge score and attitude score as
predictors of preventive practices score.
I started analyzing my data as a linear model with both categorical and
continuous predictors:

glm(practices~site + sex + education + occupation + knowledge score +
attitude score

But discussing the results with my phD advisor she suggested me to put site
as a random effect in a linear mixed model because of lack of independence
between observations from the same site:

lmer(practices~sex + education + occupation + knowledge score + attitude
score + (1|site))

Thing is that i have less than 100 observations and the variance of random
effects equals to 0. I read in a previous post on this group that it
indicates that the model could be simplified by removing the random effect
but i wish to know if simplifying my model (going back to the original
regression model) will be appropiate to model the lack of independence of
the data or should i also include random slopes for knowledge and attitude
scores into the model? Thanks in advance

Tamara Ricardo
Lic. en Biodiversidad - Becaria CONICET
FHUC - Universidad Nacional del Litoral
Ciudad Universitaria - Pje. el Pozo
Santa Fe (3000) - Argentina

	[[alternative HTML version deleted]]


From bakaburg1 at gmail.com  Wed Aug  9 17:43:53 2017
From: bakaburg1 at gmail.com (Angelo D'Ambrosio)
Date: Wed, 9 Aug 2017 17:43:53 +0200
Subject: [R-sig-ME] A mixed effect regression tool based on bayesian
 priors like bayesglm
In-Reply-To: <598B2D2C.7060407@mpi.nl>
References: <CALcwahN41htOSqF_E3LwyuaxqVuSFyW=Zx9Q-cW5x37rN4Eddw@mail.gmail.com>
 <598B2D2C.7060407@mpi.nl>
Message-ID: <CALcwahMV_gOiRVYP43eGHD03=4HOb9k9qPp5tfCAbS=rHOSc6Q@mail.gmail.com>

Thanks Philip,

I actually did that after suggestion by Gelman itself!

Sorry I didn't upgrade the thread...

Regards
Angelo

2017-08-09 17:41 GMT+02:00 Phillip Alday <phillip.alday at mpi.nl>:

> Sidestepping your question a bit, you might want to consider the
> rstanarm package instead of blme because it is more directly in the
> Gelman/arm tradition/school of thought. You can move your arm::bayesglm
> models to rstanarm::stan_glm and then use rstanarm:stan_glmer for the
> mixed model. But only *you* can know / justify which priors you should
> use -- default priors are just that, default and they may not always be
> sensible for every case.
>
> Phillip
>
> On 05/17/2017 10:46 AM, Angelo D'Ambrosio wrote:
> > I use extensively Gelman's bayesglm for the every day use due to the
> great
> > stability of the estimates especially in the case of separation.
> >
> > I needed an equivalent of empirical bayesian regularization for glm mixed
> > effect models. These models are strongly influenced by extreme conditions
> > (like conditional probabilities of zero and separation) and like usual
> > logistic regression model they fail in these cases.
> >
> > I found the blme package that does exactly what I need, solving the
> > separation problem. Now the problem is to set it up in order to be work
> > exactly as bayesglm, in order to achieve consistency in my analysis.
> > Reading Gelman paper on bayesglm() I understood I should use a t
> > distribution with 1 df (eg. Cauchy) and 2.5 scale, rescaling inputs:
> >
> >     bglmer(Out ~ arm::rescale(Pred) + (1 | PatientID), family = binomial,
> > Data.events, fixef.prior = t(df = 1, scale = 2.5))
> >
> > Is it correct? My doubt is what to do with the cov.prior parameter;
> should
> > I leave it as default (wishart) or should I put it to NULL? Also in
> > Gelman's paper it is said that the intercept should have the same prior
> > distribution but with scale 10, and I don't know how to specify a
> different
> > prior for it.
> >
> > Also, I'm starting to think that bayesglm doesn't rescale the inputs
> > directly but scales the prior distribution according to the inputs. Am I
> > right?
> >
> > Can you help me with this?
> >
> > Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Wed Aug  9 23:41:18 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Wed, 9 Aug 2017 21:41:18 +0000
Subject: [R-sig-ME] is a mixed effect model appropiate?
In-Reply-To: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
References: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
Message-ID: <1502314878.2877.13.camel@mpi.nl>

With only three sites, you don't have enough levels to use site as a
grouping variable / random effect. Random effects are *variance*
components and it doesn't make too much sense to discuss variance with
only three group members.

You could include site as a fixed effect, as you're doing now; adding
interaction terms would largely address the independence issue. Note
however that the inference from fixed and random effects is slightly
different: with fixed effects, you get estimates for each level, but
for random effects you get an estimate of the variance between / due to
sites and, optionally, a prediction for individual sites. So the random
effect will tend to generalize better to across all possible sites,
assuming that you sampled enough sites to begin with, while the fixed
effect will better model individual sites.

In your case, I would focus on including interaction terms before
modelling site. If you are able to do that, I would include site as a
fixed effect (too few levels as a random effect), but I suspect site
will correlate strongly with some of the other variables and so you
might have some issues with collinearity.

One final thing: you can fit (Gaussian) linear models with glm(), but
lm() will tend to be faster and offer some additional summary info. You
of course still need glm() for generalized variants such as logit, etc.
For lmer and glmer, the distinction is stricter -- you must use lmer()
for the (Gaussian) linear case and glmer() for the generalized case or
glmer() will complain.

Best,
Phillip

On Wed, 2017-08-09 at 16:26 -0300, Tamara R wrote:
> Hi, i'm working with survey data regarding leptospirosis knowledge,
> attitudes and practices on residents from three slum settlements and
> i'm
> using socio-demographic indicators, knowledge score and attitude
> score as
> predictors of preventive practices score.
> I started analyzing my data as a linear model with both categorical
> and
> continuous predictors:
> 
> glm(practices~site + sex + education + occupation + knowledge score +
> attitude score
> 
> But discussing the results with my phD advisor she suggested me to
> put site
> as a random effect in a linear mixed model because of lack of
> independence
> between observations from the same site:
> 
> lmer(practices~sex + education + occupation + knowledge score +
> attitude
> score + (1|site))
> 
> Thing is that i have less than 100 observations and the variance of
> random
> effects equals to 0. I read in a previous post on this group that it
> indicates that the model could be simplified by removing the random
> effect
> but i wish to know if simplifying my model (going back to the
> original
> regression model) will be appropiate to model the lack of
> independence of
> the data or should i also include random slopes for knowledge and
> attitude
> scores into the model? Thanks in advance
> 
> Tamara Ricardo
> Lic. en Biodiversidad - Becaria CONICET
> FHUC - Universidad Nacional del Litoral
> Ciudad Universitaria - Pje. el Pozo
> Santa Fe (3000) - Argentina
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From jpmcintyre at alaska.edu  Thu Aug 10 04:52:55 2017
From: jpmcintyre at alaska.edu (Julie McIntyre)
Date: Wed, 9 Aug 2017 18:52:55 -0800
Subject: [R-sig-ME] double repeated measures
Message-ID: <CAH3OF--Uwk0gWKnxyO4HpdjUdTMsGY8J+A6crA_TsnvAqpvY-A@mail.gmail.com>

Hello,

I am trying to fit a model to data that are recorded in a doubly-repeated
measures type design, and I'm having trouble with the syntax for lmer.  The
response is a count representing the number of animals harvested at each of
six locations during a hunting season.  Counts are recorded daily at each
location for a fixed period (about 45 days).  In addition, the daily counts
at each location have been repeated themselves over several years (about
30).  The dates of the counts are the same every year.  Additional
covariates are measured on a daily basis.

Graphically, for all locations there is a clear trend in count by day, with
some year-to-year variation.  There are also clear but weaker trends in
counts by year (for fixed day), with variation among locations.  The
general shape of the trend changes quite a bit depending on the day (e.g.,
early vs. late in the season).  That said, the main interest is in
understanding the influence of the covariates on harvest.

I believe the following code fits a random intercept and slope model to
daily counts within years, separately for each location.  This model fits
well, and allows testing of the covariate effects (X1 and X2).  However it
ignores the second layer of repetition and the trend in count by year,
within locations.

M1=lmer(log(Count+1)~X1+X2+Location+Day+(1+Day|Year), data=Harvest)

I would like to know the correct syntax to also include terms for the
repeated measurement by year, within locations.  This model might be close,
but I'm just not certain:

M2=lmer(log(Count+1)~X1+X2+Day+(1+Day|Year/Location)+(1+Year|Location),
data=Harvest)

I'd appreciate any suggestions or advice.  Thank you!

Julie McIntyre

	[[alternative HTML version deleted]]


From dexter.locke at gmail.com  Thu Aug 10 15:06:00 2017
From: dexter.locke at gmail.com (Dexter Locke)
Date: Thu, 10 Aug 2017 09:06:00 -0400
Subject: [R-sig-ME] double repeated measures
In-Reply-To: <CAH3OF--Uwk0gWKnxyO4HpdjUdTMsGY8J+A6crA_TsnvAqpvY-A@mail.gmail.com>
References: <CAH3OF--Uwk0gWKnxyO4HpdjUdTMsGY8J+A6crA_TsnvAqpvY-A@mail.gmail.com>
Message-ID: <CAA=SVwETMEet6R1HExmhq2a7B5OC9j-eA0dE0DGjstcniD6HAg@mail.gmail.com>

Hi,

While this doesn't address the question about repeated measures, consider
looking at

O?Hara, R. B., Kotze, D. J., O ?Hara, R. B., & Kotze, D. J. (2010). Do not
log-transform count data. Methods in Ecology and Evolution, 1(2), 118?122.
https://doi.org/10.1111/j.2041-210X.2010.00021.x

for the left-hand side of the model.

- Dexter


On Wed, Aug 9, 2017 at 10:52 PM, Julie McIntyre <jpmcintyre at alaska.edu>
wrote:

> Hello,
>
> I am trying to fit a model to data that are recorded in a doubly-repeated
> measures type design, and I'm having trouble with the syntax for lmer.  The
> response is a count representing the number of animals harvested at each of
> six locations during a hunting season.  Counts are recorded daily at each
> location for a fixed period (about 45 days).  In addition, the daily counts
> at each location have been repeated themselves over several years (about
> 30).  The dates of the counts are the same every year.  Additional
> covariates are measured on a daily basis.
>
> Graphically, for all locations there is a clear trend in count by day, with
> some year-to-year variation.  There are also clear but weaker trends in
> counts by year (for fixed day), with variation among locations.  The
> general shape of the trend changes quite a bit depending on the day (e.g.,
> early vs. late in the season).  That said, the main interest is in
> understanding the influence of the covariates on harvest.
>
> I believe the following code fits a random intercept and slope model to
> daily counts within years, separately for each location.  This model fits
> well, and allows testing of the covariate effects (X1 and X2).  However it
> ignores the second layer of repetition and the trend in count by year,
> within locations.
>
> M1=lmer(log(Count+1)~X1+X2+Location+Day+(1+Day|Year), data=Harvest)
>
> I would like to know the correct syntax to also include terms for the
> repeated measurement by year, within locations.  This model might be close,
> but I'm just not certain:
>
> M2=lmer(log(Count+1)~X1+X2+Day+(1+Day|Year/Location)+(1+Year|Location),
> data=Harvest)
>
> I'd appreciate any suggestions or advice.  Thank you!
>
> Julie McIntyre
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From karistaeh at gmail.com  Thu Aug 10 16:52:33 2017
From: karistaeh at gmail.com (Karista Hudelson)
Date: Thu, 10 Aug 2017 10:52:33 -0400
Subject: [R-sig-ME] Comparing Model Performance Across Data Sets: report
	p values?
In-Reply-To: <598AD041.60000@mpi.nl>
References: <CAKeD0uiXtExnF8oOPi4QdHbhPyFFk6CeB2cJmVEnupfgiyC1Rg@mail.gmail.com>
 <CAJuCY5z4pfT4sG=aVaQHLmifxRChOyNBiOA5bk2CuU+8Nuiguw@mail.gmail.com>
 <5982E187.6010901@mpi.nl>
 <CAKeD0ujPLa7NJLWNL8996=MLaa+R7X8WFGxgPmOV8DQQ=Uf+Kg@mail.gmail.com>
 <598AD041.60000@mpi.nl>
Message-ID: <CAKeD0uigDoFJuu2U9cUvpzFVMzuv5cip+ryR1+nEFQ9nmdEOZQ@mail.gmail.com>

Hello Phillip (and List),

Thank you again for your careful consideration of my question.  Setting
REML to False was really helpful!  In the end I decided to go ahead and
break the data into two phases and then apply the model.  I tested the
power of the model on the two subsets to determine if my n values were
sufficient for the interpretation of the p values.  I think this approach,
rather than leaving the data all in one set and including phase as a
variable, more directly addresses the hypothesis I was testing.  You did
give me lots of "food for thought" which lead me in the right direction!

Happy researching all!
Karista

On Wed, Aug 9, 2017 at 5:05 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:

> Hi Karista,
>
> it is not surprising that the combined model has a poorer overall fit
> than the separate models, for two reasons:
>
> 1. It has to model more data.
> 2. In some sense, it has fewer "independent" (I'm not using this word in
> a rigorous sense!) parameters than two distinct models because the two
> phases share a common set of parameters and thus the two distinct phases
> bias each other.
>
> The latter point is an example of the variance-bias tradeoff (which
> really came to light with the Stein paradox for OLS) or equivalently the
> overfitting-underfitting continuum. There are lots of good resources on
> this, but I particularly like McElreath's discussion in his book
> Statistical Rethinking.
>
> The tl;dr version is that the combination model will often have a poorer
> fit on the current data (bias away from observed means,etc.) but
> generalize better to new data (less variance). Or expressed in terms of
> "fitting", the two within-phase models tend to overfit a little bit to
> particular details of the data within each phase and thus will
> generalize less well the combination model, which will tend to underfit
> the data within each phase but generalize better to new data because it
> doesn't capture as much noisy detail.
>
> I would modify your combination model in one way though: I would include
> a main effect for phase.
>
> Also, when comparing models with different fixed-effects structures, it
> is important to use ML, i.e. set REML=FALSE, because the REML criterion
> is dependent on the fixed-effects parameterisation.
>
> This doesn't answer your questions directly, but hopefully gives you
> more food for thought. :)
>
> Best,
> Phillip
>
> On 08/08/2017 06:38 PM, Karista Hudelson wrote:
> > Hello again List,
> >
> > Thanks for the clarification question Thierry.  I want to compare the
> > predictive ability of the model terms between the two phases.  For
> > instance, is Sea Ice more important in phase 1?  This comparison is
> > confounded somewhat by the unequal sample sizes in the phases I think,
> > but am not sure.  Maybe that is part of my question: should I focus less
> > on the p values (as Phillip recommends in his first point I think) and
> > instead look at the overall model fit for each phase?
> >
> > Phillip, thank you for your second suggestion!  I followed your advice
> > and included Phase in the model and also tried running it with
> > interactions between the fixed effects and phase.
> >
> > *_Here is the model without phase:_*
> >
> > FSVlmer1a<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_MST+
> Summer_Rain+(1|WA),data=FSV2)
> >
> > REML criterion at convergence: -389.3
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -6.1650 -0.6235 -0.0447  0.6380  3.0889
> >
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  WA       (Intercept) 0.11493  0.3390
> >  Residual             0.03244  0.1801
> > Number of obs: 790, groups:  WA, 5
> >
> > Fixed effects:
> >                   Estimate Std. Error         df t value Pr(>|t|)
> > (Intercept)     -1.064e+00  1.971e-01  1.130e+01  -5.399 0.000195 ***
> > Length           2.204e-02  1.105e-03  7.817e+02  19.952  < 2e-16 ***
> > Res_Sea_Ice_Dur  7.917e-04  2.977e-04  7.813e+02   2.660 0.007978 **
> > Spring_MST       1.892e-02  4.514e-03  7.812e+02   4.190 3.11e-05 ***
> > Summer_Rain     -2.194e-03  3.650e-04  7.811e+02  -6.011 2.82e-09 ***
> > ---
> >> sem.model.fits(FSVlmer1a)
> >            Class   Family     Link   n Marginal Conditional
> > 1 merModLmerTest gaussian identity 790 0.127793   0.8080115
> >
> >> AIC(FSVlmer1a)
> > [1] -375.2507
> >
> > *_Same model with Phase interactions:_*
> >
> >>
> > FSV2lmer1bi<-lmer(logHg~Length*Phase+Res_Sea_Ice_Dur*
> Phase+Spring_MST*Phase+Summer_Rain*Phase+(1|WA),data=FSV2)
> >
> > REML criterion at convergence: -360.9
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -6.2490 -0.6285 -0.0176  0.6076  3.1211
> >
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  WA       (Intercept) 0.11988  0.3462
> >  Residual             0.03195  0.1788
> > Number of obs: 790, groups:  WA, 5
> >
> > Fixed effects:
> >                            Estimate Std. Error         df t value
> > Pr(>|t|)
> > (Intercept)              -1.179e+00  2.122e-01  1.400e+01  -5.556
> > 7.10e-05 ***
> > Length                    2.146e-02  1.204e-03  7.767e+02  17.827  <
> > 2e-16 ***
> > *Phasepre                  8.858e-01  3.945e-01  7.765e+02   2.246
> > 0.025014 *  *
> > Res_Sea_Ice_Dur           1.389e-03  3.963e-04  7.763e+02   3.504
> > 0.000484 ***
> > Spring_MST                1.680e-02  4.924e-03  7.761e+02   3.411
> > 0.000681 ***
> > Summer_Rain              -2.254e-03  3.980e-04  7.760e+02  -5.664
> > 2.08e-08 ***
> > *Length:Phasepre           2.582e-03  2.917e-03  7.762e+02   0.885
> > 0.376294    *
> > *Phasepre:Res_Sea_Ice_Dur -4.806e-03  1.607e-03  7.764e+02  -2.990
> > 0.002876 ** *
> > *Phasepre:Spring_MST      -8.681e-03  2.147e-02  7.760e+02  -0.404
> > 0.686088    *
> > *Phasepre:Summer_Rain     -4.634e-03  2.072e-03  7.764e+02  -2.236
> > 0.025636 *  *
> >
> >> AIC(FSV2lmer1bi)
> > [1] -336.8567
> >
> >> sem.model.fits(FSV2lmer1bi,aicc=T)
> >            Class   Family     Link   n Marginal Conditional
> > 1 merModLmerTest gaussian identity 790 0.126233   0.8161111
> >
> > So the overall fit metrics for these two models are not so different,
> > and the simpler one is a bit better.
> >
> > And in case it would be helpful/interesting, here are the fits of the
> > models for phase 1 and phase 2 (which were described in my first
> question):
> >
> > FSV2lmer1apre<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_
> MST+Summer_Rain+(1|WA),data=FSV2pre)
> > # AIC 10.06269, R2s:0.1508716   0.7681201
> >
> > FSV2lmer1apost<-lmer(logHg~Length+Res_Sea_Ice_Dur+Spring_
> MST+Summer_Rain+(1|WA),data=FSV2post)
> > # AIC -335.1748, R2s: 0.1233518   0.8228584
> >
> > Thank you Phillip and Thierry for your kind and encouraging attention to
> > this question.  I hope I can trouble you and the rest of the list for a
> > bit more instruction on this/these questions, as this issue is the crux
> > of the interpretation of this data.
> >
> > Looking forward to your thoughts and suggestions,
> > Karista
> >
> >
> > On Thu, Aug 3, 2017 at 4:40 AM, Phillip Alday <phillip.alday at mpi.nl
> > <mailto:phillip.alday at mpi.nl>> wrote:
> >
> >     Dear Karista,
> >
> >     as Thierry said, knowing more about the inferences you want to make
> will
> >     get you better advice here. That said, I do have two suggestions in
> the
> >     meantime:
> >
> >     1. Don't focus on significance, especially of individual predictors,
> as
> >     much as estimates and overall model fit / predictive ability. (cf.
> The
> >     New Statistics, The Difference between Significant and Insignificant
> is
> >     not itself Significant, Choosing prediction over explanation in
> >     psychology, etc.)
> >
> >     2. Put all your data into one model and include time period as a
> fixed
> >     effect. Such pooling will generally help all your estimates;
> moreover,
> >     it gives you a more principled way to compare time periods (both in
> the
> >     main effect of time period and in its interactions with individual
> >     variables).
> >
> >     Best,
> >     Phillip
> >
> >     On 08/03/2017 10:20 AM, Thierry Onkelinx wrote:
> >     > Dear Karista,
> >     >
> >     > Much depends on what you want to compare between the models. The
> >     parameter
> >     > estimates? The predicted values? The goodness of fit? You 'll need
> >     to make
> >     > that clear.
> >     >
> >     > Best regards,
> >     >
> >     >
> >     > ir. Thierry Onkelinx
> >     > Instituut voor natuur- en bosonderzoek / Research Institute for
> >     Nature and
> >     > Forest
> >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance
> >     > Kliniekstraat 25
> >     > 1070 Anderlecht
> >     > Belgium
> >     >
> >     > To call in the statistician after the experiment is done may be no
> >     more
> >     > than asking him to perform a post-mortem examination: he may be
> >     able to say
> >     > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >     > The plural of anecdote is not data. ~ Roger Brinner
> >     > The combination of some data and an aching desire for an answer
> >     does not
> >     > ensure that a reasonable answer can be extracted from a given body
> >     of data.
> >     > ~ John Tukey
> >     >
> >     > 2017-08-02 19:54 GMT+02:00 Karista Hudelson <karistaeh at gmail.com
> >     <mailto:karistaeh at gmail.com>>:
> >     >
> >     >> Hello All,
> >     >>
> >     >> I am comparing the fit of a mixed model on different time periods
> >     of a data
> >     >> set.  For the first time period I have 113 observations and only
> >     one of the
> >     >> fixed effects is significant.  For the second time period I have
> 322
> >     >> observations and all of the fixed effects are significant.
> >     Because n is
> >     >> important in the calculation of p, I'm not sure how or even if to
> >     interpret
> >     >> the differences in p values for the model terms in the two time
> >     periods.
> >     >> Does anyone have advice on how to compare the fit of the
> >     variables in the
> >     >> mixed model for the two data sets in a way that is less impacted
> >     by the
> >     >> difference in the number of observations?  Or is a difference of
> 209
> >     >> observations enough to drive these differences in p values?
> >     >>
> >     >> Time period 1 output:
> >     >> Fixed effects:
> >     >>                   Estimate Std. Error         df t value Pr(>|t|)
> >     >> (Intercept)      -0.354795   0.811871  82.140000  -0.437    0.663
> >     >> Length            0.024371   0.003536 106.650000   6.892 4.01e-10
> ***
> >     >> Res_Sea_Ice_Dur  -0.002408   0.002623 107.970000  -0.918    0.361
> >     >> Sp_MST        0.014259   0.024197 106.310000   0.589    0.557
> >     >> Summer_Rain      -0.005015   0.003536 107.970000  -1.418    0.159
> >     >>
> >     >>
> >     >> Time period 2 output:
> >     >> Fixed effects:
> >     >>                   Estimate Std. Error         df t value Pr(>|t|)
> >     >> (Intercept)     -1.183e+00  3.103e-01  6.650e+00  -3.812 0.007281
> **
> >     >> Length           1.804e-02  1.623e-03  3.151e+02  11.120  < 2e-16
> ***
> >     >> Res_Sea_Ice_Dur  2.206e-03  5.929e-04  3.153e+02   3.721 0.000235
> ***
> >     >> Spring_MST       1.022e-02  7.277e-03  3.150e+02   1.404 0.161319
> >     >> Summer_Rain     -1.853e-03  5.544e-04  3.150e+02  -3.343 0.000929
> ***
> >     >>
> >     >>
> >     >>
> >     >>
> >     >> Thanks in advance for your time and consideration of this
> question.
> >     >> Karista
> >     >>
> >     >>         [[alternative HTML version deleted]]
> >     >>
> >     >> _______________________________________________
> >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >>
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >
> >
> >
> >
> >
> > --
> > Karista
>



-- 
Karista

	[[alternative HTML version deleted]]


From iss3ngard at gmail.com  Thu Aug 10 18:33:12 2017
From: iss3ngard at gmail.com (Tamara R)
Date: Thu, 10 Aug 2017 13:33:12 -0300
Subject: [R-sig-ME] is a mixed effect model appropiate?
In-Reply-To: <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>
References: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
 <1502314878.2877.13.camel@mpi.nl>
 <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>
Message-ID: <CAD6xXtDVuAJ=JcDp3O+Rb7gYcFMwYwnP3U8=BzbUYBM46UAaRA@mail.gmail.com>

Thank you for your help!!! And how about including random slopes for
continuous predictors? Already know from descriptive statistics that means
for knowledge, attitude and practices scores differs between sites.

*Tamara Ricardo*
Lic. en Biodiversidad - Becaria CONICET
FHUC - Universidad Nacional del Litoral
Ciudad Universitaria - Pje. el Pozo
Santa Fe (3000) - Argentina

2017-08-09 19:06 GMT-03:00 Christian Ritz <ritz at nexs.ku.dk>:

> Dear Tamara,
>
> in my experience it works fine to fit a linear mixed model with lmer() in
> cases where there are only few levels of a random effect.
>
> Most of the time the estimated variance (component) (in your case the
> between-site variance) will be become 0, most likely reflecting that there
> was very little information in the data (not enough sites) for estimation
> of this parameter.
>
> I would prefer this approach (including site as a random effect) to using
> a decision rule where the number of levels of the random effect determines
> whether or not a random effect is included in a model.
>
> Best wishes Christian
>
> On 09-08-2017 23:41, Alday, Phillip wrote:
>
> With only three sites, you don't have enough levels to use site as a
> grouping variable / random effect. Random effects are *variance*
> components and it doesn't make too much sense to discuss variance with
> only three group members.
>
> You could include site as a fixed effect, as you're doing now; adding
> interaction terms would largely address the independence issue. Note
> however that the inference from fixed and random effects is slightly
> different: with fixed effects, you get estimates for each level, but
> for random effects you get an estimate of the variance between / due to
> sites and, optionally, a prediction for individual sites. So the random
> effect will tend to generalize better to across all possible sites,
> assuming that you sampled enough sites to begin with, while the fixed
> effect will better model individual sites.
>
> In your case, I would focus on including interaction terms before
> modelling site. If you are able to do that, I would include site as a
> fixed effect (too few levels as a random effect), but I suspect site
> will correlate strongly with some of the other variables and so you
> might have some issues with collinearity.
>
> One final thing: you can fit (Gaussian) linear models with glm(), but
> lm() will tend to be faster and offer some additional summary info. You
> of course still need glm() for generalized variants such as logit, etc.
> For lmer and glmer, the distinction is stricter -- you must use lmer()
> for the (Gaussian) linear case and glmer() for the generalized case or
> glmer() will complain.
>
> Best,
> Phillip
>
> On Wed, 2017-08-09 at 16:26 -0300, Tamara R wrote:
>
> Hi, i'm working with survey data regarding leptospirosis knowledge,
> attitudes and practices on residents from three slum settlements and
> i'm
> using socio-demographic indicators, knowledge score and attitude
> score as
> predictors of preventive practices score.
> I started analyzing my data as a linear model with both categorical
> and
> continuous predictors:
>
> glm(practices~site + sex + education + occupation + knowledge score +
> attitude score
>
> But discussing the results with my phD advisor she suggested me to
> put site
> as a random effect in a linear mixed model because of lack of
> independence
> between observations from the same site:
>
> lmer(practices~sex + education + occupation + knowledge score +
> attitude
> score + (1|site))
>
> Thing is that i have less than 100 observations and the variance of
> random
> effects equals to 0. I read in a previous post on this group that it
> indicates that the model could be simplified by removing the random
> effect
> but i wish to know if simplifying my model (going back to the
> original
> regression model) will be appropiate to model the lack of
> independence of
> the data or should i also include random slopes for knowledge and
> attitude
> scores into the model? Thanks in advance
>
> Tamara Ricardo
> Lic. en Biodiversidad - Becaria CONICET
> FHUC - Universidad Nacional del Litoral
> Ciudad Universitaria - Pje. el Pozo
> Santa Fe (3000) - Argentina
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From ritz at nexs.ku.dk  Thu Aug 10 00:06:33 2017
From: ritz at nexs.ku.dk (Christian Ritz)
Date: Thu, 10 Aug 2017 00:06:33 +0200
Subject: [R-sig-ME] is a mixed effect model appropiate?
In-Reply-To: <1502314878.2877.13.camel@mpi.nl>
References: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
 <1502314878.2877.13.camel@mpi.nl>
Message-ID: <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>

Dear Tamara,

in my experience it works fine to fit a linear mixed model with lmer() 
in cases where there are only few levels of a random effect.

Most of the time the estimated variance (component) (in your case the 
between-site variance) will be become 0, most likely reflecting that 
there was very little information in the data (not enough sites) for 
estimation of this parameter.

I would prefer this approach (including site as a random effect) to 
using a decision rule where the number of levels of the random effect 
determines whether or not a random effect is included in a model.

Best wishes Christian


On 09-08-2017 23:41, Alday, Phillip wrote:
> With only three sites, you don't have enough levels to use site as a
> grouping variable / random effect. Random effects are *variance*
> components and it doesn't make too much sense to discuss variance with
> only three group members.
>
> You could include site as a fixed effect, as you're doing now; adding
> interaction terms would largely address the independence issue. Note
> however that the inference from fixed and random effects is slightly
> different: with fixed effects, you get estimates for each level, but
> for random effects you get an estimate of the variance between / due to
> sites and, optionally, a prediction for individual sites. So the random
> effect will tend to generalize better to across all possible sites,
> assuming that you sampled enough sites to begin with, while the fixed
> effect will better model individual sites.
>
> In your case, I would focus on including interaction terms before
> modelling site. If you are able to do that, I would include site as a
> fixed effect (too few levels as a random effect), but I suspect site
> will correlate strongly with some of the other variables and so you
> might have some issues with collinearity.
>
> One final thing: you can fit (Gaussian) linear models with glm(), but
> lm() will tend to be faster and offer some additional summary info. You
> of course still need glm() for generalized variants such as logit, etc.
> For lmer and glmer, the distinction is stricter -- you must use lmer()
> for the (Gaussian) linear case and glmer() for the generalized case or
> glmer() will complain.
>
> Best,
> Phillip
>
> On Wed, 2017-08-09 at 16:26 -0300, Tamara R wrote:
>> Hi, i'm working with survey data regarding leptospirosis knowledge,
>> attitudes and practices on residents from three slum settlements and
>> i'm
>> using socio-demographic indicators, knowledge score and attitude
>> score as
>> predictors of preventive practices score.
>> I started analyzing my data as a linear model with both categorical
>> and
>> continuous predictors:
>>
>> glm(practices~site + sex + education + occupation + knowledge score +
>> attitude score
>>
>> But discussing the results with my phD advisor she suggested me to
>> put site
>> as a random effect in a linear mixed model because of lack of
>> independence
>> between observations from the same site:
>>
>> lmer(practices~sex + education + occupation + knowledge score +
>> attitude
>> score + (1|site))
>>
>> Thing is that i have less than 100 observations and the variance of
>> random
>> effects equals to 0. I read in a previous post on this group that it
>> indicates that the model could be simplified by removing the random
>> effect
>> but i wish to know if simplifying my model (going back to the
>> original
>> regression model) will be appropiate to model the lack of
>> independence of
>> the data or should i also include random slopes for knowledge and
>> attitude
>> scores into the model? Thanks in advance
>>
>> Tamara Ricardo
>> Lic. en Biodiversidad - Becaria CONICET
>> FHUC - Universidad Nacional del Litoral
>> Ciudad Universitaria - Pje. el Pozo
>> Santa Fe (3000) - Argentina
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Thu Aug 10 23:05:27 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Thu, 10 Aug 2017 17:05:27 -0400
Subject: [R-sig-ME] Comparing variance components of crossed effects models
 fit with lme4 and nlme
Message-ID: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>

Hi all,

I'm trying to fit models with a) crossed random effects and b) a specific
residual structure (auto-correlation). Based on my understanding of what
nlme and lme4 do well, I would normally turn to lme4 to fit a model with
crossed random effects, but because I'm trying to structure the residuals,
I am trying nlme.

In trying to fit and compare the same variance components (no fixed
effects) model using lme4 and nlme, I found the output is similar but a bit
different. Specifically, the standard deviations of the random effects and
the log-likelihood statistics are different. Would you expect the output to
be a bit different?

The models I fit to compare the output are here, though the output is also
here:
https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/


library(lme4)
library(nlme)

m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data = Penicillin)
m_lme4

m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample = ~ 1), data
= Penicillin)
m_nlme


?Thank you for considering this question,
Josh?

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
?&?
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Thu Aug 10 23:28:56 2017
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 10 Aug 2017 21:28:56 +0000
Subject: [R-sig-ME] double repeated measures
In-Reply-To: <CAA=SVwETMEet6R1HExmhq2a7B5OC9j-eA0dE0DGjstcniD6HAg@mail.gmail.com>
References: <CAH3OF--Uwk0gWKnxyO4HpdjUdTMsGY8J+A6crA_TsnvAqpvY-A@mail.gmail.com>
 <CAA=SVwETMEet6R1HExmhq2a7B5OC9j-eA0dE0DGjstcniD6HAg@mail.gmail.com>
Message-ID: <87A10D58-3B97-4698-8185-A6DA4A0F93E1@anu.edu.au>

All that the simulations in the O?Hara et al paper show is the E[log(y)] does not equal log(E[y]), where E[] is expectation.
The O?Hara et al paper?s claim that "the transformations performed poorly? is just wrong, as it relates to what
their simulations might demonstrate.

See https://stats.stackexchange.com/questions/114848/negative-binomial-glm-vs-log-transforming-for-count-data-increased-type-i-erro/215080#215080
and the following paper that discusses the same sort of issue for RNA-Seq gene expression counts:
Law, CW, Chen, Y, Shi, W, Smyth, GK (2014). Voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biology 15, R29. http://genomebiology.com/2014/15/2/R29

I have an immediate interest in the equivalent issue for glmer models, used
for insect dose-mortality data where the error is a version of over-dispersed
binomial, with the amount of over-dispersion greatest around 50% mortality
and reducing at high mortalities.  Working with transformed mortality and
an lmer() model does a much better job of modeling the within replicate
variation than anything that one can readily do with a glmer() model that
is set up to (strictly) handle only binomial error.  One possibility for adapting
glmer() may be to apply weights that are designed to ?fix up? the within
replicate variance structure ? my impression is, however, that this adjusts
both levels of the variance structure.  The attempt to incorporate observation
level random effects led (at least when I tried to fit a model that had random
slopes and intercepts) to a message that the model was over-parameterized.

The vignette cfAnalyses.html that can be found at
https://github.com/jhmaindonald/qra-R-package/tree/master/vignettes
looks at this issue, plus outliers issues!  Practical data analysis can get
very messy!


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 11/08/2017, at 01:06, Dexter Locke <dexter.locke at gmail.com<mailto:dexter.locke at gmail.com>> wrote:

Hi,

While this doesn't address the question about repeated measures, consider
looking at

O?Hara, R. B., Kotze, D. J., O ?Hara, R. B., & Kotze, D. J. (2010). Do not
log-transform count data. Methods in Ecology and Evolution, 1(2), 118?122.
https://doi.org/10.1111/j.2041-210X.2010.00021.x

for the left-hand side of the model.

- Dexter


On Wed, Aug 9, 2017 at 10:52 PM, Julie McIntyre <jpmcintyre at alaska.edu>
wrote:

Hello,

I am trying to fit a model to data that are recorded in a doubly-repeated
measures type design, and I'm having trouble with the syntax for lmer.  The
response is a count representing the number of animals harvested at each of
six locations during a hunting season.  Counts are recorded daily at each
location for a fixed period (about 45 days).  In addition, the daily counts
at each location have been repeated themselves over several years (about
30).  The dates of the counts are the same every year.  Additional
covariates are measured on a daily basis.

Graphically, for all locations there is a clear trend in count by day, with
some year-to-year variation.  There are also clear but weaker trends in
counts by year (for fixed day), with variation among locations.  The
general shape of the trend changes quite a bit depending on the day (e.g.,
early vs. late in the season).  That said, the main interest is in
understanding the influence of the covariates on harvest.

I believe the following code fits a random intercept and slope model to
daily counts within years, separately for each location.  This model fits
well, and allows testing of the covariate effects (X1 and X2).  However it
ignores the second layer of repetition and the trend in count by year,
within locations.

M1=lmer(log(Count+1)~X1+X2+Location+Day+(1+Day|Year), data=Harvest)

I would like to know the correct syntax to also include terms for the
repeated measurement by year, within locations.  This model might be close,
but I'm just not certain:

M2=lmer(log(Count+1)~X1+X2+Day+(1+Day|Year/Location)+(1+Year|Location),
data=Harvest)

I'd appreciate any suggestions or advice.  Thank you!

Julie McIntyre

       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Fri Aug 11 12:23:39 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Fri, 11 Aug 2017 12:23:39 +0200
Subject: [R-sig-ME] is a mixed effect model appropiate?
In-Reply-To: <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>
References: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
 <1502314878.2877.13.camel@mpi.nl>
 <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>
Message-ID: <c5701e8e-fd9e-dae5-e00b-b1f61dd97595@psychologie.uzh.ch>

Whereas it is certainly possible to do so, the problem of estimating 
random-effects parameters for a grouping factor with very few levels 
(e.g., 3) is that usually the power for detecting fixed effects suffers 
quite considerably.

Jake Westfall and colleagues show this quite convincingly in the context 
of linear mixed models and models with multiple independent (i.e., 
crossed) random-effects grouping factors:
http://jakewestfall.org/publications/crossed_power_JEPG.pdf

Obviously the situation here is different, but I would not be surprised 
if a similar problem holds. So one more vote for Phillip's comment from me.

Cheers,
Henrik


Am 10.08.2017 um 00:06 schrieb Christian Ritz:
> Dear Tamara,
> 
> in my experience it works fine to fit a linear mixed model with lmer()
> in cases where there are only few levels of a random effect.
> 
> Most of the time the estimated variance (component) (in your case the
> between-site variance) will be become 0, most likely reflecting that
> there was very little information in the data (not enough sites) for
> estimation of this parameter.
> 
> I would prefer this approach (including site as a random effect) to
> using a decision rule where the number of levels of the random effect
> determines whether or not a random effect is included in a model.
> 
> Best wishes Christian
> 
> 
> On 09-08-2017 23:41, Alday, Phillip wrote:
>> With only three sites, you don't have enough levels to use site as a
>> grouping variable / random effect. Random effects are *variance*
>> components and it doesn't make too much sense to discuss variance with
>> only three group members.
>>
>> You could include site as a fixed effect, as you're doing now; adding
>> interaction terms would largely address the independence issue. Note
>> however that the inference from fixed and random effects is slightly
>> different: with fixed effects, you get estimates for each level, but
>> for random effects you get an estimate of the variance between / due to
>> sites and, optionally, a prediction for individual sites. So the random
>> effect will tend to generalize better to across all possible sites,
>> assuming that you sampled enough sites to begin with, while the fixed
>> effect will better model individual sites.
>>
>> In your case, I would focus on including interaction terms before
>> modelling site. If you are able to do that, I would include site as a
>> fixed effect (too few levels as a random effect), but I suspect site
>> will correlate strongly with some of the other variables and so you
>> might have some issues with collinearity.
>>
>> One final thing: you can fit (Gaussian) linear models with glm(), but
>> lm() will tend to be faster and offer some additional summary info. You
>> of course still need glm() for generalized variants such as logit, etc.
>> For lmer and glmer, the distinction is stricter -- you must use lmer()
>> for the (Gaussian) linear case and glmer() for the generalized case or
>> glmer() will complain.
>>
>> Best,
>> Phillip
>>
>> On Wed, 2017-08-09 at 16:26 -0300, Tamara R wrote:
>>> Hi, i'm working with survey data regarding leptospirosis knowledge,
>>> attitudes and practices on residents from three slum settlements and
>>> i'm
>>> using socio-demographic indicators, knowledge score and attitude
>>> score as
>>> predictors of preventive practices score.
>>> I started analyzing my data as a linear model with both categorical
>>> and
>>> continuous predictors:
>>>
>>> glm(practices~site + sex + education + occupation + knowledge score +
>>> attitude score
>>>
>>> But discussing the results with my phD advisor she suggested me to
>>> put site
>>> as a random effect in a linear mixed model because of lack of
>>> independence
>>> between observations from the same site:
>>>
>>> lmer(practices~sex + education + occupation + knowledge score +
>>> attitude
>>> score + (1|site))
>>>
>>> Thing is that i have less than 100 observations and the variance of
>>> random
>>> effects equals to 0. I read in a previous post on this group that it
>>> indicates that the model could be simplified by removing the random
>>> effect
>>> but i wish to know if simplifying my model (going back to the
>>> original
>>> regression model) will be appropiate to model the lack of
>>> independence of
>>> the data or should i also include random slopes for knowledge and
>>> attitude
>>> scores into the model? Thanks in advance
>>>
>>> Tamara Ricardo
>>> Lic. en Biodiversidad - Becaria CONICET
>>> FHUC - Universidad Nacional del Litoral
>>> Ciudad Universitaria - Pje. el Pozo
>>> Santa Fe (3000) - Argentina
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
>


From thierry.onkelinx at inbo.be  Fri Aug 11 14:38:41 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 11 Aug 2017 14:38:41 +0200
Subject: [R-sig-ME] Comparing variance components of crossed effects
 models fit with lme4 and nlme
In-Reply-To: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
References: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
Message-ID: <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>

Dear Joshua,

Crossed random effects are difficult to specify in nlme. I think that you
have to use pdBlocked() in the specification.

When I need correlation I often use INLA (r-inla.org). It allows for
correlated random effects. Crossed random effects are no problem.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-10 23:05 GMT+02:00 Joshua Rosenberg <jmichaelrosenberg at gmail.com>:

> Hi all,
>
> I'm trying to fit models with a) crossed random effects and b) a specific
> residual structure (auto-correlation). Based on my understanding of what
> nlme and lme4 do well, I would normally turn to lme4 to fit a model with
> crossed random effects, but because I'm trying to structure the residuals,
> I am trying nlme.
>
> In trying to fit and compare the same variance components (no fixed
> effects) model using lme4 and nlme, I found the output is similar but a bit
> different. Specifically, the standard deviations of the random effects and
> the log-likelihood statistics are different. Would you expect the output to
> be a bit different?
>
> The models I fit to compare the output are here, though the output is also
> here:
> https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/
>
>
> library(lme4)
> library(nlme)
>
> m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data =
> Penicillin)
> m_lme4
>
> m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample = ~ 1), data
> = Penicillin)
> m_nlme
>
>
> ?Thank you for considering this question,
> Josh?
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology
> ?&?
>  Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From apro at unimelb.edu.au  Fri Aug 11 12:52:03 2017
From: apro at unimelb.edu.au (Andrew Robinson)
Date: Fri, 11 Aug 2017 20:52:03 +1000
Subject: [R-sig-ME] is a mixed effect model appropiate?
In-Reply-To: <cd71c6a5126642319b9d7f7f9872753d@ME1PR01MB1442.ausprd01.prod.outlook.com>
References: <CAD6xXtCHP3B++XUgihcGxJFHFZeWb0tXbNAZLUU3n+N-OR_JzA@mail.gmail.com>
 <1502314878.2877.13.camel@mpi.nl>
 <06a9ea41-f99b-248c-ff48-1cceb6f1ab8d@nexs.ku.dk>
 <cd71c6a5126642319b9d7f7f9872753d@ME1PR01MB1442.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd4mLFzsVCRB1L=GUo5mFPU0xmVqoGe25SbWxJx0-a6U9g@mail.gmail.com>

Having a statistical history more closely related to experimental design
than to modeling, I am more relaxed about the use of a random effect to
capture even small numbers of levels.

The disadvantage of imposing a fixed effect where the design calls for a
random effect is that the random variation is being reduced in the model,
possibly unreasonably.

It really depends on what the intent of the model is.

The Westfall paper is interesting - thanks for pointing it out! - but I do
not think that its conclusions hold in this instance.  I vote for random
effects.

Best wishes,

Andrew


On 11 August 2017 at 20:23, Henrik Singmann <singmann at psychologie.uzh.ch>
wrote:

> Whereas it is certainly possible to do so, the problem of estimating
> random-effects parameters for a grouping factor with very few levels
> (e.g., 3) is that usually the power for detecting fixed effects suffers
> quite considerably.
>
> Jake Westfall and colleagues show this quite convincingly in the context
> of linear mixed models and models with multiple independent (i.e.,
> crossed) random-effects grouping factors:
> http://jakewestfall.org/publications/crossed_power_JEPG.pdf
>
> Obviously the situation here is different, but I would not be surprised
> if a similar problem holds. So one more vote for Phillip's comment from me.
>
> Cheers,
> Henrik
>
>
> Am 10.08.2017 um 00:06 schrieb Christian Ritz:
> > Dear Tamara,
> >
> > in my experience it works fine to fit a linear mixed model with lmer()
> > in cases where there are only few levels of a random effect.
> >
> > Most of the time the estimated variance (component) (in your case the
> > between-site variance) will be become 0, most likely reflecting that
> > there was very little information in the data (not enough sites) for
> > estimation of this parameter.
> >
> > I would prefer this approach (including site as a random effect) to
> > using a decision rule where the number of levels of the random effect
> > determines whether or not a random effect is included in a model.
> >
> > Best wishes Christian
> >
> >
> > On 09-08-2017 23:41, Alday, Phillip wrote:
> >> With only three sites, you don't have enough levels to use site as a
> >> grouping variable / random effect. Random effects are *variance*
> >> components and it doesn't make too much sense to discuss variance with
> >> only three group members.
> >>
> >> You could include site as a fixed effect, as you're doing now; adding
> >> interaction terms would largely address the independence issue. Note
> >> however that the inference from fixed and random effects is slightly
> >> different: with fixed effects, you get estimates for each level, but
> >> for random effects you get an estimate of the variance between / due to
> >> sites and, optionally, a prediction for individual sites. So the random
> >> effect will tend to generalize better to across all possible sites,
> >> assuming that you sampled enough sites to begin with, while the fixed
> >> effect will better model individual sites.
> >>
> >> In your case, I would focus on including interaction terms before
> >> modelling site. If you are able to do that, I would include site as a
> >> fixed effect (too few levels as a random effect), but I suspect site
> >> will correlate strongly with some of the other variables and so you
> >> might have some issues with collinearity.
> >>
> >> One final thing: you can fit (Gaussian) linear models with glm(), but
> >> lm() will tend to be faster and offer some additional summary info. You
> >> of course still need glm() for generalized variants such as logit, etc.
> >> For lmer and glmer, the distinction is stricter -- you must use lmer()
> >> for the (Gaussian) linear case and glmer() for the generalized case or
> >> glmer() will complain.
> >>
> >> Best,
> >> Phillip
> >>
> >> On Wed, 2017-08-09 at 16:26 -0300, Tamara R wrote:
> >>> Hi, i'm working with survey data regarding leptospirosis knowledge,
> >>> attitudes and practices on residents from three slum settlements and
> >>> i'm
> >>> using socio-demographic indicators, knowledge score and attitude
> >>> score as
> >>> predictors of preventive practices score.
> >>> I started analyzing my data as a linear model with both categorical
> >>> and
> >>> continuous predictors:
> >>>
> >>> glm(practices~site + sex + education + occupation + knowledge score +
> >>> attitude score
> >>>
> >>> But discussing the results with my phD advisor she suggested me to
> >>> put site
> >>> as a random effect in a linear mixed model because of lack of
> >>> independence
> >>> between observations from the same site:
> >>>
> >>> lmer(practices~sex + education + occupation + knowledge score +
> >>> attitude
> >>> score + (1|site))
> >>>
> >>> Thing is that i have less than 100 observations and the variance of
> >>> random
> >>> effects equals to 0. I read in a previous post on this group that it
> >>> indicates that the model could be simplified by removing the random
> >>> effect
> >>> but i wish to know if simplifying my model (going back to the
> >>> original
> >>> regression model) will be appropiate to model the lack of
> >>> independence of
> >>> the data or should i also include random slopes for knowledge and
> >>> attitude
> >>> scores into the model? Thanks in advance
> >>>
> >>> Tamara Ricardo
> >>> Lic. en Biodiversidad - Becaria CONICET
> >>> FHUC - Universidad Nacional del Litoral
> >>> Ciudad Universitaria - Pje. el Pozo
> >>> Santa Fe (3000) - Argentina
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >       [[alternative HTML version deleted]]
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03
8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From kbomb at umich.edu  Fri Aug 11 23:03:11 2017
From: kbomb at umich.edu (Dennis F. Kahlbaum)
Date: Fri, 11 Aug 2017 17:03:11 -0400
Subject: [R-sig-ME] PROC MIXED RANDOM equivalence in R nlme
Message-ID: <c4b37bd5-fd71-cd31-5113-c83d60cdfba5@umich.edu>

I am trying to reproduce some old SAS PROC MIXED code using R and nlme.

As background, the data consist of 300+ vehicle emission test results 
(grams/mile of THC over a given driving cycle) versus the gasoline fuel 
properties, which include: Read Vapor Pressure (rv), Temperature for 50% 
Evaporation (t5), Temperature for 90% Evaporation (t9), Aromatics (ar), 
Olefins, (ol), Sulfur (su), Oxygenate (ox), Benzene (bz), and a code 
identifying the study and vehicle (study_vehicle). All variables are 
real numbers except "study_vehicle", which is character. Unfortunately, 
since the data are confidential, I'm unable to provide an example.

The goal is to determine the relationship between the emissions and the 
fuel properties.

The original SAS v6.12 code is provided below:

------------------------------------------------------------------
/* READ DATA */
DATA emiss;
    INFILE 'data.tab' LRECL=8000 FIRSTOBS=2 DLM='09'X MISSOVER DSD;
    INPUT study_vehicle $ thc rv t5 t9 ar ol ox su bz;

/* CREATE NEW VARIABLE */
ln_thc = log (thc);

/* PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES */
PROC MIXED DATA=emiss MAXITER=1000 CONVH=1E-8 METHOD=REML NOCLPRINT 
NOITPRINT;
CLASS study_vehicle;

MODEL ln_thc = rv t5 t9 ar ol ox su bz
                 /S DDFM=RES;

RANDOM         int rv t5 t9 ar ol ox su bz
                /SUB=study_vehicle;
RUN;
------------------------------------------------------------------

The R code I've devised for reading/processing the data and to replicate 
the PROC MIXED statement is shown below:

------------------------------------------------------------------
# LOAD REQUIRED LIBRARY
library (?lmne?)

# FORCE R TO USE THE SAME "CONTRAST" METHOD AS SAS
options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))

# READ DATA (study_vehicle, thc, rv, t5, t9, ar, ol, ox, su, bz)
emiss <- read.table("data.csv", header=TRUE, sep=",") # NA for missing 
data (default)

# CREATE NEW VARIABLE
ln_thc <- log(thc)

# PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES
FitTHC <- lme(ln_thc ~ rv + t5 + t9 + ar + ol + ox + su + bz,
           data = emiss,
           random = ??????? | study_vehicle )

# OUTPUT THE RESULTS
summary(FitTHC)
------------------------------------------------------------------

A review of the dataframe "emiss" shows that all variables, except 
"study_vehicle", are of type "num". As expected, the character variable 
"study_vehicle" is of type "factor".  These properties match those from SAS.

As indicated by the questions marks, the problem I'm having is in 
constructing the equivalent R random code for the SAS RANDOM and any 
remaining settings (e.g. "/S DDFM=RES"). I've tried

random = ~1 + rv + t5 + t9 + ar + ol + ox + su + bz | study_vehicle)

but R gets caught in a processing loop that produces no errors or 
warnings, and no results, even after 15+ minutes of execution time. As I 
recall, the SAS code took less than 15 seconds back in 1999.

I have also tried

random = ~1 | study_vehicle)

and R immediately produces output.  However, although the regression 
coefficients are close to those from SAS, the degrees of freedom from 
SAS are higher than those from R.

Therefore, what is the equivalent R random code for the original SAS RANDOM?

Thanks!


From jake.a.westfall at gmail.com  Fri Aug 11 23:27:00 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Fri, 11 Aug 2017 16:27:00 -0500
Subject: [R-sig-ME] PROC MIXED RANDOM equivalence in R nlme
In-Reply-To: <c4b37bd5-fd71-cd31-5113-c83d60cdfba5@umich.edu>
References: <c4b37bd5-fd71-cd31-5113-c83d60cdfba5@umich.edu>
Message-ID: <CAE9_Wg48V_XUB5AwJBXBKY8m5ExxzCx8+CrUk6MkM8qMqToGJA@mail.gmail.com>

Dennis,

The two models are not equivalent because the R model uses an unstructured
covariance for the random effects (estimates all possible correlations
among random effects) while the SAS model uses a diagonal covariance matrix
(assumes no correlations among random effects). You can make them
equivalent by adding type=un to the end of the RANDOM statement in the SAS
model and you'll find that the SAS model takes a lot longer to run then :)

Jake

On Fri, Aug 11, 2017 at 4:03 PM, Dennis F. Kahlbaum <kbomb at umich.edu> wrote:

> I am trying to reproduce some old SAS PROC MIXED code using R and nlme.
>
> As background, the data consist of 300+ vehicle emission test results
> (grams/mile of THC over a given driving cycle) versus the gasoline fuel
> properties, which include: Read Vapor Pressure (rv), Temperature for 50%
> Evaporation (t5), Temperature for 90% Evaporation (t9), Aromatics (ar),
> Olefins, (ol), Sulfur (su), Oxygenate (ox), Benzene (bz), and a code
> identifying the study and vehicle (study_vehicle). All variables are real
> numbers except "study_vehicle", which is character. Unfortunately, since
> the data are confidential, I'm unable to provide an example.
>
> The goal is to determine the relationship between the emissions and the
> fuel properties.
>
> The original SAS v6.12 code is provided below:
>
> ------------------------------------------------------------------
> /* READ DATA */
> DATA emiss;
>    INFILE 'data.tab' LRECL=8000 FIRSTOBS=2 DLM='09'X MISSOVER DSD;
>    INPUT study_vehicle $ thc rv t5 t9 ar ol ox su bz;
>
> /* CREATE NEW VARIABLE */
> ln_thc = log (thc);
>
> /* PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES */
> PROC MIXED DATA=emiss MAXITER=1000 CONVH=1E-8 METHOD=REML NOCLPRINT
> NOITPRINT;
> CLASS study_vehicle;
>
> MODEL ln_thc = rv t5 t9 ar ol ox su bz
>                 /S DDFM=RES;
>
> RANDOM         int rv t5 t9 ar ol ox su bz
>                /SUB=study_vehicle;
> RUN;
> ------------------------------------------------------------------
>
> The R code I've devised for reading/processing the data and to replicate
> the PROC MIXED statement is shown below:
>
> ------------------------------------------------------------------
> # LOAD REQUIRED LIBRARY
> library (?lmne?)
>
> # FORCE R TO USE THE SAME "CONTRAST" METHOD AS SAS
> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
>
> # READ DATA (study_vehicle, thc, rv, t5, t9, ar, ol, ox, su, bz)
> emiss <- read.table("data.csv", header=TRUE, sep=",") # NA for missing
> data (default)
>
> # CREATE NEW VARIABLE
> ln_thc <- log(thc)
>
> # PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES
> FitTHC <- lme(ln_thc ~ rv + t5 + t9 + ar + ol + ox + su + bz,
>           data = emiss,
>           random = ??????? | study_vehicle )
>
> # OUTPUT THE RESULTS
> summary(FitTHC)
> ------------------------------------------------------------------
>
> A review of the dataframe "emiss" shows that all variables, except
> "study_vehicle", are of type "num". As expected, the character variable
> "study_vehicle" is of type "factor".  These properties match those from SAS.
>
> As indicated by the questions marks, the problem I'm having is in
> constructing the equivalent R random code for the SAS RANDOM and any
> remaining settings (e.g. "/S DDFM=RES"). I've tried
>
> random = ~1 + rv + t5 + t9 + ar + ol + ox + su + bz | study_vehicle)
>
> but R gets caught in a processing loop that produces no errors or
> warnings, and no results, even after 15+ minutes of execution time. As I
> recall, the SAS code took less than 15 seconds back in 1999.
>
> I have also tried
>
> random = ~1 | study_vehicle)
>
> and R immediately produces output.  However, although the regression
> coefficients are close to those from SAS, the degrees of freedom from SAS
> are higher than those from R.
>
> Therefore, what is the equivalent R random code for the original SAS
> RANDOM?
>
> Thanks!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Aug 11 23:31:20 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Aug 2017 17:31:20 -0400
Subject: [R-sig-ME] PROC MIXED RANDOM equivalence in R nlme
In-Reply-To: <CAE9_Wg48V_XUB5AwJBXBKY8m5ExxzCx8+CrUk6MkM8qMqToGJA@mail.gmail.com>
References: <c4b37bd5-fd71-cd31-5113-c83d60cdfba5@umich.edu>
 <CAE9_Wg48V_XUB5AwJBXBKY8m5ExxzCx8+CrUk6MkM8qMqToGJA@mail.gmail.com>
Message-ID: <ba892124-69d8-c886-283e-cb3fc35c993f@gmail.com>


Or make them equivalent by using pdDiag() to enforce a diagonal
covariance matrix.

FitTHC <- lme(ln_thc ~ rv + t5 + t9 + ar + ol + ox + su + bz,
          data = emiss,
          random = list(study_vehicle=pdDiag(~1 + rv + t5 + t9 + ar + ol
+ ox + su + bz)))

In lme4 you can do this with the double-bar operator.

On 17-08-11 05:27 PM, Jake Westfall wrote:
> Dennis,
> 
> The two models are not equivalent because the R model uses an unstructured
> covariance for the random effects (estimates all possible correlations
> among random effects) while the SAS model uses a diagonal covariance matrix
> (assumes no correlations among random effects). You can make them
> equivalent by adding type=un to the end of the RANDOM statement in the SAS
> model and you'll find that the SAS model takes a lot longer to run then :)
> 
> Jake
> 
> On Fri, Aug 11, 2017 at 4:03 PM, Dennis F. Kahlbaum <kbomb at umich.edu> wrote:
> 
>> I am trying to reproduce some old SAS PROC MIXED code using R and nlme.
>>
>> As background, the data consist of 300+ vehicle emission test results
>> (grams/mile of THC over a given driving cycle) versus the gasoline fuel
>> properties, which include: Read Vapor Pressure (rv), Temperature for 50%
>> Evaporation (t5), Temperature for 90% Evaporation (t9), Aromatics (ar),
>> Olefins, (ol), Sulfur (su), Oxygenate (ox), Benzene (bz), and a code
>> identifying the study and vehicle (study_vehicle). All variables are real
>> numbers except "study_vehicle", which is character. Unfortunately, since
>> the data are confidential, I'm unable to provide an example.
>>
>> The goal is to determine the relationship between the emissions and the
>> fuel properties.
>>
>> The original SAS v6.12 code is provided below:
>>
>> ------------------------------------------------------------------
>> /* READ DATA */
>> DATA emiss;
>>    INFILE 'data.tab' LRECL=8000 FIRSTOBS=2 DLM='09'X MISSOVER DSD;
>>    INPUT study_vehicle $ thc rv t5 t9 ar ol ox su bz;
>>
>> /* CREATE NEW VARIABLE */
>> ln_thc = log (thc);
>>
>> /* PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES */
>> PROC MIXED DATA=emiss MAXITER=1000 CONVH=1E-8 METHOD=REML NOCLPRINT
>> NOITPRINT;
>> CLASS study_vehicle;
>>
>> MODEL ln_thc = rv t5 t9 ar ol ox su bz
>>                 /S DDFM=RES;
>>
>> RANDOM         int rv t5 t9 ar ol ox su bz
>>                /SUB=study_vehicle;
>> RUN;
>> ------------------------------------------------------------------
>>
>> The R code I've devised for reading/processing the data and to replicate
>> the PROC MIXED statement is shown below:
>>
>> ------------------------------------------------------------------
>> # LOAD REQUIRED LIBRARY
>> library (?lmne?)
>>
>> # FORCE R TO USE THE SAME "CONTRAST" METHOD AS SAS
>> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
>>
>> # READ DATA (study_vehicle, thc, rv, t5, t9, ar, ol, ox, su, bz)
>> emiss <- read.table("data.csv", header=TRUE, sep=",") # NA for missing
>> data (default)
>>
>> # CREATE NEW VARIABLE
>> ln_thc <- log(thc)
>>
>> # PERFORM ANALYSIS RELATING LOG EMISSIONS TO FUEL PROPERTIES
>> FitTHC <- lme(ln_thc ~ rv + t5 + t9 + ar + ol + ox + su + bz,
>>           data = emiss,
>>           random = ??????? | study_vehicle )
>>
>> # OUTPUT THE RESULTS
>> summary(FitTHC)
>> ------------------------------------------------------------------
>>
>> A review of the dataframe "emiss" shows that all variables, except
>> "study_vehicle", are of type "num". As expected, the character variable
>> "study_vehicle" is of type "factor".  These properties match those from SAS.
>>
>> As indicated by the questions marks, the problem I'm having is in
>> constructing the equivalent R random code for the SAS RANDOM and any
>> remaining settings (e.g. "/S DDFM=RES"). I've tried
>>
>> random = ~1 + rv + t5 + t9 + ar + ol + ox + su + bz | study_vehicle)
>>
>> but R gets caught in a processing loop that produces no errors or
>> warnings, and no results, even after 15+ minutes of execution time. As I
>> recall, the SAS code took less than 15 seconds back in 1999.
>>
>> I have also tried
>>
>> random = ~1 | study_vehicle)
>>
>> and R immediately produces output.  However, although the regression
>> coefficients are close to those from SAS, the degrees of freedom from SAS
>> are higher than those from R.
>>
>> Therefore, what is the equivalent R random code for the original SAS
>> RANDOM?
>>
>> Thanks!
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From kbomb at umich.edu  Sat Aug 12 17:08:10 2017
From: kbomb at umich.edu (Dennis F. Kahlbaum)
Date: Sat, 12 Aug 2017 11:08:10 -0400
Subject: [R-sig-ME] PROC MIXED RANDOM equivalence in R nlme
Message-ID: <081da7b2-bc92-b761-4035-f4d8a580a147@umich.edu>

Jake and Ben:

Thank you so much for your responses!  Your explanations and solutions 
have finally resolved this problem.

Although the SAS and R outputs for AIC, BIC, and Degrees of Freedom are 
different, all of the other parameters (logLik, Value, Std.Error,  
t-value, p-value, etc) do match.

I am indeed grateful for your help.

--Dennis


From jmichaelrosenberg at gmail.com  Mon Aug 14 18:23:23 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Mon, 14 Aug 2017 12:23:23 -0400
Subject: [R-sig-ME] Comparing variance components of crossed effects
 models fit with lme4 and nlme
In-Reply-To: <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>
References: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
 <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>
Message-ID: <CANYHYTR=tYd3HXDkBT1ZNvfvXh29wNbdFj7c5+13m7EGpYqacA@mail.gmail.com>

Thank you, I will explore use of INLA (or potentially the brms package
because of my familiarity with the [lme4-like] syntax).

I'm curious whether you (or anyone else) has thoughts / advice on using a
package that uses a Bayesian approach for carrying out mixed effects
modeling. In my field / area of research, mixed effects models are new! And
so a Bayesian approach to them would be *very *new. Even though if I
understand (very preliminarily), with some (uniform) prior specification,
results can be comparable to models specified with a maximum likelihood
approach, when possible.

Thank you again!
Josh

On Fri, Aug 11, 2017 at 8:38 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Joshua,
>
> Crossed random effects are difficult to specify in nlme. I think that you
> have to use pdBlocked() in the specification.
>
> When I need correlation I often use INLA (r-inla.org). It allows for
> correlated random effects. Crossed random effects are no problem.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-08-10 23:05 GMT+02:00 Joshua Rosenberg <jmichaelrosenberg at gmail.com>:
>
>> Hi all,
>>
>> I'm trying to fit models with a) crossed random effects and b) a specific
>> residual structure (auto-correlation). Based on my understanding of what
>> nlme and lme4 do well, I would normally turn to lme4 to fit a model with
>> crossed random effects, but because I'm trying to structure the residuals,
>> I am trying nlme.
>>
>> In trying to fit and compare the same variance components (no fixed
>> effects) model using lme4 and nlme, I found the output is similar but a
>> bit
>> different. Specifically, the standard deviations of the random effects and
>> the log-likelihood statistics are different. Would you expect the output
>> to
>> be a bit different?
>>
>> The models I fit to compare the output are here, though the output is also
>> here:
>> https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/
>>
>>
>> library(lme4)
>> library(nlme)
>>
>> m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data =
>> Penicillin)
>> m_lme4
>>
>> m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample = ~ 1), data
>> = Penicillin)
>> m_nlme
>>
>>
>> ?Thank you for considering this question,
>> Josh?
>>
>> --
>> Joshua Rosenberg, Ph.D. Candidate
>> Educational Psychology
>> ?&?
>>  Educational Technology
>> Michigan State University
>> http://jmichaelrosenberg.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
?&?
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 15 00:54:01 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Aug 2017 18:54:01 -0400
Subject: [R-sig-ME] Comparing variance components of crossed effects
 models fit with lme4 and nlme
In-Reply-To: <CANYHYTR=tYd3HXDkBT1ZNvfvXh29wNbdFj7c5+13m7EGpYqacA@mail.gmail.com>
References: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
 <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>
 <CANYHYTR=tYd3HXDkBT1ZNvfvXh29wNbdFj7c5+13m7EGpYqacA@mail.gmail.com>
Message-ID: <CABghstQafxeBW108H=fHkcgpVoGA1+yk8uGNiEVp4Qm0mVsH3A@mail.gmail.com>

  A couple of thoughts:

(1) INLA *is* explicitly Bayesian, although I don't know what it
specifies (implicitly or explicitly) for priors or whether it allows
them to be user-adjusted (I'm too lazy to go look at the documentation
or Google "INLA priors" right now ...)
(2) it's worth making a distinction between
    (a) stochastic optimization (as in Bayesian MCMC, or frequentist
Monte Carlo expectation-maximization (MCEM) approaches) and
hill-climbing/deterministic optimization (as in INLA, or lme4, or
glmmTMB -- anything that says it uses the Laplace approximation, or
Gaussian quadrature ...)
   (b) inference based on a maximum point (MLE, or maximum a
posteriori [MAP] estimates in the Bayesian world) and inferences based
on means and distributions (MCMC). Typically the former goes with
deterministic optimization and the latter goes with stochastic
optimization
(3) in addition to INLA, there are a variety of existing Bayesian
machines in R (blme, MCMCglmm, brms, rstanarm ...) -- I think MCMCglmm
and brms implement some flavours of (temporal) autoregression ...

  Depending on the kind of autoregressive structure you want, glmmTMB
is also a possibility.

On Mon, Aug 14, 2017 at 12:23 PM, Joshua Rosenberg
<jmichaelrosenberg at gmail.com> wrote:
> Thank you, I will explore use of INLA (or potentially the brms package
> because of my familiarity with the [lme4-like] syntax).
>
> I'm curious whether you (or anyone else) has thoughts / advice on using a
> package that uses a Bayesian approach for carrying out mixed effects
> modeling. In my field / area of research, mixed effects models are new! And
> so a Bayesian approach to them would be *very *new. Even though if I
> understand (very preliminarily), with some (uniform) prior specification,
> results can be comparable to models specified with a maximum likelihood
> approach, when possible.
>
> Thank you again!
> Josh
>
> On Fri, Aug 11, 2017 at 8:38 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Joshua,
>>
>> Crossed random effects are difficult to specify in nlme. I think that you
>> have to use pdBlocked() in the specification.
>>
>> When I need correlation I often use INLA (r-inla.org). It allows for
>> correlated random effects. Crossed random effects are no problem.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2017-08-10 23:05 GMT+02:00 Joshua Rosenberg <jmichaelrosenberg at gmail.com>:
>>
>>> Hi all,
>>>
>>> I'm trying to fit models with a) crossed random effects and b) a specific
>>> residual structure (auto-correlation). Based on my understanding of what
>>> nlme and lme4 do well, I would normally turn to lme4 to fit a model with
>>> crossed random effects, but because I'm trying to structure the residuals,
>>> I am trying nlme.
>>>
>>> In trying to fit and compare the same variance components (no fixed
>>> effects) model using lme4 and nlme, I found the output is similar but a
>>> bit
>>> different. Specifically, the standard deviations of the random effects and
>>> the log-likelihood statistics are different. Would you expect the output
>>> to
>>> be a bit different?
>>>
>>> The models I fit to compare the output are here, though the output is also
>>> here:
>>> https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/
>>>
>>>
>>> library(lme4)
>>> library(nlme)
>>>
>>> m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data =
>>> Penicillin)
>>> m_lme4
>>>
>>> m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample = ~ 1), data
>>> = Penicillin)
>>> m_nlme
>>>
>>>
>>> Thank you for considering this question,
>>> Josh
>>>
>>> --
>>> Joshua Rosenberg, Ph.D. Candidate
>>> Educational Psychology
>>> &
>>>  Educational Technology
>>> Michigan State University
>>> http://jmichaelrosenberg.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology
> &
>  Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From S.Kim at tue.nl  Tue Aug 15 11:39:51 2017
From: S.Kim at tue.nl (Kim, S.)
Date: Tue, 15 Aug 2017 09:39:51 +0000
Subject: [R-sig-ME] MCMCglmm with a AR(1)
Message-ID: <8C9CA8EFDB10B54AAFFD41D93D46FC84345A3F92@xserver30c.campus.tue.nl>

Dear list member,

I was wondering if anyone would able to give me a guidance with the following:

I would like to consider both random effects and temporal autocorrelation in my model. So I have used MCMCglmm (developed by Jarrod Hadfield).
But I have a difficulty with considering temporal autocorrelation (in my case, first-order autoregressive process, AR(1)).

At the most of previous studies, the autocorrelation is evaluated on the covariance structure of residuals.

Corr(eit, eit')~rho^|t-t'|
where, e is the residual, i is the individual, and t is the time.

However, in my multinomial response, this is not the case because the residuals do not follow the normal distribution anymore in logistic regression model (So I set R-structure as fix=1).
I have a feeling that the autocorrelation should be evaluated on the realization of response rather than residuals, therefore,

Corr(yit, yit')~rho^|t-t'|
where, e is the residual, i is the individual, and t is the time.

Could anyone help me to take temporal autocorrelation into account in my model?

Belows are the short version of the data.
I have a longitudinal data with repeated measures. Observation spans several months with the choice of individuals out of 5 choice alternatives (A,B,C,D,E).

ind.id

P1

P2

T1

T2

T3

T4

date.time

response

1

3

2

410

2.8

0

3

1/26/2017 9:35

A

1

3

2

603

11.9

0

1

1/26/2017 9:48

C

2

1

3

410

13.2

0

3

1/25/2017 12:28

B

2

1

3

639

8.9

0

1

1/25/2017 12:50

C

2

1

3

538

11.8

50.5

3

1/25/2017 17:20

B

2

1

3

628

14

0

3

1/25/2017 18:08

B

2

1

3

239

7.9

0

3

1/25/2017 18:25

B

2

1

3

561

12.7

50.5

2

1/25/2017 18:50

D

2

1

3

150

9.4

50.5

2

1/26/2017 13:14

D

3

1

3

476

13

50.5

3

1/26/2017 18:45

B

3

1

3

1146

12

0

3

1/26/2017 21:14

E

3

1

3

1038

11.5

50.5

1

1/26/2017 21:37

D

3

1

3

2230

1.8

18

3

1/27/2017 8:06

B

4

1

3

1916

6.2

18

2

1/27/2017 17:08

C

4

1

3

603

10.6

50.5

1

1/27/2017 19:29

D

4

1

3

627

3.6

0.7

3

1/27/2017 20:52

B

4

1

3

918

2.2

0

3

1/28/2017 9:16

B

5

1

3

382

9.6

50.5

3

1/28/2017 9:56

B

5

1

3

4940

0.9

0.7

3

1/29/2017 9:53

E

5

1

3

383

10.6

50.5

3

1/29/2017 12:14

B

5

1

3

232

8.1

0

3

1/29/2017 12:22

A

5

1

3

302

5.4

50.5

3

1/29/2017 12:30

B



The code below is the model without AR(1) but with random effects grouped by individual.

# Set variable type
sig$ind.id<- as.factor(sig$ind.id)
sig$P1<- as.factor(sig$P1)
sig$P2<- as.factor(sig$P2)
sig$T1<- as.factor(sig$T1)
sig$T2<- as.factor(sig$T2)
sig$T3<- as.factor(sig$T3)
sig$T4<- as.factor(sig$T4)
sig$response<- as.factor(sig$response)

library(MCMCglmm)

# Set priors
k <- length(levels(sig$response))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

prior <- list(
                  G = list(G1 = list(V = diag(k-1), n = k-1)),
                  R = list(fix=1, V= (1/2) * (I + J), n = k-1))

# Fit MCMCglmm
m <- MCMCglmm(fixed = response ~ P1+P2+T1+T2+T3+T4+trait-1,
                                     random = ~ us(trait):ind.id,
                                     rcov = ~us(trait):units,
                                     prior = prior,
                                     burnin =10000,
                                     nitt = 110000,
                                    thin = 10,
                                    pr = TRUE,
                                     family = "categorical",
                                     data = sig,
                                     verbose = T)

Many thanks in advance.
Seheon


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Aug 15 12:33:22 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 15 Aug 2017 11:33:22 +0100
Subject: [R-sig-ME] MCMCglmm with a AR(1)
In-Reply-To: <8C9CA8EFDB10B54AAFFD41D93D46FC84345A3F92@xserver30c.campus.tue.nl>
References: <8C9CA8EFDB10B54AAFFD41D93D46FC84345A3F92@xserver30c.campus.tue.nl>
Message-ID: <e265534e-083b-c571-8bdc-800e7ede68a9@ed.ac.uk>

Hi,

MCMCglmm cannot fit AR1 models but it can fit 1st-order antedependence 
models (an ar1 process sampled from time t=0 rather than from the 
stationary process). That being said, it only really works when you have 
short-time series where all observations have been sampled at the same 
time. I'm not sure if this is your case? Its also not clear how you 
would set up the AR1 for a 5-category multinomial  - something like a 
vector autoregressive might make sense but this is not implemented in 
MCMCglmm except for Gaussian traits and at the observation-level rather 
than the residual level. For non-Gaussian traits, particularly 
multinomial, you're probably going to have to code the model yourself in 
stan/JAGS if you want autocorrelation at the observation-level.

Cheers,

Jarrod



(except for Gaussian traits and at the observation-level).


On 15/08/2017 10:39, Kim, S. wrote:
> Dear list member,
>
> I was wondering if anyone would able to give me a guidance with the following:
>
> I would like to consider both random effects and temporal autocorrelation in my model. So I have used MCMCglmm (developed by Jarrod Hadfield).
> But I have a difficulty with considering temporal autocorrelation (in my case, first-order autoregressive process, AR(1)).
>
> At the most of previous studies, the autocorrelation is evaluated on the covariance structure of residuals.
>
> Corr(eit, eit')~rho^|t-t'|
> where, e is the residual, i is the individual, and t is the time.
>
> However, in my multinomial response, this is not the case because the residuals do not follow the normal distribution anymore in logistic regression model (So I set R-structure as fix=1).
> I have a feeling that the autocorrelation should be evaluated on the realization of response rather than residuals, therefore,
>
> Corr(yit, yit')~rho^|t-t'|
> where, e is the residual, i is the individual, and t is the time.
>
> Could anyone help me to take temporal autocorrelation into account in my model?
>
> Belows are the short version of the data.
> I have a longitudinal data with repeated measures. Observation spans several months with the choice of individuals out of 5 choice alternatives (A,B,C,D,E).
>
> ind.id
>
> P1
>
> P2
>
> T1
>
> T2
>
> T3
>
> T4
>
> date.time
>
> response
>
> 1
>
> 3
>
> 2
>
> 410
>
> 2.8
>
> 0
>
> 3
>
> 1/26/2017 9:35
>
> A
>
> 1
>
> 3
>
> 2
>
> 603
>
> 11.9
>
> 0
>
> 1
>
> 1/26/2017 9:48
>
> C
>
> 2
>
> 1
>
> 3
>
> 410
>
> 13.2
>
> 0
>
> 3
>
> 1/25/2017 12:28
>
> B
>
> 2
>
> 1
>
> 3
>
> 639
>
> 8.9
>
> 0
>
> 1
>
> 1/25/2017 12:50
>
> C
>
> 2
>
> 1
>
> 3
>
> 538
>
> 11.8
>
> 50.5
>
> 3
>
> 1/25/2017 17:20
>
> B
>
> 2
>
> 1
>
> 3
>
> 628
>
> 14
>
> 0
>
> 3
>
> 1/25/2017 18:08
>
> B
>
> 2
>
> 1
>
> 3
>
> 239
>
> 7.9
>
> 0
>
> 3
>
> 1/25/2017 18:25
>
> B
>
> 2
>
> 1
>
> 3
>
> 561
>
> 12.7
>
> 50.5
>
> 2
>
> 1/25/2017 18:50
>
> D
>
> 2
>
> 1
>
> 3
>
> 150
>
> 9.4
>
> 50.5
>
> 2
>
> 1/26/2017 13:14
>
> D
>
> 3
>
> 1
>
> 3
>
> 476
>
> 13
>
> 50.5
>
> 3
>
> 1/26/2017 18:45
>
> B
>
> 3
>
> 1
>
> 3
>
> 1146
>
> 12
>
> 0
>
> 3
>
> 1/26/2017 21:14
>
> E
>
> 3
>
> 1
>
> 3
>
> 1038
>
> 11.5
>
> 50.5
>
> 1
>
> 1/26/2017 21:37
>
> D
>
> 3
>
> 1
>
> 3
>
> 2230
>
> 1.8
>
> 18
>
> 3
>
> 1/27/2017 8:06
>
> B
>
> 4
>
> 1
>
> 3
>
> 1916
>
> 6.2
>
> 18
>
> 2
>
> 1/27/2017 17:08
>
> C
>
> 4
>
> 1
>
> 3
>
> 603
>
> 10.6
>
> 50.5
>
> 1
>
> 1/27/2017 19:29
>
> D
>
> 4
>
> 1
>
> 3
>
> 627
>
> 3.6
>
> 0.7
>
> 3
>
> 1/27/2017 20:52
>
> B
>
> 4
>
> 1
>
> 3
>
> 918
>
> 2.2
>
> 0
>
> 3
>
> 1/28/2017 9:16
>
> B
>
> 5
>
> 1
>
> 3
>
> 382
>
> 9.6
>
> 50.5
>
> 3
>
> 1/28/2017 9:56
>
> B
>
> 5
>
> 1
>
> 3
>
> 4940
>
> 0.9
>
> 0.7
>
> 3
>
> 1/29/2017 9:53
>
> E
>
> 5
>
> 1
>
> 3
>
> 383
>
> 10.6
>
> 50.5
>
> 3
>
> 1/29/2017 12:14
>
> B
>
> 5
>
> 1
>
> 3
>
> 232
>
> 8.1
>
> 0
>
> 3
>
> 1/29/2017 12:22
>
> A
>
> 5
>
> 1
>
> 3
>
> 302
>
> 5.4
>
> 50.5
>
> 3
>
> 1/29/2017 12:30
>
> B
>
>
>
> The code below is the model without AR(1) but with random effects grouped by individual.
>
> # Set variable type
> sig$ind.id<- as.factor(sig$ind.id)
> sig$P1<- as.factor(sig$P1)
> sig$P2<- as.factor(sig$P2)
> sig$T1<- as.factor(sig$T1)
> sig$T2<- as.factor(sig$T2)
> sig$T3<- as.factor(sig$T3)
> sig$T4<- as.factor(sig$T4)
> sig$response<- as.factor(sig$response)
>
> library(MCMCglmm)
>
> # Set priors
> k <- length(levels(sig$response))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>
> prior <- list(
>                    G = list(G1 = list(V = diag(k-1), n = k-1)),
>                    R = list(fix=1, V= (1/2) * (I + J), n = k-1))
>
> # Fit MCMCglmm
> m <- MCMCglmm(fixed = response ~ P1+P2+T1+T2+T3+T4+trait-1,
>                                       random = ~ us(trait):ind.id,
>                                       rcov = ~us(trait):units,
>                                       prior = prior,
>                                       burnin =10000,
>                                       nitt = 110000,
>                                      thin = 10,
>                                      pr = TRUE,
>                                       family = "categorical",
>                                       data = sig,
>                                       verbose = T)
>
> Many thanks in advance.
> Seheon
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From S.Kim at tue.nl  Tue Aug 15 14:09:56 2017
From: S.Kim at tue.nl (Kim, S.)
Date: Tue, 15 Aug 2017 12:09:56 +0000
Subject: [R-sig-ME] MCMCglmm with a AR(1)
In-Reply-To: <e265534e-083b-c571-8bdc-800e7ede68a9@ed.ac.uk>
References: <8C9CA8EFDB10B54AAFFD41D93D46FC84345A3F92@xserver30c.campus.tue.nl>
 <e265534e-083b-c571-8bdc-800e7ede68a9@ed.ac.uk>
Message-ID: <8C9CA8EFDB10B54AAFFD41D93D46FC84345A6020@xserver30c.campus.tue.nl>

Thanks Jarrod,

Unfortunately the data I have spans a few months with repeated measurements and each individual participates the survey at random time points.
Yes. I would consider a vector autoregressive (VAR(p)).
And sorry for the messy data. The example data and code looks like follows. Also it would be greatly appreciated if you comment whether there is any mistakes in the code (without AR(1)).

> head(sig)
         ind.id	 P1 	P2	 T1	   T2	   T3	 T4       	date.time		    response
1      1          	3  	2	 410	   2.8	    0	  3 	 1/26/2017 9:35    	    A
2      1          	3  	2	 603	   11.9	    0	  1 	 1/26/2017 9:48    	    C
3      2          	1  	3	 410	   13.2  	    0	  3	 1/25/2017 12:28     	    B
4      2          	1  	3   	 639	   8.9   	    0	  1 	 1/25/2017 12:50    	    C
5      2          	1  	3	 538	   11.8	    50.5	  3 	 1/25/2017 17:20    	    E
6      2          	1  	3	 628	   14   	    0 	  3 	 1/25/2017 18:08     	    D

> library(MCMCglmm)

> # Set priors
> k <- length(levels(sig$response))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>
> prior <- list(
>                    G = list(G1 = list(V = diag(k-1), n = k-1)),
>                    R = list(fix=1, V= diag(k-1), n = k-1))
>
> # Fit MCMCglmm
> m <- MCMCglmm(fixed = response ~ P1+P2+T1+T2+T3+T4+trait-1,
>                                       random = ~ us(trait):ind.id,
>                                       rcov = ~us(trait):units,
>                                       prior = prior,
>                                       burnin =10000,
>                                       nitt = 110000,
>                                      thin = 10,
>                                      pr = TRUE,
>                                       family = "categorical",
>                                       data = sig,
>                                       verbose = T)

Best regards,
Seheon


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jarrod Hadfield
Sent: Tuesday, August 15, 2017 12:33 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm with a AR(1)

Hi,

MCMCglmm cannot fit AR1 models but it can fit 1st-order antedependence models (an ar1 process sampled from time t=0 rather than from the stationary process). That being said, it only really works when you have short-time series where all observations have been sampled at the same time. I'm not sure if this is your case? Its also not clear how you would set up the AR1 for a 5-category multinomial  - something like a vector autoregressive might make sense but this is not implemented in MCMCglmm except for Gaussian traits and at the observation-level rather than the residual level. For non-Gaussian traits, particularly multinomial, you're probably going to have to code the model yourself in stan/JAGS if you want autocorrelation at the observation-level.

Cheers,

Jarrod



(except for Gaussian traits and at the observation-level).


On 15/08/2017 10:39, Kim, S. wrote:
> Dear list member,
>
> I was wondering if anyone would able to give me a guidance with the following:
>
> I would like to consider both random effects and temporal autocorrelation in my model. So I have used MCMCglmm (developed by Jarrod Hadfield).
> But I have a difficulty with considering temporal autocorrelation (in my case, first-order autoregressive process, AR(1)).
>
> At the most of previous studies, the autocorrelation is evaluated on the covariance structure of residuals.
>
> Corr(eit, eit')~rho^|t-t'|
> where, e is the residual, i is the individual, and t is the time.
>
> However, in my multinomial response, this is not the case because the residuals do not follow the normal distribution anymore in logistic regression model (So I set R-structure as fix=1).
> I have a feeling that the autocorrelation should be evaluated on the 
> realization of response rather than residuals, therefore,
>
> Corr(yit, yit')~rho^|t-t'|
> where, e is the residual, i is the individual, and t is the time.
>
> Could anyone help me to take temporal autocorrelation into account in my model?
>
> Belows are the short version of the data.
> I have a longitudinal data with repeated measures. Observation spans several months with the choice of individuals out of 5 choice alternatives (A,B,C,D,E).
>
> ind.id
>
> P1
>
> P2
>
> T1
>
> T2
>
> T3
>
> T4
>
> date.time
>
> response
>
> 1
>
> 3
>
> 2
>
> 410
>
> 2.8
>
> 0
>
> 3
>
> 1/26/2017 9:35
>
> A
>
> 1
>
> 3
>
> 2
>
> 603
>
> 11.9
>
> 0
>
> 1
>
> 1/26/2017 9:48
>
> C
>
> 2
>
> 1
>
> 3
>
> 410
>
> 13.2
>
> 0
>
> 3
>
> 1/25/2017 12:28
>
> B
>
> 2
>
> 1
>
> 3
>
> 639
>
> 8.9
>
> 0
>
> 1
>
> 1/25/2017 12:50
>
> C
>
> 2
>
> 1
>
> 3
>
> 538
>
> 11.8
>
> 50.5
>
> 3
>
> 1/25/2017 17:20
>
> B
>
> 2
>
> 1
>
> 3
>
> 628
>
> 14
>
> 0
>
> 3
>
> 1/25/2017 18:08
>
> B
>
> 2
>
> 1
>
> 3
>
> 239
>
> 7.9
>
> 0
>
> 3
>
> 1/25/2017 18:25
>
> B
>
> 2
>
> 1
>
> 3
>
> 561
>
> 12.7
>
> 50.5
>
> 2
>
> 1/25/2017 18:50
>
> D
>
> 2
>
> 1
>
> 3
>
> 150
>
> 9.4
>
> 50.5
>
> 2
>
> 1/26/2017 13:14
>
> D
>
> 3
>
> 1
>
> 3
>
> 476
>
> 13
>
> 50.5
>
> 3
>
> 1/26/2017 18:45
>
> B
>
> 3
>
> 1
>
> 3
>
> 1146
>
> 12
>
> 0
>
> 3
>
> 1/26/2017 21:14
>
> E
>
> 3
>
> 1
>
> 3
>
> 1038
>
> 11.5
>
> 50.5
>
> 1
>
> 1/26/2017 21:37
>
> D
>
> 3
>
> 1
>
> 3
>
> 2230
>
> 1.8
>
> 18
>
> 3
>
> 1/27/2017 8:06
>
> B
>
> 4
>
> 1
>
> 3
>
> 1916
>
> 6.2
>
> 18
>
> 2
>
> 1/27/2017 17:08
>
> C
>
> 4
>
> 1
>
> 3
>
> 603
>
> 10.6
>
> 50.5
>
> 1
>
> 1/27/2017 19:29
>
> D
>
> 4
>
> 1
>
> 3
>
> 627
>
> 3.6
>
> 0.7
>
> 3
>
> 1/27/2017 20:52
>
> B
>
> 4
>
> 1
>
> 3
>
> 918
>
> 2.2
>
> 0
>
> 3
>
> 1/28/2017 9:16
>
> B
>
> 5
>
> 1
>
> 3
>
> 382
>
> 9.6
>
> 50.5
>
> 3
>
> 1/28/2017 9:56
>
> B
>
> 5
>
> 1
>
> 3
>
> 4940
>
> 0.9
>
> 0.7
>
> 3
>
> 1/29/2017 9:53
>
> E
>
> 5
>
> 1
>
> 3
>
> 383
>
> 10.6
>
> 50.5
>
> 3
>
> 1/29/2017 12:14
>
> B
>
> 5
>
> 1
>
> 3
>
> 232
>
> 8.1
>
> 0
>
> 3
>
> 1/29/2017 12:22
>
> A
>
> 5
>
> 1
>
> 3
>
> 302
>
> 5.4
>
> 50.5
>
> 3
>
> 1/29/2017 12:30
>
> B
>
>
>
> The code below is the model without AR(1) but with random effects grouped by individual.
>
> # Set variable type
> sig$ind.id<- as.factor(sig$ind.id)
> sig$P1<- as.factor(sig$P1)
> sig$P2<- as.factor(sig$P2)
> sig$T1<- as.factor(sig$T1)
> sig$T2<- as.factor(sig$T2)
> sig$T3<- as.factor(sig$T3)
> sig$T4<- as.factor(sig$T4)
> sig$response<- as.factor(sig$response)
>
> library(MCMCglmm)
>
> # Set priors
> k <- length(levels(sig$response))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>
> prior <- list(
>                    G = list(G1 = list(V = diag(k-1), n = k-1)),
>                    R = list(fix=1, V= (1/2) * (I + J), n = k-1))
>
> # Fit MCMCglmm
> m <- MCMCglmm(fixed = response ~ P1+P2+T1+T2+T3+T4+trait-1,
>                                       random = ~ us(trait):ind.id,
>                                       rcov = ~us(trait):units,
>                                       prior = prior,
>                                       burnin =10000,
>                                       nitt = 110000,
>                                      thin = 10,
>                                      pr = TRUE,
>                                       family = "categorical",
>                                       data = sig,
>                                       verbose = T)
>
> Many thanks in advance.
> Seheon
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From petr.pikal at precheza.cz  Tue Aug 15 17:14:08 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 15 Aug 2017 15:14:08 +0000
Subject: [R-sig-ME] nlme augPred problem
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAAB91@SRVEXCHCM301.precheza.cz>

Dear all

I encountered strange behaviour of augPred with virtually the same data

Firs I made groupedData object.
> mar.g<-groupedData(rutilizace~doba|int, data=mar)

When I perform nlme on complete dataset I get an error with augPred
> fit<-nlsList(rutilizace~SSasymp(doba, Asym, R0,  lrc), data=mar.g)
Warning message:
c("1 error caught in nls(y ~ cbind(1 - exp(-exp(lrc) * x), exp(-exp(lrc) * x)), data = xy, : singular gradient", "1 error caught in     start = list(lrc = lrc), algorithm = \"plinear\"): singular gradient")
> fit1<-nlme(fit)
> plot(augPred(fit1, level=0:1))
Error in `[[<-.data.frame`(`*tmp*`, nm, value = c(6L, 6L, 6L, 6L, 8L,  :
  replacement has 60 rows, data has 12

However when I make subset of my data
>
> mar.g<-mar.g[,c(3,4, 21)]

> fit<-nlsList(rutilizace~SSasymp(doba, Asym, R0,  lrc), data=mar.g)
Warning message:
c("1 error caught in nls(y ~ cbind(1 - exp(-exp(lrc) * x), exp(-exp(lrc) * x)), data = xy, : singular gradient", "1 error caught in     start = list(lrc = lrc), algorithm = \"plinear\"): singular gradient")
> fit1<-nlme(fit)
> plot(augPred(fit1, level=0:1))
>
augPred works as a charm. Does anybody know where I should try to search for problems?

Best regards
Petr

> version
               _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status         Under development (unstable)
major          3
minor          5.0
year           2017
month          07
day            31
svn rev        73003
language       R
version.string R Under development (unstable) (2017-07-31 r73003)
nickname       Unsuffered Consequences
>

Package nlme version 3.1-131

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From orchidn at live.com  Tue Aug 15 21:07:02 2017
From: orchidn at live.com (dani)
Date: Tue, 15 Aug 2017 19:07:02 +0000
Subject: [R-sig-ME] GAMM4 error
Message-ID: <DM5PR12MB1580B74EFAF354E8D21DF768D68D0@DM5PR12MB1580.namprd12.prod.outlook.com>

Hello everyone,


I am a beginner struggling with GAMM4. I employed a GAMM4 model using a binomial distribution involving two smoothers and two random intercepts (corresponding to a structure involving observations cross-classified into two groups: pupils and neighbourhoods):


model <- gamm4(y ~ x1+x2+s(x3)+s(x4), random=~ (1|pupil)+(1|neigh), data=mydata, family= binomial)

I received the following error message:
Error in smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) :
  NA/NaN/Inf in foreign function call (arg 1)

I was wondering if anyone can please help me elucidate what might this mean.

Best regards, everyone!
Nicole-Miki




<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 15 21:36:19 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Aug 2017 15:36:19 -0400
Subject: [R-sig-ME] GAMM4 error
In-Reply-To: <DM5PR12MB1580B74EFAF354E8D21DF768D68D0@DM5PR12MB1580.namprd12.prod.outlook.com>
References: <DM5PR12MB1580B74EFAF354E8D21DF768D68D0@DM5PR12MB1580.namprd12.prod.outlook.com>
Message-ID: <9cbe6a91-1d65-913e-7ea1-038af1ad8156@gmail.com>


  We'd love to help, but it's really, really hard without a reproducible
example.  All the error message really tells us is that somewhere in the
guts there was something like a divide-by-zero error or an infinity
produced (because your data were weird, or because some value got really
small or really large and under/overflowed).

  A reproducible example would be ideal (see e.g.
<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>
), but in its absence, `summary(mydata)` or `str(mydata)` would be
useful.  For example:

- is y a 0/1 variable?
- are all of your x variables numeric, and not super-large in magnitude?
- do you have NA values in your data?
- how many distinct values (levels) of pupil and neigh do you have?
- how many observations overall?

On 17-08-15 03:07 PM, dani wrote:
> Hello everyone,
> 
> 
> I am a beginner struggling with GAMM4. I employed a GAMM4 model using
> a binomial distribution involving two smoothers and two random
> intercepts (corresponding to a structure involving observations
> cross-classified into two groups: pupils and neighbourhoods):
> 
> 
> model <- gamm4(y ~ x1+x2+s(x3)+s(x4), random=~ (1|pupil)+(1|neigh),
> data=mydata, family= binomial)
> 
> I received the following error message: Error in
> smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) : 
> NA/NaN/Inf in foreign function call (arg 1)
> 
> I was wondering if anyone can please help me elucidate what might
> this mean.
> 
> Best regards, everyone! Nicole-Miki
> 
> 
> 
> 
> <http://aka.ms/weboutlook>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From orchidn at live.com  Tue Aug 15 22:20:00 2017
From: orchidn at live.com (dani)
Date: Tue, 15 Aug 2017 20:20:00 +0000
Subject: [R-sig-ME] GAMM4 error
In-Reply-To: <9cbe6a91-1d65-913e-7ea1-038af1ad8156@gmail.com>
References: <DM5PR12MB1580B74EFAF354E8D21DF768D68D0@DM5PR12MB1580.namprd12.prod.outlook.com>,
 <9cbe6a91-1d65-913e-7ea1-038af1ad8156@gmail.com>
Message-ID: <DM5PR12MB158047FB439E47AD99C029DFD68D0@DM5PR12MB1580.namprd12.prod.outlook.com>

Hello Ben,


Thank you so much for your kind and prompt response. I provided a little bit more detail about my data. I really appreciate you taking the time to take a look over this information.


Yes, y is a 0/1 variable.


I have a total of  185,236 observations nested in n=2,206 pupils and n = 2,314 neighbourhoods. This results in a structure with many empty cells. Out of a total of 6120860 cells (considering the cross-classification), n=6118216 are empty cells. Out of the n=2644  non-empty cells, n=1835 (69.40%) have 84 observations per cell and n=4 have one observation per cell.


I suspect the issue is the fact that I have many NA in my data. My two variables with the smoothers have the following stats:


Variable        N       Mean    Std Dev Minimum Maximum
x3
x4

153369
148319

13.01
30.28

1.77
2.72

0
18.06

14.85
38.32




summary(newdata)
 y                          x1                   x2                      x3                         x4                              neigh                      STUDYID
 0:183335   Min.   : 2.000      F: 77972        Min.   : 0.00         Min.   :18.06             J0L 1B0:  2000       35     :    84
 1:  1901   1st Qu.: 4.195      M:107264     1st Qu.:12.19      1st Qu.:28.98            J0S 1K0:   526       122    :    84
                   Median : 7.047                           Median :13.85    Median :30.29          J0J 1K0:   504       193    :    84
                    Mean   : 7.866                            Mean   :13.01    Mean   :30.28           H4B 1N2:   480      231    :    84
                   3rd Qu.:11.044                            3rd Qu.:14.40    3rd Qu.:31.93          J0P 1P0:   336        248    :    84
                    Max.   :17.981                             Max.   :14.85    Max.   :38.33              J7T 2A1:   336       257    :    84
                                                                           NA's   :31867    NA's   :36917          (Other):181054(Other):184732

 str(newdata)

'data.frame': 185236 obs. of  7 variables:
 $ y      : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ x1     : num  16.9 16.9 16.9 16.9 16.9 ...
 $ x2     : Factor w/ 2 levels "F","M": 2 2 2 2 2 2 2 2 2 2 ...
 $ x3     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ x4     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ neigh  : Factor w/ 2314 levels "A3J 1A8","A3K 2V9",..: 802 802 802 802 802 802 802 802 802 802 ...
 $ STUDYID: Factor w/ 2206 levels "35","122","193",..: 1 1 1 1 1 1 1 1 1 1 ...

Thank you so much for all your help!

Best regards, everyone!

<http://aka.ms/weboutlook>
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, August 15, 2017 12:36:19 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] GAMM4 error


  We'd love to help, but it's really, really hard without a reproducible
example.  All the error message really tells us is that somewhere in the
guts there was something like a divide-by-zero error or an infinity
produced (because your data were weird, or because some value got really
small or really large and under/overflowed).

  A reproducible example would be ideal (see e.g.
<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>
), but in its absence, `summary(mydata)` or `str(mydata)` would be
useful.  For example:

- is y a 0/1 variable?
- are all of your x variables numeric, and not super-large in magnitude?
- do you have NA values in your data?
- how many distinct values (levels) of pupil and neigh do you have?
- how many observations overall?

On 17-08-15 03:07 PM, dani wrote:
> Hello everyone,
>
>
> I am a beginner struggling with GAMM4. I employed a GAMM4 model using
> a binomial distribution involving two smoothers and two random
> intercepts (corresponding to a structure involving observations
> cross-classified into two groups: pupils and neighbourhoods):
>
>
> model <- gamm4(y ~ x1+x2+s(x3)+s(x4), random=~ (1|pupil)+(1|neigh),
> data=mydata, family= binomial)
>
> I received the following error message: Error in
> smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) :
> NA/NaN/Inf in foreign function call (arg 1)
>
> I was wondering if anyone can please help me elucidate what might
> this mean.
>
> Best regards, everyone! Nicole-Miki
>
>
>
>
> <http://aka.ms/weboutlook>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 15 22:38:24 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Aug 2017 16:38:24 -0400
Subject: [R-sig-ME] GAMM4 error
In-Reply-To: <DM5PR12MB158047FB439E47AD99C029DFD68D0@DM5PR12MB1580.namprd12.prod.outlook.com>
References: <DM5PR12MB1580B74EFAF354E8D21DF768D68D0@DM5PR12MB1580.namprd12.prod.outlook.com>
 <9cbe6a91-1d65-913e-7ea1-038af1ad8156@gmail.com>
 <DM5PR12MB158047FB439E47AD99C029DFD68D0@DM5PR12MB1580.namprd12.prod.outlook.com>
Message-ID: <93746c34-412f-a82b-168e-2191ca6ee186@gmail.com>


  A couple of things to try first.  Not sure if either will work but
both are easy.

  Use na.omit() to remove values up front (do this only on the subset of
columns that you're actually going to use in your model, e.g.

  newdat <- na.omit(olddat[c("y","x1","x2","x3","x4","pupil","neigh")])

(this is irrelevant if your data set is already pared down to the
necessary set of columns).

  Change your y variable to numeric, i.e. data$y =
as.numeric(as.character(data$y))   *or* as.numeric(data$y)-1 (base R's
glm is very permissive about this, but GAMM4 might be stricter).



On 17-08-15 04:20 PM, dani wrote:
> Hello Ben,
> 
> 
> Thank you so much for your kind and prompt response. I provided a little
> bit more detail about my data. I really appreciate you taking the time
> to take a look over this information.
> 
> 
> Yes, y is a 0/1 variable.
> 
> 
> I have a total of  185,236 observations nested in n=2,206 pupils and n =
> 2,314 neighbourhoods. This results in a structure with many empty cells.
> Out of a total of 6120860 cells (considering the cross-classification),
> n=6118216 are empty cells. Out of the n=2644  non-empty cells, n=1835
> (69.40%) have 84 observations per cell and n=4 have one observation per
> cell. 
> 
> 
> I suspect the issue is the fact that I have many NA in my data. My two
> variables with the smoothers have the following stats:
> 
> 
> Variable 	N 	Mean 	Std Dev 	Minimum 	Maximum
> x3
> x4
> 
> 	
> 153369
> 148319
> 
> 	
> 13.01
> 30.28
> 
> 	
> 1.77
> 2.72
> 
> 	
> 0
> 18.06
> 
> 	
> 14.85
> 38.32
> 
> 
> *
> *
> 
> **
> 
> *summary(newdata)*
>  y                          x1                   x2                    
>  x3                         x4                              neigh      
>                STUDYID      
>  0:183335   Min.   : 2.000      F: 77972        Min.   : 0.00        
> Min.   :18.06             J0L 1B0:  2000       35     :    84  
>  1:  1901   1st Qu.: 4.195      M:107264     1st Qu.:12.19      1st
> Qu.:28.98            J0S 1K0:   526       122    :    84  
>                    Median : 7.047                           Median
> :13.85    Median :30.29          J0J 1K0:   504       193    :    84  
>                     Mean   : 7.866                            Mean  
> :13.01    Mean   :30.28           H4B 1N2:   480      231    :    84  
>                    3rd Qu.:11.044                            3rd
> Qu.:14.40    3rd Qu.:31.93          J0P 1P0:   336        248    :    84  
>                     Max.   :17.981                             Max.  
> :14.85    Max.   :38.33              J7T 2A1:   336       257    :    84  
>                                                                        
>    NA's   :31867    NA's   :36917          (Other):181054(Other):184732
> 
> * str(newdata)*
> *
> *
> 'data.frame':185236 obs. of  7 variables:
>  $ y      : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
>  $ x1     : num  16.9 16.9 16.9 16.9 16.9 ...
>  $ x2     : Factor w/ 2 levels "F","M": 2 2 2 2 2 2 2 2 2 2 ...
>  $ x3     : num  NA NA NA NA NA NA NA NA NA NA ...
>  $ x4     : num  NA NA NA NA NA NA NA NA NA NA ...
>  $ neigh  : Factor w/ 2314 levels "A3J 1A8","A3K 2V9",..: 802 802 802
> 802 802 802 802 802 802 802 ...
>  $ STUDYID: Factor w/ 2206 levels "35","122","193",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>  
> Thank you so much for all your help!
> 
> Best regards, everyone!
> 
> <http://aka.ms/weboutlook>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Tuesday, August 15, 2017 12:36:19 PM
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] GAMM4 error
>  
> 
>   We'd love to help, but it's really, really hard without a reproducible
> example.  All the error message really tells us is that somewhere in the
> guts there was something like a divide-by-zero error or an infinity
> produced (because your data were weird, or because some value got really
> small or really large and under/overflowed).
> 
>   A reproducible example would be ideal (see e.g.
> <https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>
> ), but in its absence, `summary(mydata)` or `str(mydata)` would be
> useful.  For example:
> 
> - is y a 0/1 variable?
> - are all of your x variables numeric, and not super-large in magnitude?
> - do you have NA values in your data?
> - how many distinct values (levels) of pupil and neigh do you have?
> - how many observations overall?
> 
> On 17-08-15 03:07 PM, dani wrote:
>> Hello everyone,
>> 
>> 
>> I am a beginner struggling with GAMM4. I employed a GAMM4 model using
>> a binomial distribution involving two smoothers and two random
>> intercepts (corresponding to a structure involving observations
>> cross-classified into two groups: pupils and neighbourhoods):
>> 
>> 
>> model <- gamm4(y ~ x1+x2+s(x3)+s(x4), random=~ (1|pupil)+(1|neigh),
>> data=mydata, family= binomial)
>> 
>> I received the following error message: Error in
>> smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) : 
>> NA/NaN/Inf in foreign function call (arg 1)
>> 
>> I was wondering if anyone can please help me elucidate what might
>> this mean.
>> 
>> Best regards, everyone! Nicole-Miki
>> 
>> 
>> 
>> 
>> <http://aka.ms/weboutlook>
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From lorin.raats at student.kuleuven.be  Wed Aug 16 11:26:55 2017
From: lorin.raats at student.kuleuven.be (Lorin Raats)
Date: Wed, 16 Aug 2017 09:26:55 +0000
Subject: [R-sig-ME] linear mixed models explained variances
Message-ID: <75a4f3fa76db4c19bb1d1dceb5f7a5dc@ICTS-S-EXMBX7.luna.kuleuven.be>

Dear all,

I am a student and currently working with linear mixed models in my master thesis. So far, I haven?t been able to find anyone who could help solve my questions, so I hope some of you have the time to look at them.

I have made models, which are of the structure:

           fit18=lmer(recru$observed~recru$predicted*total$MMIdata+(1|total$nursery))

First of all, I would like to determine the significance of the model. So far I have only been able to determine the significance of the separate factors. But I have read that p-values don?t really work with linear mixed models. So how can I find the significance of the model?

Second of all, I would like to determine the variance explained by the separate factors, I have so far:


  1.  Using r.squaredGLLM(fit18) from the MuMIn package, you get a conditional and a marginal R?. I have taken the conditional as the variance explained by my whole model. And I have taken the marginal as the variance explained by the fixed effects. Is this correct or did I make false assumptions?
  2.  Can I assume that the variance explained by the random effects is just the subtraction of conditional and marginal?
  3.  As I have three fixed factors in my model (two + interaction effect), I would like to see how much each of the fixed variables explains. I have followed a method I found online, but I am not that sure about the validity of this method. What I have used is:
                      fixedvaiance1= whole variance*fvariance1/(rvariance+fvariance1+fvariance2)

               (with r standing for random effect and f for fixed effect.)


                      If this method is false, what method an I follow to find the variance explained by each of my separate fixed factors?

I would like to thank you very much for having a look at my questions.

Kind regards,

Lorin Raats


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From b88207001 at ntu.edu.tw  Wed Aug 16 16:38:21 2017
From: b88207001 at ntu.edu.tw (b88207001 at ntu.edu.tw)
Date: Wed, 16 Aug 2017 22:38:21 +0800
Subject: [R-sig-ME] {nlme} Question about modeling Level two
	heteroscedasticity in HLM
Message-ID: <20170816223821.149014h38ozkrpb1@wmail1.cc.ntu.edu.tw>

Hello dear uesRs in mixed models,

I am working on modeling both level one and level two heteroscedasticity in
HLM. In my model, both error variance and variance of random intercept /
random slope are affected by some level two variables.

I found that nlme is able to model heteroscedasticity. I learned how to use
it for level one heteroscedasticity but don't know how to use it to model
the level two heteroscedasticity. I wonder if anyone could give me some
guide how to do it or any suggested software / packages (such as  
lme4?) if nlme is unable to do it.

Many thanks in advance!

Best,
Yen


From paul.johnson at glasgow.ac.uk  Wed Aug 16 17:20:14 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 16 Aug 2017 15:20:14 +0000
Subject: [R-sig-ME] linear mixed models explained variances
In-Reply-To: <75a4f3fa76db4c19bb1d1dceb5f7a5dc@ICTS-S-EXMBX7.luna.kuleuven.be>
References: <75a4f3fa76db4c19bb1d1dceb5f7a5dc@ICTS-S-EXMBX7.luna.kuleuven.be>
Message-ID: <5055FBDA-7964-4053-BD31-7C815C3DE073@glasgow.ac.uk>

Hi Lorin,

> I have made models, which are of the structure:
> 
>           fit18=lmer(recru$observed~recru$predicted*total$MMIdata+(1|total$nursery))

A side point: always use the data argument, so that the fitting function takes all the data from the same data frame:

          fit18=lmer(observed~predicted*MMIdata+(1|nursery), data = recru.total.merge)

This is less error prone than what you?ve done.

> First of all, I would like to determine the significance of the model. So far I have only been able to determine the significance of the separate factors. But I have read that p-values don?t really work with linear mixed models. So how can I find the significance of the model?

What do you mean by significance of the model? This implies that you want calculate a p-value for some null hypothesis. What null hypothesis? The null hypothesis that all the fixed parameters are zero? You can get this from 
anova(fit18, update(fit18, . ~ (1|nursery)))  # the models will be automatically refitted using ML

> Second of all, I would like to determine the variance explained by the separate factors, I have so far:
> 
>  1.  Using r.squaredGLLM(fit18) from the MuMIn package, you get a conditional and a marginal R?. I have taken the conditional as the variance explained by my whole model. And I have taken the marginal as the variance explained by the fixed effects. Is this correct or did I make false assumptions?

R2C is frequently interpreted as the variance explained by both the fixed and random effect, although I prefer to think of the random effect as a residual (unexplained) variance at a higher level (here unexplained variation between nurseries).

>  2.  Can I assume that the variance explained by the random effects is just the subtraction of conditional and marginal?

Yes, that?s the proportion of variance explained by the random effects.

>  3.  As I have three fixed factors in my model (two + interaction effect), I would like to see how much each of the fixed variables explains. I have followed a method I found online, but I am not that sure about the validity of this method. What I have used is:
>                      fixedvaiance1= whole variance*fvariance1/(rvariance+fvariance1+fvariance2)


I don?t understand the terms in this equation. To me, an intuitive way of gauging the contribution of a fixed effect would be to fit the model with and without the fixed effect and compare (subtract) either the marginal R-squared, or compare the fixed effect variances. The total variance of the fixed effects can be calculated as:

      var(model.matrix(fit) %*% fixef(fit))

This should give the same result as 

      var(predict(fit, re.form = ~ 0))


[Although I think strictly the model sums of squares should be compared instead, which will just be the var(?) * (n - 1)?]

Good luck,
Paul






From jmichaelrosenberg at gmail.com  Wed Aug 16 19:21:51 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Wed, 16 Aug 2017 13:21:51 -0400
Subject: [R-sig-ME] Comparing variance components of crossed effects
 models fit with lme4 and nlme
In-Reply-To: <CABghstQafxeBW108H=fHkcgpVoGA1+yk8uGNiEVp4Qm0mVsH3A@mail.gmail.com>
References: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
 <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>
 <CANYHYTR=tYd3HXDkBT1ZNvfvXh29wNbdFj7c5+13m7EGpYqacA@mail.gmail.com>
 <CABghstQafxeBW108H=fHkcgpVoGA1+yk8uGNiEVp4Qm0mVsH3A@mail.gmail.com>
Message-ID: <CANYHYTTUF0B_F4WtrPWXzmDSzZXzk+kSXjJaMXAaQ7uvFP_LtQ@mail.gmail.com>

Thank you for helping me build a "model" around these ideas and
distinctions.

Regarding point 2 (below), for software such as brms, I notice that some
kind of (sorry if my language is too loose here) estimate is produced for
fixed effects parameters, as well as their standard errors. Based on brm's
use (I think) of stochastic optimization and inferences based on means and
distributions, do these estimates correspond to something like the maximum
point - or rather to the mean of the posterior distribution?

thank you very much again
Josh

On Mon, Aug 14, 2017 at 6:54 PM, Ben Bolker <bbolker at gmail.com> wrote:

>   A couple of thoughts:
>
> (1) INLA *is* explicitly Bayesian, although I don't know what it
> specifies (implicitly or explicitly) for priors or whether it allows
> them to be user-adjusted (I'm too lazy to go look at the documentation
> or Google "INLA priors" right now ...)
> (2) it's worth making a distinction between
>     (a) stochastic optimization (as in Bayesian MCMC, or frequentist
> Monte Carlo expectation-maximization (MCEM) approaches) and
> hill-climbing/deterministic optimization (as in INLA, or lme4, or
> glmmTMB -- anything that says it uses the Laplace approximation, or
> Gaussian quadrature ...)
>    (b) inference based on a maximum point (MLE, or maximum a
> posteriori [MAP] estimates in the Bayesian world) and inferences based
> on means and distributions (MCMC). Typically the former goes with
> deterministic optimization and the latter goes with stochastic
> optimization
> (3) in addition to INLA, there are a variety of existing Bayesian
> machines in R (blme, MCMCglmm, brms, rstanarm ...) -- I think MCMCglmm
> and brms implement some flavours of (temporal) autoregression ...
>
>   Depending on the kind of autoregressive structure you want, glmmTMB
> is also a possibility.
>
> On Mon, Aug 14, 2017 at 12:23 PM, Joshua Rosenberg
> <jmichaelrosenberg at gmail.com> wrote:
> > Thank you, I will explore use of INLA (or potentially the brms package
> > because of my familiarity with the [lme4-like] syntax).
> >
> > I'm curious whether you (or anyone else) has thoughts / advice on using a
> > package that uses a Bayesian approach for carrying out mixed effects
> > modeling. In my field / area of research, mixed effects models are new!
> And
> > so a Bayesian approach to them would be *very *new. Even though if I
> > understand (very preliminarily), with some (uniform) prior specification,
> > results can be comparable to models specified with a maximum likelihood
> > approach, when possible.
> >
> > Thank you again!
> > Josh
> >
> > On Fri, Aug 11, 2017 at 8:38 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> > wrote:
> >
> >> Dear Joshua,
> >>
> >> Crossed random effects are difficult to specify in nlme. I think that
> you
> >> have to use pdBlocked() in the specification.
> >>
> >> When I need correlation I often use INLA (r-inla.org). It allows for
> >> correlated random effects. Crossed random effects are no problem.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> >> Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >>
> >> 2017-08-10 23:05 GMT+02:00 Joshua Rosenberg <
> jmichaelrosenberg at gmail.com>:
> >>
> >>> Hi all,
> >>>
> >>> I'm trying to fit models with a) crossed random effects and b) a
> specific
> >>> residual structure (auto-correlation). Based on my understanding of
> what
> >>> nlme and lme4 do well, I would normally turn to lme4 to fit a model
> with
> >>> crossed random effects, but because I'm trying to structure the
> residuals,
> >>> I am trying nlme.
> >>>
> >>> In trying to fit and compare the same variance components (no fixed
> >>> effects) model using lme4 and nlme, I found the output is similar but a
> >>> bit
> >>> different. Specifically, the standard deviations of the random effects
> and
> >>> the log-likelihood statistics are different. Would you expect the
> output
> >>> to
> >>> be a bit different?
> >>>
> >>> The models I fit to compare the output are here, though the output is
> also
> >>> here:
> >>> https://bookdown.org/jmichaelrosenberg/comparing_
> crossed_effects_models/
> >>>
> >>>
> >>> library(lme4)
> >>> library(nlme)
> >>>
> >>> m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data =
> >>> Penicillin)
> >>> m_lme4
> >>>
> >>> m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample = ~ 1),
> data
> >>> = Penicillin)
> >>> m_nlme
> >>>
> >>>
> >>> Thank you for considering this question,
> >>> Josh
> >>>
> >>> --
> >>> Joshua Rosenberg, Ph.D. Candidate
> >>> Educational Psychology
> >>> &
> >>>  Educational Technology
> >>> Michigan State University
> >>> http://jmichaelrosenberg.com
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >
> >
> > --
> > Joshua Rosenberg, Ph.D. Candidate
> > Educational Psychology
> > &
> >  Educational Technology
> > Michigan State University
> > http://jmichaelrosenberg.com
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
?&?
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 16 20:10:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Aug 2017 14:10:52 -0400
Subject: [R-sig-ME] Comparing variance components of crossed effects
 models fit with lme4 and nlme
In-Reply-To: <CANYHYTTUF0B_F4WtrPWXzmDSzZXzk+kSXjJaMXAaQ7uvFP_LtQ@mail.gmail.com>
References: <CANYHYTSLL260MDN6LTWN4h7wW1CDJYXyvPv=yHC267eYNTR7OQ@mail.gmail.com>
 <CAJuCY5xDgp5rCGU2BBmL1qmPnh3s0ncO6oZQjLQxo4BWZs8QZA@mail.gmail.com>
 <CANYHYTR=tYd3HXDkBT1ZNvfvXh29wNbdFj7c5+13m7EGpYqacA@mail.gmail.com>
 <CABghstQafxeBW108H=fHkcgpVoGA1+yk8uGNiEVp4Qm0mVsH3A@mail.gmail.com>
 <CANYHYTTUF0B_F4WtrPWXzmDSzZXzk+kSXjJaMXAaQ7uvFP_LtQ@mail.gmail.com>
Message-ID: <9995b6c8-e78e-d5ba-3e9e-a1a57c3635d6@gmail.com>


   Most Bayesian approaches use the mean of the marginal posterior
distribution as the point estimate (although the median would be a
defensible choice as well). (I assume brms is using the mean but haven't
looked at the code/docs to confirm.)  The maximum of the marginal
posterior distribution would also be fairly easy to compute, but doesn't
have as much meaning in the Bayesian case.  The maximum (mode) of the
*multivariate* posterior distribution is the closest analogue of the
maximum likelihood estimate (with a completely uninformative prior it
would be identical), but is hard to compute.

On 17-08-16 01:21 PM, Joshua Rosenberg wrote:
> Thank you for helping me build a "model" around these ideas and
> distinctions.
> 
> Regarding point 2 (below), for software such as brms, I notice that some
> kind of (sorry if my language is too loose here) estimate is produced
> for fixed effects parameters, as well as their standard errors. Based on
> brm's use (I think) of stochastic optimization and inferences based on
> means and distributions, do these estimates correspond to something like
> the maximum point - or rather to the mean of the posterior distribution?
> 
> thank you very much again
> Josh
> 
> On Mon, Aug 14, 2017 at 6:54 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>       A couple of thoughts:
> 
>     (1) INLA *is* explicitly Bayesian, although I don't know what it
>     specifies (implicitly or explicitly) for priors or whether it allows
>     them to be user-adjusted (I'm too lazy to go look at the documentation
>     or Google "INLA priors" right now ...)
>     (2) it's worth making a distinction between
>         (a) stochastic optimization (as in Bayesian MCMC, or frequentist
>     Monte Carlo expectation-maximization (MCEM) approaches) and
>     hill-climbing/deterministic optimization (as in INLA, or lme4, or
>     glmmTMB -- anything that says it uses the Laplace approximation, or
>     Gaussian quadrature ...)
>        (b) inference based on a maximum point (MLE, or maximum a
>     posteriori [MAP] estimates in the Bayesian world) and inferences based
>     on means and distributions (MCMC). Typically the former goes with
>     deterministic optimization and the latter goes with stochastic
>     optimization
>     (3) in addition to INLA, there are a variety of existing Bayesian
>     machines in R (blme, MCMCglmm, brms, rstanarm ...) -- I think MCMCglmm
>     and brms implement some flavours of (temporal) autoregression ...
> 
>       Depending on the kind of autoregressive structure you want, glmmTMB
>     is also a possibility.
> 
>     On Mon, Aug 14, 2017 at 12:23 PM, Joshua Rosenberg
>     <jmichaelrosenberg at gmail.com <mailto:jmichaelrosenberg at gmail.com>>
>     wrote:
>     > Thank you, I will explore use of INLA (or potentially the brms package
>     > because of my familiarity with the [lme4-like] syntax).
>     >
>     > I'm curious whether you (or anyone else) has thoughts / advice on using a
>     > package that uses a Bayesian approach for carrying out mixed effects
>     > modeling. In my field / area of research, mixed effects models are new! And
>     > so a Bayesian approach to them would be *very *new. Even though if I
>     > understand (very preliminarily), with some (uniform) prior
>     specification,
>     > results can be comparable to models specified with a maximum
>     likelihood
>     > approach, when possible.
>     >
>     > Thank you again!
>     > Josh
>     >
>     > On Fri, Aug 11, 2017 at 8:38 AM, Thierry Onkelinx
>     <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>     > wrote:
>     >
>     >> Dear Joshua,
>     >>
>     >> Crossed random effects are difficult to specify in nlme. I think
>     that you
>     >> have to use pdBlocked() in the specification.
>     >>
>     >> When I need correlation I often use INLA (r-inla.org
>     <http://r-inla.org>). It allows for
>     >> correlated random effects. Crossed random effects are no problem.
>     >>
>     >> Best regards,
>     >>
>     >> ir. Thierry Onkelinx
>     >> Instituut voor natuur- en bosonderzoek / Research Institute for
>     Nature and
>     >> Forest
>     >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>     >> Kliniekstraat 25
>     >> 1070 Anderlecht
>     >> Belgium
>     >>
>     >> To call in the statistician after the experiment is done may be
>     no more
>     >> than asking him to perform a post-mortem examination: he may be
>     able to say
>     >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     >> The plural of anecdote is not data. ~ Roger Brinner
>     >> The combination of some data and an aching desire for an answer
>     does not
>     >> ensure that a reasonable answer can be extracted from a given
>     body of data.
>     >> ~ John Tukey
>     >>
>     >> 2017-08-10 23:05 GMT+02:00 Joshua Rosenberg
>     <jmichaelrosenberg at gmail.com <mailto:jmichaelrosenberg at gmail.com>>:
>     >>
>     >>> Hi all,
>     >>>
>     >>> I'm trying to fit models with a) crossed random effects and b) a
>     specific
>     >>> residual structure (auto-correlation). Based on my understanding
>     of what
>     >>> nlme and lme4 do well, I would normally turn to lme4 to fit a
>     model with
>     >>> crossed random effects, but because I'm trying to structure the
>     residuals,
>     >>> I am trying nlme.
>     >>>
>     >>> In trying to fit and compare the same variance components (no fixed
>     >>> effects) model using lme4 and nlme, I found the output is
>     similar but a
>     >>> bit
>     >>> different. Specifically, the standard deviations of the random
>     effects and
>     >>> the log-likelihood statistics are different. Would you expect
>     the output
>     >>> to
>     >>> be a bit different?
>     >>>
>     >>> The models I fit to compare the output are here, though the
>     output is also
>     >>> here:
>     >>>
>     https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/
>     <https://bookdown.org/jmichaelrosenberg/comparing_crossed_effects_models/>
>     >>>
>     >>>
>     >>> library(lme4)
>     >>> library(nlme)
>     >>>
>     >>> m_lme4 <- lmer(diameter ~ 1 + (1 | plate) + (1 | sample), data =
>     >>> Penicillin)
>     >>> m_lme4
>     >>>
>     >>> m_nlme <- lme(diameter ~ 1, random = list(plate = ~ 1, sample =
>     ~ 1), data
>     >>> = Penicillin)
>     >>> m_nlme
>     >>>
>     >>>
>     >>> Thank you for considering this question,
>     >>> Josh
>     >>>
>     >>> --
>     >>> Joshua Rosenberg, Ph.D. Candidate
>     >>> Educational Psychology
>     >>> &
>     >>>  Educational Technology
>     >>> Michigan State University
>     >>> http://jmichaelrosenberg.com
>     >>>
>     >>>         [[alternative HTML version deleted]]
>     >>>
>     >>> _______________________________________________
>     >>> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>
>     >>
>     >>
>     >
>     >
>     > --
>     > Joshua Rosenberg, Ph.D. Candidate
>     > Educational Psychology
>     > &
>     >  Educational Technology
>     > Michigan State University
>     > http://jmichaelrosenberg.com
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> 
> -- 
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology 
> ?&?
>  Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com <http://jmichaelrosenberg.com/>


From b88207001 at ntu.edu.tw  Thu Aug 17 15:53:17 2017
From: b88207001 at ntu.edu.tw (b88207001 at ntu.edu.tw)
Date: Thu, 17 Aug 2017 21:53:17 +0800
Subject: [R-sig-ME] {nlme} Question about modeling Level two
 heteroscedasticity in HLM
In-Reply-To: <20170816223821.149014h38ozkrpb1@wmail1.cc.ntu.edu.tw>
References: <20170816223821.149014h38ozkrpb1@wmail1.cc.ntu.edu.tw>
Message-ID: <20170817215317.72304nd0g40p0kb1@wmail1.cc.ntu.edu.tw>



Hello dear uesRs in mixed models,

I am working on modeling both level one and level two  
heteroscedasticity in HLM. In my model, both error variance and  
variance of random intercept / random slope are affected by some level  
two variables.

I found that nlme is able to model heteroscedasticity. I learned how  
to use it for level one heteroscedasticity but don't know how to use  
it to model the level two heteroscedasticity. I wonder if anyone could  
give me some guide how to do it or any suggested software / packages  
(such as lme4?) if nlme is unable to do it.

Many thanks in advance!

Best,
Yen


From phillip.alday at mpi.nl  Thu Aug 17 16:09:23 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 17 Aug 2017 16:09:23 +0200
Subject: [R-sig-ME] {nlme} Question about modeling Level two
 heteroscedasticity in HLM
In-Reply-To: <20170817215317.72304nd0g40p0kb1@wmail1.cc.ntu.edu.tw>
References: <20170816223821.149014h38ozkrpb1@wmail1.cc.ntu.edu.tw>
 <20170817215317.72304nd0g40p0kb1@wmail1.cc.ntu.edu.tw>
Message-ID: <5995A393.7080904@mpi.nl>

I'm not sure, but I think

1. the random slopes may be able to handle this without really doing
anything special

2. in a variation on that idea, you could also the same variable as a
fixed effect and as a grouping variable for a random intercept (see e.g.
Thierry Onkelinx's quadratic example:
http://rpubs.com/INBOstats/both_fixed_random )

3. in yet another variation on that same idea, you could also have an
observation-level random effect.

There may additionally be ways of modelling this by specifying some
covariance structure in nlme.

Phillip

On 08/17/2017 03:53 PM, b88207001 at ntu.edu.tw wrote:
> 
> 
> Hello dear uesRs in mixed models,
> 
> I am working on modeling both level one and level two heteroscedasticity
> in HLM. In my model, both error variance and variance of random
> intercept / random slope are affected by some level two variables.
> 
> I found that nlme is able to model heteroscedasticity. I learned how to
> use it for level one heteroscedasticity but don't know how to use it to
> model the level two heteroscedasticity. I wonder if anyone could give me
> some guide how to do it or any suggested software / packages (such as
> lme4?) if nlme is unable to do it.
> 
> Many thanks in advance!
> 
> Best,
> Yen
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s4anwoel at uni-trier.de  Thu Aug 17 19:09:39 2017
From: s4anwoel at uni-trier.de (=?iso-8859-1?Q?W=F6lwer=2C_Anna-Lena?=)
Date: Thu, 17 Aug 2017 17:09:39 +0000
Subject: [R-sig-ME] nlme package,
	fixing variance.covariance matrix of residuals
Message-ID: <59d7a94460ed456abf043d0d89adc022@uni-trier.de>

Dear R team,

I would like to do a multivariate meta-analysis in R using the nlme package. In meta-analysis I fix the residuals to known sampling errors. As I do a multivariate analysis, I have a variance-covariance matrix of sampling errors. Unfortunately, via varFixed I can only fix a vector of sampling errors and no matrix.

In the R package metafor using the rma.mv function I can insert the variance-covariance matrix in the function. I would like to do the same with lme from the nlme package as nlme provides more flexibility for my model.

Do you now any possibility of doing so in nlme? Are there any changes planned to incorporate this feature?

Best wishes, I am looking forward to your feedback
Anna-Lena W?lwer


	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Thu Aug 17 22:50:37 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 17 Aug 2017 22:50:37 +0200
Subject: [R-sig-ME] nlme package,
 fixing variance.covariance matrix of residuals
In-Reply-To: <27b54841-0818-49d6-9a79-6757b9792188@mpi.nl>
References: <59d7a94460ed456abf043d0d89adc022@uni-trier.de>
 <27b54841-0818-49d6-9a79-6757b9792188@mpi.nl>
Message-ID: <cd806734-4163-9437-3318-5c5967cab169@mpi.nl>

This is an indirect (non)-answer, but Wolfgang Viechtbauer has a nice
comparison of lme and rma in the metafor online documentation:

http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer

It might be possible to figure out your problem from that -- and if you
do, please 'self-answer' on the list to document it for other users!

Best,
Phillip

On 08/17/2017 07:09 PM, W?lwer, Anna-Lena wrote:
> Dear R team,
>
> I would like to do a multivariate meta-analysis in R using the nlme package. In meta-analysis I fix the residuals to known sampling errors. As I do a multivariate analysis, I have a variance-covariance matrix of sampling errors. Unfortunately, via varFixed I can only fix a vector of sampling errors and no matrix.
>
> In the R package metafor using the rma.mv function I can insert the variance-covariance matrix in the function. I would like to do the same with lme from the nlme package as nlme provides more flexibility for my model.
>
> Do you now any possibility of doing so in nlme? Are there any changes planned to incorporate this feature?
>
> Best wishes, I am looking forward to your feedback
> Anna-Lena W?lwer
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Aug 17 23:13:42 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Thu, 17 Aug 2017 21:13:42 +0000
Subject: [R-sig-ME] nlme package,
 fixing variance.covariance matrix of residuals
In-Reply-To: <cd806734-4163-9437-3318-5c5967cab169@mpi.nl>
References: <59d7a94460ed456abf043d0d89adc022@uni-trier.de>
 <27b54841-0818-49d6-9a79-6757b9792188@mpi.nl>
 <cd806734-4163-9437-3318-5c5967cab169@mpi.nl>
Message-ID: <34063fa110f847a2be5f64808a18f843@UM-MAIL3216.unimaas.nl>

To address the original question directly: No, this isn't possible with nlme (you can only specify known variances, not an entire var-cox matrix).

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Phillip Alday
Sent: Thursday, August 17, 2017 22:51
To: W?lwer, Anna-Lena; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme package, fixing variance.covariance matrix of residuals

This is an indirect (non)-answer, but Wolfgang Viechtbauer has a nice
comparison of lme and rma in the metafor online documentation:

http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer

It might be possible to figure out your problem from that -- and if you
do, please 'self-answer' on the list to document it for other users!

Best,
Phillip

On 08/17/2017 07:09 PM, W?lwer, Anna-Lena wrote:
> Dear R team,
>
> I would like to do a multivariate meta-analysis in R using the nlme package. In meta-analysis I fix the residuals to known sampling errors. As I do a multivariate analysis, I have a variance-covariance matrix of sampling errors. Unfortunately, via varFixed I can only fix a vector of sampling errors and no matrix.
>
> In the R package metafor using the rma.mv function I can insert the variance-covariance matrix in the function. I would like to do the same with lme from the nlme package as nlme provides more flexibility for my model.
>
> Do you now any possibility of doing so in nlme? Are there any changes planned to incorporate this feature?
>
> Best wishes, I am looking forward to your feedback
> Anna-Lena W?lwer

From jpouzou at epixanalytics.com  Mon Aug 21 21:01:10 2017
From: jpouzou at epixanalytics.com (Jane Pouzou)
Date: Mon, 21 Aug 2017 19:01:10 +0000
Subject: [R-sig-ME] Meta-regression of left-censored data with the blme
	package
Message-ID: <MWHPR20MB148753A447D8C3A651E1A4A2A7870@MWHPR20MB1487.namprd20.prod.outlook.com>

Hello Mixed Modelers,

I'm using the blmer function within the blme package with a residual point prior of 1 to perform a random effects meta-analysis.  The dependent variable is left-censored (due to a limit of detection),  and at the moment I'm interpolating the log-transformed outcome using a linear regression before fitting the meta-regression separately.  I'm looking for a way to fit a censored regression rather than separating the two steps, while still using the blmer function.  Has anyone had any experience with blmer and censored data?

Thank you,

Jane Pouzou

	[[alternative HTML version deleted]]


From gregd at gn.apc.org  Mon Aug 21 22:21:32 2017
From: gregd at gn.apc.org (Greg Dropkin)
Date: Mon, 21 Aug 2017 21:21:32 +0100 (BST)
Subject: [R-sig-ME] random effects CIs
Message-ID: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>

Dear list

apologies if these questions have already been answered here - if so just
point me to them.

Am I implementing these 4 approaches to CIs for the random effects
correctly (for Dyestuff), and if so, which is best (or is "best"
meaningless)? bootMer use.u=FALSE seems to be recommended in the lme4
manual, but gives quite different results to the other 3 which are roughly
comparable. Is there a better way?

thanks

Greg Dropkin

--

library(lme4)
library(lattice)
library(boot)
library(R2jags)

#1
#as in Ch 1 of Douglas Bates' book on lme4:
fm01<-lmer(Yield~1+(1|Batch),data=Dyestuff)
dotplot(ranef(fm01,condVar=TRUE))

attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")
#all the same
sd1<-attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")[[1]]^0.5
sd1
#the estimates are ranef(fm01), and the CIs shown in the dotplot are +/-
sd1*qnorm(0.975)
#e.g. for Batch A:
ranef(fm01)$Batch[1,]
ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)

#2
#as recommended in the lme4 manual
#bootMer with use.u=FALSE
g<-function(.) ranef(.)$Batch[1,]
bootg<-bootMer(fm01,g,seed=1,nsim=1000,use.u=FALSE,.progress="txt",PBarg=list(style=3))
boot.ci(bootg,type=c("norm","basic","perc"))

#3
#bootMer with use.u=TRUE
bootgu<-bootMer(fm01,g,seed=1,nsim=1000,use.u=TRUE,.progress="txt",PBarg=list(style=3))
boot.ci(bootgu,type=c("norm","basic","perc"))

#4
#R2jags
I<-1:30
J<-1+floor((I-1)/5)

zY<-with(Dyestuff,(Yield-mean(Yield))/sd(Yield))
sdY<-with(Dyestuff,sd(Yield))

mod1.data<-list("zY","I","J")
mod1.parameters<-c("Con.adj","a.adj","mu.a","sigma.a","sig")

mod1.mod<-function()
{
Con.adj<-Con+mean(a[])
for (j in 1:6)
{
a[j]~dnorm(mu.a,1/sigma.a^2)
a.adj[j]<-a[j]-mean(a[])
}

for (i in I)
{
zY[i]~dnorm(lp[i],1/sig^2)
lp[i]<-Con+a[J[i]]
}
Con~dnorm(0,0.000001)
mu.a~dnorm(0,0.0001)
sigma.a~dunif(0,100)
sig~dunif(0,100)
}

set.seed(1)
mod1.mod.fit<-jags(data=mod1.data, inits=NULL,
parameters.to.save=mod1.parameters, n.chains=3, n.iter=50000,
n.burnin=10000, model.file=mod1.mod)
mod1.mod.fit
mat1<-mod1.mod.fit$BUGSoutput$sims.matrix

mean(mat1[,1]+mat1[,2])*sdY
quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY

#comparison

cim<-matrix(0,8,3)
rownames(cim)<-c("conditional sd","bootMer use.u=F norm","bootMer use.u=F
basic","bootMer use.u=F perc","bootMer use.u=T norm","bootMer use.u=T
basic","bootMer use.u=T perc","jags")
colnames(cim)<-c("estimate","low","high")
cim[1:7,1]<-ranef(fm01)$Batch[1,]
cim[1,2:3]<-ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
cim[2,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$norm[,2:3]
cim[3,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$basic[,4:5]
cim[4,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$perc[,4:5]
cim[5,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$norm[,2:3]
cim[6,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$basic[,4:5]
cim[7,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$perc[,4:5]
cim[8,1]<-mean(mat1[,1]+mat1[,2])*sdY
cim[8,2:3]<-quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY

cim


From rmaialists at gmail.com  Tue Aug 22 02:29:32 2017
From: rmaialists at gmail.com (Rafael Maia)
Date: Mon, 21 Aug 2017 17:29:32 -0700
Subject: [R-sig-ME] Multi-response MCMCglmm and multivariate location effects
Message-ID: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>

Dear list, 

Suppose I have a dataset consisting of 3 continuous, Gaussian variables and 1 categorical variable. I would like to run a multi-response model using the 3 continuous variables as response variables and the categorical variable as a predictor. These 3 variables are somewhat arbitrary, simply representing XYZ Cartesian coordinates, and it is not particularly easy to interpret them individually. They are also in different scales and the effect of the predictor can have different signs and magnitudes on the variables. Therefore, I?m mostly interested in understanding if the categorical variable influences the overall location of the sample in this multivariate cartesian space - as a simple MANOVA would. 

I?ve looked into MCMCglmm as what seems to be the best approach to this question, and one I?m a bit familiar with. From my understanding, there are two different ways I could parametrize the fixed part of my model:

1) fixed = cbind(x,y,z) ~ trait:predictor-1, which would estimate the effects of the predictor across each of the 3 responses individually, and is like an interaction between the predictor and the responses;

2) fixed = cbind(x,y,z) ~ trait+predictor-1, which would estimate a single effect across all responses, and from what I understand, fundamentally assumes that the effect of the predictor is of the same magnitude and in the same direction across all responses.

So from my understanding, I _think_ I would want something similar to (2); however, because of the structure of the data as described above, the effect of the categorical predictor will often not be of the same magnitude/direction across xyz, so that doesn?t seem to be an appropriate model. I would rather not make my inference based on the trait:predictor fixed effects structure because, from my naive understanding, I guess this would be akin to running 3 ANOVAs instead of a MANOVA, and beat the purpose of using a multi-response model? And I think it would also be possible to not have above-zero effect on any of the 3 variables independently, yet still have a measurable difference in the multivariate location of the groups?

I guess this question is somewhat related to model selection, for which there doesn?t seem to have a satisfactory approach for when using  MCMCglmm? I remember reading somewhere that DIC model selection for models with different fixed effects wasn?t really recommended. 

(As you?d expect, this is a simplified version of the dataset I have, where there are multiple predictors and random effects, to demo these issues, which is why I?m looking for a solution using MCMCglmm!)

I?ve uploaded some code to reproduce what I?m trying to describe here: http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>

Any help would be greatly appreciated. Thanks!

Best,
Rafael Maia
?
Simons Junior Fellow, Columbia University
Rubenstein Lab
Department of Ecology, Evolution and Environmental Biology
New York, NY
http://www.rafaelmaia.net 
	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Mon Aug 28 10:34:34 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Mon, 28 Aug 2017 10:34:34 +0200
Subject: [R-sig-ME] random effects CIs
In-Reply-To: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>
References: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>
Message-ID: <0339885e-6f4c-c287-9440-ec65e7ada94d@mpi.nl>

Hi Greg,

I haven't checked your code for correctness, but the pattern you've
found is typical. I don't know if there is a "best" answer, but broader
confidence intervals are more conservative and so should have better
coverage, if that's what you're going for.  The biggest difference for 
use.u=FALSE is how the random effects are handled, from the Details for
?bootMer:

>  If ?use.u? is ?FALSE? and ?type? is ?"parametric"?, each
>  simulation generates new values of both the ?_spherical_?
>  random effects u and the i.i.d. errors epsilon, using
>  ?rnorm()? with parameters corresponding to the fitted model
>  ?x?.
>
>  If ?use.u? is ?TRUE? and ?type=="parametric"?, only the
>  i.i.d. errors (or, for GLMMs, response values drawn from the
>  appropriate distributions) are resampled, with the values of
>  u staying fixed at their estimated values.

In other words, use.u=FALSE generates new levels of the random effects,
so in the case of Dyestuff, it simulates new, unseen Batches based on
the estimates of the between-Batch variance. In the use.u=TRUE case, it
re-uses the observed Batches and just simulates the observation-level /
residual error.  So, the use.u=FALSE case introduces "new" variation /
models additional variation and has broader confidence intervals. If I'm
not mistaken, this is related to the difference between prediction and
confidence intervals.

Best,
Phillip



On 08/21/2017 10:21 PM, Greg Dropkin wrote:
> Dear list
>
> apologies if these questions have already been answered here - if so just
> point me to them.
>
> Am I implementing these 4 approaches to CIs for the random effects
> correctly (for Dyestuff), and if so, which is best (or is "best"
> meaningless)? bootMer use.u=FALSE seems to be recommended in the lme4
> manual, but gives quite different results to the other 3 which are roughly
> comparable. Is there a better way?
>
> thanks
>
> Greg Dropkin
>
> --
>
> library(lme4)
> library(lattice)
> library(boot)
> library(R2jags)
>
> #1
> #as in Ch 1 of Douglas Bates' book on lme4:
> fm01<-lmer(Yield~1+(1|Batch),data=Dyestuff)
> dotplot(ranef(fm01,condVar=TRUE))
>
> attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")
> #all the same
> sd1<-attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")[[1]]^0.5
> sd1
> #the estimates are ranef(fm01), and the CIs shown in the dotplot are +/-
> sd1*qnorm(0.975)
> #e.g. for Batch A:
> ranef(fm01)$Batch[1,]
> ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>
> #2
> #as recommended in the lme4 manual
> #bootMer with use.u=FALSE
> g<-function(.) ranef(.)$Batch[1,]
> bootg<-bootMer(fm01,g,seed=1,nsim=1000,use.u=FALSE,.progress="txt",PBarg=list(style=3))
> boot.ci(bootg,type=c("norm","basic","perc"))
>
> #3
> #bootMer with use.u=TRUE
> bootgu<-bootMer(fm01,g,seed=1,nsim=1000,use.u=TRUE,.progress="txt",PBarg=list(style=3))
> boot.ci(bootgu,type=c("norm","basic","perc"))
>
> #4
> #R2jags
> I<-1:30
> J<-1+floor((I-1)/5)
>
> zY<-with(Dyestuff,(Yield-mean(Yield))/sd(Yield))
> sdY<-with(Dyestuff,sd(Yield))
>
> mod1.data<-list("zY","I","J")
> mod1.parameters<-c("Con.adj","a.adj","mu.a","sigma.a","sig")
>
> mod1.mod<-function()
> {
> Con.adj<-Con+mean(a[])
> for (j in 1:6)
> {
> a[j]~dnorm(mu.a,1/sigma.a^2)
> a.adj[j]<-a[j]-mean(a[])
> }
>
> for (i in I)
> {
> zY[i]~dnorm(lp[i],1/sig^2)
> lp[i]<-Con+a[J[i]]
> }
> Con~dnorm(0,0.000001)
> mu.a~dnorm(0,0.0001)
> sigma.a~dunif(0,100)
> sig~dunif(0,100)
> }
>
> set.seed(1)
> mod1.mod.fit<-jags(data=mod1.data, inits=NULL,
> parameters.to.save=mod1.parameters, n.chains=3, n.iter=50000,
> n.burnin=10000, model.file=mod1.mod)
> mod1.mod.fit
> mat1<-mod1.mod.fit$BUGSoutput$sims.matrix
>
> mean(mat1[,1]+mat1[,2])*sdY
> quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>
> #comparison
>
> cim<-matrix(0,8,3)
> rownames(cim)<-c("conditional sd","bootMer use.u=F norm","bootMer use.u=F
> basic","bootMer use.u=F perc","bootMer use.u=T norm","bootMer use.u=T
> basic","bootMer use.u=T perc","jags")
> colnames(cim)<-c("estimate","low","high")
> cim[1:7,1]<-ranef(fm01)$Batch[1,]
> cim[1,2:3]<-ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
> cim[2,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$norm[,2:3]
> cim[3,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$basic[,4:5]
> cim[4,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$perc[,4:5]
> cim[5,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$norm[,2:3]
> cim[6,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$basic[,4:5]
> cim[7,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$perc[,4:5]
> cim[8,1]<-mean(mat1[,1]+mat1[,2])*sdY
> cim[8,2:3]<-quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>
> cim
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From phillip.alday at mpi.nl  Mon Aug 28 12:04:27 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Mon, 28 Aug 2017 12:04:27 +0200
Subject: [R-sig-ME] random effects CIs
In-Reply-To: <58872.10.254.253.3.1503914045.squirrel@sqmail.gn.apc.org>
References: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>
 <0339885e-6f4c-c287-9440-ec65e7ada94d@mpi.nl>
 <58872.10.254.253.3.1503914045.squirrel@sqmail.gn.apc.org>
Message-ID: <399e7a49-9a21-8a83-2f3c-b4e99b3c83d4@mpi.nl>

I'm less surprised -- the credible interval constructed with JAGS is for
the current model fit, i.e. without estimating additional levels of the
random effects. This is in line with the Bayesian way of conditioning on
the observed data. (Maybe one of the better Bayesians on the list can
better comment on this point.)

Phillip

On 08/28/2017 11:54 AM, Greg Dropkin wrote:
> Hi Phillip
>
> Thanks. Yes, I was aware of your points but what surprised me was that the
> R2jags CI was closer to use.u = true.
>
> Greg
>
>> Hi Greg,
>>
>> I haven't checked your code for correctness, but the pattern you've
>> found is typical. I don't know if there is a "best" answer, but broader
>> confidence intervals are more conservative and so should have better
>> coverage, if that's what you're going for.  The biggest difference for
>> use.u=FALSE is how the random effects are handled, from the Details for
>> ?bootMer:
>>
>>>  If ?use.u? is ?FALSE? and ?type? is ?"parametric"?, each
>>>  simulation generates new values of both the ?_spherical_?
>>>  random effects u and the i.i.d. errors epsilon, using
>>>  ?rnorm()? with parameters corresponding to the fitted model
>>>  ?x?.
>>>
>>>  If ?use.u? is ?TRUE? and ?type=="parametric"?, only the
>>>  i.i.d. errors (or, for GLMMs, response values drawn from the
>>>  appropriate distributions) are resampled, with the values of
>>>  u staying fixed at their estimated values.
>> In other words, use.u=FALSE generates new levels of the random effects,
>> so in the case of Dyestuff, it simulates new, unseen Batches based on
>> the estimates of the between-Batch variance. In the use.u=TRUE case, it
>> re-uses the observed Batches and just simulates the observation-level /
>> residual error.  So, the use.u=FALSE case introduces "new" variation /
>> models additional variation and has broader confidence intervals. If I'm
>> not mistaken, this is related to the difference between prediction and
>> confidence intervals.
>>
>> Best,
>> Phillip
>>
>>
>>
>> On 08/21/2017 10:21 PM, Greg Dropkin wrote:
>>> Dear list
>>>
>>> apologies if these questions have already been answered here - if so
>>> just
>>> point me to them.
>>>
>>> Am I implementing these 4 approaches to CIs for the random effects
>>> correctly (for Dyestuff), and if so, which is best (or is "best"
>>> meaningless)? bootMer use.u=FALSE seems to be recommended in the lme4
>>> manual, but gives quite different results to the other 3 which are
>>> roughly
>>> comparable. Is there a better way?
>>>
>>> thanks
>>>
>>> Greg Dropkin
>>>
>>> --
>>>
>>> library(lme4)
>>> library(lattice)
>>> library(boot)
>>> library(R2jags)
>>>
>>> #1
>>> #as in Ch 1 of Douglas Bates' book on lme4:
>>> fm01<-lmer(Yield~1+(1|Batch),data=Dyestuff)
>>> dotplot(ranef(fm01,condVar=TRUE))
>>>
>>> attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")
>>> #all the same
>>> sd1<-attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")[[1]]^0.5
>>> sd1
>>> #the estimates are ranef(fm01), and the CIs shown in the dotplot are +/-
>>> sd1*qnorm(0.975)
>>> #e.g. for Batch A:
>>> ranef(fm01)$Batch[1,]
>>> ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>>>
>>> #2
>>> #as recommended in the lme4 manual
>>> #bootMer with use.u=FALSE
>>> g<-function(.) ranef(.)$Batch[1,]
>>> bootg<-bootMer(fm01,g,seed=1,nsim=1000,use.u=FALSE,.progress="txt",PBarg=list(style=3))
>>> boot.ci(bootg,type=c("norm","basic","perc"))
>>>
>>> #3
>>> #bootMer with use.u=TRUE
>>> bootgu<-bootMer(fm01,g,seed=1,nsim=1000,use.u=TRUE,.progress="txt",PBarg=list(style=3))
>>> boot.ci(bootgu,type=c("norm","basic","perc"))
>>>
>>> #4
>>> #R2jags
>>> I<-1:30
>>> J<-1+floor((I-1)/5)
>>>
>>> zY<-with(Dyestuff,(Yield-mean(Yield))/sd(Yield))
>>> sdY<-with(Dyestuff,sd(Yield))
>>>
>>> mod1.data<-list("zY","I","J")
>>> mod1.parameters<-c("Con.adj","a.adj","mu.a","sigma.a","sig")
>>>
>>> mod1.mod<-function()
>>> {
>>> Con.adj<-Con+mean(a[])
>>> for (j in 1:6)
>>> {
>>> a[j]~dnorm(mu.a,1/sigma.a^2)
>>> a.adj[j]<-a[j]-mean(a[])
>>> }
>>>
>>> for (i in I)
>>> {
>>> zY[i]~dnorm(lp[i],1/sig^2)
>>> lp[i]<-Con+a[J[i]]
>>> }
>>> Con~dnorm(0,0.000001)
>>> mu.a~dnorm(0,0.0001)
>>> sigma.a~dunif(0,100)
>>> sig~dunif(0,100)
>>> }
>>>
>>> set.seed(1)
>>> mod1.mod.fit<-jags(data=mod1.data, inits=NULL,
>>> parameters.to.save=mod1.parameters, n.chains=3, n.iter=50000,
>>> n.burnin=10000, model.file=mod1.mod)
>>> mod1.mod.fit
>>> mat1<-mod1.mod.fit$BUGSoutput$sims.matrix
>>>
>>> mean(mat1[,1]+mat1[,2])*sdY
>>> quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>>
>>> #comparison
>>>
>>> cim<-matrix(0,8,3)
>>> rownames(cim)<-c("conditional sd","bootMer use.u=F norm","bootMer
>>> use.u=F
>>> basic","bootMer use.u=F perc","bootMer use.u=T norm","bootMer use.u=T
>>> basic","bootMer use.u=T perc","jags")
>>> colnames(cim)<-c("estimate","low","high")
>>> cim[1:7,1]<-ranef(fm01)$Batch[1,]
>>> cim[1,2:3]<-ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>>> cim[2,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$norm[,2:3]
>>> cim[3,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$basic[,4:5]
>>> cim[4,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$perc[,4:5]
>>> cim[5,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$norm[,2:3]
>>> cim[6,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$basic[,4:5]
>>> cim[7,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$perc[,4:5]
>>> cim[8,1]<-mean(mat1[,1]+mat1[,2])*sdY
>>> cim[8,2:3]<-quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>>
>>> cim
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>


From gregd at gn.apc.org  Mon Aug 28 11:54:05 2017
From: gregd at gn.apc.org (Greg Dropkin)
Date: Mon, 28 Aug 2017 10:54:05 +0100 (BST)
Subject: [R-sig-ME] random effects CIs
In-Reply-To: <0339885e-6f4c-c287-9440-ec65e7ada94d@mpi.nl>
References: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>
 <0339885e-6f4c-c287-9440-ec65e7ada94d@mpi.nl>
Message-ID: <58872.10.254.253.3.1503914045.squirrel@sqmail.gn.apc.org>

Hi Phillip

Thanks. Yes, I was aware of your points but what surprised me was that the
R2jags CI was closer to use.u = true.

Greg

> Hi Greg,
>
> I haven't checked your code for correctness, but the pattern you've
> found is typical. I don't know if there is a "best" answer, but broader
> confidence intervals are more conservative and so should have better
> coverage, if that's what you're going for.  The biggest difference for
> use.u=FALSE is how the random effects are handled, from the Details for
> ?bootMer:
>
>>  If ?use.u? is ?FALSE? and ?type? is ?"parametric"?, each
>>  simulation generates new values of both the ?_spherical_?
>>  random effects u and the i.i.d. errors epsilon, using
>>  ?rnorm()? with parameters corresponding to the fitted model
>>  ?x?.
>>
>>  If ?use.u? is ?TRUE? and ?type=="parametric"?, only the
>>  i.i.d. errors (or, for GLMMs, response values drawn from the
>>  appropriate distributions) are resampled, with the values of
>>  u staying fixed at their estimated values.
>
> In other words, use.u=FALSE generates new levels of the random effects,
> so in the case of Dyestuff, it simulates new, unseen Batches based on
> the estimates of the between-Batch variance. In the use.u=TRUE case, it
> re-uses the observed Batches and just simulates the observation-level /
> residual error.  So, the use.u=FALSE case introduces "new" variation /
> models additional variation and has broader confidence intervals. If I'm
> not mistaken, this is related to the difference between prediction and
> confidence intervals.
>
> Best,
> Phillip
>
>
>
> On 08/21/2017 10:21 PM, Greg Dropkin wrote:
>> Dear list
>>
>> apologies if these questions have already been answered here - if so
>> just
>> point me to them.
>>
>> Am I implementing these 4 approaches to CIs for the random effects
>> correctly (for Dyestuff), and if so, which is best (or is "best"
>> meaningless)? bootMer use.u=FALSE seems to be recommended in the lme4
>> manual, but gives quite different results to the other 3 which are
>> roughly
>> comparable. Is there a better way?
>>
>> thanks
>>
>> Greg Dropkin
>>
>> --
>>
>> library(lme4)
>> library(lattice)
>> library(boot)
>> library(R2jags)
>>
>> #1
>> #as in Ch 1 of Douglas Bates' book on lme4:
>> fm01<-lmer(Yield~1+(1|Batch),data=Dyestuff)
>> dotplot(ranef(fm01,condVar=TRUE))
>>
>> attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")
>> #all the same
>> sd1<-attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")[[1]]^0.5
>> sd1
>> #the estimates are ranef(fm01), and the CIs shown in the dotplot are +/-
>> sd1*qnorm(0.975)
>> #e.g. for Batch A:
>> ranef(fm01)$Batch[1,]
>> ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>>
>> #2
>> #as recommended in the lme4 manual
>> #bootMer with use.u=FALSE
>> g<-function(.) ranef(.)$Batch[1,]
>> bootg<-bootMer(fm01,g,seed=1,nsim=1000,use.u=FALSE,.progress="txt",PBarg=list(style=3))
>> boot.ci(bootg,type=c("norm","basic","perc"))
>>
>> #3
>> #bootMer with use.u=TRUE
>> bootgu<-bootMer(fm01,g,seed=1,nsim=1000,use.u=TRUE,.progress="txt",PBarg=list(style=3))
>> boot.ci(bootgu,type=c("norm","basic","perc"))
>>
>> #4
>> #R2jags
>> I<-1:30
>> J<-1+floor((I-1)/5)
>>
>> zY<-with(Dyestuff,(Yield-mean(Yield))/sd(Yield))
>> sdY<-with(Dyestuff,sd(Yield))
>>
>> mod1.data<-list("zY","I","J")
>> mod1.parameters<-c("Con.adj","a.adj","mu.a","sigma.a","sig")
>>
>> mod1.mod<-function()
>> {
>> Con.adj<-Con+mean(a[])
>> for (j in 1:6)
>> {
>> a[j]~dnorm(mu.a,1/sigma.a^2)
>> a.adj[j]<-a[j]-mean(a[])
>> }
>>
>> for (i in I)
>> {
>> zY[i]~dnorm(lp[i],1/sig^2)
>> lp[i]<-Con+a[J[i]]
>> }
>> Con~dnorm(0,0.000001)
>> mu.a~dnorm(0,0.0001)
>> sigma.a~dunif(0,100)
>> sig~dunif(0,100)
>> }
>>
>> set.seed(1)
>> mod1.mod.fit<-jags(data=mod1.data, inits=NULL,
>> parameters.to.save=mod1.parameters, n.chains=3, n.iter=50000,
>> n.burnin=10000, model.file=mod1.mod)
>> mod1.mod.fit
>> mat1<-mod1.mod.fit$BUGSoutput$sims.matrix
>>
>> mean(mat1[,1]+mat1[,2])*sdY
>> quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>
>> #comparison
>>
>> cim<-matrix(0,8,3)
>> rownames(cim)<-c("conditional sd","bootMer use.u=F norm","bootMer
>> use.u=F
>> basic","bootMer use.u=F perc","bootMer use.u=T norm","bootMer use.u=T
>> basic","bootMer use.u=T perc","jags")
>> colnames(cim)<-c("estimate","low","high")
>> cim[1:7,1]<-ranef(fm01)$Batch[1,]
>> cim[1,2:3]<-ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>> cim[2,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$norm[,2:3]
>> cim[3,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$basic[,4:5]
>> cim[4,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$perc[,4:5]
>> cim[5,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$norm[,2:3]
>> cim[6,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$basic[,4:5]
>> cim[7,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$perc[,4:5]
>> cim[8,1]<-mean(mat1[,1]+mat1[,2])*sdY
>> cim[8,2:3]<-quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>
>> cim
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


From gregd at gn.apc.org  Mon Aug 28 12:09:07 2017
From: gregd at gn.apc.org (Greg Dropkin)
Date: Mon, 28 Aug 2017 11:09:07 +0100 (BST)
Subject: [R-sig-ME] random effects CIs
In-Reply-To: <399e7a49-9a21-8a83-2f3c-b4e99b3c83d4@mpi.nl>
References: <46964.10.254.253.3.1503346892.squirrel@sqmail.gn.apc.org>
 <0339885e-6f4c-c287-9440-ec65e7ada94d@mpi.nl>
 <58872.10.254.253.3.1503914045.squirrel@sqmail.gn.apc.org>
 <399e7a49-9a21-8a83-2f3c-b4e99b3c83d4@mpi.nl>
Message-ID: <56750.10.254.253.3.1503914948.squirrel@sqmail.gn.apc.org>

The a[j] do vary.

But I will be very happy if Bayesians can explain!

Thanks

Greg

 I'm less surprised -- the credible interval constructed with JAGS is for
> the current model fit, i.e. without estimating additional levels of the
> random effects. This is in line with the Bayesian way of conditioning on
> the observed data. (Maybe one of the better Bayesians on the list can
> better comment on this point.)
>
> Phillip
>
> On 08/28/2017 11:54 AM, Greg Dropkin wrote:
>> Hi Phillip
>>
>> Thanks. Yes, I was aware of your points but what surprised me was that
>> the
>> R2jags CI was closer to use.u = true.
>>
>> Greg
>>
>>> Hi Greg,
>>>
>>> I haven't checked your code for correctness, but the pattern you've
>>> found is typical. I don't know if there is a "best" answer, but broader
>>> confidence intervals are more conservative and so should have better
>>> coverage, if that's what you're going for.  The biggest difference for
>>> use.u=FALSE is how the random effects are handled, from the Details for
>>> ?bootMer:
>>>
>>>>  If ?use.u? is ?FALSE? and ?type? is ?"parametric"?, each
>>>>  simulation generates new values of both the ?_spherical_?
>>>>  random effects u and the i.i.d. errors epsilon, using
>>>>  ?rnorm()? with parameters corresponding to the fitted model
>>>>  ?x?.
>>>>
>>>>  If ?use.u? is ?TRUE? and ?type=="parametric"?, only the
>>>>  i.i.d. errors (or, for GLMMs, response values drawn from the
>>>>  appropriate distributions) are resampled, with the values of
>>>>  u staying fixed at their estimated values.
>>> In other words, use.u=FALSE generates new levels of the random effects,
>>> so in the case of Dyestuff, it simulates new, unseen Batches based on
>>> the estimates of the between-Batch variance. In the use.u=TRUE case, it
>>> re-uses the observed Batches and just simulates the observation-level /
>>> residual error.  So, the use.u=FALSE case introduces "new" variation /
>>> models additional variation and has broader confidence intervals. If
>>> I'm
>>> not mistaken, this is related to the difference between prediction and
>>> confidence intervals.
>>>
>>> Best,
>>> Phillip
>>>
>>>
>>>
>>> On 08/21/2017 10:21 PM, Greg Dropkin wrote:
>>>> Dear list
>>>>
>>>> apologies if these questions have already been answered here - if so
>>>> just
>>>> point me to them.
>>>>
>>>> Am I implementing these 4 approaches to CIs for the random effects
>>>> correctly (for Dyestuff), and if so, which is best (or is "best"
>>>> meaningless)? bootMer use.u=FALSE seems to be recommended in the lme4
>>>> manual, but gives quite different results to the other 3 which are
>>>> roughly
>>>> comparable. Is there a better way?
>>>>
>>>> thanks
>>>>
>>>> Greg Dropkin
>>>>
>>>> --
>>>>
>>>> library(lme4)
>>>> library(lattice)
>>>> library(boot)
>>>> library(R2jags)
>>>>
>>>> #1
>>>> #as in Ch 1 of Douglas Bates' book on lme4:
>>>> fm01<-lmer(Yield~1+(1|Batch),data=Dyestuff)
>>>> dotplot(ranef(fm01,condVar=TRUE))
>>>>
>>>> attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")
>>>> #all the same
>>>> sd1<-attr(ranef(fm01,condVar=TRUE)$Batch,"postVar")[[1]]^0.5
>>>> sd1
>>>> #the estimates are ranef(fm01), and the CIs shown in the dotplot are
>>>> +/-
>>>> sd1*qnorm(0.975)
>>>> #e.g. for Batch A:
>>>> ranef(fm01)$Batch[1,]
>>>> ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>>>>
>>>> #2
>>>> #as recommended in the lme4 manual
>>>> #bootMer with use.u=FALSE
>>>> g<-function(.) ranef(.)$Batch[1,]
>>>> bootg<-bootMer(fm01,g,seed=1,nsim=1000,use.u=FALSE,.progress="txt",PBarg=list(style=3))
>>>> boot.ci(bootg,type=c("norm","basic","perc"))
>>>>
>>>> #3
>>>> #bootMer with use.u=TRUE
>>>> bootgu<-bootMer(fm01,g,seed=1,nsim=1000,use.u=TRUE,.progress="txt",PBarg=list(style=3))
>>>> boot.ci(bootgu,type=c("norm","basic","perc"))
>>>>
>>>> #4
>>>> #R2jags
>>>> I<-1:30
>>>> J<-1+floor((I-1)/5)
>>>>
>>>> zY<-with(Dyestuff,(Yield-mean(Yield))/sd(Yield))
>>>> sdY<-with(Dyestuff,sd(Yield))
>>>>
>>>> mod1.data<-list("zY","I","J")
>>>> mod1.parameters<-c("Con.adj","a.adj","mu.a","sigma.a","sig")
>>>>
>>>> mod1.mod<-function()
>>>> {
>>>> Con.adj<-Con+mean(a[])
>>>> for (j in 1:6)
>>>> {
>>>> a[j]~dnorm(mu.a,1/sigma.a^2)
>>>> a.adj[j]<-a[j]-mean(a[])
>>>> }
>>>>
>>>> for (i in I)
>>>> {
>>>> zY[i]~dnorm(lp[i],1/sig^2)
>>>> lp[i]<-Con+a[J[i]]
>>>> }
>>>> Con~dnorm(0,0.000001)
>>>> mu.a~dnorm(0,0.0001)
>>>> sigma.a~dunif(0,100)
>>>> sig~dunif(0,100)
>>>> }
>>>>
>>>> set.seed(1)
>>>> mod1.mod.fit<-jags(data=mod1.data, inits=NULL,
>>>> parameters.to.save=mod1.parameters, n.chains=3, n.iter=50000,
>>>> n.burnin=10000, model.file=mod1.mod)
>>>> mod1.mod.fit
>>>> mat1<-mod1.mod.fit$BUGSoutput$sims.matrix
>>>>
>>>> mean(mat1[,1]+mat1[,2])*sdY
>>>> quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>>>
>>>> #comparison
>>>>
>>>> cim<-matrix(0,8,3)
>>>> rownames(cim)<-c("conditional sd","bootMer use.u=F norm","bootMer
>>>> use.u=F
>>>> basic","bootMer use.u=F perc","bootMer use.u=T norm","bootMer use.u=T
>>>> basic","bootMer use.u=T perc","jags")
>>>> colnames(cim)<-c("estimate","low","high")
>>>> cim[1:7,1]<-ranef(fm01)$Batch[1,]
>>>> cim[1,2:3]<-ranef(fm01)$Batch[1,]+c(-1,1)*sd1*qnorm(0.975)
>>>> cim[2,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$norm[,2:3]
>>>> cim[3,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$basic[,4:5]
>>>> cim[4,2:3]<-boot.ci(bootg,type=c("norm","basic","perc"))$perc[,4:5]
>>>> cim[5,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$norm[,2:3]
>>>> cim[6,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$basic[,4:5]
>>>> cim[7,2:3]<-boot.ci(bootgu,type=c("norm","basic","perc"))$perc[,4:5]
>>>> cim[8,1]<-mean(mat1[,1]+mat1[,2])*sdY
>>>> cim[8,2:3]<-quantile(mat1[,1]+mat1[,2],c(0.025,0.975))*sdY
>>>>
>>>> cim
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>
>


From jamesaaronhogan at gmail.com  Mon Aug 28 17:02:10 2017
From: jamesaaronhogan at gmail.com (J. Aaron Hogan)
Date: Mon, 28 Aug 2017 11:02:10 -0400
Subject: [R-sig-ME] best practices and methods for fitting poisson/negative
 binomial glmm in R
Message-ID: <CANTyM0vBr-26tb+Yx1=aA7R=ENAh84b2ShAczcoT+NESr0tL6Q@mail.gmail.com>

Dear R-sig mixed modelers,

It is a pleasure to be a part of this group.  I have a few questions
regarding fitting a glmm where the data are poisson/ negative binomially
distributed.

The data are count data from a factorial block design experiment.  3
blocks, 4 treatments (one of which is a control).

The data may or may not be zero inflated; I'm not sure if it matters for
the discussion.

I've got 5 fixed factors, 6 interactions between them and three random
factors; one for block, one for plot and one for a species effect (all
random intercepts).

I fit a model using the lme4 package using the glmer.nb() function and got
some failure to converge" errors. Those errors seemed relatively benign,
after reading some of Ben Bolkers github
https://github.com/lme4/lme4/issues/120
<https://mailtrack.io/trace/link/5ea299f7b41b8ac488434e535336fa40e0bbcb94?url=https%3A%2F%2Fgithub.com%2Flme4%2Flme4%2Fissues%2F120&userId=1227428&signature=726b3079a7674983>,
and checking the Hessian gradient with:

relgrad <- with(model.final at optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))  # returns a very small number

Everything seems alright with that model (based on my understanding); I can
predict the fit back to simulated data. I get reasonable coefficients,
deviance etc.


My question is more of a philosophical one.  How do I know I have a solid
model?  Given the vast number of glmm packages, options etc, when do I know
that it's okay to stop modeling and start inferring on the model?

Should I try to fit the model in a different package, like 'glmmadmb' using
MCMC methods?
What is the best package and/or practice for going through the process of
fitting a glmm for poisson/negative binomially distributed count data?

What other suggestions or recommendations do the more experienced modelers
have for this case?



I do appreciate your time and help,

All the best,

-- 
J. Aaron Hogan M.Sc.
PhD Student
Florida International University
(970) 485-1412

<https://mailtrack.io/trace/link/acd41c31c2375846fae533bc9db76800cdb3a611?url=http%3A%2F%2Fgoog_657844730&userId=1227428&signature=6bca03c848fad248>
www.experiement.com/chinaroots
<https://mailtrack.io/trace/link/3b6f37ffc54fe93c2f7e5fbbe49c36519e142f53?url=http%3A%2F%2Fwww.experiement.com%2Fchinaroots&userId=1227428&signature=859c84ea4b7d42c1>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Aug 29 13:00:39 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 29 Aug 2017 12:00:39 +0100
Subject: [R-sig-ME] Multi-response MCMCglmm and multivariate location
 effects
In-Reply-To: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>
References: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>
Message-ID: <966d9cba-93aa-eed3-44b3-78b620878bba@ed.ac.uk>

Hi,

I think the appropriate model is 2) but you want to know whether the 3 
predictor effects could *all* be zero or not. I usually mix up my 
paradigms and perform a Wald test using the posterior means and 
posterior (co)variances. Simulation suggests it works well: the p-values 
have a uniform distribution under the null hypothesis. For example,


n<-100

V<-matrix(0.25,3,3)
diag(V)<-1

mu<-rep(0,3)
beta<-c(-0.2,0.2,0)

predictor<-rnorm(n)

y<-predictor%*%t(beta)+MASS::mvrnorm(n, mu, V)

dat<-data.frame(x=y[,1], y=y[,2], z=y[,3], predictor=predictor)

m1<-MCMCglmm(cbind(x,y,z)~trait+trait:predictor-1, 
rcov=~us(trait):units, data=dat, family=rep("gaussian",3))

aod::wald.test(cov(m1$Sol[,4:6]), colMeans(m1$Sol[,4:6]), 
Terms=1:3)$result$chi2["P"]

Cheers,

Jarrod



On 22/08/2017 01:29, Rafael Maia wrote:
> Dear list,
>
> Suppose I have a dataset consisting of 3 continuous, Gaussian variables and 1 categorical variable. I would like to run a multi-response model using the 3 continuous variables as response variables and the categorical variable as a predictor. These 3 variables are somewhat arbitrary, simply representing XYZ Cartesian coordinates, and it is not particularly easy to interpret them individually. They are also in different scales and the effect of the predictor can have different signs and magnitudes on the variables. Therefore, I?m mostly interested in understanding if the categorical variable influences the overall location of the sample in this multivariate cartesian space - as a simple MANOVA would.
>
> I?ve looked into MCMCglmm as what seems to be the best approach to this question, and one I?m a bit familiar with. From my understanding, there are two different ways I could parametrize the fixed part of my model:
>
> 1) fixed = cbind(x,y,z) ~ trait:predictor-1, which would estimate the effects of the predictor across each of the 3 responses individually, and is like an interaction between the predictor and the responses;
>
> 2) fixed = cbind(x,y,z) ~ trait+predictor-1, which would estimate a single effect across all responses, and from what I understand, fundamentally assumes that the effect of the predictor is of the same magnitude and in the same direction across all responses.
>
> So from my understanding, I _think_ I would want something similar to (2); however, because of the structure of the data as described above, the effect of the categorical predictor will often not be of the same magnitude/direction across xyz, so that doesn?t seem to be an appropriate model. I would rather not make my inference based on the trait:predictor fixed effects structure because, from my naive understanding, I guess this would be akin to running 3 ANOVAs instead of a MANOVA, and beat the purpose of using a multi-response model? And I think it would also be possible to not have above-zero effect on any of the 3 variables independently, yet still have a measurable difference in the multivariate location of the groups?
>
> I guess this question is somewhat related to model selection, for which there doesn?t seem to have a satisfactory approach for when using  MCMCglmm? I remember reading somewhere that DIC model selection for models with different fixed effects wasn?t really recommended.
>
> (As you?d expect, this is a simplified version of the dataset I have, where there are multiple predictors and random effects, to demo these issues, which is why I?m looking for a solution using MCMCglmm!)
>
> I?ve uploaded some code to reproduce what I?m trying to describe here: http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>
>
> Any help would be greatly appreciated. Thanks!
>
> Best,
> Rafael Maia
> ?
> Simons Junior Fellow, Columbia University
> Rubenstein Lab
> Department of Ecology, Evolution and Environmental Biology
> New York, NY
> http://www.rafaelmaia.net
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rmaialists at gmail.com  Tue Aug 29 20:04:18 2017
From: rmaialists at gmail.com (Rafael Maia)
Date: Tue, 29 Aug 2017 11:04:18 -0700
Subject: [R-sig-ME] Multi-response MCMCglmm and multivariate location
 effects
In-Reply-To: <966d9cba-93aa-eed3-44b3-78b620878bba@ed.ac.uk>
References: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>
 <966d9cba-93aa-eed3-44b3-78b620878bba@ed.ac.uk>
Message-ID: <98F63D91-4919-4BB8-A751-AE96528D7425@gmail.com>

Thank you so much Jarrod, that seems to be exactly what I need, cheers. Would that be equivalent to looking at the joint posterior distribution of coefficient estimates is greater/smaller than zero given their means? Crudely, something like 

sum(m1$Sol[,4] >= 0 & m1$Sol[,5] <= 0 & m1$Sol[,6] >= 0)

Given the coefficients resulting from using set.seed(1982) ? 

Thanks,
-Rafael


> On Aug 29, 2017, at 4:00 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Hi,
> 
> I think the appropriate model is 2) but you want to know whether the 3 predictor effects could *all* be zero or not. I usually mix up my paradigms and perform a Wald test using the posterior means and posterior (co)variances. Simulation suggests it works well: the p-values have a uniform distribution under the null hypothesis. For example,
> 
> 
> n<-100
> 
> V<-matrix(0.25,3,3)
> diag(V)<-1
> 
> mu<-rep(0,3)
> beta<-c(-0.2,0.2,0)
> 
> predictor<-rnorm(n)
> 
> y<-predictor%*%t(beta)+MASS::mvrnorm(n, mu, V)
> 
> dat<-data.frame(x=y[,1], y=y[,2], z=y[,3], predictor=predictor)
> 
> m1<-MCMCglmm(cbind(x,y,z)~trait+trait:predictor-1, rcov=~us(trait):units, data=dat, family=rep("gaussian",3))
> 
> aod::wald.test(cov(m1$Sol[,4:6]), colMeans(m1$Sol[,4:6]), Terms=1:3)$result$chi2["P"]
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> On 22/08/2017 01:29, Rafael Maia wrote:
>> Dear list,
>> 
>> Suppose I have a dataset consisting of 3 continuous, Gaussian variables and 1 categorical variable. I would like to run a multi-response model using the 3 continuous variables as response variables and the categorical variable as a predictor. These 3 variables are somewhat arbitrary, simply representing XYZ Cartesian coordinates, and it is not particularly easy to interpret them individually. They are also in different scales and the effect of the predictor can have different signs and magnitudes on the variables. Therefore, I?m mostly interested in understanding if the categorical variable influences the overall location of the sample in this multivariate cartesian space - as a simple MANOVA would.
>> 
>> I?ve looked into MCMCglmm as what seems to be the best approach to this question, and one I?m a bit familiar with. From my understanding, there are two different ways I could parametrize the fixed part of my model:
>> 
>> 1) fixed = cbind(x,y,z) ~ trait:predictor-1, which would estimate the effects of the predictor across each of the 3 responses individually, and is like an interaction between the predictor and the responses;
>> 
>> 2) fixed = cbind(x,y,z) ~ trait+predictor-1, which would estimate a single effect across all responses, and from what I understand, fundamentally assumes that the effect of the predictor is of the same magnitude and in the same direction across all responses.
>> 
>> So from my understanding, I _think_ I would want something similar to (2); however, because of the structure of the data as described above, the effect of the categorical predictor will often not be of the same magnitude/direction across xyz, so that doesn?t seem to be an appropriate model. I would rather not make my inference based on the trait:predictor fixed effects structure because, from my naive understanding, I guess this would be akin to running 3 ANOVAs instead of a MANOVA, and beat the purpose of using a multi-response model? And I think it would also be possible to not have above-zero effect on any of the 3 variables independently, yet still have a measurable difference in the multivariate location of the groups?
>> 
>> I guess this question is somewhat related to model selection, for which there doesn?t seem to have a satisfactory approach for when using  MCMCglmm? I remember reading somewhere that DIC model selection for models with different fixed effects wasn?t really recommended.
>> 
>> (As you?d expect, this is a simplified version of the dataset I have, where there are multiple predictors and random effects, to demo these issues, which is why I?m looking for a solution using MCMCglmm!)
>> 
>> I?ve uploaded some code to reproduce what I?m trying to describe here: http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc><http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>>
>> 
>> Any help would be greatly appreciated. Thanks!
>> 
>> Best,
>> Rafael Maia
>> ?
>> Simons Junior Fellow, Columbia University
>> Rubenstein Lab
>> Department of Ecology, Evolution and Environmental Biology
>> New York, NY
>> http://www.rafaelmaia.net <http://www.rafaelmaia.net/>
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 29 20:10:44 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 29 Aug 2017 14:10:44 -0400
Subject: [R-sig-ME] Multi-response MCMCglmm and multivariate location
 effects
In-Reply-To: <98F63D91-4919-4BB8-A751-AE96528D7425@gmail.com>
References: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>
 <966d9cba-93aa-eed3-44b3-78b620878bba@ed.ac.uk>
 <98F63D91-4919-4BB8-A751-AE96528D7425@gmail.com>
Message-ID: <1120de2c-6e7c-1e08-7bc4-95680eab7477@gmail.com>



On 17-08-29 02:04 PM, Rafael Maia wrote:
> Thank you so much Jarrod, that seems to be exactly what I need, cheers. Would that be equivalent to looking at the joint posterior distribution of coefficient estimates is greater/smaller than zero given their means? Crudely, something like 
> 
> sum(m1$Sol[,4] >= 0 & m1$Sol[,5] <= 0 & m1$Sol[,6] >= 0)
> 
> Given the coefficients resulting from using set.seed(1982) ? 
> 
> Thanks,
> -Rafael

   Jarrod's response accounts for the correlation of the estimates as
well, effectively giving an elliptical boundary.  Your solution gives a
rectangular/hypercube boundary, which will be very far off in some
cases.  (About a million years ago Doug Bates offered a similar solution
for output from the now-defunct mcmcsamp(), which did post-hoc MCMC
sampling from an lmer fit:
https://stat.ethz.ch/pipermail/r-help/2006-September/113184.html )
> 
> 
>> On Aug 29, 2017, at 4:00 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>> Hi,
>>
>> I think the appropriate model is 2) but you want to know whether the 3 predictor effects could *all* be zero or not. I usually mix up my paradigms and perform a Wald test using the posterior means and posterior (co)variances. Simulation suggests it works well: the p-values have a uniform distribution under the null hypothesis. For example,
>>
>>
>> n<-100
>>
>> V<-matrix(0.25,3,3)
>> diag(V)<-1
>>
>> mu<-rep(0,3)
>> beta<-c(-0.2,0.2,0)
>>
>> predictor<-rnorm(n)
>>
>> y<-predictor%*%t(beta)+MASS::mvrnorm(n, mu, V)
>>
>> dat<-data.frame(x=y[,1], y=y[,2], z=y[,3], predictor=predictor)
>>
>> m1<-MCMCglmm(cbind(x,y,z)~trait+trait:predictor-1, rcov=~us(trait):units, data=dat, family=rep("gaussian",3))
>>
>> aod::wald.test(cov(m1$Sol[,4:6]), colMeans(m1$Sol[,4:6]), Terms=1:3)$result$chi2["P"]
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> On 22/08/2017 01:29, Rafael Maia wrote:
>>> Dear list,
>>>
>>> Suppose I have a dataset consisting of 3 continuous, Gaussian variables and 1 categorical variable. I would like to run a multi-response model using the 3 continuous variables as response variables and the categorical variable as a predictor. These 3 variables are somewhat arbitrary, simply representing XYZ Cartesian coordinates, and it is not particularly easy to interpret them individually. They are also in different scales and the effect of the predictor can have different signs and magnitudes on the variables. Therefore, I?m mostly interested in understanding if the categorical variable influences the overall location of the sample in this multivariate cartesian space - as a simple MANOVA would.
>>>
>>> I?ve looked into MCMCglmm as what seems to be the best approach to this question, and one I?m a bit familiar with. From my understanding, there are two different ways I could parametrize the fixed part of my model:
>>>
>>> 1) fixed = cbind(x,y,z) ~ trait:predictor-1, which would estimate the effects of the predictor across each of the 3 responses individually, and is like an interaction between the predictor and the responses;
>>>
>>> 2) fixed = cbind(x,y,z) ~ trait+predictor-1, which would estimate a single effect across all responses, and from what I understand, fundamentally assumes that the effect of the predictor is of the same magnitude and in the same direction across all responses.
>>>
>>> So from my understanding, I _think_ I would want something similar to (2); however, because of the structure of the data as described above, the effect of the categorical predictor will often not be of the same magnitude/direction across xyz, so that doesn?t seem to be an appropriate model. I would rather not make my inference based on the trait:predictor fixed effects structure because, from my naive understanding, I guess this would be akin to running 3 ANOVAs instead of a MANOVA, and beat the purpose of using a multi-response model? And I think it would also be possible to not have above-zero effect on any of the 3 variables independently, yet still have a measurable difference in the multivariate location of the groups?
>>>
>>> I guess this question is somewhat related to model selection, for which there doesn?t seem to have a satisfactory approach for when using  MCMCglmm? I remember reading somewhere that DIC model selection for models with different fixed effects wasn?t really recommended.
>>>
>>> (As you?d expect, this is a simplified version of the dataset I have, where there are multiple predictors and random effects, to demo these issues, which is why I?m looking for a solution using MCMCglmm!)
>>>
>>> I?ve uploaded some code to reproduce what I?m trying to describe here: http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc><http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>>
>>>
>>> Any help would be greatly appreciated. Thanks!
>>>
>>> Best,
>>> Rafael Maia
>>> ?
>>> Simons Junior Fellow, Columbia University
>>> Rubenstein Lab
>>> Department of Ecology, Evolution and Environmental Biology
>>> New York, NY
>>> http://www.rafaelmaia.net <http://www.rafaelmaia.net/>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From rmaialists at gmail.com  Tue Aug 29 20:22:52 2017
From: rmaialists at gmail.com (Rafael Maia)
Date: Tue, 29 Aug 2017 11:22:52 -0700
Subject: [R-sig-ME] Multi-response MCMCglmm and multivariate location
 effects
In-Reply-To: <1120de2c-6e7c-1e08-7bc4-95680eab7477@gmail.com>
References: <AB0BB8FF-52FD-4AD1-B587-745EB3985586@gmail.com>
 <966d9cba-93aa-eed3-44b3-78b620878bba@ed.ac.uk>
 <98F63D91-4919-4BB8-A751-AE96528D7425@gmail.com>
 <1120de2c-6e7c-1e08-7bc4-95680eab7477@gmail.com>
Message-ID: <14486BBC-61AA-4D22-A7B6-17783695B96C@gmail.com>

Ah I see, thanks for pointing that out and that thread (11 years old!). I really appreciate everyone?s help.

Thanks, 
-R


> On Aug 29, 2017, at 11:10 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
> 
> On 17-08-29 02:04 PM, Rafael Maia wrote:
>> Thank you so much Jarrod, that seems to be exactly what I need, cheers. Would that be equivalent to looking at the joint posterior distribution of coefficient estimates is greater/smaller than zero given their means? Crudely, something like 
>> 
>> sum(m1$Sol[,4] >= 0 & m1$Sol[,5] <= 0 & m1$Sol[,6] >= 0)
>> 
>> Given the coefficients resulting from using set.seed(1982) ? 
>> 
>> Thanks,
>> -Rafael
> 
>   Jarrod's response accounts for the correlation of the estimates as
> well, effectively giving an elliptical boundary.  Your solution gives a
> rectangular/hypercube boundary, which will be very far off in some
> cases.  (About a million years ago Doug Bates offered a similar solution
> for output from the now-defunct mcmcsamp(), which did post-hoc MCMC
> sampling from an lmer fit:
> https://stat.ethz.ch/pipermail/r-help/2006-September/113184.html <https://stat.ethz.ch/pipermail/r-help/2006-September/113184.html> )
>> 
>> 
>>> On Aug 29, 2017, at 4:00 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>> 
>>> Hi,
>>> 
>>> I think the appropriate model is 2) but you want to know whether the 3 predictor effects could *all* be zero or not. I usually mix up my paradigms and perform a Wald test using the posterior means and posterior (co)variances. Simulation suggests it works well: the p-values have a uniform distribution under the null hypothesis. For example,
>>> 
>>> 
>>> n<-100
>>> 
>>> V<-matrix(0.25,3,3)
>>> diag(V)<-1
>>> 
>>> mu<-rep(0,3)
>>> beta<-c(-0.2,0.2,0)
>>> 
>>> predictor<-rnorm(n)
>>> 
>>> y<-predictor%*%t(beta)+MASS::mvrnorm(n, mu, V)
>>> 
>>> dat<-data.frame(x=y[,1], y=y[,2], z=y[,3], predictor=predictor)
>>> 
>>> m1<-MCMCglmm(cbind(x,y,z)~trait+trait:predictor-1, rcov=~us(trait):units, data=dat, family=rep("gaussian",3))
>>> 
>>> aod::wald.test(cov(m1$Sol[,4:6]), colMeans(m1$Sol[,4:6]), Terms=1:3)$result$chi2["P"]
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> On 22/08/2017 01:29, Rafael Maia wrote:
>>>> Dear list,
>>>> 
>>>> Suppose I have a dataset consisting of 3 continuous, Gaussian variables and 1 categorical variable. I would like to run a multi-response model using the 3 continuous variables as response variables and the categorical variable as a predictor. These 3 variables are somewhat arbitrary, simply representing XYZ Cartesian coordinates, and it is not particularly easy to interpret them individually. They are also in different scales and the effect of the predictor can have different signs and magnitudes on the variables. Therefore, I?m mostly interested in understanding if the categorical variable influences the overall location of the sample in this multivariate cartesian space - as a simple MANOVA would.
>>>> 
>>>> I?ve looked into MCMCglmm as what seems to be the best approach to this question, and one I?m a bit familiar with. From my understanding, there are two different ways I could parametrize the fixed part of my model:
>>>> 
>>>> 1) fixed = cbind(x,y,z) ~ trait:predictor-1, which would estimate the effects of the predictor across each of the 3 responses individually, and is like an interaction between the predictor and the responses;
>>>> 
>>>> 2) fixed = cbind(x,y,z) ~ trait+predictor-1, which would estimate a single effect across all responses, and from what I understand, fundamentally assumes that the effect of the predictor is of the same magnitude and in the same direction across all responses.
>>>> 
>>>> So from my understanding, I _think_ I would want something similar to (2); however, because of the structure of the data as described above, the effect of the categorical predictor will often not be of the same magnitude/direction across xyz, so that doesn?t seem to be an appropriate model. I would rather not make my inference based on the trait:predictor fixed effects structure because, from my naive understanding, I guess this would be akin to running 3 ANOVAs instead of a MANOVA, and beat the purpose of using a multi-response model? And I think it would also be possible to not have above-zero effect on any of the 3 variables independently, yet still have a measurable difference in the multivariate location of the groups?
>>>> 
>>>> I guess this question is somewhat related to model selection, for which there doesn?t seem to have a satisfactory approach for when using  MCMCglmm? I remember reading somewhere that DIC model selection for models with different fixed effects wasn?t really recommended.
>>>> 
>>>> (As you?d expect, this is a simplified version of the dataset I have, where there are multiple predictors and random effects, to demo these issues, which is why I?m looking for a solution using MCMCglmm!)
>>>> 
>>>> I?ve uploaded some code to reproduce what I?m trying to describe here: http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc><http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>><http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc> <http://rpubs.com/rmaia/multimcmc <http://rpubs.com/rmaia/multimcmc>>>
>>>> 
>>>> Any help would be greatly appreciated. Thanks!
>>>> 
>>>> Best,
>>>> Rafael Maia
>>>> ?
>>>> Simons Junior Fellow, Columbia University
>>>> Rubenstein Lab
>>>> Department of Ecology, Evolution and Environmental Biology
>>>> New York, NY
>>>> http://www.rafaelmaia.net <http://www.rafaelmaia.net/> <http://www.rafaelmaia.net/ <http://www.rafaelmaia.net/>>
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>> 
>>> 
>>> -- 
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Wed Aug 30 10:15:33 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 30 Aug 2017 10:15:33 +0200
Subject: [R-sig-ME] completely nested glmer
Message-ID: <cbd1c0c3-e0f3-b14e-f5ae-db875f3c387f@gvdnet.dk>

Dear friends - I have a question which is  basic and probably simple but 
disturbing  to me. I am on Windows 7 or 10, R version 3.4.1 (2017-06-30) 
-- "Single Candle"

I have 2013 measurements of capillary flow speed obtained from 204 
glomeruli originating from 29 rats, 10 of whom are controls, 11 made 
diabetic, and 8 made hyperglycemic otherwise.  Altogether I have 621 
capillaries from controls, 964 from diabetics and 428 from hyperglycemic.

If I make a direct aov

summary(z2 <- aov(Speed~TRT,SCAN))
TukeyHSD(z2)
#$TRT
#                 diff         lwr         upr     p adj
#Diab-Ctrl  -0.4266708 -0.65092625 -0.20241526 0.0000255
#Hyper-Ctrl -0.2206938 -0.49449343  0.05310581 0.1416500
#Hyper-Diab  0.2059769 -0.04716959  0.45912348 0.1365243

and a similar result is obtained with kruskal.test

I happen to know the flow is approximately gamma distributed and

summary(z1a <- glm(Speed~TRT,SCAN,family=Gamma)) where TRT is the three 
level factor, leaves me a significant effect of diabetes

However, as it is, glomeruli are nested within rats, and rats are by 
design nested within one of the three groups

Hence I make

summary(z3a <- glmer(Speed~TRT + (1|RAT)+(1|ind) + (1|RAT:ind) 
,data=SCAN,family=Gamma)) where ind is an indicator for each of the 204 
glomeruli. And the fixed effect TRT is not significant.

But taking into account that RAT is nested within TRT leaves me 
something like

summary(z77 <- glmer(Speed~ 1 +(1|TRT/RAT/ind) ,data=SCAN,family=Gamma)) 
which fits without protests and gives me

Random effects:
  Groups        Name        Variance Std.Dev.
  ind:(RAT:TRT) (Intercept) 0.003839 0.06196
  RAT:TRT       (Intercept) 0.001479 0.03846
  TRT           (Intercept) 0.000000 0.00000
  Residual                  0.237689 0.48753
Number of obs: 2013, groups:  ind:(RAT:TRT), 204; RAT:TRT, 29; TRT, 3

which hardly indicates strong effect of TRT levels?

The results of the aov or first glm would fit expectations - but ignores 
the nesting. So is the mixed model wrong? (it looks reasonable from 
diagnostic plots)

Best wishes

Troels Ring
Aalborg, Denmark


From David.Duffy at qimrberghofer.edu.au  Thu Aug 31 08:46:36 2017
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 31 Aug 2017 06:46:36 +0000
Subject: [R-sig-ME] completely nested glmer
In-Reply-To: <cbd1c0c3-e0f3-b14e-f5ae-db875f3c387f@gvdnet.dk>
References: <cbd1c0c3-e0f3-b14e-f5ae-db875f3c387f@gvdnet.dk>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D48A6DE7C3@EXCH06S.adqimr.ad.lan>

Troels Ring asked:

> I have 2013 measurements of capillary flow speed obtained from 204
> glomeruli originating from 29 rats, 10 of whom are controls, 11 made
> diabetic, and 8 made hyperglycemic otherwise.  Altogether I have 621
> capillaries from controls, 964 from diabetics and 428 from hyperglycemic.
> If I make a direct aov
> summary(z2 <- aov(Speed~TRT,SCAN))
> TukeyHSD(z2)
> #$TRT
> #                 diff         lwr         upr     p adj
> #Diab-Ctrl  -0.4266708 -0.65092625 -0.20241526 0.0000255
> #Hyper-Ctrl -0.2206938 -0.49449343  0.05310581 0.1416500
> #Hyper-Diab  0.2059769 -0.04716959  0.45912348 0.1365243

> summary(z3a <- glmer(Speed~TRT + (1|RAT)+(1|ind) + (1|RAT:ind)
> ,data=SCAN,family=Gamma)) where ind is an indicator for each of the 204
> glomeruli. And the fixed effect TRT is not significant.

I would look at the permutation test for the Jonckheere-Terpstra  test statistic for Speed ~ TRT, where TRT is a quantitative
variable 0=Ctrl 1=Hypergly 2=Frank diabetes, given I would have a strong prior hypothesis that an
association will take this form. You should look to see if RAT:ind is required eg
z3b <-  glmer(Speed~TRT + (1|RAT)+(1|ind),...)
anova(z3a, z3b)
and look at diagnostics for whether a gamma is really best (cf log-normal).

Just 2c, David Duffy.

From tring at gvdnet.dk  Thu Aug 31 09:01:33 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Thu, 31 Aug 2017 09:01:33 +0200
Subject: [R-sig-ME] completely nested glmer
In-Reply-To: <cbd1c0c3-e0f3-b14e-f5ae-db875f3c387f@gvdnet.dk>
References: <cbd1c0c3-e0f3-b14e-f5ae-db875f3c387f@gvdnet.dk>
Message-ID: <6c0fe70a-1732-4bfb-949d-56668b22548e@gvdnet.dk>

Thanks a lot!!! - but there is certainly no expected gradient here over 
the categories of TRT. The problem pertains to early diabetes 
hyperfiltration which is not a direct function of hyperglycemia but 
controversial and complicated. I refrained from looking more into the 
problem of the distribution whether log-normal or gamma, since 
everything seems buried in the problem with nesting, and I feel 
uncomfortable deciding on the needed structure based on statistical 
tests, mainly since I fear that the TRT effect is totally mixed up with 
the RAT effect - if I manage to put it reasonably correct. Everybody 
would be happy if I had just stayed with the TukeyHSD which provides me 
beautifully low P values - which cannot be correct under the structure 
of the data - right?

Best wishes

Troels

  


Den 31-08-2017 kl. 08:46 skrev David Duffy:
> Troels Ring asked:
>
>> I have 2013 measurements of capillary flow speed obtained from 204
>> glomeruli originating from 29 rats, 10 of whom are controls, 11 made
>> diabetic, and 8 made hyperglycemic otherwise.  Altogether I have 621
>> capillaries from controls, 964 from diabetics and 428 from hyperglycemic.
>> If I make a direct aov
>> summary(z2 <- aov(Speed~TRT,SCAN))
>> TukeyHSD(z2)
>> #$TRT
>> #                 diff         lwr         upr     p adj
>> #Diab-Ctrl  -0.4266708 -0.65092625 -0.20241526 0.0000255
>> #Hyper-Ctrl -0.2206938 -0.49449343  0.05310581 0.1416500
>> #Hyper-Diab  0.2059769 -0.04716959  0.45912348 0.1365243
>> summary(z3a <- glmer(Speed~TRT + (1|RAT)+(1|ind) + (1|RAT:ind)
>> ,data=SCAN,family=Gamma)) where ind is an indicator for each of the 204
>> glomeruli. And the fixed effect TRT is not significant.
> I would look at the permutation test for the Jonckheere-Terpstra  test statistic for Speed ~ TRT, where TRT is a quantitative
> variable 0=Ctrl 1=Hypergly 2=Frank diabetes, given I would have a strong prior hypothesis that an
> association will take this form. You should look to see if RAT:ind is required eg
> z3b <-  glmer(Speed~TRT + (1|RAT)+(1|ind),...)
> anova(z3a, z3b)
> and look at diagnostics for whether a gamma is really best (cf log-normal).
>
> Just 2c, David Duffy.


From r.turner at auckland.ac.nz  Sun Sep  3 10:15:13 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 3 Sep 2017 20:15:13 +1200
Subject: [R-sig-ME] nAGQ = 0
Message-ID: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>


Greetings mixed models gurus.

Some time ago I asked a question of this list concerning problems that I 
was having getting a glmer() model to fit to a data set.  (Using the 
binomial family with the cloglog link.)

It was suggested to me, in the first instance by Tony Ives (thanks 
again, Tony), that I should include the "nAGQ=0" option in my call to 
glmer().  I did so, and it worked like a charm.

I do not however really understand what "nAGQ=0" actually does.  I 
gather (vaguely) that it has something to do with the numerical 
integrals needed when evaluating the log like, and I (even more vaguely) 
gather that with nAGQ=0 this integration is somehow entirely dispensed 
with.  Perhaps I am miss-stating things here.

Be that as it may, it worries me slightly that I (apparently) have to 
use a somewhat less precise method than I otherwise might in order to
get any answer at all.

What risks am I running by setting nAGQ=0?  What perils and pitfalls 
lurk?  Surely there must be a downside to using this (???) short cut.
Although the upside, that I actually get an answer, pretty clearly 
trumps (apologies for the use of that word :-) ) the downside.

I would like some advice, pearls of wisdom, whatever from someone who 
understands what is going on in the underpinnings of fitting mixed models.

Thanks for any wise counsel that you can provide.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bachlaw01 at outlook.com  Sun Sep  3 17:48:19 2017
From: bachlaw01 at outlook.com (Jonathan Judge)
Date: Sun, 3 Sep 2017 15:48:19 +0000
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
Message-ID: <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>

Rolf:

I have not studied this extensively with smaller datasets, but with larger datasets --- five-figure and especially six-figure n --- I have found that it often makes no difference. 

When uncertain, I have used a likelihood ratio test to see if the differences are likely to be material. 

My overall suggestion would be that if the dataset is small enough for this choice to matter, it is probably also small enough to solve the model through MCMC, in which case I would recommending using that, because the incorporated uncertainty often gives you better parameter estimates than any increased level of quadrature. 

Best,
Jonathan

Sent from my iPhone

> On Sep 3, 2017, at 3:15 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Greetings mixed models gurus.
> 
> Some time ago I asked a question of this list concerning problems that I was having getting a glmer() model to fit to a data set.  (Using the binomial family with the cloglog link.)
> 
> It was suggested to me, in the first instance by Tony Ives (thanks again, Tony), that I should include the "nAGQ=0" option in my call to glmer().  I did so, and it worked like a charm.
> 
> I do not however really understand what "nAGQ=0" actually does.  I gather (vaguely) that it has something to do with the numerical integrals needed when evaluating the log like, and I (even more vaguely) gather that with nAGQ=0 this integration is somehow entirely dispensed with.  Perhaps I am miss-stating things here.
> 
> Be that as it may, it worries me slightly that I (apparently) have to use a somewhat less precise method than I otherwise might in order to
> get any answer at all.
> 
> What risks am I running by setting nAGQ=0?  What perils and pitfalls lurk?  Surely there must be a downside to using this (???) short cut.
> Although the upside, that I actually get an answer, pretty clearly trumps (apologies for the use of that word :-) ) the downside.
> 
> I would like some advice, pearls of wisdom, whatever from someone who understands what is going on in the underpinnings of fitting mixed models.
> 
> Thanks for any wise counsel that you can provide.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Sun Sep  3 23:48:52 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 4 Sep 2017 09:48:52 +1200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
Message-ID: <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>

On 04/09/17 03:48, Jonathan Judge wrote:
> Rolf:
> 
> I have not studied this extensively with smaller datasets, but with
> larger datasets --- five-figure and especially six-figure n --- I have
> found that it often makes no difference.

> When uncertain, I have used a likelihood ratio test to see if the
> differences are likely to be material.

> My overall suggestion would be that if the dataset is small enough
> for  this choice to matter, it is probably also small enough to solve the
> model through MCMC, in which case I would recommending using that,
> because the incorporated uncertainty often gives you better parameter
> estimates than any increased level of quadrature.


Thanks Jonathan.

(a) How small is "small"?  I have 3 figure n's. I am currently mucking 
about with two data sets.  One has 952 observations (with 22 treatment 
groups, 3 random effect reps per group).  The other has 142 observations 
(with 6 treatment groups and again 3 reps per group).  Would you call 
the latter data set small?

(b) I've never had the courage to try the MCMC approaches to mixed 
models; have just used lme4.  I guess it's time that I bit the bullet.
Psigh.  This is going to take me a while.  As an old dog I *can* learn 
new tricks, but I learn them *slowly*. :-)

(c) In respect of the likelihood ratio test that you suggest --- sorry 
to be a thicko, but I don't get it.  It seems to me that one is fitting 
the *same model* in both instances, so the "degrees of freedom" for such 
a test would be zero.  What am I missing?

Thanks again.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdpo223 at g.uky.edu  Mon Sep  4 00:51:40 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sun, 3 Sep 2017 18:51:40 -0400
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
Message-ID: <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>

I'm pretty sure that nAGQ=0 is generating conditional modes of group values
for the random effects without subsequently using a laplace approximation.
This is really not something that you want to do unless it's a last resort.
It's kind of like estimating a linear probability model with a random
intercept and using the values for that in the cloglog model. My
understanding is that it's not even an option in most other software.
Someone please correct me if I'm wrong here because what I've found on it
has been kind of vague and I'm making some assumptions.

My guess is that the random intercepts/slopes are going to be too small and
their distributions could be distorted if you're not actually approximating
the integral with something like quadrature or mcmc. That's the case with
PQL and MQL according to simulation evidence at least and even though this
isn't the same as PQL I'd expect a similar problem at first blush.

As to if this is a real practical problem or a theory  problem there's been
kind of a disagreement on that within the stats literature. Some people
argue, in binary outcome models, that biased random intercepts can bias
everything else and others have argued this fear is overblown. This might
well have been settled by actual statisticians by now, I'm not sure.  It's
gotten enough attention in the literature that people certainly worried
about it a lot.

Below are two articles on the topic with simulations but I've seen the
fixed effects results (and LR tests) change based on the random effects
approximation technique in my work so I'm always a bit paranoid about it.
Model misspecification and having oddly shaped random intercepts (as with
count models) can seem to make this problem worse.

You can try using the BRMS package if you aren't comfortable switching to
something totally unfamiliar. It's a wrapper for Stan designed to use lme4
syntax and a lot of good default settings. It's pretty easy to use if you
know lme4 syntax and can read up on mcmc diagnostics.

Liti?re, S., et al. (2008). "The impact of a misspecified random?effects
distribution on the estimation and the performance of inferential
procedures in generalized linear mixed models." Stat Med 27(16): 3125-3144.

McCulloch, C. E. and J. M. Neuhaus (2011). "Misspecifying the shape of a
random effects distribution: why getting it wrong may not matter."
Statistical Science: 388-402.


On Sep 3, 2017 5:49 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

> On 04/09/17 03:48, Jonathan Judge wrote:
>
>> Rolf:
>>
>> I have not studied this extensively with smaller datasets, but with
>> larger datasets --- five-figure and especially six-figure n --- I have
>> found that it often makes no difference.
>>
>
> When uncertain, I have used a likelihood ratio test to see if the
>> differences are likely to be material.
>>
>
> My overall suggestion would be that if the dataset is small enough
>> for  this choice to matter, it is probably also small enough to solve the
>> model through MCMC, in which case I would recommending using that,
>> because the incorporated uncertainty often gives you better parameter
>> estimates than any increased level of quadrature.
>>
>
>
> Thanks Jonathan.
>
> (a) How small is "small"?  I have 3 figure n's. I am currently mucking
> about with two data sets.  One has 952 observations (with 22 treatment
> groups, 3 random effect reps per group).  The other has 142 observations
> (with 6 treatment groups and again 3 reps per group).  Would you call the
> latter data set small?
>
> (b) I've never had the courage to try the MCMC approaches to mixed models;
> have just used lme4.  I guess it's time that I bit the bullet.
> Psigh.  This is going to take me a while.  As an old dog I *can* learn new
> tricks, but I learn them *slowly*. :-)
>
> (c) In respect of the likelihood ratio test that you suggest --- sorry to
> be a thicko, but I don't get it.  It seems to me that one is fitting the
> *same model* in both instances, so the "degrees of freedom" for such a test
> would be zero.  What am I missing?
>
> Thanks again.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Mon Sep  4 00:59:30 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sun, 3 Sep 2017 18:59:30 -0400
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
Message-ID: <CAFW8BypwY9LUkWtisMpXr_z_vbMY8g4BU2CL2hULYQw8s8MY5w@mail.gmail.com>

Oh and on the model comparison thing the only way i know how to directly
compare random effects distribution estimates is with gateaux derivatives a
la what Sophia Rabe-Hesketh did in her GLLAMM software for nonparametric
random effects estimation.

Usually i just kind of eyeball it and try to be overly conservative with
quadrature points or use MCMC.

I guess you could rig up some regular deviance test to do the same thing?

On Sep 3, 2017 6:51 PM, "Poe, John" <jdpo223 at g.uky.edu> wrote:

> I'm pretty sure that nAGQ=0 is generating conditional modes of group
> values for the random effects without subsequently using a laplace
> approximation. This is really not something that you want to do unless it's
> a last resort. It's kind of like estimating a linear probability model with
> a random intercept and using the values for that in the cloglog model. My
> understanding is that it's not even an option in most other software.
> Someone please correct me if I'm wrong here because what I've found on it
> has been kind of vague and I'm making some assumptions.
>
> My guess is that the random intercepts/slopes are going to be too small
> and their distributions could be distorted if you're not actually
> approximating the integral with something like quadrature or mcmc. That's
> the case with PQL and MQL according to simulation evidence at least and
> even though this isn't the same as PQL I'd expect a similar problem at
> first blush.
>
> As to if this is a real practical problem or a theory  problem there's
> been kind of a disagreement on that within the stats literature. Some
> people argue, in binary outcome models, that biased random intercepts can
> bias everything else and others have argued this fear is overblown. This
> might well have been settled by actual statisticians by now, I'm not sure.
> It's gotten enough attention in the literature that people certainly
> worried about it a lot.
>
> Below are two articles on the topic with simulations but I've seen the
> fixed effects results (and LR tests) change based on the random effects
> approximation technique in my work so I'm always a bit paranoid about it.
> Model misspecification and having oddly shaped random intercepts (as with
> count models) can seem to make this problem worse.
>
> You can try using the BRMS package if you aren't comfortable switching to
> something totally unfamiliar. It's a wrapper for Stan designed to use lme4
> syntax and a lot of good default settings. It's pretty easy to use if you
> know lme4 syntax and can read up on mcmc diagnostics.
>
> Liti?re, S., et al. (2008). "The impact of a misspecified random?effects
> distribution on the estimation and the performance of inferential
> procedures in generalized linear mixed models." Stat Med 27(16): 3125-3144.
>
> McCulloch, C. E. and J. M. Neuhaus (2011). "Misspecifying the shape of a
> random effects distribution: why getting it wrong may not matter."
> Statistical Science: 388-402.
>
>
> On Sep 3, 2017 5:49 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>
>> On 04/09/17 03:48, Jonathan Judge wrote:
>>
>>> Rolf:
>>>
>>> I have not studied this extensively with smaller datasets, but with
>>> larger datasets --- five-figure and especially six-figure n --- I have
>>> found that it often makes no difference.
>>>
>>
>> When uncertain, I have used a likelihood ratio test to see if the
>>> differences are likely to be material.
>>>
>>
>> My overall suggestion would be that if the dataset is small enough
>>> for  this choice to matter, it is probably also small enough to solve the
>>> model through MCMC, in which case I would recommending using that,
>>> because the incorporated uncertainty often gives you better parameter
>>> estimates than any increased level of quadrature.
>>>
>>
>>
>> Thanks Jonathan.
>>
>> (a) How small is "small"?  I have 3 figure n's. I am currently mucking
>> about with two data sets.  One has 952 observations (with 22 treatment
>> groups, 3 random effect reps per group).  The other has 142 observations
>> (with 6 treatment groups and again 3 reps per group).  Would you call the
>> latter data set small?
>>
>> (b) I've never had the courage to try the MCMC approaches to mixed
>> models; have just used lme4.  I guess it's time that I bit the bullet.
>> Psigh.  This is going to take me a while.  As an old dog I *can* learn
>> new tricks, but I learn them *slowly*. :-)
>>
>> (c) In respect of the likelihood ratio test that you suggest --- sorry to
>> be a thicko, but I don't get it.  It seems to me that one is fitting the
>> *same model* in both instances, so the "degrees of freedom" for such a test
>> would be zero.  What am I missing?
>>
>> Thanks again.
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Mon Sep  4 11:34:57 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Mon, 4 Sep 2017 11:34:57 +0200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <CAFW8BypwY9LUkWtisMpXr_z_vbMY8g4BU2CL2hULYQw8s8MY5w@mail.gmail.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <CAFW8BypwY9LUkWtisMpXr_z_vbMY8g4BU2CL2hULYQw8s8MY5w@mail.gmail.com>
Message-ID: <59AD1E41.5030102@mpi.nl>

Doug Bates has posted some discussion on this as part of his newest book
project on mixed models (this time in Julia):

https://github.com/dmbates/MixedModelsinJulia/blob/master/nAGQ.ipynb

I'll try to summarize. The difference seems to be

- (nAGQ=0, fast=true) the fixed effects (beta) are estimated with the
conditional modes (b) of the random effects as part of the penalized
iterative least squares (PIRLS) step. Only the covariance parameters
(theta) are estimated during the nonlinear optimization step.

or

- (nAGQ=1, fast=slow) the fixed effect estimates are further optimized
with the covariance parameters as part of the nonlinear optimization
step i.e the Laplace approximation to the deviance.

Some software supports nAGQ > 1, in which case we have a better but more
numerically intensive approximation to the optimization; the Laplace
approximation is just a special case of Gaussian quadrature with one
quadrature point. I think lme4/MixedModels.jl supports this only for
single scalar (intercept-only) random effect.

As John pointed out, there doesn't seem to be other software that is
willing to omit the fixed effects from quadrature procedure as
lme4/MixedModels.jl does for nAGQ=0. For lme4/MixedModels.jl, they are
used as the starting values for the Laplace approximation, so it's
'free' to expose them to the user.

(If I recall correctly, you get the conditional modes for "free" in the
LMM case, at least for the numerical procedure used in
lme4/MixedModels.jl. The lme4 paper has more details on this, if you're
up for the math.)

Having additional parameters in the nonlinear optimization step of
course increases the dimensionality of that step and slows it down a
bit. However, estimating the fixed effects with the full covariance
parameters will often yield a better fit and will affect error estimates
and thus t-/z-values. I'm not sure how much it will affect the
coefficient estimates for 'well-behaved' datasets -- my guess is that
computing the fixed effects with the covariance parameters will affect
the relative amount of shrinkage amongst the fixed effects, increasing
it for some, decreasing it for others.

It's interesting to note that the conditional mode estimates are the
same in both cases because they are estimated first.

Best,
Phillip

On 09/04/2017 12:59 AM, Poe, John wrote:
> Oh and on the model comparison thing the only way i know how to directly
> compare random effects distribution estimates is with gateaux derivatives a
> la what Sophia Rabe-Hesketh did in her GLLAMM software for nonparametric
> random effects estimation.
> 
> Usually i just kind of eyeball it and try to be overly conservative with
> quadrature points or use MCMC.
> 
> I guess you could rig up some regular deviance test to do the same thing?
> 
> On Sep 3, 2017 6:51 PM, "Poe, John" <jdpo223 at g.uky.edu> wrote:
> 
>> I'm pretty sure that nAGQ=0 is generating conditional modes of group
>> values for the random effects without subsequently using a laplace
>> approximation. This is really not something that you want to do unless it's
>> a last resort. It's kind of like estimating a linear probability model with
>> a random intercept and using the values for that in the cloglog model. My
>> understanding is that it's not even an option in most other software.
>> Someone please correct me if I'm wrong here because what I've found on it
>> has been kind of vague and I'm making some assumptions.
>>
>> My guess is that the random intercepts/slopes are going to be too small
>> and their distributions could be distorted if you're not actually
>> approximating the integral with something like quadrature or mcmc. That's
>> the case with PQL and MQL according to simulation evidence at least and
>> even though this isn't the same as PQL I'd expect a similar problem at
>> first blush.
>>
>> As to if this is a real practical problem or a theory  problem there's
>> been kind of a disagreement on that within the stats literature. Some
>> people argue, in binary outcome models, that biased random intercepts can
>> bias everything else and others have argued this fear is overblown. This
>> might well have been settled by actual statisticians by now, I'm not sure.
>> It's gotten enough attention in the literature that people certainly
>> worried about it a lot.
>>
>> Below are two articles on the topic with simulations but I've seen the
>> fixed effects results (and LR tests) change based on the random effects
>> approximation technique in my work so I'm always a bit paranoid about it.
>> Model misspecification and having oddly shaped random intercepts (as with
>> count models) can seem to make this problem worse.
>>
>> You can try using the BRMS package if you aren't comfortable switching to
>> something totally unfamiliar. It's a wrapper for Stan designed to use lme4
>> syntax and a lot of good default settings. It's pretty easy to use if you
>> know lme4 syntax and can read up on mcmc diagnostics.
>>
>> Liti?re, S., et al. (2008). "The impact of a misspecified random?effects
>> distribution on the estimation and the performance of inferential
>> procedures in generalized linear mixed models." Stat Med 27(16): 3125-3144.
>>
>> McCulloch, C. E. and J. M. Neuhaus (2011). "Misspecifying the shape of a
>> random effects distribution: why getting it wrong may not matter."
>> Statistical Science: 388-402.
>>
>>
>> On Sep 3, 2017 5:49 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>
>>> On 04/09/17 03:48, Jonathan Judge wrote:
>>>
>>>> Rolf:
>>>>
>>>> I have not studied this extensively with smaller datasets, but with
>>>> larger datasets --- five-figure and especially six-figure n --- I have
>>>> found that it often makes no difference.
>>>>
>>>
>>> When uncertain, I have used a likelihood ratio test to see if the
>>>> differences are likely to be material.
>>>>
>>>
>>> My overall suggestion would be that if the dataset is small enough
>>>> for  this choice to matter, it is probably also small enough to solve the
>>>> model through MCMC, in which case I would recommending using that,
>>>> because the incorporated uncertainty often gives you better parameter
>>>> estimates than any increased level of quadrature.
>>>>
>>>
>>>
>>> Thanks Jonathan.
>>>
>>> (a) How small is "small"?  I have 3 figure n's. I am currently mucking
>>> about with two data sets.  One has 952 observations (with 22 treatment
>>> groups, 3 random effect reps per group).  The other has 142 observations
>>> (with 6 treatment groups and again 3 reps per group).  Would you call the
>>> latter data set small?
>>>
>>> (b) I've never had the courage to try the MCMC approaches to mixed
>>> models; have just used lme4.  I guess it's time that I bit the bullet.
>>> Psigh.  This is going to take me a while.  As an old dog I *can* learn
>>> new tricks, but I learn them *slowly*. :-)
>>>
>>> (c) In respect of the likelihood ratio test that you suggest --- sorry to
>>> be a thicko, but I don't get it.  It seems to me that one is fitting the
>>> *same model* in both instances, so the "degrees of freedom" for such a test
>>> would be zero.  What am I missing?
>>>
>>> Thanks again.
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ahmatias at gmail.com  Tue Sep  5 10:24:50 2017
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Tue, 5 Sep 2017 10:24:50 +0200
Subject: [R-sig-ME] Likelihood estimation by glm and glmer/lmer
Message-ID: <CA+hwER=kuS2iV6KPwVLyjoMKqrnOzXXGTe51j6bkj3XKp_2Oqw@mail.gmail.com>

Dear all,

I would like to compare AIC values of a null model estimated with glm
function and AIC values of models that only have random effects fitted with
glmer or lmer functions. I understand that they are comparable because both
estimate true likelihood. Could you confirm me this?

Thank you very much in advance,

Antonio

-- 
*********************************************************

Antonio Hernandez Matias

Equip de Biologia de la Conservaci?
Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
Universitat de Barcelona (UB)
Av. Diagonal, 643
Barcelona      08028
Spain
Telephone: +34-934035857
FAX: +34-934035740
e-mail: ahernandezmatias at ub.edu

***********************************************************

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Tue Sep  5 10:55:44 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Tue, 5 Sep 2017 10:55:44 +0200
Subject: [R-sig-ME] Likelihood estimation by glm and glmer/lmer
In-Reply-To: <CA+hwER=kuS2iV6KPwVLyjoMKqrnOzXXGTe51j6bkj3XKp_2Oqw@mail.gmail.com>
References: <CA+hwER=kuS2iV6KPwVLyjoMKqrnOzXXGTe51j6bkj3XKp_2Oqw@mail.gmail.com>
Message-ID: <59AE6690.5040604@mpi.nl>

For "true likelihood" ... you should search the list archives for
discussions on REML vs ML estimation and D. Bates' comments on *the*
likelihood. But, yes, if you you use REML=FALSE in lmer, you are
estimating the likelihood.

However, there's another problem with using AIC/BIC to compare mixed vs.
non-mixed models, namely how to count parameters in mixed models.
There's also been some discussion here of late with issues in counting
parameters in mixed models. For Bayesian models using DIC and WAIC, this
seems to be somewhat less of a problem because the effective number of
parameters is estimated as part of the procedure (maybe Jarrod Hadfield
or Paul B?rkner can comment/correct here), but there doesn't seem to be
a clear answer for what the actual number of parameters in a model is.
This is related to the degrees of freedom issue (
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f
).

All that said, there's an older post on this list that suggests that you
can use the deviance (which is -2 log likelihood) to compare lm and lmer
models:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022723.html

I think newer versions of lme4 even support this explicitly without any
hacks.

tl;dr: compare the likelihoods with REML=FALSE, but be careful with
counting parameters and hence AIC, etc.

Best,
Phillip


On 09/05/2017 10:24 AM, Toni Hernandez-Matias wrote:
> Dear all,
> 
> I would like to compare AIC values of a null model estimated with glm
> function and AIC values of models that only have random effects fitted with
> glmer or lmer functions. I understand that they are comparable because both
> estimate true likelihood. Could you confirm me this?
> 
> Thank you very much in advance,
> 
> Antonio
>


From bbolker at gmail.com  Tue Sep  5 14:24:01 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Sep 2017 08:24:01 -0400
Subject: [R-sig-ME] Likelihood estimation by glm and glmer/lmer
In-Reply-To: <59AE6690.5040604@mpi.nl>
References: <CA+hwER=kuS2iV6KPwVLyjoMKqrnOzXXGTe51j6bkj3XKp_2Oqw@mail.gmail.com>
 <59AE6690.5040604@mpi.nl>
Message-ID: <CABghstQpBNsD9=R5iZeG+mXiEwupPyD6d+Y68O6M_rwf7FU2bA@mail.gmail.com>

anova(), AIC(), etc. work fine across glm / glmer models and have since
1.0-0 (Aug 2013).  More info on counting parameters (which are *numerator*
or *model* degrees of freedom, not *residual* df) is available at ...

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect


On Tue, Sep 5, 2017 at 4:55 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:

> For "true likelihood" ... you should search the list archives for
> discussions on REML vs ML estimation and D. Bates' comments on *the*
> likelihood. But, yes, if you you use REML=FALSE in lmer, you are
> estimating the likelihood.
>
> However, there's another problem with using AIC/BIC to compare mixed vs.
> non-mixed models, namely how to count parameters in mixed models.
> There's also been some discussion here of late with issues in counting
> parameters in mixed models. For Bayesian models using DIC and WAIC, this
> seems to be somewhat less of a problem because the effective number of
> parameters is estimated as part of the procedure (maybe Jarrod Hadfield
> or Paul B?rkner can comment/correct here), but there doesn't seem to be
> a clear answer for what the actual number of parameters in a model is.
> This is related to the degrees of freedom issue (
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_
> 002dvalues-not-displayed-when-using-lmer_0028_0029_003f
> ).
>
> All that said, there's an older post on this list that suggests that you
> can use the deviance (which is -2 log likelihood) to compare lm and lmer
> models:
>
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022723.html
>
> I think newer versions of lme4 even support this explicitly without any
> hacks.
>
> tl;dr: compare the likelihoods with REML=FALSE, but be careful with
> counting parameters and hence AIC, etc.
>
> Best,
> Phillip
>
>
> On 09/05/2017 10:24 AM, Toni Hernandez-Matias wrote:
> > Dear all,
> >
> > I would like to compare AIC values of a null model estimated with glm
> > function and AIC values of models that only have random effects fitted
> with
> > glmer or lmer functions. I understand that they are comparable because
> both
> > estimate true likelihood. Could you confirm me this?
> >
> > Thank you very much in advance,
> >
> > Antonio
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ahmatias at gmail.com  Tue Sep  5 14:42:02 2017
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Tue, 5 Sep 2017 14:42:02 +0200
Subject: [R-sig-ME] Likelihood estimation by glm and glmer/lmer
In-Reply-To: <CABghstQpBNsD9=R5iZeG+mXiEwupPyD6d+Y68O6M_rwf7FU2bA@mail.gmail.com>
References: <CA+hwER=kuS2iV6KPwVLyjoMKqrnOzXXGTe51j6bkj3XKp_2Oqw@mail.gmail.com>
 <59AE6690.5040604@mpi.nl>
 <CABghstQpBNsD9=R5iZeG+mXiEwupPyD6d+Y68O6M_rwf7FU2bA@mail.gmail.com>
Message-ID: <CA+hwERkXM_2tD+44UyjMhZOVWeLXN2zk6agj=ZtgevrG6gPxFw@mail.gmail.com>

Thank you very much Philip and Ben for your helpful messages!

Antonio

On Tue, Sep 5, 2017 at 2:24 PM, Ben Bolker <bbolker at gmail.com> wrote:

> anova(), AIC(), etc. work fine across glm / glmer models and have since
> 1.0-0 (Aug 2013).  More info on counting parameters (which are *numerator*
> or *model* degrees of freedom, not *residual* df) is available at ...
>
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
> can-i-use-aic-for-mixed-models-how-do-i-count-the-
> number-of-degrees-of-freedom-for-a-random-effect
>
>
> On Tue, Sep 5, 2017 at 4:55 AM, Phillip Alday <phillip.alday at mpi.nl>
> wrote:
>
>> For "true likelihood" ... you should search the list archives for
>> discussions on REML vs ML estimation and D. Bates' comments on *the*
>> likelihood. But, yes, if you you use REML=FALSE in lmer, you are
>> estimating the likelihood.
>>
>> However, there's another problem with using AIC/BIC to compare mixed vs.
>> non-mixed models, namely how to count parameters in mixed models.
>> There's also been some discussion here of late with issues in counting
>> parameters in mixed models. For Bayesian models using DIC and WAIC, this
>> seems to be somewhat less of a problem because the effective number of
>> parameters is estimated as part of the procedure (maybe Jarrod Hadfield
>> or Paul B?rkner can comment/correct here), but there doesn't seem to be
>> a clear answer for what the actual number of parameters in a model is.
>> This is related to the degrees of freedom issue (
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002d
>> values-not-displayed-when-using-lmer_0028_0029_003f
>> ).
>>
>> All that said, there's an older post on this list that suggests that you
>> can use the deviance (which is -2 log likelihood) to compare lm and lmer
>> models:
>>
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q4/022723.html
>>
>> I think newer versions of lme4 even support this explicitly without any
>> hacks.
>>
>> tl;dr: compare the likelihoods with REML=FALSE, but be careful with
>> counting parameters and hence AIC, etc.
>>
>> Best,
>> Phillip
>>
>>
>> On 09/05/2017 10:24 AM, Toni Hernandez-Matias wrote:
>> > Dear all,
>> >
>> > I would like to compare AIC values of a null model estimated with glm
>> > function and AIC values of models that only have random effects fitted
>> with
>> > glmer or lmer functions. I understand that they are comparable because
>> both
>> > estimate true likelihood. Could you confirm me this?
>> >
>> > Thank you very much in advance,
>> >
>> > Antonio
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
*********************************************************

Antonio Hernandez Matias

Equip de Biologia de la Conservaci?
Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
Universitat de Barcelona (UB)
Av. Diagonal, 643
Barcelona      08028
Spain
Telephone: +34-934035857
FAX: +34-934035740
e-mail: ahernandezmatias at ub.edu

***********************************************************

	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Tue Sep  5 17:46:06 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Tue, 5 Sep 2017 15:46:06 +0000
Subject: [R-sig-ME] effect of adding a constant to predictor
Message-ID: <22958.50878.753094.461355@losangelesyouthorchestra.org>


I expected that adding a constant to an input in a mixed
model would affect some of the coefficients, but not such basic
stuff as AIC (or loglik, from which it is derived).
But I seem to have been wrong about that:

> AIC(lmer(output ~ input1 + I(input1 * input2) + input2 + ((1 | group) + (0 + input2 | group)) , data=xxx, REML=F, control=contr))
[1] 1556.341
> xxx$input2 = xxx$input2 + 1
> AIC(lmer(output ~ input1 + I(input1 * input2) + input2 + ((1 | group) + (0 + input2 | group)) , data=xxx, REML=F, control=contr))
[1] 1551.005

Can someone explain why this change to input2 affects AIC (or loglik) ?

BTW, changing (0 + input2 | group) to (0 + input1 | group) 
produces the same AIC before and after the change to input2.


From bbolker at gmail.com  Tue Sep  5 17:54:01 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Sep 2017 11:54:01 -0400
Subject: [R-sig-ME] effect of adding a constant to predictor
In-Reply-To: <22958.50878.753094.461355@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
Message-ID: <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>


   On first glance this is indeed a bit surprising. However, I believe
the reason is that you've specified group and input2 as separate
(independent) random effects, without allowing a correlation between
them, which means that the random-effects model is no longer invariant
to shifts in the parameters.  If you had used (1+input2|group) as your
random effect instead, I believe you would get the same
log-likelihood/AIC either way.

  This mentioned on p. 7 of vignette("lmer",package="lme4"):

> Although mixed models where the random slopes and intercepts are
assumed independent are commonly used to reduce the complexity of
random-slopes models, they do have one subtle drawback. Models in which
the slopes and intercepts are allowed to have a non-zero correlation
(e.g., fm1) are invariant to additive shifts of the continuous predictor
(Days in this case). This invariance breaks down when the correlation is
constrained to zero; any shift in the predictor will necessarily lead to
a change in the estimated correlation, and in the likelihood and
predictions of the model ... The use of such models should ideally be
restricted to cases where the predictor is measured on a ratio scale
(i.e., the zero point on the scale is meaningful, not just a location
defined by convenience or convention).

  cheers
   Ben Bolker

On 17-09-05 11:46 AM, Don Cohen wrote:
> 
> I expected that adding a constant to an input in a mixed
> model would affect some of the coefficients, but not such basic
> stuff as AIC (or loglik, from which it is derived).
> But I seem to have been wrong about that:
> 
>> AIC(lmer(output ~ input1 + I(input1 * input2) + input2 + ((1 | group) + (0 + input2 | group)) , data=xxx, REML=F, control=contr))
> [1] 1556.341
>> xxx$input2 = xxx$input2 + 1
>> AIC(lmer(output ~ input1 + I(input1 * input2) + input2 + ((1 | group) + (0 + input2 | group)) , data=xxx, REML=F, control=contr))
> [1] 1551.005
> 
> Can someone explain why this change to input2 affects AIC (or loglik) ?
> 
> BTW, changing (0 + input2 | group) to (0 + input1 | group) 
> produces the same AIC before and after the change to input2.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-r-help at isis.cs3-inc.com  Tue Sep  5 18:52:03 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Tue, 5 Sep 2017 16:52:03 +0000
Subject: [R-sig-ME] effect of adding a constant to predictor
In-Reply-To: <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
Message-ID: <22958.54835.530288.669184@losangelesyouthorchestra.org>


Ben Bolker writes:

 >    On first glance this is indeed a bit surprising. However, I believe
 > the reason is that you've specified group and input2 as separate
 > (independent) random effects, without allowing a correlation between
 > them, which means that the random-effects model is no longer invariant
 > to shifts in the parameters.  If you had used (1+input2|group) as your
 > random effect instead, I believe you would get the same
 > log-likelihood/AIC either way.

Well, when I make that change I do get the same answer.
Thanks for the explanation.  Not being invariant to additive 
shifts makes me wonder whether this is a reasonable model at all.

This raises another question.  I've been using drop1 to compute
P values.  I expected that I could compute the P values at 
different values of interacting inputs by using these additive
shifts, but evidently that's not going to work.
Is there some other way to compute a p values for input1 at some 
non-zero value of input2 ?

Given that the shifted model seems to make as much sense as the
original, perhaps it's reasonable to just use one model for one 
value of input2 and the other model for the other value?


From newboch at auburn.edu  Tue Sep  5 21:49:45 2017
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 5 Sep 2017 19:49:45 +0000
Subject: [R-sig-ME] Help with mixed model design
Message-ID: <1504640986409.71596@auburn.edu>

All,



I'm having some difficulty envisioning how to address a question with mixed model and thought might find some assistance here.  I have a dataset generated from a survey where individual were asked to view a set of images and classify animals in these images according to sex/age groups.  We wanted to investigate the effects of observer experience, profession, etc., and factors related to the image itself (day/night, animal group, etc.) on how accurately observers could classify animals.  Responses in our survey could be either correct/incorrect (we knew truth in our test images) which could be input as a simple binary response; however, viewers also had the option of responding  "Unknown" for images they did not feel comfortable answering due to image quality, etc.  This was done to mimic what is done in practice in our field of work but was a real pain in our current efforts.  Since "Unknown" responses in our particular application are technically neither correct nor incorrect (but do influence census results in practice), I decided to split my analysis into two models: 1) A correct/incorrect response model (I removed the Unknown responses in this data set), and 2) An Unknown response model (I created a new binary variable for Unknown/Any other response).  These models answer two very different questions which we believe are both of value to us.



My difficulty now concerns the Incorrect responses.  I would like to find a way to determine probabilities of the kinds of error that we see in our data.  For example, images that contained male animals that were incorrectly answered, how likely were those responses female vs. young?  This information would be valuable in predicting how the errors that we observed might be influencing population surveys.



My thought is to first subset the data, maintaining only incorrect responses.  I assume I could then create a new binary factor where one level of observer responses (Male, Female, Young) is 1 and all others are 0.  I could then model this binary response with a fixed effect for the answer I know to be true (also Male, Female, Young) along with my random effects.  This would be repeated three times for each kind of incorrect response.  Something like:



Response"Male 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)

Response"Female 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)

Response"Young 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)



Does that make any sense?  Any better ideas?  It's probably very simple but I've really struggled with this one.



Thanks

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Sep  6 09:16:30 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 6 Sep 2017 09:16:30 +0200
Subject: [R-sig-ME] Help with mixed model design
In-Reply-To: <1504640986409.71596@auburn.edu>
References: <1504640986409.71596@auburn.edu>
Message-ID: <CAJuCY5ydC=NX=UCL2y6EVNtvG+6V9m_=jxVcEy_mr6pf02h7pg@mail.gmail.com>

Dear Chad,

it seems like you want predictions for specific combinations of covariates
or testing for specific contrasts of the parameters.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-09-05 21:49 GMT+02:00 Chad Newbolt <newboch at auburn.edu>:

> All,
>
>
>
> I'm having some difficulty envisioning how to address a question with
> mixed model and thought might find some assistance here.  I have a dataset
> generated from a survey where individual were asked to view a set of images
> and classify animals in these images according to sex/age groups.  We
> wanted to investigate the effects of observer experience, profession, etc.,
> and factors related to the image itself (day/night, animal group, etc.) on
> how accurately observers could classify animals.  Responses in our survey
> could be either correct/incorrect (we knew truth in our test images) which
> could be input as a simple binary response; however, viewers also had the
> option of responding  "Unknown" for images they did not feel comfortable
> answering due to image quality, etc.  This was done to mimic what is done
> in practice in our field of work but was a real pain in our current
> efforts.  Since "Unknown" responses in our particular application are
> technically neither correct nor incorrect (but d
>  o influence census results in practice), I decided to split my analysis
> into two models: 1) A correct/incorrect response model (I removed the
> Unknown responses in this data set), and 2) An Unknown response model (I
> created a new binary variable for Unknown/Any other response).  These
> models answer two very different questions which we believe are both of
> value to us.
>
>
>
> My difficulty now concerns the Incorrect responses.  I would like to find
> a way to determine probabilities of the kinds of error that we see in our
> data.  For example, images that contained male animals that were
> incorrectly answered, how likely were those responses female vs. young?
> This information would be valuable in predicting how the errors that we
> observed might be influencing population surveys.
>
>
>
> My thought is to first subset the data, maintaining only incorrect
> responses.  I assume I could then create a new binary factor where one
> level of observer responses (Male, Female, Young) is 1 and all others are
> 0.  I could then model this binary response with a fixed effect for the
> answer I know to be true (also Male, Female, Young) along with my random
> effects.  This would be repeated three times for each kind of incorrect
> response.  Something like:
>
>
>
> Response"Male 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)
>
> Response"Female 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)
>
> Response"Young 1 or 0" ~  True Answer + (1| Observer ID) + (1|Question)
>
>
>
> Does that make any sense?  Any better ideas?  It's probably very simple
> but I've really struggled with this one.
>
>
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Wed Sep  6 21:57:02 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 6 Sep 2017 19:57:02 +0000
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <22958.54835.530288.669184@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
Message-ID: <22960.21262.919792.560339@losangelesyouthorchestra.org>


My current understanding is that something like (input2 | group)
means the same as (1 + input2 | group) which means to estimate
for each group an intercept, a slope and a correlation between the two.

Does (input1 + input2 | group) mean the same as
(input1 | group) + (input2 | group) or does it also include a 
correlation between input1 and input2 ?

Back to my question about additive shifts, is that extra correlation 
required in order to maintain invariance over additive shifts?

Is there some way in the formula language to control more precisely
which correlations are to be included/excluded?


From bbolker at gmail.com  Wed Sep  6 22:45:32 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Sep 2017 16:45:32 -0400
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <22960.21262.919792.560339@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
Message-ID: <dc928820-0185-5a64-4547-07562b83864c@gmail.com>



On 17-09-06 03:57 PM, Don Cohen wrote:
> 
> My current understanding is that something like (input2 | group)
> means the same as (1 + input2 | group) which means to estimate
> for each group an intercept, a slope and a correlation between the two.

  Yes.
> 
> Does (input1 + input2 | group) mean the same as
> (input1 | group) + (input2 | group) or does it also include a 
> correlation between input1 and input2 ?

  The latter.

> 
> Back to my question about additive shifts, is that extra correlation 
> required in order to maintain invariance over additive shifts?

  Yes.

> 
> Is there some way in the formula language to control more precisely
> which correlations are to be included/excluded?
> 

  Unfortunately not.
  I gave an example here
https://stackoverflow.com/questions/38976189/syntax-of-pdblocked-to-specify-covariance-matrix-in-mixed-effects-model-nlme
about how to specify some structural zeros in the covariance matrix, but
it's not easy ...

http://rpubs.com/bbolker/varcov_equiv may be useful as well.


From don-r-help at isis.cs3-inc.com  Wed Sep  6 23:17:14 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 6 Sep 2017 21:17:14 +0000
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
Message-ID: <22960.26074.206053.16571@losangelesyouthorchestra.org>

Ben Bolker writes:

 > > Does (input1 + input2 | group) mean the same as
 > > (input1 | group) + (input2 | group) or does it also include a 
 > > correlation between input1 and input2 ?
 >   The latter.

It occurred to me after I wrote the questions that 
(input1 | group) + (input2 | group) might also include that
correlation between input1 and input2 - I gather now it does not.

 > > Back to my question about additive shifts, is that extra correlation 
 > > required in order to maintain invariance over additive shifts?
 >   Yes.

One more question (so far):
If there are two different groupings, would
 (input1 + input2 | group1) + (input1 + input2 | group2)
involve correlations between group1 and group2 ?

If I think of (1+input1 | group) as a 2x2 matrix, and
(1+input1+input2 | group) as 3x3
then is (1+input1+input2 | group1)+(1+input1+input2 | group2)
two independent 3x3's or a full 6x6 (or something else) ?


From r.turner at auckland.ac.nz  Wed Sep  6 23:48:08 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 7 Sep 2017 09:48:08 +1200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
Message-ID: <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>

On 04/09/17 10:51, Poe, John wrote:

<SNIP>

> You can try using the BRMS package if you aren't comfortable switching 
> to something totally unfamiliar. It's a wrapper for Stan designed to use 
> lme4 syntax and a lot of good default settings. It's pretty easy to use 
> if you know lme4 syntax and can read up on mcmc diagnostics.

<SNIP>

I remember a quote from some Brit comedy series (it starred the bloke 
who played Terry on "Minder"):  "My mother always said that you should 
try anything once, except for incest and Morris dancing.  She was right 
about the Morris dancing."

On that basis I decided to try using brms.  I installed the package from 
CRAN with no real problems, although there were some slightly worrying 
and highly technical warnings from "rstan" --- I think:

> warning: non-static data member initializers only available with -std=c++11 or -std=gnu++11
>        bool has_var_ = false;

Then I read the vignette brms_overview a bit, and plunged in with trying 
to fit a model.  Needless to say, the attempt didn't get much past 
square zero.  I tried it again with my artificial simulated data that I 
talked about in the post that started off this train of craziness (it 
elicited the suggestion from Tony Ives that I try using nAGQ=0).  The 
result was the same --- square zero + epsilon:

> Compiling the C++ model
> Start sampling
> 
> SAMPLING FOR MODEL 'binomial(cloglog) brms-model' NOW (CHAIN 1).
> Rejecting initial value:
>   Log probability evaluates to log(0), i.e. negative infinity.
>   Stan can't start sampling from this initial value.
     .
     .
     .
> Rejecting initial value:
>   Log probability evaluates to log(0), i.e. negative infinity.
>   Stan can't start sampling from this initial value.
> Rejecting initial value:
>   Log probability evaluates to log(0), i.e. negative infinity.
>   Stan can't start sampling from this initial value.
> 
> Initialization between (-2, 2) failed after 100 attempts. 
>  Try specifying initial values, reducing ranges of constrained values, or reparameterizing the model.
> [1] "Error in sampler$call_sampler(args_list[[i]]) : Initialization failed."
> error occurred during calling the sampler; sampling not done

Since I'm flying completely blind here (no idea WTF I'm doing) I have 
come to a shuddering halt.

I have attached my function "artSim.R" to generate the artificial data,
and a script to source to effect the call to brm() that I used.

If some kind mixed models guru could take a look and point out to me 
just what bit of egregious stupidity I am committing, I'd be ever so 
humbly grateful.  I don't know from Bayesian stuff (priors, and like 
that) at all, so it's likely to be something pretty stupid and pretty 
simple in the first instance.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
-------------- next part --------------
artSim <- function(){
#
# Function to simulate "artificial" data which is at least superficially
# similar to some real data.
#
require(MASS)

link    <- "cloglog"
B       <- binomial(link=link)
linkfun <- B$linkfun
linkinv <- B$linkinv

# Construct (artificial) treatment factor, covariate, and
# (random) replicate factor.
x    <- seq(0,28,by=2)
Trt  <- LETTERS[1:24]
Rep  <- 1:3 # Three reps per treatment.
Xdat <- expand.grid(x=x,Trt=Trt,Rep=Rep)
uRep <- with(Xdat,factor(paste0(Rep,Trt)))
Xdat$Rep <- with(Xdat,factor(as.numeric(uRep)))

beta0 <- seq(-3,0.45,by=0.15)
beta1 <- rep(seq(0.05,0.3,by=0.05),4)
names(beta0) <- Trt
names(beta1) <- Trt
Sigma <- matrix(c(0.06,-0.001,-0.001,0.0001),nrow=2)

lb0   <- beta0[match(Xdat$Trt,names(beta0))]
lb1   <- beta1[match(Xdat$Trt,names(beta1))]
nrep  <- 72
imat  <- match(Xdat$Rep,1:nrep)
Z     <- mvrnorm(nrep,c(0,0),Sigma)[imat,]
linpr <- lb0 + Z[,1] + (lb1 + Z[,2])*Xdat$x
p     <- linkinv(linpr)
nsize <- 25
Dead  <- rbinom(nrow(Xdat),nsize,p)
Alive <- nsize - Dead
x0    <- (linkfun(0.99) - beta0)/beta1
Xdat$Dead  <- Dead
Xdat$Alive <- Alive
attr(Xdat,"trueLD99") <- x0
return(Xdat)
}
-------------- next part --------------
#
# Script scr.brmsDemo
#

set.seed(42)
X <- artSim()
library(brms)
fit <- brm(Dead|trials(Dead+Alive) ~ (0+Trt)/x + (x | Rep),
           family=binomial(link="cloglog"),data=X,
           prior=set_prior("normal(0,10)"))

From jdpo223 at g.uky.edu  Thu Sep  7 00:57:09 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Wed, 6 Sep 2017 18:57:09 -0400
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
Message-ID: <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>

This is where my being a political scientist on a listserv full of
definitely not political scientists is going to make me look dumb. I've
never actually seen a model specification like that before for a multilevel
model. Is the outcome supposed to be the proportion dead out of the total
population for each row? I'm missing something about this that is probably
very obvious.

After fiddling with it I was able to get it to converge for one chain but I
wouldn't trust it at all right now.

On Wed, Sep 6, 2017 at 5:48 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 04/09/17 10:51, Poe, John wrote:
>
> <SNIP>
>
> You can try using the BRMS package if you aren't comfortable switching to
>> something totally unfamiliar. It's a wrapper for Stan designed to use lme4
>> syntax and a lot of good default settings. It's pretty easy to use if you
>> know lme4 syntax and can read up on mcmc diagnostics.
>>
>
> <SNIP>
>
> I remember a quote from some Brit comedy series (it starred the bloke who
> played Terry on "Minder"):  "My mother always said that you should try
> anything once, except for incest and Morris dancing.  She was right about
> the Morris dancing."
>
> On that basis I decided to try using brms.  I installed the package from
> CRAN with no real problems, although there were some slightly worrying and
> highly technical warnings from "rstan" --- I think:
>
> warning: non-static data member initializers only available with
>> -std=c++11 or -std=gnu++11
>>        bool has_var_ = false;
>>
>
> Then I read the vignette brms_overview a bit, and plunged in with trying
> to fit a model.  Needless to say, the attempt didn't get much past square
> zero.  I tried it again with my artificial simulated data that I talked
> about in the post that started off this train of craziness (it elicited the
> suggestion from Tony Ives that I try using nAGQ=0).  The result was the
> same --- square zero + epsilon:
>
> Compiling the C++ model
>> Start sampling
>>
>> SAMPLING FOR MODEL 'binomial(cloglog) brms-model' NOW (CHAIN 1).
>> Rejecting initial value:
>>   Log probability evaluates to log(0), i.e. negative infinity.
>>   Stan can't start sampling from this initial value.
>>
>     .
>     .
>     .
>
>> Rejecting initial value:
>>   Log probability evaluates to log(0), i.e. negative infinity.
>>   Stan can't start sampling from this initial value.
>> Rejecting initial value:
>>   Log probability evaluates to log(0), i.e. negative infinity.
>>   Stan can't start sampling from this initial value.
>>
>> Initialization between (-2, 2) failed after 100 attempts.  Try specifying
>> initial values, reducing ranges of constrained values, or reparameterizing
>> the model.
>> [1] "Error in sampler$call_sampler(args_list[[i]]) : Initialization
>> failed."
>> error occurred during calling the sampler; sampling not done
>>
>
> Since I'm flying completely blind here (no idea WTF I'm doing) I have come
> to a shuddering halt.
>
> I have attached my function "artSim.R" to generate the artificial data,
> and a script to source to effect the call to brm() that I used.
>
> If some kind mixed models guru could take a look and point out to me just
> what bit of egregious stupidity I am committing, I'd be ever so humbly
> grateful.  I don't know from Bayesian stuff (priors, and like that) at all,
> so it's likely to be something pretty stupid and pretty simple in the first
> instance.
>
> cheers,
>
> Rolf Turner
>
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>



-- 




Thanks,
John


John Poe
Research Methodologist
UK Center for Public Health Services & Systems Research
University of Kentucky
111 Washington Avenue, Room 203a
Lexington, KY 40536
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Sep  7 04:07:53 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Sep 2017 22:07:53 -0400
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <22960.26074.206053.16571@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
 <22960.26074.206053.16571@losangelesyouthorchestra.org>
Message-ID: <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>



On 17-09-06 05:17 PM, Don Cohen wrote:
> Ben Bolker writes:
> 
>  > > Does (input1 + input2 | group) mean the same as
>  > > (input1 | group) + (input2 | group) or does it also include a 
>  > > correlation between input1 and input2 ?
>  >   The latter.
> 
> It occurred to me after I wrote the questions that 
> (input1 | group) + (input2 | group) might also include that
> correlation between input1 and input2 - I gather now it does not.

 It does not.  Separate terms in lme4 formulas are always independent.

(input1|group) + (input2|group) is problematic because both terms
include an intercept.  (0+input2|group) can be helpful, but doesn't do
what you think when the variable on the LHS (e.g. input2) is a factor.
> 
>  > > Back to my question about additive shifts, is that extra correlation 
>  > > required in order to maintain invariance over additive shifts?
>  >   Yes.
> 
> One more question (so far):
> If there are two different groupings, would
>  (input1 + input2 | group1) + (input1 + input2 | group2)
> involve correlations between group1 and group2 ?

  No.

> 
> If I think of (1+input1 | group) as a 2x2 matrix, and
> (1+input1+input2 | group) as 3x3
> then is (1+input1+input2 | group1)+(1+input1+input2 | group2)
> two independent 3x3's or a full 6x6 (or something else) ?
> 

If input1 and input2 are both numeric (or 2-level factors) then they're
two independent 3x3s.


From r.turner at auckland.ac.nz  Thu Sep  7 06:12:56 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 7 Sep 2017 16:12:56 +1200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
Message-ID: <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>


On 07/09/17 10:57, Poe, John wrote:

> This is where my being a political scientist on a listserv full of 
> definitely not political scientists is going to make me look dumb. I've 
> never actually seen a model specification like that before for a 
> multilevel model. Is the outcome supposed to be the proportion dead out 
> of the total population for each row? I'm missing something about this 
> that is probably very obvious.
> 
> After fiddling with it I was able to get it to converge for one chain 
> but I wouldn't trust it at all right now.

Well, I hadn't seen a model specification quite like that either.  It's 
brm() syntax, which is a bit different from glm() or glmer() syntax.

The model being fitted is a binomial model, with success probability p 
modelled by

     g(p) = beta_0 + beta_1 * x + Z_0 + Z_1 * x

where the Z_k are the random effects, and where g() is the link 
function, e.g. cloglog(). (I *think* I've got that right.)

Of course beta_0 and beta_1 depend on treatment group and Z_0 and Z_1
depend on "Rep", which is nested within treatment group.

Note that we are talking *generalized* linear mixed models here; the 
responses are binomial success counts.  "Success" = Dead, since one is 
trying to kill the bugs.

For what it's worth the glmer() syntax is

    glmer(cbind(Dead,Alive) ~ (0 + Trt)/x + (x | Rep),
          family=binomial(link="cloglog"),data=X)

I got the brm() syntax from the vignette; as I said, I'd never seen it 
before.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From don-r-help at isis.cs3-inc.com  Thu Sep  7 06:43:07 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 7 Sep 2017 04:43:07 +0000
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
 <22960.26074.206053.16571@losangelesyouthorchestra.org>
 <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>
Message-ID: <22960.52827.310170.196801@losangelesyouthorchestra.org>


Is there some documentation I should be reading about this rather 
than asking all these questions?  Other than the code, that is?

Ben Bolker writes:
 >  Separate terms in lme4 formulas are always independent.

In a formula like "out ~ in + ((a | group) + (b | group))"
do (a | group) and (b | group) qualify as separate terms?

 > (input1|group) + (input2|group) is problematic because both terms
 > include an intercept.

I was imagining that this duplication was removed after the formula
was expanded into some internal form (that I'd like to see).  I guess
you're saying that's not true.  

 > (0+input2|group) can be helpful, but doesn't do
 > what you think when the variable on the LHS (e.g. input2) is a factor.

Where can I read about what that means?

 > If input1 and input2 are both numeric (or 2-level factors) then they're
 > two independent 3x3s.

I have trouble seeing how factors make sense on the LHS.

Another question:
I tried an example with about a dozen inputs inside one group
(in1 + in2 + ... | group1) and another with the same inputs for
a second group, and both took about a minute, and then when I
used both groups the run time went up to about 10 min.
Is this expected and easily explained?


From jake.a.westfall at gmail.com  Thu Sep  7 06:47:54 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 6 Sep 2017 23:47:54 -0500
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <22960.52827.310170.196801@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
 <22960.26074.206053.16571@losangelesyouthorchestra.org>
 <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>
 <22960.52827.310170.196801@losangelesyouthorchestra.org>
Message-ID: <CAE9_Wg7DXMEf_0cKdzrim0yRXGOCPo1sqs-UsuvBteWX+ANYPw@mail.gmail.com>

Hi Don,

Is there some documentation I should be reading about this rather
> than asking all these questions?  Other than the code, that is?


Not sure if it would answer *all* your questions but have a look at the R
GLMM FAQ, the relevant section of which is here:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification

It's a great resource on mixed models generally.

Jake

On Wed, Sep 6, 2017 at 11:43 PM, Don Cohen <don-r-help at isis.cs3-inc.com>
wrote:

>
> Is there some documentation I should be reading about this rather
> than asking all these questions?  Other than the code, that is?
>
> Ben Bolker writes:
>  >  Separate terms in lme4 formulas are always independent.
>
> In a formula like "out ~ in + ((a | group) + (b | group))"
> do (a | group) and (b | group) qualify as separate terms?
>
>  > (input1|group) + (input2|group) is problematic because both terms
>  > include an intercept.
>
> I was imagining that this duplication was removed after the formula
> was expanded into some internal form (that I'd like to see).  I guess
> you're saying that's not true.
>
>  > (0+input2|group) can be helpful, but doesn't do
>  > what you think when the variable on the LHS (e.g. input2) is a factor.
>
> Where can I read about what that means?
>
>  > If input1 and input2 are both numeric (or 2-level factors) then they're
>  > two independent 3x3s.
>
> I have trouble seeing how factors make sense on the LHS.
>
> Another question:
> I tried an example with about a dozen inputs inside one group
> (in1 + in2 + ... | group1) and another with the same inputs for
> a second group, and both took about a minute, and then when I
> used both groups the run time went up to about 10 min.
> Is this expected and easily explained?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Thu Sep  7 10:04:59 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Thu, 7 Sep 2017 08:04:59 +0000
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>,
 <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
Message-ID: <1504771498875.58215@nmbu.no>

Hi Rolf, 

Just a quick point: running the brms model with a logit link works fine for me.

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Rolf Turner <r.turner at auckland.ac.nz>
Sent: Thursday, September 7, 2017 6:12 AM
To: Poe, John
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] nAGQ = 0

On 07/09/17 10:57, Poe, John wrote:

> This is where my being a political scientist on a listserv full of
> definitely not political scientists is going to make me look dumb. I've
> never actually seen a model specification like that before for a
> multilevel model. Is the outcome supposed to be the proportion dead out
> of the total population for each row? I'm missing something about this
> that is probably very obvious.
>
> After fiddling with it I was able to get it to converge for one chain
> but I wouldn't trust it at all right now.

Well, I hadn't seen a model specification quite like that either.  It's
brm() syntax, which is a bit different from glm() or glmer() syntax.

The model being fitted is a binomial model, with success probability p
modelled by

     g(p) = beta_0 + beta_1 * x + Z_0 + Z_1 * x

where the Z_k are the random effects, and where g() is the link
function, e.g. cloglog(). (I *think* I've got that right.)

Of course beta_0 and beta_1 depend on treatment group and Z_0 and Z_1
depend on "Rep", which is nested within treatment group.

Note that we are talking *generalized* linear mixed models here; the
responses are binomial success counts.  "Success" = Dead, since one is
trying to kill the bugs.

For what it's worth the glmer() syntax is

    glmer(cbind(Dead,Alive) ~ (0 + Trt)/x + (x | Rep),
          family=binomial(link="cloglog"),data=X)

I got the brm() syntax from the vignette; as I said, I'd never seen it
before.

cheers,

Rolf

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Thu Sep  7 10:24:21 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 7 Sep 2017 20:24:21 +1200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <1504771498875.58215@nmbu.no>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
 <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
 <1504771498875.58215@nmbu.no>
Message-ID: <f1d493f2-825d-6eae-70ab-8c4bbee6399e@auckland.ac.nz>

On 07/09/17 20:04, Conor Michael Goold wrote:
> Hi Rolf,
> 
> Just a quick point: running the brms model with a logit link works fine for me.

That is indeed interesting. I'll investigate.  Thanks for pointing this out.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jfox at mcmaster.ca  Thu Sep  7 14:27:22 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 7 Sep 2017 12:27:22 +0000
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <23524_1504759401_v874hKue006673_22960.52827.310170.196801@losangelesyouthorchestra.org>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
 <22960.26074.206053.16571@losangelesyouthorchestra.org>
 <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>
 <23524_1504759401_v874hKue006673_22960.52827.310170.196801@losangelesyouthorchestra.org>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366C04A6@FHSDB4H16-2.csu.mcmaster.ca>

Dear Don,

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Don Cohen
> Sent: Thursday, September 7, 2017 12:43 AM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] meaning of lmer formula
> 
> 
> Is there some documentation I should be reading about this rather than asking
> all these questions?  Other than the code, that is?

Have you read the vignette on lmer() in the package? 

	vignette("lmer", package="lme4")

It also appeared as a paper in the Journal of Statistical Software.

It strikes me that your questions can also be answered by just trying the various formulas that you propose and examining the output.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox


> 
> Ben Bolker writes:
>  >  Separate terms in lme4 formulas are always independent.
> 
> In a formula like "out ~ in + ((a | group) + (b | group))"
> do (a | group) and (b | group) qualify as separate terms?
> 
>  > (input1|group) + (input2|group) is problematic because both terms  >
> include an intercept.
> 
> I was imagining that this duplication was removed after the formula was
> expanded into some internal form (that I'd like to see).  I guess you're saying
> that's not true.
> 
>  > (0+input2|group) can be helpful, but doesn't do  > what you think when the
> variable on the LHS (e.g. input2) is a factor.
> 
> Where can I read about what that means?
> 
>  > If input1 and input2 are both numeric (or 2-level factors) then they're  > two
> independent 3x3s.
> 
> I have trouble seeing how factors make sense on the LHS.
> 
> Another question:
> I tried an example with about a dozen inputs inside one group
> (in1 + in2 + ... | group1) and another with the same inputs for a second group,
> and both took about a minute, and then when I used both groups the run time
> went up to about 10 min.
> Is this expected and easily explained?
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From phillip.alday at mpi.nl  Thu Sep  7 21:41:51 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 7 Sep 2017 21:41:51 +0200
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
 <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
Message-ID: <59B1A0FF.1020905@mpi.nl>

As mentioned previously, the formula syntax for this one is a bit
confusing. The left-hand side was easy enough to figure out from the
brms docs, but the division operator on the RHS was a trick I had never
used before -- it took me looking at the output from the
glmer(...,nAGQ=0) model to get that it's equivalent to	

~ 0 + Trt + Trt:x + (x | Rep)

Phillip



On 09/07/2017 06:12 AM, Rolf Turner wrote:
> 
> On 07/09/17 10:57, Poe, John wrote:
> 
>> This is where my being a political scientist on a listserv full of
>> definitely not political scientists is going to make me look dumb.
>> I've never actually seen a model specification like that before for a
>> multilevel model. Is the outcome supposed to be the proportion dead
>> out of the total population for each row? I'm missing something about
>> this that is probably very obvious.
>>
>> After fiddling with it I was able to get it to converge for one chain
>> but I wouldn't trust it at all right now.
> 
> Well, I hadn't seen a model specification quite like that either.  It's
> brm() syntax, which is a bit different from glm() or glmer() syntax.
> 
> The model being fitted is a binomial model, with success probability p
> modelled by
> 
>     g(p) = beta_0 + beta_1 * x + Z_0 + Z_1 * x
> 
> where the Z_k are the random effects, and where g() is the link
> function, e.g. cloglog(). (I *think* I've got that right.)
> 
> Of course beta_0 and beta_1 depend on treatment group and Z_0 and Z_1
> depend on "Rep", which is nested within treatment group.
> 
> Note that we are talking *generalized* linear mixed models here; the
> responses are binomial success counts.  "Success" = Dead, since one is
> trying to kill the bugs.
> 
> For what it's worth the glmer() syntax is
> 
>    glmer(cbind(Dead,Alive) ~ (0 + Trt)/x + (x | Rep),
>          family=binomial(link="cloglog"),data=X)
> 
> I got the brm() syntax from the vignette; as I said, I'd never seen it
> before.
> 
> cheers,
> 
> Rolf
>


From jake.a.westfall at gmail.com  Thu Sep  7 22:00:59 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Thu, 7 Sep 2017 15:00:59 -0500
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <59B1A0FF.1020905@mpi.nl>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
 <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
 <59B1A0FF.1020905@mpi.nl>
Message-ID: <CAE9_Wg4h=85yJTgPoeG8ntOxwwCtudb-7-=QTjmqW_vHX1Uwnw@mail.gmail.com>

To further clear things up for other readers, this formula syntax is a nice
and very useful (if little known) trick for estimating separate intercepts
and x slopes for each level of Trt. It creates a design matrix like:

[1 0 x_1 0]
[1 0 x_2 0]
[0 1 0 x_3]
[0 1 0 x_4]

where the first two rows belong to Trt=1, the second two rows belong to
Trt=2; columns 1 and 2 are the Trt1 and Trt2 intercepts, respectively; and
columns 3 and 4 contain only the x values for Trt1 and Trt2, respectively,
so their associated coefficients give the group-specific slopes for each
level of Trt.

Jake

On Thu, Sep 7, 2017 at 2:41 PM, Phillip Alday <phillip.alday at mpi.nl> wrote:

> As mentioned previously, the formula syntax for this one is a bit
> confusing. The left-hand side was easy enough to figure out from the
> brms docs, but the division operator on the RHS was a trick I had never
> used before -- it took me looking at the output from the
> glmer(...,nAGQ=0) model to get that it's equivalent to
>
> ~ 0 + Trt + Trt:x + (x | Rep)
>
> Phillip
>
>
>
> On 09/07/2017 06:12 AM, Rolf Turner wrote:
> >
> > On 07/09/17 10:57, Poe, John wrote:
> >
> >> This is where my being a political scientist on a listserv full of
> >> definitely not political scientists is going to make me look dumb.
> >> I've never actually seen a model specification like that before for a
> >> multilevel model. Is the outcome supposed to be the proportion dead
> >> out of the total population for each row? I'm missing something about
> >> this that is probably very obvious.
> >>
> >> After fiddling with it I was able to get it to converge for one chain
> >> but I wouldn't trust it at all right now.
> >
> > Well, I hadn't seen a model specification quite like that either.  It's
> > brm() syntax, which is a bit different from glm() or glmer() syntax.
> >
> > The model being fitted is a binomial model, with success probability p
> > modelled by
> >
> >     g(p) = beta_0 + beta_1 * x + Z_0 + Z_1 * x
> >
> > where the Z_k are the random effects, and where g() is the link
> > function, e.g. cloglog(). (I *think* I've got that right.)
> >
> > Of course beta_0 and beta_1 depend on treatment group and Z_0 and Z_1
> > depend on "Rep", which is nested within treatment group.
> >
> > Note that we are talking *generalized* linear mixed models here; the
> > responses are binomial success counts.  "Success" = Dead, since one is
> > trying to kill the bugs.
> >
> > For what it's worth the glmer() syntax is
> >
> >    glmer(cbind(Dead,Alive) ~ (0 + Trt)/x + (x | Rep),
> >          family=binomial(link="cloglog"),data=X)
> >
> > I got the brm() syntax from the vignette; as I said, I'd never seen it
> > before.
> >
> > cheers,
> >
> > Rolf
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Thu Sep  7 22:13:40 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Thu, 7 Sep 2017 15:13:40 -0500
Subject: [R-sig-ME] nAGQ = 0
In-Reply-To: <CAE9_Wg4h=85yJTgPoeG8ntOxwwCtudb-7-=QTjmqW_vHX1Uwnw@mail.gmail.com>
References: <a478990b-5a50-1c8a-2092-999607829f8b@auckland.ac.nz>
 <BN3PR16MB0689342BD88D5F0E3A9B3970AF900@BN3PR16MB0689.namprd16.prod.outlook.com>
 <1cf9596c-2102-0dd6-f54b-9947e97ac3fa@auckland.ac.nz>
 <CAFW8Byrb_nsFWWRWFFwko25BzZn29wYiEtpom4QNnRkCDbUzWw@mail.gmail.com>
 <53e45034-22c0-fbf7-ce03-a486d52c37ea@auckland.ac.nz>
 <CAFW8ByoGrt=P0FKQ58=mv1Ye-X0RAZ006YxfnrDHNZZjJ+kNWw@mail.gmail.com>
 <81925387-e46c-67d4-50ed-90852c044ca4@auckland.ac.nz>
 <59B1A0FF.1020905@mpi.nl>
 <CAE9_Wg4h=85yJTgPoeG8ntOxwwCtudb-7-=QTjmqW_vHX1Uwnw@mail.gmail.com>
Message-ID: <CAE9_Wg5FPVra3mSpjrtutyuWMjPaoCK7DM5KQHXWB_Skq8HQBg@mail.gmail.com>

...BTW, the syntax in question, for those not interested enough to locate
it in the previously attached R script, is:
 ~ (0+Trt)/x


On Thu, Sep 7, 2017 at 3:00 PM, Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> To further clear things up for other readers, this formula syntax is a
> nice and very useful (if little known) trick for estimating separate
> intercepts and x slopes for each level of Trt. It creates a design matrix
> like:
>
> [1 0 x_1 0]
> [1 0 x_2 0]
> [0 1 0 x_3]
> [0 1 0 x_4]
>
> where the first two rows belong to Trt=1, the second two rows belong to
> Trt=2; columns 1 and 2 are the Trt1 and Trt2 intercepts, respectively; and
> columns 3 and 4 contain only the x values for Trt1 and Trt2, respectively,
> so their associated coefficients give the group-specific slopes for each
> level of Trt.
>
> Jake
>
> On Thu, Sep 7, 2017 at 2:41 PM, Phillip Alday <phillip.alday at mpi.nl>
> wrote:
>
>> As mentioned previously, the formula syntax for this one is a bit
>> confusing. The left-hand side was easy enough to figure out from the
>> brms docs, but the division operator on the RHS was a trick I had never
>> used before -- it took me looking at the output from the
>> glmer(...,nAGQ=0) model to get that it's equivalent to
>>
>> ~ 0 + Trt + Trt:x + (x | Rep)
>>
>> Phillip
>>
>>
>>
>> On 09/07/2017 06:12 AM, Rolf Turner wrote:
>> >
>> > On 07/09/17 10:57, Poe, John wrote:
>> >
>> >> This is where my being a political scientist on a listserv full of
>> >> definitely not political scientists is going to make me look dumb.
>> >> I've never actually seen a model specification like that before for a
>> >> multilevel model. Is the outcome supposed to be the proportion dead
>> >> out of the total population for each row? I'm missing something about
>> >> this that is probably very obvious.
>> >>
>> >> After fiddling with it I was able to get it to converge for one chain
>> >> but I wouldn't trust it at all right now.
>> >
>> > Well, I hadn't seen a model specification quite like that either.  It's
>> > brm() syntax, which is a bit different from glm() or glmer() syntax.
>> >
>> > The model being fitted is a binomial model, with success probability p
>> > modelled by
>> >
>> >     g(p) = beta_0 + beta_1 * x + Z_0 + Z_1 * x
>> >
>> > where the Z_k are the random effects, and where g() is the link
>> > function, e.g. cloglog(). (I *think* I've got that right.)
>> >
>> > Of course beta_0 and beta_1 depend on treatment group and Z_0 and Z_1
>> > depend on "Rep", which is nested within treatment group.
>> >
>> > Note that we are talking *generalized* linear mixed models here; the
>> > responses are binomial success counts.  "Success" = Dead, since one is
>> > trying to kill the bugs.
>> >
>> > For what it's worth the glmer() syntax is
>> >
>> >    glmer(cbind(Dead,Alive) ~ (0 + Trt)/x + (x | Rep),
>> >          family=binomial(link="cloglog"),data=X)
>> >
>> > I got the brm() syntax from the vignette; as I said, I'd never seen it
>> > before.
>> >
>> > cheers,
>> >
>> > Rolf
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Fri Sep  8 02:36:16 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Fri, 8 Sep 2017 00:36:16 +0000
Subject: [R-sig-ME] meaning of lmer formula
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366C04A6@FHSDB4H16-2.csu.mcmaster.ca>
References: <22958.50878.753094.461355@losangelesyouthorchestra.org>
 <027313e6-7566-5123-7f25-29d363d897f5@gmail.com>
 <22958.54835.530288.669184@losangelesyouthorchestra.org>
 <22960.21262.919792.560339@losangelesyouthorchestra.org>
 <dc928820-0185-5a64-4547-07562b83864c@gmail.com>
 <22960.26074.206053.16571@losangelesyouthorchestra.org>
 <8d8974c5-8ed5-efa4-07b7-4299f8faa7dc@gmail.com>
 <23524_1504759401_v874hKue006673_22960.52827.310170.196801@losangelesyouthorchestra.org>
 <ACD1644AA6C67E4FBD0C350625508EC8366C04A6@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <22961.58880.733810.897984@losangelesyouthorchestra.org>

Fox, John writes:
 > Have you read the vignette on lmer() in the package? 
I guess that's
 https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
and I guess you're referring to section 2.2 and specifically  
table 2 on p.6.
Yes, I had already seen those, but they don't answer my questions.
They provide examples but not a complete specification of the
language.

 > It strikes me that your questions can also be answered by just
 > trying the various formulas that you propose and examining the
 > output.

This would be true if it were obvious how to translate the outputs
to the meanings of formulae that should have those outputs.
I'm working on making that more obvious (to me), but have a long
way to go.
One thing I have found useful is checking to see whether two 
formulae mean the SAME thing by seeing whether they give the SAME
result - I do know how to recognize same results.  I realize that
it's possible to get the same result from two different meanings,
but I view the probability of that as negligible.
I've also tested my understanding by making small changes that
I expect to change the output in very specific ways.


From dsidhu at ucalgary.ca  Wed Sep  6 01:45:27 2017
From: dsidhu at ucalgary.ca (David Sidhu)
Date: Tue, 5 Sep 2017 23:45:27 +0000
Subject: [R-sig-ME] choice of reference category only changes coefficient
 with uncorrelated random intercept and slope
Message-ID: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>

Hi Everyone

I have noticed something strange...

I am running a glmer with a single dichotomous predictor (coded 1/0). The model also includes a random subject intercept, as well as a random item intercept and slope.

Changing which level of the predictor serves as the reference category doesn?t change the absolute value of the coefficient, EXCEPT when the random intercept and slope are uncorrelated.

This happens whether I keep the predictor as a numeric variable, or change the predictor into a factor and use the following code:

t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data, family = "binomial?)

Is this a genuine result? If so, can anyone explain why the uncorrelated random intercept and slope allow it to emerge? If not, how can I run a model that has an uncorrelated random intercept and slope that would prevent the choice of reference category from affecting the result?

Thank you very much!

Dave

---
David M. Sidhu, MSc<http://davidmsidhu.com/>
PhD Candidate
Department of Psychology
University of Calgary







	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep  8 20:04:12 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 8 Sep 2017 14:04:12 -0400
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
Message-ID: <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>

Not sure, but ...

I think this is real. (If I were going to pursue it further I would
probably try running some simulations.)  I think the asymmetry you're
seeing is most likely related to the nonlinearity inherent in a GLMM;
if that's true, then the effect should go away if you were using a LMM
instead of a GLMM ...


On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu <dsidhu at ucalgary.ca> wrote:
>
> Hi Everyone
>
> I have noticed something strange...
>
> I am running a glmer with a single dichotomous predictor (coded 1/0). The model also includes a random subject intercept, as well as a random item intercept and slope.
>
> Changing which level of the predictor serves as the reference category doesn?t change the absolute value of the coefficient, EXCEPT when the random intercept and slope are uncorrelated.
>
> This happens whether I keep the predictor as a numeric variable, or change the predictor into a factor and use the following code:
>
> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data, family = "binomial?)
>
> Is this a genuine result? If so, can anyone explain why the uncorrelated random intercept and slope allow it to emerge? If not, how can I run a model that has an uncorrelated random intercept and slope that would prevent the choice of reference category from affecting the result?
>
> Thank you very much!
>
> Dave
>
> ---
> David M. Sidhu, MSc<http://davidmsidhu.com/>
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john.morrongiello at unimelb.edu.au  Mon Sep 11 05:26:22 2017
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Mon, 11 Sep 2017 03:26:22 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope
Message-ID: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>

Dear list
I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4368045/> (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated.

(Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946).

library(rptR)
library(MCMCglmm)

#######some data#######
behaviour <-
structure(list(fid = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L,
3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L,
8L, 9L, 9L, 9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L,
13L, 13L, 13L, 14L, 14L, 14L, 15L, 15L, 15L, 16L, 16L, 16L, 17L,
17L, 17L, 18L, 18L, 18L), .Label = c("2", "3", "5", "6", "7",
"8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19",
"20", "21"), class = "factor"), week = c(1L, 2L, 3L, 1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
3L), trait1 = c(0.225903614, 0.368017058, 0.805194805, 0.691799861,
0.654561365, 0.815674805, 0.477368175, 0.222362125, 0.09480315,
0.268691229, 0.500809061, 0.262361128, 0.365236524, 0.090701498,
0.344081069, 0.851842461, 0.477558348, 0.324364209, 0.425583266,
0.085414302, 0.311696658, 0.083493708, 0.164316797, 0.104364194,
0.156442474, 0.145193036, 0.237337192, 0.445346658, 0.377818182,
0.256871307, 0.287724075, 0.334800469, 0.324204293, 0.285696594,
0.199901004, 0.227835821, 0.709611452, 0.202676634, 0.084690774,
0.288277218, 0.282670647, 0.408824789, 0.241985203, 0.159210526,
0.0565915, 0.105827529, 0.039312489, 0.049929224, 0.292300806,
0.098316799, 0.15465606, 0.175269499, 0.271719515, 0.230084728
)), .Names = c("fid", "week", "trait1"), row.names = c(NA, -54L
), class = "data.frame")

############# Repeatability from rptR package #####

###intercept only model
rep1 <- rpt(trait1 ~ (1 | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)
###common week slope
rep2 <- rpt(trait1 ~ week+ (1 | fid), grname = "fid", data = behaviour, datatype = "Gaussian", nboot = 1000, npermut = 0)
###individual differences in week slope
rep3 <- rpt(trait1 ~ week+ (week | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)

##raw repeatability: ignore temporal change
print(rep1)
##conditional repeatability 1: shared change over time
print(rep2)
##conditional repeatability 2: change over time that differs among individuals (this is what I want to get from the equivalent MCMCglmm model)
print(rep3)

########### mcmcGLMM code ####
prior1.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), R = list(V = 1, nu = 0.002))

###intercept only model
MCMC_raw<-MCMCglmm(trait1 ~1,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond1<-MCMCglmm(trait1 ~week,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond2<-MCMCglmm(trait1 ~week,
             random=~us(week):fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

####repeatability formula
R= Vg/(Vg + Vr), where R= repeatability, Vg is group level variance and Vr is data level (residual) variance

###MCMCglmm derived raw repeatability
rep4<-(MCMC_raw$VCV[,"fid"]/ (MCMC_raw$VCV[,"fid"]+MCMC_raw$VCV[,"units"]))
posterior.mode(rep4)
HPDinterval(rep4)

###MCMCglmm derived conditional repeatability 1: shared change over time
rep5<-(MCMC_cond$VCV[,"fid"]/ (MCMC_ cond $VCV[,"fid"]+MCMC_ cond $VCV[,"units"]))
posterior.mode(rep5)
HPDinterval(rep5)

####How would I estimate conditional repeatability 2: change over time that differs among individuals using MCMC_cond2?

Cheers
john
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: morrongiellolab.com<http://morrongiellolab.com/>


	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Mon Sep 11 08:41:03 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Mon, 11 Sep 2017 06:41:03 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random
	slope
In-Reply-To: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>
References: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>
Message-ID: <1505112063332.46647@nmbu.no>

Hi John, 

Repeatability for models with a random slope are a bit tricky to understand since it is calculated with respect to a particular value of a covariate. In general, it can be calculated as:

R = Vg / (Vg + Vr) 
   =  V_intercept + V_slope * X_i^2 + 2 * Cov( V_intercept + V_slope ) * X_i / (numerator + Vr)

where V_intercept = variance of intercepts, V_slope = variance of slopes, X_i is the covariate at a particular value i, Cov represents the covariance, and Vr = the residual variance. I'm not sure it can be calculated with rptR. 

For more details, see Martin et al. 2011. http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00084.x/abstract (particularly pages 371 - 372)

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Morrongiello <john.morrongiello at unimelb.edu.au>
Sent: Monday, September 11, 2017 5:26 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope

Dear list
I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4368045/> (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated.

(Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946).

library(rptR)
library(MCMCglmm)

#######some data#######
behaviour <-
structure(list(fid = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L,
3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L,
8L, 9L, 9L, 9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L,
13L, 13L, 13L, 14L, 14L, 14L, 15L, 15L, 15L, 16L, 16L, 16L, 17L,
17L, 17L, 18L, 18L, 18L), .Label = c("2", "3", "5", "6", "7",
"8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19",
"20", "21"), class = "factor"), week = c(1L, 2L, 3L, 1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
3L), trait1 = c(0.225903614, 0.368017058, 0.805194805, 0.691799861,
0.654561365, 0.815674805, 0.477368175, 0.222362125, 0.09480315,
0.268691229, 0.500809061, 0.262361128, 0.365236524, 0.090701498,
0.344081069, 0.851842461, 0.477558348, 0.324364209, 0.425583266,
0.085414302, 0.311696658, 0.083493708, 0.164316797, 0.104364194,
0.156442474, 0.145193036, 0.237337192, 0.445346658, 0.377818182,
0.256871307, 0.287724075, 0.334800469, 0.324204293, 0.285696594,
0.199901004, 0.227835821, 0.709611452, 0.202676634, 0.084690774,
0.288277218, 0.282670647, 0.408824789, 0.241985203, 0.159210526,
0.0565915, 0.105827529, 0.039312489, 0.049929224, 0.292300806,
0.098316799, 0.15465606, 0.175269499, 0.271719515, 0.230084728
)), .Names = c("fid", "week", "trait1"), row.names = c(NA, -54L
), class = "data.frame")

############# Repeatability from rptR package #####

###intercept only model
rep1 <- rpt(trait1 ~ (1 | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)
###common week slope
rep2 <- rpt(trait1 ~ week+ (1 | fid), grname = "fid", data = behaviour, datatype = "Gaussian", nboot = 1000, npermut = 0)
###individual differences in week slope
rep3 <- rpt(trait1 ~ week+ (week | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)

##raw repeatability: ignore temporal change
print(rep1)
##conditional repeatability 1: shared change over time
print(rep2)
##conditional repeatability 2: change over time that differs among individuals (this is what I want to get from the equivalent MCMCglmm model)
print(rep3)

########### mcmcGLMM code ####
prior1.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), R = list(V = 1, nu = 0.002))

###intercept only model
MCMC_raw<-MCMCglmm(trait1 ~1,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond1<-MCMCglmm(trait1 ~week,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond2<-MCMCglmm(trait1 ~week,
             random=~us(week):fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

####repeatability formula
R= Vg/(Vg + Vr), where R= repeatability, Vg is group level variance and Vr is data level (residual) variance

###MCMCglmm derived raw repeatability
rep4<-(MCMC_raw$VCV[,"fid"]/ (MCMC_raw$VCV[,"fid"]+MCMC_raw$VCV[,"units"]))
posterior.mode(rep4)
HPDinterval(rep4)

###MCMCglmm derived conditional repeatability 1: shared change over time
rep5<-(MCMC_cond$VCV[,"fid"]/ (MCMC_ cond $VCV[,"fid"]+MCMC_ cond $VCV[,"units"]))
posterior.mode(rep5)
HPDinterval(rep5)

####How would I estimate conditional repeatability 2: change over time that differs among individuals using MCMC_cond2?

Cheers
john
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: morrongiellolab.com<http://morrongiellolab.com/>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From conor.goold at nmbu.no  Mon Sep 11 08:48:49 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Mon, 11 Sep 2017 06:48:49 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random
	slope
In-Reply-To: <1505112063332.46647@nmbu.no>
References: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>,
 <1505112063332.46647@nmbu.no>
Message-ID: <1505112529478.30438@nmbu.no>

Hi again John, 

In the repeatability formula I worte, it should be Cov( V_intercept, V_slope ) with an addition sign!

Conor
________________________________________
From: Conor Michael Goold
Sent: Monday, September 11, 2017 8:41 AM
To: John Morrongiello; r-sig-mixed-models at r-project.org
Subject: Re: conditional repeatability from MCMCglmm with random slope

Hi John,

Repeatability for models with a random slope are a bit tricky to understand since it is calculated with respect to a particular value of a covariate. In general, it can be calculated as:

R = Vg / (Vg + Vr)
   =  V_intercept + V_slope * X_i^2 + 2 * Cov( V_intercept + V_slope ) * X_i / (numerator + Vr)

where V_intercept = variance of intercepts, V_slope = variance of slopes, X_i is the covariate at a particular value i, Cov represents the covariance, and Vr = the residual variance. I'm not sure it can be calculated with rptR.

For more details, see Martin et al. 2011. http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00084.x/abstract (particularly pages 371 - 372)

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Morrongiello <john.morrongiello at unimelb.edu.au>
Sent: Monday, September 11, 2017 5:26 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope

Dear list
I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4368045/> (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated.

(Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946).

library(rptR)
library(MCMCglmm)

#######some data#######
behaviour <-
structure(list(fid = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L,
3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L,
8L, 9L, 9L, 9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L,
13L, 13L, 13L, 14L, 14L, 14L, 15L, 15L, 15L, 16L, 16L, 16L, 17L,
17L, 17L, 18L, 18L, 18L), .Label = c("2", "3", "5", "6", "7",
"8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19",
"20", "21"), class = "factor"), week = c(1L, 2L, 3L, 1L, 2L,
3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
3L), trait1 = c(0.225903614, 0.368017058, 0.805194805, 0.691799861,
0.654561365, 0.815674805, 0.477368175, 0.222362125, 0.09480315,
0.268691229, 0.500809061, 0.262361128, 0.365236524, 0.090701498,
0.344081069, 0.851842461, 0.477558348, 0.324364209, 0.425583266,
0.085414302, 0.311696658, 0.083493708, 0.164316797, 0.104364194,
0.156442474, 0.145193036, 0.237337192, 0.445346658, 0.377818182,
0.256871307, 0.287724075, 0.334800469, 0.324204293, 0.285696594,
0.199901004, 0.227835821, 0.709611452, 0.202676634, 0.084690774,
0.288277218, 0.282670647, 0.408824789, 0.241985203, 0.159210526,
0.0565915, 0.105827529, 0.039312489, 0.049929224, 0.292300806,
0.098316799, 0.15465606, 0.175269499, 0.271719515, 0.230084728
)), .Names = c("fid", "week", "trait1"), row.names = c(NA, -54L
), class = "data.frame")

############# Repeatability from rptR package #####

###intercept only model
rep1 <- rpt(trait1 ~ (1 | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)
###common week slope
rep2 <- rpt(trait1 ~ week+ (1 | fid), grname = "fid", data = behaviour, datatype = "Gaussian", nboot = 1000, npermut = 0)
###individual differences in week slope
rep3 <- rpt(trait1 ~ week+ (week | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)

##raw repeatability: ignore temporal change
print(rep1)
##conditional repeatability 1: shared change over time
print(rep2)
##conditional repeatability 2: change over time that differs among individuals (this is what I want to get from the equivalent MCMCglmm model)
print(rep3)

########### mcmcGLMM code ####
prior1.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), R = list(V = 1, nu = 0.002))

###intercept only model
MCMC_raw<-MCMCglmm(trait1 ~1,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond1<-MCMCglmm(trait1 ~week,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond2<-MCMCglmm(trait1 ~week,
             random=~us(week):fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

####repeatability formula
R= Vg/(Vg + Vr), where R= repeatability, Vg is group level variance and Vr is data level (residual) variance

###MCMCglmm derived raw repeatability
rep4<-(MCMC_raw$VCV[,"fid"]/ (MCMC_raw$VCV[,"fid"]+MCMC_raw$VCV[,"units"]))
posterior.mode(rep4)
HPDinterval(rep4)

###MCMCglmm derived conditional repeatability 1: shared change over time
rep5<-(MCMC_cond$VCV[,"fid"]/ (MCMC_ cond $VCV[,"fid"]+MCMC_ cond $VCV[,"units"]))
posterior.mode(rep5)
HPDinterval(rep5)

####How would I estimate conditional repeatability 2: change over time that differs among individuals using MCMC_cond2?

Cheers
john
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: morrongiellolab.com<http://morrongiellolab.com/>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Mon Sep 11 10:35:30 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 Sep 2017 09:35:30 +0100
Subject: [R-sig-ME] Course: Introduction to regression models with spatial
 and temporal correlation using R-INLA
Message-ID: <2c459eef-2f8b-31dc-e7b6-3a66df6c81a9@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Regression Models with Spatial and Temporal 
Correlation using R-INLA
Where:? Southampton, UK
When:?? 23-27 October 2017

Course website: http://highstat.com/index.php/courses
Course flyer: 
http://highstat.com/Courses/Flyers/2017/Flyer2017_10Southampton_SpatTemp.pdf


Kind regards,

Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From john.morrongiello at unimelb.edu.au  Mon Sep 11 11:06:42 2017
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Mon, 11 Sep 2017 09:06:42 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random
	slope
In-Reply-To: <1505112529478.30438@nmbu.no>
References: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>,
 <1505112063332.46647@nmbu.no> <1505112529478.30438@nmbu.no>
Message-ID: <SYXPR01MB160026272E20A046C5801CDDC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>

Hi Conor
Thanks for getting back to me. I'll have a close read of the Martin etal paper (I'm familiar with the Goldstein etal 2002 paper they cite in this section). In regards to rptR being able to calculate a conditional repeatability involving random slopes, they provide an example of this towards the end of their vignette (https://cran.r-project.org/web/packages/rptR/vignettes/rptR.html). The trick (which is a little beyond my coding ability) is to properly average repeatability estimates across the range of the covariate as indicated in your formula below from MCMCglmm. I've had a look at the source code for rpt and I can't see where this function is estimating each covariate specific random effect variance to then calculate the mean random effect variance.

Cheers
John
 --
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au
W: morrongiellolab.com

-----Original Message-----
From: Conor Michael Goold [mailto:conor.goold at nmbu.no] 
Sent: Monday, 11 September 2017 4:49 PM
To: John Morrongiello <john.morrongiello at unimelb.edu.au>; r-sig-mixed-models at r-project.org
Subject: Re: conditional repeatability from MCMCglmm with random slope

Hi again John, 

In the repeatability formula I worte, it should be Cov( V_intercept, V_slope ) with an addition sign!

Conor
________________________________________
From: Conor Michael Goold
Sent: Monday, September 11, 2017 8:41 AM
To: John Morrongiello; r-sig-mixed-models at r-project.org
Subject: Re: conditional repeatability from MCMCglmm with random slope

Hi John,

Repeatability for models with a random slope are a bit tricky to understand since it is calculated with respect to a particular value of a covariate. In general, it can be calculated as:

R = Vg / (Vg + Vr)
   =  V_intercept + V_slope * X_i^2 + 2 * Cov( V_intercept + V_slope ) * X_i / (numerator + Vr)

where V_intercept = variance of intercepts, V_slope = variance of slopes, X_i is the covariate at a particular value i, Cov represents the covariance, and Vr = the residual variance. I'm not sure it can be calculated with rptR.

For more details, see Martin et al. 2011. http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00084.x/abstract (particularly pages 371 - 372)

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. http://www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Morrongiello <john.morrongiello at unimelb.edu.au>
Sent: Monday, September 11, 2017 5:26 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope

Dear list
I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4368045/> (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated.

(Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946).

library(rptR)
library(MCMCglmm)

#######some data#######
behaviour <-
structure(list(fid = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L, 9L, 9L, 9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L, 13L, 13L, 13L, 14L, 14L, 14L, 15L, 15L, 15L, 16L, 16L, 16L, 17L, 17L, 17L, 18L, 18L, 18L), .Label = c("2", "3", "5", "6", "7", "8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19", "20", "21"), class = "factor"), week = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), trait1 = c(0.225903614, 0.368017058, 0.805194805, 0.691799861, 0.654561365, 0.815674805, 0.477368175, 0.222362125, 0.09480315, 0.268691229, 0.500809061, 0.262361128, 0.365236524, 0.090701498, 0.344081069, 0.851842461, 0.477558348, 0.324364209, 0.425583266, 0.085414302, 0.311696658, 0.083493708, 0.164316797, 0.104364194, 0.156442474, 0.145193036, 0.237337192, 0.445346658, 0.377818182, 0.256871307, 0.287724075, 0.334800469, 0.324204293, 0.285696594, 0.199901004, 0.227835821, 0.709611452, 0.202676634, 0.084690774, 0.288277218, 0.282670647, 0.408824789, 0.241985203, 0.159210526, 0.0565915, 0.105827529, 0.039312489, 0.049929224, 0.292300806, 0.098316799, 0.15465606, 0.175269499, 0.271719515, 0.230084728 )), .Names = c("fid", "week", "trait1"), row.names = c(NA, -54L ), class = "data.frame")

############# Repeatability from rptR package #####

###intercept only model
rep1 <- rpt(trait1 ~ (1 | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0) ###common week slope
rep2 <- rpt(trait1 ~ week+ (1 | fid), grname = "fid", data = behaviour, datatype = "Gaussian", nboot = 1000, npermut = 0) ###individual differences in week slope
rep3 <- rpt(trait1 ~ week+ (week | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)

##raw repeatability: ignore temporal change
print(rep1)
##conditional repeatability 1: shared change over time
print(rep2)
##conditional repeatability 2: change over time that differs among individuals (this is what I want to get from the equivalent MCMCglmm model)
print(rep3)

########### mcmcGLMM code ####
prior1.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), R = list(V = 1, nu = 0.002))

###intercept only model
MCMC_raw<-MCMCglmm(trait1 ~1,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond1<-MCMCglmm(trait1 ~week,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond2<-MCMCglmm(trait1 ~week,
             random=~us(week):fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

####repeatability formula
R= Vg/(Vg + Vr), where R= repeatability, Vg is group level variance and Vr is data level (residual) variance

###MCMCglmm derived raw repeatability
rep4<-(MCMC_raw$VCV[,"fid"]/ (MCMC_raw$VCV[,"fid"]+MCMC_raw$VCV[,"units"]))
posterior.mode(rep4)
HPDinterval(rep4)

###MCMCglmm derived conditional repeatability 1: shared change over time rep5<-(MCMC_cond$VCV[,"fid"]/ (MCMC_ cond $VCV[,"fid"]+MCMC_ cond $VCV[,"units"]))
posterior.mode(rep5)
HPDinterval(rep5)

####How would I estimate conditional repeatability 2: change over time that differs among individuals using MCMC_cond2?

Cheers
john
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: http://morrongiellolab.com<http://morrongiellolab.com/>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From conor.goold at nmbu.no  Mon Sep 11 11:52:56 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Mon, 11 Sep 2017 09:52:56 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random
	slope
In-Reply-To: <SYXPR01MB160026272E20A046C5801CDDC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>
References: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>,
 <1505112063332.46647@nmbu.no> <1505112529478.30438@nmbu.no>,
 <SYXPR01MB160026272E20A046C5801CDDC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>
Message-ID: <1505123576079.73045@nmbu.no>

Ah, I see. It's my understanding that you can just take the range of values for the covariate, and apply the formula below. I'm not sure what you mean by the 'covariate specific random effect variance'...the variance of the random effects (intercept and slope variance terms) do not change with the covariate, but the value of the ICC will change depending on which value of the covariate it is estimated. If X is some covariate, I'd just do something like:

#########
library(rethinking)   # for the HPDI interval function

# get the unique values of your covariate X
covariate_values <- unique( X )

# assuming V_intercept, V_slope, Cov_intercept_slope and Vr are vectors of posterior probability distributions from the fitted model
ICC_vector <- sapply( covariate_values, 
                                         function(z) {  
                                                numerator <- V_intercept + V_slope * z^2 + 2 * Cov_intercept_slope * z 
                                                denominator <- numerator + Vr
                                                numerator / denominator
                                             }
                                      )

# ICC_vector is now a matrix with dimensions N (the number of posterior draws) x P (the length of covariate_values)

# create data frame to hold ICC summary statistics across the values of covariate_values
ICC_df <- data.frame(covariate_values = covariate_values, 
                                       ICC_mu = apply(ICC_vector , 2 , mean ) , 
                                       hdi_low = apply(ICC_vector , 2 , function(z) HPDI(z,0.95) )[1,] ,
                                       hdi_high = apply(ICC_vector , 2 , function(z) HPDI(z,0.95) )[2,] 
                                       )

##############    

>From there, you can take the average of the ICC values in the ICC_df data frame. 

Hope this makes sense,
Conor

________________________________________
From: John Morrongiello <john.morrongiello at unimelb.edu.au>
Sent: Monday, September 11, 2017 11:06 AM
To: Conor Michael Goold; r-sig-mixed-models at r-project.org
Subject: RE: conditional repeatability from MCMCglmm with random slope

Hi Conor
Thanks for getting back to me. I'll have a close read of the Martin etal paper (I'm familiar with the Goldstein etal 2002 paper they cite in this section). In regards to rptR being able to calculate a conditional repeatability involving random slopes, they provide an example of this towards the end of their vignette (https://cran.r-project.org/web/packages/rptR/vignettes/rptR.html). The trick (which is a little beyond my coding ability) is to properly average repeatability estimates across the range of the covariate as indicated in your formula below from MCMCglmm. I've had a look at the source code for rpt and I can't see where this function is estimating each covariate specific random effect variance to then calculate the mean random effect variance.

Cheers
John
 --
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au
W: morrongiellolab.com

-----Original Message-----
From: Conor Michael Goold [mailto:conor.goold at nmbu.no]
Sent: Monday, 11 September 2017 4:49 PM
To: John Morrongiello <john.morrongiello at unimelb.edu.au>; r-sig-mixed-models at r-project.org
Subject: Re: conditional repeatability from MCMCglmm with random slope

Hi again John,

In the repeatability formula I worte, it should be Cov( V_intercept, V_slope ) with an addition sign!

Conor
________________________________________
From: Conor Michael Goold
Sent: Monday, September 11, 2017 8:41 AM
To: John Morrongiello; r-sig-mixed-models at r-project.org
Subject: Re: conditional repeatability from MCMCglmm with random slope

Hi John,

Repeatability for models with a random slope are a bit tricky to understand since it is calculated with respect to a particular value of a covariate. In general, it can be calculated as:

R = Vg / (Vg + Vr)
   =  V_intercept + V_slope * X_i^2 + 2 * Cov( V_intercept + V_slope ) * X_i / (numerator + Vr)

where V_intercept = variance of intercepts, V_slope = variance of slopes, X_i is the covariate at a particular value i, Cov represents the covariance, and Vr = the residual variance. I'm not sure it can be calculated with rptR.

For more details, see Martin et al. 2011. http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00084.x/abstract (particularly pages 371 - 372)

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. http://www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Morrongiello <john.morrongiello at unimelb.edu.au>
Sent: Monday, September 11, 2017 5:26 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope

Dear list
I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper<https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4368045/> (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated.

(Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946).

library(rptR)
library(MCMCglmm)

#######some data#######
behaviour <-
structure(list(fid = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L, 9L, 9L, 9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L, 13L, 13L, 13L, 14L, 14L, 14L, 15L, 15L, 15L, 16L, 16L, 16L, 17L, 17L, 17L, 18L, 18L, 18L), .Label = c("2", "3", "5", "6", "7", "8", "9", "10", "11", "12", "13", "15", "16", "17", "18", "19", "20", "21"), class = "factor"), week = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), trait1 = c(0.225903614, 0.368017058, 0.805194805, 0.691799861, 0.654561365, 0.815674805, 0.477368175, 0.222362125, 0.09480315, 0.268691229, 0.500809061, 0.262361128, 0.365236524, 0.090701498, 0.344081069, 0.851842461, 0.477558348, 0.324364209, 0.425583266, 0.085414302, 0.311696658, 0.083493708, 0.164316797, 0.104364194, 0.156442474, 0.145193036, 0.237337192, 0.445346658, 0.377818182, 0.256871307, 0.287724075, 0.334800469, 0.324204293, 0.285696594, 0.199901004, 0.227835821, 0.709611452, 0.202676634, 0.084690774, 0.288277218, 0.282670647, 0.408824789, 0.241985203, 0.159210526, 0.0565915, 0.105827529, 0.039312489, 0.049929224, 0.292300806, 0.098316799, 0.15465606, 0.175269499, 0.271719515, 0.230084728 )), .Names = c("fid", "week", "trait1"), row.names = c(NA, -54L ), class = "data.frame")

############# Repeatability from rptR package #####

###intercept only model
rep1 <- rpt(trait1 ~ (1 | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0) ###common week slope
rep2 <- rpt(trait1 ~ week+ (1 | fid), grname = "fid", data = behaviour, datatype = "Gaussian", nboot = 1000, npermut = 0) ###individual differences in week slope
rep3 <- rpt(trait1 ~ week+ (week | fid), grname = "fid", data = behaviour,  datatype = "Gaussian", nboot = 1000, npermut = 0)

##raw repeatability: ignore temporal change
print(rep1)
##conditional repeatability 1: shared change over time
print(rep2)
##conditional repeatability 2: change over time that differs among individuals (this is what I want to get from the equivalent MCMCglmm model)
print(rep3)

########### mcmcGLMM code ####
prior1.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), R = list(V = 1, nu = 0.002))

###intercept only model
MCMC_raw<-MCMCglmm(trait1 ~1,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond1<-MCMCglmm(trait1 ~week,
             random=~fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

###common week slope
MCMC_cond2<-MCMCglmm(trait1 ~week,
             random=~us(week):fid,family=("gaussian"), prior=prior1.1,
             nitt=110000,thin=25,burnin=10000, data=behaviour, verbose=TRUE)

####repeatability formula
R= Vg/(Vg + Vr), where R= repeatability, Vg is group level variance and Vr is data level (residual) variance

###MCMCglmm derived raw repeatability
rep4<-(MCMC_raw$VCV[,"fid"]/ (MCMC_raw$VCV[,"fid"]+MCMC_raw$VCV[,"units"]))
posterior.mode(rep4)
HPDinterval(rep4)

###MCMCglmm derived conditional repeatability 1: shared change over time rep5<-(MCMC_cond$VCV[,"fid"]/ (MCMC_ cond $VCV[,"fid"]+MCMC_ cond $VCV[,"units"]))
posterior.mode(rep5)
HPDinterval(rep5)

####How would I estimate conditional repeatability 2: change over time that differs among individuals using MCMC_cond2?

Cheers
john
--
Dr. John R. Morrongiello
School of BioSciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: +61 403 338 554
E: john.morrongiello at unimelb.edu.au<mailto:%20jmorrongiell at unimelb.edu.au>
W: http://morrongiellolab.com<http://morrongiellolab.com/>


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




From john.morrongiello at unimelb.edu.au  Mon Sep 11 12:39:06 2017
From: john.morrongiello at unimelb.edu.au (John Morrongiello)
Date: Mon, 11 Sep 2017 10:39:06 +0000
Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random
	slope
In-Reply-To: <1505123576079.73045@nmbu.no>
References: <SYXPR01MB160090BA0201BF43DB5F013FC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>,
 <1505112063332.46647@nmbu.no> <1505112529478.30438@nmbu.no>,
 <SYXPR01MB160026272E20A046C5801CDDC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>,
 <1505123576079.73045@nmbu.no>
Message-ID: <SYXPR01MB16006723F178ED84EFF06EBAC4680@SYXPR01MB1600.ausprd01.prod.outlook.com>

Looks great, thanks Conor!

Dr John Morrongiello
Lecturer in Marine and Freshwater Biology

School of Biosciences
University of Melbourne
Victoria 3010, Australia
T: +61 3 8344 8929
M: 0403 338 554
E: john.morrongiello at unimelb.edu.au
W: www.morrongiellolab.com<http://%20www.morrongiellolab.com>



From: Conor Michael Goold
Sent: Monday, 11 September, 19:53
Subject: Re: conditional repeatability from MCMCglmm with random slope
To: John Morrongiello, r-sig-mixed-models at r-project.org


Ah, I see. It's my understanding that you can just take the range of values for the covariate, and apply the formula below. I'm not sure what you mean by the 'covariate specific random effect variance'...the variance of the random effects (intercept and slope variance terms) do not change with the covariate, but the value of the ICC will change depending on which value of the covariate it is estimated. If X is some covariate, I'd just do something like: ######### library(rethinking) # for the HPDI interval function # get the unique values of your covariate X covariate_values Sent: Monday, September 11, 2017 11:06 AM To: Conor Michael Goold; r-sig-mixed-models at r-project.org Subject: RE: conditional repeatability from MCMCglmm with random slope Hi Conor Thanks for getting back to me. I'll have a close read of the Martin etal paper (I'm familiar with the Goldstein etal 2002 paper they cite in this section). In regards to rptR being able to calculate a conditional repeatability involving random slopes, they provide an example of this towards the end of their vignette (https://cran.r-project.org/web/packages/rptR/vignettes/rptR.html). The trick (which is a little beyond my coding ability) is to properly average repeatability estimates across the range of the covariate as indicated in your formula below from MCMCglmm. I've had a look at the source code for rpt and I can't see where this function is estimating each covariate specific random effect variance to then calculate the mean random effect variance. Cheers John -- Dr. John R. Morrongiello School of BioSciences University of Melbourne Victoria 3010, Australia T: +61 3 8344 8929 M: +61 403 338 554 E: john.morrongiello at unimelb.edu.au W: http://morrongiellolab.com -----Original Message----- From: Conor Michael Goold [mailto:conor.goold at nmbu.no] Sent: Monday, 11 September 2017 4:49 PM To: John Morrongiello ; r-sig-mixed-models at r-project.org Subject: Re: conditional repeatability from MCMCglmm with random slope Hi again John, In the repeatability formula I worte, it should be Cov( V_intercept, V_slope ) with an addition sign! Conor ________________________________________ From: Conor Michael Goold Sent: Monday, September 11, 2017 8:41 AM To: John Morrongiello; r-sig-mixed-models at r-project.org Subject: Re: conditional repeatability from MCMCglmm with random slope Hi John, Repeatability for models with a random slope are a bit tricky to understand since it is calculated with respect to a particular value of a covariate. In general, it can be calculated as: R = Vg / (Vg + Vr) = V_intercept + V_slope * X_i^2 + 2 * Cov( V_intercept + V_slope ) * X_i / (numerator + Vr) where V_intercept = variance of intercepts, V_slope = variance of slopes, X_i is the covariate at a particular value i, Cov represents the covariance, and Vr = the residual variance. I'm not sure it can be calculated with rptR. For more details, see Martin et al. 2011. http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00084.x/abstract (particularly pages 371 - 372) Best regards Conor Goold PhD Student Phone: +47 67 23 27 24 Norwegian University of Life Sciences Campus ?s. http://www.nmbu.no ________________________________________ From: R-sig-mixed-models on behalf of John Morrongiello Sent: Monday, September 11, 2017 5:26 AM To: r-sig-mixed-models at r-project.org Subject: [R-sig-ME] conditional repeatability from MCMCglmm with random slope Dear list I would like to estimate conditional repeatability of a behavioural trait from a model including random slopes fit with MCMCglmm. Would someone have some tips for how this can be done? The rptR package offers this option using bootstrapping, based on Johnson's 2014 paper (equation 11). Here, the average repeatability is estimated across the distribution of a covariate in question. I can readily estimate raw (intercept only) and a conditional (common slope) repeatability from a MCMCglmm model, but I'm not sure how to get the random slopes repeatability. Any help/ advice is much appreciated. (Johnson, P.C.D. (2014). Extension of Nakagawa & Schielzeth's R2GLMMRGLMM2 to random slopes models. Methods in Ecology and Evolution 5: 944-946). library(rptR) library(MCMCglmm) #######some data####### behaviour W: http://morrongiellolab.com [[alternative HTML version deleted]] _______________________________________________ R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From lrk4 at uw.edu  Mon Sep 11 21:20:33 2017
From: lrk4 at uw.edu (Lindsey Kishline)
Date: Mon, 11 Sep 2017 12:20:33 -0700
Subject: [R-sig-ME] afex "mixed" function - issue with Helmert coded
	contrasts
Message-ID: <CALPn117JV4Z2Z0onjD+3OJ=PENC7zqVrdJEE9vtWste3+7KrfA@mail.gmail.com>

Hello all,

I am running afex "mixed" function to get p values from a lmer model with a
continuous predictor (reaction times between 200ms-999ms), five fixed
variables, and a random subject intercept.

One of my variables is Helmert coded contrast, and when I run the model
using the "mixed" function it will change that contrast to "contr.sum" and
I will not receive p values for the contrasted levels.

It successfully runs the model and gives p values for all coefficients,
except for the contrasts. If "check.contrasts" option is TRUE - it sets the
contrasts to "contr.sum" and I don't get p values for the contrasted levels
and their interactions. If "check.contrasts" = FALSE runs fine but
obviously the contrasts aren't checked.

Here are the lines of code that I am using to run the model:

full_form_RT <- formula(raw_RT ~
two_flashes*cue_attn*ecc*two_sounds_at_target_location*pressed_two +
(1|subjnum))
RT_full_mod <- mixed(full_form_RT, data=foo, method="S")

When I use method = "KR" I get the following error so I have used method =
"S":
'anova from lme4 is returned
some computational error has occurred in lmerTest
Error in '[.data.frame'(anova_table, ,c("NumDF", "DenDF", "F.value", :
undefined columns selected'


Does anyone know how I might be able to obtain p values for the contrasts?
Is there a reason that they are automatically changed to "contr.sum" and I
can't use the Helmert coding? Or why the Kenward-Roger method gives me the
above error?

Thank you for your time,

-- 
Lindsey Kishline
Graduate Student
Laboratory for Auditory Brain Sciences & Neuroengineering
ILABS
Department of Speech and Hearing Sciences
Tel: 206-616-0102

	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Tue Sep 12 17:34:40 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Tue, 12 Sep 2017 17:34:40 +0200
Subject: [R-sig-ME] afex "mixed" function - issue with Helmert coded
	contrasts
In-Reply-To: <CALPn117JV4Z2Z0onjD+3OJ=PENC7zqVrdJEE9vtWste3+7KrfA@mail.gmail.com>
References: <CALPn117JV4Z2Z0onjD+3OJ=PENC7zqVrdJEE9vtWste3+7KrfA@mail.gmail.com>
Message-ID: <4971da47-6ec1-4ecc-5c90-2ac29ada06f1@psychologie.uzh.ch>

Hi Lindsey,

The only thing check_contrasts (which was check.contrasts in previous 
versions) does, is set the contrasts for all categorical variables to 
"contr.sum". If you do not want to use contr.sum but your own coding set 
it to FALSE. It has no additional functionality. If you set it to FALSE, 
you obviously have to make sure that the contrasts of the other 
categorical variables are orthogonal (e.g., are contr.helmert or 
contr.sum). Models with interactions of categorical variables that are 
not orthogonal are somewhat nonsensical (if type=3, which is the default 
in afex).

If you then want to obtain p-values for each individual level of the 
variable (i.e., if your categorical variable has more than 2 levels), 
you can use the per_parameter argument, e.g., per_parameter = 
"two_flashes". Note that this will test the individual parameters for 
all interaction involving this factor. You can use regular expressions 
to change this (see below).

Note that you need to use method="nested-KR" (or "LRT" or "PB") to use 
this functionality. That is currently not correct in the examples in 
?mixed, I will have to change this in the next version (the contrasts 
thing in the examples is also wrong, I am not sure why I did such a bad 
job there).  A correct example combining this would be:

require(afex)
data(obk.long)

# Examples for using the per.parameter argument:
data(obk.long, package = "afex")
obk.long$hour <- ordered(obk.long$hour)
contrasts(obk.long$phase) <- "contr.sum"
contrasts(obk.long$treatment) <- "contr.sum"

# tests only the main effect parameters of hour individually per parameter.
mixed(value ~ treatment*phase*hour +(1|id), per_parameter = "^hour$", 
data = obk.long, method = "nested-KR", check_contrasts = FALSE)

# tests all parameters including hour individually
mixed(value ~ treatment*phase*hour +(1|id), per_parameter = "hour", data 
= obk.long, method = "nested-KR", check_contrasts = FALSE)


Finally, note that an intercept only model is probably not a great idea. 
In your case, the maximal model seems out of reach (just judging from 
the number of fixed effects), but you should probably take a look at the 
following three paper for some discussion. The punchline is that some of 
those fixed effects probably need some random slopes to keep the Type I 
errors within reasonable bounds.

Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random 
effects structure for confirmatory hypothesis testing: Keep it maximal. 
Journal of Memory and Language, 68(3), 255?278. 
https://doi.org/10.1016/j.jml.2012.11.001

Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., & Bates, D. (2017). 
Balancing Type I error and power in linear mixed models. Journal of 
Memory and Language, 94, 305?315. https://doi.org/10.1016/j.jml.2017.01.001

Bates, D., Kliegl, R., Vasishth, S., & Baayen, H. (2015). Parsimonious 
Mixed Models. ArXiv:1506.04967 [Stat]. Retrieved from 
http://arxiv.org/abs/1506.04967


Hope that helps,
Henrik




Am 11.09.2017 um 21:20 schrieb Lindsey Kishline:
> Hello all,
> 
> I am running afex "mixed" function to get p values from a lmer model with a
> continuous predictor (reaction times between 200ms-999ms), five fixed
> variables, and a random subject intercept.
> 
> One of my variables is Helmert coded contrast, and when I run the model
> using the "mixed" function it will change that contrast to "contr.sum" and
> I will not receive p values for the contrasted levels.
> 
> It successfully runs the model and gives p values for all coefficients,
> except for the contrasts. If "check.contrasts" option is TRUE - it sets the
> contrasts to "contr.sum" and I don't get p values for the contrasted levels
> and their interactions. If "check.contrasts" = FALSE runs fine but
> obviously the contrasts aren't checked.
> 
> Here are the lines of code that I am using to run the model:
> 
> full_form_RT <- formula(raw_RT ~
> two_flashes*cue_attn*ecc*two_sounds_at_target_location*pressed_two +
> (1|subjnum))
> RT_full_mod <- mixed(full_form_RT, data=foo, method="S")
> 
> When I use method = "KR" I get the following error so I have used method =
> "S":
> 'anova from lme4 is returned
> some computational error has occurred in lmerTest
> Error in '[.data.frame'(anova_table, ,c("NumDF", "DenDF", "F.value", :
> undefined columns selected'
> 
> 
> Does anyone know how I might be able to obtain p values for the contrasts?
> Is there a reason that they are automatically changed to "contr.sum" and I
> can't use the Helmert coding? Or why the Kenward-Roger method gives me the
> above error?
> 
> Thank you for your time,
>


From dsidhu at ucalgary.ca  Sat Sep  9 02:19:04 2017
From: dsidhu at ucalgary.ca (David Sidhu)
Date: Sat, 9 Sep 2017 00:19:04 +0000
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
Message-ID: <5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>

Hi Ben

Thanks for the reply.
Just to follow up, I tried running an lmer instead of a glmer and the same thing happens: when a random slope and intercept are uncorrelated, the choice of the reference category affects the absolutely value of that predictor?s coefficient.

Dave

---
David M. Sidhu, MSc<http://davidmsidhu.com/>
PhD Candidate
Department of Psychology
University of Calgary






On Sep 8, 2017, at 12:04 PM, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

Not sure, but ...

I think this is real. (If I were going to pursue it further I would
probably try running some simulations.)  I think the asymmetry you're
seeing is most likely related to the nonlinearity inherent in a GLMM;
if that's true, then the effect should go away if you were using a LMM
instead of a GLMM ...


On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:

Hi Everyone

I have noticed something strange...

I am running a glmer with a single dichotomous predictor (coded 1/0). The model also includes a random subject intercept, as well as a random item intercept and slope.

Changing which level of the predictor serves as the reference category doesn?t change the absolute value of the coefficient, EXCEPT when the random intercept and slope are uncorrelated.

This happens whether I keep the predictor as a numeric variable, or change the predictor into a factor and use the following code:

t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data, family = "binomial?)

Is this a genuine result? If so, can anyone explain why the uncorrelated random intercept and slope allow it to emerge? If not, how can I run a model that has an uncorrelated random intercept and slope that would prevent the choice of reference category from affecting the result?

Thank you very much!

Dave

---
David M. Sidhu, MSc<http://davidmsidhu.com/>
PhD Candidate
Department of Psychology
University of Calgary







       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Sep 12 23:08:36 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 12 Sep 2017 21:08:36 +0000
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>

Dear David and Ben,

I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.

As I said, this is far short of a proof, but the result seems intuitively plausible.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of David Sidhu
> Sent: Friday, September 8, 2017 8:19 PM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] choice of reference category only changes
> coefficient with uncorrelated random intercept and slope
> 
> Hi Ben
> 
> Thanks for the reply.
> Just to follow up, I tried running an lmer instead of a glmer and the
> same thing happens: when a random slope and intercept are uncorrelated,
> the choice of the reference category affects the absolutely value of
> that predictor?s coefficient.
> 
> Dave
> 
> ---
> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> Psychology University of Calgary
> 
> 
> 
> 
> 
> 
> On Sep 8, 2017, at 12:04 PM, Ben Bolker
> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
> 
> Not sure, but ...
> 
> I think this is real. (If I were going to pursue it further I would
> probably try running some simulations.)  I think the asymmetry you're
> seeing is most likely related to the nonlinearity inherent in a GLMM; if
> that's true, then the effect should go away if you were using a LMM
> instead of a GLMM ...
> 
> 
> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
> 
> Hi Everyone
> 
> I have noticed something strange...
> 
> I am running a glmer with a single dichotomous predictor (coded 1/0).
> The model also includes a random subject intercept, as well as a random
> item intercept and slope.
> 
> Changing which level of the predictor serves as the reference category
> doesn?t change the absolute value of the coefficient, EXCEPT when the
> random intercept and slope are uncorrelated.
> 
> This happens whether I keep the predictor as a numeric variable, or
> change the predictor into a factor and use the following code:
> 
> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
> family = "binomial?)
> 
> Is this a genuine result? If so, can anyone explain why the uncorrelated
> random intercept and slope allow it to emerge? If not, how can I run a
> model that has an uncorrelated random intercept and slope that would
> prevent the choice of reference category from affecting the result?
> 
> Thank you very much!
> 
> Dave
> 
> ---
> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> Psychology University of Calgary
> 
> 
> 
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
> mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From pdalgd at gmail.com  Wed Sep 13 15:35:50 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 13 Sep 2017 15:35:50 +0200
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
 <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>

Just stumbled over this thread, but it seems pretty obvious to me: A model where slope and intercept are independent will not have independence between the slope and the value anywhere else on the line (cov(beta,alpha+beta*x) = x*V(beta)). This is why that model is kind of weird... 

In particular, shifting the x-axis, thus changing the definition of the intercept will make the variance model substantially different in the independence case. If intercept and slope are correlated, you just get the same model parametrized differently. 

-pd

> On 12 Sep 2017, at 23:08 , Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear David and Ben,
> 
> I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.
> 
> As I said, this is far short of a proof, but the result seems intuitively plausible.
> 
> Best,
> John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of David Sidhu
>> Sent: Friday, September 8, 2017 8:19 PM
>> To: Ben Bolker <bbolker at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] choice of reference category only changes
>> coefficient with uncorrelated random intercept and slope
>> 
>> Hi Ben
>> 
>> Thanks for the reply.
>> Just to follow up, I tried running an lmer instead of a glmer and the
>> same thing happens: when a random slope and intercept are uncorrelated,
>> the choice of the reference category affects the absolutely value of
>> that predictor?s coefficient.
>> 
>> Dave
>> 
>> ---
>> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
>> Psychology University of Calgary
>> 
>> 
>> 
>> 
>> 
>> 
>> On Sep 8, 2017, at 12:04 PM, Ben Bolker
>> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
>> 
>> Not sure, but ...
>> 
>> I think this is real. (If I were going to pursue it further I would
>> probably try running some simulations.)  I think the asymmetry you're
>> seeing is most likely related to the nonlinearity inherent in a GLMM; if
>> that's true, then the effect should go away if you were using a LMM
>> instead of a GLMM ...
>> 
>> 
>> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
>> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
>> 
>> Hi Everyone
>> 
>> I have noticed something strange...
>> 
>> I am running a glmer with a single dichotomous predictor (coded 1/0).
>> The model also includes a random subject intercept, as well as a random
>> item intercept and slope.
>> 
>> Changing which level of the predictor serves as the reference category
>> doesn?t change the absolute value of the coefficient, EXCEPT when the
>> random intercept and slope are uncorrelated.
>> 
>> This happens whether I keep the predictor as a numeric variable, or
>> change the predictor into a factor and use the following code:
>> 
>> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
>> family = "binomial?)
>> 
>> Is this a genuine result? If so, can anyone explain why the uncorrelated
>> random intercept and slope allow it to emerge? If not, how can I run a
>> model that has an uncorrelated random intercept and slope that would
>> prevent the choice of reference category from affecting the result?
>> 
>> Thank you very much!
>> 
>> Dave
>> 
>> ---
>> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
>> Psychology University of Calgary
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
>> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
>> mixed-models
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From emmanuel.curis at parisdescartes.fr  Wed Sep 13 17:52:38 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 13 Sep 2017 17:52:38 +0200
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
 <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
 <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>
Message-ID: <20170913155238.GE29014@info124.pharmacie.univ-paris5.fr>

Hi,

I may be slow or missing something, but I do not clearly understand
the first point. 

I mean, even if slope and intercept are correlated, there will be
dependance between the slope and the value (cov(beta, alpha + beta*x)
= cov(alpha,beta) + x*V(beta)), and there still will be a special
point where there is uncorrelation (for x = -cov(alpha,beta)/V(beta)).

So I don't see why it's less weird than the model without correlation,
there's just an additional assumption on the location of this special
point ? which of course may be or not sensible depending on the
interpretation of x.

Am I missing something crucial?

On Wed, Sep 13, 2017 at 03:35:50PM +0200, peter dalgaard wrote:
? Just stumbled over this thread, but it seems pretty obvious to me: A model where slope and intercept are independent will not have independence between the slope and the value anywhere else on the line (cov(beta,alpha+beta*x) = x*V(beta)). This is why that model is kind of weird... 
? 
? In particular, shifting the x-axis, thus changing the definition of the intercept will make the variance model substantially different in the independence case. If intercept and slope are correlated, you just get the same model parametrized differently. 
? 
? -pd
? 
? > On 12 Sep 2017, at 23:08 , Fox, John <jfox at mcmaster.ca> wrote:
? > 
? > Dear David and Ben,
? > 
? > I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.
? > 
? > As I said, this is far short of a proof, but the result seems intuitively plausible.
? > 
? > Best,
? > John
? > 
? > --------------------------------------
? > John Fox, Professor Emeritus
? > McMaster University
? > Hamilton, Ontario, Canada
? > Web: socserv.mcmaster.ca/jfox
? > 
? > 
? > 
? >> -----Original Message-----
? >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
? >> project.org] On Behalf Of David Sidhu
? >> Sent: Friday, September 8, 2017 8:19 PM
? >> To: Ben Bolker <bbolker at gmail.com>
? >> Cc: r-sig-mixed-models at r-project.org
? >> Subject: Re: [R-sig-ME] choice of reference category only changes
? >> coefficient with uncorrelated random intercept and slope
? >> 
? >> Hi Ben
? >> 
? >> Thanks for the reply.
? >> Just to follow up, I tried running an lmer instead of a glmer and the
? >> same thing happens: when a random slope and intercept are uncorrelated,
? >> the choice of the reference category affects the absolutely value of
? >> that predictor?s coefficient.
? >> 
? >> Dave
? >> 
? >> ---
? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
? >> Psychology University of Calgary
? >> 
? >> 
? >> 
? >> 
? >> 
? >> 
? >> On Sep 8, 2017, at 12:04 PM, Ben Bolker
? >> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
? >> 
? >> Not sure, but ...
? >> 
? >> I think this is real. (If I were going to pursue it further I would
? >> probably try running some simulations.)  I think the asymmetry you're
? >> seeing is most likely related to the nonlinearity inherent in a GLMM; if
? >> that's true, then the effect should go away if you were using a LMM
? >> instead of a GLMM ...
? >> 
? >> 
? >> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
? >> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
? >> 
? >> Hi Everyone
? >> 
? >> I have noticed something strange...
? >> 
? >> I am running a glmer with a single dichotomous predictor (coded 1/0).
? >> The model also includes a random subject intercept, as well as a random
? >> item intercept and slope.
? >> 
? >> Changing which level of the predictor serves as the reference category
? >> doesn?t change the absolute value of the coefficient, EXCEPT when the
? >> random intercept and slope are uncorrelated.
? >> 
? >> This happens whether I keep the predictor as a numeric variable, or
? >> change the predictor into a factor and use the following code:
? >> 
? >> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
? >> family = "binomial?)
? >> 
? >> Is this a genuine result? If so, can anyone explain why the uncorrelated
? >> random intercept and slope allow it to emerge? If not, how can I run a
? >> model that has an uncorrelated random intercept and slope that would
? >> prevent the choice of reference category from affecting the result?
? >> 
? >> Thank you very much!
? >> 
? >> Dave
? >> 
? >> ---
? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
? >> Psychology University of Calgary
? >> 
? >> 
? >> 
? >> 
? >> 
? >> 
? >> 
? >>       [[alternative HTML version deleted]]
? >> 
? >> _______________________________________________
? >> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
? >> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
? >> mixed-models
? >> 
? >> 
? >> 	[[alternative HTML version deleted]]
? >> 
? >> _______________________________________________
? >> R-sig-mixed-models at r-project.org mailing list
? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? > _______________________________________________
? > R-sig-mixed-models at r-project.org mailing list
? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? -- 
? Peter Dalgaard, Professor,
? Center for Statistics, Copenhagen Business School
? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
? Phone: (+45)38153501
? Office: A 4.23
? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From pdalgd at gmail.com  Wed Sep 13 18:31:49 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 13 Sep 2017 18:31:49 +0200
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <20170913155238.GE29014@info124.pharmacie.univ-paris5.fr>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
 <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
 <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>
 <20170913155238.GE29014@info124.pharmacie.univ-paris5.fr>
Message-ID: <CDB73300-5FB4-4BB9-ADF1-062A6A3CCC34@gmail.com>


> On 13 Sep 2017, at 17:52 , Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
> 
> Hi,
> 
> I may be slow or missing something, but I do not clearly understand
> the first point. 
> 
> I mean, even if slope and intercept are correlated, there will be
> dependance between the slope and the value (cov(beta, alpha + beta*x)
> = cov(alpha,beta) + x*V(beta)), and there still will be a special
> point where there is uncorrelation (for x = -cov(alpha,beta)/V(beta)).
> 
> So I don't see why it's less weird than the model without correlation,
> there's just an additional assumption on the location of this special
> point ? which of course may be or not sensible depending on the
> interpretation of x.
> 
> Am I missing something crucial?

Not really, and notice that I said "kind of" weird. The weirdness (or not) is exactly the assumption that point of uncorrelatedness falls at x==0. This can make sense - the change due to treatment can be independent of initial value, for instance. In other cases, it makes no sense at all, like when the intercept refers to the value for a 0 kg adult male. 

(In older times, these discussions came up for balanced-data random coefficient regression, where each subject has measurements at x1, ..., xn.  You might get the idea of splitting data into the average and the empirical slope for each person, because they are uncorrelated if slope and intercept are considered fixed effects. You might then move on to parametrizing the model as Yij = Ai + Bi (xj - xbar) and assume that Ai and Bi are also independent. This has neat technical properties, but the model is generally unrealistic, e.g. the minimum variance of Y occurs exactly at xbar, which depends on the chosen design points.)

-pd


> 
> On Wed, Sep 13, 2017 at 03:35:50PM +0200, peter dalgaard wrote:
> ? Just stumbled over this thread, but it seems pretty obvious to me: A model where slope and intercept are independent will not have independence between the slope and the value anywhere else on the line (cov(beta,alpha+beta*x) = x*V(beta)). This is why that model is kind of weird... 
> ? 
> ? In particular, shifting the x-axis, thus changing the definition of the intercept will make the variance model substantially different in the independence case. If intercept and slope are correlated, you just get the same model parametrized differently. 
> ? 
> ? -pd
> ? 
> ? > On 12 Sep 2017, at 23:08 , Fox, John <jfox at mcmaster.ca> wrote:
> ? > 
> ? > Dear David and Ben,
> ? > 
> ? > I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.
> ? > 
> ? > As I said, this is far short of a proof, but the result seems intuitively plausible.
> ? > 
> ? > Best,
> ? > John
> ? > 
> ? > --------------------------------------
> ? > John Fox, Professor Emeritus
> ? > McMaster University
> ? > Hamilton, Ontario, Canada
> ? > Web: socserv.mcmaster.ca/jfox
> ? > 
> ? > 
> ? > 
> ? >> -----Original Message-----
> ? >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> ? >> project.org] On Behalf Of David Sidhu
> ? >> Sent: Friday, September 8, 2017 8:19 PM
> ? >> To: Ben Bolker <bbolker at gmail.com>
> ? >> Cc: r-sig-mixed-models at r-project.org
> ? >> Subject: Re: [R-sig-ME] choice of reference category only changes
> ? >> coefficient with uncorrelated random intercept and slope
> ? >> 
> ? >> Hi Ben
> ? >> 
> ? >> Thanks for the reply.
> ? >> Just to follow up, I tried running an lmer instead of a glmer and the
> ? >> same thing happens: when a random slope and intercept are uncorrelated,
> ? >> the choice of the reference category affects the absolutely value of
> ? >> that predictor?s coefficient.
> ? >> 
> ? >> Dave
> ? >> 
> ? >> ---
> ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> ? >> Psychology University of Calgary
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> On Sep 8, 2017, at 12:04 PM, Ben Bolker
> ? >> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
> ? >> 
> ? >> Not sure, but ...
> ? >> 
> ? >> I think this is real. (If I were going to pursue it further I would
> ? >> probably try running some simulations.)  I think the asymmetry you're
> ? >> seeing is most likely related to the nonlinearity inherent in a GLMM; if
> ? >> that's true, then the effect should go away if you were using a LMM
> ? >> instead of a GLMM ...
> ? >> 
> ? >> 
> ? >> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
> ? >> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
> ? >> 
> ? >> Hi Everyone
> ? >> 
> ? >> I have noticed something strange...
> ? >> 
> ? >> I am running a glmer with a single dichotomous predictor (coded 1/0).
> ? >> The model also includes a random subject intercept, as well as a random
> ? >> item intercept and slope.
> ? >> 
> ? >> Changing which level of the predictor serves as the reference category
> ? >> doesn?t change the absolute value of the coefficient, EXCEPT when the
> ? >> random intercept and slope are uncorrelated.
> ? >> 
> ? >> This happens whether I keep the predictor as a numeric variable, or
> ? >> change the predictor into a factor and use the following code:
> ? >> 
> ? >> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
> ? >> family = "binomial?)
> ? >> 
> ? >> Is this a genuine result? If so, can anyone explain why the uncorrelated
> ? >> random intercept and slope allow it to emerge? If not, how can I run a
> ? >> model that has an uncorrelated random intercept and slope that would
> ? >> prevent the choice of reference category from affecting the result?
> ? >> 
> ? >> Thank you very much!
> ? >> 
> ? >> Dave
> ? >> 
> ? >> ---
> ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> ? >> Psychology University of Calgary
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >> 
> ? >>       [[alternative HTML version deleted]]
> ? >> 
> ? >> _______________________________________________
> ? >> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
> ? >> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
> ? >> mixed-models
> ? >> 
> ? >> 
> ? >> 	[[alternative HTML version deleted]]
> ? >> 
> ? >> _______________________________________________
> ? >> R-sig-mixed-models at r-project.org mailing list
> ? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? > _______________________________________________
> ? > R-sig-mixed-models at r-project.org mailing list
> ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? -- 
> ? Peter Dalgaard, Professor,
> ? Center for Statistics, Copenhagen Business School
> ? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> ? Phone: (+45)38153501
> ? Office: A 4.23
> ? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> ? 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
>                                Emmanuel CURIS
>                                emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From EZEQUIEL_455 at hotmail.com  Wed Sep 13 20:12:16 2017
From: EZEQUIEL_455 at hotmail.com (EZEQUIEL ROSSI)
Date: Wed, 13 Sep 2017 18:12:16 +0000
Subject: [R-sig-ME] Query
Message-ID: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>

Dears,


I am working with a Federer's augmented block design in lmer function and I need indicate interaction between ramdom and fixed factors and between two ramdom factors . Can you say me how I should make this?


Thank you very much,


Best regards,


Ezequiel Rossi

	[[alternative HTML version deleted]]


From EZEQUIEL_455 at hotmail.com  Wed Sep 13 20:25:04 2017
From: EZEQUIEL_455 at hotmail.com (EZEQUIEL ROSSI)
Date: Wed, 13 Sep 2017 18:25:04 +0000
Subject: [R-sig-ME] RV: Query
In-Reply-To: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
Message-ID: <DM3PR07MB224968B6FEED95A00312C5F1BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>




________________________________
De: EZEQUIEL ROSSI
Enviado: mi?rcoles, 13 de septiembre de 2017 03:12 p.m.
Para: r-sig-mixed-models at r-project.org
Asunto: Query


Dears,


I am working with a Federer's augmented block design in lmer function and I need indicate interaction between ramdom and fixed factors and between two ramdom factors . Can you say me how I should make this?


Thank you very much,


Best regards,


Ezequiel Rossi

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep 13 20:34:19 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Sep 2017 14:34:19 -0400
Subject: [R-sig-ME] Query
In-Reply-To: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
Message-ID: <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>


   I'm going to say something here to get the conversation started, but
this information comes with a giant caveat.  I hope that someone with
more knowledge of experimental designs comes forward ...

  in general an interaction between a random factor r and a fixed factor
f is either

(1|r:f)

(assuming a positive, compound-symmetric variance-covariance matrix) or

(f|r)

(assuming an unstructured variance-covariance matrix).  The latter is
likely to be very expensive if f has more than a few levels.

  Interaction between two random factors would be (1|r1:r2) (you would
have (1|r1) and (1|r2) in the model as well).

On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> Dears,
> 
> 
> I am working with a Federer's augmented block design in lmer function
> and I need indicate interaction between ramdom and fixed factors and
> between two ramdom factors . Can you say me how I should make this?
> 
> 
> Thank you very much,
> 
> 
> Best regards,
> 
> 
> Ezequiel Rossi
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From HDoran at air.org  Wed Sep 13 20:38:30 2017
From: HDoran at air.org (Doran, Harold)
Date: Wed, 13 Sep 2017 18:38:30 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
Message-ID: <MWHPR0501MB3850D8BB8404A49DB7C7BE54CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>

I am not sure this request makes sense. Consider the general idea that the (linear) mixed model is

Y = XB + ZU + e

Where Y is the outcome, X is the model matrix for the fixed effects, Z is the model matrix for the random effects, B are estimates of the fixed effects, U are the BLUPs, and e is the error term.

You can have an interaction between columns in X, and also conceivably between things in the matrix Z. But, you're asking how to estimate something that would be a combination of something from X and another something from Z.

Perhaps I am just unclear on your question.

Instead of assuming people on this list know what the design is you have, it would be more ideal to lay out your proposed model, and then R thinkers can possibly help you figure out the right lmer syntax for that model representation.



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of EZEQUIEL ROSSI
Sent: Wednesday, September 13, 2017 2:12 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Query

Dears,


I am working with a Federer's augmented block design in lmer function and I need indicate interaction between ramdom and fixed factors and between two ramdom factors . Can you say me how I should make this?


Thank you very much,


Best regards,


Ezequiel Rossi

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From HDoran at air.org  Wed Sep 13 20:41:41 2017
From: HDoran at air.org (Doran, Harold)
Date: Wed, 13 Sep 2017 18:41:41 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
Message-ID: <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>

Perhaps a bit OT, but what *is* an interaction between a fixed and random factor? The fixed effects are estimates, BLUPs are not estimates really.

I can't quite consider what the estimand is in this instance

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Wednesday, September 13, 2017 2:34 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Query


   I'm going to say something here to get the conversation started, but this information comes with a giant caveat.  I hope that someone with more knowledge of experimental designs comes forward ...

  in general an interaction between a random factor r and a fixed factor f is either

(1|r:f)

(assuming a positive, compound-symmetric variance-covariance matrix) or

(f|r)

(assuming an unstructured variance-covariance matrix).  The latter is likely to be very expensive if f has more than a few levels.

  Interaction between two random factors would be (1|r1:r2) (you would have (1|r1) and (1|r2) in the model as well).

On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> Dears,
> 
> 
> I am working with a Federer's augmented block design in lmer function 
> and I need indicate interaction between ramdom and fixed factors and 
> between two ramdom factors . Can you say me how I should make this?
> 
> 
> Thank you very much,
> 
> 
> Best regards,
> 
> 
> Ezequiel Rossi
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jake.a.westfall at gmail.com  Wed Sep 13 20:46:25 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 13 Sep 2017 13:46:25 -0500
Subject: [R-sig-ME] Query
In-Reply-To: <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
Message-ID: <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>

Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Query
>
>
>    I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.  I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>   in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).  The latter is
> likely to be very expensive if f has more than a few levels.
>
>   Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ian.dworkin at gmail.com  Wed Sep 13 21:04:18 2017
From: ian.dworkin at gmail.com (Ian Dworkin)
Date: Wed, 13 Sep 2017 15:04:18 -0400
Subject: [R-sig-ME] Query
In-Reply-To: <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
Message-ID: <CAGudrjmHaerJ_b-_2c-vaWdGJt1L0X5WrMA9E2Vgf55UOHSchg@mail.gmail.com>

Jake

 true, but relating the old ANOVA based mixed nomenclature to the newer one
is sometimes difficult, at least with respect to what people often think is
being modeled.

in the old terminology the interaction between a fixed factor and random
effect resulted in a new random effect that was usually interpreted to mean
something like what Ben had as
(1|r:f)

However, more often than not what the researcher meant to look at was more
of the second situation
(f|r)

In quantitative genetics this comes up all the time with Genotype by
Environment interactions. Genotype (g) is usually a random effect (i.e.
different families in a quantitative genetics design), while the
environmental (e) factor (say a diet manipulation) would be the fixed
effect.

It would be common to see models (usually in SAS) where it was the
equivalent of (1|g:e). Apologies I totally forget the SAS notation, so am
keeping it consistent with the lme4 notation.

i.e
~ 1 + e + (1|g) + (1|g:e)


However when you speak to most researchers what they are often interested
in was a model that was really
~ 1 + e + (1+e | g).

I am not disagreeing with any points, just pointing out that sometimes
relating the two has caused much confusion for some researchers.


On 13 September 2017 at 14:46, Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Well in the old ANOVA-based mixed model framework we talk about
> interactions between fixed and random factors, although in modern mixed
> models we call those interactions "random slopes." (The coefficient for a
> fixed predictor X "depends on" the level of the random factor.) So Ezequiel
> could just be using the ANOVA-type terminology (used a lot in DoE) to refer
> to random slopes.
>
> Jake
>
> On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org> wrote:
>
> > Perhaps a bit OT, but what *is* an interaction between a fixed and random
> > factor? The fixed effects are estimates, BLUPs are not estimates really.
> >
> > I can't quite consider what the estimand is in this instance
> >
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-
> bounces at r-project.org]
> > On Behalf Of Ben Bolker
> > Sent: Wednesday, September 13, 2017 2:34 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Query
> >
> >
> >    I'm going to say something here to get the conversation started, but
> > this information comes with a giant caveat.  I hope that someone with
> more
> > knowledge of experimental designs comes forward ...
> >
> >   in general an interaction between a random factor r and a fixed factor
> f
> > is either
> >
> > (1|r:f)
> >
> > (assuming a positive, compound-symmetric variance-covariance matrix) or
> >
> > (f|r)
> >
> > (assuming an unstructured variance-covariance matrix).  The latter is
> > likely to be very expensive if f has more than a few levels.
> >
> >   Interaction between two random factors would be (1|r1:r2) (you would
> > have (1|r1) and (1|r2) in the model as well).
> >
> > On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > > Dears,
> > >
> > >
> > > I am working with a Federer's augmented block design in lmer function
> > > and I need indicate interaction between ramdom and fixed factors and
> > > between two ramdom factors . Can you say me how I should make this?
> > >
> > >
> > > Thank you very much,
> > >
> > >
> > > Best regards,
> > >
> > >
> > > Ezequiel Rossi
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ian Dworkin
Department of Biology
McMaster University
Office phone 905 525 9140 ext. 21775
Lab phone 905 525 9140 ext. 20076
dworkin at mcmaster.ca

	[[alternative HTML version deleted]]


From EZEQUIEL_455 at hotmail.com  Wed Sep 13 21:05:13 2017
From: EZEQUIEL_455 at hotmail.com (EZEQUIEL ROSSI)
Date: Wed, 13 Sep 2017 19:05:13 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>,
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
Message-ID: <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>

My model is the follow:


lmer(Alt_Planta ~ Environment + (1|Bloque) + Checks + (1|Testlines), data = data)


where I have two environment and in each environment the design was a randomized complete block design with 3 replications for the Checks (30 genotypes) and the Testlines had one replications.


I need estimate the variance components for each environment and across environment. If you can help me with this, I will thank him very much.


Thank you very much,


Best regards,


Ezequiel Rossi


________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Jake Westfall <jake.a.westfall at gmail.com>
Enviado: mi?rcoles, 13 de septiembre de 2017 03:46 p.m.
Para: Doran, Harold
Cc: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Query

Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Query
>
>
>    I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.  I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>   in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).  The latter is
> likely to be very expensive if f has more than a few levels.
>
>   Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From HDoran at air.org  Wed Sep 13 21:20:36 2017
From: HDoran at air.org (Doran, Harold)
Date: Wed, 13 Sep 2017 19:20:36 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>,
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
 <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
Message-ID: <MWHPR0501MB38504339D82CBA4375A48F9DCA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>

I can think of a few ways to do this; but perhaps a straightforward way is to estimate environment in a slightly different way than what you have below

lmer(Alt_Planta ~ 1 + (1|Environment) + (1|Bloque) + Checks + (1|Testlines), data = data)

This will give you the marginal variance between environments and then you can get the conditional variance of the conditional mean for each environment.


From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com] 
Sent: Wednesday, September 13, 2017 3:05 PM
To: Jake Westfall <jake.a.westfall at gmail.com>; Doran, Harold <HDoran at air.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Query

My model is the follow:

lmer(Alt_Planta ~ Environment + (1|Bloque) + Checks + (1|Testlines), data = data)

where I have two environment and in each environment the design was a randomized complete block design with 3 replications?for the Checks (30 genotypes) and the Testlines had one replications.?

I need estimate the variance components for each environment and across environment. If you can help me with this, I will thank him very much.

Thank you very much,

Best regards,

Ezequiel Rossi

________________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Jake Westfall <jake.a.westfall at gmail.com>
Enviado: mi?rcoles, 13 de septiembre de 2017 03:46 p.m.
Para: Doran, Harold
Cc: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Query 
?
Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Query
>
>
>??? I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.? I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>?? in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).? The latter is
> likely to be very expensive if f has more than a few levels.
>
>?? Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

??????? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emmanuel.curis at parisdescartes.fr  Wed Sep 13 22:24:14 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 13 Sep 2017 22:24:14 +0200
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <CDB73300-5FB4-4BB9-ADF1-062A6A3CCC34@gmail.com>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
 <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
 <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>
 <20170913155238.GE29014@info124.pharmacie.univ-paris5.fr>
 <CDB73300-5FB4-4BB9-ADF1-062A6A3CCC34@gmail.com>
Message-ID: <20170913202414.GB7273@info124.pharmacie.univ-paris5.fr>

Thanks for the explaination.

If I understand correctly, the existence of an uncorrelatedness point
is somehow "an accident" and this point has no special meaning, so
constraining it by design to a special value (in general 0, but could
be something else by fixing the correlation between slope and
intercept) makes in general little sense. Is it that?

Best regards,

On Wed, Sep 13, 2017 at 06:31:49PM +0200, Peter Dalgaard wrote:
? 
? > On 13 Sep 2017, at 17:52 , Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
? > 
? > Hi,
? > 
? > I may be slow or missing something, but I do not clearly understand
? > the first point. 
? > 
? > I mean, even if slope and intercept are correlated, there will be
? > dependance between the slope and the value (cov(beta, alpha + beta*x)
? > = cov(alpha,beta) + x*V(beta)), and there still will be a special
? > point where there is uncorrelation (for x = -cov(alpha,beta)/V(beta)).
? > 
? > So I don't see why it's less weird than the model without correlation,
? > there's just an additional assumption on the location of this special
? > point ? which of course may be or not sensible depending on the
? > interpretation of x.
? > 
? > Am I missing something crucial?
? 
? Not really, and notice that I said "kind of" weird. The weirdness (or not) is exactly the assumption that point of uncorrelatedness falls at x==0. This can make sense - the change due to treatment can be independent of initial value, for instance. In other cases, it makes no sense at all, like when the intercept refers to the value for a 0 kg adult male. 
? 
? (In older times, these discussions came up for balanced-data random coefficient regression, where each subject has measurements at x1, ..., xn.  You might get the idea of splitting data into the average and the empirical slope for each person, because they are uncorrelated if slope and intercept are considered fixed effects. You might then move on to parametrizing the model as Yij = Ai + Bi (xj - xbar) and assume that Ai and Bi are also independent. This has neat technical properties, but the model is generally unrealistic, e.g. the minimum variance of Y occurs exactly at xbar, which depends on the chosen design points.)
? 
? -pd
? 
? 
? > 
? > On Wed, Sep 13, 2017 at 03:35:50PM +0200, peter dalgaard wrote:
? > ? Just stumbled over this thread, but it seems pretty obvious to me: A model where slope and intercept are independent will not have independence between the slope and the value anywhere else on the line (cov(beta,alpha+beta*x) = x*V(beta)). This is why that model is kind of weird... 
? > ? 
? > ? In particular, shifting the x-axis, thus changing the definition of the intercept will make the variance model substantially different in the independence case. If intercept and slope are correlated, you just get the same model parametrized differently. 
? > ? 
? > ? -pd
? > ? 
? > ? > On 12 Sep 2017, at 23:08 , Fox, John <jfox at mcmaster.ca> wrote:
? > ? > 
? > ? > Dear David and Ben,
? > ? > 
? > ? > I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.
? > ? > 
? > ? > As I said, this is far short of a proof, but the result seems intuitively plausible.
? > ? > 
? > ? > Best,
? > ? > John
? > ? > 
? > ? > --------------------------------------
? > ? > John Fox, Professor Emeritus
? > ? > McMaster University
? > ? > Hamilton, Ontario, Canada
? > ? > Web: socserv.mcmaster.ca/jfox
? > ? > 
? > ? > 
? > ? > 
? > ? >> -----Original Message-----
? > ? >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
? > ? >> project.org] On Behalf Of David Sidhu
? > ? >> Sent: Friday, September 8, 2017 8:19 PM
? > ? >> To: Ben Bolker <bbolker at gmail.com>
? > ? >> Cc: r-sig-mixed-models at r-project.org
? > ? >> Subject: Re: [R-sig-ME] choice of reference category only changes
? > ? >> coefficient with uncorrelated random intercept and slope
? > ? >> 
? > ? >> Hi Ben
? > ? >> 
? > ? >> Thanks for the reply.
? > ? >> Just to follow up, I tried running an lmer instead of a glmer and the
? > ? >> same thing happens: when a random slope and intercept are uncorrelated,
? > ? >> the choice of the reference category affects the absolutely value of
? > ? >> that predictor?s coefficient.
? > ? >> 
? > ? >> Dave
? > ? >> 
? > ? >> ---
? > ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
? > ? >> Psychology University of Calgary
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> On Sep 8, 2017, at 12:04 PM, Ben Bolker
? > ? >> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
? > ? >> 
? > ? >> Not sure, but ...
? > ? >> 
? > ? >> I think this is real. (If I were going to pursue it further I would
? > ? >> probably try running some simulations.)  I think the asymmetry you're
? > ? >> seeing is most likely related to the nonlinearity inherent in a GLMM; if
? > ? >> that's true, then the effect should go away if you were using a LMM
? > ? >> instead of a GLMM ...
? > ? >> 
? > ? >> 
? > ? >> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
? > ? >> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
? > ? >> 
? > ? >> Hi Everyone
? > ? >> 
? > ? >> I have noticed something strange...
? > ? >> 
? > ? >> I am running a glmer with a single dichotomous predictor (coded 1/0).
? > ? >> The model also includes a random subject intercept, as well as a random
? > ? >> item intercept and slope.
? > ? >> 
? > ? >> Changing which level of the predictor serves as the reference category
? > ? >> doesn?t change the absolute value of the coefficient, EXCEPT when the
? > ? >> random intercept and slope are uncorrelated.
? > ? >> 
? > ? >> This happens whether I keep the predictor as a numeric variable, or
? > ? >> change the predictor into a factor and use the following code:
? > ? >> 
? > ? >> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
? > ? >> family = "binomial?)
? > ? >> 
? > ? >> Is this a genuine result? If so, can anyone explain why the uncorrelated
? > ? >> random intercept and slope allow it to emerge? If not, how can I run a
? > ? >> model that has an uncorrelated random intercept and slope that would
? > ? >> prevent the choice of reference category from affecting the result?
? > ? >> 
? > ? >> Thank you very much!
? > ? >> 
? > ? >> Dave
? > ? >> 
? > ? >> ---
? > ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
? > ? >> Psychology University of Calgary
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >> 
? > ? >>       [[alternative HTML version deleted]]
? > ? >> 
? > ? >> _______________________________________________
? > ? >> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
? > ? >> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
? > ? >> mixed-models
? > ? >> 
? > ? >> 
? > ? >> 	[[alternative HTML version deleted]]
? > ? >> 
? > ? >> _______________________________________________
? > ? >> R-sig-mixed-models at r-project.org mailing list
? > ? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? > ? > _______________________________________________
? > ? > R-sig-mixed-models at r-project.org mailing list
? > ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? > ? 
? > ? -- 
? > ? Peter Dalgaard, Professor,
? > ? Center for Statistics, Copenhagen Business School
? > ? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
? > ? Phone: (+45)38153501
? > ? Office: A 4.23
? > ? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
? > ? 
? > ? _______________________________________________
? > ? R-sig-mixed-models at r-project.org mailing list
? > ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? > 
? > -- 
? >                                Emmanuel CURIS
? >                                emmanuel.curis at parisdescartes.fr
? > 
? > Page WWW: http://emmanuel.curis.online.fr/index.html
? 
? -- 
? Peter Dalgaard, Professor,
? Center for Statistics, Copenhagen Business School
? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
? Phone: (+45)38153501
? Office: A 4.23
? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
? 
? 
? 
? 
? 
? 
? 
? 

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From pdalgd at gmail.com  Wed Sep 13 23:51:03 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 13 Sep 2017 23:51:03 +0200
Subject: [R-sig-ME] choice of reference category only changes
 coefficient with uncorrelated random intercept and slope
In-Reply-To: <20170913202414.GB7273@info124.pharmacie.univ-paris5.fr>
References: <526B029F-D8C0-4440-BE4C-C1F5891C07E2@ucalgary.ca>
 <CABghstRqFaCV3i5HB8UcoKJJRzV_PMJC6AbqD4o8Fkh=ZueBZA@mail.gmail.com>
 <25638_1505250104_v8CL1hra029985_5346517F-8B7E-4A8B-B626-6F811875BE24@ucalgary.ca>
 <ACD1644AA6C67E4FBD0C350625508EC8366C2C36@FHSDB4H16-2.csu.mcmaster.ca>
 <930BADA2-4C66-4EAE-A754-EC0B90C83A4F@gmail.com>
 <20170913155238.GE29014@info124.pharmacie.univ-paris5.fr>
 <CDB73300-5FB4-4BB9-ADF1-062A6A3CCC34@gmail.com>
 <20170913202414.GB7273@info124.pharmacie.univ-paris5.fr>
Message-ID: <18CBE0D7-B32F-4C64-A82B-D6CAA9A612CD@gmail.com>


> On 13 Sep 2017, at 22:24 , Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
> 
> Thanks for the explaination.
> 
> If I understand correctly, the existence of an uncorrelatedness point
> is somehow "an accident" and this point has no special meaning, so
> constraining it by design to a special value (in general 0, but could
> be something else by fixing the correlation between slope and
> intercept) makes in general little sense. Is it that?
> 

Yes. Maybe add "usually" somewhere in that.

-pd

> Best regards,
> 
> On Wed, Sep 13, 2017 at 06:31:49PM +0200, Peter Dalgaard wrote:
> ? 
> ? > On 13 Sep 2017, at 17:52 , Emmanuel Curis <emmanuel.curis at parisdescartes.fr> wrote:
> ? > 
> ? > Hi,
> ? > 
> ? > I may be slow or missing something, but I do not clearly understand
> ? > the first point. 
> ? > 
> ? > I mean, even if slope and intercept are correlated, there will be
> ? > dependance between the slope and the value (cov(beta, alpha + beta*x)
> ? > = cov(alpha,beta) + x*V(beta)), and there still will be a special
> ? > point where there is uncorrelation (for x = -cov(alpha,beta)/V(beta)).
> ? > 
> ? > So I don't see why it's less weird than the model without correlation,
> ? > there's just an additional assumption on the location of this special
> ? > point ? which of course may be or not sensible depending on the
> ? > interpretation of x.
> ? > 
> ? > Am I missing something crucial?
> ? 
> ? Not really, and notice that I said "kind of" weird. The weirdness (or not) is exactly the assumption that point of uncorrelatedness falls at x==0. This can make sense - the change due to treatment can be independent of initial value, for instance. In other cases, it makes no sense at all, like when the intercept refers to the value for a 0 kg adult male. 
> ? 
> ? (In older times, these discussions came up for balanced-data random coefficient regression, where each subject has measurements at x1, ..., xn.  You might get the idea of splitting data into the average and the empirical slope for each person, because they are uncorrelated if slope and intercept are considered fixed effects. You might then move on to parametrizing the model as Yij = Ai + Bi (xj - xbar) and assume that Ai and Bi are also independent. This has neat technical properties, but the model is generally unrealistic, e.g. the minimum variance of Y occurs exactly at xbar, which depends on the chosen design points.)
> ? 
> ? -pd
> ? 
> ? 
> ? > 
> ? > On Wed, Sep 13, 2017 at 03:35:50PM +0200, peter dalgaard wrote:
> ? > ? Just stumbled over this thread, but it seems pretty obvious to me: A model where slope and intercept are independent will not have independence between the slope and the value anywhere else on the line (cov(beta,alpha+beta*x) = x*V(beta)). This is why that model is kind of weird... 
> ? > ? 
> ? > ? In particular, shifting the x-axis, thus changing the definition of the intercept will make the variance model substantially different in the independence case. If intercept and slope are correlated, you just get the same model parametrized differently. 
> ? > ? 
> ? > ? -pd
> ? > ? 
> ? > ? > On 12 Sep 2017, at 23:08 , Fox, John <jfox at mcmaster.ca> wrote:
> ? > ? > 
> ? > ? > Dear David and Ben,
> ? > ? > 
> ? > ? > I haven't worked out the implications specifically, but even in a linear model fit by least-squares, with no constraints on the inter-coefficient correlations, the correlation between the coefficients is influenced by the choice of reference level for a factor. That suggests to me that constraining the correlation to zero would affect the coefficients.
> ? > ? > 
> ? > ? > As I said, this is far short of a proof, but the result seems intuitively plausible.
> ? > ? > 
> ? > ? > Best,
> ? > ? > John
> ? > ? > 
> ? > ? > --------------------------------------
> ? > ? > John Fox, Professor Emeritus
> ? > ? > McMaster University
> ? > ? > Hamilton, Ontario, Canada
> ? > ? > Web: socserv.mcmaster.ca/jfox
> ? > ? > 
> ? > ? > 
> ? > ? > 
> ? > ? >> -----Original Message-----
> ? > ? >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> ? > ? >> project.org] On Behalf Of David Sidhu
> ? > ? >> Sent: Friday, September 8, 2017 8:19 PM
> ? > ? >> To: Ben Bolker <bbolker at gmail.com>
> ? > ? >> Cc: r-sig-mixed-models at r-project.org
> ? > ? >> Subject: Re: [R-sig-ME] choice of reference category only changes
> ? > ? >> coefficient with uncorrelated random intercept and slope
> ? > ? >> 
> ? > ? >> Hi Ben
> ? > ? >> 
> ? > ? >> Thanks for the reply.
> ? > ? >> Just to follow up, I tried running an lmer instead of a glmer and the
> ? > ? >> same thing happens: when a random slope and intercept are uncorrelated,
> ? > ? >> the choice of the reference category affects the absolutely value of
> ? > ? >> that predictor?s coefficient.
> ? > ? >> 
> ? > ? >> Dave
> ? > ? >> 
> ? > ? >> ---
> ? > ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> ? > ? >> Psychology University of Calgary
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> On Sep 8, 2017, at 12:04 PM, Ben Bolker
> ? > ? >> <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:
> ? > ? >> 
> ? > ? >> Not sure, but ...
> ? > ? >> 
> ? > ? >> I think this is real. (If I were going to pursue it further I would
> ? > ? >> probably try running some simulations.)  I think the asymmetry you're
> ? > ? >> seeing is most likely related to the nonlinearity inherent in a GLMM; if
> ? > ? >> that's true, then the effect should go away if you were using a LMM
> ? > ? >> instead of a GLMM ...
> ? > ? >> 
> ? > ? >> 
> ? > ? >> On Tue, Sep 5, 2017 at 7:45 PM, David Sidhu
> ? > ? >> <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>> wrote:
> ? > ? >> 
> ? > ? >> Hi Everyone
> ? > ? >> 
> ? > ? >> I have noticed something strange...
> ? > ? >> 
> ? > ? >> I am running a glmer with a single dichotomous predictor (coded 1/0).
> ? > ? >> The model also includes a random subject intercept, as well as a random
> ? > ? >> item intercept and slope.
> ? > ? >> 
> ? > ? >> Changing which level of the predictor serves as the reference category
> ? > ? >> doesn?t change the absolute value of the coefficient, EXCEPT when the
> ? > ? >> random intercept and slope are uncorrelated.
> ? > ? >> 
> ? > ? >> This happens whether I keep the predictor as a numeric variable, or
> ? > ? >> change the predictor into a factor and use the following code:
> ? > ? >> 
> ? > ? >> t1<-glmer(DV~IV+(1|PPT)+(0+dummy(IV, "1")|Item)+(1|Item), data = data,
> ? > ? >> family = "binomial?)
> ? > ? >> 
> ? > ? >> Is this a genuine result? If so, can anyone explain why the uncorrelated
> ? > ? >> random intercept and slope allow it to emerge? If not, how can I run a
> ? > ? >> model that has an uncorrelated random intercept and slope that would
> ? > ? >> prevent the choice of reference category from affecting the result?
> ? > ? >> 
> ? > ? >> Thank you very much!
> ? > ? >> 
> ? > ? >> Dave
> ? > ? >> 
> ? > ? >> ---
> ? > ? >> David M. Sidhu, MSc<http://davidmsidhu.com/> PhD Candidate Department of
> ? > ? >> Psychology University of Calgary
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 
> ? > ? >>       [[alternative HTML version deleted]]
> ? > ? >> 
> ? > ? >> _______________________________________________
> ? > ? >> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-
> ? > ? >> project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-
> ? > ? >> mixed-models
> ? > ? >> 
> ? > ? >> 
> ? > ? >> 	[[alternative HTML version deleted]]
> ? > ? >> 
> ? > ? >> _______________________________________________
> ? > ? >> R-sig-mixed-models at r-project.org mailing list
> ? > ? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? > ? > _______________________________________________
> ? > ? > R-sig-mixed-models at r-project.org mailing list
> ? > ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? > ? 
> ? > ? -- 
> ? > ? Peter Dalgaard, Professor,
> ? > ? Center for Statistics, Copenhagen Business School
> ? > ? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> ? > ? Phone: (+45)38153501
> ? > ? Office: A 4.23
> ? > ? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> ? > ? 
> ? > ? _______________________________________________
> ? > ? R-sig-mixed-models at r-project.org mailing list
> ? > ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? > 
> ? > -- 
> ? >                                Emmanuel CURIS
> ? >                                emmanuel.curis at parisdescartes.fr
> ? > 
> ? > Page WWW: http://emmanuel.curis.online.fr/index.html
> ? 
> ? -- 
> ? Peter Dalgaard, Professor,
> ? Center for Statistics, Copenhagen Business School
> ? Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> ? Phone: (+45)38153501
> ? Office: A 4.23
> ? Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> ? 
> 
> -- 
>                                Emmanuel CURIS
>                                emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mcypsy at gmail.com  Thu Sep 14 04:02:50 2017
From: mcypsy at gmail.com (Chunyun Ma)
Date: Wed, 13 Sep 2017 22:02:50 -0400
Subject: [R-sig-ME] by-item random intercepts
Message-ID: <CAFS3taRUDrqR583s=5AOKF3t3cZ9O46pmtPevVtj9QLjASfaeg@mail.gmail.com>

Hello all,

I am facing a dilemma of whether or not I should include by-item random
intercepts in my model. Here are the details of my problem.

I have a dataset of repeated measure in which participants solved
single-digit arithmetic problems (e.g., 4x5, 2+7, ) and their response
latencies were recorded.

The dependent variable is response latency. The independent variables
include characteristics of the stimuli (i.e., level 1) and of the
participants (i.e., level 2).

I set up the structure of random effects following recommendations from
Barr et al. (2013). For simplicity, let's say the model contains one IV.

DVti = gamma00 + gamma10IVti + u0i + u1iIVti + I0i + rti

gamma00, gamma10 are fixed effects
u0i is the random intercept
u1j is the random slope
I0i is the by-item random intercept
rti is the residual

I used lme4 to test the model
lmer(DV ~ IV + (1 + IV|sub) + (1|item), data= DT)

As I mentioned, the stimuli in my experiments are single-digit arithmetic
problems. Unlike stimuli such as English words, there are only 100
single-digit arithmetic problems for each operation and all of them were
included in my experiment. So here is my dilemma:

On one hand, a random by-item intercept would allow me to account for the
fact that there are repeated observations on each item and they are not
independent from each other.
On the other, a random by-item intercept implies there exists more items
which were not included in my experiment. However, this is not the case. I
have included all single-digit arithmetic problems in my experiment.

I could adopt a fixed-effect approach and use 100 dummy variables to
account for the item-based clustering but this would be practically
impossible.

To iterate my question:
should I include a random by-item intercept given the special feature of my
dataset?
A few follow-up questions:
what's the consequence of including/excluding this random effect?  How are
type-I error and power affected?
Should I use a nested structure instead of the crossed one I have mentioned
above? For example, if each participant contributed multiple observations
on each item, should I nest the by-item random intercept under subject?

Thank you very much!

Chunyun

	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Thu Sep 14 04:21:44 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 13 Sep 2017 21:21:44 -0500
Subject: [R-sig-ME] by-item random intercepts
In-Reply-To: <CAFS3taRUDrqR583s=5AOKF3t3cZ9O46pmtPevVtj9QLjASfaeg@mail.gmail.com>
References: <CAFS3taRUDrqR583s=5AOKF3t3cZ9O46pmtPevVtj9QLjASfaeg@mail.gmail.com>
Message-ID: <CAE9_Wg6ZuaO6CpBk_5f1AObADQCVR=MOHQYH40rDp=1OSCJOmQ@mail.gmail.com>

Hi Chunyun,

As I mentioned, the stimuli in my experiments are single-digit arithmetic
> problems. Unlike stimuli such as English words, there are only 100
> single-digit arithmetic problems for each operation and all of them were
> included in my experiment.


If you've really exhaustively sampled all possible stimuli that could have
appeared in your study, then I would argue that it doesn't make conceptual
sense to analyze the stimuli as random effects.

I could adopt a fixed-effect approach and use 100 dummy variables to
> account for the item-based clustering but this would be practically
> impossible.


Is it? Have you tried it? Adding fixed effects usually increases the
computational burden *far* less than adding random effects. So while this
analysis might be a bit unwieldy, is it actually infeasible?

If the answer is yes, then a reasonable alternative is to simply ignore the
stimulus effects altogether. Practically speaking, the result is usually
much the same as explicitly adding stimulus fixed effects to the model. The
reason is because ignoring the stimulus effects (vs. adding them as fixed)
mainly just serves to throw the stimulus variance into the residual
variance, but unless your experiment is quite tiny, the residual variance
probably already contributes *very* little to the standard errors of the
fixed effect parameter estimates of interest. (Getting more into the
mathematical weeds, the residual variance enters the standard error
*roughly* as var(resid)/sqrt(n), where n is the number of rows -- this term
is probably already tiny unless your experiment is tiny, and it should
remain tiny even if you increase var(resid) by a lot.)

Note however that the above is assuming that the stimulus effects are at
best weakly correlated with the other regressors. That assumption is likely
true in an experimental context, but to the extent that it is false,
omitting the stimulus effects could also alter the other fixed effect
parameter estimates.

Should I use a nested structure instead of the crossed one I have mentioned
> above? For example, if each participant contributed multiple observations
> on each item, should I nest the by-item random intercept under subject?


I don't see why you would do that.

Jake


On Wed, Sep 13, 2017 at 9:02 PM, Chunyun Ma <mcypsy at gmail.com> wrote:

> Hello all,
>
> I am facing a dilemma of whether or not I should include by-item random
> intercepts in my model. Here are the details of my problem.
>
> I have a dataset of repeated measure in which participants solved
> single-digit arithmetic problems (e.g., 4x5, 2+7, ) and their response
> latencies were recorded.
>
> The dependent variable is response latency. The independent variables
> include characteristics of the stimuli (i.e., level 1) and of the
> participants (i.e., level 2).
>
> I set up the structure of random effects following recommendations from
> Barr et al. (2013). For simplicity, let's say the model contains one IV.
>
> DVti = gamma00 + gamma10IVti + u0i + u1iIVti + I0i + rti
>
> gamma00, gamma10 are fixed effects
> u0i is the random intercept
> u1j is the random slope
> I0i is the by-item random intercept
> rti is the residual
>
> I used lme4 to test the model
> lmer(DV ~ IV + (1 + IV|sub) + (1|item), data= DT)
>
> As I mentioned, the stimuli in my experiments are single-digit arithmetic
> problems. Unlike stimuli such as English words, there are only 100
> single-digit arithmetic problems for each operation and all of them were
> included in my experiment. So here is my dilemma:
>
> On one hand, a random by-item intercept would allow me to account for the
> fact that there are repeated observations on each item and they are not
> independent from each other.
> On the other, a random by-item intercept implies there exists more items
> which were not included in my experiment. However, this is not the case. I
> have included all single-digit arithmetic problems in my experiment.
>
> I could adopt a fixed-effect approach and use 100 dummy variables to
> account for the item-based clustering but this would be practically
> impossible.
>
> To iterate my question:
> should I include a random by-item intercept given the special feature of my
> dataset?
> A few follow-up questions:
> what's the consequence of including/excluding this random effect?  How are
> type-I error and power affected?
> Should I use a nested structure instead of the crossed one I have mentioned
> above? For example, if each participant contributed multiple observations
> on each item, should I nest the by-item random intercept under subject?
>
> Thank you very much!
>
> Chunyun
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Thu Sep 14 04:24:02 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 13 Sep 2017 21:24:02 -0500
Subject: [R-sig-ME] by-item random intercepts
In-Reply-To: <CAE9_Wg6ZuaO6CpBk_5f1AObADQCVR=MOHQYH40rDp=1OSCJOmQ@mail.gmail.com>
References: <CAFS3taRUDrqR583s=5AOKF3t3cZ9O46pmtPevVtj9QLjASfaeg@mail.gmail.com>
 <CAE9_Wg6ZuaO6CpBk_5f1AObADQCVR=MOHQYH40rDp=1OSCJOmQ@mail.gmail.com>
Message-ID: <CAE9_Wg4_iZYbpa7spK=_+kgDQeZAmyb6MzC-hV=siMYNUUbbEg@mail.gmail.com>

Er, small correction, I meant that the residual variance enters the
standard error as roughly sqrt(var(resid)/n), not var(resid)/sqrt(n) :p

Jake

On Wed, Sep 13, 2017 at 9:21 PM, Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Hi Chunyun,
>
> As I mentioned, the stimuli in my experiments are single-digit arithmetic
>> problems. Unlike stimuli such as English words, there are only 100
>> single-digit arithmetic problems for each operation and all of them were
>> included in my experiment.
>
>
> If you've really exhaustively sampled all possible stimuli that could have
> appeared in your study, then I would argue that it doesn't make conceptual
> sense to analyze the stimuli as random effects.
>
> I could adopt a fixed-effect approach and use 100 dummy variables to
>> account for the item-based clustering but this would be practically
>> impossible.
>
>
> Is it? Have you tried it? Adding fixed effects usually increases the
> computational burden *far* less than adding random effects. So while this
> analysis might be a bit unwieldy, is it actually infeasible?
>
> If the answer is yes, then a reasonable alternative is to simply ignore
> the stimulus effects altogether. Practically speaking, the result is
> usually much the same as explicitly adding stimulus fixed effects to the
> model. The reason is because ignoring the stimulus effects (vs. adding them
> as fixed) mainly just serves to throw the stimulus variance into the
> residual variance, but unless your experiment is quite tiny, the residual
> variance probably already contributes *very* little to the standard errors
> of the fixed effect parameter estimates of interest. (Getting more into the
> mathematical weeds, the residual variance enters the standard error
> *roughly* as var(resid)/sqrt(n), where n is the number of rows -- this term
> is probably already tiny unless your experiment is tiny, and it should
> remain tiny even if you increase var(resid) by a lot.)
>
> Note however that the above is assuming that the stimulus effects are at
> best weakly correlated with the other regressors. That assumption is likely
> true in an experimental context, but to the extent that it is false,
> omitting the stimulus effects could also alter the other fixed effect
> parameter estimates.
>
> Should I use a nested structure instead of the crossed one I have mentioned
>> above? For example, if each participant contributed multiple observations
>> on each item, should I nest the by-item random intercept under subject?
>
>
> I don't see why you would do that.
>
> Jake
>
>
> On Wed, Sep 13, 2017 at 9:02 PM, Chunyun Ma <mcypsy at gmail.com> wrote:
>
>> Hello all,
>>
>> I am facing a dilemma of whether or not I should include by-item random
>> intercepts in my model. Here are the details of my problem.
>>
>> I have a dataset of repeated measure in which participants solved
>> single-digit arithmetic problems (e.g., 4x5, 2+7, ) and their response
>> latencies were recorded.
>>
>> The dependent variable is response latency. The independent variables
>> include characteristics of the stimuli (i.e., level 1) and of the
>> participants (i.e., level 2).
>>
>> I set up the structure of random effects following recommendations from
>> Barr et al. (2013). For simplicity, let's say the model contains one IV.
>>
>> DVti = gamma00 + gamma10IVti + u0i + u1iIVti + I0i + rti
>>
>> gamma00, gamma10 are fixed effects
>> u0i is the random intercept
>> u1j is the random slope
>> I0i is the by-item random intercept
>> rti is the residual
>>
>> I used lme4 to test the model
>> lmer(DV ~ IV + (1 + IV|sub) + (1|item), data= DT)
>>
>> As I mentioned, the stimuli in my experiments are single-digit arithmetic
>> problems. Unlike stimuli such as English words, there are only 100
>> single-digit arithmetic problems for each operation and all of them were
>> included in my experiment. So here is my dilemma:
>>
>> On one hand, a random by-item intercept would allow me to account for the
>> fact that there are repeated observations on each item and they are not
>> independent from each other.
>> On the other, a random by-item intercept implies there exists more items
>> which were not included in my experiment. However, this is not the case. I
>> have included all single-digit arithmetic problems in my experiment.
>>
>> I could adopt a fixed-effect approach and use 100 dummy variables to
>> account for the item-based clustering but this would be practically
>> impossible.
>>
>> To iterate my question:
>> should I include a random by-item intercept given the special feature of
>> my
>> dataset?
>> A few follow-up questions:
>> what's the consequence of including/excluding this random effect?  How are
>> type-I error and power affected?
>> Should I use a nested structure instead of the crossed one I have
>> mentioned
>> above? For example, if each participant contributed multiple observations
>> on each item, should I nest the by-item random intercept under subject?
>>
>> Thank you very much!
>>
>> Chunyun
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From EZEQUIEL_455 at hotmail.com  Thu Sep 14 14:04:06 2017
From: EZEQUIEL_455 at hotmail.com (EZEQUIEL ROSSI)
Date: Thu, 14 Sep 2017 12:04:06 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <MWHPR0501MB38504339D82CBA4375A48F9DCA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>,
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
 <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>,
 <MWHPR0501MB38504339D82CBA4375A48F9DCA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
Message-ID: <DM3PR07MB2249D74786A2BAC4CEBD9257BA6F0@DM3PR07MB2249.namprd07.prod.outlook.com>

Thank you so much for your response. One question more.


I need estimate the interaction genotype x environment. How should I make this? The interaction between Checks and environment or between Testlines and environments?

Best regards,

Ezequiel Rossi

________________________________
De: Doran, Harold <HDoran at air.org>
Enviado: mi?rcoles, 13 de septiembre de 2017 04:20 p.m.
Para: 'EZEQUIEL ROSSI'; Jake Westfall
Cc: r-sig-mixed-models at r-project.org
Asunto: RE: [R-sig-ME] Query

I can think of a few ways to do this; but perhaps a straightforward way is to estimate environment in a slightly different way than what you have below

lmer(Alt_Planta ~ 1 + (1|Environment) + (1|Bloque) + Checks + (1|Testlines), data = data)

This will give you the marginal variance between environments and then you can get the conditional variance of the conditional mean for each environment.


From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com]
Sent: Wednesday, September 13, 2017 3:05 PM
To: Jake Westfall <jake.a.westfall at gmail.com>; Doran, Harold <HDoran at air.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Query

My model is the follow:

lmer(Alt_Planta ~ Environment + (1|Bloque) + Checks + (1|Testlines), data = data)

where I have two environment and in each environment the design was a randomized complete block design with 3 replications for the Checks (30 genotypes) and the Testlines had one replications.

I need estimate the variance components for each environment and across environment. If you can help me with this, I will thank him very much.

Thank you very much,

Best regards,

Ezequiel Rossi

________________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Jake Westfall <jake.a.westfall at gmail.com>
Enviado: mi?rcoles, 13 de septiembre de 2017 03:46 p.m.
Para: Doran, Harold
Cc: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Query

Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Query
>
>
>    I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.  I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>   in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).  The latter is
> likely to be very expensive if f has more than a few levels.
>
>   Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Thu Sep 14 14:57:39 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Thu, 14 Sep 2017 09:57:39 -0300
Subject: [R-sig-ME] Non-linear mixed model
Message-ID: <CAF5W3aS9rqurUxn4akVA=Z1_tpR_wZnLhvHur2bv=bGDPGHhDA@mail.gmail.com>

Dear list members,

I?m trying to test the effect of the climate region classification on
the in vitro growth of a sample (n =20) of fungus races.  I grew them
in several temperatures (20, 22, 25, 28, 31) that I knew they could
have the maximum growth:

 race state   Clima1  Kopp Kopp2   temp   rep    diam
 1      TO       F          Aw             B     20        1     4.4
 1      TO       F          Aw             B     20        2     4.1
 1      TO       F          Aw             B     20        3     4.3
 1      TO       F          Aw             B     22        1     4.8
 1      TO       F          Aw             B     22        2     4.5
 1      TO       F          Aw             B     22        3     4.4
..


The approach that I?m considering is to fitt a non- linear model:

diam ~ thy * exp (thq*(temp-thx)? + thc*(temp-thx)?)

# thx: Optimum temperature
# thy: Diameter at optimum
# thq: Curvature
# thc: Skewness

Since I have particular interest on "thx": How should I include the
effect of my climate classiification variables on that coefficient?

This is my try in nlme:

df <- groupedData(diam~temp|race, data=d, order=FALSE)

n1 <- nlme(diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3),
           fixed = thy + thq + thx + thc ~ 1,
           random = thy + thq + thx + thc ~ 1 | race,
           start = c(thy = 5.5, thq = -0.08, thx = 25, thc = -0.01),
           data = df)

The overall model converged and this is the summary:

======================================================
Nonlinear mixed-effects model fit by maximum likelihood
Model: diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3)
Data: df
       AIC      BIC    logLik
  619.2972 652.1712 -301.6486

Random effects:
Formula: list(thy ~ 1, thx ~ 1)
Level: race

Structure: General positive-definite, Log-Cholesky parametrization
         StdDev        Corr
thy      0.00002186836 thy
thx      0.00001466761 0
Residual 0.47302438540

Fixed effects: thy + thq + thx + thc ~ 1
        Value        Std.Error         DF   t-value        p-value
thy   5.456386   0.03598277  427   151.63885  0.0000
thq  -0.011081   0.00043084  427   -25.71992  0.0000
thx  25.908119  0.17218070  427   150.47052  0.0000
thc   0.000458   0.00015103  427     3.03271    0.0026
 Correlation:
    thy    thq    thx
thq -0.567
thx  0.217  0.289
thc -0.231 -0.192 -0.924

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-3.53487665 -0.64456754  0.06126737  0.67103195  2.17757223

Number of Observations: 450
Number of Groups: 20

=========================================================

Thanks in advance... Any help would be very helpful!

J. Edwards


From jesus.frias at dit.ie  Thu Sep 14 15:06:42 2017
From: jesus.frias at dit.ie (Jesus Maria Frias Celayeta)
Date: Thu, 14 Sep 2017 14:06:42 +0100
Subject: [R-sig-ME] Non-linear mixed model
In-Reply-To: <CAF5W3aS9rqurUxn4akVA=Z1_tpR_wZnLhvHur2bv=bGDPGHhDA@mail.gmail.com>
References: <CAF5W3aS9rqurUxn4akVA=Z1_tpR_wZnLhvHur2bv=bGDPGHhDA@mail.gmail.com>
Message-ID: <CAErBVpMbZqMm2YDOhNAw7=WUD4nXUjUnBJnC4Bxy+yCEAoc85A@mail.gmail.com>

Hi Juan,

You probably want to have a look at the "fixed" argument in the nlme help
page.

If the variable that gives you the indicator of the climate region is
Clima1 you probably will need something like

n2 <- nlme(diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3),
           fixed = list(thy + thq +  thc ~ 1, thx~Clima1),
           random = thy + thq + thx + thc ~ 1 | race,
           start = c(thy = 5.5, thq = -0.08, thc = -0.01, thx.clima1=xxx,
thx.clima2=xxx...,thx.climan=xxx),
           data = df)

Note that you will need estimates for your baseline ths and for the
analytical contrasts defined.

If you want to see if the addition of Clima1 to the model is giving you joy
then you need
anova(n1,n2)

and from  summary(n2) you will see if any of your climate regions are
different from the baseline control.

Alternatively 1) you may choose different contrast .2) you can give a try
to multiple comparisons. Both are well documented in this list (or the
R-help).

all the best,

Jesus

Jesus



On 14 September 2017 at 13:57, Juan Pablo Edwards Molina <
edwardsmolina at gmail.com> wrote:

> Dear list members,
>
> I?m trying to test the effect of the climate region classification on
> the in vitro growth of a sample (n =20) of fungus races.  I grew them
> in several temperatures (20, 22, 25, 28, 31) that I knew they could
> have the maximum growth:
>
>  race state   Clima1  Kopp Kopp2   temp   rep    diam
>  1      TO       F          Aw             B     20        1     4.4
>  1      TO       F          Aw             B     20        2     4.1
>  1      TO       F          Aw             B     20        3     4.3
>  1      TO       F          Aw             B     22        1     4.8
>  1      TO       F          Aw             B     22        2     4.5
>  1      TO       F          Aw             B     22        3     4.4
> ..
>
>
> The approach that I?m considering is to fitt a non- linear model:
>
> diam ~ thy * exp (thq*(temp-thx)? + thc*(temp-thx)?)
>
> # thx: Optimum temperature
> # thy: Diameter at optimum
> # thq: Curvature
> # thc: Skewness
>
> Since I have particular interest on "thx": How should I include the
> effect of my climate classiification variables on that coefficient?
>
> This is my try in nlme:
>
> df <- groupedData(diam~temp|race, data=d, order=FALSE)
>
> n1 <- nlme(diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3),
>            fixed = thy + thq + thx + thc ~ 1,
>            random = thy + thq + thx + thc ~ 1 | race,
>            start = c(thy = 5.5, thq = -0.08, thx = 25, thc = -0.01),
>            data = df)
>
> The overall model converged and this is the summary:
>
> ======================================================
> Nonlinear mixed-effects model fit by maximum likelihood
> Model: diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3)
> Data: df
>        AIC      BIC    logLik
>   619.2972 652.1712 -301.6486
>
> Random effects:
> Formula: list(thy ~ 1, thx ~ 1)
> Level: race
>
> Structure: General positive-definite, Log-Cholesky parametrization
>          StdDev        Corr
> thy      0.00002186836 thy
> thx      0.00001466761 0
> Residual 0.47302438540
>
> Fixed effects: thy + thq + thx + thc ~ 1
>         Value        Std.Error         DF   t-value        p-value
> thy   5.456386   0.03598277  427   151.63885  0.0000
> thq  -0.011081   0.00043084  427   -25.71992  0.0000
> thx  25.908119  0.17218070  427   150.47052  0.0000
> thc   0.000458   0.00015103  427     3.03271    0.0026
>  Correlation:
>     thy    thq    thx
> thq -0.567
> thx  0.217  0.289
> thc -0.231 -0.192 -0.924
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -3.53487665 -0.64456754  0.06126737  0.67103195  2.17757223
>
> Number of Observations: 450
> Number of Groups: 20
>
> =========================================================
>
> Thanks in advance... Any help would be very helpful!
>
> J. Edwards
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 

*Jes?s Mar?a Fr?as Celayeta, PhD CFS*

 *Ceannaire Acad?il, Institi?id na hInbhuanaitheachta Comhshaoil agus na
Sl?inte | Academic Leader, Environmental Sustainability and Health
Institute*

*Institi?id Teicneola?ochta Bhaile ?tha Cliath | Dublin Institute of
Technology*

*Gr?inseach Ghorm?in **|* *Grangegorman *

*Baile ?tha Cliath 7  | Dublin 7 *

*D07 H6K8*

F: +353-1-4025410 <(01)%20402%205410> M: +353-879697289

E: jesus.frias at dit.ie <james.curtin at dit.ie>

W:  <http://goog_648487918/>http://www.dit.ie/eshi

-- 


This email originated from DIT. If you received this email in error, please 
delete it from your system. Please note that if you are not the named 
addressee, disclosing, copying, distributing or taking any action based on 
the contents of this email or attachments is prohibited. www.dit.ie

Is ? ITB?C a th?inig an r?omhphost seo. M? fuair t? an r?omhphost seo tr? 
earr?id, scrios de do ch?ras ? le do thoil. Tabhair ar aird, mura t? an 
seola? ainmnithe, go bhfuil dianchosc ar aon nochtadh, aon ch?ipe?il, aon 
d?ileadh n? ar aon ghn?omh a dh?anfar bunaithe ar an ?bhar at? sa 
r?omhphost n? sna hiat?in seo. www.dit.ie

T? ITB?C ag aistri? go Gr?inseach Ghorm?in ? DIT is on the move to 
Grangegorman <http://www.dit.ie/grangegorman>

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Thu Sep 14 15:39:22 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Thu, 14 Sep 2017 10:39:22 -0300
Subject: [R-sig-ME] Non-linear mixed model
In-Reply-To: <CAErBVpMRCgaEaCGj8=gEoYX3jeMqdzyyydrbP9r-EErtZ5v1jw@mail.gmail.com>
References: <CAF5W3aS9rqurUxn4akVA=Z1_tpR_wZnLhvHur2bv=bGDPGHhDA@mail.gmail.com>
 <CAErBVpMbZqMm2YDOhNAw7=WUD4nXUjUnBJnC4Bxy+yCEAoc85A@mail.gmail.com>
 <CAF5W3aSuapwOwug+aALjmdHfL7N37PF+FDJxEyUpiZYKvxA1Kg@mail.gmail.com>
 <CAErBVpMRCgaEaCGj8=gEoYX3jeMqdzyyydrbP9r-EErtZ5v1jw@mail.gmail.com>
Message-ID: <CAF5W3aR2u+SjTu8iPerKW0M4YLhGAQ6UdDNDAq-PvtyyE342Rw@mail.gmail.com>

Thanks for your time and explanations Jesus...

I really appreciate it.

Best regards,

Juan Edwards

On Thu, Sep 14, 2017 at 10:22 AM, Jesus Maria Frias Celayeta
<jesus.frias at dit.ie> wrote:
> Hi Juan,
>
> If you have been fitting n1 to subsets of the data for each of the climate
> region you can use that information but you need to know which climate
> region is your baseline.
>
> you need to run something like
>
> levels(df$Clima1)
>
> The first level will be your baseline in the analytical contrast matrix and
> that will be the first starting parameters.
> The second starting parameter will be thx for the Clima2 subset minus
> thx.clima1
> The third starting parameter will be thx for the Clima3 subset minus
> thx.clima1
> and so on...
>
> regards,,
>
> Jesus
>
>
>
>
>
> On 14 September 2017 at 14:16, Juan Pablo Edwards Molina
> <edwardsmolina at gmail.com> wrote:
>>
>> Thanks Jesus for your quick reply! I will read the nlme help as you
>> suggested..
>>
>> I will try your first suggestion...
>>
>> for the starters of ths: can I use the overall model estimates?
>>
>>     start = c(thy = 5.5, thq = -0.08, thc = -0.01, thx.clima1=xxx,
>> thx.clima2=xxx...,thx.climan=xxx),
>>
>> and just for curiosity, is it needed to group the data before modeling it?
>> df <- groupedData(diam~temp|race, data=d, order=FALSE)
>>
>>
>> Thanks again!
>>
>> Juan
>> Juan
>>
>>
>> On Thu, Sep 14, 2017 at 10:06 AM, Jesus Maria Frias Celayeta
>> <jesus.frias at dit.ie> wrote:
>> > Hi Juan,
>> >
>> > You probably want to have a look at the "fixed" argument in the nlme
>> > help
>> > page.
>> >
>> > If the variable that gives you the indicator of the climate region is
>> > Clima1
>> > you probably will need something like
>> >
>> > n2 <- nlme(diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp -
>> > thx)^3),
>> >            fixed = list(thy + thq +  thc ~ 1, thx~Clima1),
>> >            random = thy + thq + thx + thc ~ 1 | race,
>> >            start = c(thy = 5.5, thq = -0.08, thc = -0.01,
>> > thx.clima1=xxx,
>> > thx.clima2=xxx...,thx.climan=xxx),
>> >            data = df)
>> >
>> > Note that you will need estimates for your baseline ths and for the
>> > analytical contrasts defined.
>> >
>> > If you want to see if the addition of Clima1 to the model is giving you
>> > joy
>> > then you need
>> > anova(n1,n2)
>> >
>> > and from  summary(n2) you will see if any of your climate regions are
>> > different from the baseline control.
>> >
>> > Alternatively 1) you may choose different contrast .2) you can give a
>> > try to
>> > multiple comparisons. Both are well documented in this list (or the
>> > R-help).
>> >
>> > all the best,
>> >
>> > Jesus
>> >
>> > Jesus
>> >
>> >
>> >
>> > On 14 September 2017 at 13:57, Juan Pablo Edwards Molina
>> > <edwardsmolina at gmail.com> wrote:
>> >>
>> >> Dear list members,
>> >>
>> >> I?m trying to test the effect of the climate region classification on
>> >> the in vitro growth of a sample (n =20) of fungus races.  I grew them
>> >> in several temperatures (20, 22, 25, 28, 31) that I knew they could
>> >> have the maximum growth:
>> >>
>> >>  race state   Clima1  Kopp Kopp2   temp   rep    diam
>> >>  1      TO       F          Aw             B     20        1     4.4
>> >>  1      TO       F          Aw             B     20        2     4.1
>> >>  1      TO       F          Aw             B     20        3     4.3
>> >>  1      TO       F          Aw             B     22        1     4.8
>> >>  1      TO       F          Aw             B     22        2     4.5
>> >>  1      TO       F          Aw             B     22        3     4.4
>> >> ..
>> >>
>> >>
>> >> The approach that I?m considering is to fitt a non- linear model:
>> >>
>> >> diam ~ thy * exp (thq*(temp-thx)? + thc*(temp-thx)?)
>> >>
>> >> # thx: Optimum temperature
>> >> # thy: Diameter at optimum
>> >> # thq: Curvature
>> >> # thc: Skewness
>> >>
>> >> Since I have particular interest on "thx": How should I include the
>> >> effect of my climate classiification variables on that coefficient?
>> >>
>> >> This is my try in nlme:
>> >>
>> >> df <- groupedData(diam~temp|race, data=d, order=FALSE)
>> >>
>> >> n1 <- nlme(diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp -
>> >> thx)^3),
>> >>            fixed = thy + thq + thx + thc ~ 1,
>> >>            random = thy + thq + thx + thc ~ 1 | race,
>> >>            start = c(thy = 5.5, thq = -0.08, thx = 25, thc = -0.01),
>> >>            data = df)
>> >>
>> >> The overall model converged and this is the summary:
>> >>
>> >> ======================================================
>> >> Nonlinear mixed-effects model fit by maximum likelihood
>> >> Model: diam ~ thy * exp(thq * (temp - thx)^2 + thc * (temp - thx)^3)
>> >> Data: df
>> >>        AIC      BIC    logLik
>> >>   619.2972 652.1712 -301.6486
>> >>
>> >> Random effects:
>> >> Formula: list(thy ~ 1, thx ~ 1)
>> >> Level: race
>> >>
>> >> Structure: General positive-definite, Log-Cholesky parametrization
>> >>          StdDev        Corr
>> >> thy      0.00002186836 thy
>> >> thx      0.00001466761 0
>> >> Residual 0.47302438540
>> >>
>> >> Fixed effects: thy + thq + thx + thc ~ 1
>> >>         Value        Std.Error         DF   t-value        p-value
>> >> thy   5.456386   0.03598277  427   151.63885  0.0000
>> >> thq  -0.011081   0.00043084  427   -25.71992  0.0000
>> >> thx  25.908119  0.17218070  427   150.47052  0.0000
>> >> thc   0.000458   0.00015103  427     3.03271    0.0026
>> >>  Correlation:
>> >>     thy    thq    thx
>> >> thq -0.567
>> >> thx  0.217  0.289
>> >> thc -0.231 -0.192 -0.924
>> >>
>> >> Standardized Within-Group Residuals:
>> >>         Min          Q1         Med          Q3         Max
>> >> -3.53487665 -0.64456754  0.06126737  0.67103195  2.17757223
>> >>
>> >> Number of Observations: 450
>> >> Number of Groups: 20
>> >>
>> >> =========================================================
>> >>
>> >> Thanks in advance... Any help would be very helpful!
>> >>
>> >> J. Edwards
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>> >
>> >
>> > --
>> >
>> > Jes?s Mar?a Fr?as Celayeta, PhD CFS
>> >
>> >  Ceannaire Acad?il, Institi?id na hInbhuanaitheachta Comhshaoil agus na
>> > Sl?inte | Academic Leader, Environmental Sustainability and Health
>> > Institute
>> >
>> > Institi?id Teicneola?ochta Bhaile ?tha Cliath | Dublin Institute of
>> > Technology
>> >
>> > Gr?inseach Ghorm?in | Grangegorman
>> >
>> > Baile ?tha Cliath 7  | Dublin 7
>> >
>> > D07 H6K8
>> >
>> > F: +353-1-4025410 M: +353-879697289
>> >
>> > E: jesus.frias at dit.ie
>> >
>> > W: http://www.dit.ie/eshi
>> >
>> >
>> > This email originated from DIT. If you received this email in error,
>> > please
>> > delete it from your system. Please note that if you are not the named
>> > addressee, disclosing, copying, distributing or taking any action based
>> > on
>> > the contents of this email or attachments is prohibited. www.dit.ie
>> >
>> > Is ? ITB?C a th?inig an r?omhphost seo. M? fuair t? an r?omhphost seo
>> > tr?
>> > earr?id, scrios de do ch?ras ? le do thoil. Tabhair ar aird, mura t? an
>> > seola? ainmnithe, go bhfuil dianchosc ar aon nochtadh, aon ch?ipe?il,
>> > aon
>> > d?ileadh n? ar aon ghn?omh a dh?anfar bunaithe ar an ?bhar at? sa
>> > r?omhphost
>> > n? sna hiat?in seo. www.dit.ie
>> >
>> > T? ITB?C ag aistri? go Gr?inseach Ghorm?in ? DIT is on the move to
>> > Grangegorman
>
>
>
>
> --
>
> Jes?s Mar?a Fr?as Celayeta, PhD CFS
>
>  Ceannaire Acad?il, Institi?id na hInbhuanaitheachta Comhshaoil agus na
> Sl?inte | Academic Leader, Environmental Sustainability and Health Institute
>
> Institi?id Teicneola?ochta Bhaile ?tha Cliath | Dublin Institute of
> Technology
>
> Gr?inseach Ghorm?in | Grangegorman
>
> Baile ?tha Cliath 7  | Dublin 7
>
> D07 H6K8
>
> F: +353-1-4025410 M: +353-879697289
>
> E: jesus.frias at dit.ie
>
> W: http://www.dit.ie/eshi
>
>
> This email originated from DIT. If you received this email in error, please
> delete it from your system. Please note that if you are not the named
> addressee, disclosing, copying, distributing or taking any action based on
> the contents of this email or attachments is prohibited. www.dit.ie
>
> Is ? ITB?C a th?inig an r?omhphost seo. M? fuair t? an r?omhphost seo tr?
> earr?id, scrios de do ch?ras ? le do thoil. Tabhair ar aird, mura t? an
> seola? ainmnithe, go bhfuil dianchosc ar aon nochtadh, aon ch?ipe?il, aon
> d?ileadh n? ar aon ghn?omh a dh?anfar bunaithe ar an ?bhar at? sa r?omhphost
> n? sna hiat?in seo. www.dit.ie
>
> T? ITB?C ag aistri? go Gr?inseach Ghorm?in ? DIT is on the move to
> Grangegorman


From HDoran at air.org  Thu Sep 14 17:49:35 2017
From: HDoran at air.org (Doran, Harold)
Date: Thu, 14 Sep 2017 15:49:35 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <DM3PR07MB2249D74786A2BAC4CEBD9257BA6F0@DM3PR07MB2249.namprd07.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>,
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
 <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>,
 <MWHPR0501MB38504339D82CBA4375A48F9DCA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
 <DM3PR07MB2249D74786A2BAC4CEBD9257BA6F0@DM3PR07MB2249.namprd07.prod.outlook.com>
Message-ID: <MWHPR0501MB38508E5F3C60FE7943DAFD92CA6F0@MWHPR0501MB3850.namprd05.prod.outlook.com>

In the fixed portion of the model, you would use the typical R conventions of ':' or '*'. So, as an example, x1:x2 on the RHS gives only the interaction between two variables and then the use of x1 * x2 gives both the interaction and main effects.



From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com]
Sent: Thursday, September 14, 2017 8:04 AM
To: Doran, Harold <HDoran at air.org>; Jake Westfall <jake.a.westfall at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Query


Thank you so much for your response. One question more.



I need estimate the interaction genotype x environment. How should I make this? The interaction between Checks and environment or between Testlines and environments?

Best regards,

Ezequiel Rossi
________________________________
De: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Enviado: mi?rcoles, 13 de septiembre de 2017 04:20 p.m.
Para: 'EZEQUIEL ROSSI'; Jake Westfall
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Asunto: RE: [R-sig-ME] Query

I can think of a few ways to do this; but perhaps a straightforward way is to estimate environment in a slightly different way than what you have below

lmer(Alt_Planta ~ 1 + (1|Environment) + (1|Bloque) + Checks + (1|Testlines), data = data)

This will give you the marginal variance between environments and then you can get the conditional variance of the conditional mean for each environment.


From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com]
Sent: Wednesday, September 13, 2017 3:05 PM
To: Jake Westfall <jake.a.westfall at gmail.com<mailto:jake.a.westfall at gmail.com>>; Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Query

My model is the follow:

lmer(Alt_Planta ~ Environment + (1|Bloque) + Checks + (1|Testlines), data = data)

where I have two environment and in each environment the design was a randomized complete block design with 3 replications for the Checks (30 genotypes) and the Testlines had one replications.

I need estimate the variance components for each environment and across environment. If you can help me with this, I will thank him very much.

Thank you very much,

Best regards,

Ezequiel Rossi

________________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> en nombre de Jake Westfall <jake.a.westfall at gmail.com<mailto:jake.a.westfall at gmail.com>>
Enviado: mi?rcoles, 13 de septiembre de 2017 03:46 p.m.
Para: Doran, Harold
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Query

Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Query
>
>
>    I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.  I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>   in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).  The latter is
> likely to be very expensive if f has more than a few levels.
>
>   Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From jbt27 at cam.ac.uk  Thu Sep 14 18:14:11 2017
From: jbt27 at cam.ac.uk (Jack Thorley)
Date: Thu, 14 Sep 2017 17:14:11 +0100
Subject: [R-sig-ME] =?utf-8?q?No_functions_in_the_glmmADMB_package=3F?=
Message-ID: <70e7208156c0be2b9bf0747d91ae54d7@cam.ac.uk>

Hi all,

I have been trying to install the glmmADMB package in order to run a 
binomial GLMM with zero inflation. After following the various 
suggestions on http://glmmadmb.r-forge.r-project.org/, whichever 
repository I selected returned the same error concerning non-zero 
status. For example:

    -  install.packages("glmmADMB", repos = 
"http://R-Forge.R-project.org")

    -    Warning in install.packages :
        running command '"C:/PROGRA~1/R/R-34~1.1/bin/x64/R" CMD INSTALL 
-l "C:\Users\jackt\Documents\R\win-library\3.4" 
C:\Users\jackt\AppData\Local\Temp\RtmpiYmfyc/downloaded_packages/glmmADMB_0.8.3.3.tar.gz' 
had status 65535
        Warning in install.packages :
        installation of package ?glmmADMB? had non-zero exit status


I thought I had got around the issue by installing locally from source 
via the zip file https://r-forge.r-project.org/R/?group_id=847  [version 
0.8.3.3], except I cannot run the glmmadmb function from the package, as 
it is not there.

Any suggestions to overcome these problems. I am running 3.4.1 on a 
windows 64-bit machine.

thanks in advance
Jack

-------------------------

PhD Student
Department of Zoology
University of Cambridge


From EZEQUIEL_455 at hotmail.com  Thu Sep 14 19:05:19 2017
From: EZEQUIEL_455 at hotmail.com (EZEQUIEL ROSSI)
Date: Thu, 14 Sep 2017 17:05:19 +0000
Subject: [R-sig-ME] Query
In-Reply-To: <MWHPR0501MB38508E5F3C60FE7943DAFD92CA6F0@MWHPR0501MB3850.namprd05.prod.outlook.com>
References: <DM3PR07MB22490533C3789D018CFC0E70BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>
 <c6feeffb-8b7c-7848-1526-8429e5fe65db@gmail.com>
 <MWHPR0501MB38507B5FB5F38645BE92F4A2CA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>,
 <CAE9_Wg6Hya2zOLjAvCg7_9A9-diJnFOkyW+Nf+qoi6TdRMPZfQ@mail.gmail.com>
 <DM3PR07MB2249ECB404FD54A2823D9AC5BA6E0@DM3PR07MB2249.namprd07.prod.outlook.com>,
 <MWHPR0501MB38504339D82CBA4375A48F9DCA6E0@MWHPR0501MB3850.namprd05.prod.outlook.com>
 <DM3PR07MB2249D74786A2BAC4CEBD9257BA6F0@DM3PR07MB2249.namprd07.prod.outlook.com>,
 <MWHPR0501MB38508E5F3C60FE7943DAFD92CA6F0@MWHPR0501MB3850.namprd05.prod.outlook.com>
Message-ID: <DM3PR07MB2249A060E7920E137541E378BA6F0@DM3PR07MB2249.namprd07.prod.outlook.com>

Thank you very much. Do you know if in this design the interaction should estimate with Testlines or with Checks?


Best regards,


Ezequiel Rossi


________________________________
De: Doran, Harold <HDoran at air.org>
Enviado: jueves, 14 de septiembre de 2017 12:49 p.m.
Para: 'EZEQUIEL ROSSI'; Jake Westfall
Cc: r-sig-mixed-models at r-project.org
Asunto: RE: [R-sig-ME] Query


In the fixed portion of the model, you would use the typical R conventions of ?:? or ?*?. So, as an example, x1:x2 on the RHS gives only the interaction between two variables and then the use of x1 * x2 gives both the interaction and main effects.







From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com]
Sent: Thursday, September 14, 2017 8:04 AM
To: Doran, Harold <HDoran at air.org>; Jake Westfall <jake.a.westfall at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Query



Thank you so much for your response. One question more.



I need estimate the interaction genotype x environment. How should I make this? The interaction between Checks and environment or between Testlines and environments?



Best regards,



Ezequiel Rossi

________________________________

De: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Enviado: mi?rcoles, 13 de septiembre de 2017 04:20 p.m.
Para: 'EZEQUIEL ROSSI'; Jake Westfall
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Asunto: RE: [R-sig-ME] Query



I can think of a few ways to do this; but perhaps a straightforward way is to estimate environment in a slightly different way than what you have below

lmer(Alt_Planta ~ 1 + (1|Environment) + (1|Bloque) + Checks + (1|Testlines), data = data)

This will give you the marginal variance between environments and then you can get the conditional variance of the conditional mean for each environment.


From: EZEQUIEL ROSSI [mailto:EZEQUIEL_455 at hotmail.com]
Sent: Wednesday, September 13, 2017 3:05 PM
To: Jake Westfall <jake.a.westfall at gmail.com<mailto:jake.a.westfall at gmail.com>>; Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Query

My model is the follow:

lmer(Alt_Planta ~ Environment + (1|Bloque) + Checks + (1|Testlines), data = data)

where I have two environment and in each environment the design was a randomized complete block design with 3 replications for the Checks (30 genotypes) and the Testlines had one replications.

I need estimate the variance components for each environment and across environment. If you can help me with this, I will thank him very much.

Thank you very much,

Best regards,

Ezequiel Rossi

________________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> en nombre de Jake Westfall <jake.a.westfall at gmail.com<mailto:jake.a.westfall at gmail.com>>
Enviado: mi?rcoles, 13 de septiembre de 2017 03:46 p.m.
Para: Doran, Harold
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Asunto: Re: [R-sig-ME] Query

Well in the old ANOVA-based mixed model framework we talk about
interactions between fixed and random factors, although in modern mixed
models we call those interactions "random slopes." (The coefficient for a
fixed predictor X "depends on" the level of the random factor.) So Ezequiel
could just be using the ANOVA-type terminology (used a lot in DoE) to refer
to random slopes.

Jake

On Wed, Sep 13, 2017 at 1:41 PM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> Perhaps a bit OT, but what *is* an interaction between a fixed and random
> factor? The fixed effects are estimates, BLUPs are not estimates really.
>
> I can't quite consider what the estimand is in this instance
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Wednesday, September 13, 2017 2:34 PM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Query
>
>
>    I'm going to say something here to get the conversation started, but
> this information comes with a giant caveat.  I hope that someone with more
> knowledge of experimental designs comes forward ...
>
>   in general an interaction between a random factor r and a fixed factor f
> is either
>
> (1|r:f)
>
> (assuming a positive, compound-symmetric variance-covariance matrix) or
>
> (f|r)
>
> (assuming an unstructured variance-covariance matrix).  The latter is
> likely to be very expensive if f has more than a few levels.
>
>   Interaction between two random factors would be (1|r1:r2) (you would
> have (1|r1) and (1|r2) in the model as well).
>
> On 17-09-13 02:12 PM, EZEQUIEL ROSSI wrote:
> > Dears,
> >
> >
> > I am working with a Federer's augmented block design in lmer function
> > and I need indicate interaction between ramdom and fixed factors and
> > between two ramdom factors . Can you say me how I should make this?
> >
> >
> > Thank you very much,
> >
> >
> > Best regards,
> >
> >
> > Ezequiel Rossi
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Sep 14 19:52:44 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Sep 2017 13:52:44 -0400
Subject: [R-sig-ME] No functions in the glmmADMB package?
In-Reply-To: <70e7208156c0be2b9bf0747d91ae54d7@cam.ac.uk>
References: <70e7208156c0be2b9bf0747d91ae54d7@cam.ac.uk>
Message-ID: <03e983c1-e642-9bb4-c0ff-f64761315186@gmail.com>


  The inability to install the package from r-forge is because
(probably) I forgot to update the repository structure since R 3.4.x
came out (binary packages are organized by major R release).

  When you downloaded the .zip file how did you install it?  If it was
really "from source", that wouldn't work (but I would think
install.packages(<zip file>, repos=NULL) should work.

  Did you remember library(glmmADMB) ?

  What does help(package=glmmADMB) say?

  Also: at present I'd recommend glmmTMB (on CRAN) as a better (same
capabilities or more, very similar interface, faster, more stable,
better maintained going forward) over glmmADMB.

 cheers
   Ben Bolker


On 17-09-14 12:14 PM, Jack Thorley wrote:
> Hi all,
> 
> I have been trying to install the glmmADMB package in order to run a
> binomial GLMM with zero inflation. After following the various
> suggestions on http://glmmadmb.r-forge.r-project.org/, whichever
> repository I selected returned the same error concerning non-zero
> status. For example:
> 
>    -  install.packages("glmmADMB", repos = "http://R-Forge.R-project.org")
> 
>    -    Warning in install.packages :
>        running command '"C:/PROGRA~1/R/R-34~1.1/bin/x64/R" CMD INSTALL
> -l "C:\Users\jackt\Documents\R\win-library\3.4"
> C:\Users\jackt\AppData\Local\Temp\RtmpiYmfyc/downloaded_packages/glmmADMB_0.8.3.3.tar.gz'
> had status 65535
>        Warning in install.packages :
>        installation of package ?glmmADMB? had non-zero exit status
> 
> 
> I thought I had got around the issue by installing locally from source
> via the zip file https://r-forge.r-project.org/R/?group_id=847  [version
> 0.8.3.3], except I cannot run the glmmadmb function from the package, as
> it is not there.
> 
> Any suggestions to overcome these problems. I am running 3.4.1 on a
> windows 64-bit machine.
> 
> thanks in advance
> Jack
> 
> -------------------------
> 
> PhD Student
> Department of Zoology
> University of Cambridge
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From flaviomoc at gmail.com  Fri Sep 15 00:45:34 2017
From: flaviomoc at gmail.com (=?UTF-8?B?RmzDoXZpbyBN?=)
Date: Thu, 14 Sep 2017 19:45:34 -0300
Subject: [R-sig-ME] How do I know if the lmer model is right?
Message-ID: <CAM1AygtqYbtkg-_b5RnxH7vh5SuVxGdCUOn2wsf4U--O8pwgUg@mail.gmail.com>

Dear Members,

Could you check if this analysis is right (compile attached)? I am not
familiarized with temporal variables. I am intent to find the equation to
calculate litter amount throught any value of ndvi. Both variables were
coleted monthly during three years.

I did not find a specific model for time series with two variables.
However, as they were collected every month in the same spots lmer should
works fine, right?

Best regards,
Flavio
-------------- next part --------------
library(readxl)
library(afex)
## Loading required package: lme4
## Loading required package: Matrix
## Loading required package: lsmeans
## Loading required package: estimability
## ************
## Welcome to afex. For support visit: http://afex.singmann.science/
## - Functions for ANOVAs: aov_car(), aov_ez(), and aov_4()
## - Methods for calculating p-values with mixed(): 'KR', 'S', 'LRT', and 'PB'
## - 'afex_aov' and 'mixed' objects can be passed to lsmeans() for follow-up tests
## - Get and set global package options with: afex_options()
## - Set orthogonal sum-to-zero contrasts globally: set_sum_contrasts()
## - For example analyses see: browseVignettes("afex")
## ************
## 
## Attaching package: 'afex'
## The following object is masked from 'package:lme4':
## 
##     lmer
data<-read_excel("ndvi3.xls")

data
## # A tibble: 432 x 6
##    month  year stage  plot        ndvi      litter
##    <dbl> <dbl> <chr> <dbl>       <dbl>       <dbl>
##  1     4     1 Early     1  0.30864501 -2.45986132
##  2     5     1 Early     1  0.17898780 -3.22690800
##  3     6     1 Early     1  0.00871899  0.07673787
##  4     7     1 Early     1 -0.20991200 -1.25453724
##  5     8     1 Early     1 -0.21325549 -2.76453008
##  6     9     1 Early     1 -0.21593250 -4.44981737
##  7    10     1 Early     1 -0.30416150 -4.19808639
##  8    11     1 Early     1 -0.10118885 -5.47412419
##  9    12     1 Early     1  0.22365620 -3.27540914
## 10     1     1 Early     1  0.31648629 -2.02710415
## # ... with 422 more rows
summary(data)
##      month            year      stage                plot     
##  Min.   : 1.00   Min.   :1   Length:432         Min.   :1.00  
##  1st Qu.: 3.75   1st Qu.:1   Class :character   1st Qu.:1.75  
##  Median : 6.50   Median :2   Mode  :character   Median :2.50  
##  Mean   : 6.50   Mean   :2                      Mean   :2.50  
##  3rd Qu.: 9.25   3rd Qu.:3                      3rd Qu.:3.25  
##  Max.   :12.00   Max.   :3                      Max.   :4.00  
##       ndvi              litter        
##  Min.   :-0.30416   Min.   :-5.47412  
##  1st Qu.:-0.17107   1st Qu.:-3.87032  
##  Median :-0.01833   Median :-3.00008  
##  Mean   : 0.00433   Mean   :-2.97930  
##  3rd Qu.: 0.18006   3rd Qu.:-2.24116  
##  Max.   : 0.34047   Max.   : 0.07674
m<-mixed(litter~ndvi*stage+(month|plot),data=data)
## Numerical variables NOT centered on 0 (i.e., interpretation of all main effects might be difficult if in interactions): ndvi
## Fitting one lmer() model. [DONE]
## Calculating p-values.
## Note: method with signature 'sparseMatrix#ANY' chosen for function 'kronecker',
##  target signature 'dgCMatrix#ngCMatrix'.
##  "ANY#sparseMatrix" would also be valid
## [DONE]
anova(m)
## Mixed Model Anova Table (Type 3 tests, KR-method)
## 
## Model: litter ~ ndvi * stage + (month | plot)
## Data: data
##            num Df den Df       F    Pr(>F)    
## ndvi            1 422.55 55.0619 6.473e-13 ***
## stage           2 419.25  8.1364 0.0003414 ***
## ndvi:stage      2 419.07 19.5316 7.761e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
summary(m)
## Linear mixed model fit by REML ['merModLmerTest']
## Formula: litter ~ ndvi * stage + (month | plot)
##    Data: data
## 
## REML criterion at convergence: 1348.8
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -1.72511 -0.65546 -0.07867  0.71961  2.43766 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  plot     (Intercept) 2.12254  1.4569        
##           month       0.05024  0.2241   -1.00
##  Residual             1.27952  1.1312        
## Number of obs: 432, groups:  plot, 4
## 
## Fixed effects:
##                        Estimate Std. Error t value
## (Intercept)            -2.78825    0.09599 -29.046
## ndvi                   -0.37417    0.44922  -0.833
## stageIntermediate      -0.57855    0.14344  -4.033
## stageLate              -0.24506    0.13505  -1.815
## ndvi:stageIntermediate -5.53375    0.91168  -6.070
## ndvi:stageLate         -2.00674    0.61924  -3.241
## 
## Correlation of Fixed Effects:
##             (Intr) ndvi   stgInt stagLt ndv:sI
## ndvi        -0.189                            
## stagIntrmdt -0.676  0.162                     
## stageLate   -0.708  0.121  0.476              
## ndv:stgIntr  0.075 -0.394  0.241 -0.055       
## ndvi:stagLt  0.118 -0.627 -0.083 -0.158  0.300

From miriam.alzate at unavarra.es  Tue Sep 19 00:25:03 2017
From: miriam.alzate at unavarra.es (miriam.alzate at unavarra.es)
Date: Tue, 19 Sep 2017 00:25:03 +0200
Subject: [R-sig-ME] ZINB model validation and interpretation
Message-ID: <7a1fb2d51795472cc3954f92ce9b10c5.squirrel@webmail.unavarra.es>

Hello,
I am working with a ZINB model in R. To validate it, I first did a VUONG
test to compare it with a standard NB model. The result is that the ZINB
is better than the NB. Then, I compared the ZINB to a ZIP model, comparing
the AIC index and the log-likelihood and I also get that the ZINB fits
better than the ZIP.

However, I would like to know if I should take other tests into
consideration to show the validity and robustness of my model.

On the other hand, I would like to know if I can interpret the
coefficients directly from the model result or I should compute the Odds
ratios.

Thanks a lot,

Miriam


From bbolker at gmail.com  Wed Sep 20 20:24:56 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Sep 2017 14:24:56 -0400
Subject: [R-sig-ME] ZINB model validation and interpretation
In-Reply-To: <7a1fb2d51795472cc3954f92ce9b10c5.squirrel@webmail.unavarra.es>
References: <7a1fb2d51795472cc3954f92ce9b10c5.squirrel@webmail.unavarra.es>
Message-ID: <CABghstTKAzCgwurDse4tEGSh68kwioz=tdttsmKtx0qzkLS1qA@mail.gmail.com>

This isn't actually a mixed-model question as far as I can tell, but
I'll take a stab at it.  (https://stats.stackexchange.com is probably
the best option for follow-ups, as R-help isn't for general statistics
questions.)

Your approach seems not-crazy to me, although I would probably be
lazier/slopper and compare all four cases (P, NB, ZIP, ZINB) in a
single AIC(c) table. In any case, there are very basic issues with
either P vs NB or ZIP vs ZINB tests based on any of the standard
approaches (Vuong, *IC, likelihood ratio test) that come from the fact
that one of the pair of models is on the boundary of the feasible
space, see e.g.
https://stats.stackexchange.com/questions/182020/zero-inflated-poisson-regression-vuong-test-raw-aic-or-bic-corrected-results/217869

For validity and robustness, I would suggest more "impressionistic"
diagnostics (inspect residuals for independence of predictors, lack of
heteroscedasticity; look for influential/outlier residuals; compare
patterns of predictions with patterns in raw data for evidence of
unexpected patterns). If you want more formal tests, try generating
posterior predictive simulations of quantities that are important to
you and see if they match the observed values of those quantities.

On Mon, Sep 18, 2017 at 6:25 PM,  <miriam.alzate at unavarra.es> wrote:
> Hello,
> I am working with a ZINB model in R. To validate it, I first did a VUONG
> test to compare it with a standard NB model. The result is that the ZINB
> is better than the NB. Then, I compared the ZINB to a ZIP model, comparing
> the AIC index and the log-likelihood and I also get that the ZINB fits
> better than the ZIP.
>
> However, I would like to know if I should take other tests into
> consideration to show the validity and robustness of my model.
>
> On the other hand, I would like to know if I can interpret the
> coefficients directly from the model result or I should compute the Odds
> ratios.
>
> Thanks a lot,
>
> Miriam
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cddesjardins at gmail.com  Wed Sep 20 20:32:48 2017
From: cddesjardins at gmail.com (Christopher David Desjardins)
Date: Wed, 20 Sep 2017 11:32:48 -0700
Subject: [R-sig-ME] ZINB model validation and interpretation
In-Reply-To: <CABghstTKAzCgwurDse4tEGSh68kwioz=tdttsmKtx0qzkLS1qA@mail.gmail.com>
References: <7a1fb2d51795472cc3954f92ce9b10c5.squirrel@webmail.unavarra.es>
 <CABghstTKAzCgwurDse4tEGSh68kwioz=tdttsmKtx0qzkLS1qA@mail.gmail.com>
Message-ID: <CALrjt7-VnZZeq9kZBUqTjrZ4Zm+M1ir3X1hhpWM+vc-o9o+zWw@mail.gmail.com>

Hi Miriam,

As Ben mentioned, this isn't a mixed effects model. But what you've done is
reasonable and would second Ben's framework for investigating your model.

I am assuming you're using the pscl library? If so, Achim Zeileis has a
vignette that goes over these models which you might find helpful:
http://ftp.uni-bayreuth.de/math/statlib/R/CRAN/doc/vignettes/pscl/countreg.pdf
.

I investigated these models under simulation in my dissertation and if
you've like more references or have specific question, please feel free to
contact me off list.
Chris


On Wed, Sep 20, 2017 at 11:24 AM, Ben Bolker <bbolker at gmail.com> wrote:

> This isn't actually a mixed-model question as far as I can tell, but
> I'll take a stab at it.  (https://stats.stackexchange.com is probably
> the best option for follow-ups, as R-help isn't for general statistics
> questions.)
>
> Your approach seems not-crazy to me, although I would probably be
> lazier/slopper and compare all four cases (P, NB, ZIP, ZINB) in a
> single AIC(c) table. In any case, there are very basic issues with
> either P vs NB or ZIP vs ZINB tests based on any of the standard
> approaches (Vuong, *IC, likelihood ratio test) that come from the fact
> that one of the pair of models is on the boundary of the feasible
> space, see e.g.
> https://stats.stackexchange.com/questions/182020/zero-
> inflated-poisson-regression-vuong-test-raw-aic-or-bic-
> corrected-results/217869
>
> For validity and robustness, I would suggest more "impressionistic"
> diagnostics (inspect residuals for independence of predictors, lack of
> heteroscedasticity; look for influential/outlier residuals; compare
> patterns of predictions with patterns in raw data for evidence of
> unexpected patterns). If you want more formal tests, try generating
> posterior predictive simulations of quantities that are important to
> you and see if they match the observed values of those quantities.
>
> On Mon, Sep 18, 2017 at 6:25 PM,  <miriam.alzate at unavarra.es> wrote:
> > Hello,
> > I am working with a ZINB model in R. To validate it, I first did a VUONG
> > test to compare it with a standard NB model. The result is that the ZINB
> > is better than the NB. Then, I compared the ZINB to a ZIP model,
> comparing
> > the AIC index and the log-likelihood and I also get that the ZINB fits
> > better than the ZIP.
> >
> > However, I would like to know if I should take other tests into
> > consideration to show the validity and robustness of my model.
> >
> > On the other hand, I would like to know if I can interpret the
> > coefficients directly from the model result or I should compute the Odds
> > ratios.
> >
> > Thanks a lot,
> >
> > Miriam
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
https://cddesja.github.io/

	[[alternative HTML version deleted]]


From chrishold at psyctc.org  Thu Sep 21 11:29:11 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Thu, 21 Sep 2017 10:29:11 +0100 (BST)
Subject: [R-sig-ME] Failing to understand effect of centering a predictor in
 multilevel model
Message-ID: <81508081.26500897.1505986151718.JavaMail.zimbra@psyctc.org>

I am trying to make sure I understand the use of multilevel modelling to look at change (on questionnaire scores) across sessions of psychotherapy. This is widely done in my applied field. I am a researcher (and ex-therapist) not a statistician and have no direct availability of a statistician but I'm fairly savvy about stats. I am simulating, rather crudely, data which have both fixed and random intercepts and slopes with a quadratic as well as a linear effect of session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R 3.4.1 on Windoze running in Rstudio. 

The thing that's baffling me is that centering my predictor (session count) seems to have NO effect on my results, neither on the fixed nor the random effects. I would have expected the intercept to have changed at the very least given the effects I've simulated. 

Details: session count can range from 1 to 51 (the number of sessions per client in my simulation can vary, realistically, from 4 to 51 so no client has fewer than four). I have modelled in a random linear and quadratic effect of session count but such that the overall effects are both negative. Code and session info are at the end of the post. Here is code and output from uncentred: 

m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID), 
data=longdat4) 
summary(m4) 

## Linear mixed model fit by REML t-tests use Satterthwaite approximations 
## to degrees of freedom [lmerMod] 
## Formula: 
## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID) 
## Data: longdat4 
## 
## REML criterion at convergence: -29507 
## 
## Scaled residuals: 
## Min 1Q Median 3Q Max 
## -3.6274 -0.6583 0.0035 0.6420 4.0849 
## 
## Random effects: 
## Groups Name Variance Std.Dev. Corr 
## validPOC_ID (Intercept) 9.309e+00 3.05101 
## poly(session, 2)1 7.390e+03 85.96686 0.20 
## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00 
## Residual 4.973e-03 0.07052 
## Number of obs: 15399, groups: validPOC_ID, 500 
## 
## Fixed effects: 
## Estimate Std. Error df t value Pr(>|t|) 
## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 *** 
## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 *** 
## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 *** 
## --- 
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
## 
## Correlation of Fixed Effects: 
## (Intr) p(,2)1 
## ply(sss,2)1 0.210 
## ply(sss,2)2 0.215 0.995 

Here is the centered one (lengthCentre is 29.5). 

longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $ sessionC1 ) 
## Min. 1st Qu. Median Mean 3rd Qu. Max. 
## -28.50 -21.50 -12.50 -10.09 -0.50 21.50 
m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) | validPOC_ID ) , data = longdat4 ) summary ( m5 ) 
## Linear mixed model fit by REML t-tests use Satterthwaite approximations 
## to degrees of freedom [lmerMod] 
## Formula: 
## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID) 
## Data: longdat4 
## 
## REML criterion at convergence: -29507 
## 
## Scaled residuals: 
## Min 1Q Median 3Q Max 
## -3.6274 -0.6583 0.0035 0.6420 4.0849 
## 
## Random effects: 
## Groups Name Variance Std.Dev. Corr 
## validPOC_ID (Intercept) 9.309e+00 3.05101 
## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20 
## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00 
## Residual 4.973e-03 0.07052 
## Number of obs: 15399, groups: validPOC_ID, 500 
## 
## Fixed effects: 
## Estimate Std. Error df t value Pr(>|t|) 
## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 *** 
## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 *** 
## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 *** 
## --- 
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
## 
## Correlation of Fixed Effects: 
## (Intr) p(C1,2)1 
## ply(sC1,2)1 0.210 
## ply(sC1,2)2 0.215 0.995 

This makes no sense to me. I had expected that the very crude centering must shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong linear and quadratic effects in the model. I also thought (the whole reason I'm doing this) that it would change the correlation between the linear and quadratic terms as I should be moving from a strong positive correlation between them to a much smaller one. 

I'm sure I'm doing something utterly stupid, or revealing shocking failure to comprehend the multilevel model, but I'm looking straight through the explanation and stuck. I hope someone will help me! 

TIA, 


Chris 



Here is entire pertinent code. 

```{r sim4,warning=FALSE,message=FALSE,cache=TRUE} 
require(reshape2) 
set.seed(12345) 
### set up the parameters for the simulation 
n <- 500 
minNSessions <- 4 
maxNSessions <- 55 
linSlope <- -.02 
errVar <- .005 
### derived variables 
lengthRange <- minNSessions:maxNSessions 
lengthCentre <- (minNSessions+maxNSessions)/2 
ID <- 1:n 
### create a variable, length = n for the session counts 
sessions <- sample(lengthRange,n,replace=TRUE) 
### for now, give all starting scores of 10 
startScores <- rnorm(n,mean=10,sd=3) 
slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes 
### set up matrix to store the simulated scores 
scores <- matrix(rep(NA,n*maxNSessions),nrow=n) 
dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores)) 
for (i in 1:nrow(dat4)) { 
nSessions <- dat4$sessions[i] 
tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes 
tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear effect 
tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic effect 
tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error 
dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame 
} 
### now melt to create a long data frame 
longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55) 
colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL") 
longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get start at 1 
# as data start in column 5 
longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),] 
longdat4 <- na.omit(longdat4) # ditch the empty data 
``` 

So the data frame longdat4 has 
`r nrow(longdat4)` rows and 
`r ncol(longdat4)` columns and the column names are 
`r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4) and the head of the long one (longdat4). 

```{r head4,warning=FALSE,message=FALSE,cache=TRUE} 
require(knitr) 
kable(head(dat4[,1:10]),digits=3) 
kable(head(longdat4)) 
``` 

Elisa's lattice plot. 

```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE} 
library(lattice) 
samp <- sample(unique(longdat4$validPOC_ID), 35) 
xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4, 
type = c("p","g","r"), 
subset = (validPOC_ID %in% samp), 
col="dark blue", 
col.line="black", 
strip = F, 
xlab = "Weeks in treatment", 
ylab = "Depression Scores") 
``` 

Now Elisa's tangle plot. Just first 40 simulated cases. 

```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE} 
library(ggplot2) 
first40 <- longdat4[longdat4$validPOC_ID <=40,] 
tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) + 
geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) + 
theme_bw() 
tanglePlot 
``` 

```{r model4, warning=FALSE, message=FALSE,cache=TRUE} 
require(lmerTest) 
### this next fails to converge and has perfect correlation of linear & quadratic effects 
# m4 <- lmer(DEP_TOTAL ~ session+I(session^2)+(1+session+I(session^2)|validPOC_ID), 
# data=longdat4) 
### is this better: 
summary(longdat4$session) 
hist(longdat4$session, 
main="Histogram of raw session counts", 
xlab="Raw session n", 
col="grey") 
m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID), 
data=longdat4) 
summary(m4) 
``` 

This next should test the random effect (and should find it highly significant I think). 

```{r mode4rand,eval=FALSE} 
rand(m4) 
### fails with message: 
### Error in terms.formula(tmp, simplify = TRUE) : 
### invalid model formula in ExtractVars 
``` 

And this summarises the random effects. These are deviations from the fixed effects so both are centred on zero. 

```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE} 
apply(ranef(m4)$validPOC_ID,2,summary) 
par(mfrow=c(1,3)) 
hist(ranef(m4)$validPOC_ID[,1], 
xlab="Intercept deviation values", 
main="Random intercepts", 
col="grey") 
abline(v=0) 
hist(ranef(m4)$validPOC_ID[,2], 
main="Random slopes", 
xlab="Linear slope deviation values", 
col="grey") 
abline(v=0) 
hist(ranef(m4)$validPOC_ID[,3], 
main="Random slopes", 
xlab="Quadratic slope deviation values", 
col="grey") 
abline(v=0) 
``` 


# Simulation 5: random intercept and random slope with quadratic effect, CENTRED 

OK. Random intercept and slope has linear and quadratic effects. Now going to centre the session count by subtracting lengthCentre 


```{r model5, warning=FALSE, message=FALSE} 
longdat4$sessionC1 <- longdat4$session - lengthCentre 
summary(longdat4$sessionC1) 
hist(longdat4$sessionC1, 
main="Histogram of centred session counts", 
xlab="Centred session n", 
col="grey") 
abline(v=0) 
require(lmerTest) 
m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID), 
data=longdat4) 
summary(m5) 
``` 



```{r mode5rand,eval=FALSE} 
rand(m5) 
### fails with message: 
### Error in terms.formula(tmp, simplify = TRUE) : 
### invalid model formula in ExtractVars 
``` 


```{r coeffs5,fig.width=11,fig.height=8} 
apply(ranef(m5)$validPOC_ID,2,summary) 
par(mfrow=c(1,3)) 
hist(ranef(m5)$validPOC_ID[,1], 
xlab="Intercept deviation values", 
main="Random intercepts", 
col="grey") 
abline(v=0) 
hist(ranef(m5)$validPOC_ID[,2], 
main="Random slopes", 
xlab="Linear slope deviation values", 
col="grey") 
abline(v=0) 
hist(ranef(m5)$validPOC_ID[,3], 
main="Random slopes", 
xlab="Quadratic slope deviation values", 
col="grey") 
abline(v=0) 
``` 

And here is sessionInfo() 

> sessionInfo() 
R version 3.4.1 (2017-06-30) 
Platform: x86_64-w64-mingw32/x64 (64-bit) 
Running under: Windows >= 8 x64 (build 9200) 

Matrix products: default 

locale: 
[1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C 
[5] LC_TIME=English_United Kingdom.1252 

attached base packages: 
[1] stats graphics grDevices utils datasets methods base 

other attached packages: 
[1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13 
[6] Matrix_1.2-11 reshape2_1.4.2 

loaded via a namespace (and not attached): 
[1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1 
[5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1 
[9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9 
[13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0 
[17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6 
[21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2 
[25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69 
[29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2 
[33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0 
[37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5 
[41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1 
[45] lazyeval_0.2.0 munsell_0.4.3 
> 


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Sep 21 11:36:40 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 21 Sep 2017 11:36:40 +0200
Subject: [R-sig-ME] Failing to understand effect of centering a
 predictor in multilevel model
In-Reply-To: <81508081.26500897.1505986151718.JavaMail.zimbra@psyctc.org>
References: <81508081.26500897.1505986151718.JavaMail.zimbra@psyctc.org>
Message-ID: <CAJuCY5wr+jD5_vU1SVdVBT2FbuWH2wMOVCPLDR9gdXzJYgCA8A@mail.gmail.com>

Dear Chris,

This is because you use poly() on all variables

x <- 10:20
cx <- x - mean(x)
all.equal(poly(x, 2), poly(cx, 2), check.attributes = FALSE)
all.equal(poly(x, 2), poly(cx, 2))

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-21 11:29 GMT+02:00 Chris Evans <chrishold at psyctc.org>:
> I am trying to make sure I understand the use of multilevel modelling to look at change (on questionnaire scores) across sessions of psychotherapy. This is widely done in my applied field. I am a researcher (and ex-therapist) not a statistician and have no direct availability of a statistician but I'm fairly savvy about stats. I am simulating, rather crudely, data which have both fixed and random intercepts and slopes with a quadratic as well as a linear effect of session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R 3.4.1 on Windoze running in Rstudio.
>
> The thing that's baffling me is that centering my predictor (session count) seems to have NO effect on my results, neither on the fixed nor the random effects. I would have expected the intercept to have changed at the very least given the effects I've simulated.
>
> Details: session count can range from 1 to 51 (the number of sessions per client in my simulation can vary, realistically, from 4 to 51 so no client has fewer than four). I have modelled in a random linear and quadratic effect of session count but such that the overall effects are both negative. Code and session info are at the end of the post. Here is code and output from uncentred:
>
> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
> data=longdat4)
> summary(m4)
>
> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
> ## to degrees of freedom [lmerMod]
> ## Formula:
> ## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID)
> ## Data: longdat4
> ##
> ## REML criterion at convergence: -29507
> ##
> ## Scaled residuals:
> ## Min 1Q Median 3Q Max
> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
> ##
> ## Random effects:
> ## Groups Name Variance Std.Dev. Corr
> ## validPOC_ID (Intercept) 9.309e+00 3.05101
> ## poly(session, 2)1 7.390e+03 85.96686 0.20
> ## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00
> ## Residual 4.973e-03 0.07052
> ## Number of obs: 15399, groups: validPOC_ID, 500
> ##
> ## Fixed effects:
> ## Estimate Std. Error df t value Pr(>|t|)
> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
> ## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
> ## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
> ## ---
> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ##
> ## Correlation of Fixed Effects:
> ## (Intr) p(,2)1
> ## ply(sss,2)1 0.210
> ## ply(sss,2)2 0.215 0.995
>
> Here is the centered one (lengthCentre is 29.5).
>
> longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $ sessionC1 )
> ## Min. 1st Qu. Median Mean 3rd Qu. Max.
> ## -28.50 -21.50 -12.50 -10.09 -0.50 21.50
> m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) | validPOC_ID ) , data = longdat4 ) summary ( m5 )
> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
> ## to degrees of freedom [lmerMod]
> ## Formula:
> ## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID)
> ## Data: longdat4
> ##
> ## REML criterion at convergence: -29507
> ##
> ## Scaled residuals:
> ## Min 1Q Median 3Q Max
> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
> ##
> ## Random effects:
> ## Groups Name Variance Std.Dev. Corr
> ## validPOC_ID (Intercept) 9.309e+00 3.05101
> ## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20
> ## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00
> ## Residual 4.973e-03 0.07052
> ## Number of obs: 15399, groups: validPOC_ID, 500
> ##
> ## Fixed effects:
> ## Estimate Std. Error df t value Pr(>|t|)
> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
> ## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
> ## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
> ## ---
> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ##
> ## Correlation of Fixed Effects:
> ## (Intr) p(C1,2)1
> ## ply(sC1,2)1 0.210
> ## ply(sC1,2)2 0.215 0.995
>
> This makes no sense to me. I had expected that the very crude centering must shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong linear and quadratic effects in the model. I also thought (the whole reason I'm doing this) that it would change the correlation between the linear and quadratic terms as I should be moving from a strong positive correlation between them to a much smaller one.
>
> I'm sure I'm doing something utterly stupid, or revealing shocking failure to comprehend the multilevel model, but I'm looking straight through the explanation and stuck. I hope someone will help me!
>
> TIA,
>
>
> Chris
>
>
>
> Here is entire pertinent code.
>
> ```{r sim4,warning=FALSE,message=FALSE,cache=TRUE}
> require(reshape2)
> set.seed(12345)
> ### set up the parameters for the simulation
> n <- 500
> minNSessions <- 4
> maxNSessions <- 55
> linSlope <- -.02
> errVar <- .005
> ### derived variables
> lengthRange <- minNSessions:maxNSessions
> lengthCentre <- (minNSessions+maxNSessions)/2
> ID <- 1:n
> ### create a variable, length = n for the session counts
> sessions <- sample(lengthRange,n,replace=TRUE)
> ### for now, give all starting scores of 10
> startScores <- rnorm(n,mean=10,sd=3)
> slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes
> ### set up matrix to store the simulated scores
> scores <- matrix(rep(NA,n*maxNSessions),nrow=n)
> dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores))
> for (i in 1:nrow(dat4)) {
> nSessions <- dat4$sessions[i]
> tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes
> tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear effect
> tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic effect
> tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error
> dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame
> }
> ### now melt to create a long data frame
> longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55)
> colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL")
> longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get start at 1
> # as data start in column 5
> longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),]
> longdat4 <- na.omit(longdat4) # ditch the empty data
> ```
>
> So the data frame longdat4 has
> `r nrow(longdat4)` rows and
> `r ncol(longdat4)` columns and the column names are
> `r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4) and the head of the long one (longdat4).
>
> ```{r head4,warning=FALSE,message=FALSE,cache=TRUE}
> require(knitr)
> kable(head(dat4[,1:10]),digits=3)
> kable(head(longdat4))
> ```
>
> Elisa's lattice plot.
>
> ```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE}
> library(lattice)
> samp <- sample(unique(longdat4$validPOC_ID), 35)
> xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4,
> type = c("p","g","r"),
> subset = (validPOC_ID %in% samp),
> col="dark blue",
> col.line="black",
> strip = F,
> xlab = "Weeks in treatment",
> ylab = "Depression Scores")
> ```
>
> Now Elisa's tangle plot. Just first 40 simulated cases.
>
> ```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE}
> library(ggplot2)
> first40 <- longdat4[longdat4$validPOC_ID <=40,]
> tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) +
> geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) +
> theme_bw()
> tanglePlot
> ```
>
> ```{r model4, warning=FALSE, message=FALSE,cache=TRUE}
> require(lmerTest)
> ### this next fails to converge and has perfect correlation of linear & quadratic effects
> # m4 <- lmer(DEP_TOTAL ~ session+I(session^2)+(1+session+I(session^2)|validPOC_ID),
> # data=longdat4)
> ### is this better:
> summary(longdat4$session)
> hist(longdat4$session,
> main="Histogram of raw session counts",
> xlab="Raw session n",
> col="grey")
> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
> data=longdat4)
> summary(m4)
> ```
>
> This next should test the random effect (and should find it highly significant I think).
>
> ```{r mode4rand,eval=FALSE}
> rand(m4)
> ### fails with message:
> ### Error in terms.formula(tmp, simplify = TRUE) :
> ### invalid model formula in ExtractVars
> ```
>
> And this summarises the random effects. These are deviations from the fixed effects so both are centred on zero.
>
> ```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE}
> apply(ranef(m4)$validPOC_ID,2,summary)
> par(mfrow=c(1,3))
> hist(ranef(m4)$validPOC_ID[,1],
> xlab="Intercept deviation values",
> main="Random intercepts",
> col="grey")
> abline(v=0)
> hist(ranef(m4)$validPOC_ID[,2],
> main="Random slopes",
> xlab="Linear slope deviation values",
> col="grey")
> abline(v=0)
> hist(ranef(m4)$validPOC_ID[,3],
> main="Random slopes",
> xlab="Quadratic slope deviation values",
> col="grey")
> abline(v=0)
> ```
>
>
> # Simulation 5: random intercept and random slope with quadratic effect, CENTRED
>
> OK. Random intercept and slope has linear and quadratic effects. Now going to centre the session count by subtracting lengthCentre
>
>
> ```{r model5, warning=FALSE, message=FALSE}
> longdat4$sessionC1 <- longdat4$session - lengthCentre
> summary(longdat4$sessionC1)
> hist(longdat4$sessionC1,
> main="Histogram of centred session counts",
> xlab="Centred session n",
> col="grey")
> abline(v=0)
> require(lmerTest)
> m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID),
> data=longdat4)
> summary(m5)
> ```
>
>
>
> ```{r mode5rand,eval=FALSE}
> rand(m5)
> ### fails with message:
> ### Error in terms.formula(tmp, simplify = TRUE) :
> ### invalid model formula in ExtractVars
> ```
>
>
> ```{r coeffs5,fig.width=11,fig.height=8}
> apply(ranef(m5)$validPOC_ID,2,summary)
> par(mfrow=c(1,3))
> hist(ranef(m5)$validPOC_ID[,1],
> xlab="Intercept deviation values",
> main="Random intercepts",
> col="grey")
> abline(v=0)
> hist(ranef(m5)$validPOC_ID[,2],
> main="Random slopes",
> xlab="Linear slope deviation values",
> col="grey")
> abline(v=0)
> hist(ranef(m5)$validPOC_ID[,3],
> main="Random slopes",
> xlab="Quadratic slope deviation values",
> col="grey")
> abline(v=0)
> ```
>
> And here is sessionInfo()
>
>> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13
> [6] Matrix_1.2-11 reshape2_1.4.2
>
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1
> [5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1
> [9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9
> [13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0
> [17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6
> [21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2
> [25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69
> [29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2
> [33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0
> [37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5
> [41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1
> [45] lazyeval_0.2.0 munsell_0.4.3
>>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chrishold at psyctc.org  Thu Sep 21 12:22:06 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Thu, 21 Sep 2017 11:22:06 +0100 (BST)
Subject: [R-sig-ME] Failing to understand effect of centering a
 predictor in multilevel model
In-Reply-To: <CAJuCY5wr+jD5_vU1SVdVBT2FbuWH2wMOVCPLDR9gdXzJYgCA8A@mail.gmail.com>
References: <81508081.26500897.1505986151718.JavaMail.zimbra@psyctc.org>
 <CAJuCY5wr+jD5_vU1SVdVBT2FbuWH2wMOVCPLDR9gdXzJYgCA8A@mail.gmail.com>
Message-ID: <1833960877.26538753.1505989326855.JavaMail.zimbra@psyctc.org>

Oh dear, many, many thanks Thierry,

Of course.  I knew it must be something idiotic I was doing. 

I think what had thrown me off from seeing that was the correlations in the fixed and random estimates.  As I read them (see output in my original post), the correlation between the fixed estimates of the linear and quadratic terms came out as .995 and the correlation for the random effects as 1.0  I had, perhaps naively, assumed that with linear and quadratic effects built into the population model with x (sessions) all positive would have inevitable strong collinearity and that was what I was seeing in the raw run and that centering would reduce it.  

I think, in some stupid way, I had just forgotten that the use of poly() (instead of "+ session + I(session^2)" ?) was transforming things in a way that makes any linear transform of session irrelevent (as you nicely point out!)

So, can I put three more short follow up questions here:
1) am I reading those correlations correctly?
2) if so, then clearly I've misunderstood poly(): I thought it would have created essentially uncorrelated predictors, and cor(cbind(x,x^2,poly(x,2)) from your example seems to fit with that.  I thought that would have reduced or removed the inevitable collinearity of a linear and a quadratic effect and correlations of .995 and 1.0 seem not very reduced!
3) can you or someone point me to reading on how to interpret the correlations as warnings of possibly misleading estimates?

TIA,

Chris


----- Original Message -----
> From: "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Thursday, 21 September, 2017 10:36:40
> Subject: Re: [R-sig-ME] Failing to understand effect of centering a predictor in multilevel model

> Dear Chris,
> 
> This is because you use poly() on all variables
> 
> x <- 10:20
> cx <- x - mean(x)
> all.equal(poly(x, 2), poly(cx, 2), check.attributes = FALSE)
> all.equal(poly(x, 2), poly(cx, 2))
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus/ Statiscian
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 2017-09-21 11:29 GMT+02:00 Chris Evans <chrishold at psyctc.org>:
>> I am trying to make sure I understand the use of multilevel modelling to look at
>> change (on questionnaire scores) across sessions of psychotherapy. This is
>> widely done in my applied field. I am a researcher (and ex-therapist) not a
>> statistician and have no direct availability of a statistician but I'm fairly
>> savvy about stats. I am simulating, rather crudely, data which have both fixed
>> and random intercepts and slopes with a quadratic as well as a linear effect of
>> session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R
>> 3.4.1 on Windoze running in Rstudio.
>>
>> The thing that's baffling me is that centering my predictor (session count)
>> seems to have NO effect on my results, neither on the fixed nor the random
>> effects. I would have expected the intercept to have changed at the very least
>> given the effects I've simulated.
>>
>> Details: session count can range from 1 to 51 (the number of sessions per client
>> in my simulation can vary, realistically, from 4 to 51 so no client has fewer
>> than four). I have modelled in a random linear and quadratic effect of session
>> count but such that the overall effects are both negative. Code and session
>> info are at the end of the post. Here is code and output from uncentred:
>>
>> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
>> data=longdat4)
>> summary(m4)
>>
>> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
>> ## to degrees of freedom [lmerMod]
>> ## Formula:
>> ## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID)
>> ## Data: longdat4
>> ##
>> ## REML criterion at convergence: -29507
>> ##
>> ## Scaled residuals:
>> ## Min 1Q Median 3Q Max
>> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
>> ##
>> ## Random effects:
>> ## Groups Name Variance Std.Dev. Corr
>> ## validPOC_ID (Intercept) 9.309e+00 3.05101
>> ## poly(session, 2)1 7.390e+03 85.96686 0.20
>> ## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00
>> ## Residual 4.973e-03 0.07052
>> ## Number of obs: 15399, groups: validPOC_ID, 500
>> ##
>> ## Fixed effects:
>> ## Estimate Std. Error df t value Pr(>|t|)
>> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
>> ## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
>> ## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
>> ## ---
>> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> ##
>> ## Correlation of Fixed Effects:
>> ## (Intr) p(,2)1
>> ## ply(sss,2)1 0.210
>> ## ply(sss,2)2 0.215 0.995
>>
>> Here is the centered one (lengthCentre is 29.5).
>>
>> longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $
>> sessionC1 )
>> ## Min. 1st Qu. Median Mean 3rd Qu. Max.
>> ## -28.50 -21.50 -12.50 -10.09 -0.50 21.50
>> m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) |
>> validPOC_ID ) , data = longdat4 ) summary ( m5 )
>> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
>> ## to degrees of freedom [lmerMod]
>> ## Formula:
>> ## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID)
>> ## Data: longdat4
>> ##
>> ## REML criterion at convergence: -29507
>> ##
>> ## Scaled residuals:
>> ## Min 1Q Median 3Q Max
>> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
>> ##
>> ## Random effects:
>> ## Groups Name Variance Std.Dev. Corr
>> ## validPOC_ID (Intercept) 9.309e+00 3.05101
>> ## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20
>> ## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00
>> ## Residual 4.973e-03 0.07052
>> ## Number of obs: 15399, groups: validPOC_ID, 500
>> ##
>> ## Fixed effects:
>> ## Estimate Std. Error df t value Pr(>|t|)
>> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
>> ## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
>> ## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
>> ## ---
>> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> ##
>> ## Correlation of Fixed Effects:
>> ## (Intr) p(C1,2)1
>> ## ply(sC1,2)1 0.210
>> ## ply(sC1,2)2 0.215 0.995
>>
>> This makes no sense to me. I had expected that the very crude centering must
>> shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong
>> linear and quadratic effects in the model. I also thought (the whole reason I'm
>> doing this) that it would change the correlation between the linear and
>> quadratic terms as I should be moving from a strong positive correlation
>> between them to a much smaller one.
>>
>> I'm sure I'm doing something utterly stupid, or revealing shocking failure to
>> comprehend the multilevel model, but I'm looking straight through the
>> explanation and stuck. I hope someone will help me!
>>
>> TIA,
>>
>>
>> Chris
>>
>>
>>
>> Here is entire pertinent code.
>>
>> ```{r sim4,warning=FALSE,message=FALSE,cache=TRUE}
>> require(reshape2)
>> set.seed(12345)
>> ### set up the parameters for the simulation
>> n <- 500
>> minNSessions <- 4
>> maxNSessions <- 55
>> linSlope <- -.02
>> errVar <- .005
>> ### derived variables
>> lengthRange <- minNSessions:maxNSessions
>> lengthCentre <- (minNSessions+maxNSessions)/2
>> ID <- 1:n
>> ### create a variable, length = n for the session counts
>> sessions <- sample(lengthRange,n,replace=TRUE)
>> ### for now, give all starting scores of 10
>> startScores <- rnorm(n,mean=10,sd=3)
>> slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes
>> ### set up matrix to store the simulated scores
>> scores <- matrix(rep(NA,n*maxNSessions),nrow=n)
>> dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores))
>> for (i in 1:nrow(dat4)) {
>> nSessions <- dat4$sessions[i]
>> tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes
>> tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear
>> effect
>> tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic
>> effect
>> tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error
>> dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame
>> }
>> ### now melt to create a long data frame
>> longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55)
>> colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL")
>> longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get
>> start at 1
>> # as data start in column 5
>> longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),]
>> longdat4 <- na.omit(longdat4) # ditch the empty data
>> ```
>>
>> So the data frame longdat4 has
>> `r nrow(longdat4)` rows and
>> `r ncol(longdat4)` columns and the column names are
>> `r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4)
>> and the head of the long one (longdat4).
>>
>> ```{r head4,warning=FALSE,message=FALSE,cache=TRUE}
>> require(knitr)
>> kable(head(dat4[,1:10]),digits=3)
>> kable(head(longdat4))
>> ```
>>
>> Elisa's lattice plot.
>>
>> ```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE}
>> library(lattice)
>> samp <- sample(unique(longdat4$validPOC_ID), 35)
>> xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4,
>> type = c("p","g","r"),
>> subset = (validPOC_ID %in% samp),
>> col="dark blue",
>> col.line="black",
>> strip = F,
>> xlab = "Weeks in treatment",
>> ylab = "Depression Scores")
>> ```
>>
>> Now Elisa's tangle plot. Just first 40 simulated cases.
>>
>> ```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE}
>> library(ggplot2)
>> first40 <- longdat4[longdat4$validPOC_ID <=40,]
>> tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) +
>> geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) +
>> theme_bw()
>> tanglePlot
>> ```
>>
>> ```{r model4, warning=FALSE, message=FALSE,cache=TRUE}
>> require(lmerTest)
>> ### this next fails to converge and has perfect correlation of linear &
>> quadratic effects
>> # m4 <- lmer(DEP_TOTAL ~
>> session+I(session^2)+(1+session+I(session^2)|validPOC_ID),
>> # data=longdat4)
>> ### is this better:
>> summary(longdat4$session)
>> hist(longdat4$session,
>> main="Histogram of raw session counts",
>> xlab="Raw session n",
>> col="grey")
>> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
>> data=longdat4)
>> summary(m4)
>> ```
>>
>> This next should test the random effect (and should find it highly significant I
>> think).
>>
>> ```{r mode4rand,eval=FALSE}
>> rand(m4)
>> ### fails with message:
>> ### Error in terms.formula(tmp, simplify = TRUE) :
>> ### invalid model formula in ExtractVars
>> ```
>>
>> And this summarises the random effects. These are deviations from the fixed
>> effects so both are centred on zero.
>>
>> ```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE}
>> apply(ranef(m4)$validPOC_ID,2,summary)
>> par(mfrow=c(1,3))
>> hist(ranef(m4)$validPOC_ID[,1],
>> xlab="Intercept deviation values",
>> main="Random intercepts",
>> col="grey")
>> abline(v=0)
>> hist(ranef(m4)$validPOC_ID[,2],
>> main="Random slopes",
>> xlab="Linear slope deviation values",
>> col="grey")
>> abline(v=0)
>> hist(ranef(m4)$validPOC_ID[,3],
>> main="Random slopes",
>> xlab="Quadratic slope deviation values",
>> col="grey")
>> abline(v=0)
>> ```
>>
>>
>> # Simulation 5: random intercept and random slope with quadratic effect, CENTRED
>>
>> OK. Random intercept and slope has linear and quadratic effects. Now going to
>> centre the session count by subtracting lengthCentre
>>
>>
>> ```{r model5, warning=FALSE, message=FALSE}
>> longdat4$sessionC1 <- longdat4$session - lengthCentre
>> summary(longdat4$sessionC1)
>> hist(longdat4$sessionC1,
>> main="Histogram of centred session counts",
>> xlab="Centred session n",
>> col="grey")
>> abline(v=0)
>> require(lmerTest)
>> m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID),
>> data=longdat4)
>> summary(m5)
>> ```
>>
>>
>>
>> ```{r mode5rand,eval=FALSE}
>> rand(m5)
>> ### fails with message:
>> ### Error in terms.formula(tmp, simplify = TRUE) :
>> ### invalid model formula in ExtractVars
>> ```
>>
>>
>> ```{r coeffs5,fig.width=11,fig.height=8}
>> apply(ranef(m5)$validPOC_ID,2,summary)
>> par(mfrow=c(1,3))
>> hist(ranef(m5)$validPOC_ID[,1],
>> xlab="Intercept deviation values",
>> main="Random intercepts",
>> col="grey")
>> abline(v=0)
>> hist(ranef(m5)$validPOC_ID[,2],
>> main="Random slopes",
>> xlab="Linear slope deviation values",
>> col="grey")
>> abline(v=0)
>> hist(ranef(m5)$validPOC_ID[,3],
>> main="Random slopes",
>> xlab="Quadratic slope deviation values",
>> col="grey")
>> abline(v=0)
>> ```
>>
>> And here is sessionInfo()
>>
>>> sessionInfo()
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252
>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United Kingdom.1252
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> other attached packages:
>> [1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13
>> [6] Matrix_1.2-11 reshape2_1.4.2
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1
>> [5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1
>> [9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9
>> [13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0
>> [17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6
>> [21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2
>> [25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69
>> [29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2
>> [33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0
>> [37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5
>> [41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1
>> [45] lazyeval_0.2.0 munsell_0.4.3
>>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Thu Sep 21 15:27:17 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 21 Sep 2017 15:27:17 +0200
Subject: [R-sig-ME] Failing to understand effect of centering a
 predictor in multilevel model
In-Reply-To: <1833960877.26538753.1505989326855.JavaMail.zimbra@psyctc.org>
References: <81508081.26500897.1505986151718.JavaMail.zimbra@psyctc.org>
 <CAJuCY5wr+jD5_vU1SVdVBT2FbuWH2wMOVCPLDR9gdXzJYgCA8A@mail.gmail.com>
 <1833960877.26538753.1505989326855.JavaMail.zimbra@psyctc.org>
Message-ID: <CAJuCY5yMU69sGvDroCX-Q2AJ0eL1YVtU=b1zphZHwCMx34BvAw@mail.gmail.com>

Dear Chris,

Collinearity is not an issue because poly() creates orthogonal
polynomials. I expect that the problem is with the distribution of the
session variable. Does the range of "session" depends on the subject?
In the example below, each is has a session "1", but very few have a
session "50". In this case the model has plenty of data for low values
of session but not for high values. Making it harder to fit a
quadratic term.

set.seed(1234)
n_id <- 100
n_session <- rnbinom(n_id, size = 1, prob = 0.06)
n_session <- pmax(1, pmin(50, n_session))
dataset <- do.call(
  rbind,
  lapply(
    seq_along(n_session),
    function(i){
      data.frame(id = i, session = seq_len(n_session[i]))
    }
  )
)
fixed <- matrix(runif(3), ncol = 1)
random <- matrix(runif(3 * n_id), nrow = n_id)

dataset$fixed <- as.vector(model.matrix(id ~ poly(session, 2), data =
dataset) %*% fixed)
dataset$random <- rowSums(model.matrix(id ~ poly(session, 2), data =
dataset) * random[dataset$id, ])
dataset$mu <- dataset$fixed + dataset$random
dataset$y <- rnorm(nrow(dataset), mean = dataset$mu, sd = 0.05)
library(ggplot2)
ggplot(dataset, aes(x = session, y = mu, group = id)) +
  geom_line()
ggplot(dataset, aes(x = session, y = y, group = id)) +
  geom_line()

library(lme4)
model <- lmer(y ~ poly(session, 2) + (poly(session, 2) | id), data = dataset)
summary(model)

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-21 12:22 GMT+02:00 Chris Evans <chrishold at psyctc.org>:
> Oh dear, many, many thanks Thierry,
>
> Of course.  I knew it must be something idiotic I was doing.
>
> I think what had thrown me off from seeing that was the correlations in the fixed and random estimates.  As I read them (see output in my original post), the correlation between the fixed estimates of the linear and quadratic terms came out as .995 and the correlation for the random effects as 1.0  I had, perhaps naively, assumed that with linear and quadratic effects built into the population model with x (sessions) all positive would have inevitable strong collinearity and that was what I was seeing in the raw run and that centering would reduce it.
>
> I think, in some stupid way, I had just forgotten that the use of poly() (instead of "+ session + I(session^2)" ?) was transforming things in a way that makes any linear transform of session irrelevent (as you nicely point out!)
>
> So, can I put three more short follow up questions here:
> 1) am I reading those correlations correctly?
> 2) if so, then clearly I've misunderstood poly(): I thought it would have created essentially uncorrelated predictors, and cor(cbind(x,x^2,poly(x,2)) from your example seems to fit with that.  I thought that would have reduced or removed the inevitable collinearity of a linear and a quadratic effect and correlations of .995 and 1.0 seem not very reduced!
> 3) can you or someone point me to reading on how to interpret the correlations as warnings of possibly misleading estimates?
>
> TIA,
>
> Chris
>
>
> ----- Original Message -----
>> From: "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
>> To: "Chris Evans" <chrishold at psyctc.org>
>> Cc: r-sig-mixed-models at r-project.org
>> Sent: Thursday, 21 September, 2017 10:36:40
>> Subject: Re: [R-sig-ME] Failing to understand effect of centering a predictor in multilevel model
>
>> Dear Chris,
>>
>> This is because you use poly() on all variables
>>
>> x <- 10:20
>> cx <- x - mean(x)
>> all.equal(poly(x, 2), poly(cx, 2), check.attributes = FALSE)
>> all.equal(poly(x, 2), poly(cx, 2))
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus/ Statiscian
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Kliniekstraat 25, B-1070 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>> 2017-09-21 11:29 GMT+02:00 Chris Evans <chrishold at psyctc.org>:
>>> I am trying to make sure I understand the use of multilevel modelling to look at
>>> change (on questionnaire scores) across sessions of psychotherapy. This is
>>> widely done in my applied field. I am a researcher (and ex-therapist) not a
>>> statistician and have no direct availability of a statistician but I'm fairly
>>> savvy about stats. I am simulating, rather crudely, data which have both fixed
>>> and random intercepts and slopes with a quadratic as well as a linear effect of
>>> session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R
>>> 3.4.1 on Windoze running in Rstudio.
>>>
>>> The thing that's baffling me is that centering my predictor (session count)
>>> seems to have NO effect on my results, neither on the fixed nor the random
>>> effects. I would have expected the intercept to have changed at the very least
>>> given the effects I've simulated.
>>>
>>> Details: session count can range from 1 to 51 (the number of sessions per client
>>> in my simulation can vary, realistically, from 4 to 51 so no client has fewer
>>> than four). I have modelled in a random linear and quadratic effect of session
>>> count but such that the overall effects are both negative. Code and session
>>> info are at the end of the post. Here is code and output from uncentred:
>>>
>>> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
>>> data=longdat4)
>>> summary(m4)
>>>
>>> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
>>> ## to degrees of freedom [lmerMod]
>>> ## Formula:
>>> ## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID)
>>> ## Data: longdat4
>>> ##
>>> ## REML criterion at convergence: -29507
>>> ##
>>> ## Scaled residuals:
>>> ## Min 1Q Median 3Q Max
>>> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
>>> ##
>>> ## Random effects:
>>> ## Groups Name Variance Std.Dev. Corr
>>> ## validPOC_ID (Intercept) 9.309e+00 3.05101
>>> ## poly(session, 2)1 7.390e+03 85.96686 0.20
>>> ## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00
>>> ## Residual 4.973e-03 0.07052
>>> ## Number of obs: 15399, groups: validPOC_ID, 500
>>> ##
>>> ## Fixed effects:
>>> ## Estimate Std. Error df t value Pr(>|t|)
>>> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
>>> ## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
>>> ## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
>>> ## ---
>>> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> ##
>>> ## Correlation of Fixed Effects:
>>> ## (Intr) p(,2)1
>>> ## ply(sss,2)1 0.210
>>> ## ply(sss,2)2 0.215 0.995
>>>
>>> Here is the centered one (lengthCentre is 29.5).
>>>
>>> longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $
>>> sessionC1 )
>>> ## Min. 1st Qu. Median Mean 3rd Qu. Max.
>>> ## -28.50 -21.50 -12.50 -10.09 -0.50 21.50
>>> m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) |
>>> validPOC_ID ) , data = longdat4 ) summary ( m5 )
>>> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
>>> ## to degrees of freedom [lmerMod]
>>> ## Formula:
>>> ## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID)
>>> ## Data: longdat4
>>> ##
>>> ## REML criterion at convergence: -29507
>>> ##
>>> ## Scaled residuals:
>>> ## Min 1Q Median 3Q Max
>>> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
>>> ##
>>> ## Random effects:
>>> ## Groups Name Variance Std.Dev. Corr
>>> ## validPOC_ID (Intercept) 9.309e+00 3.05101
>>> ## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20
>>> ## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00
>>> ## Residual 4.973e-03 0.07052
>>> ## Number of obs: 15399, groups: validPOC_ID, 500
>>> ##
>>> ## Fixed effects:
>>> ## Estimate Std. Error df t value Pr(>|t|)
>>> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
>>> ## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
>>> ## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
>>> ## ---
>>> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>> ##
>>> ## Correlation of Fixed Effects:
>>> ## (Intr) p(C1,2)1
>>> ## ply(sC1,2)1 0.210
>>> ## ply(sC1,2)2 0.215 0.995
>>>
>>> This makes no sense to me. I had expected that the very crude centering must
>>> shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong
>>> linear and quadratic effects in the model. I also thought (the whole reason I'm
>>> doing this) that it would change the correlation between the linear and
>>> quadratic terms as I should be moving from a strong positive correlation
>>> between them to a much smaller one.
>>>
>>> I'm sure I'm doing something utterly stupid, or revealing shocking failure to
>>> comprehend the multilevel model, but I'm looking straight through the
>>> explanation and stuck. I hope someone will help me!
>>>
>>> TIA,
>>>
>>>
>>> Chris
>>>
>>>
>>>
>>> Here is entire pertinent code.
>>>
>>> ```{r sim4,warning=FALSE,message=FALSE,cache=TRUE}
>>> require(reshape2)
>>> set.seed(12345)
>>> ### set up the parameters for the simulation
>>> n <- 500
>>> minNSessions <- 4
>>> maxNSessions <- 55
>>> linSlope <- -.02
>>> errVar <- .005
>>> ### derived variables
>>> lengthRange <- minNSessions:maxNSessions
>>> lengthCentre <- (minNSessions+maxNSessions)/2
>>> ID <- 1:n
>>> ### create a variable, length = n for the session counts
>>> sessions <- sample(lengthRange,n,replace=TRUE)
>>> ### for now, give all starting scores of 10
>>> startScores <- rnorm(n,mean=10,sd=3)
>>> slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes
>>> ### set up matrix to store the simulated scores
>>> scores <- matrix(rep(NA,n*maxNSessions),nrow=n)
>>> dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores))
>>> for (i in 1:nrow(dat4)) {
>>> nSessions <- dat4$sessions[i]
>>> tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes
>>> tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear
>>> effect
>>> tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic
>>> effect
>>> tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error
>>> dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame
>>> }
>>> ### now melt to create a long data frame
>>> longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55)
>>> colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL")
>>> longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get
>>> start at 1
>>> # as data start in column 5
>>> longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),]
>>> longdat4 <- na.omit(longdat4) # ditch the empty data
>>> ```
>>>
>>> So the data frame longdat4 has
>>> `r nrow(longdat4)` rows and
>>> `r ncol(longdat4)` columns and the column names are
>>> `r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4)
>>> and the head of the long one (longdat4).
>>>
>>> ```{r head4,warning=FALSE,message=FALSE,cache=TRUE}
>>> require(knitr)
>>> kable(head(dat4[,1:10]),digits=3)
>>> kable(head(longdat4))
>>> ```
>>>
>>> Elisa's lattice plot.
>>>
>>> ```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE}
>>> library(lattice)
>>> samp <- sample(unique(longdat4$validPOC_ID), 35)
>>> xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4,
>>> type = c("p","g","r"),
>>> subset = (validPOC_ID %in% samp),
>>> col="dark blue",
>>> col.line="black",
>>> strip = F,
>>> xlab = "Weeks in treatment",
>>> ylab = "Depression Scores")
>>> ```
>>>
>>> Now Elisa's tangle plot. Just first 40 simulated cases.
>>>
>>> ```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE}
>>> library(ggplot2)
>>> first40 <- longdat4[longdat4$validPOC_ID <=40,]
>>> tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) +
>>> geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) +
>>> theme_bw()
>>> tanglePlot
>>> ```
>>>
>>> ```{r model4, warning=FALSE, message=FALSE,cache=TRUE}
>>> require(lmerTest)
>>> ### this next fails to converge and has perfect correlation of linear &
>>> quadratic effects
>>> # m4 <- lmer(DEP_TOTAL ~
>>> session+I(session^2)+(1+session+I(session^2)|validPOC_ID),
>>> # data=longdat4)
>>> ### is this better:
>>> summary(longdat4$session)
>>> hist(longdat4$session,
>>> main="Histogram of raw session counts",
>>> xlab="Raw session n",
>>> col="grey")
>>> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
>>> data=longdat4)
>>> summary(m4)
>>> ```
>>>
>>> This next should test the random effect (and should find it highly significant I
>>> think).
>>>
>>> ```{r mode4rand,eval=FALSE}
>>> rand(m4)
>>> ### fails with message:
>>> ### Error in terms.formula(tmp, simplify = TRUE) :
>>> ### invalid model formula in ExtractVars
>>> ```
>>>
>>> And this summarises the random effects. These are deviations from the fixed
>>> effects so both are centred on zero.
>>>
>>> ```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE}
>>> apply(ranef(m4)$validPOC_ID,2,summary)
>>> par(mfrow=c(1,3))
>>> hist(ranef(m4)$validPOC_ID[,1],
>>> xlab="Intercept deviation values",
>>> main="Random intercepts",
>>> col="grey")
>>> abline(v=0)
>>> hist(ranef(m4)$validPOC_ID[,2],
>>> main="Random slopes",
>>> xlab="Linear slope deviation values",
>>> col="grey")
>>> abline(v=0)
>>> hist(ranef(m4)$validPOC_ID[,3],
>>> main="Random slopes",
>>> xlab="Quadratic slope deviation values",
>>> col="grey")
>>> abline(v=0)
>>> ```
>>>
>>>
>>> # Simulation 5: random intercept and random slope with quadratic effect, CENTRED
>>>
>>> OK. Random intercept and slope has linear and quadratic effects. Now going to
>>> centre the session count by subtracting lengthCentre
>>>
>>>
>>> ```{r model5, warning=FALSE, message=FALSE}
>>> longdat4$sessionC1 <- longdat4$session - lengthCentre
>>> summary(longdat4$sessionC1)
>>> hist(longdat4$sessionC1,
>>> main="Histogram of centred session counts",
>>> xlab="Centred session n",
>>> col="grey")
>>> abline(v=0)
>>> require(lmerTest)
>>> m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID),
>>> data=longdat4)
>>> summary(m5)
>>> ```
>>>
>>>
>>>
>>> ```{r mode5rand,eval=FALSE}
>>> rand(m5)
>>> ### fails with message:
>>> ### Error in terms.formula(tmp, simplify = TRUE) :
>>> ### invalid model formula in ExtractVars
>>> ```
>>>
>>>
>>> ```{r coeffs5,fig.width=11,fig.height=8}
>>> apply(ranef(m5)$validPOC_ID,2,summary)
>>> par(mfrow=c(1,3))
>>> hist(ranef(m5)$validPOC_ID[,1],
>>> xlab="Intercept deviation values",
>>> main="Random intercepts",
>>> col="grey")
>>> abline(v=0)
>>> hist(ranef(m5)$validPOC_ID[,2],
>>> main="Random slopes",
>>> xlab="Linear slope deviation values",
>>> col="grey")
>>> abline(v=0)
>>> hist(ranef(m5)$validPOC_ID[,3],
>>> main="Random slopes",
>>> xlab="Quadratic slope deviation values",
>>> col="grey")
>>> abline(v=0)
>>> ```
>>>
>>> And here is sessionInfo()
>>>
>>>> sessionInfo()
>>> R version 3.4.1 (2017-06-30)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows >= 8 x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252
>>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United Kingdom.1252
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> other attached packages:
>>> [1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13
>>> [6] Matrix_1.2-11 reshape2_1.4.2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1
>>> [5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1
>>> [9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9
>>> [13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0
>>> [17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6
>>> [21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2
>>> [25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69
>>> [29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2
>>> [33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0
>>> [37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5
>>> [41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1
>>> [45] lazyeval_0.2.0 munsell_0.4.3
>>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chris at psyctc.org  Thu Sep 21 09:48:50 2017
From: chris at psyctc.org (Chris Evans)
Date: Thu, 21 Sep 2017 08:48:50 +0100 (BST)
Subject: [R-sig-ME] Failing to understand effect of centering a predictor in
 multilevel model
Message-ID: <2118835736.26446064.1505980130059.JavaMail.zimbra@psyctc.org>

I am trying to make sure I understand the use of multilevel modelling to look at change (on questionnaire scores) across sessions of psychotherapy. This is widely done in my applied field. I am a researcher (and ex-therapist) not a statistician and have no direct availability of a statistician but I'm fairly savvy about stats. I am simulating, rather crudely, data which have both fixed and random intercepts and slopes with a quadratic as well as a linear effect of session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R 3.4.1 on Windoze running in Rstudio. 

The thing that's baffling me is that centering my predictor (session count) seems to have NO effect on my results, neither on the fixed nor the random effects. I would have expected the intercept to have changed at the very least given the effects I've simulated. 

Details: session count can range from 1 to 51 (the number of sessions per client in my simulation can vary, realistically, from 4 to 51 so no client has fewer than four). I have modelled in a random linear and quadratic effect of session count but such that the overall effects are both negative. Code and session info are at the end of the post. Here is code and output from uncentred: 

m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID), 
data=longdat4) 
summary(m4) 

## Linear mixed model fit by REML t-tests use Satterthwaite approximations 
## to degrees of freedom [lmerMod] 
## Formula: 
## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID) 
## Data: longdat4 
## 
## REML criterion at convergence: -29507 
## 
## Scaled residuals: 
## Min 1Q Median 3Q Max 
## -3.6274 -0.6583 0.0035 0.6420 4.0849 
## 
## Random effects: 
## Groups Name Variance Std.Dev. Corr 
## validPOC_ID (Intercept) 9.309e+00 3.05101 
## poly(session, 2)1 7.390e+03 85.96686 0.20 
## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00 
## Residual 4.973e-03 0.07052 
## Number of obs: 15399, groups: validPOC_ID, 500 
## 
## Fixed effects: 
## Estimate Std. Error df t value Pr(>|t|) 
## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 *** 
## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 *** 
## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 *** 
## --- 
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
## 
## Correlation of Fixed Effects: 
## (Intr) p(,2)1 
## ply(sss,2)1 0.210 
## ply(sss,2)2 0.215 0.995 

Here is the centered one (lengthCentre is 29.5). 

longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $ sessionC1 ) 
## Min. 1st Qu. Median Mean 3rd Qu. Max. 
## -28.50 -21.50 -12.50 -10.09 -0.50 21.50 
m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) | validPOC_ID ) , data = longdat4 ) summary ( m5 ) 
## Linear mixed model fit by REML t-tests use Satterthwaite approximations 
## to degrees of freedom [lmerMod] 
## Formula: 
## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID) 
## Data: longdat4 
## 
## REML criterion at convergence: -29507 
## 
## Scaled residuals: 
## Min 1Q Median 3Q Max 
## -3.6274 -0.6583 0.0035 0.6420 4.0849 
## 
## Random effects: 
## Groups Name Variance Std.Dev. Corr 
## validPOC_ID (Intercept) 9.309e+00 3.05101 
## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20 
## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00 
## Residual 4.973e-03 0.07052 
## Number of obs: 15399, groups: validPOC_ID, 500 
## 
## Fixed effects: 
## Estimate Std. Error df t value Pr(>|t|) 
## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 *** 
## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 *** 
## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 *** 
## --- 
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
## 
## Correlation of Fixed Effects: 
## (Intr) p(C1,2)1 
## ply(sC1,2)1 0.210 
## ply(sC1,2)2 0.215 0.995 

This makes no sense to me. I had expected that the very crude centering must shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong linear and quadratic effects in the model. I also thought (the whole reason I'm doing this) that it would change the correlation between the linear and quadratic terms as I should be moving from a strong positive correlation between them to a much smaller one. 

I'm sure I'm doing something utterly stupid, or revealing shocking failure to comprehend the multilevel model, but I'm looking straight through the explanation and stuck. I hope someone will help me! 

TIA, 


Chris 



Here is entire pertinent code. 

```{r sim4,warning=FALSE,message=FALSE,cache=TRUE} 
require(reshape2) 
set.seed(12345) 
### set up the parameters for the simulation 
n <- 500 
minNSessions <- 4 
maxNSessions <- 55 
linSlope <- -.02 
errVar <- .005 
### derived variables 
lengthRange <- minNSessions:maxNSessions 
lengthCentre <- (minNSessions+maxNSessions)/2 
ID <- 1:n 
### create a variable, length = n for the session counts 
sessions <- sample(lengthRange,n,replace=TRUE) 
### for now, give all starting scores of 10 
startScores <- rnorm(n,mean=10,sd=3) 
slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes 
### set up matrix to store the simulated scores 
scores <- matrix(rep(NA,n*maxNSessions),nrow=n) 
dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores)) 
for (i in 1:nrow(dat4)) { 
nSessions <- dat4$sessions[i] 
tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes 
tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear effect 
tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic effect 
tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error 
dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame 
} 
### now melt to create a long data frame 
longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55) 
colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL") 
longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get start at 1 
# as data start in column 5 
longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),] 
longdat4 <- na.omit(longdat4) # ditch the empty data 
``` 

So the data frame longdat4 has 
`r nrow(longdat4)` rows and 
`r ncol(longdat4)` columns and the column names are 
`r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4) and the head of the long one (longdat4). 

```{r head4,warning=FALSE,message=FALSE,cache=TRUE} 
require(knitr) 
kable(head(dat4[,1:10]),digits=3) 
kable(head(longdat4)) 
``` 

Elisa's lattice plot. 

```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE} 
library(lattice) 
samp <- sample(unique(longdat4$validPOC_ID), 35) 
xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4, 
type = c("p","g","r"), 
subset = (validPOC_ID %in% samp), 
col="dark blue", 
col.line="black", 
strip = F, 
xlab = "Weeks in treatment", 
ylab = "Depression Scores") 
``` 

Now Elisa's tangle plot. Just first 40 simulated cases. 

```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE} 
library(ggplot2) 
first40 <- longdat4[longdat4$validPOC_ID <=40,] 
tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) + 
geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) + 
theme_bw() 
tanglePlot 
``` 

```{r model4, warning=FALSE, message=FALSE,cache=TRUE} 
require(lmerTest) 
### this next fails to converge and has perfect correlation of linear & quadratic effects 
# m4 <- lmer(DEP_TOTAL ~ session+I(session^2)+(1+session+I(session^2)|validPOC_ID), 
# data=longdat4) 
### is this better: 
summary(longdat4$session) 
hist(longdat4$session, 
main="Histogram of raw session counts", 
xlab="Raw session n", 
col="grey") 
m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID), 
data=longdat4) 
summary(m4) 
``` 

This next should test the random effect (and should find it highly significant I think). 

```{r mode4rand,eval=FALSE} 
rand(m4) 
### fails with message: 
### Error in terms.formula(tmp, simplify = TRUE) : 
### invalid model formula in ExtractVars 
``` 

And this summarises the random effects. These are deviations from the fixed effects so both are centred on zero. 

```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE} 
apply(ranef(m4)$validPOC_ID,2,summary) 
par(mfrow=c(1,3)) 
hist(ranef(m4)$validPOC_ID[,1], 
xlab="Intercept deviation values", 
main="Random intercepts", 
col="grey") 
abline(v=0) 
hist(ranef(m4)$validPOC_ID[,2], 
main="Random slopes", 
xlab="Linear slope deviation values", 
col="grey") 
abline(v=0) 
hist(ranef(m4)$validPOC_ID[,3], 
main="Random slopes", 
xlab="Quadratic slope deviation values", 
col="grey") 
abline(v=0) 
``` 


# Simulation 5: random intercept and random slope with quadratic effect, CENTRED 

OK. Random intercept and slope has linear and quadratic effects. Now going to centre the session count by subtracting lengthCentre 


```{r model5, warning=FALSE, message=FALSE} 
longdat4$sessionC1 <- longdat4$session - lengthCentre 
summary(longdat4$sessionC1) 
hist(longdat4$sessionC1, 
main="Histogram of centred session counts", 
xlab="Centred session n", 
col="grey") 
abline(v=0) 
require(lmerTest) 
m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID), 
data=longdat4) 
summary(m5) 
``` 



```{r mode5rand,eval=FALSE} 
rand(m5) 
### fails with message: 
### Error in terms.formula(tmp, simplify = TRUE) : 
### invalid model formula in ExtractVars 
``` 


```{r coeffs5,fig.width=11,fig.height=8} 
apply(ranef(m5)$validPOC_ID,2,summary) 
par(mfrow=c(1,3)) 
hist(ranef(m5)$validPOC_ID[,1], 
xlab="Intercept deviation values", 
main="Random intercepts", 
col="grey") 
abline(v=0) 
hist(ranef(m5)$validPOC_ID[,2], 
main="Random slopes", 
xlab="Linear slope deviation values", 
col="grey") 
abline(v=0) 
hist(ranef(m5)$validPOC_ID[,3], 
main="Random slopes", 
xlab="Quadratic slope deviation values", 
col="grey") 
abline(v=0) 
``` 

And here is sessionInfo() 

> sessionInfo() 
R version 3.4.1 (2017-06-30) 
Platform: x86_64-w64-mingw32/x64 (64-bit) 
Running under: Windows >= 8 x64 (build 9200) 

Matrix products: default 

locale: 
[1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252 
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C 
[5] LC_TIME=English_United Kingdom.1252 

attached base packages: 
[1] stats graphics grDevices utils datasets methods base 

other attached packages: 
[1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13 
[6] Matrix_1.2-11 reshape2_1.4.2 

loaded via a namespace (and not attached): 
[1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1 
[5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1 
[9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9 
[13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0 
[17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6 
[21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2 
[25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69 
[29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2 
[33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0 
[37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5 
[41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1 
[45] lazyeval_0.2.0 munsell_0.4.3 
> 

	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Sep 22 02:52:31 2017
From: orchidn at live.com (dani)
Date: Fri, 22 Sep 2017 00:52:31 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
Message-ID: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,

I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.

The model includes
- four categorical variables
- 6 continuous variables (for one of them I would like to include a smoother)
- the offset=log(duration)

I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).

My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))

mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
                    random =~ ID+class+idv(x6numspline2),
                    data   = newdat,
                    family = "poisson",
                    thin   = 100,
                    burnin = 10000,
                    nitt   = 150000,
                    saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)

In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?

Thank you all so much!
Best regards,
N-M.
<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Sep 22 06:55:02 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 22 Sep 2017 05:55:02 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>

Hi,

The model looks OK as far as can be assessed without knowing the data. 
For the offset term you need to hold the associated coefficient at 1 by 
placing a strong prior on it. If  you want everything else to have the 
default prior then use:

k<-11 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
             R=list(V=1, nu=0),
             G=list(G1=list(V=1, nu=0),
                    G2=list(V=1, nu=0),
                    G3=list(V=1, nu=0)))

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8

The interpretation of the offset is simply the coefficient is assumed to 
be one and that the rate at which events occur is constant.

Cheers,

Jarrod




On 22/09/2017 01:52, dani wrote:
> Hello everyone,
>
> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>
> The model includes
> - four categorical variables
> - 6 continuous variables (for one of them I would like to include a smoother)
> - the offset=log(duration)
>
> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>
> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>
> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>                      random =~ ID+class+idv(x6numspline2),
>                      data   = newdat,
>                      family = "poisson",
>                      thin   = 100,
>                      burnin = 10000,
>                      nitt   = 150000,
>                      saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>
> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>
> Thank you all so much!
> Best regards,
> N-M.
> <http://aka.ms/weboutlook>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jessiebarker at gmail.com  Fri Sep 22 11:41:19 2017
From: jessiebarker at gmail.com (Jessie Barker)
Date: Fri, 22 Sep 2017 11:41:19 +0200
Subject: [R-sig-ME] Changing reference level in clmm() ordinal regression
Message-ID: <CABtDSpiXeZmZCzrb3aQ0y7Nos3ZMOXO01FovYfE11p__3qU_yQ@mail.gmail.com>

I have a couple of questions that I asked on StackExchange and someone
suggested that I ask this mailing list. The post on StackExchange is here (
https://stats.stackexchange.com/questions/304092/changing-reference-level-in-clmm-ordinal-regression-in-r),
but I am summarizing it below:

I?m analyzing data from a questionnaire where participants had to rank
three answers to each question (e.g. 1 = most likely, 3 = least likely).
They had to give a different rank to each answer, so each question has one
answer ranked 1, one ranked 2, and one ranked 3. The set of three answers
is the same for each questions, and there were seven questions.

I want to know whether participants give different ranks to different
answers, and whether that is affected by question. Here's my model:

model1 <- clmm(rank ~ answer + answer:question + (1+answer|participant),
data = mydata)

(I don?t have question as a fixed effect, because for each question
participants had to give a 1, 2 and 3 rank, so question alone does not
affect rank.)

My first question is whether I?ve set up the model correctly, as I don?t
have any experience with ordinal regression. When I look at coef(model1),
all participants seem to have the same intercepts and coefficients for the
different answers, which is not what I thought should happen (I thought I
was setting up a model with random intercepts and random slopes).

My second question is about changing the reference level of question and
answer. When I look at summary(model1), it uses answer a1 and question q1
as the reference levels, so I ran the model again using different answers
and questions as reference levels.

When I run the model again using a different answer as the reference level,
the coefficients for the fixed effects are the same, but the random effects
and threshold coefficients are quite different.
When I run the model using a different question as the reference level, the
coefficients for the fixed effects are quite different, but the random
effects are exactly the same, and the threshold coefficients relatively
similar.

Could someone please help me understand what?s going on here?

Thanks in advance,
Jessie Barker

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Sep 22 14:38:46 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 22 Sep 2017 14:38:46 +0200
Subject: [R-sig-ME] Changing reference level in clmm() ordinal regression
In-Reply-To: <CABtDSpiXeZmZCzrb3aQ0y7Nos3ZMOXO01FovYfE11p__3qU_yQ@mail.gmail.com>
References: <CABtDSpiXeZmZCzrb3aQ0y7Nos3ZMOXO01FovYfE11p__3qU_yQ@mail.gmail.com>
Message-ID: <CAJuCY5w0LZ4U2LvoZKCo5fiQu+_JOKYB+dC4cxM0E3yqgyHMHQ@mail.gmail.com>

Dear Jessie,

All models have an identical fit. They only differ in the
parametrisation. "a3" estimates the difference between "a3" and the
reference. Hence, changing the reference results in a different
interpretation of the parameter and thus a different estimate.

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-22 11:41 GMT+02:00 Jessie Barker <jessiebarker at gmail.com>:
> I have a couple of questions that I asked on StackExchange and someone
> suggested that I ask this mailing list. The post on StackExchange is here (
> https://stats.stackexchange.com/questions/304092/changing-reference-level-in-clmm-ordinal-regression-in-r),
> but I am summarizing it below:
>
> I?m analyzing data from a questionnaire where participants had to rank
> three answers to each question (e.g. 1 = most likely, 3 = least likely).
> They had to give a different rank to each answer, so each question has one
> answer ranked 1, one ranked 2, and one ranked 3. The set of three answers
> is the same for each questions, and there were seven questions.
>
> I want to know whether participants give different ranks to different
> answers, and whether that is affected by question. Here's my model:
>
> model1 <- clmm(rank ~ answer + answer:question + (1+answer|participant),
> data = mydata)
>
> (I don?t have question as a fixed effect, because for each question
> participants had to give a 1, 2 and 3 rank, so question alone does not
> affect rank.)
>
> My first question is whether I?ve set up the model correctly, as I don?t
> have any experience with ordinal regression. When I look at coef(model1),
> all participants seem to have the same intercepts and coefficients for the
> different answers, which is not what I thought should happen (I thought I
> was setting up a model with random intercepts and random slopes).
>
> My second question is about changing the reference level of question and
> answer. When I look at summary(model1), it uses answer a1 and question q1
> as the reference levels, so I ran the model again using different answers
> and questions as reference levels.
>
> When I run the model again using a different answer as the reference level,
> the coefficients for the fixed effects are the same, but the random effects
> and threshold coefficients are quite different.
> When I run the model using a different question as the reference level, the
> coefficients for the fixed effects are quite different, but the random
> effects are exactly the same, and the threshold coefficients relatively
> similar.
>
> Could someone please help me understand what?s going on here?
>
> Thanks in advance,
> Jessie Barker
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jessiebarker at gmail.com  Fri Sep 22 17:24:59 2017
From: jessiebarker at gmail.com (Jessie Barker)
Date: Fri, 22 Sep 2017 17:24:59 +0200
Subject: [R-sig-ME] Changing reference level in clmm() ordinal regression
In-Reply-To: <CAJuCY5w0LZ4U2LvoZKCo5fiQu+_JOKYB+dC4cxM0E3yqgyHMHQ@mail.gmail.com>
References: <CABtDSpiXeZmZCzrb3aQ0y7Nos3ZMOXO01FovYfE11p__3qU_yQ@mail.gmail.com>
 <CAJuCY5w0LZ4U2LvoZKCo5fiQu+_JOKYB+dC4cxM0E3yqgyHMHQ@mail.gmail.com>
Message-ID: <CABtDSpg_SU6D4BZkM3Czf=E-vHJT+Rym_Km9oibcV0W0GrbpAw@mail.gmail.com>

Hi Thierry,

Thank you for your reply.

I see that when changing the reference from say, a1 to a2, the estimate for
a3 will be different.
However, I'm still not sure why, when I change the reference of the other
factor from, say, q1 to q2, the estimate for a3 will be different (because
a3 is is still being compared to the same reference level of a, regardless
of what the reference level of q is). Or am I misinterpreting that?

Thanks again,

Jessie

On 22 September 2017 at 14:38, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Jessie,
>
> All models have an identical fit. They only differ in the
> parametrisation. "a3" estimates the difference between "a3" and the
> reference. Hence, changing the reference results in a different
> interpretation of the parameter and thus a different estimate.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statiscian
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
> Brussel.
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
> 2017-09-22 11:41 GMT+02:00 Jessie Barker <jessiebarker at gmail.com>:
> > I have a couple of questions that I asked on StackExchange and someone
> > suggested that I ask this mailing list. The post on StackExchange is
> here (
> > https://stats.stackexchange.com/questions/304092/changing-
> reference-level-in-clmm-ordinal-regression-in-r),
> > but I am summarizing it below:
> >
> > I?m analyzing data from a questionnaire where participants had to rank
> > three answers to each question (e.g. 1 = most likely, 3 = least likely).
> > They had to give a different rank to each answer, so each question has
> one
> > answer ranked 1, one ranked 2, and one ranked 3. The set of three answers
> > is the same for each questions, and there were seven questions.
> >
> > I want to know whether participants give different ranks to different
> > answers, and whether that is affected by question. Here's my model:
> >
> > model1 <- clmm(rank ~ answer + answer:question + (1+answer|participant),
> > data = mydata)
> >
> > (I don?t have question as a fixed effect, because for each question
> > participants had to give a 1, 2 and 3 rank, so question alone does not
> > affect rank.)
> >
> > My first question is whether I?ve set up the model correctly, as I don?t
> > have any experience with ordinal regression. When I look at coef(model1),
> > all participants seem to have the same intercepts and coefficients for
> the
> > different answers, which is not what I thought should happen (I thought I
> > was setting up a model with random intercepts and random slopes).
> >
> > My second question is about changing the reference level of question and
> > answer. When I look at summary(model1), it uses answer a1 and question q1
> > as the reference levels, so I ran the model again using different answers
> > and questions as reference levels.
> >
> > When I run the model again using a different answer as the reference
> level,
> > the coefficients for the fixed effects are the same, but the random
> effects
> > and threshold coefficients are quite different.
> > When I run the model using a different question as the reference level,
> the
> > coefficients for the fixed effects are quite different, but the random
> > effects are exactly the same, and the threshold coefficients relatively
> > similar.
> >
> > Could someone please help me understand what?s going on here?
> >
> > Thanks in advance,
> > Jessie Barker
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Sep 22 19:01:09 2017
From: orchidn at live.com (dani)
Date: Fri, 22 Sep 2017 17:01:09 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
Message-ID: <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Jarrod,


Thank you so much for your prompt and helpful response!

I ran the code you sent me for the prior, but I am getting the following error:

Error in prior$B[k, k] <- 1e-08 :
  incorrect number of subscripts on matrix


Here is what I get for prior:
> prior
$B
$B$V
       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
 [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
 [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
 [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
 [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
[10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
[11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08

$B$mu
 [1] 0 0 0 0 0 0 0 0 0 0 0


$R
$R$V
[1] 1

$R$nu
[1] 0


$G
$G$G1
$G$G1$V
[1] 1

$G$G1$nu
[1] 0


$G$G2
$G$G2$V
[1] 1

$G$G2$nu
[1] 0


$G$G3
$G$G3$V
[1] 1

$G$G3$nu
[1] 0



$mu
 [1] NA NA NA NA NA NA NA NA NA NA  1



I am not sure what to do next. Any help would be very appreciated!

Best regards,

N-M



Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Thursday, September 21, 2017 9:55 PM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hi,

The model looks OK as far as can be assessed without knowing the data.
For the offset term you need to hold the associated coefficient at 1 by
placing a strong prior on it. If  you want everything else to have the
default prior then use:

k<-11 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
             R=list(V=1, nu=0),
             G=list(G1=list(V=1, nu=0),
                    G2=list(V=1, nu=0),
                    G3=list(V=1, nu=0)))

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8

The interpretation of the offset is simply the coefficient is assumed to
be one and that the rate at which events occur is constant.

Cheers,

Jarrod




On 22/09/2017 01:52, dani wrote:
> Hello everyone,
>
> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>
> The model includes
> - four categorical variables
> - 6 continuous variables (for one of them I would like to include a smoother)
> - the offset=log(duration)
>
> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>
> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>
> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>                      random =~ ID+class+idv(x6numspline2),
>                      data   = newdat,
>                      family = "poisson",
>                      thin   = 100,
>                      burnin = 10000,
>                      nitt   = 150000,
>                      saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>
> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>
> Thank you all so much!
> Best regards,
> N-M.
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Sep 22 19:14:44 2017
From: orchidn at live.com (dani)
Date: Fri, 22 Sep 2017 17:14:44 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
Message-ID: <MWHPR1201MB0029A47F32D332FD37E456C0D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Matt,

Thank you so much! I did try that code, as well, with the same result. Not sure what to do next:)

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Matthew <mew0099 at auburn.edu>
Sent: Friday, September 22, 2017 10:10 AM
To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hi Dani,

Jarrod probably meant

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-8

Instead of:

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8


Sincerely,
Matthew

****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu

On 22/09/17 12:01, dani wrote:
> Hi Jarrod,
>
>
> Thank you so much for your prompt and helpful response!
>
> I ran the code you sent me for the prior, but I am getting the following error:
>
> Error in prior$B[k, k] <- 1e-08 :
>    incorrect number of subscripts on matrix
>
>
> Here is what I get for prior:
>> prior
> $B
> $B$V
>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>   [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>   [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>   [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>   [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
>
> $B$mu
>   [1] 0 0 0 0 0 0 0 0 0 0 0
>
>
> $R
> $R$V
> [1] 1
>
> $R$nu
> [1] 0
>
>
> $G
> $G$G1
> $G$G1$V
> [1] 1
>
> $G$G1$nu
> [1] 0
>
>
> $G$G2
> $G$G2$V
> [1] 1
>
> $G$G2$nu
> [1] 0
>
>
> $G$G3
> $G$G3$V
> [1] 1
>
> $G$G3$nu
> [1] 0
>
>
>
> $mu
>   [1] NA NA NA NA NA NA NA NA NA NA  1
>
>
>
> I am not sure what to do next. Any help would be very appreciated!
>
> Best regards,
>
> N-M
>
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>
> ________________________________
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Sent: Thursday, September 21, 2017 9:55 PM
> To: dani; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
> Hi,
>
> The model looks OK as far as can be assessed without knowing the data.
> For the offset term you need to hold the associated coefficient at 1 by
> placing a strong prior on it. If  you want everything else to have the
> default prior then use:
>
> k<-11 # number of fixed effects
>
> prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
> The interpretation of the offset is simply the coefficient is assumed to
> be one and that the rate at which events occur is constant.
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 22/09/2017 01:52, dani wrote:
>> Hello everyone,
>>
>> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>>
>> The model includes
>> - four categorical variables
>> - 6 continuous variables (for one of them I would like to include a smoother)
>> - the offset=log(duration)
>>
>> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>>
>> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>>
>> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>>                       random =~ ID+class+idv(x6numspline2),
>>                       data   = newdat,
>>                       family = "poisson",
>>                       thin   = 100,
>>                       burnin = 10000,
>>                       nitt   = 150000,
>>                       saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>>
>> Thank you all so much!
>> Best regards,
>> N-M.
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Sep 22 19:17:37 2017
From: orchidn at live.com (dani)
Date: Fri, 22 Sep 2017 17:17:37 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
Message-ID: <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>

just a correction, the code prior$B$V[k,k]<-1e-8 works but the model provides this error


Error in MCMCglmm(y ~ x1 + x2 + X8 + x9 +x10 +  :
  prior list should contain elements R, G, and/or B only



Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Matthew <mew0099 at auburn.edu>
Sent: Friday, September 22, 2017 10:10 AM
To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hi Dani,

Jarrod probably meant

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-8

Instead of:

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8


Sincerely,
Matthew

****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu

On 22/09/17 12:01, dani wrote:
> Hi Jarrod,
>
>
> Thank you so much for your prompt and helpful response!
>
> I ran the code you sent me for the prior, but I am getting the following error:
>
> Error in prior$B[k, k] <- 1e-08 :
>    incorrect number of subscripts on matrix
>
>
> Here is what I get for prior:
>> prior
> $B
> $B$V
>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>   [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>   [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>   [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>   [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
>
> $B$mu
>   [1] 0 0 0 0 0 0 0 0 0 0 0
>
>
> $R
> $R$V
> [1] 1
>
> $R$nu
> [1] 0
>
>
> $G
> $G$G1
> $G$G1$V
> [1] 1
>
> $G$G1$nu
> [1] 0
>
>
> $G$G2
> $G$G2$V
> [1] 1
>
> $G$G2$nu
> [1] 0
>
>
> $G$G3
> $G$G3$V
> [1] 1
>
> $G$G3$nu
> [1] 0
>
>
>
> $mu
>   [1] NA NA NA NA NA NA NA NA NA NA  1
>
>
>
> I am not sure what to do next. Any help would be very appreciated!
>
> Best regards,
>
> N-M
>
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>
> ________________________________
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Sent: Thursday, September 21, 2017 9:55 PM
> To: dani; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
> Hi,
>
> The model looks OK as far as can be assessed without knowing the data.
> For the offset term you need to hold the associated coefficient at 1 by
> placing a strong prior on it. If  you want everything else to have the
> default prior then use:
>
> k<-11 # number of fixed effects
>
> prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
> The interpretation of the offset is simply the coefficient is assumed to
> be one and that the rate at which events occur is constant.
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 22/09/2017 01:52, dani wrote:
>> Hello everyone,
>>
>> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>>
>> The model includes
>> - four categorical variables
>> - 6 continuous variables (for one of them I would like to include a smoother)
>> - the offset=log(duration)
>>
>> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>>
>> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>>
>> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>>                       random =~ ID+class+idv(x6numspline2),
>>                       data   = newdat,
>>                       family = "poisson",
>>                       thin   = 100,
>>                       burnin = 10000,
>>                       nitt   = 150000,
>>                       saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>>
>> Thank you all so much!
>> Best regards,
>> N-M.
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From mew0099 at auburn.edu  Fri Sep 22 19:10:26 2017
From: mew0099 at auburn.edu (Matthew)
Date: Fri, 22 Sep 2017 12:10:26 -0500
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>

Hi Dani,

Jarrod probably meant

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-8

Instead of:

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8


Sincerely,
Matthew

****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu

On 22/09/17 12:01, dani wrote:
> Hi Jarrod,
>
>
> Thank you so much for your prompt and helpful response!
>
> I ran the code you sent me for the prior, but I am getting the following error:
>
> Error in prior$B[k, k] <- 1e-08 :
>    incorrect number of subscripts on matrix
>
>
> Here is what I get for prior:
>> prior
> $B
> $B$V
>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>   [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>   [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>   [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>   [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
>
> $B$mu
>   [1] 0 0 0 0 0 0 0 0 0 0 0
>
>
> $R
> $R$V
> [1] 1
>
> $R$nu
> [1] 0
>
>
> $G
> $G$G1
> $G$G1$V
> [1] 1
>
> $G$G1$nu
> [1] 0
>
>
> $G$G2
> $G$G2$V
> [1] 1
>
> $G$G2$nu
> [1] 0
>
>
> $G$G3
> $G$G3$V
> [1] 1
>
> $G$G3$nu
> [1] 0
>
>
>
> $mu
>   [1] NA NA NA NA NA NA NA NA NA NA  1
>
>
>
> I am not sure what to do next. Any help would be very appreciated!
>
> Best regards,
>
> N-M
>
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>
> ________________________________
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> Sent: Thursday, September 21, 2017 9:55 PM
> To: dani; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
> Hi,
>
> The model looks OK as far as can be assessed without knowing the data.
> For the offset term you need to hold the associated coefficient at 1 by
> placing a strong prior on it. If  you want everything else to have the
> default prior then use:
>
> k<-11 # number of fixed effects
>
> prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
> The interpretation of the offset is simply the coefficient is assumed to
> be one and that the rate at which events occur is constant.
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 22/09/2017 01:52, dani wrote:
>> Hello everyone,
>>
>> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>>
>> The model includes
>> - four categorical variables
>> - 6 continuous variables (for one of them I would like to include a smoother)
>> - the offset=log(duration)
>>
>> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>>
>> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>>
>> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>>                       random =~ ID+class+idv(x6numspline2),
>>                       data   = newdat,
>>                       family = "poisson",
>>                       thin   = 100,
>>                       burnin = 10000,
>>                       nitt   = 150000,
>>                       saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>>
>> Thank you all so much!
>> Best regards,
>> N-M.
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mew0099 at auburn.edu  Fri Sep 22 19:20:45 2017
From: mew0099 at auburn.edu (Matthew)
Date: Fri, 22 Sep 2017 12:20:45 -0500
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>

Hi Dani,


Redo the prior specification from scratch (i.e., overwrite the entire 
`prior` object). The original code creates an unecessary/undefined 
element in the prior list.


Matthew

****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu

On 22/09/17 12:17, dani wrote:
>
> just a correction, the code prior$B$V[k,k]<-1e-8?works but the model 
> provides?this error
>
>
> Error in MCMCglmm(y ~ x1 + x2 + X8 + x9 +x10 + ?:
> ? prior list should contain elements R, G, and/or B only
>
>
> Sent from Outlook <http://aka.ms/weboutlook>
>
>
> ------------------------------------------------------------------------
> *From:* Matthew <mew0099 at auburn.edu>
> *Sent:* Friday, September 22, 2017 10:10 AM
> *To:* dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
> splines
> Hi Dani,
>
> Jarrod probably meant
>
> prior$B$mu[k]<-1 # assuming the offset term is last
> prior$B$V[k,k]<-1e-8
>
> Instead of:
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
>
> Sincerely,
> Matthew
>
> ****************************************************
> Matthew E. Wolak, Ph.D.
> Assistant Professor
> Department of Biological Sciences
> Auburn University
> 306 Funchess Hall
> Auburn, AL 36849, USA
> Email: matthew.wolak at auburn.edu
>
> On 22/09/17 12:01, dani wrote:
> > Hi Jarrod,
> >
> >
> > Thank you so much for your prompt and helpful response!
> >
> > I ran the code you sent me for the prior, but I am getting the 
> following error:
> >
> > Error in prior$B[k, k] <- 1e-08 :
> >??? incorrect number of subscripts on matrix
> >
> >
> > Here is what I get for prior:
> >> prior
> > $B
> > $B$V
> >???????? [,1]? [,2]? [,3]? [,4]? [,5]? [,6]? [,7] [,8]? [,9] [,10] [,11]
> >?? [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
> >?? [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
> >?? [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
> >?? [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> > [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> > [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
> >
> > $B$mu
> >?? [1] 0 0 0 0 0 0 0 0 0 0 0
> >
> >
> > $R
> > $R$V
> > [1] 1
> >
> > $R$nu
> > [1] 0
> >
> >
> > $G
> > $G$G1
> > $G$G1$V
> > [1] 1
> >
> > $G$G1$nu
> > [1] 0
> >
> >
> > $G$G2
> > $G$G2$V
> > [1] 1
> >
> > $G$G2$nu
> > [1] 0
> >
> >
> > $G$G3
> > $G$G3$V
> > [1] 1
> >
> > $G$G3$nu
> > [1] 0
> >
> >
> >
> > $mu
> >?? [1] NA NA NA NA NA NA NA NA NA NA? 1
> >
> >
> >
> > I am not sure what to do next. Any help would be very appreciated!
> >
> > Best regards,
> >
> > N-M
> >
> >
> >
> > Sent from Outlook<http://aka.ms/weboutlook>
> >
> >
> > ________________________________
> > From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> > Sent: Thursday, September 21, 2017 9:55 PM
> > To: dani; r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
> >
> > Hi,
> >
> > The model looks OK as far as can be assessed without knowing the data.
> > For the offset term you need to hold the associated coefficient at 1 by
> > placing a strong prior on it. If? you want everything else to have the
> > default prior then use:
> >
> > k<-11 # number of fixed effects
> >
> > prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
> >?????????????? R=list(V=1, nu=0),
> >?????????????? G=list(G1=list(V=1, nu=0),
> >????????????????????? G2=list(V=1, nu=0),
> >????????????????????? G3=list(V=1, nu=0)))
> >
> > prior$mu[k]<-1 # assuming the offset term is last
> > prior$B[k,k]<-1e-8
> >
> > The interpretation of the offset is simply the coefficient is assumed to
> > be one and that the rate at which events occur is constant.
> >
> > Cheers,
> >
> > Jarrod
> >
> >
> >
> >
> > On 22/09/2017 01:52, dani wrote:
> >> Hello everyone,
> >>
> >> I have a Poisson model with an offset term that involves repeated 
> observations nested into two cross-classified groups.
> >>
> >> The model includes
> >> - four categorical variables
> >> - 6 continuous variables (for one of them I would like to include a 
> smoother)
> >> - the offset=log(duration)
> >>
> >> I first used the spl2 function to create the fixed ((x6numspline1) 
> and random terms (x6numspline2) for the smoother. I added the random 
> smoother term to the other two random intercepts (for student ID and 
> classroom) that I have (which are cross-classified).
> >>
> >> My question is: Do you find my model sound? Before I study the 
> priors, I just wanted to run a default model - is my inclusion of an 
> offset ok? Also, given that the observations are repeated and nested 
> into both Student ID and classroom, I am not sure how to specify the 
> variance structure in MCMCglmm (beginner here:))
> >>
> >> mc_spl0 <- MCMCglmm(number_events ~ 
> x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
> >>?????????????????????? random =~ ID+class+idv(x6numspline2),
> >>?????????????????????? data?? = newdat,
> >>?????????????????????? family = "poisson",
> >>?????????????????????? thin?? = 100,
> >>?????????????????????? burnin = 10000,
> >>?????????????????????? nitt?? = 150000,
> >>?????????????????????? saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, 
> pl=TRUE)
> >>
> >> In addition, I am not sure what to make of the results for the 
> offset term (included as a covariate in the model) in the output - how 
> should I discuss them?
> >>
> >> Thank you all so much!
> >> Best regards,
> >> N-M.
> >> <http://aka.ms/weboutlook>
> >>
> >>???????? [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > --
> > The University of Edinburgh is a charitable body, registered in
> > Scotland, with registration number SC005336.
> >
> >
> >??????? [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From orchidn at live.com  Fri Sep 22 19:34:31 2017
From: orchidn at live.com (dani)
Date: Fri, 22 Sep 2017 17:34:31 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
Message-ID: <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi again,


Thanks! It looks like it is working. This is like V looks like:

> prior$B$V
       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
 [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
 [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
 [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
 [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
 [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
[10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
[11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e-08

However, when I run my model, I get this new error:
 fixed effect V prior is not positive definite


Thanks!

Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Matthew <mew0099 at auburn.edu>
Sent: Friday, September 22, 2017 10:20:45 AM
To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


Redo the prior specification from scratch (i.e., overwrite the entire `prior` object). The original code creates an unecessary/undefined element in the prior list.


Matthew


****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu<mailto:matthew.wolak at auburn.edu>


On 22/09/17 12:17, dani wrote:

just a correction, the code prior$B$V[k,k]<-1e-8 works but the model provides this error


Error in MCMCglmm(y ~ x1 + x2 + X8 + x9 +x10 +  :
  prior list should contain elements R, G, and/or B only



Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Matthew <mew0099 at auburn.edu><mailto:mew0099 at auburn.edu>
Sent: Friday, September 22, 2017 10:10 AM
To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hi Dani,

Jarrod probably meant

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-8

Instead of:

prior$mu[k]<-1 # assuming the offset term is last
prior$B[k,k]<-1e-8


Sincerely,
Matthew

****************************************************
Matthew E. Wolak, Ph.D.
Assistant Professor
Department of Biological Sciences
Auburn University
306 Funchess Hall
Auburn, AL 36849, USA
Email: matthew.wolak at auburn.edu<mailto:matthew.wolak at auburn.edu>

On 22/09/17 12:01, dani wrote:
> Hi Jarrod,
>
>
> Thank you so much for your prompt and helpful response!
>
> I ran the code you sent me for the prior, but I am getting the following error:
>
> Error in prior$B[k, k] <- 1e-08 :
>    incorrect number of subscripts on matrix
>
>
> Here is what I get for prior:
>> prior
> $B
> $B$V
>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>   [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>   [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>   [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>   [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>   [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
>
> $B$mu
>   [1] 0 0 0 0 0 0 0 0 0 0 0
>
>
> $R
> $R$V
> [1] 1
>
> $R$nu
> [1] 0
>
>
> $G
> $G$G1
> $G$G1$V
> [1] 1
>
> $G$G1$nu
> [1] 0
>
>
> $G$G2
> $G$G2$V
> [1] 1
>
> $G$G2$nu
> [1] 0
>
>
> $G$G3
> $G$G3$V
> [1] 1
>
> $G$G3$nu
> [1] 0
>
>
>
> $mu
>   [1] NA NA NA NA NA NA NA NA NA NA  1
>
>
>
> I am not sure what to do next. Any help would be very appreciated!
>
> Best regards,
>
> N-M
>
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>
> ________________________________
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
> Sent: Thursday, September 21, 2017 9:55 PM
> To: dani; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
> Hi,
>
> The model looks OK as far as can be assessed without knowing the data.
> For the offset term you need to hold the associated coefficient at 1 by
> placing a strong prior on it. If  you want everything else to have the
> default prior then use:
>
> k<-11 # number of fixed effects
>
> prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
>               R=list(V=1, nu=0),
>               G=list(G1=list(V=1, nu=0),
>                      G2=list(V=1, nu=0),
>                      G3=list(V=1, nu=0)))
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
> The interpretation of the offset is simply the coefficient is assumed to
> be one and that the rate at which events occur is constant.
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 22/09/2017 01:52, dani wrote:
>> Hello everyone,
>>
>> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>>
>> The model includes
>> - four categorical variables
>> - 6 continuous variables (for one of them I would like to include a smoother)
>> - the offset=log(duration)
>>
>> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>>
>> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>>
>> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>>                       random =~ ID+class+idv(x6numspline2),
>>                       data   = newdat,
>>                       family = "poisson",
>>                       thin   = 100,
>>                       burnin = 10000,
>>                       nitt   = 150000,
>>                       saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>
>> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>>
>> Thank you all so much!
>> Best regards,
>> N-M.
>> <http://aka.ms/weboutlook>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 22 21:12:08 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Sep 2017 15:12:08 -0400
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>

  I suspect that the broad range of the prior variances (from 1e8 to
1e-8) has led to an underflow error.  Try setting the prior variances
to 1e4 for all but the offset element and 1e-4 for the offset element ...

  Just a quick comment: this is why it can be helpful to provide a
minimal reproducible example
(you don't necessarily have to give us all of your data: see
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example).
Debugging one step at a time can be frustrating for all concerned ...

On Fri, Sep 22, 2017 at 1:34 PM, dani <orchidn at live.com> wrote:
> Hi again,
>
>
> Thanks! It looks like it is working. This is like V looks like:
>
>> prior$B$V
>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>  [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>  [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>  [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>  [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>  [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>  [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>  [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>  [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>  [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e-08
>
> However, when I run my model, I get this new error:
>  fixed effect V prior is not positive definite
>
>
> Thanks!
>
> Sent from Outlook<http://aka.ms/weboutlook>
> ________________________________
> From: Matthew <mew0099 at auburn.edu>
> Sent: Friday, September 22, 2017 10:20:45 AM
> To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
>
> Hi Dani,
>
>
> Redo the prior specification from scratch (i.e., overwrite the entire `prior` object). The original code creates an unecessary/undefined element in the prior list.
>
>
> Matthew
>
>
> ****************************************************
> Matthew E. Wolak, Ph.D.
> Assistant Professor
> Department of Biological Sciences
> Auburn University
> 306 Funchess Hall
> Auburn, AL 36849, USA
> Email: matthew.wolak at auburn.edu<mailto:matthew.wolak at auburn.edu>
>
>
> On 22/09/17 12:17, dani wrote:
>
> just a correction, the code prior$B$V[k,k]<-1e-8 works but the model provides this error
>
>
> Error in MCMCglmm(y ~ x1 + x2 + X8 + x9 +x10 +  :
>   prior list should contain elements R, G, and/or B only
>
>
>
> Sent from Outlook<http://aka.ms/weboutlook>
>
>
> ________________________________
> From: Matthew <mew0099 at auburn.edu><mailto:mew0099 at auburn.edu>
> Sent: Friday, September 22, 2017 10:10 AM
> To: dani; Jarrod Hadfield; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>
> Hi Dani,
>
> Jarrod probably meant
>
> prior$B$mu[k]<-1 # assuming the offset term is last
> prior$B$V[k,k]<-1e-8
>
> Instead of:
>
> prior$mu[k]<-1 # assuming the offset term is last
> prior$B[k,k]<-1e-8
>
>
> Sincerely,
> Matthew
>
> ****************************************************
> Matthew E. Wolak, Ph.D.
> Assistant Professor
> Department of Biological Sciences
> Auburn University
> 306 Funchess Hall
> Auburn, AL 36849, USA
> Email: matthew.wolak at auburn.edu<mailto:matthew.wolak at auburn.edu>
>
> On 22/09/17 12:01, dani wrote:
>> Hi Jarrod,
>>
>>
>> Thank you so much for your prompt and helpful response!
>>
>> I ran the code you sent me for the prior, but I am getting the following error:
>>
>> Error in prior$B[k, k] <- 1e-08 :
>>    incorrect number of subscripts on matrix
>>
>>
>> Here is what I get for prior:
>>> prior
>> $B
>> $B$V
>>         [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
>>   [1,] 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [2,] 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [3,] 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [4,] 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [5,] 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [6,] 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00 0e+00
>>   [7,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00 0e+00
>>   [8,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00 0e+00
>>   [9,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00 0e+00
>> [10,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08 0e+00
>> [11,] 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 0e+00 1e+08
>>
>> $B$mu
>>   [1] 0 0 0 0 0 0 0 0 0 0 0
>>
>>
>> $R
>> $R$V
>> [1] 1
>>
>> $R$nu
>> [1] 0
>>
>>
>> $G
>> $G$G1
>> $G$G1$V
>> [1] 1
>>
>> $G$G1$nu
>> [1] 0
>>
>>
>> $G$G2
>> $G$G2$V
>> [1] 1
>>
>> $G$G2$nu
>> [1] 0
>>
>>
>> $G$G3
>> $G$G3$V
>> [1] 1
>>
>> $G$G3$nu
>> [1] 0
>>
>>
>>
>> $mu
>>   [1] NA NA NA NA NA NA NA NA NA NA  1
>>
>>
>>
>> I am not sure what to do next. Any help would be very appreciated!
>>
>> Best regards,
>>
>> N-M
>>
>>
>>
>> Sent from Outlook<http://aka.ms/weboutlook>
>>
>>
>> ________________________________
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
>> Sent: Thursday, September 21, 2017 9:55 PM
>> To: dani; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>
>> Hi,
>>
>> The model looks OK as far as can be assessed without knowing the data.
>> For the offset term you need to hold the associated coefficient at 1 by
>> placing a strong prior on it. If  you want everything else to have the
>> default prior then use:
>>
>> k<-11 # number of fixed effects
>>
>> prior<-list(B=list(V=diag(k)*1e8, mu=rep(0,k)),
>>               R=list(V=1, nu=0),
>>               G=list(G1=list(V=1, nu=0),
>>                      G2=list(V=1, nu=0),
>>                      G3=list(V=1, nu=0)))
>>
>> prior$mu[k]<-1 # assuming the offset term is last
>> prior$B[k,k]<-1e-8
>>
>> The interpretation of the offset is simply the coefficient is assumed to
>> be one and that the rate at which events occur is constant.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> On 22/09/2017 01:52, dani wrote:
>>> Hello everyone,
>>>
>>> I have a Poisson model with an offset term that involves repeated observations nested into two cross-classified groups.
>>>
>>> The model includes
>>> - four categorical variables
>>> - 6 continuous variables (for one of them I would like to include a smoother)
>>> - the offset=log(duration)
>>>
>>> I first used the spl2 function to create the fixed ((x6numspline1) and random terms (x6numspline2) for the smoother. I added the random smoother term to the other two random intercepts (for student ID and classroom) that I have (which are cross-classified).
>>>
>>> My question is: Do you find my model sound? Before I study the priors, I just wanted to run a default model - is my inclusion of an offset ok? Also, given that the observations are repeated and nested into both Student ID and classroom, I am not sure how to specify the variance structure in MCMCglmm (beginner here:))
>>>
>>> mc_spl0 <- MCMCglmm(number_events ~ x1cat+x2cat+x8cat+x9cat+x3num+x4num+x5num+x6numspline1+x7num+x8num+log(duration),
>>>                       random =~ ID+class+idv(x6numspline2),
>>>                       data   = newdat,
>>>                       family = "poisson",
>>>                       thin   = 100,
>>>                       burnin = 10000,
>>>                       nitt   = 150000,
>>>                       saveX=TRUE, saveZ=TRUE, saveXL=TRUE, pr=TRUE, pl=TRUE)
>>>
>>> In addition, I am not sure what to make of the results for the offset term (included as a covariate in the model) in the output - how should I discuss them?
>>>
>>> Thank you all so much!
>>> Best regards,
>>> N-M.
>>> <http://aka.ms/weboutlook>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Maarten.Jung at mailbox.tu-dresden.de  Sat Sep 23 11:43:27 2017
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sat, 23 Sep 2017 11:43:27 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
Message-ID: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>

Hello everyone,

I have a question regarding the equivalence of the following models:

m1 <- lmer(y ~ factor + (0 + factor|group))
m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))

Douglas Bates states (slide 91 in this presentation [1])  that these models
are equivalent in case of compound symmetry.

1. I realized that I don't really understand the random slope by factor
model (m1) and espacially why it reduces to m2 given compound symmetry.
Also, why is there no random intercept in m1?
Can anyone explain the difference between the models and how m1 reduces to
m2 in an intuitive way.

2. If m1 is a special case of m2 ? this could be an interesting option for
model reduction but I?ve never seen something like m2 in papers. Instead
they suggest dropping the random slope and thus the interaction completely
(e.g. Matuschek et al. 2017 [3]).
What do you think about it?

Please note that I asked the question on Stack Exchange [2] but some
consider it as off-topic. So, I hope one of you can help me out.


Best regards,
Maarten

[1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
[2] https://stats.stackexchange.com/q/304374/136579
[3] https://doi.org/10.1016/j.jml.2017.01.001

	[[alternative HTML version deleted]]


From reinhold.kliegl at gmail.com  Sat Sep 23 13:41:40 2017
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 23 Sep 2017 13:41:40 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
Message-ID: <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>

The models are on a continuum of complexity wrt to the random-effects
structure. Specifically:

m1 estimates k variance components and k(k-1) correlation parameters for
the k levels of factor f

m2 estimates 1 variance component for the intercept and a 1 variance
component for the k-1 contrasts defined for the k levels of factor f, that
it constrains the k-1 contrasts for factor f to the same value. The
correlation parameters are forced to zero.

The continuum becomes transparent if one re-parameterizes m1 as a m1a (see
below) with 1 variance component for the intercept and k-1 variance
components for the k levels of factor f, and k(k-1) correlation parameters.
 m1 and m1a have the same number of parameters and identical deviance.

m1a <- lmer(y ~ factor + (factor|group))

There is an additional model specification on this continuum between m1 and
m2.  If contrasts are converted to numeric covariates, one can force
correlation parameters to zero, but estimate different variance components
for the k-1 contrasts of factor f. We call this the zero-correlation
parameter model.

cB_A <- model.matrix(m1)[,2]
cC_A <- model.matrix(m1)[,3]

m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
 data=Machines, REML=FALSE)
print(summary(m.zcp), corr=FALSE)

Note that m.zcp without the double-bar is equivalent to m1 and m1b.
m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
 data=Machines, REML=FALSE)
print(summary(m.zcp), corr=FALSE)

Of course, there is also a simpler model than m2 - the
varying-intercept-only model:

m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
REML=FALSE)
print(summary(m.zcp), corr=FALSE)

Here is some R code demonstrating all this for the Machines data.

####
library(lme4)
#library(RePsychLing)

data("Machines", package = "MEMSS")

# OP m1
m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker), data=Machines,
REML=FALSE)
print(summary(m1), corr=FALSE)

# re-parameterization of m1
m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker), data=Machines,
REML=FALSE)
print(summary(m1a), corr=FALSE)

# alternative specification of m1a
cB_A <- model.matrix(m1)[,2]
cC_A <- model.matrix(m1)[,3]

m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
 data=Machines, REML=FALSE)
print(summary(m1b), corr=FALSE)

anova(m1, m1a, m1b)

# zero-correlation parameter LMM
m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
 data=Machines, REML=FALSE)
print(summary(m.zcp), corr=FALSE)

# OP m2
m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
data=Machines, REML=FALSE)
print(summary(m2), corr=FALSE)

# varying-intercept-only LMM
m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines, REML=FALSE)
print(summary(m.vio), corr=FALSE)

anova(m1, m.zcp, m2, m.vio)

sessionInfo()
####

You may also want to look this RPub:
http://www.rpubs.com/Reinhold/22193

On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Hello everyone,
>
> I have a question regarding the equivalence of the following models:
>
> m1 <- lmer(y ~ factor + (0 + factor|group))
> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
>
> Douglas Bates states (slide 91 in this presentation [1])  that these models
> are equivalent in case of compound symmetry.
>
> 1. I realized that I don't really understand the random slope by factor
> model (m1) and espacially why it reduces to m2 given compound symmetry.
> Also, why is there no random intercept in m1?
> Can anyone explain the difference between the models and how m1 reduces to
> m2 in an intuitive way.
>
> 2. If m1 is a special case of m2 ? this could be an interesting option for
> model reduction but I?ve never seen something like m2 in papers. Instead
> they suggest dropping the random slope and thus the interaction completely
> (e.g. Matuschek et al. 2017 [3]).
> What do you think about it?
>
> Please note that I asked the question on Stack Exchange [2] but some
> consider it as off-topic. So, I hope one of you can help me out.
>
>
> Best regards,
> Maarten
>
> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
> [2] https://stats.stackexchange.com/q/304374/136579
> [3] https://doi.org/10.1016/j.jml.2017.01.001
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From reinhold.kliegl at gmail.com  Sat Sep 23 13:51:57 2017
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 23 Sep 2017 13:51:57 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
Message-ID: <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>

This should always be "k(k-1)/2" correlation parameters, of course.

Also perhaps you may want to read this post to the list by Douglas Bates:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html

On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <reinhold.kliegl at gmail.com>
wrote:

> The models are on a continuum of complexity wrt to the random-effects
> structure. Specifically:
>
> m1 estimates k variance components and k(k-1) correlation parameters for
> the k levels of factor f
>
> m2 estimates 1 variance component for the intercept and a 1 variance
> component for the k-1 contrasts defined for the k levels of factor f, that
> it constrains the k-1 contrasts for factor f to the same value. The
> correlation parameters are forced to zero.
>
> The continuum becomes transparent if one re-parameterizes m1 as a m1a (see
> below) with 1 variance component for the intercept and k-1 variance
> components for the k levels of factor f, and k(k-1) correlation parameters.
>  m1 and m1a have the same number of parameters and identical deviance.
>
> m1a <- lmer(y ~ factor + (factor|group))
>
> There is an additional model specification on this continuum between m1
> and m2.  If contrasts are converted to numeric covariates, one can force
> correlation parameters to zero, but estimate different variance components
> for the k-1 contrasts of factor f. We call this the zero-correlation
> parameter model.
>
> cB_A <- model.matrix(m1)[,2]
> cC_A <- model.matrix(m1)[,3]
>
> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
>  data=Machines, REML=FALSE)
> print(summary(m.zcp), corr=FALSE)
>
> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
>  data=Machines, REML=FALSE)
> print(summary(m.zcp), corr=FALSE)
>
> Of course, there is also a simpler model than m2 - the
> varying-intercept-only model:
>
> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
> REML=FALSE)
> print(summary(m.zcp), corr=FALSE)
>
> Here is some R code demonstrating all this for the Machines data.
>
> ####
> library(lme4)
> #library(RePsychLing)
>
> data("Machines", package = "MEMSS")
>
> # OP m1
> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker), data=Machines,
> REML=FALSE)
> print(summary(m1), corr=FALSE)
>
> # re-parameterization of m1
> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker), data=Machines,
> REML=FALSE)
> print(summary(m1a), corr=FALSE)
>
> # alternative specification of m1a
> cB_A <- model.matrix(m1)[,2]
> cC_A <- model.matrix(m1)[,3]
>
> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
>  data=Machines, REML=FALSE)
> print(summary(m1b), corr=FALSE)
>
> anova(m1, m1a, m1b)
>
> # zero-correlation parameter LMM
> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
>  data=Machines, REML=FALSE)
> print(summary(m.zcp), corr=FALSE)
>
> # OP m2
> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
> data=Machines, REML=FALSE)
> print(summary(m2), corr=FALSE)
>
> # varying-intercept-only LMM
> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
> REML=FALSE)
> print(summary(m.vio), corr=FALSE)
>
> anova(m1, m.zcp, m2, m.vio)
>
> sessionInfo()
> ####
>
> You may also want to look this RPub:
> http://www.rpubs.com/Reinhold/22193
>
> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <Maarten.Jung at mailbox.tu-
> dresden.de> wrote:
>
>> Hello everyone,
>>
>> I have a question regarding the equivalence of the following models:
>>
>> m1 <- lmer(y ~ factor + (0 + factor|group))
>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
>>
>> Douglas Bates states (slide 91 in this presentation [1])  that these
>> models
>> are equivalent in case of compound symmetry.
>>
>> 1. I realized that I don't really understand the random slope by factor
>> model (m1) and espacially why it reduces to m2 given compound symmetry.
>> Also, why is there no random intercept in m1?
>> Can anyone explain the difference between the models and how m1 reduces to
>> m2 in an intuitive way.
>>
>> 2. If m1 is a special case of m2 ? this could be an interesting option for
>> model reduction but I?ve never seen something like m2 in papers. Instead
>> they suggest dropping the random slope and thus the interaction completely
>> (e.g. Matuschek et al. 2017 [3]).
>> What do you think about it?
>>
>> Please note that I asked the question on Stack Exchange [2] but some
>> consider it as off-topic. So, I hope one of you can help me out.
>>
>>
>> Best regards,
>> Maarten
>>
>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
>> [2] https://stats.stackexchange.com/q/304374/136579
>> [3] https://doi.org/10.1016/j.jml.2017.01.001
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From francescobryanromano at gmail.com  Sat Sep 23 18:48:51 2017
From: francescobryanromano at gmail.com (Francesco Romano)
Date: Sat, 23 Sep 2017 18:48:51 +0200
Subject: [R-sig-ME] Main effects for zero inflation poisson regression
Message-ID: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>

Hello All,

I am trying to run a type III Anova test on a zero-inflation poisson model
with count data to obtain stats for main effects. In other words, I would
like the output to include the df, Chisq, and p value for the main effect
of my fixed effects. In the past, I have done this using the 'mixed'
function or 'car::Anova' functions from the car package, or in the more
traditional (and tedious) way by model comparison via anova(model1, model2,
etc...).

Unfortunately, none of these methods work as R returns an error message:


#
> anova(p.tmb5, p.tmb5a)
Error in anova.glmmTMB(p.tmb5, p.tmb5a) :
  no single-model anova() method for glmmTMB

> car::Anova(p.tmb5, type = "III")
Error in I.p[subs, , drop = FALSE] : subscript out of bounds
In addition: Warning message:
In is.na(coef(mod)) :
  is.na() applied to non-(list or vector) of type 'NULL'

The mixed function also can't be used because it will not work with glmmTMB
which includes two formulas, one for the poisson regression, the other for
the zero-inflation (see below).

 My final model has two fixed effects, Verb.form and Response.type, with
three levels each, and a random effect for participants.

> p.tmb5<-glmmTMB(Count~Response.type*Verb.form+(1|Partname), data = p, zi
= ~Response.type)

Any suggestions are greatly appreciated. I attach my data in csv format.
PS: Partnames and classes are fictitious.

-- 
Frank Romano Ph.D.

From Maarten.Jung at mailbox.tu-dresden.de  Sat Sep 23 19:26:53 2017
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sat, 23 Sep 2017 19:26:53 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
 <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
Message-ID: <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>

Thanks, this really helped me understand the models!

There is one thing I still don't understand: I think that compound symmetry
implies equal variances within the factor levels and equal
covariances/correlations between the levels. If there are equal variances
within the factor levels and no correlations between the levels I
understand the equivalence of m1, m.zcp and m2.

But what if there are correlations between the levels? you explained that
m2 forces the correlation parameters to zero. But Douglas Bates states that
the models are equivalent given compound symmetry (which I think doesn't
imply zero correlations).

Just to double check: This m1 -> m.zcp -> m2 -> m.vio is a reasonable model
reduction approach, right?

2017-09-23 13:51 GMT+02:00 Reinhold Kliegl <reinhold.kliegl at gmail.com>:

> This should always be "k(k-1)/2" correlation parameters, of course.
>
> Also perhaps you may want to read this post to the list by Douglas Bates:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html
>
> On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <
> reinhold.kliegl at gmail.com> wrote:
>
>> The models are on a continuum of complexity wrt to the random-effects
>> structure. Specifically:
>>
>> m1 estimates k variance components and k(k-1) correlation parameters for
>> the k levels of factor f
>>
>> m2 estimates 1 variance component for the intercept and a 1 variance
>> component for the k-1 contrasts defined for the k levels of factor f, that
>> it constrains the k-1 contrasts for factor f to the same value. The
>> correlation parameters are forced to zero.
>>
>> The continuum becomes transparent if one re-parameterizes m1 as a m1a
>> (see below) with 1 variance component for the intercept and k-1 variance
>> components for the k levels of factor f, and k(k-1) correlation parameters.
>>  m1 and m1a have the same number of parameters and identical deviance.
>>
>> m1a <- lmer(y ~ factor + (factor|group))
>>
>> There is an additional model specification on this continuum between m1
>> and m2.  If contrasts are converted to numeric covariates, one can force
>> correlation parameters to zero, but estimate different variance components
>> for the k-1 contrasts of factor f. We call this the zero-correlation
>> parameter model.
>>
>> cB_A <- model.matrix(m1)[,2]
>> cC_A <- model.matrix(m1)[,3]
>>
>> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
>>  data=Machines, REML=FALSE)
>> print(summary(m.zcp), corr=FALSE)
>>
>> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
>> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
>>  data=Machines, REML=FALSE)
>> print(summary(m.zcp), corr=FALSE)
>>
>> Of course, there is also a simpler model than m2 - the
>> varying-intercept-only model:
>>
>> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
>> REML=FALSE)
>> print(summary(m.zcp), corr=FALSE)
>>
>> Here is some R code demonstrating all this for the Machines data.
>>
>> ####
>> library(lme4)
>> #library(RePsychLing)
>>
>> data("Machines", package = "MEMSS")
>>
>> # OP m1
>> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker), data=Machines,
>> REML=FALSE)
>> print(summary(m1), corr=FALSE)
>>
>> # re-parameterization of m1
>> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker), data=Machines,
>> REML=FALSE)
>> print(summary(m1a), corr=FALSE)
>>
>> # alternative specification of m1a
>> cB_A <- model.matrix(m1)[,2]
>> cC_A <- model.matrix(m1)[,3]
>>
>> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
>>  data=Machines, REML=FALSE)
>> print(summary(m1b), corr=FALSE)
>>
>> anova(m1, m1a, m1b)
>>
>> # zero-correlation parameter LMM
>> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
>>  data=Machines, REML=FALSE)
>> print(summary(m.zcp), corr=FALSE)
>>
>> # OP m2
>> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
>> data=Machines, REML=FALSE)
>> print(summary(m2), corr=FALSE)
>>
>> # varying-intercept-only LMM
>> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
>> REML=FALSE)
>> print(summary(m.vio), corr=FALSE)
>>
>> anova(m1, m.zcp, m2, m.vio)
>>
>> sessionInfo()
>> ####
>>
>> You may also want to look this RPub:
>> http://www.rpubs.com/Reinhold/22193
>>
>> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>
>>> Hello everyone,
>>>
>>> I have a question regarding the equivalence of the following models:
>>>
>>> m1 <- lmer(y ~ factor + (0 + factor|group))
>>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
>>>
>>> Douglas Bates states (slide 91 in this presentation [1])  that these
>>> models
>>> are equivalent in case of compound symmetry.
>>>
>>> 1. I realized that I don't really understand the random slope by factor
>>> model (m1) and espacially why it reduces to m2 given compound symmetry.
>>> Also, why is there no random intercept in m1?
>>> Can anyone explain the difference between the models and how m1 reduces
>>> to
>>> m2 in an intuitive way.
>>>
>>> 2. If m1 is a special case of m2 ? this could be an interesting option
>>> for
>>> model reduction but I?ve never seen something like m2 in papers. Instead
>>> they suggest dropping the random slope and thus the interaction
>>> completely
>>> (e.g. Matuschek et al. 2017 [3]).
>>> What do you think about it?
>>>
>>> Please note that I asked the question on Stack Exchange [2] but some
>>> consider it as off-topic. So, I hope one of you can help me out.
>>>
>>>
>>> Best regards,
>>> Maarten
>>>
>>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
>>> [2] https://stats.stackexchange.com/q/304374/136579
>>> [3] https://doi.org/10.1016/j.jml.2017.01.001
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Sep 25 01:28:19 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 24 Sep 2017 19:28:19 -0400
Subject: [R-sig-ME] Main effects for zero inflation poisson regression
In-Reply-To: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>
References: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>
Message-ID: <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>

I think it would be worth posting this as an issue on the glmmTMB
issues list here: https://github.com/glmmtmb/glmmTMB/issues .  (You
might be able to attach a CSV file there: you can't send CSV
attachments to this mailing list.)

I'm not surprised that car::Anova doesn't work (I've still been
working on that one: see
https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/inst/other_methods/car_methods.R
). On the other hand, I am surprised that the standard two-model
anova() method doesn't work for you, e.g.

 g1 <- glmmTMB(Reaction~Days+(Days|Subject),lme4::sleepstudy)
 g0 <- update(g1,.~.-Days)
 anova(g0,g1)

On Sat, Sep 23, 2017 at 12:48 PM, Francesco Romano
<francescobryanromano at gmail.com> wrote:
> Hello All,
>
> I am trying to run a type III Anova test on a zero-inflation poisson model
> with count data to obtain stats for main effects. In other words, I would
> like the output to include the df, Chisq, and p value for the main effect
> of my fixed effects. In the past, I have done this using the 'mixed'
> function or 'car::Anova' functions from the car package, or in the more
> traditional (and tedious) way by model comparison via anova(model1, model2,
> etc...).
>
> Unfortunately, none of these methods work as R returns an error message:
>
>
> #
>> anova(p.tmb5, p.tmb5a)
> Error in anova.glmmTMB(p.tmb5, p.tmb5a) :
>   no single-model anova() method for glmmTMB
>
>> car::Anova(p.tmb5, type = "III")
> Error in I.p[subs, , drop = FALSE] : subscript out of bounds
> In addition: Warning message:
> In is.na(coef(mod)) :
>   is.na() applied to non-(list or vector) of type 'NULL'
>
> The mixed function also can't be used because it will not work with glmmTMB
> which includes two formulas, one for the poisson regression, the other for
> the zero-inflation (see below).
>
>  My final model has two fixed effects, Verb.form and Response.type, with
> three levels each, and a random effect for participants.
>
>> p.tmb5<-glmmTMB(Count~Response.type*Verb.form+(1|Partname), data = p, zi
> = ~Response.type)
>
> Any suggestions are greatly appreciated. I attach my data in csv format.
> PS: Partnames and classes are fictitious.
>
> --
> Frank Romano Ph.D.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jdpo223 at g.uky.edu  Mon Sep 25 02:59:38 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sun, 24 Sep 2017 20:59:38 -0400
Subject: [R-sig-ME] Getting the right uncertainties when fitting multilevel
	models
In-Reply-To: <CAFW8ByoMnvaEK73TE1E-QwWgqEMSQ8kcOZD+PaD6V55Db3RsUg@mail.gmail.com>
References: <CAFW8Byr3rCPfB7ZqCbSrUXcq96h3LMaF_fbOnHXBejvJvJEGsw@mail.gmail.com>
 <CAFW8ByrjL-0ve-6ipjzmHUKUznwEZW-YuCNwm-ZSSWPYQsmT+A@mail.gmail.com>
 <CAFW8Byre=i-OSWt+=VmfggGQBjWTzningeOnZ1_5pgi7kU+MMw@mail.gmail.com>
 <CAFW8Byp+0sRK5=KuEFgS_eOHhwVR1acGbnNdG=+5BpeN4YNPMg@mail.gmail.com>
 <CAFW8ByqdjLrsHkw55fB17XZZCa-inYx7jWVPhUuOc834M+OXRg@mail.gmail.com>
 <CAFW8Byq+U5u9avKKeSeBUVub1Q58fsZQA_TcXgJWO41sPXZ80g@mail.gmail.com>
 <CAFW8ByoMnvaEK73TE1E-QwWgqEMSQ8kcOZD+PaD6V55Db3RsUg@mail.gmail.com>
Message-ID: <CAFW8ByopscB_orj9A8KyntC-QwRbvFZUV-q9mW+QNFEE-mteWA@mail.gmail.com>

I'm just wondering if anyone who knows more about lme4 than i do has any
comments on the Gelman post today. He's pretty vague and brief in his
reply.



Cesare Aloisi writes:

I am writing you regarding something I recently stumbled upon in your book
Data Analysis Using Regression and Multilevel/Hierarchical Models which
confused me, in hopes you could help me understand it. This book has been
my reference guide for many years now, and I am extremely grateful for
everything I learnt from you.

On page 261, a 95% confidence interval for the intercept in a certain group
(County 26) is calculated using only the standard error of the ?random
effect? (the county-level error). The string is as follows:

coef(M1)$county[26,1] + c(-2,2)*se.ranef(M1)$county[26]

My understanding is that, since the group-level prediction (call it y.hat_j
= coef(M1)$county[26,1]) is a linear combination of a global average and a
group-level deviation from the average (y.hat_j = beta_0 + eta_j), then the
variance of y.hat_j should be the sum of the covariances of beta_0 and
eta_j, not just the variance of eta_j, as the code on page 261 seems to
imply. In other words:

Var(y.hat_j) = Var(beta_0) + Var(eta_j) + 2Cov(beta_0, eta_j)

Admittedly, lme4 does not provide an estimate for the last term, the
covariance between ?fixed? and ?random? effects. Was the code used in the
book to simplify the calculations, or was there some deeper reason to it
that I failed to grasp?

My (Gelman's) reply: The short answer is that it?s difficult to get this
correct in lmer but very easy when using stan_lmer() in the rstanarm
package. That?s what I recommend, and that?s what we?ll be doing in the 2nd
edition of our book


http://andrewgelman.com/2017/09/23/getting-right-uncertainties-fitting-multilevel-models/

	[[alternative HTML version deleted]]


From bachlaw01 at outlook.com  Mon Sep 25 04:07:34 2017
From: bachlaw01 at outlook.com (Jonathan Judge)
Date: Mon, 25 Sep 2017 02:07:34 +0000
Subject: [R-sig-ME] Getting the right uncertainties when fitting
 multilevel	models
In-Reply-To: <CAFW8ByopscB_orj9A8KyntC-QwRbvFZUV-q9mW+QNFEE-mteWA@mail.gmail.com>
References: <CAFW8Byr3rCPfB7ZqCbSrUXcq96h3LMaF_fbOnHXBejvJvJEGsw@mail.gmail.com>
 <CAFW8ByrjL-0ve-6ipjzmHUKUznwEZW-YuCNwm-ZSSWPYQsmT+A@mail.gmail.com>
 <CAFW8Byre=i-OSWt+=VmfggGQBjWTzningeOnZ1_5pgi7kU+MMw@mail.gmail.com>
 <CAFW8Byp+0sRK5=KuEFgS_eOHhwVR1acGbnNdG=+5BpeN4YNPMg@mail.gmail.com>
 <CAFW8ByqdjLrsHkw55fB17XZZCa-inYx7jWVPhUuOc834M+OXRg@mail.gmail.com>
 <CAFW8Byq+U5u9avKKeSeBUVub1Q58fsZQA_TcXgJWO41sPXZ80g@mail.gmail.com>
 <CAFW8ByoMnvaEK73TE1E-QwWgqEMSQ8kcOZD+PaD6V55Db3RsUg@mail.gmail.com>,
 <CAFW8ByopscB_orj9A8KyntC-QwRbvFZUV-q9mW+QNFEE-mteWA@mail.gmail.com>
Message-ID: <DM3PR16MB0700CAE0E45D7DDBBFC3EE63AF7A0@DM3PR16MB0700.namprd16.prod.outlook.com>

Not entirely sure what you are looking for but I believe the example just extrapolates from the random effects having a normal default distribution and adds an interval of 2 SDs to the county intercept plus underlying population coefficient estimate to get the likely range for a particular county.

Better ways to approximate this confidence interval now would be to either use merTools (which extends the arm::sim function to simulate intervals for mixed model parameters / intercepts) or bootMer, which gives similar approximations in a more robust way (and often provides narrower / more confident estimates in my experience). Any true Bayesian method, such as the stan_glmer function, will usually provide even more robust estimates, as Gelman indicates, and return intervals by default.

As always, sample size is important. The larger the sample, the less that the difference in method matters. IIRC, the radon data set is sufficiently small that incorporating uncertainty into the model is probably beneficial.

I suspect Gelman?s point is that the rstanarm package is now sufficiently comparable to lme4 for ease of use that he will start with rstanarm as his gateway drug (instead of lme4) and then move to Stan code from there. But I guess we?ll have to see.

Best,
Jonathan

On Sep 24, 2017, at 7:59 PM, Poe, John <jdpo223 at g.uky.edu<mailto:jdpo223 at g.uky.edu>> wrote:

I'm just wondering if anyone who knows more about lme4 than i do has any
comments on the Gelman post today. He's pretty vague and brief in his
reply.



Cesare Aloisi writes:

I am writing you regarding something I recently stumbled upon in your book
Data Analysis Using Regression and Multilevel/Hierarchical Models which
confused me, in hopes you could help me understand it. This book has been
my reference guide for many years now, and I am extremely grateful for
everything I learnt from you.

On page 261, a 95% confidence interval for the intercept in a certain group
(County 26) is calculated using only the standard error of the ?random
effect? (the county-level error). The string is as follows:

coef(M1)$county[26,1] + c(-2,2)*se.ranef(M1)$county[26]

My understanding is that, since the group-level prediction (call it y.hat_j
= coef(M1)$county[26,1]) is a linear combination of a global average and a
group-level deviation from the average (y.hat_j = beta_0 + eta_j), then the
variance of y.hat_j should be the sum of the covariances of beta_0 and
eta_j, not just the variance of eta_j, as the code on page 261 seems to
imply. In other words:

Var(y.hat_j) = Var(beta_0) + Var(eta_j) + 2Cov(beta_0, eta_j)

Admittedly, lme4 does not provide an estimate for the last term, the
covariance between ?fixed? and ?random? effects. Was the code used in the
book to simplify the calculations, or was there some deeper reason to it
that I failed to grasp?

My (Gelman's) reply: The short answer is that it?s difficult to get this
correct in lmer but very easy when using stan_lmer() in the rstanarm
package. That?s what I recommend, and that?s what we?ll be doing in the 2nd
edition of our book


http://andrewgelman.com/2017/09/23/getting-right-uncertainties-fitting-multilevel-models/

   [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Sep 25 09:29:49 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 25 Sep 2017 20:29:49 +1300
Subject: [R-sig-ME] [FORGED] Re: Main effects for zero inflation poisson
 regression
In-Reply-To: <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
References: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>
 <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
Message-ID: <cbe7fed7-4556-f161-7704-5a5cd509ae3a@auckland.ac.nz>

On 25/09/17 12:28, Ben Bolker wrote:
> I think it would be worth posting this as an issue on the glmmTMB
> issues list here: https://github.com/glmmtmb/glmmTMB/issues .  (You
> might be able to attach a CSV file there: you can't send CSV
> attachments to this mailing list.)

<SNIP>

It is my understanding that you *can* send csv attachments to this list; 
you just can't *call* them that.  I.e. if you want to attach a csv file 
"clyde.csv" to a post to this list just rename it "clyde.txt" and attach 
that.  It will go through since it actually *is* a plain text file and 
these are acceptable.  Of course alert your readers to what you have done.

If I am wrong about this, please enlighten me.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From emmanuel.curis at parisdescartes.fr  Mon Sep 25 10:15:41 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Mon, 25 Sep 2017 10:15:41 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
 <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
 <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>
Message-ID: <20170925081541.GC11898@info124.pharmacie.univ-paris5.fr>

Hello,

I'm not sure if I understand correctly, but I think the "compound
symmetry" mention usually applies to the covariance matrix of the
observations, Y, in a given cluster.

In that case, and omiting the fixed part of the model that does not
change the Y covariance matrix, we have

 Y = fixed effects + X U + epsilon

with U the random effect(s), X the design matrix for it, and epsilon
the residual error.

Hence, assuming random effect and epsilon independant

Sigma(Y) = tX Sigma( U ) X + Sigma( epsilon)

so Sigma(Y) will have compound symmetry as soon as both X Sigma(U) tX
and Sigma( epsilon ) have themselves compound symmetry ? or if they
have structure that kind of "compensate" themselve. So basically, that
does not preclude from having correlations between levels of a fixed
effect factor.

However, let consider a scholar case with two observations on the same
patient [cluster] that takes or not its treatment [fixed effect], with
a different random effect for both cases, and let consider two ways of
writing it.

Let Sigma(epsilon) = ( se? rse   ), Sigma(U) = ( sa? r   )
                     ( rse  se?' )             ( r   sb? )

(typically, rse = 0, se? = se?')

1) Let be U1 the random effect for patient without treatment and U2
   therandom effect for the same patient with treatment, so

X = ( 1 0 ) = identity.
    ( 0 1 )

In that case, X Sigma(U) tX = Sigma(U) so 

Sigma(Y) = ( sa? + se?     r + rse  )
           (  r  + rse   sb? + se?' )

and you have compound symmetry if sa? + se? = sb? + se?', that is in
the classical case of se? = se?', assuming equal variances for both
the two random effects. But there is no condition on r: you can have
any correlation between the levels and still have compound symmetry.

2) U1 for patient i and U2 for effect of treatment in patient i.

So X = ( 1 0 ), tX = ( 1 1 )
       ( 1 1 )       ( 0 1 )

Then Sigma(Y) = ( sa? + se?        sa? + r + rse         )
                ( sa? + r + rse    sa? + sb? + 2r + se?' )

and compound symmetry is much harder to obtain for Y, you should have
se? = sb? + se?' + 2r ? only possible for the usual model that assumes
se?' = se? if r = -sb?/2, which is a special case. Other correlations
between levels (r) will not lead to compound symmetry.

(Hope my computations are correct).

This suggests that the answer also depends on the way the model is
coded...

Hope this helps and really corresponds to the question asked,

Best regards,

On Sat, Sep 23, 2017 at 07:26:53PM +0200, Maarten Jung wrote:
? Thanks, this really helped me understand the models!
? 
? There is one thing I still don't understand: I think that compound symmetry
? implies equal variances within the factor levels and equal
? covariances/correlations between the levels. If there are equal variances
? within the factor levels and no correlations between the levels I
? understand the equivalence of m1, m.zcp and m2.
? 
? But what if there are correlations between the levels? you explained that
? m2 forces the correlation parameters to zero. But Douglas Bates states that
? the models are equivalent given compound symmetry (which I think doesn't
? imply zero correlations).
? 
? Just to double check: This m1 -> m.zcp -> m2 -> m.vio is a reasonable model
? reduction approach, right?
? 
? 2017-09-23 13:51 GMT+02:00 Reinhold Kliegl <reinhold.kliegl at gmail.com>:
? 
? > This should always be "k(k-1)/2" correlation parameters, of course.
? >
? > Also perhaps you may want to read this post to the list by Douglas Bates:
? > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html
? >
? > On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <
? > reinhold.kliegl at gmail.com> wrote:
? >
? >> The models are on a continuum of complexity wrt to the random-effects
? >> structure. Specifically:
? >>
? >> m1 estimates k variance components and k(k-1) correlation parameters for
? >> the k levels of factor f
? >>
? >> m2 estimates 1 variance component for the intercept and a 1 variance
? >> component for the k-1 contrasts defined for the k levels of factor f, that
? >> it constrains the k-1 contrasts for factor f to the same value. The
? >> correlation parameters are forced to zero.
? >>
? >> The continuum becomes transparent if one re-parameterizes m1 as a m1a
? >> (see below) with 1 variance component for the intercept and k-1 variance
? >> components for the k levels of factor f, and k(k-1) correlation parameters.
? >>  m1 and m1a have the same number of parameters and identical deviance.
? >>
? >> m1a <- lmer(y ~ factor + (factor|group))
? >>
? >> There is an additional model specification on this continuum between m1
? >> and m2.  If contrasts are converted to numeric covariates, one can force
? >> correlation parameters to zero, but estimate different variance components
? >> for the k-1 contrasts of factor f. We call this the zero-correlation
? >> parameter model.
? >>
? >> cB_A <- model.matrix(m1)[,2]
? >> cC_A <- model.matrix(m1)[,3]
? >>
? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
? >>  data=Machines, REML=FALSE)
? >> print(summary(m.zcp), corr=FALSE)
? >>
? >> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
? >> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
? >>  data=Machines, REML=FALSE)
? >> print(summary(m.zcp), corr=FALSE)
? >>
? >> Of course, there is also a simpler model than m2 - the
? >> varying-intercept-only model:
? >>
? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
? >> REML=FALSE)
? >> print(summary(m.zcp), corr=FALSE)
? >>
? >> Here is some R code demonstrating all this for the Machines data.
? >>
? >> ####
? >> library(lme4)
? >> #library(RePsychLing)
? >>
? >> data("Machines", package = "MEMSS")
? >>
? >> # OP m1
? >> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker), data=Machines,
? >> REML=FALSE)
? >> print(summary(m1), corr=FALSE)
? >>
? >> # re-parameterization of m1
? >> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker), data=Machines,
? >> REML=FALSE)
? >> print(summary(m1a), corr=FALSE)
? >>
? >> # alternative specification of m1a
? >> cB_A <- model.matrix(m1)[,2]
? >> cC_A <- model.matrix(m1)[,3]
? >>
? >> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
? >>  data=Machines, REML=FALSE)
? >> print(summary(m1b), corr=FALSE)
? >>
? >> anova(m1, m1a, m1b)
? >>
? >> # zero-correlation parameter LMM
? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
? >>  data=Machines, REML=FALSE)
? >> print(summary(m.zcp), corr=FALSE)
? >>
? >> # OP m2
? >> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
? >> data=Machines, REML=FALSE)
? >> print(summary(m2), corr=FALSE)
? >>
? >> # varying-intercept-only LMM
? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
? >> REML=FALSE)
? >> print(summary(m.vio), corr=FALSE)
? >>
? >> anova(m1, m.zcp, m2, m.vio)
? >>
? >> sessionInfo()
? >> ####
? >>
? >> You may also want to look this RPub:
? >> http://www.rpubs.com/Reinhold/22193
? >>
? >> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
? >> Maarten.Jung at mailbox.tu-dresden.de> wrote:
? >>
? >>> Hello everyone,
? >>>
? >>> I have a question regarding the equivalence of the following models:
? >>>
? >>> m1 <- lmer(y ~ factor + (0 + factor|group))
? >>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
? >>>
? >>> Douglas Bates states (slide 91 in this presentation [1])  that these
? >>> models
? >>> are equivalent in case of compound symmetry.
? >>>
? >>> 1. I realized that I don't really understand the random slope by factor
? >>> model (m1) and espacially why it reduces to m2 given compound symmetry.
? >>> Also, why is there no random intercept in m1?
? >>> Can anyone explain the difference between the models and how m1 reduces
? >>> to
? >>> m2 in an intuitive way.
? >>>
? >>> 2. If m1 is a special case of m2 ? this could be an interesting option
? >>> for
? >>> model reduction but I?ve never seen something like m2 in papers. Instead
? >>> they suggest dropping the random slope and thus the interaction
? >>> completely
? >>> (e.g. Matuschek et al. 2017 [3]).
? >>> What do you think about it?
? >>>
? >>> Please note that I asked the question on Stack Exchange [2] but some
? >>> consider it as off-topic. So, I hope one of you can help me out.
? >>>
? >>>
? >>> Best regards,
? >>> Maarten
? >>>
? >>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
? >>> [2] https://stats.stackexchange.com/q/304374/136579
? >>> [3] https://doi.org/10.1016/j.jml.2017.01.001
? >>>
? >>>         [[alternative HTML version deleted]]
? >>>
? >>> _______________________________________________
? >>> R-sig-mixed-models at r-project.org mailing list
? >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >>
? >>
? >>
? >
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From j.hadfield at ed.ac.uk  Mon Sep 25 17:51:09 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Sep 2017 16:51:09 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>

Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the 
model. Change k to the number of fixed effects in the model.

Jarrod



On 25/09/2017 16:39, dani wrote:
> mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
> ?random =~ STUDYID+class+idv(l_lfvcspn),
> ?data ? = newdatab,
> ?family = "poisson"

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170925/cb9b8f07/attachment.ksh>

From orchidn at live.com  Mon Sep 25 19:08:08 2017
From: orchidn at live.com (dani)
Date: Mon, 25 Sep 2017 17:08:08 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
Message-ID: <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Mon Sep 25 21:38:07 2017
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Mon, 25 Sep 2017 21:38:07 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <20170925081541.GC11898@info124.pharmacie.univ-paris5.fr>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
 <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
 <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>
 <20170925081541.GC11898@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAHr4DycK6ynqnVWQi9+Wx-u=Sx+KyanwRo51oY2HsZ-BQ1tQ5A@mail.gmail.com>

Thanks for the very nice explanation of compound symmetry in your examples.
I understand the continuum of complexity wrt to the random-effects
structure explained by Reinhold Kliegl, also.
But I still don't see the link between m1 and m2 in case of compound
symmetry - sorry for that!
Analogous to this post http://www.rpubs.com/Reinhold/22193 mod2 should
constrain the group-related effects to equality. What exactly does this
have to do with compound symmetry?

2017-09-25 10:15 GMT+02:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
:

> Hello,
>
> I'm not sure if I understand correctly, but I think the "compound
> symmetry" mention usually applies to the covariance matrix of the
> observations, Y, in a given cluster.
>
> In that case, and omiting the fixed part of the model that does not
> change the Y covariance matrix, we have
>
>  Y = fixed effects + X U + epsilon
>
> with U the random effect(s), X the design matrix for it, and epsilon
> the residual error.
>
> Hence, assuming random effect and epsilon independant
>
> Sigma(Y) = tX Sigma( U ) X + Sigma( epsilon)
>
> so Sigma(Y) will have compound symmetry as soon as both X Sigma(U) tX
> and Sigma( epsilon ) have themselves compound symmetry ? or if they
> have structure that kind of "compensate" themselve. So basically, that
> does not preclude from having correlations between levels of a fixed
> effect factor.
>
> However, let consider a scholar case with two observations on the same
> patient [cluster] that takes or not its treatment [fixed effect], with
> a different random effect for both cases, and let consider two ways of
> writing it.
>
> Let Sigma(epsilon) = ( se? rse   ), Sigma(U) = ( sa? r   )
>                      ( rse  se?' )             ( r   sb? )
>
> (typically, rse = 0, se? = se?')
>
> 1) Let be U1 the random effect for patient without treatment and U2
>    therandom effect for the same patient with treatment, so
>
> X = ( 1 0 ) = identity.
>     ( 0 1 )
>
> In that case, X Sigma(U) tX = Sigma(U) so
>
> Sigma(Y) = ( sa? + se?     r + rse  )
>            (  r  + rse   sb? + se?' )
>
> and you have compound symmetry if sa? + se? = sb? + se?', that is in
> the classical case of se? = se?', assuming equal variances for both
> the two random effects. But there is no condition on r: you can have
> any correlation between the levels and still have compound symmetry.
>
> 2) U1 for patient i and U2 for effect of treatment in patient i.
>
> So X = ( 1 0 ), tX = ( 1 1 )
>        ( 1 1 )       ( 0 1 )
>
> Then Sigma(Y) = ( sa? + se?        sa? + r + rse         )
>                 ( sa? + r + rse    sa? + sb? + 2r + se?' )
>
> and compound symmetry is much harder to obtain for Y, you should have
> se? = sb? + se?' + 2r ? only possible for the usual model that assumes
> se?' = se? if r = -sb?/2, which is a special case. Other correlations
> between levels (r) will not lead to compound symmetry.
>
> (Hope my computations are correct).
>
> This suggests that the answer also depends on the way the model is
> coded...
>
> Hope this helps and really corresponds to the question asked,
>
> Best regards,
>
> On Sat, Sep 23, 2017 at 07:26:53PM +0200, Maarten Jung wrote:
> ? Thanks, this really helped me understand the models!
> ?
> ? There is one thing I still don't understand: I think that compound
> symmetry
> ? implies equal variances within the factor levels and equal
> ? covariances/correlations between the levels. If there are equal variances
> ? within the factor levels and no correlations between the levels I
> ? understand the equivalence of m1, m.zcp and m2.
> ?
> ? But what if there are correlations between the levels? you explained that
> ? m2 forces the correlation parameters to zero. But Douglas Bates states
> that
> ? the models are equivalent given compound symmetry (which I think doesn't
> ? imply zero correlations).
> ?
> ? Just to double check: This m1 -> m.zcp -> m2 -> m.vio is a reasonable
> model
> ? reduction approach, right?
> ?
> ? 2017-09-23 13:51 GMT+02:00 Reinhold Kliegl <reinhold.kliegl at gmail.com>:
> ?
> ? > This should always be "k(k-1)/2" correlation parameters, of course.
> ? >
> ? > Also perhaps you may want to read this post to the list by Douglas
> Bates:
> ? > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html
> ? >
> ? > On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <
> ? > reinhold.kliegl at gmail.com> wrote:
> ? >
> ? >> The models are on a continuum of complexity wrt to the random-effects
> ? >> structure. Specifically:
> ? >>
> ? >> m1 estimates k variance components and k(k-1) correlation parameters
> for
> ? >> the k levels of factor f
> ? >>
> ? >> m2 estimates 1 variance component for the intercept and a 1 variance
> ? >> component for the k-1 contrasts defined for the k levels of factor f,
> that
> ? >> it constrains the k-1 contrasts for factor f to the same value. The
> ? >> correlation parameters are forced to zero.
> ? >>
> ? >> The continuum becomes transparent if one re-parameterizes m1 as a m1a
> ? >> (see below) with 1 variance component for the intercept and k-1
> variance
> ? >> components for the k levels of factor f, and k(k-1) correlation
> parameters.
> ? >>  m1 and m1a have the same number of parameters and identical deviance.
> ? >>
> ? >> m1a <- lmer(y ~ factor + (factor|group))
> ? >>
> ? >> There is an additional model specification on this continuum between
> m1
> ? >> and m2.  If contrasts are converted to numeric covariates, one can
> force
> ? >> correlation parameters to zero, but estimate different variance
> components
> ? >> for the k-1 contrasts of factor f. We call this the zero-correlation
> ? >> parameter model.
> ? >>
> ? >> cB_A <- model.matrix(m1)[,2]
> ? >> cC_A <- model.matrix(m1)[,3]
> ? >>
> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
> ? >>  data=Machines, REML=FALSE)
> ? >> print(summary(m.zcp), corr=FALSE)
> ? >>
> ? >> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
> ? >> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
> ? >>  data=Machines, REML=FALSE)
> ? >> print(summary(m.zcp), corr=FALSE)
> ? >>
> ? >> Of course, there is also a simpler model than m2 - the
> ? >> varying-intercept-only model:
> ? >>
> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
> ? >> REML=FALSE)
> ? >> print(summary(m.zcp), corr=FALSE)
> ? >>
> ? >> Here is some R code demonstrating all this for the Machines data.
> ? >>
> ? >> ####
> ? >> library(lme4)
> ? >> #library(RePsychLing)
> ? >>
> ? >> data("Machines", package = "MEMSS")
> ? >>
> ? >> # OP m1
> ? >> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker),
> data=Machines,
> ? >> REML=FALSE)
> ? >> print(summary(m1), corr=FALSE)
> ? >>
> ? >> # re-parameterization of m1
> ? >> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker),
> data=Machines,
> ? >> REML=FALSE)
> ? >> print(summary(m1a), corr=FALSE)
> ? >>
> ? >> # alternative specification of m1a
> ? >> cB_A <- model.matrix(m1)[,2]
> ? >> cC_A <- model.matrix(m1)[,3]
> ? >>
> ? >> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
> ? >>  data=Machines, REML=FALSE)
> ? >> print(summary(m1b), corr=FALSE)
> ? >>
> ? >> anova(m1, m1a, m1b)
> ? >>
> ? >> # zero-correlation parameter LMM
> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
> ? >>  data=Machines, REML=FALSE)
> ? >> print(summary(m.zcp), corr=FALSE)
> ? >>
> ? >> # OP m2
> ? >> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
> ? >> data=Machines, REML=FALSE)
> ? >> print(summary(m2), corr=FALSE)
> ? >>
> ? >> # varying-intercept-only LMM
> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
> ? >> REML=FALSE)
> ? >> print(summary(m.vio), corr=FALSE)
> ? >>
> ? >> anova(m1, m.zcp, m2, m.vio)
> ? >>
> ? >> sessionInfo()
> ? >> ####
> ? >>
> ? >> You may also want to look this RPub:
> ? >> http://www.rpubs.com/Reinhold/22193
> ? >>
> ? >> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
> ? >> Maarten.Jung at mailbox.tu-dresden.de> wrote:
> ? >>
> ? >>> Hello everyone,
> ? >>>
> ? >>> I have a question regarding the equivalence of the following models:
> ? >>>
> ? >>> m1 <- lmer(y ~ factor + (0 + factor|group))
> ? >>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
> ? >>>
> ? >>> Douglas Bates states (slide 91 in this presentation [1])  that these
> ? >>> models
> ? >>> are equivalent in case of compound symmetry.
> ? >>>
> ? >>> 1. I realized that I don't really understand the random slope by
> factor
> ? >>> model (m1) and espacially why it reduces to m2 given compound
> symmetry.
> ? >>> Also, why is there no random intercept in m1?
> ? >>> Can anyone explain the difference between the models and how m1
> reduces
> ? >>> to
> ? >>> m2 in an intuitive way.
> ? >>>
> ? >>> 2. If m1 is a special case of m2 ? this could be an interesting
> option
> ? >>> for
> ? >>> model reduction but I?ve never seen something like m2 in papers.
> Instead
> ? >>> they suggest dropping the random slope and thus the interaction
> ? >>> completely
> ? >>> (e.g. Matuschek et al. 2017 [3]).
> ? >>> What do you think about it?
> ? >>>
> ? >>> Please note that I asked the question on Stack Exchange [2] but some
> ? >>> consider it as off-topic. So, I hope one of you can help me out.
> ? >>>
> ? >>>
> ? >>> Best regards,
> ? >>> Maarten
> ? >>>
> ? >>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
> ? >>> [2] https://stats.stackexchange.com/q/304374/136579
> ? >>> [3] https://doi.org/10.1016/j.jml.2017.01.001
> ? >>>
> ? >>>         [[alternative HTML version deleted]]
> ? >>>
> ? >>> _______________________________________________
> ? >>> R-sig-mixed-models at r-project.org mailing list
> ? >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >>
> ? >>
> ? >>
> ? >
> ?
> ?       [[alternative HTML version deleted]]
> ?
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>

	[[alternative HTML version deleted]]


From jessiebarker at gmail.com  Tue Sep 26 11:55:45 2017
From: jessiebarker at gmail.com (Jessie Barker)
Date: Tue, 26 Sep 2017 11:55:45 +0200
Subject: [R-sig-ME] Changing reference level in clmm() ordinal regression
In-Reply-To: <20170925093045.GG16947@info124.pharmacie.univ-paris5.fr>
References: <CABtDSpiXeZmZCzrb3aQ0y7Nos3ZMOXO01FovYfE11p__3qU_yQ@mail.gmail.com>
 <CAJuCY5w0LZ4U2LvoZKCo5fiQu+_JOKYB+dC4cxM0E3yqgyHMHQ@mail.gmail.com>
 <CABtDSpg_SU6D4BZkM3Czf=E-vHJT+Rym_Km9oibcV0W0GrbpAw@mail.gmail.com>
 <20170925093045.GG16947@info124.pharmacie.univ-paris5.fr>
Message-ID: <CABtDSpgH9d4QAaJNHHimu3LyewUp9mLeHkbF_8eYBqF=Lv_D6A@mail.gmail.com>

Hi Emmanuel,

Thanks very much for your reply! Your example is very helpful.

All the best,
Jessie

On 25 September 2017 at 11:30, Emmanuel Curis <
emmanuel.curis at parisdescartes.fr> wrote:

> Hello Jessie,
>
> Imagine a two-factors design, let's say sex and tobacco status. You
> can imagine the results as spanned in a 2?2 table :
>
>             Sex
>            F    M
> Tobacco N  ?0  ?1
>         Y  ?2  ?3
>
> The concept of "reference level" is to be meant on the basis of the
> cells of this table, not on the margins.
>
> That is, with the default orders of levels in R (alphabetical order),
> the reference value will be here ?0, and the coefficients will be a1 =
> (?1-?0) [change only Sex], b1 = (?2-?0) [change only Tobacco] and i =
> (?3-[?0+a1+b1]), interaction.
>
> If you change the reference level for Sex, for instance, then the
> reference value becomes ?1, and the coefficients are now a1' = (?0-?1)
> = -a1, b1' = (?3-?1) and i' = (?2 - [?1+a1'+b1']).
>
> So, as you can see, changing the reference level of one factor changes
> the coefficients for all factors ? because you change in fact the
> reference cell in your table, and not only in the margin.
>
> Best regards,
>
> On Fri, Sep 22, 2017 at 05:24:59PM +0200, Jessie Barker wrote:
> ? Hi Thierry,
> ?
> ? Thank you for your reply.
> ?
> ? I see that when changing the reference from say, a1 to a2, the estimate
> for
> ? a3 will be different.
> ? However, I'm still not sure why, when I change the reference of the other
> ? factor from, say, q1 to q2, the estimate for a3 will be different
> (because
> ? a3 is is still being compared to the same reference level of a,
> regardless
> ? of what the reference level of q is). Or am I misinterpreting that?
> ?
> ? Thanks again,
> ?
> ? Jessie
> ?
> ? On 22 September 2017 at 14:38, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> ? wrote:
> ?
> ? > Dear Jessie,
> ? >
> ? > All models have an identical fit. They only differ in the
> ? > parametrisation. "a3" estimates the difference between "a3" and the
> ? > reference. Hence, changing the reference results in a different
> ? > interpretation of the parameter and thus a different estimate.
> ? >
> ? > Best regards,
> ? >
> ? > ir. Thierry Onkelinx
> ? > Statisticus/ Statiscian
> ? >
> ? > Vlaamse Overheid / Government of Flanders
> ? > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> ? > AND FOREST
> ? > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> ? > thierry.onkelinx at inbo.be
> ? > Kliniekstraat 25, B-1070 Brussel
> ? > www.inbo.be
> ? >
> ? > ////////////////////////////////////////////////////////////
> ? > ///////////////////////////////
> ? > To call in the statistician after the experiment is done may be no
> ? > more than asking him to perform a post-mortem examination: he may be
> ? > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> ? > The plural of anecdote is not data. ~ Roger Brinner
> ? > The combination of some data and an aching desire for an answer does
> ? > not ensure that a reasonable answer can be extracted from a given body
> ? > of data. ~ John Tukey
> ? > ////////////////////////////////////////////////////////////
> ? > ///////////////////////////////
> ? >
> ? >
> ? > Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> ? > Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> ? > Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
> ? > Brussel.
> ? >
> ? > ////////////////////////////////////////////////////////////
> ? > ///////////////////////////////
> ? >
> ? >
> ? >
> ? > 2017-09-22 11:41 GMT+02:00 Jessie Barker <jessiebarker at gmail.com>:
> ? > > I have a couple of questions that I asked on StackExchange and
> someone
> ? > > suggested that I ask this mailing list. The post on StackExchange is
> ? > here (
> ? > > https://stats.stackexchange.com/questions/304092/changing-
> ? > reference-level-in-clmm-ordinal-regression-in-r),
> ? > > but I am summarizing it below:
> ? > >
> ? > > I?m analyzing data from a questionnaire where participants had to
> rank
> ? > > three answers to each question (e.g. 1 = most likely, 3 = least
> likely).
> ? > > They had to give a different rank to each answer, so each question
> has
> ? > one
> ? > > answer ranked 1, one ranked 2, and one ranked 3. The set of three
> answers
> ? > > is the same for each questions, and there were seven questions.
> ? > >
> ? > > I want to know whether participants give different ranks to different
> ? > > answers, and whether that is affected by question. Here's my model:
> ? > >
> ? > > model1 <- clmm(rank ~ answer + answer:question +
> (1+answer|participant),
> ? > > data = mydata)
> ? > >
> ? > > (I don?t have question as a fixed effect, because for each question
> ? > > participants had to give a 1, 2 and 3 rank, so question alone does
> not
> ? > > affect rank.)
> ? > >
> ? > > My first question is whether I?ve set up the model correctly, as I
> don?t
> ? > > have any experience with ordinal regression. When I look at
> coef(model1),
> ? > > all participants seem to have the same intercepts and coefficients
> for
> ? > the
> ? > > different answers, which is not what I thought should happen (I
> thought I
> ? > > was setting up a model with random intercepts and random slopes).
> ? > >
> ? > > My second question is about changing the reference level of question
> and
> ? > > answer. When I look at summary(model1), it uses answer a1 and
> question q1
> ? > > as the reference levels, so I ran the model again using different
> answers
> ? > > and questions as reference levels.
> ? > >
> ? > > When I run the model again using a different answer as the reference
> ? > level,
> ? > > the coefficients for the fixed effects are the same, but the random
> ? > effects
> ? > > and threshold coefficients are quite different.
> ? > > When I run the model using a different question as the reference
> level,
> ? > the
> ? > > coefficients for the fixed effects are quite different, but the
> random
> ? > > effects are exactly the same, and the threshold coefficients
> relatively
> ? > > similar.
> ? > >
> ? > > Could someone please help me understand what?s going on here?
> ? > >
> ? > > Thanks in advance,
> ? > > Jessie Barker
> ? > >
> ? > >         [[alternative HTML version deleted]]
> ? > >
> ? > > _______________________________________________
> ? > > R-sig-mixed-models at r-project.org mailing list
> ? > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >
> ?
> ?       [[alternative HTML version deleted]]
> ?
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>

	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Tue Sep 26 13:30:41 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Tue, 26 Sep 2017 13:30:41 +0200
Subject: [R-sig-ME] Failing to understand effect of centering a
 predictor in multilevel model
In-Reply-To: <2118835736.26446064.1505980130059.JavaMail.zimbra@psyctc.org>
References: <2118835736.26446064.1505980130059.JavaMail.zimbra@psyctc.org>
Message-ID: <5a9bc9fb-64d4-e3e8-349b-4849cbacde5a@uni-potsdam.de>

This may be a superficial answer given the detail of your question, but 
as far as I understand, centering your predictor is a linear 
transformation. You're simply subtracting values so the predictor is 
centered around a different value than before. Thus, it should *not* 
make a difference to your results.
Centering and scaling predictor is done to make results more easily 
interpretable and to deal with different scales your predictors are on - 
not change your results.

Cheers
Diana


Am 21.09.2017 um 09:48 schrieb Chris Evans:
> I am trying to make sure I understand the use of multilevel modelling to look at change (on questionnaire scores) across sessions of psychotherapy. This is widely done in my applied field. I am a researcher (and ex-therapist) not a statistician and have no direct availability of a statistician but I'm fairly savvy about stats. I am simulating, rather crudely, data which have both fixed and random intercepts and slopes with a quadratic as well as a linear effect of session number. I'm using lmer from lme4 overloaded by lmerTest in 64 bit R 3.4.1 on Windoze running in Rstudio.
>
> The thing that's baffling me is that centering my predictor (session count) seems to have NO effect on my results, neither on the fixed nor the random effects. I would have expected the intercept to have changed at the very least given the effects I've simulated.
>
> Details: session count can range from 1 to 51 (the number of sessions per client in my simulation can vary, realistically, from 4 to 51 so no client has fewer than four). I have modelled in a random linear and quadratic effect of session count but such that the overall effects are both negative. Code and session info are at the end of the post. Here is code and output from uncentred:
>
> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
> data=longdat4)
> summary(m4)
>
> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
> ## to degrees of freedom [lmerMod]
> ## Formula:
> ## DEP_TOTAL ~ poly(session, 2) + (1 + poly(session, 2) | validPOC_ID)
> ## Data: longdat4
> ##
> ## REML criterion at convergence: -29507
> ##
> ## Scaled residuals:
> ## Min 1Q Median 3Q Max
> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
> ##
> ## Random effects:
> ## Groups Name Variance Std.Dev. Corr
> ## validPOC_ID (Intercept) 9.309e+00 3.05101
> ## poly(session, 2)1 7.390e+03 85.96686 0.20
> ## poly(session, 2)2 4.154e+02 20.38232 0.21 1.00
> ## Residual 4.973e-03 0.07052
> ## Number of obs: 15399, groups: validPOC_ID, 500
> ##
> ## Fixed effects:
> ## Estimate Std. Error df t value Pr(>|t|)
> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
> ## poly(session, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
> ## poly(session, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
> ## ---
> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ##
> ## Correlation of Fixed Effects:
> ## (Intr) p(,2)1
> ## ply(sss,2)1 0.210
> ## ply(sss,2)2 0.215 0.995
>
> Here is the centered one (lengthCentre is 29.5).
>
> longdat4 $ sessionC1 <- longdat4 $ session - lengthCentre summary ( longdat4 $ sessionC1 )
> ## Min. 1st Qu. Median Mean 3rd Qu. Max.
> ## -28.50 -21.50 -12.50 -10.09 -0.50 21.50
> m5 <- lmer ( DEP_TOTAL ~ poly ( sessionC1 , 2 ) + ( 1 + poly ( sessionC1 , 2 ) | validPOC_ID ) , data = longdat4 ) summary ( m5 )
> ## Linear mixed model fit by REML t-tests use Satterthwaite approximations
> ## to degrees of freedom [lmerMod]
> ## Formula:
> ## DEP_TOTAL ~ poly(sessionC1, 2) + (1 + poly(sessionC1, 2) | validPOC_ID)
> ## Data: longdat4
> ##
> ## REML criterion at convergence: -29507
> ##
> ## Scaled residuals:
> ## Min 1Q Median 3Q Max
> ## -3.6274 -0.6583 0.0035 0.6420 4.0849
> ##
> ## Random effects:
> ## Groups Name Variance Std.Dev. Corr
> ## validPOC_ID (Intercept) 9.309e+00 3.05101
> ## poly(sessionC1, 2)1 7.390e+03 85.96686 0.20
> ## poly(sessionC1, 2)2 4.154e+02 20.38232 0.21 1.00
> ## Residual 4.973e-03 0.07052
> ## Number of obs: 15399, groups: validPOC_ID, 500
> ##
> ## Fixed effects:
> ## Estimate Std. Error df t value Pr(>|t|)
> ## (Intercept) 8.6192 0.1367 526.0000 63.07 <2e-16 ***
> ## poly(sessionC1, 2)1 -179.5508 3.9684 4712.0000 -45.25 <2e-16 ***
> ## poly(sessionC1, 2)2 -42.1333 0.9497 4029.0000 -44.37 <2e-16 ***
> ## ---
> ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ##
> ## Correlation of Fixed Effects:
> ## (Intr) p(C1,2)1
> ## ply(sC1,2)1 0.210
> ## ply(sC1,2)2 0.215 0.995
>
> This makes no sense to me. I had expected that the very crude centering must shift the fixed intercept as the x=0 has shifted left by 29.5 and I have strong linear and quadratic effects in the model. I also thought (the whole reason I'm doing this) that it would change the correlation between the linear and quadratic terms as I should be moving from a strong positive correlation between them to a much smaller one.
>
> I'm sure I'm doing something utterly stupid, or revealing shocking failure to comprehend the multilevel model, but I'm looking straight through the explanation and stuck. I hope someone will help me!
>
> TIA,
>
>
> Chris
>
>
>
> Here is entire pertinent code.
>
> ```{r sim4,warning=FALSE,message=FALSE,cache=TRUE}
> require(reshape2)
> set.seed(12345)
> ### set up the parameters for the simulation
> n <- 500
> minNSessions <- 4
> maxNSessions <- 55
> linSlope <- -.02
> errVar <- .005
> ### derived variables
> lengthRange <- minNSessions:maxNSessions
> lengthCentre <- (minNSessions+maxNSessions)/2
> ID <- 1:n
> ### create a variable, length = n for the session counts
> sessions <- sample(lengthRange,n,replace=TRUE)
> ### for now, give all starting scores of 10
> startScores <- rnorm(n,mean=10,sd=3)
> slopes <- rnorm(n,mean=linSlope,sd=.01) # random slopes
> ### set up matrix to store the simulated scores
> scores <- matrix(rep(NA,n*maxNSessions),nrow=n)
> dat4 <- as.data.frame(cbind(ID,sessions,startScores,slopes,scores))
> for (i in 1:nrow(dat4)) {
> nSessions <- dat4$sessions[i]
> tmpScores <- rep(dat4$startScores[i],nSessions) # scores: no slopes
> tmpScores <- tmpScores + c(0,slopes[i]*(2:nSessions)) # scores: add linear effect
> tmpScores <- tmpScores + c(0,slopes[i]*((2:nSessions)^2))/10 # add quadratic effect
> tmpScores <- tmpScores + rnorm(nSessions,mean=0,sd=sqrt(errVar)) # now add error
> dat4[i,5:(4+nSessions)] <- tmpScores # put into data frame
> }
> ### now melt to create a long data frame
> longdat4 <- melt(dat4,id.vars="ID",measure.vars = 4:55)
> colnames(longdat4) <- c("validPOC_ID","wks","DEP_TOTAL")
> longdat4$session <- as.numeric(substr(longdat4$wks,2,3))-4 # minus 4 to get start at 1
> # as data start in column 5
> longdat4 <- longdat4[order(longdat4$validPOC_ID,longdat4$wks),]
> longdat4 <- na.omit(longdat4) # ditch the empty data
> ```
>
> So the data frame longdat4 has
> `r nrow(longdat4)` rows and
> `r ncol(longdat4)` columns and the column names are
> `r colnames(longdat4)`. Here is a bit of the head of the wide data frame (dat4) and the head of the long one (longdat4).
>
> ```{r head4,warning=FALSE,message=FALSE,cache=TRUE}
> require(knitr)
> kable(head(dat4[,1:10]),digits=3)
> kable(head(longdat4))
> ```
>
> Elisa's lattice plot.
>
> ```{r spaghetti4,warning=FALSE,message=FALSE,cache=TRUE}
> library(lattice)
> samp <- sample(unique(longdat4$validPOC_ID), 35)
> xyplot(DEP_TOTAL ~ wks|validPOC_ID, longdat4,
> type = c("p","g","r"),
> subset = (validPOC_ID %in% samp),
> col="dark blue",
> col.line="black",
> strip = F,
> xlab = "Weeks in treatment",
> ylab = "Depression Scores")
> ```
>
> Now Elisa's tangle plot. Just first 40 simulated cases.
>
> ```{r tangle4, warning=FALSE,message=FALSE,cache=TRUE}
> library(ggplot2)
> first40 <- longdat4[longdat4$validPOC_ID <=40,]
> tanglePlot <- ggplot(data = longdat4, aes(x = wks, y = DEP_TOTAL)) +
> geom_line(data = longdat4, alpha = 0.5, aes(group = validPOC_ID)) +
> theme_bw()
> tanglePlot
> ```
>
> ```{r model4, warning=FALSE, message=FALSE,cache=TRUE}
> require(lmerTest)
> ### this next fails to converge and has perfect correlation of linear & quadratic effects
> # m4 <- lmer(DEP_TOTAL ~ session+I(session^2)+(1+session+I(session^2)|validPOC_ID),
> # data=longdat4)
> ### is this better:
> summary(longdat4$session)
> hist(longdat4$session,
> main="Histogram of raw session counts",
> xlab="Raw session n",
> col="grey")
> m4 <- lmer(DEP_TOTAL ~ poly(session,2)+(1+poly(session,2)|validPOC_ID),
> data=longdat4)
> summary(m4)
> ```
>
> This next should test the random effect (and should find it highly significant I think).
>
> ```{r mode4rand,eval=FALSE}
> rand(m4)
> ### fails with message:
> ### Error in terms.formula(tmp, simplify = TRUE) :
> ### invalid model formula in ExtractVars
> ```
>
> And this summarises the random effects. These are deviations from the fixed effects so both are centred on zero.
>
> ```{r coeffs4,fig.width=11,fig.height=8,cache=TRUE}
> apply(ranef(m4)$validPOC_ID,2,summary)
> par(mfrow=c(1,3))
> hist(ranef(m4)$validPOC_ID[,1],
> xlab="Intercept deviation values",
> main="Random intercepts",
> col="grey")
> abline(v=0)
> hist(ranef(m4)$validPOC_ID[,2],
> main="Random slopes",
> xlab="Linear slope deviation values",
> col="grey")
> abline(v=0)
> hist(ranef(m4)$validPOC_ID[,3],
> main="Random slopes",
> xlab="Quadratic slope deviation values",
> col="grey")
> abline(v=0)
> ```
>
>
> # Simulation 5: random intercept and random slope with quadratic effect, CENTRED
>
> OK. Random intercept and slope has linear and quadratic effects. Now going to centre the session count by subtracting lengthCentre
>
>
> ```{r model5, warning=FALSE, message=FALSE}
> longdat4$sessionC1 <- longdat4$session - lengthCentre
> summary(longdat4$sessionC1)
> hist(longdat4$sessionC1,
> main="Histogram of centred session counts",
> xlab="Centred session n",
> col="grey")
> abline(v=0)
> require(lmerTest)
> m5 <- lmer(DEP_TOTAL ~ poly(sessionC1,2)+(1+poly(sessionC1,2)|validPOC_ID),
> data=longdat4)
> summary(m5)
> ```
>
>
>
> ```{r mode5rand,eval=FALSE}
> rand(m5)
> ### fails with message:
> ### Error in terms.formula(tmp, simplify = TRUE) :
> ### invalid model formula in ExtractVars
> ```
>
>
> ```{r coeffs5,fig.width=11,fig.height=8}
> apply(ranef(m5)$validPOC_ID,2,summary)
> par(mfrow=c(1,3))
> hist(ranef(m5)$validPOC_ID[,1],
> xlab="Intercept deviation values",
> main="Random intercepts",
> col="grey")
> abline(v=0)
> hist(ranef(m5)$validPOC_ID[,2],
> main="Random slopes",
> xlab="Linear slope deviation values",
> col="grey")
> abline(v=0)
> hist(ranef(m5)$validPOC_ID[,3],
> main="Random slopes",
> xlab="Quadratic slope deviation values",
> col="grey")
> abline(v=0)
> ```
>
> And here is sessionInfo()
>
>> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] ggplot2_2.2.1 lattice_0.20-35 knitr_1.17 lmerTest_2.0-33 lme4_1.1-13
> [6] Matrix_1.2-11 reshape2_1.4.2
>
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.12 highr_0.6 RColorBrewer_1.1-2 compiler_3.4.1
> [5] nloptr_1.0.4 plyr_1.8.4 base64enc_0.1-3 tools_3.4.1
> [9] rpart_4.1-11 digest_0.6.12 checkmate_1.8.3 htmlTable_1.9
> [13] evaluate_0.10.1 tibble_1.3.4 nlme_3.1-131 gtable_0.2.0
> [17] rlang_0.1.2 yaml_2.1.14 gridExtra_2.3 cluster_2.0.6
> [21] stringr_1.2.0 htmlwidgets_0.9 nnet_7.3-12 rprojroot_1.2
> [25] grid_3.4.1 data.table_1.10.4 survival_2.41-3 foreign_0.8-69
> [29] rmarkdown_1.6 latticeExtra_0.6-28 minqa_1.2.4 Formula_1.2-2
> [33] magrittr_1.5 backports_1.1.0 Hmisc_4.0-3 scales_0.5.0
> [37] htmltools_0.3.6 MASS_7.3-47 splines_3.4.1 rsconnect_0.8.5
> [41] colorspace_1.3-2 labeling_0.3 stringi_1.1.5 acepack_1.4.1
> [45] lazyeval_0.2.0 munsell_0.4.3
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl
www.duoinfernale.eu


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Sep 26 21:01:19 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 26 Sep 2017 20:01:19 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>

Hi Dani,


It is still not possible for us to diagnose the problem. You need to 
provide code+data that reproduces the error. f_lfv_c does not appear in 
newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:
>
> Hello again,
>
>
> Thank you so much for your prompt response. I apologize for the silly 
> questions, I am a true beginner and I am ashamed of my ignorance. I 
> guess I should explain what I did:
>
>
> I used the spl2 function and obtained the fixed and random factors 
> corresponding to the variable I needed the smoother for (named f_lfv_c).
>
>
> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>
> I am not sure how to attach the random effects corresponding to the 
> l_lfvcspn. I get this array of 8 variables and I am really not sure 
> how to include them in the model. Should I get forget about spl2 and 
> simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the 
> idv random term?
>
> Also, it seems to me that I have 11 fixed effects, I am not sure what 
> to do.
>
> I am really sorry about all these silly questions, I really do not 
> understand how these things work, but I would like to know more about 
> this.
>
> Best regards!
>
>
> Sent from Outlook <http://aka.ms/weboutlook>
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* Monday, September 25, 2017 8:51:09 AM
> *To:* dani; Ben Bolker
> *Cc:* Matthew; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
> splines
>
> Hi,
>
> The example is not reproducible: l_lfvcspn does not exist.
>
> The error is telling you that you don't have 11 fixed effects in the 
> model. Change k to the number of fixed effects in the model.
>
> Jarrod
>
>
>
> On 25/09/2017 16:39, dani wrote:
>> mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>    random =~ STUDYID+class+idv(l_lfvcspn),
>>    data   = newdatab,
>>    family = "poisson"
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170926/df6ac8c9/attachment-0001.ksh>

From orchidn at live.com  Tue Sep 26 21:26:01 2017
From: orchidn at live.com (dani)
Date: Tue, 26 Sep 2017 19:26:01 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>,
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <MWHPR1201MB0029E1BDDBA2224F29B41A78D67B0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi Jarrod,


Thank you so much for your kind answer! I have been struggling with it and went back to read more about MCMC. I will be posting the complete code and the data as soon as I get a chance this afternoon.


Best regards!

Dani N-M


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of dani <orchidn at live.com>
Sent: Monday, September 25, 2017 10:08:08 AM
To: Jarrod Hadfield; Ben Bolker
Cc: r-sig-mixed-models at r-project.org; Matthew
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From van.liceralde at gmail.com  Tue Sep 26 23:03:32 2017
From: van.liceralde at gmail.com (Van Rynald Liceralde)
Date: Tue, 26 Sep 2017 17:03:32 -0400
Subject: [R-sig-ME] specifying crossed random effects for glmmPQL / lme
Message-ID: <CAOQn1wW27+DymtS=aNJ16GjYJ0AdMERhWNXAzvNDY-0FYvFevA@mail.gmail.com>

Hello,

I'm trying to fit a GLMM on simulated response time data (continuous,
positively skewed) obtained from hypothetical participants (Subject)
responding to the same set of hypothetical items (Item), so it's a
fully-crossed design. I intend to include several crossed-random effects
for Subject and Item, so in lme4 language, it would look like the following:

glmer(y ~ x1*x2*z1 + (1+x1+x2|Subject) + (1|Item),
family=Gamma("identity"), data=foo)

However, as I read from Ben Bolker's GLMM FAQ (
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#fn1), the
estimation procedure used by glmer (adaptive Gauss-Hermite quadrature) can
only handle up to 2-3 random effects. Indeed, running glmer on my simulated
data not only results in inevitable non-convergence but also takes such a
long time to run.

Someone recommended to me to use MASS::glmmPQL instead because the cases in
which penalized quasi-likelihood (PQL) would perform poorly (count/binomial
DV, mean DV < 5) doesn't apply to my data (continuous DV, identity link,
many items, and many subjects). Moreover, PQL could handle more random
effects than GHQ; it could also allow for correlations of random effects to
be estimated; and it estimates the model faster than GHQ. (I don't actually
know about any of those being accurate characterizations of PQL and GHQ;
would be happy to be corrected and pointed to the right direction.)

The solution suggested online on CrossValidated is as follows:

> bar <- glmmPQL(y ~ x1*x2*z1, random=list(Subject=~1+x1+x2, Item=~1),
                 family=Gamma("identity"),data=foo)

but this way of doing it seems to model the random effect for Item as if it
was nested under Subject, but I want them to be identified as crossed. I
was wondering if someone can point me to how I'd be able to specify my
model using glmmPQL such that the effects of Subject and Item are truly
crossed. Thank you so much!

Sincerely,
Van Liceralde
-- 
Van Rynald T. Liceralde, BS, BA
Graduate Student, Cognitive Psychology
University of North Carolina at Chapel Hill

	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Wed Sep 27 02:32:58 2017
From: burwood70 at gmail.com (Steve Candy)
Date: Wed, 27 Sep 2017 10:32:58 +1000
Subject: [R-sig-ME] Failing to understand effect of centering a
	predictor in multilevel model
Message-ID: <008d01d33728$2e0f71e0$8a2e55a0$@gmail.com>

If my memory serves me correctly when in checked this out with a simple
random slopes, random intercept model on a single predictor, say x,
centering x changed the correlation between the random effects quite
dramatically but nothing else compared to the lmer with uncentered x.

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Sep 27 16:16:58 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 14:16:58 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
Message-ID: <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello Jarrod,

I have attached my code and my file.

Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.

I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.

Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.

The MCMC model worked properly based on the prior using k=13.

Please see the code below:

#spl2 function

library(mgcv)

spl2<-function(formula, data, p=TRUE, dataX=data){

  aug<-nrow(data)-nrow(dataX)

  if(aug!=0){
    if(aug<0){
      stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
    }else{
      augX<-matrix(0, aug, ncol(dataX))
      colnames(augX)<-colnames(dataX)
      dataX<-rbind(dataX, augX)
    }
  }
  smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
  sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

  Sed<-eigen(sm$S[[1]])
  Su<-Sed$vectors
  Sd<-Sed$values
  nonzeros <- which(Sd > sqrt(.Machine$double.eps))

  if(p){
    Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
  }else{
    Zn<-sm$X[,-nonzeros, drop=FALSE]
  }
  return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

$spline terms

newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
summary(newdatab1$l_lfvcspo)
summary(newdatab1$l_lfvcspn)

summary(newdatab1)
dim(newdatab1)
str(newdatab1)

#PRIOR


k<-13 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
            R=list(V=1, nu=0),
            G=list(G1=list(V=1, nu=0),
                   G2=list(V=1, nu=0),
                   G3=list(V=1, nu=0)))

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-4

# MCMC model

mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)
summary(mcmc)



This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.

I truly appreciate all your invaluable help!
Best regards,
Dani NM
<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Tuesday, September 26, 2017 12:01:19 PM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"



	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Sep 27 16:28:17 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 27 Sep 2017 15:28:17 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>

Hi,


There are 12 terms in the model not 13 so k=12. The k in the prior 
specification is completely unrelated to the number of knot points in 
the spline.


Cheers,


Jarrod


On 27/09/2017 15:16, dani wrote:
> Hello Jarrod,
>
> I have attached my code and my file.
>
> Variable age has 3 levels, variables x2, x8, and x9 have two levels 
> each, and the rest of the variables are continuous.
>
> I re-ran the spl2 function and this time around I obtained one single 
> fixed smoother (l_lfvcspo)?and one single random smoother (l_lfvcspn). 
> Last time around I got 8 variables with suffixes from 1-8 for 
> l_lfvcspn and I did not know what to do with those.
>
> Also, as I had 11 fixed effects (corresponding to 11 variables), I 
> thought it was appropriate to choose k=11. I was not sure whether the 
> intercept needed to be counted as well as the levels of the 
> categorical fixed predictors (except for their reference categories). 
> Because I kept on getting the "mu" error for k=11, I tried k=13 (which 
> includes the intercept and the 2 levels for the 3-level age variable, 
> which I did not consider before). I am not sure this is the way to go, 
> I guess I need to read more to be able to model properly fixed effects 
> in R, but for now I was wondering whether this consideration of fixed 
> effects?sounds ok in this particular example.
>
> The MCMC model worked properly based on the prior using k=13.
>
> Please see the code below:
>
> *#spl2 function*
>
> library(mgcv)
>
> spl2<-function(formula, data, p=TRUE, dataX=data){
> aug<-nrow(data)-nrow(dataX)
> ? if(aug!=0){
> ? ? if(aug<0){
> ? ? ? stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
> ? ? }else{
> ? ? ? augX<-matrix(0, aug, ncol(dataX))
> colnames(augX)<-colnames(dataX)
> dataX<-rbind(dataX, augX)
> ? ? }
> ? }
> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
> sm<-smoothCon(smooth.spec.object, data=data, 
> knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
> ? Sed<-eigen(sm$S[[1]])
> ? Su<-Sed$vectors
> ? Sd<-Sed$values
> ? nonzeros <- which(Sd > sqrt(.Machine$double.eps))
> ? if(p){
> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
> ? }else{
> ? ? Zn<-sm$X[,-nonzeros, drop=FALSE]
> ? }
> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
> }
>
> *$spline terms*
> *
> *
> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
> summary(newdatab1$l_lfvcspo)
> summary(newdatab1$l_lfvcspn)
>
> summary(newdatab1)
> dim(newdatab1)
> str(newdatab1)
>
> *#PRIOR*
>
>
> k<-13 # number of fixed effects
>
> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
> ? ? ? ? ? ? R=list(V=1, nu=0),
> G=list(G1=list(V=1, nu=0),
> ?G2=list(V=1, nu=0),
> ?G3=list(V=1, nu=0)))
>
> prior$B$mu[k]<-1 # assuming the offset term is last
> prior$B$V[k,k]<-1e-4
>
> *# MCMC model*
>
> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
> ? ? ? ? ? ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
> ? ? ? ? ? ? ? ? ?data ? = newdatab1,
> ? ? ? ? ? ? ? ? ?family = "poisson", prior=prior)
> summary(mcmc)
>
>
> This model has worked, so I would like to thank you so much for all 
> your help so far. I guess I just want to make sure I understand how to 
> model the fixed effects in MCMCglmm and I also would like to make sure 
> that my model is correct.
>
> I truly appreciate all your invaluable?help!
> Best regards,
> Dani NM
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
> *To:* dani; Ben Bolker
> *Cc:* Matthew; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
> splines
>
> Hi Dani,
>
>
> It is still not possible for us to diagnose the problem. You need to 
> provide code+data that reproduces the error. f_lfv_c does not appear 
> in newdatab.
>
>
> Cheers,
>
>
> Jarrod
>
>
> On 25/09/2017 18:08, dani wrote:
>>
>> Hello again,
>>
>>
>> Thank you so much for your prompt response. I apologize for the silly 
>> questions, I am a true beginner and I am ashamed of my ignorance. I 
>> guess I should explain what I did:
>>
>>
>> I used the spl2 function and obtained the fixed and random factors 
>> corresponding to the variable I needed the smoother for (named?f_lfv_c).
>>
>>
>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>
>> I am not sure how to attach the random effects corresponding to the 
>> l_lfvcspn. I get this array of 8 variables and I am really not sure 
>> how to include them in the model. Should I get forget about spl2 and 
>> simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the 
>> idv random term?
>>
>> Also, it seems to me that I have 11 fixed effects, I am not sure what 
>> to do.
>>
>> I am really sorry about all these silly?questions, I really do not 
>> understand how these things work, but I would like to know more about 
>> this.
>>
>> Best regards!
>>
>>
>> Sent from Outlook <http://aka.ms/weboutlook>
>> ------------------------------------------------------------------------
>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>> *To:* dani; Ben Bolker
>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>> splines
>>
>> Hi,
>>
>> The example is not reproducible: l_lfvcspn does not exist.
>>
>> The error is telling you that you don't have 11 fixed effects in the 
>> model. Change k to the number of fixed effects in the model.
>>
>> Jarrod
>>
>>
>>
>> On 25/09/2017 16:39, dani wrote:
>>> mc_spl1gna <- MCMCglmm(y ~ 
>>> age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>> ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
>>> ? ? ? ?data ? = newdatab,
>>> ? ? ? ?family = "poisson"
>>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170927/803e3d48/attachment-0001.ksh>

From orchidn at live.com  Wed Sep 27 16:38:58 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 14:38:58 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <52eb33f3-09d5-49e1-a277-c1beabf6bda6@ed.ac.uk>
 <MWHPR1201MB0029D0BE0E1E285952CFBAE5D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
Message-ID: <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?


Also, for k=12 in the prior formula, I get this error:

Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


I am puzzled about this error.


I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.


Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:28:17 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.


Cheers,


Jarrod

On 27/09/2017 15:16, dani wrote:
Hello Jarrod,

I have attached my code and my file.

Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.

I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.

Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.

The MCMC model worked properly based on the prior using k=13.

Please see the code below:

#spl2 function

library(mgcv)

spl2<-function(formula, data, p=TRUE, dataX=data){

  aug<-nrow(data)-nrow(dataX)

  if(aug!=0){
    if(aug<0){
      stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
    }else{
      augX<-matrix(0, aug, ncol(dataX))
      colnames(augX)<-colnames(dataX)
      dataX<-rbind(dataX, augX)
    }
  }
  smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
  sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

  Sed<-eigen(sm$S[[1]])
  Su<-Sed$vectors
  Sd<-Sed$values
  nonzeros <- which(Sd > sqrt(.Machine$double.eps))

  if(p){
    Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
  }else{
    Zn<-sm$X[,-nonzeros, drop=FALSE]
  }
  return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

$spline terms

newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
summary(newdatab1$l_lfvcspo)
summary(newdatab1$l_lfvcspn)

summary(newdatab1)
dim(newdatab1)
str(newdatab1)

#PRIOR


k<-13 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
            R=list(V=1, nu=0),
            G=list(G1=list(V=1, nu=0),
                   G2=list(V=1, nu=0),
                   G3=list(V=1, nu=0)))

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-4

# MCMC model

mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)
summary(mcmc)



This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.

I truly appreciate all your invaluable help!
Best regards,
Dani NM
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Tuesday, September 26, 2017 12:01:19 PM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"




	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Sep 27 16:55:07 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 27 Sep 2017 15:55:07 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>

Hi,


Yes - the intercept is a parameter so should be included. If you get 13 
effects then the data/code you sent us are different from the data/code 
you are using. The issue is not really anything to do with your 
(mis)understanding about priors it is simply that you have set priors 
for k parameters whereas there are in fact not k parameters.


Cheers,


Jarrod


On 27/09/2017 15:38, dani wrote:
>
> Hello again,
>
>
> Thanks! I was indeed referring to the k in the prior formula. I guess 
> I am still confused whether I should add the intercept to the number 
> of fixed effects, as I have 12 variables as I count as fixed effects 
> without the intercept. Would it be possible to confirm that for me, 
> please?
>
>
> Also, for k=12 in the prior formula, I get this error:
>
> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 + ?:
> ? fixed effect mu prior is the wrong dimension
>
> I am puzzled about this error.
>
>
> I do not seem to understand how to select the fixed effects. Could 
> someone point me to a source of information where I can learn more 
> about this, please? ?Also, is there a book where I can learn more 
> about prior specification? I think I need to see more examples.
>
>
> Thank you so much. I apologize for this, but I am very confused and I 
> would like to learn more about this!
>
> Best,
>
> DNM
>
>
> Sent from Outlook <http://aka.ms/weboutlook>
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* Wednesday, September 27, 2017 7:28:17 AM
> *To:* dani; Ben Bolker
> *Cc:* Matthew; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
> splines
>
> Hi,
>
>
> There are 12 terms in the model not 13 so k=12. The k in the prior 
> specification is completely unrelated to the number of knot points in 
> the spline.
>
>
> Cheers,
>
>
> Jarrod
>
>
> On 27/09/2017 15:16, dani wrote:
>> Hello Jarrod,
>>
>> I have attached my code and my file.
>>
>> Variable age has 3 levels, variables x2, x8, and x9 have two levels 
>> each, and the rest of the variables are continuous.
>>
>> I re-ran the spl2 function and this time around I obtained one single 
>> fixed smoother (l_lfvcspo)?and one single random smoother 
>> (l_lfvcspn). Last time around I got 8 variables with suffixes from 
>> 1-8 for l_lfvcspn and I did not know what to do with those.
>>
>> Also, as I had 11 fixed effects (corresponding to 11 variables), I 
>> thought it was appropriate to choose k=11. I was not sure whether the 
>> intercept needed to be counted as well as the levels of the 
>> categorical fixed predictors (except for their reference categories). 
>> Because I kept on getting the "mu" error for k=11, I tried k=13 
>> (which includes the intercept and the 2 levels for the 3-level age 
>> variable, which I did not consider before). I am not sure this is the 
>> way to go, I guess I need to read more to be able to model properly 
>> fixed effects in R, but for now I was wondering whether this 
>> consideration of fixed effects?sounds ok in this particular example.
>>
>> The MCMC model worked properly based on the prior using k=13.
>>
>> Please see the code below:
>>
>> *#spl2 function*
>>
>> library(mgcv)
>>
>> spl2<-function(formula, data, p=TRUE, dataX=data){
>> aug<-nrow(data)-nrow(dataX)
>> ? if(aug!=0){
>> ? ? if(aug<0){
>> ? ? ? stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
>> ? ? }else{
>> augX<-matrix(0, aug, ncol(dataX))
>> colnames(augX)<-colnames(dataX)
>> dataX<-rbind(dataX, augX)
>> ? ? }
>> ? }
>> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
>> sm<-smoothCon(smooth.spec.object, data=data, 
>> knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
>> Sed<-eigen(sm$S[[1]])
>> ? Su<-Sed$vectors
>> ? Sd<-Sed$values
>> ? nonzeros <- which(Sd > sqrt(.Machine$double.eps))
>> ? if(p){
>> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
>> ? }else{
>> Zn<-sm$X[,-nonzeros, drop=FALSE]
>> ? }
>> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
>> }
>>
>> *$spline terms*
>> *
>> *
>> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
>> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
>> summary(newdatab1$l_lfvcspo)
>> summary(newdatab1$l_lfvcspn)
>>
>> summary(newdatab1)
>> dim(newdatab1)
>> str(newdatab1)
>>
>> *#PRIOR*
>>
>>
>> k<-13 # number of fixed effects
>>
>> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>> ? ? ? ? ? ? R=list(V=1, nu=0),
>> G=list(G1=list(V=1, nu=0),
>> ?G2=list(V=1, nu=0),
>> ?G3=list(V=1, nu=0)))
>>
>> prior$B$mu[k]<-1 # assuming the offset term is last
>> prior$B$V[k,k]<-1e-4
>>
>> *# MCMC model*
>>
>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>> ? ? ? ? ? ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
>> ? ? ? ? ? ? ? ? ?data = newdatab1,
>> ? ? ? ? ? ? ? ? ?family = "poisson", prior=prior)
>> summary(mcmc)
>>
>>
>> This model has worked, so I would like to thank you so much for all 
>> your help so far. I guess I just want to make sure I understand how 
>> to model the fixed effects in MCMCglmm and I also would like to make 
>> sure that my model is correct.
>>
>> I truly appreciate all your invaluable?help!
>> Best regards,
>> Dani NM
>> ------------------------------------------------------------------------
>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
>> *To:* dani; Ben Bolker
>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>> splines
>>
>> Hi Dani,
>>
>>
>> It is still not possible for us to diagnose the problem. You need to 
>> provide code+data that reproduces the error. f_lfv_c does not appear 
>> in newdatab.
>>
>>
>> Cheers,
>>
>>
>> Jarrod
>>
>>
>> On 25/09/2017 18:08, dani wrote:
>>>
>>> Hello again,
>>>
>>>
>>> Thank you so much for your prompt response. I apologize for the 
>>> silly questions, I am a true beginner and I am ashamed of my 
>>> ignorance. I guess I should explain what I did:
>>>
>>>
>>> I used the spl2 function and obtained the fixed and random factors 
>>> corresponding to the variable I needed the smoother for (named?f_lfv_c).
>>>
>>>
>>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>>
>>> I am not sure how to attach the random effects corresponding to the 
>>> l_lfvcspn. I get this array of 8 variables and I am really not sure 
>>> how to include them in the model. Should I get forget about spl2 and 
>>> simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in 
>>> the idv random term?
>>>
>>> Also, it seems to me that I have 11 fixed effects, I am not sure 
>>> what to do.
>>>
>>> I am really sorry about all these silly?questions, I really do not 
>>> understand how these things work, but I would like to know more 
>>> about this.
>>>
>>> Best regards!
>>>
>>>
>>> Sent from Outlook <http://aka.ms/weboutlook>
>>> ------------------------------------------------------------------------
>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>>> *To:* dani; Ben Bolker
>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>>> splines
>>>
>>> Hi,
>>>
>>> The example is not reproducible: l_lfvcspn does not exist.
>>>
>>> The error is telling you that you don't have 11 fixed effects in the 
>>> model. Change k to the number of fixed effects in the model.
>>>
>>> Jarrod
>>>
>>>
>>>
>>> On 25/09/2017 16:39, dani wrote:
>>>> mc_spl1gna <- MCMCglmm(y ~ 
>>>> age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>> ? ? ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
>>>> ? ? ? ? ? ?data ? = newdatab,
>>>> ? ? ? ? ? ?family = "poisson"
>>>
>>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170927/8eff2170/attachment-0001.ksh>

From orchidn at live.com  Wed Sep 27 17:13:51 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 15:13:51 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <799952e8-0de0-7ea6-f948-2a897b0a00f8@auburn.edu>
 <MWHPR1201MB0029620679442D1A46D0C7DDD6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
Message-ID: <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>


Hello Jarrod,


Thank you so much for your patience!


This is the model that I used:


mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)

I simply do not understand what am I doing wrong. These are my fixed terms:


1) age

2) x2

3) x8

4) x9

5) x3

6) l_lfvcspo

7) x4

8) x5

9) x6

10) x7

11) offset


There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.


If I put k=12 per the number of fixed effects that I have, I get this error:


Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.


I apologize again, I really do not understand what am I doing wrong and how can I improve.


Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:55 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.


Cheers,


Jarrod

On 27/09/2017 15:38, dani wrote:

Hello again,


Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?


Also, for k=12 in the prior formula, I get this error:

Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


I am puzzled about this error.


I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.


Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:28:17 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.


Cheers,


Jarrod

On 27/09/2017 15:16, dani wrote:
Hello Jarrod,

I have attached my code and my file.

Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.

I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.

Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.

The MCMC model worked properly based on the prior using k=13.

Please see the code below:

#spl2 function

library(mgcv)

spl2<-function(formula, data, p=TRUE, dataX=data){

  aug<-nrow(data)-nrow(dataX)

  if(aug!=0){
    if(aug<0){
      stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
    }else{
      augX<-matrix(0, aug, ncol(dataX))
      colnames(augX)<-colnames(dataX)
      dataX<-rbind(dataX, augX)
    }
  }
  smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
  sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

  Sed<-eigen(sm$S[[1]])
  Su<-Sed$vectors
  Sd<-Sed$values
  nonzeros <- which(Sd > sqrt(.Machine$double.eps))

  if(p){
    Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
  }else{
    Zn<-sm$X[,-nonzeros, drop=FALSE]
  }
  return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

$spline terms

newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
summary(newdatab1$l_lfvcspo)
summary(newdatab1$l_lfvcspn)

summary(newdatab1)
dim(newdatab1)
str(newdatab1)

#PRIOR


k<-13 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
            R=list(V=1, nu=0),
            G=list(G1=list(V=1, nu=0),
                   G2=list(V=1, nu=0),
                   G3=list(V=1, nu=0)))

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-4

# MCMC model

mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)
summary(mcmc)



This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.

I truly appreciate all your invaluable help!
Best regards,
Dani NM
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Tuesday, September 26, 2017 12:01:19 PM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"





	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Sep 27 17:19:13 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 27 Sep 2017 16:19:13 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>

Hi,


If I use the code you sent me with the data you sent me there are 12 
effects and using k=12 works fine. You must have changed the data and/or 
the code.


Jarrod


On 27/09/2017 16:13, dani wrote:
>
>
> Hello Jarrod,
>
>
> Thank you so much for your patience!
>
>
> This is the model that I used:
>
>
> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
> ? ? ? ? ? ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
> ? ? ? ? ? ? ? ? ?data ? = newdatab1,
> ? ? ? ? ? ? ? ? ?family = "poisson", prior=prior)
>
> I simply do not understand what am I doing wrong. These are my fixed 
> terms:
>
>
> 1) age
>
> 2) x2
>
> 3)?x8
>
> 4)?x9
>
> 5)?x3
>
> 6)?l_lfvcspo
>
> 7)?x4
>
> 8)?x5
>
> 9)?x6
>
> 10)?x7
>
> 11)?offset
>
> There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.
>
>
> If I put k=12 per the number of fixed effects that I have, I get this 
> error:
>
>
> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 + ?:
> ? fixed effect mu prior is the wrong dimension
>
> Do you think it might be an issue with the structure of the newdatab1 
> dataset? It seems Ok when I look at it. I do not know what else to do, 
> I seem to have exhausted all options.
>
>
> I apologize again, I really do not understand what am I doing wrong 
> and how can I improve.
>
>
> Best,
>
> DNM
>
>
> Sent from Outlook <http://aka.ms/weboutlook>
>
>
> ------------------------------------------------------------------------
> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
> *Sent:* Wednesday, September 27, 2017 7:55 AM
> *To:* dani; Ben Bolker
> *Cc:* Matthew; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
> splines
>
> Hi,
>
>
> Yes - the intercept is a parameter so should be included. If you get 
> 13 effects then the data/code you sent us are different from the 
> data/code you are using. The issue is not really anything to do with 
> your (mis)understanding about priors it is simply that you have set 
> priors for k parameters whereas there are in fact not k parameters.
>
>
> Cheers,
>
>
> Jarrod
>
>
> On 27/09/2017 15:38, dani wrote:
>>
>> Hello again,
>>
>>
>> Thanks! I was indeed referring to the k in the prior formula. I guess 
>> I am still confused whether I should add the intercept to the number 
>> of fixed effects, as I have 12 variables as I count as fixed effects 
>> without the intercept. Would it be possible to confirm that for me, 
>> please?
>>
>>
>> Also, for k=12 in the prior formula, I get this error:
>>
>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 + ?:
>> ? fixed effect mu prior is the wrong dimension
>>
>> I am puzzled about this error.
>>
>>
>> I do not seem to understand how to select the fixed effects. Could 
>> someone point me to a source of information where I can learn more 
>> about this, please? ?Also, is there a book where I can learn more 
>> about prior specification? I think I need to see more examples.
>>
>>
>> Thank you so much. I apologize for this, but I am very confused and I 
>> would like to learn more about this!
>>
>> Best,
>>
>> DNM
>>
>>
>> Sent from Outlook <http://aka.ms/weboutlook>
>> ------------------------------------------------------------------------
>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> *Sent:* Wednesday, September 27, 2017 7:28:17 AM
>> *To:* dani; Ben Bolker
>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>> splines
>>
>> Hi,
>>
>>
>> There are 12 terms in the model not 13 so k=12. The k in the prior 
>> specification is completely unrelated to the number of knot points in 
>> the spline.
>>
>>
>> Cheers,
>>
>>
>> Jarrod
>>
>>
>> On 27/09/2017 15:16, dani wrote:
>>> Hello Jarrod,
>>>
>>> I have attached my code and my file.
>>>
>>> Variable age has 3 levels, variables x2, x8, and x9 have two levels 
>>> each, and the rest of the variables are continuous.
>>>
>>> I re-ran the spl2 function and this time around I obtained one 
>>> single fixed smoother (l_lfvcspo)?and one single random smoother 
>>> (l_lfvcspn). Last time around I got 8 variables with suffixes from 
>>> 1-8 for l_lfvcspn and I did not know what to do with those.
>>>
>>> Also, as I had 11 fixed effects (corresponding to 11 variables), I 
>>> thought it was appropriate to choose k=11. I was not sure whether 
>>> the intercept needed to be counted as well as the levels of the 
>>> categorical fixed predictors (except for their reference 
>>> categories). Because I kept on getting the "mu" error for k=11, I 
>>> tried k=13 (which includes the intercept and the 2 levels for the 
>>> 3-level age variable, which I did not consider before). I am not 
>>> sure this is the way to go, I guess I need to read more to be able 
>>> to model properly fixed effects in R, but for now I was wondering 
>>> whether this consideration of fixed effects?sounds ok in this 
>>> particular example.
>>>
>>> The MCMC model worked properly based on the prior using k=13.
>>>
>>> Please see the code below:
>>>
>>> *#spl2 function*
>>>
>>> library(mgcv)
>>>
>>> spl2<-function(formula, data, p=TRUE, dataX=data){
>>> aug<-nrow(data)-nrow(dataX)
>>> ? if(aug!=0){
>>> if(aug<0){
>>> ? ? ? stop("sorry nrow(dataX) must be less than or equal to 
>>> nrow(data)")
>>> ? ? }else{
>>> augX<-matrix(0, aug, ncol(dataX))
>>> colnames(augX)<-colnames(dataX)
>>> dataX<-rbind(dataX, augX)
>>> ? ? }
>>> ? }
>>> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
>>> sm<-smoothCon(smooth.spec.object, data=data, 
>>> knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
>>> Sed<-eigen(sm$S[[1]])
>>> Su<-Sed$vectors
>>> Sd<-Sed$values
>>> ? nonzeros <- which(Sd > sqrt(.Machine$double.eps))
>>> ? if(p){
>>> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
>>> ? }else{
>>> Zn<-sm$X[,-nonzeros, drop=FALSE]
>>> ? }
>>> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
>>> }
>>>
>>> *$spline terms*
>>> *
>>> *
>>> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
>>> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
>>> summary(newdatab1$l_lfvcspo)
>>> summary(newdatab1$l_lfvcspn)
>>>
>>> summary(newdatab1)
>>> dim(newdatab1)
>>> str(newdatab1)
>>>
>>> *#PRIOR*
>>>
>>>
>>> k<-13 # number of fixed effects
>>>
>>> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>> R=list(V=1, nu=0),
>>> G=list(G1=list(V=1, nu=0),
>>> ?G2=list(V=1, nu=0),
>>> ?G3=list(V=1, nu=0)))
>>>
>>> prior$B$mu[k]<-1 # assuming the offset term is last
>>> prior$B$V[k,k]<-1e-4
>>>
>>> *# MCMC model*
>>>
>>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>> ?random =~ STUDYID+class+idv(l_lfvcspn),
>>> ?data ? = newdatab1,
>>> ?family = "poisson", prior=prior)
>>> summary(mcmc)
>>>
>>>
>>> This model has worked, so I would like to thank you so much for all 
>>> your help so far. I guess I just want to make sure I understand how 
>>> to model the fixed effects in MCMCglmm and I also would like to make 
>>> sure that my model is correct.
>>>
>>> I truly appreciate all your invaluable?help!
>>> Best regards,
>>> Dani NM
>>> ------------------------------------------------------------------------
>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
>>> *To:* dani; Ben Bolker
>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>>> splines
>>>
>>> Hi Dani,
>>>
>>>
>>> It is still not possible for us to diagnose the problem. You need to 
>>> provide code+data that reproduces the error. f_lfv_c does not appear 
>>> in newdatab.
>>>
>>>
>>> Cheers,
>>>
>>>
>>> Jarrod
>>>
>>>
>>> On 25/09/2017 18:08, dani wrote:
>>>>
>>>> Hello again,
>>>>
>>>>
>>>> Thank you so much for your prompt response. I apologize for the 
>>>> silly questions, I am a true beginner and I am ashamed of my 
>>>> ignorance. I guess I should explain what I did:
>>>>
>>>>
>>>> I used the spl2 function and obtained the fixed and random factors 
>>>> corresponding to the variable I needed the smoother for 
>>>> (named?f_lfv_c).
>>>>
>>>>
>>>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>>>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>>>
>>>> I am not sure how to attach the random effects corresponding to the 
>>>> l_lfvcspn. I get this array of 8 variables and I am really not sure 
>>>> how to include them in the model. Should I get forget about spl2 
>>>> and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) 
>>>> in the idv random term?
>>>>
>>>> Also, it seems to me that I have 11 fixed effects, I am not sure 
>>>> what to do.
>>>>
>>>> I am really sorry about all these silly?questions, I really do not 
>>>> understand how these things work, but I would like to know more 
>>>> about this.
>>>>
>>>> Best regards!
>>>>
>>>>
>>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>> ------------------------------------------------------------------------
>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>>>> *To:* dani; Ben Bolker
>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and 
>>>> splines
>>>>
>>>> Hi,
>>>>
>>>> The example is not reproducible: l_lfvcspn does not exist.
>>>>
>>>> The error is telling you that you don't have 11 fixed effects in 
>>>> the model. Change k to the number of fixed effects in the model.
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> On 25/09/2017 16:39, dani wrote:
>>>>> mc_spl1gna <- MCMCglmm(y ~ 
>>>>> age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>> ? ? ? ? ? ? ? ? ? ?random =~ STUDYID+class+idv(l_lfvcspn),
>>>>> ? ? ? ? ? ? ? ? ? ?data ? = newdatab,
>>>>> ? ? ? ? ? ? ? ? ? ?family = "poisson"
>>>>
>>>
>>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170927/22d1115d/attachment-0001.ksh>

From orchidn at live.com  Wed Sep 27 17:27:21 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 15:27:21 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>
Message-ID: <MWHPR1201MB002977BB2841EFFF3C44B9DDD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hi,


This is very puzzling. I simply copied and pasted the code that I sent you and I used the same table, I did not do anything else. I will re-try on a different computer. The error persists when I use k=12 and I attempt to run my model.


I will try again and report back soon.

Thanks!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 8:19 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


If I use the code you sent me with the data you sent me there are 12 effects and using k=12 works fine. You must have changed the data and/or the code.


Jarrod

On 27/09/2017 16:13, dani wrote:


Hello Jarrod,


Thank you so much for your patience!


This is the model that I used:


mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)

I simply do not understand what am I doing wrong. These are my fixed terms:


1) age

2) x2

3) x8

4) x9

5) x3

6) l_lfvcspo

7) x4

8) x5

9) x6

10) x7

11) offset


There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.


If I put k=12 per the number of fixed effects that I have, I get this error:


Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.


I apologize again, I really do not understand what am I doing wrong and how can I improve.


Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:55 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.


Cheers,


Jarrod

On 27/09/2017 15:38, dani wrote:

Hello again,


Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?


Also, for k=12 in the prior formula, I get this error:

Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


I am puzzled about this error.


I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.


Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:28:17 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.


Cheers,


Jarrod

On 27/09/2017 15:16, dani wrote:
Hello Jarrod,

I have attached my code and my file.

Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.

I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.

Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.

The MCMC model worked properly based on the prior using k=13.

Please see the code below:

#spl2 function

library(mgcv)

spl2<-function(formula, data, p=TRUE, dataX=data){

  aug<-nrow(data)-nrow(dataX)

  if(aug!=0){
    if(aug<0){
      stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
    }else{
      augX<-matrix(0, aug, ncol(dataX))
      colnames(augX)<-colnames(dataX)
      dataX<-rbind(dataX, augX)
    }
  }
  smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
  sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

  Sed<-eigen(sm$S[[1]])
  Su<-Sed$vectors
  Sd<-Sed$values
  nonzeros <- which(Sd > sqrt(.Machine$double.eps))

  if(p){
    Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
  }else{
    Zn<-sm$X[,-nonzeros, drop=FALSE]
  }
  return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

$spline terms

newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
summary(newdatab1$l_lfvcspo)
summary(newdatab1$l_lfvcspn)

summary(newdatab1)
dim(newdatab1)
str(newdatab1)

#PRIOR


k<-13 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
            R=list(V=1, nu=0),
            G=list(G1=list(V=1, nu=0),
                   G2=list(V=1, nu=0),
                   G3=list(V=1, nu=0)))

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-4

# MCMC model

mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)
summary(mcmc)



This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.

I truly appreciate all your invaluable help!
Best regards,
Dani NM
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Tuesday, September 26, 2017 12:01:19 PM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"






	[[alternative HTML version deleted]]


From orchidn at live.com  Wed Sep 27 17:42:11 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 15:42:11 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <MWHPR1201MB002977BB2841EFFF3C44B9DDD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>,
 <MWHPR1201MB002977BB2841EFFF3C44B9DDD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <MWHPR1201MB0029BDF3E9AD580223AC8D5CD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello again,


I re-run everything and it worked! Thank you so much!


I elucidated what the problem was: after I ran the spl2 function and I created the two terms for the splines, I saved the table and I guess something happened when I did that. I have now commented that line and I simply ran the code without exporting the file and it finally worked.


Thank you so much, Jarrod! I truly appreciate all your help!

To the other members of the list, I would like to apologize for sending so many messages.

Best regards,

DNM


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of dani <orchidn at live.com>
Sent: Wednesday, September 27, 2017 8:27 AM
To: Jarrod Hadfield; Ben Bolker
Cc: r-sig-mixed-models at r-project.org; Matthew
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

Hi,


This is very puzzling. I simply copied and pasted the code that I sent you and I used the same table, I did not do anything else. I will re-try on a different computer. The error persists when I use k=12 and I attempt to run my model.


I will try again and report back soon.

Thanks!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 8:19 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


If I use the code you sent me with the data you sent me there are 12 effects and using k=12 works fine. You must have changed the data and/or the code.


Jarrod

On 27/09/2017 16:13, dani wrote:


Hello Jarrod,


Thank you so much for your patience!


This is the model that I used:


mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)

I simply do not understand what am I doing wrong. These are my fixed terms:


1) age

2) x2

3) x8

4) x9

5) x3

6) l_lfvcspo

7) x4

8) x5

9) x6

10) x7

11) offset


There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.


If I put k=12 per the number of fixed effects that I have, I get this error:


Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.


I apologize again, I really do not understand what am I doing wrong and how can I improve.


Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:55 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.


Cheers,


Jarrod

On 27/09/2017 15:38, dani wrote:

Hello again,


Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?


Also, for k=12 in the prior formula, I get this error:

Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
  fixed effect mu prior is the wrong dimension


I am puzzled about this error.


I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.


Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!

Best,

DNM


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Wednesday, September 27, 2017 7:28:17 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,


There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.


Cheers,


Jarrod

On 27/09/2017 15:16, dani wrote:
Hello Jarrod,

I have attached my code and my file.

Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.

I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.

Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.

The MCMC model worked properly based on the prior using k=13.

Please see the code below:

#spl2 function

library(mgcv)

spl2<-function(formula, data, p=TRUE, dataX=data){

  aug<-nrow(data)-nrow(dataX)

  if(aug!=0){
    if(aug<0){
      stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
    }else{
      augX<-matrix(0, aug, ncol(dataX))
      colnames(augX)<-colnames(dataX)
      dataX<-rbind(dataX, augX)
    }
  }
  smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
  sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

  Sed<-eigen(sm$S[[1]])
  Su<-Sed$vectors
  Sd<-Sed$values
  nonzeros <- which(Sd > sqrt(.Machine$double.eps))

  if(p){
    Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
  }else{
    Zn<-sm$X[,-nonzeros, drop=FALSE]
  }
  return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

$spline terms

newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
summary(newdatab1$l_lfvcspo)
summary(newdatab1$l_lfvcspn)

summary(newdatab1)
dim(newdatab1)
str(newdatab1)

#PRIOR


k<-13 # number of fixed effects

prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
            R=list(V=1, nu=0),
            G=list(G1=list(V=1, nu=0),
                   G2=list(V=1, nu=0),
                   G3=list(V=1, nu=0)))

prior$B$mu[k]<-1 # assuming the offset term is last
prior$B$V[k,k]<-1e-4

# MCMC model

mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                 random =~ STUDYID+class+idv(l_lfvcspn),
                 data   = newdatab1,
                 family = "poisson", prior=prior)
summary(mcmc)



This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.

I truly appreciate all your invaluable help!
Best regards,
Dani NM
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Tuesday, September 26, 2017 12:01:19 PM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi Dani,


It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.


Cheers,


Jarrod


On 25/09/2017 18:08, dani wrote:

Hello again,


Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:


I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).


newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)

I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?

Also, it seems to me that I have 11 fixed effects, I am not sure what to do.

I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.

Best regards!


Sent from Outlook<http://aka.ms/weboutlook>
________________________________
From: Jarrod Hadfield <j.hadfield at ed.ac.uk><mailto:j.hadfield at ed.ac.uk>
Sent: Monday, September 25, 2017 8:51:09 AM
To: dani; Ben Bolker
Cc: Matthew; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines


Hi,

The example is not reproducible: l_lfvcspn does not exist.

The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.

Jarrod


On 25/09/2017 16:39, dani wrote:
mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
                       random =~ STUDYID+class+idv(l_lfvcspn),
                       data   = newdatab,
                       family = "poisson"






        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From fbromano77 at gmail.com  Mon Sep 25 07:09:48 2017
From: fbromano77 at gmail.com (Francesco Romano)
Date: Mon, 25 Sep 2017 07:09:48 +0200
Subject: [R-sig-ME] Main effects for zero inflation poisson regression
In-Reply-To: <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
References: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>
 <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
Message-ID: <CABX-QoHahG3aDkUcTQfnOnSmWp0L1xKkEZTD6JfGFTpq4rDDZQ@mail.gmail.com>

Hello Ben,


Thanks for the reply. I will give it a go on the glmmTMB group.
I have also taken the liberty of replying directly to you attaching
my csv file. Would you mind giving it a go with anova()?

I also emailed the maintainer Mollie Brooks.

Thanks,

Frank

Best,

Frank

On Mon, Sep 25, 2017 at 1:28 AM, Ben Bolker <bbolker at gmail.com> wrote:

> I think it would be worth posting this as an issue on the glmmTMB
> issues list here: https://github.com/glmmtmb/glmmTMB/issues .  (You
> might be able to attach a CSV file there: you can't send CSV
> attachments to this mailing list.)
>
> I'm not surprised that car::Anova doesn't work (I've still been
> working on that one: see
> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/
> inst/other_methods/car_methods.R
> ). On the other hand, I am surprised that the standard two-model
> anova() method doesn't work for you, e.g.
>
>  g1 <- glmmTMB(Reaction~Days+(Days|Subject),lme4::sleepstudy)
>  g0 <- update(g1,.~.-Days)
>  anova(g0,g1)
>
> On Sat, Sep 23, 2017 at 12:48 PM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Hello All,
> >
> > I am trying to run a type III Anova test on a zero-inflation poisson
> model
> > with count data to obtain stats for main effects. In other words, I would
> > like the output to include the df, Chisq, and p value for the main effect
> > of my fixed effects. In the past, I have done this using the 'mixed'
> > function or 'car::Anova' functions from the car package, or in the more
> > traditional (and tedious) way by model comparison via anova(model1,
> model2,
> > etc...).
> >
> > Unfortunately, none of these methods work as R returns an error message:
> >
> >
> > #
> >> anova(p.tmb5, p.tmb5a)
> > Error in anova.glmmTMB(p.tmb5, p.tmb5a) :
> >   no single-model anova() method for glmmTMB
> >
> >> car::Anova(p.tmb5, type = "III")
> > Error in I.p[subs, , drop = FALSE] : subscript out of bounds
> > In addition: Warning message:
> > In is.na(coef(mod)) :
> >   is.na() applied to non-(list or vector) of type 'NULL'
> >
> > The mixed function also can't be used because it will not work with
> glmmTMB
> > which includes two formulas, one for the poisson regression, the other
> for
> > the zero-inflation (see below).
> >
> >  My final model has two fixed effects, Verb.form and Response.type, with
> > three levels each, and a random effect for participants.
> >
> >> p.tmb5<-glmmTMB(Count~Response.type*Verb.form+(1|Partname), data = p,
> zi
> > = ~Response.type)
> >
> > Any suggestions are greatly appreciated. I attach my data in csv format.
> > PS: Partnames and classes are fictitious.
> >
> > --
> > Frank Romano Ph.D.
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From fbromano77 at gmail.com  Tue Sep 26 12:35:52 2017
From: fbromano77 at gmail.com (Francesco Romano)
Date: Tue, 26 Sep 2017 12:35:52 +0200
Subject: [R-sig-ME] Main effects for zero inflation poisson regression
In-Reply-To: <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
References: <CABZN5+H-At7uvqZ4SWUsK5OSou3f-EhPSoA9E4QpGwhRJyUpyw@mail.gmail.com>
 <CABghstR=h_qfPX45=eCYAF9XvsvMxjhreJuus+7zrqu7Lj8WJw@mail.gmail.com>
Message-ID: <CABX-QoF=B1D4rhp9vHF3z-vVh_vTe3Pq8So+_LgyMYS9AK42vQ@mail.gmail.com>

The anova() somehow worked the second time around.
This issue has now been solved.



Best,

Frank

On Mon, Sep 25, 2017 at 1:28 AM, Ben Bolker <bbolker at gmail.com> wrote:

> I think it would be worth posting this as an issue on the glmmTMB
> issues list here: https://github.com/glmmtmb/glmmTMB/issues .  (You
> might be able to attach a CSV file there: you can't send CSV
> attachments to this mailing list.)
>
> I'm not surprised that car::Anova doesn't work (I've still been
> working on that one: see
> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/
> inst/other_methods/car_methods.R
> ). On the other hand, I am surprised that the standard two-model
> anova() method doesn't work for you, e.g.
>
>  g1 <- glmmTMB(Reaction~Days+(Days|Subject),lme4::sleepstudy)
>  g0 <- update(g1,.~.-Days)
>  anova(g0,g1)
>
> On Sat, Sep 23, 2017 at 12:48 PM, Francesco Romano
> <francescobryanromano at gmail.com> wrote:
> > Hello All,
> >
> > I am trying to run a type III Anova test on a zero-inflation poisson
> model
> > with count data to obtain stats for main effects. In other words, I would
> > like the output to include the df, Chisq, and p value for the main effect
> > of my fixed effects. In the past, I have done this using the 'mixed'
> > function or 'car::Anova' functions from the car package, or in the more
> > traditional (and tedious) way by model comparison via anova(model1,
> model2,
> > etc...).
> >
> > Unfortunately, none of these methods work as R returns an error message:
> >
> >
> > #
> >> anova(p.tmb5, p.tmb5a)
> > Error in anova.glmmTMB(p.tmb5, p.tmb5a) :
> >   no single-model anova() method for glmmTMB
> >
> >> car::Anova(p.tmb5, type = "III")
> > Error in I.p[subs, , drop = FALSE] : subscript out of bounds
> > In addition: Warning message:
> > In is.na(coef(mod)) :
> >   is.na() applied to non-(list or vector) of type 'NULL'
> >
> > The mixed function also can't be used because it will not work with
> glmmTMB
> > which includes two formulas, one for the poisson regression, the other
> for
> > the zero-inflation (see below).
> >
> >  My final model has two fixed effects, Verb.form and Response.type, with
> > three levels each, and a random effect for participants.
> >
> >> p.tmb5<-glmmTMB(Count~Response.type*Verb.form+(1|Partname), data = p,
> zi
> > = ~Response.type)
> >
> > Any suggestions are greatly appreciated. I attach my data in csv format.
> > PS: Partnames and classes are fictitious.
> >
> > --
> > Frank Romano Ph.D.
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep 27 19:58:21 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Sep 2017 10:58:21 -0700
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>
Message-ID: <20359A7E-9408-4664-A6D2-25D6FF31411D@comcast.net>

This is just a heads up for dani and Jarrod.

You are having a nice conversation, but the data was never distributed to the list because as far as I can see dani only uses HTML in his emails and probably sent a csv or .Rdata file which would have been scrubbed by the mailserver. So no one but you two can see what is really happening, even though some of the rest of us might have an interest in seeing how well splines do (or don't) work in MCMCglmm.models.

Best;
David.


> On Sep 27, 2017, at 8:19 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> 
> Hi,
> 
> 
> If I use the code you sent me with the data you sent me there are 12 effects and using k=12 works fine. You must have changed the data and/or the code.
> 
> 
> Jarrod
> 
> 
> On 27/09/2017 16:13, dani wrote:
>> 
>> 
>> Hello Jarrod,
>> 
>> 
>> Thank you so much for your patience!
>> 
>> 
>> This is the model that I used:
>> 
>> 
>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>                  random =~ STUDYID+class+idv(l_lfvcspn),
>>                  data   = newdatab1,
>>                  family = "poisson", prior=prior)
>> 
>> I simply do not understand what am I doing wrong. These are my fixed terms:
>> 
>> 
>> 1) age
>> 
>> 2) x2
>> 
>> 3) x8
>> 
>> 4) x9
>> 
>> 5) x3
>> 
>> 6) l_lfvcspo
>> 
>> 7) x4
>> 
>> 8) x5
>> 
>> 9) x6
>> 
>> 10) x7
>> 
>> 11) offset
>> 
>> There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.
>> 
>> 
>> If I put k=12 per the number of fixed effects that I have, I get this error:
>> 
>> 
>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>   fixed effect mu prior is the wrong dimension
>> 
>> Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.
>> 
>> 
>> I apologize again, I really do not understand what am I doing wrong and how can I improve.
>> 
>> 
>> Best,
>> 
>> DNM
>> 
>> 
>> Sent from Outlook <http://aka.ms/weboutlook>
>> 
>> 
>> ------------------------------------------------------------------------
>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> *Sent:* Wednesday, September 27, 2017 7:55 AM
>> *To:* dani; Ben Bolker
>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>> 
>> Hi,
>> 
>> 
>> Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.
>> 
>> 
>> Cheers,
>> 
>> 
>> Jarrod
>> 
>> 
>> On 27/09/2017 15:38, dani wrote:
>>> 
>>> Hello again,
>>> 
>>> 
>>> Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?
>>> 
>>> 
>>> Also, for k=12 in the prior formula, I get this error:
>>> 
>>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>>   fixed effect mu prior is the wrong dimension
>>> 
>>> I am puzzled about this error.
>>> 
>>> 
>>> I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.
>>> 
>>> 
>>> Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!
>>> 
>>> Best,
>>> 
>>> DNM
>>> 
>>> 
>>> Sent from Outlook <http://aka.ms/weboutlook>
>>> ------------------------------------------------------------------------
>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> *Sent:* Wednesday, September 27, 2017 7:28:17 AM
>>> *To:* dani; Ben Bolker
>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>> 
>>> Hi,
>>> 
>>> 
>>> There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.
>>> 
>>> 
>>> Cheers,
>>> 
>>> 
>>> Jarrod
>>> 
>>> 
>>> On 27/09/2017 15:16, dani wrote:
>>>> Hello Jarrod,
>>>> 
>>>> I have attached my code and my file.
>>>> 
>>>> Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.
>>>> 
>>>> I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.
>>>> 
>>>> Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.
>>>> 
>>>> The MCMC model worked properly based on the prior using k=13.
>>>> 
>>>> Please see the code below:
>>>> 
>>>> *#spl2 function*
>>>> 
>>>> library(mgcv)
>>>> 
>>>> spl2<-function(formula, data, p=TRUE, dataX=data){
>>>> aug<-nrow(data)-nrow(dataX)
>>>>   if(aug!=0){
>>>> if(aug<0){
>>>>       stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
>>>>     }else{
>>>> augX<-matrix(0, aug, ncol(dataX))
>>>> colnames(augX)<-colnames(dataX)
>>>> dataX<-rbind(dataX, augX)
>>>>     }
>>>>   }
>>>> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
>>>> sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
>>>> Sed<-eigen(sm$S[[1]])
>>>> Su<-Sed$vectors
>>>> Sd<-Sed$values
>>>>   nonzeros <- which(Sd > sqrt(.Machine$double.eps))
>>>>   if(p){
>>>> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
>>>>   }else{
>>>> Zn<-sm$X[,-nonzeros, drop=FALSE]
>>>>   }
>>>> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
>>>> }
>>>> 
>>>> *$spline terms*
>>>> *
>>>> *
>>>> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
>>>> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
>>>> summary(newdatab1$l_lfvcspo)
>>>> summary(newdatab1$l_lfvcspn)
>>>> 
>>>> summary(newdatab1)
>>>> dim(newdatab1)
>>>> str(newdatab1)
>>>> 
>>>> *#PRIOR*
>>>> 
>>>> 
>>>> k<-13 # number of fixed effects
>>>> 
>>>> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>>> R=list(V=1, nu=0),
>>>> G=list(G1=list(V=1, nu=0),
>>>>  G2=list(V=1, nu=0),
>>>>  G3=list(V=1, nu=0)))
>>>> 
>>>> prior$B$mu[k]<-1 # assuming the offset term is last
>>>> prior$B$V[k,k]<-1e-4
>>>> 
>>>> *# MCMC model*
>>>> 
>>>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>  random =~ STUDYID+class+idv(l_lfvcspn),
>>>>  data   = newdatab1,
>>>>  family = "poisson", prior=prior)
>>>> summary(mcmc)
>>>> 
>>>> 
>>>> This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.
>>>> 
>>>> I truly appreciate all your invaluable help!
>>>> Best regards,
>>>> Dani NM
>>>> ------------------------------------------------------------------------
>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
>>>> *To:* dani; Ben Bolker
>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>> 
>>>> Hi Dani,
>>>> 
>>>> 
>>>> It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.
>>>> 
>>>> 
>>>> Cheers,
>>>> 
>>>> 
>>>> Jarrod
>>>> 
>>>> 
>>>> On 25/09/2017 18:08, dani wrote:
>>>>> 
>>>>> Hello again,
>>>>> 
>>>>> 
>>>>> Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:
>>>>> 
>>>>> 
>>>>> I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).
>>>>> 
>>>>> 
>>>>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>>>>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>>>> 
>>>>> I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?
>>>>> 
>>>>> Also, it seems to me that I have 11 fixed effects, I am not sure what to do.
>>>>> 
>>>>> I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.
>>>>> 
>>>>> Best regards!
>>>>> 
>>>>> 
>>>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>>> ------------------------------------------------------------------------
>>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>>>>> *To:* dani; Ben Bolker
>>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> The example is not reproducible: l_lfvcspn does not exist.
>>>>> 
>>>>> The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> On 25/09/2017 16:39, dani wrote:
>>>>>> mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>>>                    random =~ STUDYID+class+idv(l_lfvcspn),
>>>>>>                    data   = newdatab,
>>>>>>                    family = "poisson"
>>>>> 
>>>> 
>>> 
>> 
> 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From orchidn at live.com  Wed Sep 27 20:26:13 2017
From: orchidn at live.com (dani)
Date: Wed, 27 Sep 2017 18:26:13 +0000
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <20359A7E-9408-4664-A6D2-25D6FF31411D@comcast.net>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <346be122-aac8-9066-6c92-fc36c8a3ee43@auburn.edu>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>,
 <20359A7E-9408-4664-A6D2-25D6FF31411D@comcast.net>
Message-ID: <MWHPR1201MB00295C5A0E8163235CDCFF46D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello David,


My file is very large indeed.


I would just like to emphasize that there was nothing wrong with the way the spl2 function worked.


Everything worked properly when I followed Jarrod's advice. The code was ok.


The problem is that I am a beginner and I keep on saving my files and exporting my file messed with my table.


Therefore, everything worked properly.


I apologize again for taking so much time from everyone with this problem that turned out not to be a problem, after all.


Thanks again everyone!

Best

DNM


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, September 27, 2017 10:58 AM
To: Jarrod Hadfield
Cc: dani; Ben Bolker; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines

This is just a heads up for dani and Jarrod.

You are having a nice conversation, but the data was never distributed to the list because as far as I can see dani only uses HTML in his emails and probably sent a csv or .Rdata file which would have been scrubbed by the mailserver. So no one but you two can see what is really happening, even though some of the rest of us might have an interest in seeing how well splines do (or don't) work in MCMCglmm.models.

Best;
David.


> On Sep 27, 2017, at 8:19 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
> Hi,
>
>
> If I use the code you sent me with the data you sent me there are 12 effects and using k=12 works fine. You must have changed the data and/or the code.
>
>
> Jarrod
>
>
> On 27/09/2017 16:13, dani wrote:
>>
>>
>> Hello Jarrod,
>>
>>
>> Thank you so much for your patience!
>>
>>
>> This is the model that I used:
>>
>>
>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>                  random =~ STUDYID+class+idv(l_lfvcspn),
>>                  data   = newdatab1,
>>                  family = "poisson", prior=prior)
>>
>> I simply do not understand what am I doing wrong. These are my fixed terms:
>>
>>
>> 1) age
>>
>> 2) x2
>>
>> 3) x8
>>
>> 4) x9
>>
>> 5) x3
>>
>> 6) l_lfvcspo
>>
>> 7) x4
>>
>> 8) x5
>>
>> 9) x6
>>
>> 10) x7
>>
>> 11) offset
>>
>> There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.
>>
>>
>> If I put k=12 per the number of fixed effects that I have, I get this error:
>>
>>
>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>   fixed effect mu prior is the wrong dimension
>>
>> Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.
>>
>>
>> I apologize again, I really do not understand what am I doing wrong and how can I improve.
>>
>>
>> Best,
>>
>> DNM
>>
>>
>> Sent from Outlook <http://aka.ms/weboutlook>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> *Sent:* Wednesday, September 27, 2017 7:55 AM
>> *To:* dani; Ben Bolker
>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>
>> Hi,
>>
>>
>> Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.
>>
>>
>> Cheers,
>>
>>
>> Jarrod
>>
>>
>> On 27/09/2017 15:38, dani wrote:
>>>
>>> Hello again,
>>>
>>>
>>> Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?
>>>
>>>
>>> Also, for k=12 in the prior formula, I get this error:
>>>
>>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>>   fixed effect mu prior is the wrong dimension
>>>
>>> I am puzzled about this error.
>>>
>>>
>>> I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.
>>>
>>>
>>> Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!
>>>
>>> Best,
>>>
>>> DNM
>>>
>>>
>>> Sent from Outlook <http://aka.ms/weboutlook>
>>> ------------------------------------------------------------------------
>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> *Sent:* Wednesday, September 27, 2017 7:28:17 AM
>>> *To:* dani; Ben Bolker
>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>
>>> Hi,
>>>
>>>
>>> There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.
>>>
>>>
>>> Cheers,
>>>
>>>
>>> Jarrod
>>>
>>>
>>> On 27/09/2017 15:16, dani wrote:
>>>> Hello Jarrod,
>>>>
>>>> I have attached my code and my file.
>>>>
>>>> Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.
>>>>
>>>> I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.
>>>>
>>>> Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.
>>>>
>>>> The MCMC model worked properly based on the prior using k=13.
>>>>
>>>> Please see the code below:
>>>>
>>>> *#spl2 function*
>>>>
>>>> library(mgcv)
>>>>
>>>> spl2<-function(formula, data, p=TRUE, dataX=data){
>>>> aug<-nrow(data)-nrow(dataX)
>>>>   if(aug!=0){
>>>> if(aug<0){
>>>>       stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
>>>>     }else{
>>>> augX<-matrix(0, aug, ncol(dataX))
>>>> colnames(augX)<-colnames(dataX)
>>>> dataX<-rbind(dataX, augX)
>>>>     }
>>>>   }
>>>> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
>>>> sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
>>>> Sed<-eigen(sm$S[[1]])
>>>> Su<-Sed$vectors
>>>> Sd<-Sed$values
>>>>   nonzeros <- which(Sd > sqrt(.Machine$double.eps))
>>>>   if(p){
>>>> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
>>>>   }else{
>>>> Zn<-sm$X[,-nonzeros, drop=FALSE]
>>>>   }
>>>> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
>>>> }
>>>>
>>>> *$spline terms*
>>>> *
>>>> *
>>>> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
>>>> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
>>>> summary(newdatab1$l_lfvcspo)
>>>> summary(newdatab1$l_lfvcspn)
>>>>
>>>> summary(newdatab1)
>>>> dim(newdatab1)
>>>> str(newdatab1)
>>>>
>>>> *#PRIOR*
>>>>
>>>>
>>>> k<-13 # number of fixed effects
>>>>
>>>> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>>> R=list(V=1, nu=0),
>>>> G=list(G1=list(V=1, nu=0),
>>>>  G2=list(V=1, nu=0),
>>>>  G3=list(V=1, nu=0)))
>>>>
>>>> prior$B$mu[k]<-1 # assuming the offset term is last
>>>> prior$B$V[k,k]<-1e-4
>>>>
>>>> *# MCMC model*
>>>>
>>>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>  random =~ STUDYID+class+idv(l_lfvcspn),
>>>>  data   = newdatab1,
>>>>  family = "poisson", prior=prior)
>>>> summary(mcmc)
>>>>
>>>>
>>>> This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.
>>>>
>>>> I truly appreciate all your invaluable help!
>>>> Best regards,
>>>> Dani NM
>>>> ------------------------------------------------------------------------
>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
>>>> *To:* dani; Ben Bolker
>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>
>>>> Hi Dani,
>>>>
>>>>
>>>> It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.
>>>>
>>>>
>>>> Cheers,
>>>>
>>>>
>>>> Jarrod
>>>>
>>>>
>>>> On 25/09/2017 18:08, dani wrote:
>>>>>
>>>>> Hello again,
>>>>>
>>>>>
>>>>> Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:
>>>>>
>>>>>
>>>>> I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).
>>>>>
>>>>>
>>>>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>>>>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>>>>
>>>>> I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?
>>>>>
>>>>> Also, it seems to me that I have 11 fixed effects, I am not sure what to do.
>>>>>
>>>>> I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.
>>>>>
>>>>> Best regards!
>>>>>
>>>>>
>>>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>>> ------------------------------------------------------------------------
>>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>>>>> *To:* dani; Ben Bolker
>>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>>
>>>>> Hi,
>>>>>
>>>>> The example is not reproducible: l_lfvcspn does not exist.
>>>>>
>>>>> The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>> On 25/09/2017 16:39, dani wrote:
>>>>>> mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>>>                    random =~ STUDYID+class+idv(l_lfvcspn),
>>>>>>                    data   = newdatab,
>>>>>>                    family = "poisson"
>>>>>
>>>>
>>>
>>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Sep 27 21:04:07 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 27 Sep 2017 20:04:07 +0100
Subject: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
In-Reply-To: <20359A7E-9408-4664-A6D2-25D6FF31411D@comcast.net>
References: <MWHPR1201MB0029D6B962316483AACA48A4D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <MWHPR1201MB002981E96A9B7170A9E66493D6670@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <CABghstSyME=TYbgCMxUdarmTDsisysKuwGSd-TEAAJFfPVH_eQ@mail.gmail.com>
 <MWHPR1201MB002944173C438E84CF18802BD67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <4e932aba-7e31-6c7d-245c-25fa3d786ced@ed.ac.uk>
 <MWHPR1201MB002996FCA7C42BF5F9528272D67A0@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <952f46c3-fb68-5fed-2a93-4e1d69ccd040@ed.ac.uk>
 <MWHPR1201MB002926558ED58AC907EA44D3D6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <9a075e05-9e27-6548-666b-c9febdd2b36b@ed.ac.uk>
 <MWHPR1201MB0029CBDD8AEFEE407AEEEB7DD6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <ad54d068-89b6-1329-a1ce-8dcf142874c2@ed.ac.uk>
 <MWHPR1201MB00296B7CF2BEB502D1281B8ED6780@MWHPR1201MB0029.namprd12.prod.outlook.com>
 <084d0e3f-5a7c-7843-32f0-56e7ba5e2f95@ed.ac.uk>
 <20359A7E-9408-4664-A6D2-25D6FF31411D@comcast.net>
Message-ID: <2c2996b0-9d46-592a-845a-8d34b0d72d49@ed.ac.uk>

Hi David,

Dani's original issue wasn't with the spline part of the model per se 
but fixing the parameter associated with the offset variable at 1. Below 
is an example of fitting a spline to made up wiggly data if that helps.

Cheers,

Jarrod


library(mgcv)
library(MCMCglmm)

spl2<-function(formula, data, p=TRUE, dataX=data){

   aug<-nrow(data)-nrow(dataX)

   if(aug!=0){
     if(aug<0){
       stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
     }else{
       augX<-matrix(0, aug, ncol(dataX))
       colnames(augX)<-colnames(dataX)
       dataX<-rbind(dataX, augX)
     }
   }
   smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
   sm<-smoothCon(smooth.spec.object, data=data, 
knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]

   Sed<-eigen(sm$S[[1]])
   Su<-Sed$vectors
   Sd<-Sed$values
   nonzeros <- which(Sd > sqrt(.Machine$double.eps))

   if(p){
     Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
   }else{
     Zn<-sm$X[,-nonzeros, drop=FALSE]
   }
   return(Zn[1:(nrow(data)-aug),,drop=FALSE])
}

x<-rnorm(200)
y<-3*cos(x*3)+0.6*x^2+x+rnorm(200)
# made up data that `wiggles' with respect to x

dat<-data.frame(y=y,x=x)

dat$xpo<-spl2(~s(x,k=10), data=dat, p=F)

# random effect predictor for non-smoothed spline term

dat$xpn<-spl2(~s(x,k=10), data=dat)
# random effect design matrix for smoothed spline terms

m1<-MCMCglmm(y~xpo, random=~idv(xpn), data=dat, pr=TRUE)
# fit model

p1<-predict(m1, marginal=NULL)
# get spline predictions

plot(y~x)
# plot data

lines(p1[order(x)]~x[order(x)])
# plot spline predictions

lines(3*cos(x[order(x)]*3)+0.6*x[order(x)]^2+x[order(x)]~x[order(x)], lty=2)
# plot actual function


On 27/09/2017 18:58, David Winsemius wrote:
> This is just a heads up for dani and Jarrod.
>
> You are having a nice conversation, but the data was never distributed to the list because as far as I can see dani only uses HTML in his emails and probably sent a csv or .Rdata file which would have been scrubbed by the mailserver. So no one but you two can see what is really happening, even though some of the rest of us might have an interest in seeing how well splines do (or don't) work in MCMCglmm.models.
>
> Best;
> David.
>
>
>> On Sep 27, 2017, at 8:19 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>> Hi,
>>
>>
>> If I use the code you sent me with the data you sent me there are 12 effects and using k=12 works fine. You must have changed the data and/or the code.
>>
>>
>> Jarrod
>>
>>
>> On 27/09/2017 16:13, dani wrote:
>>>
>>> Hello Jarrod,
>>>
>>>
>>> Thank you so much for your patience!
>>>
>>>
>>> This is the model that I used:
>>>
>>>
>>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>                   random =~ STUDYID+class+idv(l_lfvcspn),
>>>                   data   = newdatab1,
>>>                   family = "poisson", prior=prior)
>>>
>>> I simply do not understand what am I doing wrong. These are my fixed terms:
>>>
>>>
>>> 1) age
>>>
>>> 2) x2
>>>
>>> 3) x8
>>>
>>> 4) x9
>>>
>>> 5) x3
>>>
>>> 6) l_lfvcspo
>>>
>>> 7) x4
>>>
>>> 8) x5
>>>
>>> 9) x6
>>>
>>> 10) x7
>>>
>>> 11) offset
>>>
>>> There are thus 11 terms. If I add the intercept I obtain 12 fixed effects.
>>>
>>>
>>> If I put k=12 per the number of fixed effects that I have, I get this error:
>>>
>>>
>>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>>    fixed effect mu prior is the wrong dimension
>>>
>>> Do you think it might be an issue with the structure of the newdatab1 dataset? It seems Ok when I look at it. I do not know what else to do, I seem to have exhausted all options.
>>>
>>>
>>> I apologize again, I really do not understand what am I doing wrong and how can I improve.
>>>
>>>
>>> Best,
>>>
>>> DNM
>>>
>>>
>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>
>>>
>>> ------------------------------------------------------------------------
>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> *Sent:* Wednesday, September 27, 2017 7:55 AM
>>> *To:* dani; Ben Bolker
>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>
>>> Hi,
>>>
>>>
>>> Yes - the intercept is a parameter so should be included. If you get 13 effects then the data/code you sent us are different from the data/code you are using. The issue is not really anything to do with your (mis)understanding about priors it is simply that you have set priors for k parameters whereas there are in fact not k parameters.
>>>
>>>
>>> Cheers,
>>>
>>>
>>> Jarrod
>>>
>>>
>>> On 27/09/2017 15:38, dani wrote:
>>>> Hello again,
>>>>
>>>>
>>>> Thanks! I was indeed referring to the k in the prior formula. I guess I am still confused whether I should add the intercept to the number of fixed effects, as I have 12 variables as I count as fixed effects without the intercept. Would it be possible to confirm that for me, please?
>>>>
>>>>
>>>> Also, for k=12 in the prior formula, I get this error:
>>>>
>>>> Error in MCMCglmm(y ~ age + x2 + x8 + x9 + x3 + l_lfvcspo + x4 + x5 +  :
>>>>    fixed effect mu prior is the wrong dimension
>>>>
>>>> I am puzzled about this error.
>>>>
>>>>
>>>> I do not seem to understand how to select the fixed effects. Could someone point me to a source of information where I can learn more about this, please?  Also, is there a book where I can learn more about prior specification? I think I need to see more examples.
>>>>
>>>>
>>>> Thank you so much. I apologize for this, but I am very confused and I would like to learn more about this!
>>>>
>>>> Best,
>>>>
>>>> DNM
>>>>
>>>>
>>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>> ------------------------------------------------------------------------
>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> *Sent:* Wednesday, September 27, 2017 7:28:17 AM
>>>> *To:* dani; Ben Bolker
>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>
>>>> Hi,
>>>>
>>>>
>>>> There are 12 terms in the model not 13 so k=12. The k in the prior specification is completely unrelated to the number of knot points in the spline.
>>>>
>>>>
>>>> Cheers,
>>>>
>>>>
>>>> Jarrod
>>>>
>>>>
>>>> On 27/09/2017 15:16, dani wrote:
>>>>> Hello Jarrod,
>>>>>
>>>>> I have attached my code and my file.
>>>>>
>>>>> Variable age has 3 levels, variables x2, x8, and x9 have two levels each, and the rest of the variables are continuous.
>>>>>
>>>>> I re-ran the spl2 function and this time around I obtained one single fixed smoother (l_lfvcspo) and one single random smoother (l_lfvcspn). Last time around I got 8 variables with suffixes from 1-8 for l_lfvcspn and I did not know what to do with those.
>>>>>
>>>>> Also, as I had 11 fixed effects (corresponding to 11 variables), I thought it was appropriate to choose k=11. I was not sure whether the intercept needed to be counted as well as the levels of the categorical fixed predictors (except for their reference categories). Because I kept on getting the "mu" error for k=11, I tried k=13 (which includes the intercept and the 2 levels for the 3-level age variable, which I did not consider before). I am not sure this is the way to go, I guess I need to read more to be able to model properly fixed effects in R, but for now I was wondering whether this consideration of fixed effects sounds ok in this particular example.
>>>>>
>>>>> The MCMC model worked properly based on the prior using k=13.
>>>>>
>>>>> Please see the code below:
>>>>>
>>>>> *#spl2 function*
>>>>>
>>>>> library(mgcv)
>>>>>
>>>>> spl2<-function(formula, data, p=TRUE, dataX=data){
>>>>> aug<-nrow(data)-nrow(dataX)
>>>>>    if(aug!=0){
>>>>> if(aug<0){
>>>>>        stop("sorry nrow(dataX) must be less than or equal to nrow(data)")
>>>>>      }else{
>>>>> augX<-matrix(0, aug, ncol(dataX))
>>>>> colnames(augX)<-colnames(dataX)
>>>>> dataX<-rbind(dataX, augX)
>>>>>      }
>>>>>    }
>>>>> smooth.spec.object<-interpret.gam(formula)$smooth.spec[[1]]
>>>>> sm<-smoothCon(smooth.spec.object, data=data, knots=NULL,absorb.cons=TRUE, dataX=dataX)[[1]]
>>>>> Sed<-eigen(sm$S[[1]])
>>>>> Su<-Sed$vectors
>>>>> Sd<-Sed$values
>>>>>    nonzeros <- which(Sd > sqrt(.Machine$double.eps))
>>>>>    if(p){
>>>>> Zn<-sm$X%*%Su[,nonzeros, drop=FALSE]%*%diag(1/sqrt(Sd[nonzeros]))
>>>>>    }else{
>>>>> Zn<-sm$X[,-nonzeros, drop=FALSE]
>>>>>    }
>>>>> return(Zn[1:(nrow(data)-aug),,drop=FALSE])
>>>>> }
>>>>>
>>>>> *$spline terms*
>>>>> *
>>>>> *
>>>>> newdatab1$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab1, p=F)
>>>>> newdatab1$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab1)
>>>>> summary(newdatab1$l_lfvcspo)
>>>>> summary(newdatab1$l_lfvcspn)
>>>>>
>>>>> summary(newdatab1)
>>>>> dim(newdatab1)
>>>>> str(newdatab1)
>>>>>
>>>>> *#PRIOR*
>>>>>
>>>>>
>>>>> k<-13 # number of fixed effects
>>>>>
>>>>> prior<-list(B=list(V=diag(k)*1e4, mu=rep(0,k)),
>>>>> R=list(V=1, nu=0),
>>>>> G=list(G1=list(V=1, nu=0),
>>>>>   G2=list(V=1, nu=0),
>>>>>   G3=list(V=1, nu=0)))
>>>>>
>>>>> prior$B$mu[k]<-1 # assuming the offset term is last
>>>>> prior$B$V[k,k]<-1e-4
>>>>>
>>>>> *# MCMC model*
>>>>>
>>>>> mcmc <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>>   random =~ STUDYID+class+idv(l_lfvcspn),
>>>>>   data   = newdatab1,
>>>>>   family = "poisson", prior=prior)
>>>>> summary(mcmc)
>>>>>
>>>>>
>>>>> This model has worked, so I would like to thank you so much for all your help so far. I guess I just want to make sure I understand how to model the fixed effects in MCMCglmm and I also would like to make sure that my model is correct.
>>>>>
>>>>> I truly appreciate all your invaluable help!
>>>>> Best regards,
>>>>> Dani NM
>>>>> ------------------------------------------------------------------------
>>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>> *Sent:* Tuesday, September 26, 2017 12:01:19 PM
>>>>> *To:* dani; Ben Bolker
>>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>>
>>>>> Hi Dani,
>>>>>
>>>>>
>>>>> It is still not possible for us to diagnose the problem. You need to provide code+data that reproduces the error. f_lfv_c does not appear in newdatab.
>>>>>
>>>>>
>>>>> Cheers,
>>>>>
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>> On 25/09/2017 18:08, dani wrote:
>>>>>> Hello again,
>>>>>>
>>>>>>
>>>>>> Thank you so much for your prompt response. I apologize for the silly questions, I am a true beginner and I am ashamed of my ignorance. I guess I should explain what I did:
>>>>>>
>>>>>>
>>>>>> I used the spl2 function and obtained the fixed and random factors corresponding to the variable I needed the smoother for (named f_lfv_c).
>>>>>>
>>>>>>
>>>>>> newdatab$l_lfvcspo<-spl2(~s(f_lfv_c,k=10), data=newdatab, p=F)
>>>>>> newdatab$l_lfvcspn<-spl2(~s(f_lfv_c,k=10), data=newdatab)
>>>>>>
>>>>>> I am not sure how to attach the random effects corresponding to the l_lfvcspn. I get this array of 8 variables and I am really not sure how to include them in the model. Should I get forget about spl2 and simply add the variable f_lfv_c as a fixed term and spl(f_lfv) in the idv random term?
>>>>>>
>>>>>> Also, it seems to me that I have 11 fixed effects, I am not sure what to do.
>>>>>>
>>>>>> I am really sorry about all these silly questions, I really do not understand how these things work, but I would like to know more about this.
>>>>>>
>>>>>> Best regards!
>>>>>>
>>>>>>
>>>>>> Sent from Outlook <http://aka.ms/weboutlook>
>>>>>> ------------------------------------------------------------------------
>>>>>> *From:* Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>> *Sent:* Monday, September 25, 2017 8:51:09 AM
>>>>>> *To:* dani; Ben Bolker
>>>>>> *Cc:* Matthew; r-sig-mixed-models at r-project.org
>>>>>> *Subject:* Re: [R-sig-ME] MCMCglmm Poisson with an offset term and splines
>>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> The example is not reproducible: l_lfvcspn does not exist.
>>>>>>
>>>>>> The error is telling you that you don't have 11 fixed effects in the model. Change k to the number of fixed effects in the model.
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 25/09/2017 16:39, dani wrote:
>>>>>>> mc_spl1gna <- MCMCglmm(y ~ age+x2+x8+x9+x3+l_lfvcspo+x4+x5+x6+x7+offset,
>>>>>>>                     random =~ STUDYID+class+idv(l_lfvcspn),
>>>>>>>                     data   = newdatab,
>>>>>>>                     family = "poisson"
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From nika.galic001 at gmail.com  Wed Sep 27 21:39:29 2017
From: nika.galic001 at gmail.com (Nika Galic)
Date: Wed, 27 Sep 2017 15:39:29 -0400
Subject: [R-sig-ME] Data weighting in gnls
Message-ID: <CAB67MVy553r23WLN94EOgQ87=Y0Wm2x4wJF8fV==DWNX4CD44A@mail.gmail.com>

Dear all,

I have a data set in which different species contribute different numbers
of data points and I am fitting non-liner models to it. Does anyone know
how I could weight each data point so that species with few points are
equally weighted as those with many data points?

I would assume that something where each point is weighted by 1/n (n-number
of data points for a single species) for the model fitting routine could be
the answer, but I am not totally sure if this is the way and how to
implement this. I am using the *gnls *function in the nlme package, and am
applying a phylogenetic correction (using the correlation argument) for
model fitting.

Any suggestions are very much appreciated, apologies if this group is not
the most appropriate for this posting.

Thanks,
Nika

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Sep 28 14:04:11 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 28 Sep 2017 14:04:11 +0200
Subject: [R-sig-ME] nested residual covariance matrices longitudinal data
Message-ID: <95e97e78-7ce1-389f-0291-1e885dc9cbc5@maw.ru.nl>

Dear list,

I would like to ask a few questions about comparing longitudinal model 
results. For longitudinal data with say 4 fixed occasions, my model 
looks like this:

Y = b0 + b1*occ1 + b2*occ2 + b3*occ3 + e

where occ1, occ2 and occ3 are 0-1 dummy variables for the first three 
occasions and "e" is the error term. The data are in "long" format with 
four records for each person. When using "gls" from the nlme package, I 
can choose among many different covariance structures for the residuals 
"e". In would like to confine my question to four of these:

unstructered (UN), compound symmetry (CS), autoregressive 1 (AR1), 
Toeplitz.

As far as these different structures are nested, one can use likelihood 
ratio tests. E.g. one could compare Toeplitz with AR1, since AR1 is a 
special case of Toeplitz. Am I right here? The anova command in R allows 
doing this comparison for Toeplitz and AR1 and produces a chisquare 
test, but does it indeed make sense, i.e. are these two models indeed 
nested?

For the comparison of CS and AR1, however, anova does not produce a 
chisquare test to compare these models, I guess since the two are NOT 
nested. Is this correct? IMHO they are indeed not nested, but I'm not 
completely sure...

For comparing CS, AR1 and Toeplitz with UN,? anova nicely produces 
chisquares. Does it mean that (as I would expect) the three are all 
nested within UN?

And finally the last question. In a book (can't remember which one...) I 
once found a general remark about using likelihood ratio tests (LRT) to 
compare models? with different covariance structures for residuals but 
identical fixed effects. A warning was given that one should be cautious 
to use LRT's in case the restricted model arises by putting variances 
equal to zero in the full model. In such situation the H0 hypothesized 
value of the variance lies "on the boundary of the parameter space" and 
consequently the difference in deviance of the two models will not be 
chisquare distributed. Subsequently, one uses AIC and BIC instead of 
model deviances to select the "better" model.
 ??? However, for the above comparisons I do not see that variances are 
set equal to zero. E.g. comparing Toeplitz and CS comes down to assuming 
EQUAL covariances instead of just ONE covariance. Would you agree that 
therefore, when pairwise comparing the models mentioned (as far as 
nested) this "boundary" problem does not exist?

Thanks a lot for any help!!!

Ben Pelzer.


From b.pelzer at maw.ru.nl  Thu Sep 28 14:05:58 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 28 Sep 2017 14:05:58 +0200
Subject: [R-sig-ME] nested residual covariance matrices longitudinal data
Message-ID: <2b6f82a9-7f2d-7437-5848-9bc0586c4bdb@maw.ru.nl>

Dear list,

I would like to ask a few questions about comparing longitudinal model 
results. For longitudinal data with say 4 fixed occasions, my model 
looks like this:

Y = b0 + b1*occ1 + b2*occ2 + b3*occ3 + e

where occ1, occ2 and occ3 are 0-1 dummy variables for the first three 
occasions and "e" is the error term. The data are in "long" format with 
four records for each person. When using "gls" from the nlme package, I 
can choose among many different covariance structures for the residuals 
"e". In would like to confine my question to four of these:

unstructered (UN), compound symmetry (CS), autoregressive 1 (AR1), 
Toeplitz.

As far as these different structures are nested, one can use likelihood 
ratio tests. E.g. one could compare Toeplitz with AR1, since AR1 is a 
special case of Toeplitz. Am I right here? The anova command in R allows 
doing this comparison for Toeplitz and AR1 and produces a chisquare 
test, but does it indeed make sense, i.e. are these two models indeed 
nested?

For the comparison of CS and AR1, however, anova does not produce a 
chisquare test to compare these models, I guess since the two are NOT 
nested. Is this correct? IMHO they are indeed not nested, but I'm not 
completely sure...

For comparing CS, AR1 and Toeplitz with UN,? anova nicely produces 
chisquares. Does it mean that (as I would expect) the three are all 
nested within UN?

And finally the last question. In a book (can't remember which one...) I 
once found a general remark about using likelihood ratio tests (LRT) to 
compare models? with different covariance structures for residuals but 
identical fixed effects. A warning was given that one should be cautious 
to use LRT's in case the restricted model arises by putting variances 
equal to zero in the full model. In such situation the H0 hypothesized 
value of the variance lies "on the boundary of the parameter space" and 
consequently the difference in deviance of the two models will not be 
chisquare distributed. Subsequently, one uses AIC and BIC instead of 
model deviances to select the "better" model.
 ??? However, for the above comparisons I do not see that variances are 
set equal to zero. E.g. comparing Toeplitz and CS comes down to assuming 
EQUAL covariances instead of just ONE covariance. Would you agree that 
therefore, when pairwise comparing the models mentioned (as far as 
nested) this "boundary" problem does not exist?

Thanks a lot for any help!!!

Ben Pelzer.


From Maarten.Jung at mailbox.tu-dresden.de  Thu Sep 28 16:33:41 2017
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 28 Sep 2017 16:33:41 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAHr4DycK6ynqnVWQi9+Wx-u=Sx+KyanwRo51oY2HsZ-BQ1tQ5A@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
 <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
 <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>
 <20170925081541.GC11898@info124.pharmacie.univ-paris5.fr>
 <CAHr4DycK6ynqnVWQi9+Wx-u=Sx+KyanwRo51oY2HsZ-BQ1tQ5A@mail.gmail.com>
Message-ID: <CAHr4Dyc1zW-hR2T2h_vyX=mavav=4WEkGNHPn6Y2eq0HgtkgdA@mail.gmail.com>

@ Emmanuel Curis Douglas Bates' statement is about the "variance-covariance
matrix for the vector-valued random effects" (slide 91) not about the
covariance matrix of the observations.

2017-09-25 21:38 GMT+02:00 Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
:

> Thanks for the very nice explanation of compound symmetry in your
> examples.
> I understand the continuum of complexity wrt to the random-effects
> structure explained by Reinhold Kliegl, also.
> But I still don't see the link between m1 and m2 in case of compound
> symmetry - sorry for that!
> Analogous to this post http://www.rpubs.com/Reinhold/22193 mod2 should
> constrain the group-related effects to equality. What exactly does this
> have to do with compound symmetry?
>
> 2017-09-25 10:15 GMT+02:00 Emmanuel Curis <emmanuel.curis at parisdescartes
> .fr>:
>
>> Hello,
>>
>> I'm not sure if I understand correctly, but I think the "compound
>> symmetry" mention usually applies to the covariance matrix of the
>> observations, Y, in a given cluster.
>>
>> In that case, and omiting the fixed part of the model that does not
>> change the Y covariance matrix, we have
>>
>>  Y = fixed effects + X U + epsilon
>>
>> with U the random effect(s), X the design matrix for it, and epsilon
>> the residual error.
>>
>> Hence, assuming random effect and epsilon independant
>>
>> Sigma(Y) = tX Sigma( U ) X + Sigma( epsilon)
>>
>> so Sigma(Y) will have compound symmetry as soon as both X Sigma(U) tX
>> and Sigma( epsilon ) have themselves compound symmetry ? or if they
>> have structure that kind of "compensate" themselve. So basically, that
>> does not preclude from having correlations between levels of a fixed
>> effect factor.
>>
>> However, let consider a scholar case with two observations on the same
>> patient [cluster] that takes or not its treatment [fixed effect], with
>> a different random effect for both cases, and let consider two ways of
>> writing it.
>>
>> Let Sigma(epsilon) = ( se? rse   ), Sigma(U) = ( sa? r   )
>>                      ( rse  se?' )             ( r   sb? )
>>
>> (typically, rse = 0, se? = se?')
>>
>> 1) Let be U1 the random effect for patient without treatment and U2
>>    therandom effect for the same patient with treatment, so
>>
>> X = ( 1 0 ) = identity.
>>     ( 0 1 )
>>
>> In that case, X Sigma(U) tX = Sigma(U) so
>>
>> Sigma(Y) = ( sa? + se?     r + rse  )
>>            (  r  + rse   sb? + se?' )
>>
>> and you have compound symmetry if sa? + se? = sb? + se?', that is in
>> the classical case of se? = se?', assuming equal variances for both
>> the two random effects. But there is no condition on r: you can have
>> any correlation between the levels and still have compound symmetry.
>>
>> 2) U1 for patient i and U2 for effect of treatment in patient i.
>>
>> So X = ( 1 0 ), tX = ( 1 1 )
>>        ( 1 1 )       ( 0 1 )
>>
>> Then Sigma(Y) = ( sa? + se?        sa? + r + rse         )
>>                 ( sa? + r + rse    sa? + sb? + 2r + se?' )
>>
>> and compound symmetry is much harder to obtain for Y, you should have
>> se? = sb? + se?' + 2r ? only possible for the usual model that assumes
>> se?' = se? if r = -sb?/2, which is a special case. Other correlations
>> between levels (r) will not lead to compound symmetry.
>>
>> (Hope my computations are correct).
>>
>> This suggests that the answer also depends on the way the model is
>> coded...
>>
>> Hope this helps and really corresponds to the question asked,
>>
>> Best regards,
>>
>> On Sat, Sep 23, 2017 at 07:26:53PM +0200, Maarten Jung wrote:
>> ? Thanks, this really helped me understand the models!
>> ?
>> ? There is one thing I still don't understand: I think that compound
>> symmetry
>> ? implies equal variances within the factor levels and equal
>> ? covariances/correlations between the levels. If there are equal
>> variances
>> ? within the factor levels and no correlations between the levels I
>> ? understand the equivalence of m1, m.zcp and m2.
>> ?
>> ? But what if there are correlations between the levels? you explained
>> that
>> ? m2 forces the correlation parameters to zero. But Douglas Bates states
>> that
>> ? the models are equivalent given compound symmetry (which I think doesn't
>> ? imply zero correlations).
>> ?
>> ? Just to double check: This m1 -> m.zcp -> m2 -> m.vio is a reasonable
>> model
>> ? reduction approach, right?
>> ?
>> ? 2017-09-23 13:51 GMT+02:00 Reinhold Kliegl <reinhold.kliegl at gmail.com>:
>> ?
>> ? > This should always be "k(k-1)/2" correlation parameters, of course.
>> ? >
>> ? > Also perhaps you may want to read this post to the list by Douglas
>> Bates:
>> ? > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html
>> ? >
>> ? > On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <
>> ? > reinhold.kliegl at gmail.com> wrote:
>> ? >
>> ? >> The models are on a continuum of complexity wrt to the random-effects
>> ? >> structure. Specifically:
>> ? >>
>> ? >> m1 estimates k variance components and k(k-1) correlation parameters
>> for
>> ? >> the k levels of factor f
>> ? >>
>> ? >> m2 estimates 1 variance component for the intercept and a 1 variance
>> ? >> component for the k-1 contrasts defined for the k levels of factor
>> f, that
>> ? >> it constrains the k-1 contrasts for factor f to the same value. The
>> ? >> correlation parameters are forced to zero.
>> ? >>
>> ? >> The continuum becomes transparent if one re-parameterizes m1 as a m1a
>> ? >> (see below) with 1 variance component for the intercept and k-1
>> variance
>> ? >> components for the k levels of factor f, and k(k-1) correlation
>> parameters.
>> ? >>  m1 and m1a have the same number of parameters and identical
>> deviance.
>> ? >>
>> ? >> m1a <- lmer(y ~ factor + (factor|group))
>> ? >>
>> ? >> There is an additional model specification on this continuum between
>> m1
>> ? >> and m2.  If contrasts are converted to numeric covariates, one can
>> force
>> ? >> correlation parameters to zero, but estimate different variance
>> components
>> ? >> for the k-1 contrasts of factor f. We call this the zero-correlation
>> ? >> parameter model.
>> ? >>
>> ? >> cB_A <- model.matrix(m1)[,2]
>> ? >> cC_A <- model.matrix(m1)[,3]
>> ? >>
>> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
>> ? >>  data=Machines, REML=FALSE)
>> ? >> print(summary(m.zcp), corr=FALSE)
>> ? >>
>> ? >> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
>> ? >> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
>> ? >>  data=Machines, REML=FALSE)
>> ? >> print(summary(m.zcp), corr=FALSE)
>> ? >>
>> ? >> Of course, there is also a simpler model than m2 - the
>> ? >> varying-intercept-only model:
>> ? >>
>> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
>> ? >> REML=FALSE)
>> ? >> print(summary(m.zcp), corr=FALSE)
>> ? >>
>> ? >> Here is some R code demonstrating all this for the Machines data.
>> ? >>
>> ? >> ####
>> ? >> library(lme4)
>> ? >> #library(RePsychLing)
>> ? >>
>> ? >> data("Machines", package = "MEMSS")
>> ? >>
>> ? >> # OP m1
>> ? >> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker),
>> data=Machines,
>> ? >> REML=FALSE)
>> ? >> print(summary(m1), corr=FALSE)
>> ? >>
>> ? >> # re-parameterization of m1
>> ? >> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker),
>> data=Machines,
>> ? >> REML=FALSE)
>> ? >> print(summary(m1a), corr=FALSE)
>> ? >>
>> ? >> # alternative specification of m1a
>> ? >> cB_A <- model.matrix(m1)[,2]
>> ? >> cC_A <- model.matrix(m1)[,3]
>> ? >>
>> ? >> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
>> ? >>  data=Machines, REML=FALSE)
>> ? >> print(summary(m1b), corr=FALSE)
>> ? >>
>> ? >> anova(m1, m1a, m1b)
>> ? >>
>> ? >> # zero-correlation parameter LMM
>> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
>> ? >>  data=Machines, REML=FALSE)
>> ? >> print(summary(m.zcp), corr=FALSE)
>> ? >>
>> ? >> # OP m2
>> ? >> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
>> ? >> data=Machines, REML=FALSE)
>> ? >> print(summary(m2), corr=FALSE)
>> ? >>
>> ? >> # varying-intercept-only LMM
>> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
>> ? >> REML=FALSE)
>> ? >> print(summary(m.vio), corr=FALSE)
>> ? >>
>> ? >> anova(m1, m.zcp, m2, m.vio)
>> ? >>
>> ? >> sessionInfo()
>> ? >> ####
>> ? >>
>> ? >> You may also want to look this RPub:
>> ? >> http://www.rpubs.com/Reinhold/22193
>> ? >>
>> ? >> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
>> ? >> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> ? >>
>> ? >>> Hello everyone,
>> ? >>>
>> ? >>> I have a question regarding the equivalence of the following models:
>> ? >>>
>> ? >>> m1 <- lmer(y ~ factor + (0 + factor|group))
>> ? >>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
>> ? >>>
>> ? >>> Douglas Bates states (slide 91 in this presentation [1])  that these
>> ? >>> models
>> ? >>> are equivalent in case of compound symmetry.
>> ? >>>
>> ? >>> 1. I realized that I don't really understand the random slope by
>> factor
>> ? >>> model (m1) and espacially why it reduces to m2 given compound
>> symmetry.
>> ? >>> Also, why is there no random intercept in m1?
>> ? >>> Can anyone explain the difference between the models and how m1
>> reduces
>> ? >>> to
>> ? >>> m2 in an intuitive way.
>> ? >>>
>> ? >>> 2. If m1 is a special case of m2 ? this could be an interesting
>> option
>> ? >>> for
>> ? >>> model reduction but I?ve never seen something like m2 in papers.
>> Instead
>> ? >>> they suggest dropping the random slope and thus the interaction
>> ? >>> completely
>> ? >>> (e.g. Matuschek et al. 2017 [3]).
>> ? >>> What do you think about it?
>> ? >>>
>> ? >>> Please note that I asked the question on Stack Exchange [2] but some
>> ? >>> consider it as off-topic. So, I hope one of you can help me out.
>> ? >>>
>> ? >>>
>> ? >>> Best regards,
>> ? >>> Maarten
>> ? >>>
>> ? >>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
>> ? >>> [2] https://stats.stackexchange.com/q/304374/136579
>> ? >>> [3] https://doi.org/10.1016/j.jml.2017.01.001
>> ? >>>
>> ? >>>         [[alternative HTML version deleted]]
>> ? >>>
>> ? >>> _______________________________________________
>> ? >>> R-sig-mixed-models at r-project.org mailing list
>> ? >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> ? >>
>> ? >>
>> ? >>
>> ? >
>> ?
>> ?       [[alternative HTML version deleted]]
>> ?
>> ? _______________________________________________
>> ? R-sig-mixed-models at r-project.org mailing list
>> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>>                                 Emmanuel CURIS
>>                                 emmanuel.curis at parisdescartes.fr
>>
>> Page WWW: http://emmanuel.curis.online.fr/index.html
>>
>
>

	[[alternative HTML version deleted]]


From udube at wustl.edu  Thu Sep 28 16:58:12 2017
From: udube at wustl.edu (Dube, Umber)
Date: Thu, 28 Sep 2017 14:58:12 +0000
Subject: [R-sig-ME] Questions about design and convergence warnings
Message-ID: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>

Thanks for your continued development of lme4 and all the support you've provided.

This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.

I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).

I have been modelling the following as fixed effects:
RNA Integrity Number (RIN) - quality of the total RNA extracted from each tissues (continuous)
Post-mortem Interval (PMI) - how much time elapsed following death until the tissue was frozen (continuous)
Sex - genetic sex of the organ (categorical)
Age at death (AOD) - age of organ at death (continuous)
Species - species of organ (categorical)
Gene -  normalized count data of gene expression (continuous)

I have been modelling the following as random effects:
Batch (categorical)

I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).

Altogether, my model is:

glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue + (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(), control=glmerControl(optCtrl=list(maxfun=1e9) ) )

I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

To address this:

1) I've centered and scaled my continous predictors

2) I've checked for singularity #False

3) I've printed and compared with internal calculations

4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.


> ss$ fixef ## extract fixed effects
        (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802


> ss$ llik ## log-likelihoods
        bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
        -327.896        -327.896        -327.896        -327.896        -327.933        -327.933

> ss$ sdcor ## SDs and correlations
                Organ:Tissue.(Intercept)        batch.(Intercept)
        bobyqa  3.68E-05        0.520826
        Nelder_Mead     5.56E-03        0.52084
        nlminbw 3.10E-08        0.520826
        optimx.L-BFGS-B 0.00E+00        0.52084
        nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
        nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555



> ss$ theta ## Cholesky factors
                Organ:Tissue.(Intercept)        batch.(Intercept)
        bobyqa  3.68E-05        0.520826
        Nelder_Mead     5.56E-03        0.52084
        nlminbw 3.10E-08        0.520826
        optimx.L-BFGS-B 0.00E+00        0.52084
        nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
        nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555


> ss$ which.OK ## which fits worked
        bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
        TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE


I would appreciate comment on my design, convergence warnings, and troubleshooting results.

Thanks,

Umber


	[[alternative HTML version deleted]]


From Zhengyang.Zhou at UTSouthwestern.edu  Thu Sep 28 22:15:21 2017
From: Zhengyang.Zhou at UTSouthwestern.edu (Zhengyang Zhou)
Date: Thu, 28 Sep 2017 20:15:21 +0000
Subject: [R-sig-ME] How to specify user-defined matrix Z?
Message-ID: <1506629721473.18753@UTSouthwestern.edu>

?Hi all,


In genetic studies, we sometimes include the genetic relatedness matrix as a variance component, so we have this following model:
Y~Xbeta+Zb+error,

where beta are the fixed effects, b~N(0,sigma^2*I) are the random effects, error are the random error, Z is the cholesky decomposition of the known genetic relatedness matrix. So how to use lme4 to fit this model if we know X and Z beforehand? I can use the package "nlme" to do it using the code like

lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
but how to do it using lme4?

(It's my first time to submit a post, and please let me know if I made anything wrong/inproper.)


Thank you.
Zhengyang


________________________________

UT Southwestern


Medical Center



The future of medicine, today.


	[[alternative HTML version deleted]]


From R.E.Crump at warwick.ac.uk  Fri Sep 29 12:28:18 2017
From: R.E.Crump at warwick.ac.uk (Crump, Ron)
Date: Fri, 29 Sep 2017 10:28:18 +0000
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
Message-ID: <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>

Hi Zhengyang,

> In genetic studies, we sometimes include the genetic relatedness matrix as a variance component, so we have this following model:
> Y~Xbeta+Zb+error,
> 
> where beta are the fixed effects, b~N(0,sigma^2*I) are the random effects, error are the random error, Z is the cholesky decomposition of the known genetic relatedness matrix. So how to use lme4 to fit this model if we know X and Z beforehand? I can use the package "nlme" to do it using the code like
> 
> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
> but how to do it using lme4?

I think, assuming you are using I to indicate an identity matrix, that
in neither case are you specifying a genetic relationship matrix, unless 
you are somehow incorporating it into Z (in which case I'd like to see how).

I don't believe that either lme4 or nlme will allow you to do what you
want. (Somebody might correct me on this).

Within R you could certainly use MCMCglmm or INLA to do analysis of
quantitative genetics data to obtain genetic parameters (or the asremlr
interface to ASREML). I've not used it, but the pedigreemm package also
looks like it would help you and there may be others. Outside of R,
Karin Meyer's wombat program will also do the job.


Regards,
Ron.

From thierry.onkelinx at inbo.be  Fri Sep 29 13:34:32 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 29 Sep 2017 13:34:32 +0200
Subject: [R-sig-ME] Questions about design and convergence warnings
In-Reply-To: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
References: <MWHPR0201MB3513B4790A2D7A1B70BFF57CAA790@MWHPR0201MB3513.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5xV63y53dGOKtkOMTXdX7ghtX6LrVW1qe-a544tg_m6uA@mail.gmail.com>

Dear Umber,

Can you clarify what a tissue is? Distinct parts of an organ (tissue 1
for organ 1 refers to the same part as tissue 1 for organ 2)? Or
merely different samples for the same organ (no link between tissue 1
between organs). Tissue as random effect is only relevant in the first
case. In the latter case is depends on the number of replicates per
tissue:organ. In case of one replication go for (1|Organ), in case of
multiple replications go for (1|Organ/Tissue).

It looks like you have very strong species effects. That is an
indication for quasi-complete separation, which can trigger
convergence warnings.

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-28 16:58 GMT+02:00 Dube, Umber <udube at wustl.edu>:
> Thanks for your continued development of lme4 and all the support you've provided.
>
> This is my first mixed model analysis. I've done my best to read over the past messages and think I've found a proper method for performing it, but I would like to verify that is correct.
>
> I'm interested in performing a generalized linear mixed model analysis on RNA-sequencing data from different tissues derived from the same organ (I have 4 different tissues from ~160 diseased organs, ~60 healthy organs).
>
> I have been modelling the following as fixed effects:
> RNA Integrity Number (RIN) - quality of the total RNA extracted from each tissues (continuous)
> Post-mortem Interval (PMI) - how much time elapsed following death until the tissue was frozen (continuous)
> Sex - genetic sex of the organ (categorical)
> Age at death (AOD) - age of organ at death (continuous)
> Species - species of organ (categorical)
> Gene -  normalized count data of gene expression (continuous)
>
> I have been modelling the following as random effects:
> Batch (categorical)
>
> I understand that I have a nested model Organ/Tissue, but after reading (https://stackoverflow.com/questions/19414336/using-glmer-for-nested-data), I modeled tissue as a fixed effect due to the small numbers (4 tissues).
>
> Altogether, my model is:
>
> glmer(Disease ~ RIN + SEX + AOD + PMI + Species + (1|batch) + Tissue + (1|Tissue:Organ) + Gene, data=NormDEGenes, family=binomial(), control=glmerControl(optCtrl=list(maxfun=1e9) ) )
>
> I unfortunately get convergence warnings with these models, but after going through the ?convergence documentation I hope they are false positives.
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>
> To address this:
>
> 1) I've centered and scaled my continous predictors
>
> 2) I've checked for singularity #False
>
> 3) I've printed and compared with internal calculations
>
> 4) I've tried all available optimizers. I believe all of them have failed to converge, but they all end up with approximately the same log-liklihoods.
>
>
>> ss$ fixef ## extract fixed effects
>         (Intercept)     RIN_scale       SEXF    AOD_scale       PMI_scale       Species1        Species2        Species3        Tissue1 Tissue2 Tissue3 Gene
> bobyqa  0.11463   -0.41005      0.409846        -0.07834        -0.65198        14.79972        13.30085        14.88501        -0.35383        -0.31039        0.666657        -2.42662
> Nelder_Mead     -0.10894        -0.41005        0.40988 -0.07834        -0.652  15.02298        13.52411        15.10837        -0.35371        -0.31033        0.666808        -2.42659
> nlminbw 0.067   -0.41005        0.409846        -0.07834        -0.65198        14.84728        13.34841        14.93257        -0.35383        -0.3104 0.666653        -2.4266
> optimx.L-BFGS-B 0.066515        -0.40992        0.40951 -0.07822        -0.65189        14.84686        13.34846        14.93227        -0.35369        -0.3102 0.666332        -2.42644
> nloptwrap.NLOPT_LN_NELDERMEAD   -0.19423        -0.40082        0.401142        -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
> nloptwrap.NLOPT_LN_BOBYQA       -0.19423        -0.40082         0.401142       -0.07745        -0.63582        14.74898        13.28662        14.83122        -0.3464 -0.30534        0.646181        -2.36802
>
>
>> ss$ llik ## log-likelihoods
>         bobyqa  Nelder_Mead     nlminbw optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD   nloptwrap.NLOPT_LN_BOBYQA
>         -327.896        -327.896        -327.896        -327.896        -327.933        -327.933
>
>> ss$ sdcor ## SDs and correlations
>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>         bobyqa  3.68E-05        0.520826
>         Nelder_Mead     5.56E-03        0.52084
>         nlminbw 3.10E-08        0.520826
>         optimx.L-BFGS-B 0.00E+00        0.52084
>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08         0.517555
>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>
>
>
>> ss$ theta ## Cholesky factors
>                 Organ:Tissue.(Intercept)        batch.(Intercept)
>         bobyqa  3.68E-05        0.520826
>         Nelder_Mead     5.56E-03        0.52084
>         nlminbw 3.10E-08        0.520826
>         optimx.L-BFGS-B 0.00E+00        0.52084
>         nloptwrap.NLOPT_LN_NELDERMEAD   4.56E-08        0.517555
>         nloptwrap.NLOPT_LN_BOBYQA       4.56E-08        0.517555
>
>
>> ss$ which.OK ## which fits worked
>         bobyqa   Nelder_Mead     nlminbw        nmkbw   optimx.L-BFGS-B  nloptwrap.NLOPT_LN_NELDERMEAD  nloptwrap.NLOPT_LN_BOBYQA
>         TRUE    TRUE    TRUE    FALSE   TRUE    TRUE    TRUE
>
>
> I would appreciate comment on my design, convergence warnings, and troubleshooting results.
>
> Thanks,
>
> Umber
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jacoba at control.lth.se  Fri Sep 29 13:39:48 2017
From: jacoba at control.lth.se (Jacob Bergstedt)
Date: Fri, 29 Sep 2017 13:39:48 +0200
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
Message-ID: <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>

Hi,

You can use the lmekin function in the coxme package.

Best regards,

Jacob


On 2017-09-29 12:28, Crump, Ron wrote:
> Hi Zhengyang,
>
>> In genetic studies, we sometimes include the genetic relatedness matrix as a variance component, so we have this following model:
>> Y~Xbeta+Zb+error,
>>
>> where beta are the fixed effects, b~N(0,sigma^2*I) are the random effects, error are the random error, Z is the cholesky decomposition of the known genetic relatedness matrix. So how to use lme4 to fit this model if we know X and Z beforehand? I can use the package "nlme" to do it using the code like
>>
>> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
>> but how to do it using lme4?
> I think, assuming you are using I to indicate an identity matrix, that
> in neither case are you specifying a genetic relationship matrix, unless
> you are somehow incorporating it into Z (in which case I'd like to see how).
>
> I don't believe that either lme4 or nlme will allow you to do what you
> want. (Somebody might correct me on this).
>
> Within R you could certainly use MCMCglmm or INLA to do analysis of
> quantitative genetics data to obtain genetic parameters (or the asremlr
> interface to ASREML). I've not used it, but the pedigreemm package also
> looks like it would help you and there may be others. Outside of R,
> Karin Meyer's wombat program will also do the job.
>
>
> Regards,
> Ron.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ricardo.duran.reyes at arauco.cl  Fri Sep 29 18:52:39 2017
From: ricardo.duran.reyes at arauco.cl (Ricardo Francisco Duran Reyes)
Date: Fri, 29 Sep 2017 16:52:39 +0000
Subject: [R-sig-ME] Linear mixed model in lme4
Message-ID: <DM5PR11MB156300A4B73E77FB13A1A246A47E0@DM5PR11MB1563.namprd11.prod.outlook.com>

Dear all,
I am a forestry researcher from Chile and I want to use the Lme4 packages for fitting a linear mixed model according this equation:
 Y=mu+Female+Male+FemxMale+Clone+e
 Where some trees are clones with know family and other are clones with unknow parents, others are family data with both parents know and other are family data with just one parent know.
 Is lme4 capable for doing this analysis?
 An example of how data looks is here:
 Family

Female

Male

Clone

Type of data

AH

FA7

FV7

AH714

Clonal data

AH

FA7

FV7



Full sib progeny

LB

FA7

Unknown

LB315

Clonal data (one parent known)

Unknown

Unknown

Unknown

BA465

Clonal data (unknown family)

BT

FA21

FV50



Full sib progeny

BA

G184

Unknown



OP progeny


I would appreciate any help

Best regards,

Ricardo Dur?n


	[[alternative HTML version deleted]]


From Zhengyang.Zhou at UTSouthwestern.edu  Fri Sep 29 21:48:22 2017
From: Zhengyang.Zhou at UTSouthwestern.edu (Zhengyang Zhou)
Date: Fri, 29 Sep 2017 19:48:22 +0000
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>,
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
Message-ID: <1506714501011.47966@UTSouthwestern.edu>

Hi Ron,

Thank you for your reply. nlme can fit the model using:

group=rep(1,n)
fit_full = try(lme(y~-1+X, random=list(group=pdIdent(~-1+Z))))

I think it takes the Z to be the matrix of the random effects, and the group level is 1 for all observations. But I don't know how it works exactly.

I need to use lme4 because I want to test for the fixed effects (ie., beta), and the packages which can do it (eg, pbkrtest) is based on lme4.

Sincerely,
Zhengyang
________________________________________
From: Crump, Ron <R.E.Crump at warwick.ac.uk>
Sent: Friday, September 29, 2017 5:28 AM
To: r-sig-mixed-models at r-project.org; Zhengyang Zhou
Subject: Re: How to specify user-defined matrix Z?

Hi Zhengyang,

> In genetic studies, we sometimes include the genetic relatedness matrix as a variance component, so we have this following model:
> Y~Xbeta+Zb+error,
>
> where beta are the fixed effects, b~N(0,sigma^2*I) are the random effects, error are the random error, Z is the cholesky decomposition of the known genetic relatedness matrix. So how to use lme4 to fit this model if we know X and Z beforehand? I can use the package "nlme" to do it using the code like
>
> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
> but how to do it using lme4?

I think, assuming you are using I to indicate an identity matrix, that
in neither case are you specifying a genetic relationship matrix, unless
you are somehow incorporating it into Z (in which case I'd like to see how).

I don't believe that either lme4 or nlme will allow you to do what you
want. (Somebody might correct me on this).

Within R you could certainly use MCMCglmm or INLA to do analysis of
quantitative genetics data to obtain genetic parameters (or the asremlr
interface to ASREML). I've not used it, but the pedigreemm package also
looks like it would help you and there may be others. Outside of R,
Karin Meyer's wombat program will also do the job.


Regards,
Ron.

________________________________

UT Southwestern


Medical Center



The future of medicine, today.


From Zhengyang.Zhou at UTSouthwestern.edu  Fri Sep 29 21:51:54 2017
From: Zhengyang.Zhou at UTSouthwestern.edu (Zhengyang Zhou)
Date: Fri, 29 Sep 2017 19:51:54 +0000
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>,
 <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>
Message-ID: <1506714713397.37325@UTSouthwestern.edu>

Hi Jacob,

Thank you for your reply. I need to use lme4 because I want to test for the fixed effects (ie., beta), and the packages which can do it (eg, pbkrtest) is based on lme4.

Sincerely,
Zhengyang
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jacob Bergstedt <jacoba at control.lth.se>
Sent: Friday, September 29, 2017 6:39 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to specify user-defined matrix Z?

Hi,

You can use the lmekin function in the coxme package.

Best regards,

Jacob


On 2017-09-29 12:28, Crump, Ron wrote:
> Hi Zhengyang,
>
>> In genetic studies, we sometimes include the genetic relatedness matrix as a variance component, so we have this following model:
>> Y~Xbeta+Zb+error,
>>
>> where beta are the fixed effects, b~N(0,sigma^2*I) are the random effects, error are the random error, Z is the cholesky decomposition of the known genetic relatedness matrix. So how to use lme4 to fit this model if we know X and Z beforehand? I can use the package "nlme" to do it using the code like
>>
>> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
>> but how to do it using lme4?
> I think, assuming you are using I to indicate an identity matrix, that
> in neither case are you specifying a genetic relationship matrix, unless
> you are somehow incorporating it into Z (in which case I'd like to see how).
>
> I don't believe that either lme4 or nlme will allow you to do what you
> want. (Somebody might correct me on this).
>
> Within R you could certainly use MCMCglmm or INLA to do analysis of
> quantitative genetics data to obtain genetic parameters (or the asremlr
> interface to ASREML). I've not used it, but the pedigreemm package also
> looks like it would help you and there may be others. Outside of R,
> Karin Meyer's wombat program will also do the job.
>
>
> Regards,
> Ron.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

________________________________

UT Southwestern


Medical Center



The future of medicine, today.


From diogro at gmail.com  Sat Sep 30 18:27:19 2017
From: diogro at gmail.com (Diogo Melo)
Date: Sat, 30 Sep 2017 13:27:19 -0300
Subject: [R-sig-ME] How to specify user-defined matrix Z?
In-Reply-To: <1506714713397.37325@UTSouthwestern.edu>
References: <mailman.9.1506679201.34390.r-sig-mixed-models@r-project.org>
 <a06aed92-6ce6-b9d6-6f23-c3a1ccf3b084@warwick.ac.uk>
 <8ef01ac9-639a-e003-b668-214e986902f6@control.lth.se>
 <1506714713397.37325@UTSouthwestern.edu>
Message-ID: <CALKSUOkcsaMGx2Xc0A08M3THg-f+CHqxxLDO050CN7gwwYic_Q@mail.gmail.com>

I'm pretty sure lme4qtl can handle this:

https://www.biorxiv.org/content/early/2017/05/18/139816.1
https://github.com/variani/lme4qtl

Cheers,
Diogo

On Fri, Sep 29, 2017 at 4:51 PM, Zhengyang Zhou <
Zhengyang.Zhou at utsouthwestern.edu> wrote:

> Hi Jacob,
>
> Thank you for your reply. I need to use lme4 because I want to test for
> the fixed effects (ie., beta), and the packages which can do it (eg,
> pbkrtest) is based on lme4.
>
> Sincerely,
> Zhengyang
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Jacob Bergstedt <jacoba at control.lth.se>
> Sent: Friday, September 29, 2017 6:39 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to specify user-defined matrix Z?
>
> Hi,
>
> You can use the lmekin function in the coxme package.
>
> Best regards,
>
> Jacob
>
>
> On 2017-09-29 12:28, Crump, Ron wrote:
> > Hi Zhengyang,
> >
> >> In genetic studies, we sometimes include the genetic relatedness matrix
> as a variance component, so we have this following model:
> >> Y~Xbeta+Zb+error,
> >>
> >> where beta are the fixed effects, b~N(0,sigma^2*I) are the random
> effects, error are the random error, Z is the cholesky decomposition of the
> known genetic relatedness matrix. So how to use lme4 to fit this model if
> we know X and Z beforehand? I can use the package "nlme" to do it using the
> code like
> >>
> >> lme(y~-1+X, random=list(group=pdIdent(~-1+Z))),
> >> but how to do it using lme4?
> > I think, assuming you are using I to indicate an identity matrix, that
> > in neither case are you specifying a genetic relationship matrix, unless
> > you are somehow incorporating it into Z (in which case I'd like to see
> how).
> >
> > I don't believe that either lme4 or nlme will allow you to do what you
> > want. (Somebody might correct me on this).
> >
> > Within R you could certainly use MCMCglmm or INLA to do analysis of
> > quantitative genetics data to obtain genetic parameters (or the asremlr
> > interface to ASREML). I've not used it, but the pedigreemm package also
> > looks like it would help you and there may be others. Outside of R,
> > Karin Meyer's wombat program will also do the job.
> >
> >
> > Regards,
> > Ron.
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ________________________________
>
> UT Southwestern
>
>
> Medical Center
>
>
>
> The future of medicine, today.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Sat Sep 30 19:32:14 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Sat, 30 Sep 2017 19:32:14 +0200
Subject: [R-sig-ME] Equivalence of (0 + factor|group) and (1|group) +
 (1|group:factor) random effect specifications in case of compound symmetry
In-Reply-To: <CAHr4Dyc1zW-hR2T2h_vyX=mavav=4WEkGNHPn6Y2eq0HgtkgdA@mail.gmail.com>
References: <CAHr4Dyc9awDVdDeQr=uRqemN5hysncNG-G_jPF1BayVkCr_0jQ@mail.gmail.com>
 <CAG+WrEx_jmPBwT5OPRnig-34j=NytgwG6j2Q1nNqnDY2LaJk-g@mail.gmail.com>
 <CAG+WrEzSbYiHM4F0dcDkJzBpc9jpO1PavqTU4Jmf6ROrTsWspg@mail.gmail.com>
 <CAHr4Dyct_9RrNHwJ-1mkBD8AqJBxLiV0W96Ys3U+s_+YBkB7Bg@mail.gmail.com>
 <20170925081541.GC11898@info124.pharmacie.univ-paris5.fr>
 <CAHr4DycK6ynqnVWQi9+Wx-u=Sx+KyanwRo51oY2HsZ-BQ1tQ5A@mail.gmail.com>
 <CAHr4Dyc1zW-hR2T2h_vyX=mavav=4WEkGNHPn6Y2eq0HgtkgdA@mail.gmail.com>
Message-ID: <20170930173214.GA10048@info124.pharmacie.univ-paris5.fr>

Let's continue with the example given in the previous computation,
that is a 2-levels factor and the very simple case of one observation
for each of these levels for each patient (groupe). And let consider a
single group, since anyways each groups are assumed independents and
having the same random effects distribution, so the result of having
more patients will be a block-diagonal matrix, each block being the
one computed here.

I'm not completely sure of the design matrix constructed by lme4, but
let's try...

Let be Y = X Z + epsilon, with X the design matrix for the random
effects and Z the random effects themselves.

Sigma(Y) = X Sigma( Z ) tX + Sigma( epsilon )
         = SigmaRE + Sigma( epsilon )

and I assume SigmaRE is what is investigated here as the "random
effects covariance matrix".

Model m1: Y ~ fixed part + (0 + factor | group)

  => there is two random effects for each group, one for each level of
     factor

  => Sigma( Z ) = (   sa?     r sa sb )
     	      	  ( r sa sb     sb?   )

     X = ( 1 0 )  tX = X = I  hence SigmaRE = Sigma( Z )
         ( 0 1 )

Model m2: Y ~ fixed part + (1|group) + (1|group:factor)

    the (1|group) term gives a single random effect of variance sg?,
    and the design matrix is X = t(1 1) because it takes the same
    value for all observations in the group
 
  => it contributes to SigmaRE by a matrix ( sg? sg? )
                                           ( sg? sg? )

    the (1|group:factor) gives a single random effect of variance sf?,
    but that this time takes a different value according to the value
    taken by factor in the observations of the group, and these values
    are independent, so in our special example, it is equivalent to a
    two-dimensional random effect of covariance matrix

    SigmaGF = ( sf? 0  )   and design matrix X' = ( 1 0 )
              ( 0  sf? )                          ( 0 1 )

   so we have X SigmaGF tX = SigmaGF and finally 

   SigmaRE = ( sg? + sf?   sg?       )
             ( sg?         sg? + sf? )

   which is of compound symmetry ? whereas in the first model, m1, we
   had

   SigmaRE = ( sa?        r sa sb )
             ( r sa sb    sb?     )

   which is the more general form you can imagine.

   To have the two matrices equal, you must assume that 1) sb? = sa?
   and 2) 0 <= r < 1 [and then sg? = r sa?, sf? = sa? (1 - r)].

   Since this is a special case of the model 1, you can suppose these
   are nested models. But since for r it does not impose a specific
   value, only an interval which is a subset of all possible values,
   I'm not sure the definition of "nested models" rigorously holds,
   neither that the asymptotic law is still a khi-square.

Hope this helps, and that people more familiar with nested models
theory will comment on the last point.

On Thu, Sep 28, 2017 at 04:33:41PM +0200, Maarten Jung wrote:
? @ Emmanuel Curis Douglas Bates' statement is about the "variance-covariance
? matrix for the vector-valued random effects" (slide 91) not about the
? covariance matrix of the observations.
? 
? 2017-09-25 21:38 GMT+02:00 Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
? :
? 
? > Thanks for the very nice explanation of compound symmetry in your
? > examples.
? > I understand the continuum of complexity wrt to the random-effects
? > structure explained by Reinhold Kliegl, also.
? > But I still don't see the link between m1 and m2 in case of compound
? > symmetry - sorry for that!
? > Analogous to this post http://www.rpubs.com/Reinhold/22193 mod2 should
? > constrain the group-related effects to equality. What exactly does this
? > have to do with compound symmetry?
? >
? > 2017-09-25 10:15 GMT+02:00 Emmanuel Curis <emmanuel.curis at parisdescartes
? > .fr>:
? >
? >> Hello,
? >>
? >> I'm not sure if I understand correctly, but I think the "compound
? >> symmetry" mention usually applies to the covariance matrix of the
? >> observations, Y, in a given cluster.
? >>
? >> In that case, and omiting the fixed part of the model that does not
? >> change the Y covariance matrix, we have
? >>
? >>  Y = fixed effects + X U + epsilon
? >>
? >> with U the random effect(s), X the design matrix for it, and epsilon
? >> the residual error.
? >>
? >> Hence, assuming random effect and epsilon independant
? >>
? >> Sigma(Y) = tX Sigma( U ) X + Sigma( epsilon)
? >>
? >> so Sigma(Y) will have compound symmetry as soon as both X Sigma(U) tX
? >> and Sigma( epsilon ) have themselves compound symmetry ? or if they
? >> have structure that kind of "compensate" themselve. So basically, that
? >> does not preclude from having correlations between levels of a fixed
? >> effect factor.
? >>
? >> However, let consider a scholar case with two observations on the same
? >> patient [cluster] that takes or not its treatment [fixed effect], with
? >> a different random effect for both cases, and let consider two ways of
? >> writing it.
? >>
? >> Let Sigma(epsilon) = ( se? rse   ), Sigma(U) = ( sa? r   )
? >>                      ( rse  se?' )             ( r   sb? )
? >>
? >> (typically, rse = 0, se? = se?')
? >>
? >> 1) Let be U1 the random effect for patient without treatment and U2
? >>    therandom effect for the same patient with treatment, so
? >>
? >> X = ( 1 0 ) = identity.
? >>     ( 0 1 )
? >>
? >> In that case, X Sigma(U) tX = Sigma(U) so
? >>
? >> Sigma(Y) = ( sa? + se?     r + rse  )
? >>            (  r  + rse   sb? + se?' )
? >>
? >> and you have compound symmetry if sa? + se? = sb? + se?', that is in
? >> the classical case of se? = se?', assuming equal variances for both
? >> the two random effects. But there is no condition on r: you can have
? >> any correlation between the levels and still have compound symmetry.
? >>
? >> 2) U1 for patient i and U2 for effect of treatment in patient i.
? >>
? >> So X = ( 1 0 ), tX = ( 1 1 )
? >>        ( 1 1 )       ( 0 1 )
? >>
? >> Then Sigma(Y) = ( sa? + se?        sa? + r + rse         )
? >>                 ( sa? + r + rse    sa? + sb? + 2r + se?' )
? >>
? >> and compound symmetry is much harder to obtain for Y, you should have
? >> se? = sb? + se?' + 2r ? only possible for the usual model that assumes
? >> se?' = se? if r = -sb?/2, which is a special case. Other correlations
? >> between levels (r) will not lead to compound symmetry.
? >>
? >> (Hope my computations are correct).
? >>
? >> This suggests that the answer also depends on the way the model is
? >> coded...
? >>
? >> Hope this helps and really corresponds to the question asked,
? >>
? >> Best regards,
? >>
? >> On Sat, Sep 23, 2017 at 07:26:53PM +0200, Maarten Jung wrote:
? >> ? Thanks, this really helped me understand the models!
? >> ?
? >> ? There is one thing I still don't understand: I think that compound
? >> symmetry
? >> ? implies equal variances within the factor levels and equal
? >> ? covariances/correlations between the levels. If there are equal
? >> variances
? >> ? within the factor levels and no correlations between the levels I
? >> ? understand the equivalence of m1, m.zcp and m2.
? >> ?
? >> ? But what if there are correlations between the levels? you explained
? >> that
? >> ? m2 forces the correlation parameters to zero. But Douglas Bates states
? >> that
? >> ? the models are equivalent given compound symmetry (which I think doesn't
? >> ? imply zero correlations).
? >> ?
? >> ? Just to double check: This m1 -> m.zcp -> m2 -> m.vio is a reasonable
? >> model
? >> ? reduction approach, right?
? >> ?
? >> ? 2017-09-23 13:51 GMT+02:00 Reinhold Kliegl <reinhold.kliegl at gmail.com>:
? >> ?
? >> ? > This should always be "k(k-1)/2" correlation parameters, of course.
? >> ? >
? >> ? > Also perhaps you may want to read this post to the list by Douglas
? >> Bates:
? >> ? > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001736.html
? >> ? >
? >> ? > On Sat, Sep 23, 2017 at 1:41 PM, Reinhold Kliegl <
? >> ? > reinhold.kliegl at gmail.com> wrote:
? >> ? >
? >> ? >> The models are on a continuum of complexity wrt to the random-effects
? >> ? >> structure. Specifically:
? >> ? >>
? >> ? >> m1 estimates k variance components and k(k-1) correlation parameters
? >> for
? >> ? >> the k levels of factor f
? >> ? >>
? >> ? >> m2 estimates 1 variance component for the intercept and a 1 variance
? >> ? >> component for the k-1 contrasts defined for the k levels of factor
? >> f, that
? >> ? >> it constrains the k-1 contrasts for factor f to the same value. The
? >> ? >> correlation parameters are forced to zero.
? >> ? >>
? >> ? >> The continuum becomes transparent if one re-parameterizes m1 as a m1a
? >> ? >> (see below) with 1 variance component for the intercept and k-1
? >> variance
? >> ? >> components for the k levels of factor f, and k(k-1) correlation
? >> parameters.
? >> ? >>  m1 and m1a have the same number of parameters and identical
? >> deviance.
? >> ? >>
? >> ? >> m1a <- lmer(y ~ factor + (factor|group))
? >> ? >>
? >> ? >> There is an additional model specification on this continuum between
? >> m1
? >> ? >> and m2.  If contrasts are converted to numeric covariates, one can
? >> force
? >> ? >> correlation parameters to zero, but estimate different variance
? >> components
? >> ? >> for the k-1 contrasts of factor f. We call this the zero-correlation
? >> ? >> parameter model.
? >> ? >>
? >> ? >> cB_A <- model.matrix(m1)[,2]
? >> ? >> cC_A <- model.matrix(m1)[,3]
? >> ? >>
? >> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  ||  Worker),
? >> ? >>  data=Machines, REML=FALSE)
? >> ? >> print(summary(m.zcp), corr=FALSE)
? >> ? >>
? >> ? >> Note that m.zcp without the double-bar is equivalent to m1 and m1b.
? >> ? >> m.1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  |  Worker),
? >> ? >>  data=Machines, REML=FALSE)
? >> ? >> print(summary(m.zcp), corr=FALSE)
? >> ? >>
? >> ? >> Of course, there is also a simpler model than m2 - the
? >> ? >> varying-intercept-only model:
? >> ? >>
? >> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker),  data=Machines,
? >> ? >> REML=FALSE)
? >> ? >> print(summary(m.zcp), corr=FALSE)
? >> ? >>
? >> ? >> Here is some R code demonstrating all this for the Machines data.
? >> ? >>
? >> ? >> ####
? >> ? >> library(lme4)
? >> ? >> #library(RePsychLing)
? >> ? >>
? >> ? >> data("Machines", package = "MEMSS")
? >> ? >>
? >> ? >> # OP m1
? >> ? >> m1 <- lmer(score ~ 1 + Machine + (0 + Machine | Worker),
? >> data=Machines,
? >> ? >> REML=FALSE)
? >> ? >> print(summary(m1), corr=FALSE)
? >> ? >>
? >> ? >> # re-parameterization of m1
? >> ? >> m1a <- lmer(score ~ 1 + Machine + (1 + Machine | Worker),
? >> data=Machines,
? >> ? >> REML=FALSE)
? >> ? >> print(summary(m1a), corr=FALSE)
? >> ? >>
? >> ? >> # alternative specification of m1a
? >> ? >> cB_A <- model.matrix(m1)[,2]
? >> ? >> cC_A <- model.matrix(m1)[,3]
? >> ? >>
? >> ? >> m1b <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  | Worker),
? >> ? >>  data=Machines, REML=FALSE)
? >> ? >> print(summary(m1b), corr=FALSE)
? >> ? >>
? >> ? >> anova(m1, m1a, m1b)
? >> ? >>
? >> ? >> # zero-correlation parameter LMM
? >> ? >> m.zcp <- lmer(score ~ 1 + Machine + (1 + cB_A + cC_A  || Worker),
? >> ? >>  data=Machines, REML=FALSE)
? >> ? >> print(summary(m.zcp), corr=FALSE)
? >> ? >>
? >> ? >> # OP m2
? >> ? >> m2 <- lmer(score ~ 1 + Machine + (1 | Worker) + (1 | Machine:Worker),
? >> ? >> data=Machines, REML=FALSE)
? >> ? >> print(summary(m2), corr=FALSE)
? >> ? >>
? >> ? >> # varying-intercept-only LMM
? >> ? >> m.vio <- lmer(score ~ 1 + Machine + (1 | Worker), data=Machines,
? >> ? >> REML=FALSE)
? >> ? >> print(summary(m.vio), corr=FALSE)
? >> ? >>
? >> ? >> anova(m1, m.zcp, m2, m.vio)
? >> ? >>
? >> ? >> sessionInfo()
? >> ? >> ####
? >> ? >>
? >> ? >> You may also want to look this RPub:
? >> ? >> http://www.rpubs.com/Reinhold/22193
? >> ? >>
? >> ? >> On Sat, Sep 23, 2017 at 11:43 AM, Maarten Jung <
? >> ? >> Maarten.Jung at mailbox.tu-dresden.de> wrote:
? >> ? >>
? >> ? >>> Hello everyone,
? >> ? >>>
? >> ? >>> I have a question regarding the equivalence of the following models:
? >> ? >>>
? >> ? >>> m1 <- lmer(y ~ factor + (0 + factor|group))
? >> ? >>> m2 <- lmer(y ~ factor + (1|group) + (1|group:factor))
? >> ? >>>
? >> ? >>> Douglas Bates states (slide 91 in this presentation [1])  that these
? >> ? >>> models
? >> ? >>> are equivalent in case of compound symmetry.
? >> ? >>>
? >> ? >>> 1. I realized that I don't really understand the random slope by
? >> factor
? >> ? >>> model (m1) and espacially why it reduces to m2 given compound
? >> symmetry.
? >> ? >>> Also, why is there no random intercept in m1?
? >> ? >>> Can anyone explain the difference between the models and how m1
? >> reduces
? >> ? >>> to
? >> ? >>> m2 in an intuitive way.
? >> ? >>>
? >> ? >>> 2. If m1 is a special case of m2 ? this could be an interesting
? >> option
? >> ? >>> for
? >> ? >>> model reduction but I?ve never seen something like m2 in papers.
? >> Instead
? >> ? >>> they suggest dropping the random slope and thus the interaction
? >> ? >>> completely
? >> ? >>> (e.g. Matuschek et al. 2017 [3]).
? >> ? >>> What do you think about it?
? >> ? >>>
? >> ? >>> Please note that I asked the question on Stack Exchange [2] but some
? >> ? >>> consider it as off-topic. So, I hope one of you can help me out.
? >> ? >>>
? >> ? >>>
? >> ? >>> Best regards,
? >> ? >>> Maarten
? >> ? >>>
? >> ? >>> [1] http://www.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf
? >> ? >>> [2] https://stats.stackexchange.com/q/304374/136579
? >> ? >>> [3] https://doi.org/10.1016/j.jml.2017.01.001
? >> ? >>>
? >> ? >>>         [[alternative HTML version deleted]]
? >> ? >>>
? >> ? >>> _______________________________________________
? >> ? >>> R-sig-mixed-models at r-project.org mailing list
? >> ? >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >> ? >>
? >> ? >>
? >> ? >>
? >> ? >
? >> ?
? >> ?       [[alternative HTML version deleted]]
? >> ?
? >> ? _______________________________________________
? >> ? R-sig-mixed-models at r-project.org mailing list
? >> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >>
? >> --
? >>                                 Emmanuel CURIS
? >>                                 emmanuel.curis at parisdescartes.fr
? >>
? >> Page WWW: http://emmanuel.curis.online.fr/index.html
? >>
? >
? >

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From andrea.p.drager at rice.edu  Sat Sep 30 02:28:51 2017
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Fri, 29 Sep 2017 19:28:51 -0500
Subject: [R-sig-ME] MCMCglmm error message: MME singular: use a stronger
	prior
Message-ID: <20170929192851.Horde.hlLEI2002RTnuQ2_SN4S0w4@webmail.rice.edu>


Hi All,

I've received the MCMCglmm error message: Mixed model equations  
singular: use a (stronger) prior

In general, I'm curious what prior this refers to if one is specifying  
priors for both fixed and random effects?


More specific to my case:

My model is has a binary response, two continuous fixed effects and  
two random effects. I have a dataset of individual tree measurements  
for 23 species, and the issue that has caused this error is that one  
of the fixed effects, Zabund, is fixed per species, so that each  
individual of a species has the same value for this.

Error in MCMCglmm(tally ~ Zabund + Zdbh + Znnd, random = ~phylo +  
code, family = "categorical",  :
   Mixed model equations singular: use a (stronger) prior

priorI = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V =  
1,nu = 0),
                                                          G2=list(V=1,nu=0)))

Thanks for any insight,


Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


