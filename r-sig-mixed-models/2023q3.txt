From bbo|ker @end|ng |rom gm@||@com  Mon Jul  3 21:49:40 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 3 Jul 2023 15:49:40 -0400
Subject: [R-sig-ME] GAMM- Missing/uncertain group id's in random effect
In-Reply-To: <YT4PR01MB98329EDC859766913B673AC5A32AA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
References: <YT4PR01MB98329EDC859766913B673AC5A32AA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <4b5dbdb2-ccbf-9571-df8f-8ccba09fd9d5@gmail.com>

    Unfortunately, I don't think there's an easy way to deal with this. 
You *could* build a fancy Bayesian engine that would try to 
estimate/impute uncertain boat IDs concurrently with the statistical 
analysis (I think people *may* have done this for IDing individual 
animals from camera trap or sighting data, but I don't remember).

   However, my recommendation would be to try to come up with some 
reasonable, objective heuristics for lumping IDs together.  Can you use 
information about co-occurrence of observations in space and time (or 
not) to come up with a set of rules?  (Basically, think about how you 
would try to pick out suspected duplicates by eye, then try to implement 
those rules in code.) For small, noisy data sets, if you can't make 
reasonable guesses about duplicates, it's unlikely that a computer will 
be able to do better.

  Misclassification in this way (either incorrectly lumping or 
splitting) might not make a huge difference to your results, as it will 
affect the correlation of observations, not the observed 
gear/effort/habitat/CPUE relationships directly ...

   good luck,
    Ben Bolker


On 2023-06-30 12:23 p.m., Meaghan Rupprecht wrote:
> I am currently modelling fish catch in the Amazon River in response to variables such as habitat, effort, gear type, and spatial locations. The model we have selected to accomplish this task is a GAMM, and we are currently using the mgcv and brms packages in R. We are facing an issue with random effects in our model, and I was hoping to get some insight about possible solutions. I've tried to find solutions online without much luck.
> 
> For each record of fish catch, there is information recorded such as boat name and boat length. We aimed at using this information to generate a unique boat id, which would be treated as a group id for a random effect variable in our model. A problem arises in boat names because they may not be unique, but boat lengths are somewhat unreliable information and could have varying responses. This creates some records where the boat names may be the same with slightly varying lengths, resulting in multiple id's being generated for what might actually be the same boat (i.e., boat 1 with length of 17m and boat 1 with length of 17.2m). This greatly complicates our attempts at identifying unique boats and generates uncertainty in our classifications.
> Is there a method for dealing with uncertainty or missing group id's in random effects? I'd be happy to elaborate or provide additional information if anything above was unclear.
> Thanks for your time.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Jul  4 00:23:31 2023
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Mon, 3 Jul 2023 23:23:31 +0100
Subject: [R-sig-ME] GAMM- Missing/uncertain group id's in random effect
In-Reply-To: <4b5dbdb2-ccbf-9571-df8f-8ccba09fd9d5@gmail.com>
References: <YT4PR01MB98329EDC859766913B673AC5A32AA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
 <4b5dbdb2-ccbf-9571-df8f-8ccba09fd9d5@gmail.com>
Message-ID: <475d0fa7-f666-c7ea-9b2e-8b08d6eac503@psyctc.org>

Formally, this is way, way above my IQ grade but I wonder if permuting 
across the possible matches would allow a sort of sensitivity/robustness 
exploration.? It sounds as if you there are correct boat IDs are unknown 
across a range of options.? Being very low IQ about this, say there are 
are 5 records with boat name "Sally" and they have a range of lengths 
say, 18m, 17m, 19m, 18m, 20m then I might write an algorithm to give me 
something like this:

run simID name length

1, Sally1, Sally, 18
1, Sally1, Sally, 17
1, Sally1, Sally, 19
1, Sally1, Sally, 18
1, Sally1, Sally, 20
2, Sally21, Sally, 18
2, Sally22, Sally, 17
2, Sally23, Sally, 19
2, Sally24, Sally, 18
2, Sally25, Sally, 20
3, Sally31, Sally, 18
3, Sally31, Sally, 17
3, Sally32, Sally, 19
3, Sally33, Sally, 18
3, Sally34, Sally, 20

...

Then I would look at the model results iterating over the run variable 
and using simID as the unique boat identifier.

Clearly if the combinations possible get very large there are all sorts 
of challenges but I wonder if there is literature on trying something 
like this?? My guess is that if this is combined with using some savvy 
of the sort Ben is suggesting then the numbers of possible ways of 
mapping the records to "pseudoBoats" might get fairly small and you 
might be able to show that the impacts on your findings would be small.

Mad or just perhaps possible?

Chris

P.S. I think this is the first time I've dared offer a suggestion here 
but I have learned an incredible amount from the list and am in awe of 
the skills _and_ the generosity of so many people who do answer things 
here: thanks.


On 03/07/2023 20:49, Ben Bolker wrote:
> ?? Unfortunately, I don't think there's an easy way to deal with this. 
> You *could* build a fancy Bayesian engine that would try to 
> estimate/impute uncertain boat IDs concurrently with the statistical 
> analysis (I think people *may* have done this for IDing individual 
> animals from camera trap or sighting data, but I don't remember).
>
> ? However, my recommendation would be to try to come up with some 
> reasonable, objective heuristics for lumping IDs together. Can you use 
> information about co-occurrence of observations in space and time (or 
> not) to come up with a set of rules? (Basically, think about how you 
> would try to pick out suspected duplicates by eye, then try to 
> implement those rules in code.) For small, noisy data sets, if you 
> can't make reasonable guesses about duplicates, it's unlikely that a 
> computer will be able to do better.
>
> ?Misclassification in this way (either incorrectly lumping or 
> splitting) might not make a huge difference to your results, as it 
> will affect the correlation of observations, not the observed 
> gear/effort/habitat/CPUE relationships directly ...
>
> ? good luck,
> ?? Ben Bolker
>
>
> On 2023-06-30 12:23 p.m., Meaghan Rupprecht wrote:
>> I am currently modelling fish catch in the Amazon River in response 
>> to variables such as habitat, effort, gear type, and spatial 
>> locations. The model we have selected to accomplish this task is a 
>> GAMM, and we are currently using the mgcv and brms packages in R. We 
>> are facing an issue with random effects in our model, and I was 
>> hoping to get some insight about possible solutions. I've tried to 
>> find solutions online without much luck.
>>
>> For each record of fish catch, there is information recorded such as 
>> boat name and boat length. We aimed at using this information to 
>> generate a unique boat id, which would be treated as a group id for a 
>> random effect variable in our model. A problem arises in boat names 
>> because they may not be unique, but boat lengths are somewhat 
>> unreliable information and could have varying responses. This creates 
>> some records where the boat names may be the same with slightly 
>> varying lengths, resulting in multiple id's being generated for what 
>> might actually be the same boat (i.e., boat 1 with length of 17m and 
>> boat 1 with length of 17.2m). This greatly complicates our attempts 
>> at identifying unique boats and generates uncertainty in our 
>> classifications.
>> Is there a method for dealing with uncertainty or missing group id's 
>> in random effects? I'd be happy to elaborate or provide additional 
>> information if anything above was unclear.
>> Thanks for your time.
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Chris Evans (he/him)
Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor, 
University of Roehampton, London, UK.
Work web site: https://www.psyctc.org/psyctc/
CORE site: http://www.coresystemtrust.org.uk/
Personal site: https://www.psyctc.org/pelerinage2016/
Emeetings (Thursdays): 
https://www.psyctc.org/psyctc/booking-meetings-with-me/
(Beware: French time, generally an hour ahead of UK)
<https://ombook.psyctc.org/book>


From b@sii@m@iy m@iii@g oii u@ibe@ch  Tue Jul  4 15:02:42 2023
From: b@sii@m@iy m@iii@g oii u@ibe@ch (b@sii@m@iy m@iii@g oii u@ibe@ch)
Date: Tue, 4 Jul 2023 13:02:42 +0000
Subject: [R-sig-ME] R-sig-mixed-models mailing list submissions: Crossed
 Random Factors Mediation
Message-ID: <GV0P278MB1144CC466BD9BA2709B5E415E82EA@GV0P278MB1144.CHEP278.PROD.OUTLOOK.COM>

Dear colleagues

I would like to calculate a multilevel mediation using a linear multilevel model with crossed random factors. The code for the model is as follows:

### R-Code:

model <- lmer(outcome ~ condition + rating + (1|id) + (1|stimulusid), data = dat, REML = TRUE)


I am not aware of any mediation package in R that can compute mediation with crossed random factors. Also, Lavaan does not support models with crossed random factors. Therefore, I aimed to implement the indirect effect test with BootMer by myself. I would like to use the semi-parametric bootstrapping. This is my attempt so far:

### R-Code:
function_indirect_effect <- function(x) {
                                                                 fixef(x)[2]*fixef(x)[3]
}

boots <- bootMer(model,
               FUN = function_indirect_effect,
               use.u = FALSE,
type = "parametric",
nsim = 1000)

boots <- bootMer(model,
               FUN = function_indirect_effect,
               use.u = TRUE,
type = "semiparametric",
nsim = 1000)

However, the semi-parametric bootstrapping does not work, and only NAs are produced (?Warning: some bootstrap runs failed (1000/1000)?).
The problem is probably the simulation of the random effects (?use.u = TRUE?), since parametric bootstrapping doesn't work in this case either.


Does anyone have a hint what this could be due to and how I could fix the? Or does anyone know another way/package to compute and test the indirect effect?

Thanks for your time and kind regards,
Basil Maly

	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Wed Jul  5 11:00:36 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Wed, 5 Jul 2023 10:00:36 +0100
Subject: [R-sig-ME] Reducing two mixed models into one
In-Reply-To: <CADreqiy9VB9QcpTgNyhBNfADVawTsDyHbWthwo9Nkn7n_w+o2g@mail.gmail.com>
References: <CADreqix8_TF8b3TPTW_y--SHCFtzyJ7tDHFo1aZrBzje0Q9HrA@mail.gmail.com>
 <CAJuCY5z52ka+4=vyTaKx9znui3+3HYWVKO1byMdukAKv226mbw@mail.gmail.com>
 <CADreqizdUMbQoeBjPz7rZ5guZSnzGXJMOcuuLykQpPk08JYtOw@mail.gmail.com>
 <52f8e21f-0bf4-a2de-bef7-3d45ede9450a@gmail.com>
 <CADreqiy9VB9QcpTgNyhBNfADVawTsDyHbWthwo9Nkn7n_w+o2g@mail.gmail.com>
Message-ID: <3632c29a-fc95-b7e9-8414-5d773c936692@gmail.com>

Hi Timothy,

- the rescaling of -1/RT was only to avoid very small estimates which 
can sometimes hurt convergence; -1000/RT is a bit more manageable and 
has an interpretation as rate in seconds.

- I used lmer() instead of blmer() only to get a hang on the basic 
setup. Indeed, if you're estimating random effects, setting a prior on 
the variance-covariace matrix might be helpful ... so you may be better 
off with blmer() (or with full bayesian sampling, as with brms/stan).

Jo?o

On 13/06/2023 18:38, Timothy MacKenzie wrote:
> Dear Jo?o,
>
> Thank you for your clarification. You made two changes in your code
> that I wanted to check with you.
>
> First, you rescaled the outcome from -1/RT to -1000/RT. I wonder in
> what way that improved the model?
>
> Second, instead of blmer(), you used lmer() but your lmer() random
> effects matrix is singular which makes me think if the correlation
> (~0.95) estimated by lmer() is as dependable/reliable?
>
> Thanks,
> Tim M
>
> On Tue, Jun 13, 2023 at 12:01?PM Jo?o Ver?ssimo<jl.verissimo at gmail.com>  wrote:
>> Hi Timothy,
>>
>> The formula I've suggested before is identical to the first parametrization in Thierry's answer, i.e., writing "item_num / Condition" is the same as writing "item_num + item_num:Condition".
>> That parametrization gives you estimates for the Condition slopes separately for each level of item_num. So the correlation between the corresponding by-subject random slopes is (I believe) what you want:
>>
>>> d <- read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
>>> model_1 <- lmer(I(-1000/RT) ~ item_num / Condition + (item_num / Condition|Subject) + (item_num / Condition|Item), data = d)
>>> re.corrs <- attr(VarCorr(model_1)$Subject, "correlation")
>>> re.corrs["item_numEven:Conditionunrelated", "item_numOdd:Conditionunrelated"]
>> [1] 0.9499885
>>
>>
>> Jo?o
>>
>> On 13/06/2023 18:36, Timothy MacKenzie wrote:
>>
>> Dear Thierry,
>>
>> Thank you so much for your highly informative answer. If I may, I
>> wanted to ask a follow-up question.
>>
>> Previously, from the two separate models, I used to compute a
>> correlation (0.849635) between the random slopes of subjects in
>> 'Condition==unrelated' for Odd vs. Even items (shown below).
>>
>> **Question: Could we obtain the latent equivalent of the above
>> correlation (which may not be numerically the same as 0.849635) from
>> `attr(VarCorr(First_Parametrization_Model)$Subject, "correlation")`?
>>
>> Thank you so much again,
>> Tim M
>>
>> ranef_model_2_even = data.frame(ranef(model_2)$Subject)
>> ranef_model_2_even$Subject <- row.names(ranef_model_2_even)
>> ranef_model_3_odd = data.frame(ranef(model_3)$Subject)
>> ranef_model_3_odd$Subject <- row.names(ranef_model_3_odd)
>>
>> Subject = merge(ranef_model_2_even, ranef_model_3_odd, by = "Subject",
>> suffixes = c("_even", "_odd"))
>> cor(Subject$Conditionunrelated_even, Subject $Conditionunrelated_odd)
>> #  [1] 0.849635
>>
>>
>>
>>
>>
>> On Mon, Jun 12, 2023 at 1:36?AM Thierry Onkelinx
>> <thierry.onkelinx at inbo.be>  wrote:
>>
>> Dear Timothy,
>>
>> Add the interaction with item_num to every parameter and you should have the same parameterization for both models in a single model.
>>
>> # gives similar parameters as both models
>> I(-1/RT) ~ item_num + item_num:Condition + (item_num + item_num:Condition|Subject) + (item_num + item_num:Condition|Item)
>> # same model fit, different parametrization
>> I(-1/RT) ~ item_num*Condition + (item_num*Condition|Subject) + (item_num*Condition|Item)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> Op za 10 jun 2023 om 19:06 schreef Timothy MacKenzie<fswfswt at gmail.com>:
>>
>> Hello All,
>>
>> I'm hoping to clarify my prior post to elicit an informative response
>> from the experts on the list.
>>
>> Currently, I'm running two models each using a subset of my data (below).
>>
>> <Question>: Instead of running two separate models, is it possible to
>> create one model that captures both these separate models?
>>
>> Thank you,
>> Tim M
>> ################
>> d = read.csv("https://raw.githubusercontent.com/fpqq/w/main/d3.csv")
>> library(optimx)
>> library(blme)
>>
>> # Subset 1:
>> model_2 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>             subset = item_num == "Even")
>>
>> # Subset 2:
>> model_3 = blmer(I(-1/RT) ~ Condition + (Condition|Subject) + (Condition|Item),
>> data = d, control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
>>               subset = item_num == "Odd")
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>

-- 
*Jo?o Ver?ssimo*
Assistant Professor | /Professor Auxiliar/
School of Arts and Humanities | /Faculdade de Letras/
University of Lisbon | /Universidade de Lisboa/
	[[alternative HTML version deleted]]


From deuc@m||@ @end|ng |rom gm@||@com  Mon Jul 10 16:27:22 2023
From: deuc@m||@ @end|ng |rom gm@||@com (Camila Deutsch)
Date: Mon, 10 Jul 2023 11:27:22 -0300
Subject: [R-sig-ME] Hosmer-Lemeshow test in GLMM (binomial family) using
 lme4 package
Message-ID: <CADQK1zvnc0CFf6vwt-uKOaSPKux-7Ocr30fkhu6_gOF4v2t+Dw@mail.gmail.com>

Hi!
I ran a GLMM (binomial family) using the package lme4:
library(lme4)
#GLMM
m1 <- glmer(Canto ~ T + H + Patm + V + Pp + CU + (1|Evento), data = Datos,
family = binomial)

I was wondering if it would be appropriate to evaluate the goodness of fit
of the model by applying the Hosmer-Lemeshow test.

Thank you very much.
Lic. Camila Deutsch
Becaria Doctoral-CONICET
Grupo de Estudios sobre Biodiversidad en Agroecosistemas
Facultad de Ciencias Exactas y Naturales. IEGEBA
Universidad de Buenos Aires - CONICET

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jul 10 16:53:58 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 10 Jul 2023 10:53:58 -0400
Subject: [R-sig-ME] Hosmer-Lemeshow test in GLMM (binomial family) using
 lme4 package
In-Reply-To: <CADQK1zvnc0CFf6vwt-uKOaSPKux-7Ocr30fkhu6_gOF4v2t+Dw@mail.gmail.com>
References: <CADQK1zvnc0CFf6vwt-uKOaSPKux-7Ocr30fkhu6_gOF4v2t+Dw@mail.gmail.com>
Message-ID: <6256dc7c-29c5-46e7-d238-f899fff6c0ff@gmail.com>

    I think it should be appropriate.

   However, Frank Harrell (a leading biostatistician)

https://twitter.com/f2harrell/status/1228423023834718208

"The Hosmer-Lemeshow test has been obsolete for more than a decade.  Not 
recommend.  Low power, hard to interpret, very arbitrary to how deciles 
are computed."

  You can use 
https://search.r-project.org/CRAN/refmans/DescTools/html/HosmerLemeshowTest.html 
(which returns both HL and the recommned le Cessie-van 
Houwelingen-Copas-Hosmer statistics ...)

   cheers
    Ben Bolker


On 2023-07-10 10:27 a.m., Camila Deutsch wrote:
> Hi!
> I ran a GLMM (binomial family) using the package lme4:
> library(lme4)
> #GLMM
> m1 <- glmer(Canto ~ T + H + Patm + V + Pp + CU + (1|Evento), data = Datos,
> family = binomial)
> 
> I was wondering if it would be appropriate to evaluate the goodness of fit
> of the model by applying the Hosmer-Lemeshow test.
> 
> Thank you very much.
> Lic. Camila Deutsch
> Becaria Doctoral-CONICET
> Grupo de Estudios sobre Biodiversidad en Agroecosistemas
> Facultad de Ciencias Exactas y Naturales. IEGEBA
> Universidad de Buenos Aires - CONICET
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Mon Jul 10 19:08:45 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Mon, 10 Jul 2023 20:08:45 +0300
Subject: [R-sig-ME] Hosmer-Lemeshow test in GLMM (binomial family) using
 lme4 package
In-Reply-To: <6256dc7c-29c5-46e7-d238-f899fff6c0ff@gmail.com>
References: <CADQK1zvnc0CFf6vwt-uKOaSPKux-7Ocr30fkhu6_gOF4v2t+Dw@mail.gmail.com>
 <6256dc7c-29c5-46e7-d238-f899fff6c0ff@gmail.com>
Message-ID: <CAG_dBVfFnUmS4J8HLogyZGWY_os+dMKK9dqcQVX0B1behNBhDw@mail.gmail.com>

On top of what Frank (and Ben) already mentioned, AFAIK the Hosmer-Lemeshow
test is known to overreject GLMMs. The authors of the test acknowledge this
themselves (Hosmer, Lemeshow and Sturdivant 2013: 366). Not optimal at all.

J

Hosmer, David, Stanley Lemeshow and Rodney X Sturdivant. 2013. *Applied
Logistic Regression *(3rd ed.). Wiley.

ma 10. hein?k. 2023 klo 17.58 Ben Bolker (bbolker at gmail.com) kirjoitti:

>     I think it should be appropriate.
>
>    However, Frank Harrell (a leading biostatistician)
>
> https://twitter.com/f2harrell/status/1228423023834718208
>
> "The Hosmer-Lemeshow test has been obsolete for more than a decade.  Not
> recommend.  Low power, hard to interpret, very arbitrary to how deciles
> are computed."
>
>   You can use
>
> https://search.r-project.org/CRAN/refmans/DescTools/html/HosmerLemeshowTest.html
> (which returns both HL and the recommned le Cessie-van
> Houwelingen-Copas-Hosmer statistics ...)
>
>    cheers
>     Ben Bolker
>
>
> On 2023-07-10 10:27 a.m., Camila Deutsch wrote:
> > Hi!
> > I ran a GLMM (binomial family) using the package lme4:
> > library(lme4)
> > #GLMM
> > m1 <- glmer(Canto ~ T + H + Patm + V + Pp + CU + (1|Evento), data =
> Datos,
> > family = binomial)
> >
> > I was wondering if it would be appropriate to evaluate the goodness of
> fit
> > of the model by applying the Hosmer-Lemeshow test.
> >
> > Thank you very much.
> > Lic. Camila Deutsch
> > Becaria Doctoral-CONICET
> > Grupo de Estudios sobre Biodiversidad en Agroecosistemas
> > Facultad de Ciencias Exactas y Naturales. IEGEBA
> > Universidad de Buenos Aires - CONICET
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From k@r| @end|ng |rom hu|t|@@org  Wed Jul 12 20:41:04 2023
From: k@r| @end|ng |rom hu|t|@@org (Karl Ove Hufthammer)
Date: Wed, 12 Jul 2023 20:41:04 +0200
Subject: [R-sig-ME] Hosmer-Lemeshow test in GLMM (binomial family) using
 lme4 package
In-Reply-To: <6256dc7c-29c5-46e7-d238-f899fff6c0ff@gmail.com>
References: <CADQK1zvnc0CFf6vwt-uKOaSPKux-7Ocr30fkhu6_gOF4v2t+Dw@mail.gmail.com>
 <6256dc7c-29c5-46e7-d238-f899fff6c0ff@gmail.com>
Message-ID: <424bf202-f698-d320-c108-33ce99702025@huftis.org>

Ben Bolker skreiv 10.07.2023 16:53:
> However, Frank Harrell (a leading biostatistician)
>
> https://twitter.com/f2harrell/status/1228423023834718208
>
> "The Hosmer-Lemeshow test has been obsolete for more than a decade.? 
> Not recommend.? Low power, hard to interpret, very arbitrary to how 
> deciles are computed." 

Even though the Hosmer?Lemeshow test isn?t very good (for many reasons), 
the idea behind it, comparing predicted probabilities with relative 
frequencies, is sound. You do this comparison by plotting *smoothed* 
observed values against the predicted probabilities using the 
Hmisc::wtd.loess.noiter() function (compare the results with a 
abline(0,1) line). This function has some properties that makes it 
suitable for drawing calibration plots.

I?m sure there are other functions you can use for drawing calibration 
plots, but I like the simplicity of wtd.loess.noiter().


-- 
Karl Ove Hufthammer


From hkubr@@eno| @end|ng |rom gm@||@com  Wed Jul 12 22:22:58 2023
From: hkubr@@eno| @end|ng |rom gm@||@com (HATICE T KUBRA AKDUR)
Date: Wed, 12 Jul 2023 23:22:58 +0300
Subject: [R-sig-ME] GLMMadaptive Estimation Issue
Message-ID: <CA+_DO+z9GUROOKwmLCfH+3PQC4H-vE7+E3BBuQaD+yr0orXkKw@mail.gmail.com>

Dear Group Members,

I am trying to develop a new generalized mixed model using a new count
distribution. To see the behavior of model parameter estimates, I compare
the estimates I obtained with the GLMMadaptive package in terms of mse and
biases in simulation for laplace and AGQ estimation methods. When I
increase the cluster size to see their consistency, the mse and bias are
unfortunately higher than the smaller cluster size. I checked the
simulation code dozens of times. I couldn't find any problem in the code.
Could this be due to the package I'm using?
 Estimation bias: It's possible that estimation procedure is introducing
bias into the parameter estimates, which becomes more pronounced as the
cluster size increases. This can occur if there are numerical stability
issues, convergence problems, or other algorithmic limitations.
What do you think?
If anyone can help, I'll be very glad

Sincerely,

-- 
Assoc. Prof. Dr. Hatice T. Kubra AKDUR
Department of Statistics, Faculty of Science, Gazi University
06500 Teknikokullar ANKARA, TURKEY
Phone: +90 553 324 5380
Email: hatice_senol at wsu.edu
https://scholar.google.com/citations?user=_DLBsl4AAAAJ&hl=en

	[[alternative HTML version deleted]]


From je@@|ecom|ey44 @end|ng |rom gm@||@com  Tue Jul 25 04:06:09 2023
From: je@@|ecom|ey44 @end|ng |rom gm@||@com (jessica comley)
Date: Tue, 25 Jul 2023 10:06:09 +0800
Subject: [R-sig-ME] MCMCglmm with multinomial models
In-Reply-To: <CANdGWBFLdWxDmhfpBWkjQJgRf9RBGHtic5ZxZyyKQPm5CLhWbQ@mail.gmail.com>
References: <CANdGWBHgzmN15cvGu7zU90o-+sZn4fUS92_nanb6OYYW8f2rog@mail.gmail.com>
 <CAJtCY7XH=AACiNbTo4SLo4gMQnM7ub1vVEOwGGqB-AvuJf5+Jw@mail.gmail.com>
 <CANdGWBFmXtPEvaREGQenkqq403+toEFJvLMgPTzdFWGix-ggGA@mail.gmail.com>
 <CAJtCY7XW=aT50ZCGUr2Y8ERPT1x2UC686Odti8n1kTRj4hC+LQ@mail.gmail.com>
 <57338F74-D980-4078-A389-EDA67E79C1A6@ed.ac.uk>
 <CANdGWBF3uc7SM0-a7uW54iNBPvRHPTTG+jd8-yjYzUz49o-N4g@mail.gmail.com>
 <63B269B7-6C5F-4A0C-BC08-51FE97C621BF@ed.ac.uk>
 <CANdGWBE5fEdZpnKiJ8ZgaRgFChG4=K5zp2Gpufq-p8KRddX7fw@mail.gmail.com>
 <CANdGWBFY0s2y=qaKhwKAU5cvg2xW5rQ_3CmmXvvj+q5v-Fee3g@mail.gmail.com>
 <56260042-774A-4135-9E38-986F98546F45@ed.ac.uk>
 <CANdGWBFRhtZLV3U4QmP9FmZPFmw_6Ht5x9WiyiyV2ao_D9KimA@mail.gmail.com>
 <CANdGWBFJ30UCL3pXXPzn3fQT54vcQXvrdn2vsg_0B-XcYV2sHw@mail.gmail.com>
 <5FBB3A08-E3BA-4925-8A64-DC6753C0BA5B@ed.ac.uk>
 <CANdGWBEPE2=pbb5Y2J3jcjmoCbfbUyOM89LrkuDhduZUqnXMKw@mail.gmail.com>
 <45DC4F2C-0720-4193-9CBB-675B48873A8D@ed.ac.uk>
 <CANdGWBFLdWxDmhfpBWkjQJgRf9RBGHtic5ZxZyyKQPm5CLhWbQ@mail.gmail.com>
Message-ID: <CANdGWBG6eXaB42rathZAS0Ozj1TFJNSF0tpCRfDJz2ejMbXjJA@mail.gmail.com>

Hi Jarrod,

Thank you for all your help on this last year. We submitted our paper and
have gotten comments back from a reviewer asking if we could test for the
interaction between culling activity and predator presence with the data we
have?

Below is the model I ran previously.

*prior1=list(R=list(V=1, nu=0.002))*
*m1<-MCMCglmm(cbind(dawn, diurnal, dusk, nocturnal)~trait
-1+trait:culling+trait:predator, rcov=~idv(units+trait:units),
prior=prior1, data=bbj, family="multinomial4", nitt= 150000)*

All the best,
Jess

On Wed, Jul 27, 2022 at 8:36?PM jessica comley <jessiecomley44 at gmail.com>
wrote:

> Okay great, thank you. I have run Wald tests and they show that culling is
> significant but predator presence is not.
>
> On Wed, Jul 27, 2022 at 4:35 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Not quite -  it means the odds of diurnal activity compared to nocturnal
>> activity is greater when there is no culling compared to lethal culling.
>> However, I would do the omnibus Wald test before interpreting the
>> significance of individual tests.
>>
>>
>> On 27 Jul 2022, at 06:31, jessica comley <jessiecomley44 at gmail.com>
>> wrote:
>>
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that the
>> email is genuine and the content is safe.
>> Sorry, let me try rephrasing my question. From my results, how do I
>> interpret the base activity nocturnal. Does the significant result of  *traitdiurnal:cullingnone
>> *mean that there is more diurnal activity than nocturnal activity when
>> culling is none compared to lethal?
>>
>> On Wed, Jul 27, 2022 at 12:54 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>
>>> The trait:culling interactions are the degree to which activity is
>>> higher when culling is none rather than lethal. If you exponentiate the
>>> effects you get the promotional change in the odds ratio none:lethal.
>>>
>>>
>>>
>>> On 27 Jul 2022, at 05:48, jessica comley <jessiecomley44 at gmail.com>
>>> wrote:
>>>
>>> This email was sent to you by someone outside the University.
>>> You should only click on links or attachments if you are certain that
>>> the email is genuine and the content is safe.
>>> Sorry Jarrod, one last question I swear.
>>>
>>> From my corrected outcome:
>>>
>>> *Location effects: cbind(dawn, diurnal, dusk, nocturnal) ~ trait - 1 +
>>> trait:culling + trait:predator*
>>>
>>> *                          post.mean l-95% CI u-95% CI eff.samp
>>> pMCMC   *
>>> *traitdawn                  -1.49696 -1.91443 -1.03494    449.8 < 7e-05
>>> ****
>>> *traitdiurnal               -1.26128 -1.65569 -0.87573    173.7 < 7e-05
>>> ****
>>> *traitdusk                  -1.69165 -2.14582 -1.25074    304.0 < 7e-05
>>> ****
>>> *traitdawn:cullingnone      -0.35018 -0.75539  0.03488   1453.5 0.06068
>>> . *
>>> *traitdiurnal:cullingnone    0.61075  0.22682  0.99247    646.2 0.00653
>>> ***
>>> *traitdusk:cullingnone       0.32833 -0.07876  0.72035   1218.7
>>> 0.10136   *
>>> *traitdawn:predatorhigh      0.12826 -0.48062  0.81929    696.5
>>> 0.70884   *
>>> *traitdiurnal:predatorhigh  -0.45382 -1.03340  0.15183    293.7
>>> 0.12313   *
>>> *traitdusk:predatorhigh     -0.14870 -0.77156  0.49585    475.2
>>> 0.62830   *
>>> *traitdawn:predatorlow       0.41706 -0.11004  0.93341    579.5
>>> 0.10626   *
>>> *traitdiurnal:predatorlow   -0.01279 -0.47660  0.49818    206.6
>>> 0.95741   *
>>> *traitdusk:predatorlow       0.16600 -0.36760  0.71419    323.0 0.55102
>>>   *
>>>
>>> How would I work out whether traitnocturnal:cullingnone occured more or
>>> less than cullinglethal? Is this something that can be done?
>>>
>>> Cheers,
>>> Jess
>>>
>>> On Wed, Jul 27, 2022 at 12:24 PM jessica comley <
>>> jessiecomley44 at gmail.com> wrote:
>>>
>>>> Hi Jarrod,
>>>>
>>>> Yes I did have a typo in my data, which I have corrected and now all is
>>>> working well.
>>>>
>>>> Thank you very much for your help, I really do appreciate your
>>>> responses!
>>>>
>>>> Cheers,
>>>> Jess
>>>>
>>>> On Wed, Jul 27, 2022 at 12:14 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> 1/ My guess is that there is a mistake/typo in your data.frame:
>>>>> culling has 3 levels not 2. Does table(bbj$culling) return what you expect?
>>>>>
>>>>> 2/ They mean i) there is more diurnal activity under culling compared
>>>>> to whatever the mystery level of culling is. ii) there is more dawn
>>>>> activity when predators is low compared to absent.
>>>>>
>>>>> 3/ The indices should be for all terms involving the thing to be
>>>>> tested. So in the current model they should be 4:9 and 10:15 (not 3:5 and
>>>>> 6:8). This will change when you sort out your culling column (probably to
>>>>> 4:6 and 7:12). In my previous email I said you should be testing 3 effects
>>>>> for predator, but in fact there should be 6 (I thought predator had 3
>>>>> levels not 2).
>>>>>
>>>>> You might want a -1 in your model formula (i.e
>>>>> trait-1+trait:culling+trait:predator) to make the interpretation of
>>>>> the first 3 terms a little easier, but up to you.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On 27 Jul 2022, at 04:42, jessica comley <jessiecomley44 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> This email was sent to you by someone outside the University.
>>>>> You should only click on links or attachments if you are certain that
>>>>> the email is genuine and the content is safe.
>>>>> Dear Jarrod,
>>>>>
>>>>> Sorry to bother you again, I just want to make sure I am doing this
>>>>> correctly and understanding my results.
>>>>>
>>>>> I used the model you suggested:
>>>>>
>>>>> *prior1=list(R=list(V=1, nu=0.002)) m1<-MCMCglmm(cbind(dawn, diurnal,
>>>>> dusk, nocturnal)~trait+trait:culling+trait:predator,
>>>>> rcov=~idv(units+trait:units), prior=prior1, data=bbj,
>>>>> family="multinomial4", nitt= 150000)*
>>>>>
>>>>> And this is my outcome:
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> *Iterations = 3001:149991  Thinning interval  = 10  Sample size  =
>>>>> 14700   DIC: 10312.95   R-structure:  ~idv(units + trait:units)
>>>>> post.mean  l-95% CI u-95% CI eff.samp trait:units   0.01932 0.0002102
>>>>>  0.07042      441  Location effects: cbind(dawn, diurnal, dusk, nocturnal)
>>>>> ~ trait + trait:culling + trait:predator
>>>>>  post.mean  l-95% CI  u-95% CI eff.samp   pMCMC     (Intercept)
>>>>>    -2.018903 -2.677830 -1.335305    609.1 < 7e-05 *** traitdiurnal
>>>>>        0.542636 -0.363766  1.405230    644.6 0.22068     traitdusk
>>>>>          -0.047952 -0.984923  0.917710    374.6 0.91850
>>>>> traitdawn:cullingLethal     0.534474  0.003076  1.058211    596.8 0.05524 .
>>>>>   traitdiurnal:cullingLethal  0.232597 -0.369959  0.834347    404.7 0.42789
>>>>>     traitdusk:cullingLethal     0.376191 -0.217707  0.964636    408.2
>>>>> 0.19782     traitdawn:cullingnone      -0.163961 -0.573477  0.298182
>>>>> 2945.5 0.38245     traitdiurnal:cullingnone    0.674041  0.247724  1.101917
>>>>>   2825.0 0.00952 **  traitdusk:cullingnone       0.449710 -0.014263
>>>>>  0.874925   1683.9 0.05102 .   traitdawn:predatorhigh      0.456119
>>>>> -0.206435  1.151283    561.7 0.18531     traitdiurnal:predatorhigh
>>>>>  -0.303114 -0.976842  0.377294    479.9 0.36939     traitdusk:predatorhigh
>>>>>      0.108262 -0.674552  0.895819    256.7 0.76122
>>>>> traitdawn:predatorlow       0.756262  0.160407  1.323520    418.1 0.01279 *
>>>>>   traitdiurnal:predatorlow    0.136875 -0.446984  0.750518    305.7 0.65619
>>>>>     traitdusk:predatorlow       0.422497 -0.303586  1.145038    194.9
>>>>> 0.22857     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ?
>>>>> ? 1*
>>>>>
>>>>> 1) Why do the 2 categories for culling both show up but then only 2 of
>>>>> the three categories for predator show up? i.e. predatorabsent is missing?
>>>>>
>>>>> 2) Do these results mean that i) diurnal activity and lethal culling
>>>>> is sig different from nocturnal activity and lethal culling; ii) dawn
>>>>> activity and predator low is sig different from nocturnal activity and
>>>>> predator low?
>>>>>
>>>>> 3) Is this the correct way and interpretation of the within group
>>>>> effects?
>>>>> *##culling lethal*
>>>>>
>>>>>
>>>>> * aod::wald.test(cov(m1$Sol[,3:5]),
>>>>> colMeans(m1$Sol[,3:5]),Terms=1:3)$result$chi2["P"]         P  0.1638938*
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> * ##culling  none aod::wald.test(cov(m1$Sol[,6:8]),
>>>>> colMeans(m1$Sol[,6:8]),Terms=1:3)$result$chi2["P"]           P  0.006497424*
>>>>>
>>>>>
>>>>> So these results show us that culling none has an effect on activity?
>>>>>
>>>>> Thank you in advance,
>>>>> Jess
>>>>>
>>>>> On Wed, Jul 27, 2022 at 8:20 AM jessica comley <
>>>>> jessiecomley44 at gmail.com> wrote:
>>>>>
>>>>>> Dear Jarrod,
>>>>>>
>>>>>> Thank you so much for your help, I greatly appreciate it!
>>>>>>
>>>>>> All the best,
>>>>>> Jess
>>>>>>
>>>>>> On Wed, Jul 27, 2022 at 3:32 AM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Jess,
>>>>>>>
>>>>>>> Section should definitely not be left out, but I would imagine it is
>>>>>>> going to be very difficult to separate culling, predator and Section
>>>>>>> effects - I would expect the credible intervals to be large.
>>>>>>>
>>>>>>> As mentioned in my previous post you can test for an effect of
>>>>>>> culling by fitting the model
>>>>>>>
>>>>>>> ~trait+trait:culling+trait:predator
>>>>>>>
>>>>>>> And then fitting a Wald test to the three terms with 'culling' in.
>>>>>>> The effect of predator can be tested similarly but with the 3 terms with
>>>>>>> 'predator' in.
>>>>>>>
>>>>>>> Since your covariates do not vary within Section it will be much
>>>>>>> easier to aggregate the counts at the Section level (i.e have a data frame
>>>>>>> with 14 rows and 1 column for each activity with the number observed for
>>>>>>> each activity) and fit family="multinomial". You can then get rid of the
>>>>>>> random formula as the Section effects are now effectively the residuals.
>>>>>>> Given the lack of replication I would advise using the idv formula that I
>>>>>>> suggested previously and hope the model isn't too misspecified:
>>>>>>>
>>>>>>> prior=list(R=list(V=1, nu=0.002))
>>>>>>>
>>>>>>> m1<-MCMCglmm(cbind(dawn, diurnal, dusk,
>>>>>>> nocturnal)~trait+trait:culling+trait:predator,
>>>>>>> rcov=~idv(units+trait:units), prior=prior, ...)
>>>>>>>
>>>>>>> Note this models is identical to the original model, it's just
>>>>>>> parameterised in a more efficient way.
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 25 Jul 2022, at 03:52, jessica comley <jessiecomley44 at gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>> This email was sent to you by someone outside the University.
>>>>>>> You should only click on links or attachments if you are certain
>>>>>>> that the email is genuine and the content is safe.
>>>>>>> Dear Jarrod and Walid,
>>>>>>>
>>>>>>> Thank you for your replies, it is greatly appreciated.
>>>>>>>
>>>>>>> The predator and culling factors do not vary within sites. As shown
>>>>>>> in the example data in one of my previous emails, Bucklands only has
>>>>>>> culling as lethal and predator as low, whereas Colchester only has predator
>>>>>>> as high and culling as none.
>>>>>>>
>>>>>>> We are trying to submit a paper on black-backed jackal and caracal
>>>>>>> activity in the presence of different culling practices and
>>>>>>> predator presence. The reviewers want us to try a GLMM approach to
>>>>>>> determine whether culling or predators have an effect on black-backed
>>>>>>> jackal or caracal activity.
>>>>>>>
>>>>>>> Therefore, in your opinion how could be go about this given our
>>>>>>> data? Would it be advisable to leave out the random effect of Section?
>>>>>>>
>>>>>>> All the best,
>>>>>>> Jess
>>>>>>>
>>>>>>> On Wed, Jul 20, 2022 at 3:06 PM Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> Hi Jess
>>>>>>>>
>>>>>>>> In multinomial models the linear model is set up as a (logit)
>>>>>>>> difference in probability between an outcome and some base-line outcome.
>>>>>>>> Often, as here, the base-line outcome is arbitrary, and so the idh
>>>>>>>> structure is a little odd. For example, if A is the base line category, idh
>>>>>>>> assumes COV(B-A, C-A) = 0 which therefore assumes
>>>>>>>> COV(B,C)+VAR(A) =COV(A,B)+COV(C,A). It's not clear why this would
>>>>>>>> be the case. Perhaps a more reasonable, but less parameter rich, option
>>>>>>>> would be to have:
>>>>>>>>
>>>>>>>> ~idv(Section+trait:Section)
>>>>>>>>
>>>>>>>> which parameterises the Section covariance matrix by a single
>>>>>>>> parameter (rather than 6). The term idv(Section+trait:Section) fits a 3x3
>>>>>>>> covariance matrix of the form v*(I+J) where v is the estimated variance.
>>>>>>>> This assumes i) Sections are repeatable in outcome, but knowing that a
>>>>>>>> Section has an increased 'preference' for A doesn?t tell you whether it
>>>>>>>> also has an increased preference for one of the other categories and ii)
>>>>>>>> the repeatability for each outcome within sites is the same (on the latent
>>>>>>>> scale).
>>>>>>>>
>>>>>>>> To test groups of effects (in your case the 3 culling:trait
>>>>>>>> effects), I usually use a Wald test and the posterior covariances (see here
>>>>>>>>
>>>>>>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025930.html).
>>>>>>>> It's far from correct and so Walid's suggestions may be better, but
>>>>>>>> small-scale simulations suggests it has good frequentist properties.
>>>>>>>>
>>>>>>>> To add predator presence you can just add a predator:trait effect
>>>>>>>> into the linear model. If the culling and predator factors do not vary
>>>>>>>> within sites then you probably don't have enough information to reliably
>>>>>>>> estimate these effects.
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>> Jarrod
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> > On 19 Jul 2022, at 18:17, Walid Mawass <walidmawass10 at gmail.com>
>>>>>>>> wrote:
>>>>>>>> >
>>>>>>>> > This email was sent to you by someone outside the University.
>>>>>>>> > You should only click on links or attachments if you are certain
>>>>>>>> that the email is genuine and the content is safe.
>>>>>>>> >
>>>>>>>> > Hey Jess,
>>>>>>>> >
>>>>>>>> > 1) Yes that is correct
>>>>>>>> >
>>>>>>>> > 2) To my knowledge there is a rule of thumb, where you set the
>>>>>>>> nitt (# of
>>>>>>>> > iterations) to a large number that includes the burnin amount,
>>>>>>>> then you
>>>>>>>> > choose your thinning interval (sampling of the chain). For
>>>>>>>> example, this is
>>>>>>>> > what I would use: nitt= 150000, burnin=50000, thin=100. This will
>>>>>>>> give you
>>>>>>>> > a decent burnin and a final sample of 1000 saved iterations. Note
>>>>>>>> however
>>>>>>>> > that this does not have to increase the effective sample size for
>>>>>>>> certain
>>>>>>>> > variables, but it might do the trick.
>>>>>>>> >
>>>>>>>> > 3) hmm...I think one way to do it is to make predictions using
>>>>>>>> the above
>>>>>>>> > model and interpret the patterns you see for each relationship
>>>>>>>> you are
>>>>>>>> > interested in. Another way to compare effect size would be to use
>>>>>>>> bayesian
>>>>>>>> > posterior indices. I suggest these two papers by Makowski et al.
>>>>>>>> (2019a &
>>>>>>>> > b) that present both interesting posterior indices to use with
>>>>>>>> Bayesian
>>>>>>>> > statistical analysis and an associated R package that does the
>>>>>>>> job of
>>>>>>>> > computing these indices, *bayestestR*.
>>>>>>>> >
>>>>>>>> > Good luck
>>>>>>>> > --
>>>>>>>> > Walid Mawass
>>>>>>>> > Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>>>> > *Currently* Postdoctoral Research Associate
>>>>>>>> > Masel Lab - University of Arizona
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > On Sun, Jul 17, 2022 at 11:32 PM jessica comley <
>>>>>>>> jessiecomley44 at gmail.com>
>>>>>>>> > wrote:
>>>>>>>> >
>>>>>>>> >> Hi Walid,
>>>>>>>> >>
>>>>>>>> >> Thank you for your reply, I greatly appreciate it. I have a few
>>>>>>>> more
>>>>>>>> >> questions and if you could help that would be great.
>>>>>>>> >>
>>>>>>>> >> I tested for correlation between activities and the 14 Sections
>>>>>>>> and the
>>>>>>>> >> correlation comes out as low. Therefore I have changed my code
>>>>>>>> to use idh()
>>>>>>>> >> instead of us as suggested:
>>>>>>>> >>
>>>>>>>> >> test1c.5b <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait +
>>>>>>>> >> at.level(culling, 2):trait, random=~idh(trait):Section, rcov =
>>>>>>>> >> ~idh(trait):units, data = caracal, family = "categorical", prior
>>>>>>>> = prior,
>>>>>>>> >> burnin=5000, nitt=80000)
>>>>>>>> >>
>>>>>>>> >> 1) Is this correct?
>>>>>>>> >>
>>>>>>>> >> 2) Increasing the number of interactions increases the effective
>>>>>>>> sample
>>>>>>>> >> size, therefore is there a general rule of thumb as to how large
>>>>>>>> your
>>>>>>>> >> effective sample size should be?
>>>>>>>> >>
>>>>>>>> >> 3) I understand how to use and interpret the results of
>>>>>>>> HPDinterval (i.e.
>>>>>>>> >> if intervals do not overlap 0 then relationship is strong), but
>>>>>>>> how am I
>>>>>>>> >> able to test the relationship between all four activities and
>>>>>>>> fixed effects
>>>>>>>> >> and not just have the three categories (i.e. diurnal, dusk,
>>>>>>>> nocturnal)
>>>>>>>> >> compared to the base category (dawn)? For example, I am also
>>>>>>>> interested in
>>>>>>>> >> whether there is a significant/strong relationship between
>>>>>>>> activities of
>>>>>>>> >> caracal at dusk with culling(Lethal)/no culling(none) compared to
>>>>>>>> >> activities of caracal at diurnal with culling(Lethal)/no
>>>>>>>> culling(none).
>>>>>>>> >>
>>>>>>>> >> Below is an example of our dataset:
>>>>>>>> >> Camera Section CameraID Animal predator culling activity
>>>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal diurnal
>>>>>>>> >> 1a Bucklands Bucklands1a Caracal low Lethal dawn
>>>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal dusk
>>>>>>>> >> 2a Bucklands Bucklands2a Caracal low Lethal diurnal
>>>>>>>> >> 3a Bucklands Bucklands3a Caracal low Lethal dawn
>>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>>> >> Cam 1  Colchester ColchesterCam 1  Caracal high none diurnal
>>>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>>>> >> Cam 2  Colchester ColchesterCam 2  Caracal high none diurnal
>>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>>> >> Cam 3  Colchester ColchesterCam 3  Caracal high none diurnal
>>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none diurnal
>>>>>>>> >> Cam 4  Colchester ColchesterCam 4  Caracal high none nocturnal
>>>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>>>> >> 1a Connaught Connaught1a Caracal low Lethal nocturnal
>>>>>>>> >> 1d Connaught Connaught1d Caracal low Lethal diurnal
>>>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>>>> >> 3B Connaught Connaught3B Caracal low Lethal diurnal
>>>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>>>> >> 4a Connaught Connaught4a Caracal low Lethal nocturnal
>>>>>>>> >> 4b Connaught Connaught4b Caracal low Lethal diurnal
>>>>>>>> >> 6a Connaught Connaught6a Caracal low Lethal nocturnal
>>>>>>>> >> 6b Connaught Connaught6b Caracal low Lethal diurnal
>>>>>>>> >> 7a Connaught Connaught7a Caracal low Lethal nocturnal
>>>>>>>> >> 9a Connaught Connaught9a Caracal low Lethal nocturnal
>>>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal nocturnal
>>>>>>>> >> 9d Connaught Connaught9d Caracal low Lethal dusk
>>>>>>>> >> 7d Diepdam Diepdam7d Caracal absent Lethal dusk
>>>>>>>> >> 8d Diepdam Diepdam8d Caracal absent Lethal diurnal
>>>>>>>> >> 9c Diepdam Diepdam9c Caracal absent Lethal nocturnal
>>>>>>>> >>
>>>>>>>> >> All the best,
>>>>>>>> >> Jess
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >> On Fri, Jul 15, 2022 at 11:37 PM Walid Mawass <
>>>>>>>> walidmawass10 at gmail.com>
>>>>>>>> >> wrote:
>>>>>>>> >>
>>>>>>>> >>> Hello,
>>>>>>>> >>>
>>>>>>>> >>> I don't think I can specifically help you with some of your
>>>>>>>> inquiries.
>>>>>>>> >>> However, I do want to comment on a few things that might need
>>>>>>>> some
>>>>>>>> >>> attention.
>>>>>>>> >>>
>>>>>>>> >>> First, MCMCglmm is based on a Bayesian implementation and does
>>>>>>>> not
>>>>>>>> >>> compute p-values to compare. What you need to compare are the
>>>>>>>> posterior
>>>>>>>> >>> distributions of your effect sizes. This can be done visually
>>>>>>>> using the
>>>>>>>> >>> base plot function in R. Or by comparing the HPD intervals and
>>>>>>>> the mode (or
>>>>>>>> >>> mean) of the posterior distributions.
>>>>>>>> >>>
>>>>>>>> >>> Second, I have no idea what your data structure looks like
>>>>>>>> (which makes
>>>>>>>> >>> it hard to interpret model results), but the effective sample
>>>>>>>> size (from
>>>>>>>> >>> the 5500 saved iterations sample) for your random variable
>>>>>>>> Section is very
>>>>>>>> >>> low (the same applies for your fixed effects). You should
>>>>>>>> consider this
>>>>>>>> >>> issue and look again at your assumption of correlation between
>>>>>>>> >>> activities for the 14 sections you have in your dataset. If you
>>>>>>>> do not
>>>>>>>> >>> expect among activity correlations then you can use the idh()
>>>>>>>> function
>>>>>>>> >>> instead of us().
>>>>>>>> >>>
>>>>>>>> >>> Hopefully this helps and in hope that people on this list with
>>>>>>>> more
>>>>>>>> >>> knowledge of these models will help out.
>>>>>>>> >>>
>>>>>>>> >>> Best,
>>>>>>>> >>> --
>>>>>>>> >>> Walid Mawass
>>>>>>>> >>> Ph.D. candidate in Evolutionary Biology - UQTR
>>>>>>>> >>> *Currently* Postdoctoral Research Associate
>>>>>>>> >>> Masel Lab - University of Arizona
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>> On Fri, Jul 15, 2022 at 8:49 AM jessica comley <
>>>>>>>> jessiecomley44 at gmail.com>
>>>>>>>> >>> wrote:
>>>>>>>> >>>
>>>>>>>> >>>> Dear all,
>>>>>>>> >>>>
>>>>>>>> >>>> I am hoping that someone will be able to help me with
>>>>>>>> conducting MCMCglmm
>>>>>>>> >>>> multinomial models.
>>>>>>>> >>>>
>>>>>>>> >>>> The data I am working with is for black-backed jackal (bbj)
>>>>>>>> and carcal.
>>>>>>>> >>>> For
>>>>>>>> >>>> each species we have a multinomial response variable called
>>>>>>>> activity
>>>>>>>> >>>> which
>>>>>>>> >>>> has four categories (dawn, diurnal, dusk, nocturnal). We have
>>>>>>>> two
>>>>>>>> >>>> categorical fixed effects which are 1) culling (none, lethal)
>>>>>>>> and 2)
>>>>>>>> >>>> predator presence (absent, high, low). We also have a
>>>>>>>> categorical
>>>>>>>> >>>> variable
>>>>>>>> >>>> called Section (made up of 14 different reserves/ farms where
>>>>>>>> the
>>>>>>>> >>>> activity
>>>>>>>> >>>> of caracal and bbj were recorded). There are 273 observations
>>>>>>>> for caracal
>>>>>>>> >>>> and 4399 for bbj. We are wanting to test the effects of
>>>>>>>> culling and
>>>>>>>> >>>> predators on caracal and bbj activity separately.
>>>>>>>> >>>>
>>>>>>>> >>>> I have been working through Jarrod Hadfields course notes,
>>>>>>>> particularly
>>>>>>>> >>>> with regards to Chapter 5.2. The chi-square analyses reveal
>>>>>>>> that the
>>>>>>>> >>>> frequencies of culling and predators differ as do activities.
>>>>>>>> >>>>
>>>>>>>> >>>> I have managed to work out the specific probabilities for the
>>>>>>>> culling
>>>>>>>> >>>> none
>>>>>>>> >>>> vs culling lethal for each activity (dawn, diurnal, dusk,
>>>>>>>> nocturnal) for
>>>>>>>> >>>> caracal, but I'm confused as to how to determine p-values to
>>>>>>>> determine
>>>>>>>> >>>> which activities culling none vs culling lethal are affecting?
>>>>>>>> >>>>
>>>>>>>> >>>> Myy code and outcomes are pasted below with questions stated
>>>>>>>> in bold.
>>>>>>>> >>>>
>>>>>>>> >>>> caracal2 <- read.csv("caracal_new.csv", header=T)
>>>>>>>> >>>> caracal <- as.data.frame(unclass(caracal2), stringsAsFactors =
>>>>>>>> TRUE)
>>>>>>>> >>>>
>>>>>>>> >>>> #Chi-squared tests
>>>>>>>> >>>> Ctable1 <- table(caracal$activity, caracal$culling)
>>>>>>>> >>>> chisq.test(rowSums(Ctable1)) #strongly suggests activities
>>>>>>>> differ
>>>>>>>> >>>> chisq.test(Ctable1)#strongly suggests culling category differs
>>>>>>>> >>>>
>>>>>>>> >>>> Ctable2 <- table(caracal$activity, caracal$predator)
>>>>>>>> >>>> chisq.test(rowSums(Ctable2))#strongly suggests activities
>>>>>>>> differ
>>>>>>>> >>>> chisq.test(Ctable2)#strongly suggests predator category differs
>>>>>>>> >>>>
>>>>>>>> >>>> prior = list(R = list(fix=1, V=(1/k) * (I + J)), G =
>>>>>>>> list(G1=list(V =
>>>>>>>> >>>> diag(k-1), nu=1)))
>>>>>>>> >>>> test1c.5 <- MCMCglmm(activity ~ -1 + at.level(culling,1):trait
>>>>>>>> +
>>>>>>>> >>>> at.level(culling, 2):trait, random=~us(trait):Section, rcov =
>>>>>>>> >>>> ~us(trait):units, data = caracal, family = "categorical",
>>>>>>>> prior = prior,
>>>>>>>> >>>> burnin=5000, nitt=60000)
>>>>>>>> >>>> *##I'm not sure how to add the three predator levels to this
>>>>>>>> model or if
>>>>>>>> >>>> it
>>>>>>>> >>>> would be appropriate?*
>>>>>>>> >>>>
>>>>>>>> >>>>
>>>>>>>> >>>> k <- length(levels(caracal$activity))
>>>>>>>> >>>> I <- diag(k-1)
>>>>>>>> >>>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>>>>>>>> >>>> IJ <- (1/k) *(diag(k-1) + matrix(1,k-1, k-1))
>>>>>>>> >>>>
>>>>>>>> >>>> contrasts(caracal$activity)
>>>>>>>> >>>>
>>>>>>>> >>>> #culling lethal
>>>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,1:3],1, function(x) + D %*%
>>>>>>>> (x/sqrt(1 + c2 *
>>>>>>>> >>>> diag(IJ)))))
>>>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>>> >>>>
>>>>>>>> >>>> prop.table(Ctable1[,1])
>>>>>>>> >>>>
>>>>>>>> >>>> #culling none
>>>>>>>> >>>> Delta <- cbind(c(0,1,0,0), c(0,0,1,0), c(0,0,0,1))
>>>>>>>> >>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>>>> >>>> D <- ginv(Delta %*% t(Delta)) %*% Delta
>>>>>>>> >>>> Int <- t(apply(test1c.5$Sol[,4:6],1, function(x) + D %*%
>>>>>>>> (x/sqrt(1 + c2 *
>>>>>>>> >>>> diag(IJ)))))
>>>>>>>> >>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>>> >>>>
>>>>>>>> >>>> prop.table((Ctable1[,2]))
>>>>>>>> >>>>
>>>>>>>> >>>> HPDinterval(test1c.5$Sol)
>>>>>>>> >>>>
>>>>>>>> >>>> #model summary
>>>>>>>> >>>>> summary(test1c.5)
>>>>>>>> >>>>
>>>>>>>> >>>> Iterations = 5001:59991
>>>>>>>> >>>> Thinning interval  = 10
>>>>>>>> >>>> Sample size  = 5500
>>>>>>>> >>>>
>>>>>>>> >>>> DIC: 699.7014
>>>>>>>> >>>>
>>>>>>>> >>>> G-structure:  ~us(trait):Section
>>>>>>>> >>>>
>>>>>>>> >>>>
>>>>>>>> post.mean l-95%
>>>>>>>> >>>> CI
>>>>>>>> >>>> u-95% CI eff.samp
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.Section
>>>>>>>> 1.8124
>>>>>>>> >>>> 0.09784
>>>>>>>> >>>>   5.665    77.01
>>>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.Section
>>>>>>>>  0.8450
>>>>>>>> >>>> -0.83585
>>>>>>>> >>>>   3.856    64.17
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.Section
>>>>>>>> 1.3621
>>>>>>>> >>>> -1.19129
>>>>>>>> >>>>   6.157    58.48
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.Section
>>>>>>>>  0.8450
>>>>>>>> >>>> -0.83585
>>>>>>>> >>>>   3.856    64.17
>>>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.Section
>>>>>>>> 1.2034
>>>>>>>> >>>> 0.07090
>>>>>>>> >>>>   3.681   102.16
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.Section
>>>>>>>>  0.7505
>>>>>>>> >>>> -1.77113
>>>>>>>> >>>>   4.524    43.53
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.Section
>>>>>>>> 1.3621
>>>>>>>> >>>> -1.19129
>>>>>>>> >>>>   6.157    58.48
>>>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.Section
>>>>>>>>  0.7505
>>>>>>>> >>>> -1.77113
>>>>>>>> >>>>   4.524    43.53
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.Section
>>>>>>>> 2.7148
>>>>>>>> >>>> 0.09401
>>>>>>>> >>>>   8.397    76.59
>>>>>>>> >>>>
>>>>>>>> >>>> R-structure:  ~us(trait):units
>>>>>>>> >>>>
>>>>>>>> >>>>                                                      post.mean
>>>>>>>> l-95% CI
>>>>>>>> >>>> u-95% CI eff.samp
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.diurnal.units
>>>>>>>> 0.50     0.50
>>>>>>>> >>>>  0.50        0
>>>>>>>> >>>> traitactivity.dusk:traitactivity.diurnal.units
>>>>>>>>  0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.diurnal.units
>>>>>>>> 0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.dusk.units
>>>>>>>>  0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.dusk:traitactivity.dusk.units
>>>>>>>> 0.50     0.50
>>>>>>>> >>>>  0.50        0
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.dusk.units
>>>>>>>>  0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.diurnal:traitactivity.nocturnal.units
>>>>>>>> 0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.dusk:traitactivity.nocturnal.units
>>>>>>>>  0.25     0.25
>>>>>>>> >>>>  0.25        0
>>>>>>>> >>>> traitactivity.nocturnal:traitactivity.nocturnal.units
>>>>>>>> 0.50     0.50
>>>>>>>> >>>>  0.50        0
>>>>>>>> >>>>
>>>>>>>> >>>> Location effects: activity ~ -1 + at.level(culling, 1):trait +
>>>>>>>> >>>> at.level(culling, 2):trait
>>>>>>>> >>>>
>>>>>>>> >>>>                                             post.mean l-95% CI
>>>>>>>> u-95% CI
>>>>>>>> >>>> eff.samp  pMCMC
>>>>>>>> >>>> at.level(culling, 1):traitactivity.diurnal      1.2306
>>>>>>>> -0.0533   2.6793
>>>>>>>> >>>> 145.29 0.0418 *
>>>>>>>> >>>> at.level(culling, 1):traitactivity.dusk         0.6605
>>>>>>>> -0.6006   2.0761
>>>>>>>> >>>> 92.91 0.2840
>>>>>>>> >>>> at.level(culling, 1):traitactivity.nocturnal    1.6090
>>>>>>>>  0.0914   3.1356
>>>>>>>> >>>> 151.02 0.0265 *
>>>>>>>> >>>> traitactivity.diurnal:at.level(culling, 2)      1.2664
>>>>>>>> -0.1552   2.7750
>>>>>>>> >>>> 226.40 0.0604 .
>>>>>>>> >>>> traitactivity.dusk:at.level(culling, 2)         0.3533
>>>>>>>> -0.9898   1.5218
>>>>>>>> >>>> 148.44 0.5447
>>>>>>>> >>>> traitactivity.nocturnal:at.level(culling, 2)    1.0447
>>>>>>>> -0.6405   2.8354
>>>>>>>> >>>> 346.40 0.1618
>>>>>>>> >>>> ---
>>>>>>>> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>>> >>>>
>>>>>>>> >>>> *##So for the model summary I get that lethal culling at
>>>>>>>> activity diurnal
>>>>>>>> >>>> is significantly different from lethal culling at dawn (its
>>>>>>>> the base
>>>>>>>> >>>> reference), but I'm also interested in whether lethal culling
>>>>>>>> at activity
>>>>>>>> >>>> diurnal is different from lethal culling at dusk for example.
>>>>>>>> Is this
>>>>>>>> >>>> possible? *
>>>>>>>> >>>>
>>>>>>>> >>>> #outcomes culling lethal
>>>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>>> >>>>
>>>>>>>> >>>> Iterations = 1:5500
>>>>>>>> >>>> Thinning interval = 1
>>>>>>>> >>>> Number of chains = 1
>>>>>>>> >>>> Sample size per chain = 5500
>>>>>>>> >>>>
>>>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>>>> >>>>   plus standard error of the mean:
>>>>>>>> >>>>
>>>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>>>> >>>> [1,] 0.1253 0.05565 0.0007504       0.002484
>>>>>>>> >>>> [2,] 0.3748 0.10497 0.0014155       0.003204
>>>>>>>> >>>> [3,] 0.1757 0.06640 0.0008954       0.002515
>>>>>>>> >>>> [4,] 0.3242 0.11939 0.0016099       0.003514
>>>>>>>> >>>>
>>>>>>>> >>>> 2. Quantiles for each variable:
>>>>>>>> >>>>
>>>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>>>> >>>> var1 0.03641 0.08695 0.1198 0.1554 0.2553
>>>>>>>> >>>> var2 0.17298 0.30580 0.3704 0.4431 0.5896
>>>>>>>> >>>> var3 0.06166 0.12913 0.1705 0.2161 0.3215
>>>>>>>> >>>> var4 0.12610 0.23999 0.3090 0.3901 0.6045
>>>>>>>> >>>>
>>>>>>>> >>>>> prop.table(Ctable1[,1])
>>>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>>>> >>>> 0.1250000 0.2812500 0.1770833 0.4166667
>>>>>>>> >>>>
>>>>>>>> >>>>
>>>>>>>> >>>> #outcomes culling none
>>>>>>>> >>>>> summary(mcmc(exp(Int)/rowSums(exp(Int))))
>>>>>>>> >>>>
>>>>>>>> >>>> Iterations = 1:5500
>>>>>>>> >>>> Thinning interval = 1
>>>>>>>> >>>> Number of chains = 1
>>>>>>>> >>>> Sample size per chain = 5500
>>>>>>>> >>>>
>>>>>>>> >>>> 1. Empirical mean and standard deviation for each variable,
>>>>>>>> >>>>   plus standard error of the mean:
>>>>>>>> >>>>
>>>>>>>> >>>>       Mean      SD  Naive SE Time-series SE
>>>>>>>> >>>> [1,] 0.1288 0.06141 0.0008280       0.002787
>>>>>>>> >>>> [2,] 0.3804 0.10406 0.0014032       0.002662
>>>>>>>> >>>> [3,] 0.1710 0.06844 0.0009228       0.002592
>>>>>>>> >>>> [4,] 0.3198 0.11812 0.0015928       0.002956
>>>>>>>> >>>>
>>>>>>>> >>>> 2. Quantiles for each variable:
>>>>>>>> >>>>
>>>>>>>> >>>>        2.5%     25%    50%    75%  97.5%
>>>>>>>> >>>> var1 0.02891 0.08896 0.1220 0.1594 0.2685
>>>>>>>> >>>> var2 0.18007 0.31094 0.3783 0.4474 0.5965
>>>>>>>> >>>> var3 0.05840 0.12425 0.1634 0.2083 0.3250
>>>>>>>> >>>> var4 0.12430 0.23921 0.3077 0.3862 0.5964
>>>>>>>> >>>>
>>>>>>>> >>>>> prop.table((Ctable1[,2]))
>>>>>>>> >>>>     dawn   diurnal      dusk nocturnal
>>>>>>>> >>>> 0.1306818 0.4375000 0.1875000 0.2443182
>>>>>>>> >>>>
>>>>>>>> >>>> Any help or guidance will be greatly appreciated.
>>>>>>>> >>>>
>>>>>>>> >>>> All the best,
>>>>>>>> >>>> Jess
>>>>>>>> >>>>
>>>>>>>> >>>> --
>>>>>>>> >>>> Jessica Comley (PhD)
>>>>>>>> >>>> Research Scientist
>>>>>>>> >>>>
>>>>>>>> >>>>        [[alternative HTML version deleted]]
>>>>>>>> >>>>
>>>>>>>> >>>> _______________________________________________
>>>>>>>> >>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> >>>>
>>>>>>>> >>>
>>>>>>>> >>
>>>>>>>> >> --
>>>>>>>> >> Jessica Comley (PhD)
>>>>>>>> >> Research Scientist
>>>>>>>> >>
>>>>>>>> >>
>>>>>>>> >
>>>>>>>> >        [[alternative HTML version deleted]]
>>>>>>>> >
>>>>>>>> > _______________________________________________
>>>>>>>> > R-sig-mixed-models at r-project.org mailing list
>>>>>>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336. Is e buidheann carthannais a
>>>>>>>> th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh
>>>>>>>> SC005336.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Jessica Comley (PhD)
>>>>>>> Research Scientist
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dr Jessica Comley
>>>>>> Lecturer: Environmental and Life Sciences
>>>>>> Faculty of Science
>>>>>> Universiti Brunei Darussalam
>>>>>>
>>>>>> Email: jessica.comley at ubd.edu.bn
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Dr Jessica Comley
>>>>> Lecturer: Environmental and Life Sciences
>>>>> Faculty of Science
>>>>> Universiti Brunei Darussalam
>>>>>
>>>>> Email: jessica.comley at ubd.edu.bn
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Dr Jessica Comley
>>>> Lecturer: Environmental and Life Sciences
>>>> Faculty of Science
>>>> Universiti Brunei Darussalam
>>>>
>>>> Email: jessica.comley at ubd.edu.bn
>>>>
>>>>
>>>
>>> --
>>> Dr Jessica Comley
>>> Lecturer: Environmental and Life Sciences
>>> Faculty of Science
>>> Universiti Brunei Darussalam
>>>
>>> Email: jessica.comley at ubd.edu.bn
>>>
>>>
>>>
>>
>> --
>> Dr Jessica Comley
>> Lecturer: Environmental and Life Sciences
>> Faculty of Science
>> Universiti Brunei Darussalam
>>
>> Email: jessica.comley at ubd.edu.bn
>>
>>
>>
>
> --
> Dr Jessica Comley
> Lecturer: Environmental and Life Sciences
> Faculty of Science
> Universiti Brunei Darussalam
>
> Email: jessica.comley at ubd.edu.bn
>
>

-- 
Dr Jessica Comley
Lecturer: Environmental and Life Sciences
Faculty of Science
Universiti Brunei Darussalam

Email: jessica.comley at ubd.edu.bn

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Sun Jul 30 17:36:10 2023
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Sun, 30 Jul 2023 17:36:10 +0200
Subject: [R-sig-ME] Nonsensical results in glmer (bglmer)
Message-ID: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>

Dear all,


I wonder if anyone can account for a counterintuitive result in my analyses
of a logistic regression run with glmer. The data, where I only use the
columns RESP as a binomial outcome coded as character (correct vs.
incorrect), Type as a factor with 2 levels where 'islands' constitutes the
reference level, Group as a factor with two levels where 'L1' constitutes
the reference level, and SUBJ and ITEM as random effects, is attached. In
this particular analysis I use bglmer but the same result ensues from glmer
or even a bernoulli brm analysis in the Bayesian framework (i.e. brms
package).

The following output shows that the group L1, the reference group, has a
lower probability of a correct score compared to L2. If the output is
garbled in your email, feel free to run the code yourself to get a clearer
picture. Under the fixed-effects of the output, we interpret the
coefficient -1.38 of r*elevel(masterPT$Group, ref = "L2")L1        -1.3802
    0.6907  -1.998  0.04567 * *to mean that the probability of scoring a
correct answer is approximately 34% lower in the L1 than the L2 group
(following Gelman and Hill, 2007, p.93) we divide the coeffecient -1.38
expressed in log odds by 4 to obtain an approximate corresponding
probability). This is counterintuitive because the L1 group is basically a
group of native speakers of Spanish, the language being tested, while the
L2 is a bilingual group being tested in Spanish as a foreign language which
they learned later in life. Even playing devil's advocate, a quick look at
a prop table or even the figures also attached shows the L1 group exhibit
lower counts of incorrect responses. In the figures, this can be easily
seen by comparing the amount of light blue splash for either of the Type
levels between the L1 and L2 groups. There is far less of a splash in the
L1 data which suggests they should statisticall have a higher chance of
selecting a correct response.

> freqmodel2<-bglmer(as.factor(RESP)~Type*relevel(masterPT$Group, ref =
"L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> summary(freqmodel2)
Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
Prior dev  : -5.3929

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: as.factor(RESP) ~ Type * relevel(masterPT$Group, ref = "L2") +
 (1 + Type | SUBJ) + (1 + Group | ITEM)
   Data: masterPT
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  1676.8   1734.1   -828.4   1656.8     2265

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.1192 -0.3447 -0.1315  0.1106  4.8595

Random effects:
 Groups Name        Variance Std.Dev. Corr
 SUBJ   (Intercept) 1.915    1.384
        Type2       1.642    1.281    -0.74
 ITEM   (Intercept) 8.970    2.995
        Group2      6.479    2.545    -0.74
Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35

Fixed effects:
                                            Estimate Std. Error z value
Pr(>|z|)
(Intercept)                                  -1.3577     0.4947  -2.745
 0.00606 **
Type2                                         1.4683     0.8340   1.760
 0.07834 .
relevel(masterPT$Group, ref = "L2")L1        -1.3802     0.6907  -1.998
 0.04567 *
Type2:relevel(masterPT$Group, ref = "L2")L1  -4.0366     1.2383  -3.260
 0.00112 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Type2  r(Pr="
Type2       -0.546
r(PT$G,r="L -0.325  0.157
T2:(PT$Gr="  0.151 -0.221 -0.442


What am I missing here?
Am I interpreting something wrong?

Many thanks in advance for any help,

Best,

Francesco Romano PhD

-------------- next part --------------
A non-text attachment was scrubbed...
Name: L2speakersoverallPT.png
Type: image/png
Size: 22795 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20230730/903c8b72/attachment-0002.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: L1speakersoverallPT.png
Type: image/png
Size: 23650 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20230730/903c8b72/attachment-0003.png>

From th|erry@onke||nx @end|ng |rom |nbo@be  Sun Jul 30 18:52:36 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Sun, 30 Jul 2023 18:52:36 +0200
Subject: [R-sig-ME] Nonsensical results in glmer (bglmer)
In-Reply-To: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>
References: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>
Message-ID: <CAJuCY5yQqi5fT2m6Nk8Y8_PJaDE2KmiUsbcaKjrvUE4i+iJb+w@mail.gmail.com>

Dear Francesco,

Don't use a factor response variable. Use either FALSE/TRUE or 0/1. Note
that as.factor() would use "correct" as the first level and "incorrect" as
the second level. Maybe the model uses the first levels as FALSE and
the second as TRUE. Setting TRUE and FALSE yourselves eliminates such
ambiguity.
I prefer to do any transformations like as.factor() or relevel() prior to
fitting the model. Then you have the same variables available in the
dataset (e.g. for plotting).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op zo 30 jul 2023 om 17:46 schreef Francesco Romano <fbromano77 at gmail.com>:

> Dear all,
>
>
> I wonder if anyone can account for a counterintuitive result in my analyses
> of a logistic regression run with glmer. The data, where I only use the
> columns RESP as a binomial outcome coded as character (correct vs.
> incorrect), Type as a factor with 2 levels where 'islands' constitutes the
> reference level, Group as a factor with two levels where 'L1' constitutes
> the reference level, and SUBJ and ITEM as random effects, is attached. In
> this particular analysis I use bglmer but the same result ensues from glmer
> or even a bernoulli brm analysis in the Bayesian framework (i.e. brms
> package).
>
> The following output shows that the group L1, the reference group, has a
> lower probability of a correct score compared to L2. If the output is
> garbled in your email, feel free to run the code yourself to get a clearer
> picture. Under the fixed-effects of the output, we interpret the
> coefficient -1.38 of r*elevel(masterPT$Group, ref = "L2")L1        -1.3802
>     0.6907  -1.998  0.04567 * *to mean that the probability of scoring a
> correct answer is approximately 34% lower in the L1 than the L2 group
> (following Gelman and Hill, 2007, p.93) we divide the coeffecient -1.38
> expressed in log odds by 4 to obtain an approximate corresponding
> probability). This is counterintuitive because the L1 group is basically a
> group of native speakers of Spanish, the language being tested, while the
> L2 is a bilingual group being tested in Spanish as a foreign language which
> they learned later in life. Even playing devil's advocate, a quick look at
> a prop table or even the figures also attached shows the L1 group exhibit
> lower counts of incorrect responses. In the figures, this can be easily
> seen by comparing the amount of light blue splash for either of the Type
> levels between the L1 and L2 groups. There is far less of a splash in the
> L1 data which suggests they should statisticall have a higher chance of
> selecting a correct response.
>
> > freqmodel2<-bglmer(as.factor(RESP)~Type*relevel(masterPT$Group, ref =
> "L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
> data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> > summary(freqmodel2)
> Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
>            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
> Prior dev  : -5.3929
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['bglmerMod']
>  Family: binomial  ( logit )
> Formula: as.factor(RESP) ~ Type * relevel(masterPT$Group, ref = "L2") +
>  (1 + Type | SUBJ) + (1 + Group | ITEM)
>    Data: masterPT
> Control: glmerControl(optimizer = "bobyqa")
>
>      AIC      BIC   logLik deviance df.resid
>   1676.8   1734.1   -828.4   1656.8     2265
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.1192 -0.3447 -0.1315  0.1106  4.8595
>
> Random effects:
>  Groups Name        Variance Std.Dev. Corr
>  SUBJ   (Intercept) 1.915    1.384
>         Type2       1.642    1.281    -0.74
>  ITEM   (Intercept) 8.970    2.995
>         Group2      6.479    2.545    -0.74
> Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
>
> Fixed effects:
>                                             Estimate Std. Error z value
> Pr(>|z|)
> (Intercept)                                  -1.3577     0.4947  -2.745
>  0.00606 **
> Type2                                         1.4683     0.8340   1.760
>  0.07834 .
> relevel(masterPT$Group, ref = "L2")L1        -1.3802     0.6907  -1.998
>  0.04567 *
> Type2:relevel(masterPT$Group, ref = "L2")L1  -4.0366     1.2383  -3.260
>  0.00112 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) Type2  r(Pr="
> Type2       -0.546
> r(PT$G,r="L -0.325  0.157
> T2:(PT$Gr="  0.151 -0.221 -0.442
>
>
> What am I missing here?
> Am I interpreting something wrong?
>
> Many thanks in advance for any help,
>
> Best,
>
> Francesco Romano PhD
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Mon Jul 31 08:38:04 2023
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Mon, 31 Jul 2023 08:38:04 +0200
Subject: [R-sig-ME] Fwd:  Nonsensical results in glmer (bglmer)
In-Reply-To: <CABX-QoGScApuyoXGQf9ycDWWHRTJW9PCg78ZscMCW8NkpiHuOA@mail.gmail.com>
References: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>
 <CAJuCY5yQqi5fT2m6Nk8Y8_PJaDE2KmiUsbcaKjrvUE4i+iJb+w@mail.gmail.com>
 <CABX-QoGScApuyoXGQf9ycDWWHRTJW9PCg78ZscMCW8NkpiHuOA@mail.gmail.com>
Message-ID: <CABX-QoFDu_h1TXzvDkjE4EZ0dzhP0QHUqzLbnshEsPG5Rv15dQ@mail.gmail.com>

Hello Thierry,

Unfortunately that doesn't seem to make any difference. The result is the
same: *Group2        -1.3802     0.6907  -1.998 0.045681 *  *
I paste the output below.

#create a new dummy variable recoding RESP#

> masterPT$Correct <- 0

#recode correct responses as a score of 1#

> masterPT$Correct<-ifelse(masterPT$RESP=="correct",1,0)

> summary(masterPT$Correct)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 0.0000  0.0000  1.0000  0.7371  1.0000  1.0000

> freqmodel4<-bglmer(Correct~Type*Group+(1+Type|SUBJ)+(1+Group|ITEM),
family = binomial(link="logit"), data=masterPT,
control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> summary(freqmodel4)
Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
Prior dev  : -5.3929

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: Correct ~ Type * Group + (1 + Type | SUBJ) + (1 + Group | ITEM)
   Data: masterPT
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  1676.8   1734.1   -828.4   1656.8     2265

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.8595 -0.1106  0.1315  0.3447  4.1192

Random effects:
 Groups Name        Variance Std.Dev. Corr
 SUBJ   (Intercept) 1.915    1.384
        Type2       1.642    1.281    -0.74
 ITEM   (Intercept) 8.970    2.995
        Group2      6.479    2.545    -0.74
Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    2.7380     0.7070   3.872 0.000108 ***
Type2          2.5683     1.3313   1.929 0.053707 .
Group2        -1.3802     0.6907  -1.998 0.045681 *
Type2:Group2  -4.0366     1.2383  -3.260 0.001115 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Type2  Group2
Type2       -0.446
Group2      -0.750  0.312
Type2:Grop2  0.326 -0.792 -0.442

Best,

Francesco Romano PhD


On Sun, Jul 30, 2023 at 6:53?PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Francesco,
>
> Don't use a factor response variable. Use either FALSE/TRUE or 0/1. Note
> that as.factor() would use "correct" as the first level and "incorrect" as
> the second level. Maybe the model uses the first levels as FALSE and
> the second as TRUE. Setting TRUE and FALSE yourselves eliminates such
> ambiguity.
> I prefer to do any transformations like as.factor() or relevel() prior to
> fitting the model. Then you have the same variables available in the
> dataset (e.g. for plotting).
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op zo 30 jul 2023 om 17:46 schreef Francesco Romano <fbromano77 at gmail.com
> >:
>
>> Dear all,
>>
>>
>> I wonder if anyone can account for a counterintuitive result in my
>> analyses
>> of a logistic regression run with glmer. The data, where I only use the
>> columns RESP as a binomial outcome coded as character (correct vs.
>> incorrect), Type as a factor with 2 levels where 'islands' constitutes the
>> reference level, Group as a factor with two levels where 'L1' constitutes
>> the reference level, and SUBJ and ITEM as random effects, is attached. In
>> this particular analysis I use bglmer but the same result ensues from
>> glmer
>> or even a bernoulli brm analysis in the Bayesian framework (i.e. brms
>> package).
>>
>> The following output shows that the group L1, the reference group, has a
>> lower probability of a correct score compared to L2. If the output is
>> garbled in your email, feel free to run the code yourself to get a clearer
>> picture. Under the fixed-effects of the output, we interpret the
>> coefficient -1.38 of r*elevel(masterPT$Group, ref = "L2")L1        -1.3802
>>     0.6907  -1.998  0.04567 * *to mean that the probability of scoring a
>> correct answer is approximately 34% lower in the L1 than the L2 group
>> (following Gelman and Hill, 2007, p.93) we divide the coeffecient -1.38
>> expressed in log odds by 4 to obtain an approximate corresponding
>> probability). This is counterintuitive because the L1 group is basically a
>> group of native speakers of Spanish, the language being tested, while the
>> L2 is a bilingual group being tested in Spanish as a foreign language
>> which
>> they learned later in life. Even playing devil's advocate, a quick look at
>> a prop table or even the figures also attached shows the L1 group exhibit
>> lower counts of incorrect responses. In the figures, this can be easily
>> seen by comparing the amount of light blue splash for either of the Type
>> levels between the L1 and L2 groups. There is far less of a splash in the
>> L1 data which suggests they should statisticall have a higher chance of
>> selecting a correct response.
>>
>> > freqmodel2<-bglmer(as.factor(RESP)~Type*relevel(masterPT$Group, ref =
>> "L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
>> data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
>> > summary(freqmodel2)
>> Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
>> common.scale = TRUE)
>>            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
>> common.scale = TRUE)
>> Prior dev  : -5.3929
>>
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['bglmerMod']
>>  Family: binomial  ( logit )
>> Formula: as.factor(RESP) ~ Type * relevel(masterPT$Group, ref = "L2") +
>>  (1 + Type | SUBJ) + (1 + Group | ITEM)
>>    Data: masterPT
>> Control: glmerControl(optimizer = "bobyqa")
>>
>>      AIC      BIC   logLik deviance df.resid
>>   1676.8   1734.1   -828.4   1656.8     2265
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -4.1192 -0.3447 -0.1315  0.1106  4.8595
>>
>> Random effects:
>>  Groups Name        Variance Std.Dev. Corr
>>  SUBJ   (Intercept) 1.915    1.384
>>         Type2       1.642    1.281    -0.74
>>  ITEM   (Intercept) 8.970    2.995
>>         Group2      6.479    2.545    -0.74
>> Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
>>
>> Fixed effects:
>>                                             Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                                  -1.3577     0.4947  -2.745
>>  0.00606 **
>> Type2                                         1.4683     0.8340   1.760
>>  0.07834 .
>> relevel(masterPT$Group, ref = "L2")L1        -1.3802     0.6907  -1.998
>>  0.04567 *
>> Type2:relevel(masterPT$Group, ref = "L2")L1  -4.0366     1.2383  -3.260
>>  0.00112 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>             (Intr) Type2  r(Pr="
>> Type2       -0.546
>> r(PT$G,r="L -0.325  0.157
>> T2:(PT$Gr="  0.151 -0.221 -0.442
>>
>>
>> What am I missing here?
>> Am I interpreting something wrong?
>>
>> Many thanks in advance for any help,
>>
>> Best,
>>
>> Francesco Romano PhD
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 31 09:44:14 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 31 Jul 2023 09:44:14 +0200
Subject: [R-sig-ME] Fwd: Nonsensical results in glmer (bglmer)
In-Reply-To: <CABX-QoFDu_h1TXzvDkjE4EZ0dzhP0QHUqzLbnshEsPG5Rv15dQ@mail.gmail.com>
References: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>
 <CAJuCY5yQqi5fT2m6Nk8Y8_PJaDE2KmiUsbcaKjrvUE4i+iJb+w@mail.gmail.com>
 <CABX-QoGScApuyoXGQf9ycDWWHRTJW9PCg78ZscMCW8NkpiHuOA@mail.gmail.com>
 <CABX-QoFDu_h1TXzvDkjE4EZ0dzhP0QHUqzLbnshEsPG5Rv15dQ@mail.gmail.com>
Message-ID: <CAJuCY5yP5oVXCBN7GqQaPbSp25onQt9htQd=WHF0ERr=X-BCeA@mail.gmail.com>

Dear Francesco,

The interaction in the fixed effects is very strong. The same goes for the
item variances. There is probably some quasi complete separation going on.

I would start by dropping the random slope from item. Then the random
intercept of item. Maybe even the type group interaction.

Best regards,

Thierry

Op ma 31 jul. 2023 08:38 schreef Francesco Romano <fbromano77 at gmail.com>:

> Hello Thierry,
>
> Unfortunately that doesn't seem to make any difference. The result is the
> same: *Group2        -1.3802     0.6907  -1.998 0.045681 *  *
> I paste the output below.
>
> #create a new dummy variable recoding RESP#
>
> > masterPT$Correct <- 0
>
> #recode correct responses as a score of 1#
>
> > masterPT$Correct<-ifelse(masterPT$RESP=="correct",1,0)
>
> > summary(masterPT$Correct)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  0.0000  0.0000  1.0000  0.7371  1.0000  1.0000
>
> > freqmodel4<-bglmer(Correct~Type*Group+(1+Type|SUBJ)+(1+Group|ITEM),
> family = binomial(link="logit"), data=masterPT,
> control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> > summary(freqmodel4)
> Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
>            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
> Prior dev  : -5.3929
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['bglmerMod']
>  Family: binomial  ( logit )
> Formula: Correct ~ Type * Group + (1 + Type | SUBJ) + (1 + Group | ITEM)
>    Data: masterPT
> Control: glmerControl(optimizer = "bobyqa")
>
>      AIC      BIC   logLik deviance df.resid
>   1676.8   1734.1   -828.4   1656.8     2265
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.8595 -0.1106  0.1315  0.3447  4.1192
>
> Random effects:
>  Groups Name        Variance Std.Dev. Corr
>  SUBJ   (Intercept) 1.915    1.384
>         Type2       1.642    1.281    -0.74
>  ITEM   (Intercept) 8.970    2.995
>         Group2      6.479    2.545    -0.74
> Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
>
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)    2.7380     0.7070   3.872 0.000108 ***
> Type2          2.5683     1.3313   1.929 0.053707 .
> Group2        -1.3802     0.6907  -1.998 0.045681 *
> Type2:Group2  -4.0366     1.2383  -3.260 0.001115 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) Type2  Group2
> Type2       -0.446
> Group2      -0.750  0.312
> Type2:Grop2  0.326 -0.792 -0.442
>
> Best,
>
> Francesco Romano PhD
>
>
> On Sun, Jul 30, 2023 at 6:53?PM Thierry Onkelinx <thierry.onkelinx at inbo.be
> >
> wrote:
>
> > Dear Francesco,
> >
> > Don't use a factor response variable. Use either FALSE/TRUE or 0/1. Note
> > that as.factor() would use "correct" as the first level and "incorrect"
> as
> > the second level. Maybe the model uses the first levels as FALSE and
> > the second as TRUE. Setting TRUE and FALSE yourselves eliminates such
> > ambiguity.
> > I prefer to do any transformations like as.factor() or relevel() prior to
> > fitting the model. Then you have the same variables available in the
> > dataset (e.g. for plotting).
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op zo 30 jul 2023 om 17:46 schreef Francesco Romano <
> fbromano77 at gmail.com
> > >:
> >
> >> Dear all,
> >>
> >>
> >> I wonder if anyone can account for a counterintuitive result in my
> >> analyses
> >> of a logistic regression run with glmer. The data, where I only use the
> >> columns RESP as a binomial outcome coded as character (correct vs.
> >> incorrect), Type as a factor with 2 levels where 'islands' constitutes
> the
> >> reference level, Group as a factor with two levels where 'L1'
> constitutes
> >> the reference level, and SUBJ and ITEM as random effects, is attached.
> In
> >> this particular analysis I use bglmer but the same result ensues from
> >> glmer
> >> or even a bernoulli brm analysis in the Bayesian framework (i.e. brms
> >> package).
> >>
> >> The following output shows that the group L1, the reference group, has a
> >> lower probability of a correct score compared to L2. If the output is
> >> garbled in your email, feel free to run the code yourself to get a
> clearer
> >> picture. Under the fixed-effects of the output, we interpret the
> >> coefficient -1.38 of r*elevel(masterPT$Group, ref = "L2")L1
> -1.3802
> >>     0.6907  -1.998  0.04567 * *to mean that the probability of scoring a
> >> correct answer is approximately 34% lower in the L1 than the L2 group
> >> (following Gelman and Hill, 2007, p.93) we divide the coeffecient -1.38
> >> expressed in log odds by 4 to obtain an approximate corresponding
> >> probability). This is counterintuitive because the L1 group is
> basically a
> >> group of native speakers of Spanish, the language being tested, while
> the
> >> L2 is a bilingual group being tested in Spanish as a foreign language
> >> which
> >> they learned later in life. Even playing devil's advocate, a quick look
> at
> >> a prop table or even the figures also attached shows the L1 group
> exhibit
> >> lower counts of incorrect responses. In the figures, this can be easily
> >> seen by comparing the amount of light blue splash for either of the Type
> >> levels between the L1 and L2 groups. There is far less of a splash in
> the
> >> L1 data which suggests they should statisticall have a higher chance of
> >> selecting a correct response.
> >>
> >> > freqmodel2<-bglmer(as.factor(RESP)~Type*relevel(masterPT$Group, ref =
> >> "L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
> >> data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> >> > summary(freqmodel2)
> >> Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale =
> cov,
> >> common.scale = TRUE)
> >>            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale =
> cov,
> >> common.scale = TRUE)
> >> Prior dev  : -5.3929
> >>
> >> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> Approximation) ['bglmerMod']
> >>  Family: binomial  ( logit )
> >> Formula: as.factor(RESP) ~ Type * relevel(masterPT$Group, ref = "L2") +
> >>  (1 + Type | SUBJ) + (1 + Group | ITEM)
> >>    Data: masterPT
> >> Control: glmerControl(optimizer = "bobyqa")
> >>
> >>      AIC      BIC   logLik deviance df.resid
> >>   1676.8   1734.1   -828.4   1656.8     2265
> >>
> >> Scaled residuals:
> >>     Min      1Q  Median      3Q     Max
> >> -4.1192 -0.3447 -0.1315  0.1106  4.8595
> >>
> >> Random effects:
> >>  Groups Name        Variance Std.Dev. Corr
> >>  SUBJ   (Intercept) 1.915    1.384
> >>         Type2       1.642    1.281    -0.74
> >>  ITEM   (Intercept) 8.970    2.995
> >>         Group2      6.479    2.545    -0.74
> >> Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
> >>
> >> Fixed effects:
> >>                                             Estimate Std. Error z value
> >> Pr(>|z|)
> >> (Intercept)                                  -1.3577     0.4947  -2.745
> >>  0.00606 **
> >> Type2                                         1.4683     0.8340   1.760
> >>  0.07834 .
> >> relevel(masterPT$Group, ref = "L2")L1        -1.3802     0.6907  -1.998
> >>  0.04567 *
> >> Type2:relevel(masterPT$Group, ref = "L2")L1  -4.0366     1.2383  -3.260
> >>  0.00112 **
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> Correlation of Fixed Effects:
> >>             (Intr) Type2  r(Pr="
> >> Type2       -0.546
> >> r(PT$G,r="L -0.325  0.157
> >> T2:(PT$Gr="  0.151 -0.221 -0.442
> >>
> >>
> >> What am I missing here?
> >> Am I interpreting something wrong?
> >>
> >> Many thanks in advance for any help,
> >>
> >> Best,
> >>
> >> Francesco Romano PhD
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Mon Jul 31 14:42:59 2023
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Mon, 31 Jul 2023 14:42:59 +0200
Subject: [R-sig-ME] Fwd: Nonsensical results in glmer (bglmer)
In-Reply-To: <CAGLQsKc5ay0jahJok4u7najHLuc2349Z+Otz8W7nJt0a9c6mfw@mail.gmail.com>
References: <CABX-QoGspynBw83CC4-unuLAY0hiQHdWd2_N6cKiGTnPFTPHLQ@mail.gmail.com>
 <CAJuCY5yQqi5fT2m6Nk8Y8_PJaDE2KmiUsbcaKjrvUE4i+iJb+w@mail.gmail.com>
 <CABX-QoGScApuyoXGQf9ycDWWHRTJW9PCg78ZscMCW8NkpiHuOA@mail.gmail.com>
 <CABX-QoFDu_h1TXzvDkjE4EZ0dzhP0QHUqzLbnshEsPG5Rv15dQ@mail.gmail.com>
 <CAGLQsKc5ay0jahJok4u7najHLuc2349Z+Otz8W7nJt0a9c6mfw@mail.gmail.com>
Message-ID: <CABX-QoESLrvatdvXE-9o_+46X8JKVipZ3D9uYTobWHGNncVg3w@mail.gmail.com>

Hello Tom,

Thank you so much for pitching in.

I haven't touched the levels for group so the ref level is L1-L2 as far as
I can see.

> contrasts(masterPT$Group)
   2
L1 0
L2 1

What seems strange to me is that the output is calling the levels 1 and 2
rather than
what they actually are, L1 and L2. This is new to me because in the past I
have always seen
something like GroupL1 or GroupL2 in the fixed-effects section of the
output.

Just in case, I reset the contrast scheme to treatment and ran the analysis
again (the binomial outcome was recoded as 0/1 as 'Correct'):

> contrasts(masterPT$Group) = contr.treatment(2)
> contrasts(masterPT$Type) = contr.treatment(2)
> freqmodel4<-bglmer(Correct~Type*Group+(1+Type|SUBJ)+(1+Group|ITEM),
family = binomial(link="logit"), data=masterPT,
control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> summary(freqmodel4)
Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
Prior dev  : -5.3929

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: Correct ~ Type * Group + (1 + Type | SUBJ) + (1 + Group | ITEM)
   Data: masterPT
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  1676.8   1734.1   -828.4   1656.8     2265

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.8595 -0.1106  0.1315  0.3447  4.1192

Random effects:
 Groups Name        Variance Std.Dev. Corr
 SUBJ   (Intercept) 1.915    1.384
        Type2       1.642    1.281    -0.74
 ITEM   (Intercept) 8.970    2.995
        Group2      6.479    2.545    -0.74
Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    2.7380     0.7070   3.872 0.000108 ***
Type2          2.5683     1.3313   1.929 0.053707 .
Group2        -1.3802     0.6907  -1.998 0.045681 *
Type2:Group2  -4.0366     1.2383  -3.260 0.001115 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Type2  Group2
Type2       -0.446
Group2      -0.750  0.312
Type2:Grop2  0.326 -0.792 -0.442

Now this has basically turn things around the way they should be. Group2 is
in fact the L1 group so the coefficient makes sense.
It seems like recoding the outcome to 0/1 from correct/incorrect did the
trick. I confirmed this by relevelling:

> freqmodel5<-bglmer(Correct~Type*relevel(masterPT$Group, ref =
"L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> summary(freqmodel5)
Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
Prior dev  : -5.3929

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: Correct ~ Type * relevel(masterPT$Group, ref = "L2") + (1 + Type |
     SUBJ) + (1 + Group | ITEM)
   Data: masterPT
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  1676.8   1734.1   -828.4   1656.8     2265

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.8595 -0.1106  0.1315  0.3447  4.1192

Random effects:
 Groups Name        Variance Std.Dev. Corr
 SUBJ   (Intercept) 1.915    1.384
        Type2       1.642    1.281    -0.74
 ITEM   (Intercept) 8.970    2.995
        Group2      6.479    2.545    -0.74
Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35

Fixed effects:
                                            Estimate Std. Error z value
Pr(>|z|)
(Intercept)                                   1.3577     0.4946   2.745
 0.00605 **
Type2                                        -1.4683     0.8340  -1.761
 0.07832 .
relevel(masterPT$Group, ref = "L2")L1         1.3802     0.6906   1.999
 0.04566 *
Type2:relevel(masterPT$Group, ref = "L2")L1   4.0366     1.2381   3.260
 0.00111 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Type2  r(Pr="
Type2       -0.546
r(PT$G,r="L -0.325  0.157
T2:(PT$Gr="  0.151 -0.221 -0.442

The coefficient now correctly indicates a higher chance of scoring a
correct answer when going from the L2 to the L1 group by 34%.

Thanks Tom and Thierry!



Francesco Romano PhD


On Mon, Jul 31, 2023 at 8:52?AM Tom Fritzsche <tom.fritzsche at uni-potsdam.de>
wrote:

> Dear Francsco,
>
> In your new model, it seems you don't set your group reference level
> to 2 (unless you did that independently before, which I would also
> recommend).
> Could it be that now group 1 (the native language group) is the
> reference level so that the results make sense?
> You could check by looking at
> contrasts(masterPT$Group)
> to see what the contrast specification is.
>
> Best,
> Tom
>
> ---
> Tom Fritzsche (pronoun: he)
> University of Potsdam
> Department of Linguistics
> Karl-Liebknecht-Str. 24-25
> 14476 Potsdam
> Germany
>
> Office:  House 14 / Room 1.40
> Phone: +49 331 977 2296
> Fax:      +49 331 977 2095
> Email:   tom.fritzsche at uni-potsdam.de
> https://www.ling.uni-potsdam.de/~fritzsche/
> https://orcid.org/0000-0002-7917-514X
>
> On Mon, 31 Jul 2023 at 08:38, Francesco Romano <fbromano77 at gmail.com>
> wrote:
> >
> > Hello Thierry,
> >
> > Unfortunately that doesn't seem to make any difference. The result is the
> > same: *Group2        -1.3802     0.6907  -1.998 0.045681 *  *
> > I paste the output below.
> >
> > #create a new dummy variable recoding RESP#
> >
> > > masterPT$Correct <- 0
> >
> > #recode correct responses as a score of 1#
> >
> > > masterPT$Correct<-ifelse(masterPT$RESP=="correct",1,0)
> >
> > > summary(masterPT$Correct)
> >    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >  0.0000  0.0000  1.0000  0.7371  1.0000  1.0000
> >
> > > freqmodel4<-bglmer(Correct~Type*Group+(1+Type|SUBJ)+(1+Group|ITEM),
> > family = binomial(link="logit"), data=masterPT,
> > control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> > > summary(freqmodel4)
> > Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> > common.scale = TRUE)
> >            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale = cov,
> > common.scale = TRUE)
> > Prior dev  : -5.3929
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['bglmerMod']
> >  Family: binomial  ( logit )
> > Formula: Correct ~ Type * Group + (1 + Type | SUBJ) + (1 + Group | ITEM)
> >    Data: masterPT
> > Control: glmerControl(optimizer = "bobyqa")
> >
> >      AIC      BIC   logLik deviance df.resid
> >   1676.8   1734.1   -828.4   1656.8     2265
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -4.8595 -0.1106  0.1315  0.3447  4.1192
> >
> > Random effects:
> >  Groups Name        Variance Std.Dev. Corr
> >  SUBJ   (Intercept) 1.915    1.384
> >         Type2       1.642    1.281    -0.74
> >  ITEM   (Intercept) 8.970    2.995
> >         Group2      6.479    2.545    -0.74
> > Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
> >
> > Fixed effects:
> >              Estimate Std. Error z value Pr(>|z|)
> > (Intercept)    2.7380     0.7070   3.872 0.000108 ***
> > Type2          2.5683     1.3313   1.929 0.053707 .
> > Group2        -1.3802     0.6907  -1.998 0.045681 *
> > Type2:Group2  -4.0366     1.2383  -3.260 0.001115 **
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) Type2  Group2
> > Type2       -0.446
> > Group2      -0.750  0.312
> > Type2:Grop2  0.326 -0.792 -0.442
> >
> > Best,
> >
> > Francesco Romano PhD
> >
> >
> > On Sun, Jul 30, 2023 at 6:53?PM Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> > wrote:
> >
> > > Dear Francesco,
> > >
> > > Don't use a factor response variable. Use either FALSE/TRUE or 0/1.
> Note
> > > that as.factor() would use "correct" as the first level and
> "incorrect" as
> > > the second level. Maybe the model uses the first levels as FALSE and
> > > the second as TRUE. Setting TRUE and FALSE yourselves eliminates such
> > > ambiguity.
> > > I prefer to do any transformations like as.factor() or relevel() prior
> to
> > > fitting the model. Then you have the same variables available in the
> > > dataset (e.g. for plotting).
> > >
> > > Best regards,
> > >
> > > ir. Thierry Onkelinx
> > > Statisticus / Statistician
> > >
> > > Vlaamse Overheid / Government of Flanders
> > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > > FOREST
> > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > > thierry.onkelinx at inbo.be
> > > Havenlaan 88 bus 73, 1000 Brussel
> > > www.inbo.be
> > >
> > >
> > >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > To call in the statistician after the experiment is done may be no more
> > > than asking him to perform a post-mortem examination: he may be able
> to say
> > > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does
> not
> > > ensure that a reasonable answer can be extracted from a given body of
> data.
> > > ~ John Tukey
> > >
> > >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > <https://www.inbo.be>
> > >
> > >
> > > Op zo 30 jul 2023 om 17:46 schreef Francesco Romano <
> fbromano77 at gmail.com
> > > >:
> > >
> > >> Dear all,
> > >>
> > >>
> > >> I wonder if anyone can account for a counterintuitive result in my
> > >> analyses
> > >> of a logistic regression run with glmer. The data, where I only use
> the
> > >> columns RESP as a binomial outcome coded as character (correct vs.
> > >> incorrect), Type as a factor with 2 levels where 'islands'
> constitutes the
> > >> reference level, Group as a factor with two levels where 'L1'
> constitutes
> > >> the reference level, and SUBJ and ITEM as random effects, is
> attached. In
> > >> this particular analysis I use bglmer but the same result ensues from
> > >> glmer
> > >> or even a bernoulli brm analysis in the Bayesian framework (i.e. brms
> > >> package).
> > >>
> > >> The following output shows that the group L1, the reference group,
> has a
> > >> lower probability of a correct score compared to L2. If the output is
> > >> garbled in your email, feel free to run the code yourself to get a
> clearer
> > >> picture. Under the fixed-effects of the output, we interpret the
> > >> coefficient -1.38 of r*elevel(masterPT$Group, ref = "L2")L1
> -1.3802
> > >>     0.6907  -1.998  0.04567 * *to mean that the probability of
> scoring a
> > >> correct answer is approximately 34% lower in the L1 than the L2 group
> > >> (following Gelman and Hill, 2007, p.93) we divide the coeffecient
> -1.38
> > >> expressed in log odds by 4 to obtain an approximate corresponding
> > >> probability). This is counterintuitive because the L1 group is
> basically a
> > >> group of native speakers of Spanish, the language being tested, while
> the
> > >> L2 is a bilingual group being tested in Spanish as a foreign language
> > >> which
> > >> they learned later in life. Even playing devil's advocate, a quick
> look at
> > >> a prop table or even the figures also attached shows the L1 group
> exhibit
> > >> lower counts of incorrect responses. In the figures, this can be
> easily
> > >> seen by comparing the amount of light blue splash for either of the
> Type
> > >> levels between the L1 and L2 groups. There is far less of a splash in
> the
> > >> L1 data which suggests they should statisticall have a higher chance
> of
> > >> selecting a correct response.
> > >>
> > >> > freqmodel2<-bglmer(as.factor(RESP)~Type*relevel(masterPT$Group, ref
> =
> > >> "L2")+(1+Type|SUBJ)+(1+Group|ITEM), family = binomial(link="logit"),
> > >> data=masterPT, control=glmerControl(optimizer = "bobyqa"), nAGQ=1)
> > >> > summary(freqmodel2)
> > >> Cov prior  : SUBJ ~ wishart(df = 4.5, scale = Inf, posterior.scale =
> cov,
> > >> common.scale = TRUE)
> > >>            : ITEM ~ wishart(df = 4.5, scale = Inf, posterior.scale =
> cov,
> > >> common.scale = TRUE)
> > >> Prior dev  : -5.3929
> > >>
> > >> Generalized linear mixed model fit by maximum likelihood (Laplace
> > >> Approximation) ['bglmerMod']
> > >>  Family: binomial  ( logit )
> > >> Formula: as.factor(RESP) ~ Type * relevel(masterPT$Group, ref = "L2")
> +
> > >>  (1 + Type | SUBJ) + (1 + Group | ITEM)
> > >>    Data: masterPT
> > >> Control: glmerControl(optimizer = "bobyqa")
> > >>
> > >>      AIC      BIC   logLik deviance df.resid
> > >>   1676.8   1734.1   -828.4   1656.8     2265
> > >>
> > >> Scaled residuals:
> > >>     Min      1Q  Median      3Q     Max
> > >> -4.1192 -0.3447 -0.1315  0.1106  4.8595
> > >>
> > >> Random effects:
> > >>  Groups Name        Variance Std.Dev. Corr
> > >>  SUBJ   (Intercept) 1.915    1.384
> > >>         Type2       1.642    1.281    -0.74
> > >>  ITEM   (Intercept) 8.970    2.995
> > >>         Group2      6.479    2.545    -0.74
> > >> Number of obs: 2275, groups:  SUBJ, 65; ITEM, 35
> > >>
> > >> Fixed effects:
> > >>                                             Estimate Std. Error z
> value
> > >> Pr(>|z|)
> > >> (Intercept)                                  -1.3577     0.4947
> -2.745
> > >>  0.00606 **
> > >> Type2                                         1.4683     0.8340
>  1.760
> > >>  0.07834 .
> > >> relevel(masterPT$Group, ref = "L2")L1        -1.3802     0.6907
> -1.998
> > >>  0.04567 *
> > >> Type2:relevel(masterPT$Group, ref = "L2")L1  -4.0366     1.2383
> -3.260
> > >>  0.00112 **
> > >> ---
> > >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >>
> > >> Correlation of Fixed Effects:
> > >>             (Intr) Type2  r(Pr="
> > >> Type2       -0.546
> > >> r(PT$G,r="L -0.325  0.157
> > >> T2:(PT$Gr="  0.151 -0.221 -0.442
> > >>
> > >>
> > >> What am I missing here?
> > >> Am I interpreting something wrong?
> > >>
> > >> Many thanks in advance for any help,
> > >>
> > >> Best,
> > >>
> > >> Francesco Romano PhD
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From 2779300S @end|ng |rom @tudent@g|@@@c@uk  Thu Aug 10 17:42:57 2023
From: 2779300S @end|ng |rom @tudent@g|@@@c@uk (Xuan Sun (student))
Date: Thu, 10 Aug 2023 15:42:57 +0000
Subject: [R-sig-ME] question about nested random effect
Message-ID: <LO2P302MB000904FD00CF809F4B6836178013A@LO2P302MB0009.GBRP302.PROD.OUTLOOK.COM>

Hi everyone

I do a research about the relationship between kid age and kids' height and other variables.
In my data, one mother has many kid, and a kid only have one mom.
I have consider the nested kid and mom. How could I consider the autocorrelation of each kid.
It is a 3 levels model, It is too hard for me.

Question 1: This is my modle now, how chould I correct it to consider the autocorrelation? In my opinion, I have to add a new level age which is nested in kid.id.(z-score here is standsrd children's height)
lmm_4<-lmer(weight.z.score ~ KID.AGE.YEARS
+ (1|MOM.ID/KID.ID),
data=data_calculate_without_na)

Question 2: When I add more variables, where should I but these variables? Is it right?
lmm_age_sib_WAZ<- gls(weight.z.score ~ KID.AGE.YEARS
+ as.factor(OLDER.SIBLINGS)
+ as.factor(YOUNG.SIBS)
+ KID.AGE.YEARS:OLDER.SIBLINGS
+ KID.AGE.YEARS:YOUNG.SIBS,
correlation = corCompSymm(form = ~ 1+KID.AGE.YEARS|MOM.ID/KID.ID),
data = HAZ_Sign_sib)

Qestion 3: when I want to fit it using gamm, what should I do to fit model consider these three levels. where should I add nested level in this model
gamm_age_sib_WAZ <-gamm(weight.z.score ~ s(KID.AGE.YEARS, bs = "ps",k=5)
+ s(as.factor(HAZ_Sign_sib$OLDER.SIBLINGS),
bs = "re",k=length(unique(HAZ_Sign_sib$OLDER.SIBLINGS)))
+ s(as.factor(HAZ_Sign_sib$YOUNG.SIBS),
bs = "re",k=length(unique(HAZ_Sign_sib$YOUNG.SIBS)))
+ te(KID.AGE.YEARS,by=(OLDER.SIBLINGS))
+ te(KID.AGE.YEARS,by=(YOUNG.SIBS)),
data = HAZ_Sign_sib)


If you can reply me, thank you so much!!


Best wishes

Xuan


	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Fri Aug 11 10:03:04 2023
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Fri, 11 Aug 2023 08:03:04 +0000
Subject: [R-sig-ME] question about nested random effect
In-Reply-To: <LO2P302MB000904FD00CF809F4B6836178013A@LO2P302MB0009.GBRP302.PROD.OUTLOOK.COM>
References: <LO2P302MB000904FD00CF809F4B6836178013A@LO2P302MB0009.GBRP302.PROD.OUTLOOK.COM>
Message-ID: <1d1aebaba4ff432fa745a5ee516d990c@qimrberghofer.edu.au>

You might look at the pedigreemm package, and the examples they analyse there. Because you only have nuclear families, the default genetic model pedigreemm 
uses is equivalent to what you want for the familial correlations.

Cheers, David Duffy.

> I do a research about the relationship between kid age and kids' height and other variables.
> In my data, one mother has many kid, and a kid only have one mom.
> I have consider the nested kid and mom. How could I consider the autocorrelation of each kid.
> It is a 3 levels model, It is too hard for me.


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Fri Aug 11 14:18:55 2023
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Fri, 11 Aug 2023 13:18:55 +0100
Subject: [R-sig-ME] Introduction To Mixed Models Using R And Rstudio (IMMR07)
Message-ID: <CAEsSYzwwmqxVKf7F5S+9jHA+L3zbh7Ka4fG-sYWxc48LKHhT9g@mail.gmail.com>

ONLINE COURSE ? Introduction To Mixed Models Using R And Rstudio (IMMR07)

https://www.prstatistics.com/course/introduction-to-mixed-models-using-r-and-rstudio-immr07/

24th - 26th October

Please feel free to share!

Limited early bird tickets available prioced @ ?150.00

Courses are recorded to accommodate different time zones. All attendees
will have access to recordings for a further 3 months after the course to
revisit any of the classes.

*COURSE OVERVIEW - *In this two day course, we provide a comprehensive
practical and theoretical introduction to multilevel models, also known as
hierarchical or mixed effects models. We will focus primarily on multilevel
linear models, but also cover multilevel generalized linear models.
Likewise, we will also describe Bayesian approaches to multilevel
modelling. On Day 1, we will begin by focusing on random effects multilevel
models. These models make it clear how multilevel models are in fact models
of models. In addition, random effects models serve as a solid basis for
understanding mixed effects, i.e. fixed and random effects, models. In this
coverage of random effects, we will also cover the important concepts of
statistical shrinkage in the estimation of effects, as well as intraclass
correlation. We then proceed to cover linear mixed effects models,
particularly focusing on varying intercept and/or varying slopes
regresssion models. On Day 2, we cover further aspects of linear mixed
effects models, including multilevel models for nested and crossed data
data, and group level predictor variables. On Day 2, we also cover Bayesian
approaches to multilevel levels using the brms R package.

Please email oliverhooker at prstatistics.com with any questions.

-- 

Oliver Hooker PhD.
PR statistics

	[[alternative HTML version deleted]]


From i@io m@iii@g oii phys@ii@-courses@org  Fri Aug 11 18:18:36 2023
From: i@io m@iii@g oii phys@ii@-courses@org (i@io m@iii@g oii phys@ii@-courses@org)
Date: Fri, 11 Aug 2023 18:18:36 +0200 (CEST)
Subject: [R-sig-ME] 
 Generalised Linear Mixed Models in R - October 9-13, 2023
Message-ID: <1691770716.735532693@webmail.jimdo.com>


Dear all,
We're excited to introduce our upcoming course on (Generalised) Linear Mixed Models in R, scheduled to take place from October 9th to 13th, 2023. This intensive online course is tailored to enhance your expertise in statistical analysis and data modeling.
 
**Course Overview:**
The (Generalised) Linear Mixed Models (GLMMs) framework is a cornerstone in statistical analysis. It extends traditional models by incorporating random effects, variance structures, and correlation structures. Designed for graduate students and researchers, this course will empower you to confidently specify, interpret, and validate linear and generalized linear mixed models. The practical emphasis is on real-world applications using R, with a focus on the lme4 and glmmTMB regression packages.
 
**Target Audience and Assumed Background:**
If you're familiar with generalized linear regression models in R and seek to elevate your proficiency, this course is ideal for you. The curriculum encompasses a review of foundational concepts, ensuring a seamless transition to mastering the GLMM framework. However, if you're seeking a more comprehensive introduction to regression analysis, our course "Generalized Linear Models as a unified framework for data analysis in R" might be better suited.
 
**Learning Outcomes:**
Upon completion, you will achieve the following:
1. Gain a deepened understanding of core regression concepts, from interactions to ANOVA.
2. Grasp the components of the GLMM framework, including distributions, random effects, and correlation structures.
3. Select the appropriate model structure for your applied analysis using lme4 and glmmTMB in R.
4. Visualize fitted GLMMs with effects and assess model assumptions using DHARMa.
 
 
For more information and to secure your spot, please visit: [ https://www.physalia-courses.org/courses-workshops/glmms-in-r/ ]( https://www.physalia-courses.org/courses-workshops/glmms-in-r/ ) 
 
We look forward to welcoming you to the course and embarking on this educational journey together.
Best regards,
Valentina
 
 
Valentina Sardina
Course coordinator
info at physalia-courses.org
[ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ ) 
mobile: +49 17645230846
Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon ]( https://mas.to/@PhysaliaCourses )
	[[alternative HTML version deleted]]


From c@roz @end|ng |rom zed@t@|u-ber||n@de  Mon Aug 14 14:20:24 2023
From: c@roz @end|ng |rom zed@t@|u-ber||n@de (Caroline Zanchi)
Date: Mon, 14 Aug 2023 14:20:24 +0200
Subject: [R-sig-ME] co-occurence of mutations as explanatory and response
 variable ?
Message-ID: <8c71ca03-df8b-590d-2604-4e30c5bb76c1@zedat.fu-berlin.de>

Hello,

I hope I am still in the topic of this mailing list !

A colleague of mine has performed experimental evolution of some 
bacteria populations in the presence of several antimicrobial agents. 
The experiment has been replicated twice (2 blocks containing each 3 
replicate populations per condition). We have resequenced some 
individual colonies of these populations at the end of the experimental 
evolution.

There were 5 genes which were overrepresented as having snps. In some 
clones, there were several of these 5 genes which showed snps. In the 
end, my colleague measured the difference in minimum inhibitory 
concentration reached at the end of the evolution versus what it was at 
the beginning (MIC fold-change). The sample size is not so high in the 
end, which is typical of this kind of experiment, but I would still like 
to be able to analyze whether some combinations of mutations were 
selected in some regimes.

My dataset contains one column per each of these 5 genes with ?0? 
meaning no snp, ?1? meaning snp. I also added one column which is a 
concatenation of the affected genes, i.e. the mutations combination. 
Some combinations emerge only once of course... I attach my dataset to 
this email, it might be much easier to understand than my description :)

I have performed a clogit regression with the survival package with each 
of the 5 genes in turn as a response variable (presence/absence), and 
the other remaining genes as explanatory variables (presence/absence), 
with the block as a random factor.

I would not be surprised if there was a much better alternative, which 
is why I am asking the opinion of the community. I would really love to 
be able to ask for combination of mutations + regime +(1|block) for 
example.

Ultimately it would be great to know whether the difference in MIC 
between end and beginning is affected by the mutation combination or 
individual mutations !

I thank you in advance for any feedback !

Caroline

From ondo@@mue|10 @end|ng |rom gm@||@com  Mon Aug 14 15:16:27 2023
From: ondo@@mue|10 @end|ng |rom gm@||@com (Samuel Ondo)
Date: Mon, 14 Aug 2023 15:16:27 +0200
Subject: [R-sig-ME] Estimation of coefficients in MCMCglmm
Message-ID: <CAC9HA+ooO7YOf1rrytj86xjOVdeeq+a6rwJ_R=pTojDqLD0w1g@mail.gmail.com>

Hello,
Am I talking to the author of the MCMCGlmm  packages ?
If it's right , I would have a question.
When one adjusts an ordinal model with MCMCglmm, what coefficiens are
estimated (coefficients accessible with model$Sol) : -beta_i or beta_i.
Indeed, I got a coefficient with an unexpected sign.
Cordiallu

	[[alternative HTML version deleted]]


From w|||thek|w| @end|ng |rom gm@||@com  Fri Aug 18 07:06:41 2023
From: w|||thek|w| @end|ng |rom gm@||@com (Will Hopkins)
Date: Fri, 18 Aug 2023 17:06:41 +1200
Subject: [R-sig-ME] Random effects in R vs SAS
Message-ID: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>

I am a SAS user, and I have just finished a near-final draft of an article
about identifying and specifying fixed and random effects for mixed models
in SAS. At the moment, all I say about R is this: "To all users of the R
stats package, my apologies: a few years ago, I found the mixed model in R
too limiting, and I struggled with the coding. I hope someone with R smarts
will consider adapting my programs and publishing them here." I really would
like to know if the limitations (or at least, what I consider to be
limitations) have been addressed, so I can be more specific in my article.
Specifically can anyone answer these questions?

 

1. Can you specify negative variance for random effects in R? (That doesn't
apply to the variances representing residuals, which are never negative).

 

2. Can you get trustworthy estimates of standard errors for the
random-effect and residual variances in R? (By trustworthy, I guess I mean
the same as SAS's, but it could mean that someone has shown that the
confidence intervals derived with the SEs have good coverage, assuming
normality for the variances representing random effects and chi-squared for
variances representing residuals.) 

 

3. Does R have the equivalent of the repeated statement in SAS, whereby you
can specify a repeated measure with an unstructured or other covariance
matrix? (e.g., repeated Time/subject=SubjectID type=un. This statement works
more reliably than the random statement in SAS with small sample sizes, but
it doesn't produce residual variances, not directly anyway.)

 

4. Does R have the equivalent of the group= option in SAS, whereby you can
specify separate estimates of random-effect variances and covariances,
and/or separate estimates of residuals, for different groups? (e.g., random
SubjectID/group=Sex; repeated/group=Sex;)

 

The draft article is available at
https://sportsci.org/2023/EffectsModels.htm. It's not published yet (i.e.,
not linked to the Sportscience homepage yet). I would be grateful for any
feedback. I can incorporate more about R and would love someone to provide R
code for the programs I have published. See below for the title and
abstract.

 

Will

 

How to Identify and Specify Fixed and Random Effects for Linear Mixed Models
in the Statistical Analysis System

 

Most analyses require linear mixed modeling to properly account not only for
mean effects but also for sources of variability and error in the data. In
linear mixed models, means and their differences are specified with fixed
effects, while variabilities and errors are specified with random effects
(including residuals) and are summarized as standard deviations. In this
tutorial article, I explain how variables represent effects in linear mixed
models and how identifying clusters of observations in a dataset is the key
to identifying the fixed and random effects. I also provide programs written
in the language of the Statistical analysis system to simulate data and
analyze them with the general linear mixed model, Proc Mixed, which is used
when the dependent variable is continuous. The analyses include simple
linear regression, reliability and time series, controlled trials, and
combined within- and between-subject modeling. Finally, I explain how
dependent variables representing counts or proportions require generalized
linear mixed models, realized in SAS with Proc Glimmix, where the main
difference is the specification of the residuals.

 


	[[alternative HTML version deleted]]


From jhm@|ndon@|d @end|ng |rom gm@||@com  Fri Aug 18 10:01:29 2023
From: jhm@|ndon@|d @end|ng |rom gm@||@com (John H Maindonald)
Date: Fri, 18 Aug 2023 20:01:29 +1200
Subject: [R-sig-ME] Random effects in R vs SAS
In-Reply-To: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
References: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
Message-ID: <4C7D2D05-9903-44B3-A55E-C4DD179993B4@gmail.com>

Will, an immediate comment is that what may be accommodated are
variance ?components'.  They are not the variances of any identifiable
quantity. It is surely misleading to call them variances.  For residuals,
the component is at the same time a variance.  With a suitably balanced
experimental design, one can work with the function aov() to obtain a
breakdown from which the negative component can be extracted,

The following inflates within block variances ? it mirrors a context
where blocks have been designed to be more heterogenous than
plots generally.

> set.seed(29)
   library(lme4)
   df0 <- data.frame(block=rep(1:100, rep(10,100)), trt=rep(1:5,200),
                  y=rnorm(1000,4,1))
  ## Plot variances are all set to 1.0
  df0$y <- df0$y + df0$trt*0.1  ## Differences between treatments
  ## Add systematic within block variation
  ## 10 different systematic effects for the 10 different plots in
  ## a block are randomly assigned  
  systeff <- 0.4*(1:10)
  df <- df0
  for(i in 1:100)df$y[df$block==i] <- df$y[df$block==i]+sample(systeff)
  ## sample does the random assignment
  df$block = factor(df$block); df$trt =factor(df$trt)
  y.aov <- aov(y ~ trt +Error(block), data=df)

> summary(y.aov)

Error: block
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 99  127.7    1.29               

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
trt         4   23.5   5.865   2.302 0.0569
Residuals 896 2282.8   2.548      

> y.lmer <- lmer(y~trt + (1|block), data=df)
boundary (singular) fit: see help('isSingular?)

> summary(y.lmer)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ trt + (1 | block)
   Data: df

REML criterion at convergence: 3776.3

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-2.78060 -0.72441  0.04553  0.70139  2.79109 

Random effects:
 Groups   Name        Variance Std.Dev.
 block    (Intercept) 0.000    0.000   
 Residual             2.537    1.593   
Number of obs: 1000, groups:  block, 100

. . .

> library(nlme)
> df.lme <- lme(y~trt, random=~1|block, data=df)
> ## No complaints!  This is a worry.

> summary(df.lme)
Linear mixed-effects model fit by REML
  Data: df 
       AIC      BIC    logLik
  3790.336 3824.655 -1888.168

Random effects:
 Formula: ~1 | block
         (Intercept) Residual
StdDev: 6.727467e-05 1.592659

Fixed effects:  y ~ trt 
               Value Std.Error  DF  t-value p-value
(Intercept) 6.096161 0.1126180 896 54.13131  0.0000
trt2        0.305667 0.1592659 896  1.91922  0.0553
trt3        0.418814 0.1592659 896  2.62965  0.0087
trt4        0.515445 0.1592659 896  3.23638  0.0013
trt5        0.561525 0.1592659 896  3.52571  0.0004

. . .

In principle, one should be able to set up a within blocks correlation
structure that accommodates the negative component of variance.
John Maindonald
Statistics Reseach Associates
Wellington NZ.

> On 18/08/2023, at 17:06, Will Hopkins <willthekiwi at gmail.com> wrote:
> 
> I am a SAS user, and I have just finished a near-final draft of an article
> about identifying and specifying fixed and random effects for mixed models
> in SAS. At the moment, all I say about R is this: "To all users of the R
> stats package, my apologies: a few years ago, I found the mixed model in R
> too limiting, and I struggled with the coding. I hope someone with R smarts
> will consider adapting my programs and publishing them here." I really would
> like to know if the limitations (or at least, what I consider to be
> limitations) have been addressed, so I can be more specific in my article.
> Specifically can anyone answer these questions?
> 
> 
> 
> 1. Can you specify negative variance for random effects in R? (That doesn't
> apply to the variances representing residuals, which are never negative).
> 
> 
> 
> 2. Can you get trustworthy estimates of standard errors for the
> random-effect and residual variances in R? (By trustworthy, I guess I mean
> the same as SAS's, but it could mean that someone has shown that the
> confidence intervals derived with the SEs have good coverage, assuming
> normality for the variances representing random effects and chi-squared for
> variances representing residuals.) 
> 
> 
> 
> 3. Does R have the equivalent of the repeated statement in SAS, whereby you
> can specify a repeated measure with an unstructured or other covariance
> matrix? (e.g., repeated Time/subject=SubjectID type=un. This statement works
> more reliably than the random statement in SAS with small sample sizes, but
> it doesn't produce residual variances, not directly anyway.)
> 
> 
> 
> 4. Does R have the equivalent of the group= option in SAS, whereby you can
> specify separate estimates of random-effect variances and covariances,
> and/or separate estimates of residuals, for different groups? (e.g., random
> SubjectID/group=Sex; repeated/group=Sex;)
> 
> 
> 
> The draft article is available at
> https://sportsci.org/2023/EffectsModels.htm. It's not published yet (i.e.,
> not linked to the Sportscience homepage yet). I would be grateful for any
> feedback. I can incorporate more about R and would love someone to provide R
> code for the programs I have published. See below for the title and
> abstract.
> 
> 
> 
> Will
> 
> 
> 
> How to Identify and Specify Fixed and Random Effects for Linear Mixed Models
> in the Statistical Analysis System
> 
> 
> 
> Most analyses require linear mixed modeling to properly account not only for
> mean effects but also for sources of variability and error in the data. In
> linear mixed models, means and their differences are specified with fixed
> effects, while variabilities and errors are specified with random effects
> (including residuals) and are summarized as standard deviations. In this
> tutorial article, I explain how variables represent effects in linear mixed
> models and how identifying clusters of observations in a dataset is the key
> to identifying the fixed and random effects. I also provide programs written
> in the language of the Statistical analysis system to simulate data and
> analyze them with the general linear mixed model, Proc Mixed, which is used
> when the dependent variable is continuous. The analyses include simple
> linear regression, reliability and time series, controlled trials, and
> combined within- and between-subject modeling. Finally, I explain how
> dependent variables representing counts or proportions require generalized
> linear mixed models, realized in SAS with Proc Glimmix, where the main
> difference is the specification of the residuals.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From mvez|n@ @end|ng |rom u@|bert@@c@  Tue Aug 22 00:52:40 2023
From: mvez|n@ @end|ng |rom u@|bert@@c@ (Melanie Dickie)
Date: Mon, 21 Aug 2023 16:52:40 -0600
Subject: [R-sig-ME] Random slope specification with interactions in fixed
 effects
Message-ID: <CAJn6-XAEdNf7Tf7woQLk42g0GYx4y5u_L3xF4UYEJTG4RDyfMA@mail.gmail.com>

Hello,

I am attempting to evaluate the influence of two main continuous
independent variables (?winter severity? aka WinterSeverity and ?% habitat
alteration? aka Alteration), and their interaction, on a continuous
dependent variable (?density?, measured as #animals/km2). I have reason to
suspect the impact of these two variables also depends on the underlying
habitat context (measured using a continuous variable, let?s say the
Normalized Difference Vegetation Index ?NDVI?). From this, my base model is:

Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity

Density is sampled in quadrats, with multiple quadrats clumped together in
?clusters?; such that the ?cluster? is the true sample unit, if you will,
and the quadrats are replicated samples of each ?cluster?.

One complicating twist is that the independent variables are all measured
at each ?cluster?, such that there is no variation in the independent
variables within each cluster, but there is variation among clusters. Each
of the quadrats within each cluster have different density values, but the
same value for winter severity, % habitat alteration, and NDVI.

Putting the twist aside for a moment, my understanding is that I should be
using a random slope model to gain inference at the cluster level. The
random effects would allow the covariate effects to vary among clusters and
the fixed effects would capture the average effect of each covariate across
clusters. From this, the full specification of the model is (with
appropriate specification of the family and link):

Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
+ ( NDVI*Alteration  |Cluster) + ( NDVI*WinterSeverity  |Cluster) + (
NDVI*WinterSeverity  |Cluster)

This model, however, appears to be too complex for my data and will not
converge. To that end, I have also considered the following reduced model
that does not include the interactions in the random effect structure (this
model converges):

Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
+ (0+NDVI|Cluster) + (0+Alteration|Cluster) + (0+WinterSeverity|Cluster)

I have two main questions:

1.       For the simplified model, I am unsure of the interpretation of the
beta coefficients for the fixed-effect interactions if only the independent
variables with no interactions are specified as random slopes. Do the fixed
coefficients still yield inferences at the cluster level?

2.       Is the lack of variation in independent variables within each
cluster problematic? Is there an alternative way to model this that I am
missing?
Thank you for your help,
Melanie
-- 
Melanie Dickie
PhD Candidate

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Aug 22 15:23:02 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 22 Aug 2023 15:23:02 +0200
Subject: [R-sig-ME] 
 Random slope specification with interactions in fixed effects
In-Reply-To: <CAJn6-XAEdNf7Tf7woQLk42g0GYx4y5u_L3xF4UYEJTG4RDyfMA@mail.gmail.com>
References: <CAJn6-XAEdNf7Tf7woQLk42g0GYx4y5u_L3xF4UYEJTG4RDyfMA@mail.gmail.com>
Message-ID: <CAJuCY5wZngWs+Y-tB0Sxuu8tQuWG97QxNt442jx_a1moc=m85A@mail.gmail.com>

Dear Melanie,

Fitting random slopes requires a range of values within each unit. Since
your covariates remain constant within the cluster, you can't estimate the
slope within each cluster. Hence the model should be
Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity +
(1|Cluster)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 22 aug 2023 om 15:13 schreef Melanie Dickie <mvezina at ualberta.ca>:

> Hello,
>
> I am attempting to evaluate the influence of two main continuous
> independent variables (?winter severity? aka WinterSeverity and ?% habitat
> alteration? aka Alteration), and their interaction, on a continuous
> dependent variable (?density?, measured as #animals/km2). I have reason to
> suspect the impact of these two variables also depends on the underlying
> habitat context (measured using a continuous variable, let?s say the
> Normalized Difference Vegetation Index ?NDVI?). From this, my base model
> is:
>
> Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
>
> Density is sampled in quadrats, with multiple quadrats clumped together in
> ?clusters?; such that the ?cluster? is the true sample unit, if you will,
> and the quadrats are replicated samples of each ?cluster?.
>
> One complicating twist is that the independent variables are all measured
> at each ?cluster?, such that there is no variation in the independent
> variables within each cluster, but there is variation among clusters. Each
> of the quadrats within each cluster have different density values, but the
> same value for winter severity, % habitat alteration, and NDVI.
>
> Putting the twist aside for a moment, my understanding is that I should be
> using a random slope model to gain inference at the cluster level. The
> random effects would allow the covariate effects to vary among clusters and
> the fixed effects would capture the average effect of each covariate across
> clusters. From this, the full specification of the model is (with
> appropriate specification of the family and link):
>
> Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
> + ( NDVI*Alteration  |Cluster) + ( NDVI*WinterSeverity  |Cluster) + (
> NDVI*WinterSeverity  |Cluster)
>
> This model, however, appears to be too complex for my data and will not
> converge. To that end, I have also considered the following reduced model
> that does not include the interactions in the random effect structure (this
> model converges):
>
> Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
> + (0+NDVI|Cluster) + (0+Alteration|Cluster) + (0+WinterSeverity|Cluster)
>
> I have two main questions:
>
> 1.       For the simplified model, I am unsure of the interpretation of the
> beta coefficients for the fixed-effect interactions if only the independent
> variables with no interactions are specified as random slopes. Do the fixed
> coefficients still yield inferences at the cluster level?
>
> 2.       Is the lack of variation in independent variables within each
> cluster problematic? Is there an alternative way to model this that I am
> missing?
> Thank you for your help,
> Melanie
> --
> Melanie Dickie
> PhD Candidate
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Tue Aug 22 16:34:04 2023
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?UTF-8?Q?Jo=c3=a3o_Ver=c3=adssimo?=)
Date: Tue, 22 Aug 2023 16:34:04 +0200
Subject: [R-sig-ME] 
 Random slope specification with interactions in fixed effects
In-Reply-To: <CAJn6-XAEdNf7Tf7woQLk42g0GYx4y5u_L3xF4UYEJTG4RDyfMA@mail.gmail.com>
References: <CAJn6-XAEdNf7Tf7woQLk42g0GYx4y5u_L3xF4UYEJTG4RDyfMA@mail.gmail.com>
Message-ID: <45944113-091c-36e8-fca4-b265196e8d68@gmail.com>

On 22/08/2023 00:52, Melanie Dickie wrote:
> One complicating twist is that the independent variables are all measured
> at each ?cluster?, such that there is no variation in the independent
> variables within each cluster, but there is variation among clusters. Each
> of the quadrats within each cluster have different density values, but the
> same value for winter severity, % habitat alteration, and NDVI.
This means that by-cluster random slopes should not be included, since 
you cannot estimate their within-cluster effect.

If I'm seeing this correctly, the model that you're looking for is simply:
Density ~ NDVI*Alteration + NDVI*WinterSeverity + 
Alteration*WinterSeverity + (1|Cluster)

Jo?o

> Putting the twist aside for a moment, my understanding is that I should be
> using a random slope model to gain inference at the cluster level. The
> random effects would allow the covariate effects to vary among clusters and
> the fixed effects would capture the average effect of each covariate across
> clusters. From this, the full specification of the model is (with
> appropriate specification of the family and link):
>
> Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
> + ( NDVI*Alteration  |Cluster) + ( NDVI*WinterSeverity  |Cluster) + (
> NDVI*WinterSeverity  |Cluster)
>
> This model, however, appears to be too complex for my data and will not
> converge. To that end, I have also considered the following reduced model
> that does not include the interactions in the random effect structure (this
> model converges):
>
> Density ~ NDVI*Alteration + NDVI*WinterSeverity + Alteration*WinterSeverity
> + (0+NDVI|Cluster) + (0+Alteration|Cluster) + (0+WinterSeverity|Cluster)
>
> I have two main questions:
>
> 1.       For the simplified model, I am unsure of the interpretation of the
> beta coefficients for the fixed-effect interactions if only the independent
> variables with no interactions are specified as random slopes. Do the fixed
> coefficients still yield inferences at the cluster level?
>
> 2.       Is the lack of variation in independent variables within each
> cluster problematic? Is there an alternative way to model this that I am
> missing?
> Thank you for your help,
> Melanie


From @|ex@nder_@oko|ov@ky @end|ng |rom brown@edu  Wed Aug 23 03:48:06 2023
From: @|ex@nder_@oko|ov@ky @end|ng |rom brown@edu (Sokolovsky, Alexander)
Date: Tue, 22 Aug 2023 21:48:06 -0400
Subject: [R-sig-ME] Interrupted time series on grouped data with count
 outcome in glmmTMB
Message-ID: <CAK-pkDAkWfUGJUc3OXJkQ3MTKJQxDgLgYz7e8nKb1aHo=_zgSQ@mail.gmail.com>

Hi all,

This is my first time sending a question to this list so apologies if I
miss something that is typically expected. I am trying to fit an
interrupted time series type model on grouped data (by individual).
Specifically, I am modeling compliance with a remote survey tool that
delivered 5 surveys a day for 28 days across two bursts. The outcome
variable is a count of missed surveys on days with any engagement (so range
0-4) (https://i.stack.imgur.com/FThRs.png). Ignoring covariates, the three
focal predictors are thus time (studyday_new), burst (wave), and time after
burst 2 starts (studyday_new_post). The model is specified as follows (and
I acknowledge I could be making a mistake here, I tried to follow Ben
Bolker's thoughts on fitting this models with temporal autocorrelation in
glmmTMB from
https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html):

mod1_mde <- glmmTMB(missed_surveys ~ w1age + school + w1sex + w1hislat +
w1racer + studyday_new + wave + studyday_new_post + ar1(studyday_new_t +
0|id) + (1 |id), data = daily_data3_mde, family = "poisson")

This model converges. But when I plot the predicted values
(using ggpredict from ggeffects) over the observed daily means, the
predicted values appear to be underestimating the observed means.

Here is the plot: https://i.stack.imgur.com/bRfue.png

Now what's interesting to me is that when I fit this model to a gaussian
distribution instead, the resulting predicted values are reasonable:
https://i.stack.imgur.com/rIYnZ.png

And when I fit this model to a poisson distribution but exclude the AR
covariance structure and random intercept (both of which are obviously
critical) I also get reasonable predicted values:
https://i.stack.imgur.com/dWlho.png

(Please ignore the different labels on the plots I just copied the syntax
from other parts of my code when I was writing it).

So is there something I'm missing about getting predicted values from this
model?

All the best,
-- Alex

-- 
*Alexander W. Sokolovsky, PhD*
Assistant Professor
Center for Alcohol and Addiction Studies
Department of Behavioral and Social Sciences
E: Alexander_Sokolovsky at Brown.edu
P: (401) 863-6629(401) 863-6697 (Fax)
A: Box G-S121-5, Providence, RI 02912
<https://maps.google.com/?q=Box%20G-S121-5%2C%20Providence%2C%20RI%2002912>
W: https://vivo.brown.edu/display/asokolo1
[image: Twitter]AlexSokoPhD <https://twitter.com/AlexSokoPhD>
?The greatest enemy of knowledge is not ignorance, it is the illusion of
knowledge.?
- Stephen Hawking

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Aug 23 03:58:07 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 22 Aug 2023 21:58:07 -0400
Subject: [R-sig-ME] Interrupted time series on grouped data with count
 outcome in glmmTMB
In-Reply-To: <CAK-pkDAkWfUGJUc3OXJkQ3MTKJQxDgLgYz7e8nKb1aHo=_zgSQ@mail.gmail.com>
References: <CAK-pkDAkWfUGJUc3OXJkQ3MTKJQxDgLgYz7e8nKb1aHo=_zgSQ@mail.gmail.com>
Message-ID: <f56017bb-968b-4f5c-bd63-c49ac0fb2c2e@gmail.com>

    Check the section on "bias adjustment" in the emmeans vignette:

https://cran.r-project.org/web/packages/emmeans/vignettes/transformations.html#bias-adj

   I think? you can probably pass these options through ggpredict ...

On 2023-08-22 9:48 p.m., Sokolovsky, Alexander wrote:
> Hi all,
> 
> This is my first time sending a question to this list so apologies if I
> miss something that is typically expected. I am trying to fit an
> interrupted time series type model on grouped data (by individual).
> Specifically, I am modeling compliance with a remote survey tool that
> delivered 5 surveys a day for 28 days across two bursts. The outcome
> variable is a count of missed surveys on days with any engagement (so range
> 0-4) (https://i.stack.imgur.com/FThRs.png). Ignoring covariates, the three
> focal predictors are thus time (studyday_new), burst (wave), and time after
> burst 2 starts (studyday_new_post). The model is specified as follows (and
> I acknowledge I could be making a mistake here, I tried to follow Ben
> Bolker's thoughts on fitting this models with temporal autocorrelation in
> glmmTMB from
> https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html):
> 
> mod1_mde <- glmmTMB(missed_surveys ~ w1age + school + w1sex + w1hislat +
> w1racer + studyday_new + wave + studyday_new_post + ar1(studyday_new_t +
> 0|id) + (1 |id), data = daily_data3_mde, family = "poisson")
> 
> This model converges. But when I plot the predicted values
> (using ggpredict from ggeffects) over the observed daily means, the
> predicted values appear to be underestimating the observed means.
> 
> Here is the plot: https://i.stack.imgur.com/bRfue.png
> 
> Now what's interesting to me is that when I fit this model to a gaussian
> distribution instead, the resulting predicted values are reasonable:
> https://i.stack.imgur.com/rIYnZ.png
> 
> And when I fit this model to a poisson distribution but exclude the AR
> covariance structure and random intercept (both of which are obviously
> critical) I also get reasonable predicted values:
> https://i.stack.imgur.com/dWlho.png
> 
> (Please ignore the different labels on the plots I just copied the syntax
> from other parts of my code when I was writing it).
> 
> So is there something I'm missing about getting predicted values from this
> model?
> 
> All the best,
> -- Alex
>


From @|ex@nder_@oko|ov@ky @end|ng |rom brown@edu  Wed Aug 23 05:39:56 2023
From: @|ex@nder_@oko|ov@ky @end|ng |rom brown@edu (Sokolovsky, Alexander)
Date: Tue, 22 Aug 2023 23:39:56 -0400
Subject: [R-sig-ME] Interrupted time series on grouped data with count
 outcome in glmmTMB
In-Reply-To: <f56017bb-968b-4f5c-bd63-c49ac0fb2c2e@gmail.com>
References: <CAK-pkDAkWfUGJUc3OXJkQ3MTKJQxDgLgYz7e8nKb1aHo=_zgSQ@mail.gmail.com>
 <f56017bb-968b-4f5c-bd63-c49ac0fb2c2e@gmail.com>
Message-ID: <CAK-pkDAOu+FZkjCE6ynavufR4u6+m=VZZcwr0ot-TRCM5g8ixQ@mail.gmail.com>

Hello Ben,

Thanks for the reply I totally missed the part on "bias adjustment"; this
seems to have done the trick. Wasn't able to figure out how to send it
through to emmeans from ggmeans for whatever reason, but I just went
through the emmeans vignette to get them. Appreciate your help and I'll
avoid cross-posting in the future.

All the best,
-- Alex

On Tue, Aug 22, 2023 at 9:59?PM Ben Bolker <bbolker at gmail.com> wrote:

>     Check the section on "bias adjustment" in the emmeans vignette:
>
>
> https://cran.r-project.org/web/packages/emmeans/vignettes/transformations.html#bias-adj
>
>    I think? you can probably pass these options through ggpredict ...
>
> On 2023-08-22 9:48 p.m., Sokolovsky, Alexander wrote:
> > Hi all,
> >
> > This is my first time sending a question to this list so apologies if I
> > miss something that is typically expected. I am trying to fit an
> > interrupted time series type model on grouped data (by individual).
> > Specifically, I am modeling compliance with a remote survey tool that
> > delivered 5 surveys a day for 28 days across two bursts. The outcome
> > variable is a count of missed surveys on days with any engagement (so
> range
> > 0-4) (https://i.stack.imgur.com/FThRs.png). Ignoring covariates, the
> three
> > focal predictors are thus time (studyday_new), burst (wave), and time
> after
> > burst 2 starts (studyday_new_post). The model is specified as follows
> (and
> > I acknowledge I could be making a mistake here, I tried to follow Ben
> > Bolker's thoughts on fitting this models with temporal autocorrelation in
> > glmmTMB from
> > https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html):
> >
> > mod1_mde <- glmmTMB(missed_surveys ~ w1age + school + w1sex + w1hislat +
> > w1racer + studyday_new + wave + studyday_new_post + ar1(studyday_new_t +
> > 0|id) + (1 |id), data = daily_data3_mde, family = "poisson")
> >
> > This model converges. But when I plot the predicted values
> > (using ggpredict from ggeffects) over the observed daily means, the
> > predicted values appear to be underestimating the observed means.
> >
> > Here is the plot: https://i.stack.imgur.com/bRfue.png
> >
> > Now what's interesting to me is that when I fit this model to a gaussian
> > distribution instead, the resulting predicted values are reasonable:
> > https://i.stack.imgur.com/rIYnZ.png
> >
> > And when I fit this model to a poisson distribution but exclude the AR
> > covariance structure and random intercept (both of which are obviously
> > critical) I also get reasonable predicted values:
> > https://i.stack.imgur.com/dWlho.png
> >
> > (Please ignore the different labels on the plots I just copied the syntax
> > from other parts of my code when I was writing it).
> >
> > So is there something I'm missing about getting predicted values from
> this
> > model?
> >
> > All the best,
> > -- Alex
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
*Alexander W. Sokolovsky, PhD*
Assistant Professor
Center for Alcohol and Addiction Studies
Department of Behavioral and Social Sciences
E: Alexander_Sokolovsky at Brown.edu
P: (401) 863-6629(401) 863-6697 (Fax)
A: Box G-S121-5, Providence, RI 02912
<https://maps.google.com/?q=Box%20G-S121-5%2C%20Providence%2C%20RI%2002912>
W: https://vivo.brown.edu/display/asokolo1
[image: Twitter]AlexSokoPhD <https://twitter.com/AlexSokoPhD>
?The greatest enemy of knowledge is not ignorance, it is the illusion of
knowledge.?
- Stephen Hawking

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Thu Aug 24 13:28:35 2023
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Thu, 24 Aug 2023 13:28:35 +0200
Subject: [R-sig-ME] Random effects in R vs SAS
In-Reply-To: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
References: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
Message-ID: <DAF6E60C-6BCC-4D3E-BDE4-FA849DF9A9D6@gmail.com>


> On 18 Aug 2023, at 07.06, Will Hopkins <willthekiwi at gmail.com> wrote:
> 
> I am a SAS user, and I have just finished a near-final draft of an article
> about identifying and specifying fixed and random effects for mixed models
> in SAS. At the moment, all I say about R is this: "To all users of the R
> stats package, my apologies: a few years ago, I found the mixed model in R
> too limiting, and I struggled with the coding. I hope someone with R smarts
> will consider adapting my programs and publishing them here." I really would
> like to know if the limitations (or at least, what I consider to be
> limitations) have been addressed, so I can be more specific in my article.
> Specifically can anyone answer these questions?
> 
> 
> 
> 1. Can you specify negative variance for random effects in R? (That doesn't
> apply to the variances representing residuals, which are never negative).
> 
> 
> 
> 2. Can you get trustworthy estimates of standard errors for the
> random-effect and residual variances in R? (By trustworthy, I guess I mean
> the same as SAS's, but it could mean that someone has shown that the
> confidence intervals derived with the SEs have good coverage, assuming
> normality for the variances representing random effects and chi-squared for
> variances representing residuals.) 
> 
> 
> 
> 3. Does R have the equivalent of the repeated statement in SAS, whereby you
> can specify a repeated measure with an unstructured or other covariance
> matrix? (e.g., repeated Time/subject=SubjectID type=un. This statement works
> more reliably than the random statement in SAS with small sample sizes, but
> it doesn't produce residual variances, not directly anyway.)
> 

I am not a SAS user, but I guess that their unstructured covariance matrix might be similar to the one described here
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

> 
> 
> 4. Does R have the equivalent of the group= option in SAS, whereby you can
> specify separate estimates of random-effect variances and covariances,
> and/or separate estimates of residuals, for different groups? (e.g., random
> SubjectID/group=Sex; repeated/group=Sex;)

This section of this website explains how a variety of random effects can be specified in many R packages
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification


Mollie

> 
> 
> 
> The draft article is available at
> https://sportsci.org/2023/EffectsModels.htm. It's not published yet (i.e.,
> not linked to the Sportscience homepage yet). I would be grateful for any
> feedback. I can incorporate more about R and would love someone to provide R
> code for the programs I have published. See below for the title and
> abstract.
> 
> 
> 
> Will
> 
> 
> 
> How to Identify and Specify Fixed and Random Effects for Linear Mixed Models
> in the Statistical Analysis System
> 
> 
> 
> Most analyses require linear mixed modeling to properly account not only for
> mean effects but also for sources of variability and error in the data. In
> linear mixed models, means and their differences are specified with fixed
> effects, while variabilities and errors are specified with random effects
> (including residuals) and are summarized as standard deviations. In this
> tutorial article, I explain how variables represent effects in linear mixed
> models and how identifying clusters of observations in a dataset is the key
> to identifying the fixed and random effects. I also provide programs written
> in the language of the Statistical analysis system to simulate data and
> analyze them with the general linear mixed model, Proc Mixed, which is used
> when the dependent variable is continuous. The analyses include simple
> linear regression, reliability and time series, controlled trials, and
> combined within- and between-subject modeling. Finally, I explain how
> dependent variables representing counts or proportions require generalized
> linear mixed models, realized in SAS with Proc Glimmix, where the main
> difference is the specification of the residuals.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Thu Aug 24 13:27:34 2023
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Thu, 24 Aug 2023 13:27:34 +0200
Subject: [R-sig-ME] Random effects in R vs SAS
In-Reply-To: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
References: <80c901d9d191$c83240e0$5896c2a0$@gmail.com>
Message-ID: <8B0D4046-AC73-4BF5-BC73-02E83AECA839@gmail.com>


> On 18 Aug 2023, at 07.06, Will Hopkins <willthekiwi at gmail.com> wrote:
> 
> I am a SAS user, and I have just finished a near-final draft of an article
> about identifying and specifying fixed and random effects for mixed models
> in SAS. At the moment, all I say about R is this: "To all users of the R
> stats package, my apologies: a few years ago, I found the mixed model in R
> too limiting, and I struggled with the coding. I hope someone with R smarts
> will consider adapting my programs and publishing them here." I really would
> like to know if the limitations (or at least, what I consider to be
> limitations) have been addressed, so I can be more specific in my article.
> Specifically can anyone answer these questions?
> 
> 
> 
> 1. Can you specify negative variance for random effects in R? (That doesn't
> apply to the variances representing residuals, which are never negative).
> 
> 
> 
> 2. Can you get trustworthy estimates of standard errors for the
> random-effect and residual variances in R? (By trustworthy, I guess I mean
> the same as SAS's, but it could mean that someone has shown that the
> confidence intervals derived with the SEs have good coverage, assuming
> normality for the variances representing random effects and chi-squared for
> variances representing residuals.) 
> 
> 
> 
> 3. Does R have the equivalent of the repeated statement in SAS, whereby you
> can specify a repeated measure with an unstructured or other covariance
> matrix? (e.g., repeated Time/subject=SubjectID type=un. This statement works
> more reliably than the random statement in SAS with small sample sizes, but
> it doesn't produce residual variances, not directly anyway.)
> 

I am not a SAS user, but I guess that their unstructured covariance matrix might be similar to the one described here
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

> 
> 
> 4. Does R have the equivalent of the group= option in SAS, whereby you can
> specify separate estimates of random-effect variances and covariances,
> and/or separate estimates of residuals, for different groups? (e.g., random
> SubjectID/group=Sex; repeated/group=Sex;)

This section of this website explains how a variety of random effects can be specified in many R packages
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification


Mollie

> 
> 
> 
> The draft article is available at
> https://sportsci.org/2023/EffectsModels.htm. It's not published yet (i.e.,
> not linked to the Sportscience homepage yet). I would be grateful for any
> feedback. I can incorporate more about R and would love someone to provide R
> code for the programs I have published. See below for the title and
> abstract.
> 
> 
> 
> Will
> 
> 
> 
> How to Identify and Specify Fixed and Random Effects for Linear Mixed Models
> in the Statistical Analysis System
> 
> 
> 
> Most analyses require linear mixed modeling to properly account not only for
> mean effects but also for sources of variability and error in the data. In
> linear mixed models, means and their differences are specified with fixed
> effects, while variabilities and errors are specified with random effects
> (including residuals) and are summarized as standard deviations. In this
> tutorial article, I explain how variables represent effects in linear mixed
> models and how identifying clusters of observations in a dataset is the key
> to identifying the fixed and random effects. I also provide programs written
> in the language of the Statistical analysis system to simulate data and
> analyze them with the general linear mixed model, Proc Mixed, which is used
> when the dependent variable is continuous. The analyses include simple
> linear regression, reliability and time series, controlled trials, and
> combined within- and between-subject modeling. Finally, I explain how
> dependent variables representing counts or proportions require generalized
> linear mixed models, realized in SAS with Proc Glimmix, where the main
> difference is the specification of the residuals.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Tue Aug 29 20:56:33 2023
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Tue, 29 Aug 2023 12:56:33 -0600
Subject: [R-sig-ME] Request for advice: Multivariate Wilcoxon Test
Message-ID: <CAEatWUoXXqLwb3Wi3C=DvN-FcEXs8T3cOLmyMBu4TZgV9nBDMA@mail.gmail.com>

Hello,

I performed an unpaired Wilcoxon test on a continuous measure with
non-parametric distribution and detected a significant difference between
two levels of an independent variable. However, I suspect that another
independent variable could be confounding this outcome. Could you kindly
advise on how I can control for this possible confounder using a
multivariate Wilcoxon test? I'm not quite sure how to go about this.

Thank you,
Faith

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed Aug 30 09:46:26 2023
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 30 Aug 2023 09:46:26 +0200
Subject: [R-sig-ME] Request for advice: Multivariate Wilcoxon Test
In-Reply-To: <CAEatWUoXXqLwb3Wi3C=DvN-FcEXs8T3cOLmyMBu4TZgV9nBDMA@mail.gmail.com>
References: <CAEatWUoXXqLwb3Wi3C=DvN-FcEXs8T3cOLmyMBu4TZgV9nBDMA@mail.gmail.com>
Message-ID: <b8668b8b-1b66-f6af-7868-8f34c1e02eff@math.uni-giessen.de>

Hello, Faith,

this is a rather not R-related, but statistical question for which you 
should probably seek (professional?) advice. Nevertheless, as unspecific 
as you formulated it, you may want to look at Friedman's test which 
allows to use a (second) blocking variable, or at a regression approach. 
If you are really kean on a nonparametric _multivariate_ method the 
references below *may* be helpful. The first is really mathematical, the 
second more applied.

 ?Hth? --? Gerrit

@misc{puri1971nonparametric,
address = {New York {[u.a.]},

author = {Puri, Madan Lal},

isbn = {0471702404},

series = {Wiley series in probability and mathematical statistics},

title = {Nonparametric methods in multivariate analysis},

year = 1971

}


@misc{pesarin2010permutation,
address = {Chichester},

author = {Pesarin, Fortunato},

isbn = {0470516410},

series = {Wiley series in probability and statistics},

title = {Permutation tests for complex data : theory, applications and 
software},

year = 2010

}



Am 29.08.2023 um 20:56 schrieb Ebhodaghe Faith:
> Hello,
>
> I performed an unpaired Wilcoxon test on a continuous measure with
> non-parametric distribution and detected a significant difference between
> two levels of an independent variable. However, I suspect that another
> independent variable could be confounding this outcome. Could you kindly
> advise on how I can control for this possible confounder using a
> multivariate Wilcoxon test? I'm not quite sure how to go about this.
>
> Thank you,
> Faith
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Aug 31 10:01:31 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 31 Aug 2023 11:01:31 +0300
Subject: [R-sig-ME] glmer conditional deviance DECREASING after removal of
 fixed effect??
Message-ID: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>

Hi,

I thought it was impossible for deviance to decrease when a term is
removed!?!? Yet I'm seeing it happen with this pair of relatively simple
Bernoulli GLMMs fit using lme4:glmer():

> full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
> 6, data = anon)

> reduced <- update(full, ~. -x1)

> c(full = deviance(full), reduced = deviance(reduced))


*     full  reduced*
*2808.671 2807.374 *

What on earth going on? FYI, I am deliberately comparing conditional
deviances rather than marginal ones, because quite a few of the clusters
are of inherent interest and likely to recur in future data.

My anonymized datafile is attached.

Best,

Juho

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: anon.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20230831/bca7eb87/attachment-0001.txt>

From dmb@te@ @end|ng |rom gm@||@com  Thu Aug 31 14:56:00 2023
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Thu, 31 Aug 2023 07:56:00 -0500
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
Message-ID: <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>

You say you are comparing conditional deviances rather than marginal
deviances.  Can you expand on that a bit further?  How are you evaluating
the conditional deviances?

The models are being fit according to what you describe as the marginal
deviance - what I would call the deviance.  It is not surprising that what
you are calling the conditional deviance is inconsistent with the nesting
of the models because they weren't fit according to that criterion.

julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
           fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
       end
Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
  y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
  Distribution: Bernoulli{Float64}
  Link: LogitLink()

   logLik    deviance     AIC       AICc        BIC
 -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600

Variance components:
      Column   Variance Std.Dev.
id (Intercept)  0.270823 0.520406

 Number of obs: 2217; levels of grouping factors: 331

Fixed-effects parameters:
????????????????????????????????????????????????????
                  Coef.  Std. Error      z  Pr(>|z|)
????????????????????????????????????????????????????
(Intercept)   0.0969256   0.140211    0.69    0.4894
x1: 1        -0.0449824   0.0553361  -0.81    0.4163
x2            0.0744891   0.0133743   5.57    <1e-07
x3           -0.548392    0.0914109  -6.00    <1e-08
x4: B         0.390359    0.0803063   4.86    <1e-05
x4: C         0.299932    0.0991249   3.03    0.0025
????????????????????????????????????????????????????

julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
           fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
       end
Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
  y ~ 1 + x1 + x2 + x3 + (1 | id)
  Distribution: Bernoulli{Float64}
  Link: LogitLink()

   logLik    deviance     AIC       AICc        BIC
 -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297

Variance components:
      Column   Variance Std.Dev.
id (Intercept)  0.274331 0.523766

 Number of obs: 2217; levels of grouping factors: 331

Fixed-effects parameters:
????????????????????????????????????????????????????
                  Coef.  Std. Error      z  Pr(>|z|)
????????????????????????????????????????????????????
(Intercept)  -0.448496    0.100915   -4.44    <1e-05
x1: 1        -0.0527684   0.0547746  -0.96    0.3354
x2            0.0694393   0.0131541   5.28    <1e-06
x3           -0.556903    0.0904798  -6.15    <1e-09
????????????????????????????????????????????????????

julia> MixedModels.likelihoodratiotest(m02, m01)
Model Formulae
1: y ~ 1 + x1 + x2 + x3 + (1 | id)
2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
??????????????????????????????????????????????????
     model-dof   deviance       ??  ??-dof  P(>??)
??????????????????????????????????????????????????
[1]          5  2944.0654
[2]          7  2900.8511  43.2144       2  <1e-09
??????????????????????????????????????????????????

I would note that your data are so imbalanced with respect to id that it is
not surprising that you get unstable results.  (I changed your id column
from integers to a factor so that 33 becomes S033.)

331?2 DataFrame
 Row ? id      nrow
     ? String  Int64
?????????????????????
   1 ? S033     1227
   2 ? S134       46
   3 ? S295       45
   4 ? S127       41
   5 ? S125       33
   6 ? S228       31
   7 ? S193       23
   8 ? S064       18
   9 ? S281       16
  10 ? S055       13
  11 ? S035       13
  12 ? S091       12
  13 ? S175       11
  14 ? S284       10
  15 ? S159       10
  ?  ?   ?       ?
 317 ? S324        1
 318 ? S115        1
 319 ? S192        1
 320 ? S201        1
 321 ? S156        1
 322 ? S202        1
 323 ? S067        1
 324 ? S264        1
 325 ? S023        1
 326 ? S090        1
 327 ? S195        1
 328 ? S170        1
 329 ? S241        1
 330 ? S189        1
 331 ? S213        1
     301 rows omitted



On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
juho.kristian.ruohonen at gmail.com> wrote:

> Hi,
>
> I thought it was impossible for deviance to decrease when a term is
> removed!?!? Yet I'm seeing it happen with this pair of relatively simple
> Bernoulli GLMMs fit using lme4:glmer():
>
> > full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
> > 6, data = anon)
>
> > reduced <- update(full, ~. -x1)
>
> > c(full = deviance(full), reduced = deviance(reduced))
>
>
> *     full  reduced*
> *2808.671 2807.374 *
>
> What on earth going on? FYI, I am deliberately comparing conditional
> deviances rather than marginal ones, because quite a few of the clusters
> are of inherent interest and likely to recur in future data.
>
> My anonymized datafile is attached.
>
> Best,
>
> Juho
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Aug 31 15:35:13 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 31 Aug 2023 16:35:13 +0300
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
Message-ID: <CAG_dBVcZyj6+dqQFTLZQFL=2FMMz4Se5S97E3vRpx4rHz-iY4Q@mail.gmail.com>

>
> You say you are comparing conditional deviances rather than marginal
> deviances.  Can you expand on that a bit further?
>

My (possibly mistaken) understanding of the conditional deviance is that it
is the deviance that results from comparing the observed responses to
fitted values calculated with the BLUPs factored in. Since the cluster
effects are of inherent interest and bound to recur, this is what I want.

It is not surprising that what you are calling the conditional deviance is
> inconsistent with the nesting of the models because they weren't fit
> according to that criterion.
>

Wow. I think that's the answer, simple as that. Now I'm kinda embarrassed
for having even had to ask.

Many thanks!

Best,

Juho

to 31. elok. 2023 klo 15.56 Douglas Bates (dmbates at gmail.com) kirjoitti:

> You say you are comparing conditional deviances rather than marginal
> deviances.  Can you expand on that a bit further?  How are you evaluating
> the conditional deviances?
>
> The models are being fit according to what you describe as the marginal
> deviance - what I would call the deviance.  It is not surprising that what
> you are calling the conditional deviance is inconsistent with the nesting
> of the models because they weren't fit according to that criterion.
>
> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>        end
> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>   y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>   Distribution: Bernoulli{Float64}
>   Link: LogitLink()
>
>    logLik    deviance     AIC       AICc        BIC
>  -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
>
> Variance components:
>       Column   Variance Std.Dev.
> id (Intercept)  0.270823 0.520406
>
>  Number of obs: 2217; levels of grouping factors: 331
>
> Fixed-effects parameters:
> ????????????????????????????????????????????????????
>                   Coef.  Std. Error      z  Pr(>|z|)
> ????????????????????????????????????????????????????
> (Intercept)   0.0969256   0.140211    0.69    0.4894
> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
> x2            0.0744891   0.0133743   5.57    <1e-07
> x3           -0.548392    0.0914109  -6.00    <1e-08
> x4: B         0.390359    0.0803063   4.86    <1e-05
> x4: C         0.299932    0.0991249   3.03    0.0025
> ????????????????????????????????????????????????????
>
> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>        end
> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>   y ~ 1 + x1 + x2 + x3 + (1 | id)
>   Distribution: Bernoulli{Float64}
>   Link: LogitLink()
>
>    logLik    deviance     AIC       AICc        BIC
>  -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
>
> Variance components:
>       Column   Variance Std.Dev.
> id (Intercept)  0.274331 0.523766
>
>  Number of obs: 2217; levels of grouping factors: 331
>
> Fixed-effects parameters:
> ????????????????????????????????????????????????????
>                   Coef.  Std. Error      z  Pr(>|z|)
> ????????????????????????????????????????????????????
> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
> x2            0.0694393   0.0131541   5.28    <1e-06
> x3           -0.556903    0.0904798  -6.15    <1e-09
> ????????????????????????????????????????????????????
>
> julia> MixedModels.likelihoodratiotest(m02, m01)
> Model Formulae
> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> ??????????????????????????????????????????????????
>      model-dof   deviance       ??  ??-dof  P(>??)
> ??????????????????????????????????????????????????
> [1]          5  2944.0654
> [2]          7  2900.8511  43.2144       2  <1e-09
> ??????????????????????????????????????????????????
>
> I would note that your data are so imbalanced with respect to id that it
> is not surprising that you get unstable results.  (I changed your id column
> from integers to a factor so that 33 becomes S033.)
>
> 331?2 DataFrame
>  Row ? id      nrow
>      ? String  Int64
> ?????????????????????
>    1 ? S033     1227
>    2 ? S134       46
>    3 ? S295       45
>    4 ? S127       41
>    5 ? S125       33
>    6 ? S228       31
>    7 ? S193       23
>    8 ? S064       18
>    9 ? S281       16
>   10 ? S055       13
>   11 ? S035       13
>   12 ? S091       12
>   13 ? S175       11
>   14 ? S284       10
>   15 ? S159       10
>   ?  ?   ?       ?
>  317 ? S324        1
>  318 ? S115        1
>  319 ? S192        1
>  320 ? S201        1
>  321 ? S156        1
>  322 ? S202        1
>  323 ? S067        1
>  324 ? S264        1
>  325 ? S023        1
>  326 ? S090        1
>  327 ? S195        1
>  328 ? S170        1
>  329 ? S241        1
>  330 ? S189        1
>  331 ? S213        1
>      301 rows omitted
>
>
>
> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
> juho.kristian.ruohonen at gmail.com> wrote:
>
>> Hi,
>>
>> I thought it was impossible for deviance to decrease when a term is
>> removed!?!? Yet I'm seeing it happen with this pair of relatively simple
>> Bernoulli GLMMs fit using lme4:glmer():
>>
>> > full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
>> > 6, data = anon)
>>
>> > reduced <- update(full, ~. -x1)
>>
>> > c(full = deviance(full), reduced = deviance(reduced))
>>
>>
>> *     full  reduced*
>> *2808.671 2807.374 *
>>
>> What on earth going on? FYI, I am deliberately comparing conditional
>> deviances rather than marginal ones, because quite a few of the clusters
>> are of inherent interest and likely to recur in future data.
>>
>> My anonymized datafile is attached.
>>
>> Best,
>>
>> Juho
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From dmb@te@ @end|ng |rom gm@||@com  Thu Aug 31 15:37:22 2023
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Thu, 31 Aug 2023 08:37:22 -0500
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
Message-ID: <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>

I may have attributed the confusion about conditional and marginal
deviances to you, Juho, when in fact it is the fault of the authors of
lme4, of whom I am one.  If so, I apologize.

We (the authors of lme4) had a discussion about the definition of deviance
many years ago and I am not sure what the upshot was.  It may have been
that we went with this incorrect definition of the "conditional deviance".
Unfortunately my R skills are sufficiently atrophied that I haven't been
able to look up what is actually evaluated.

The area of generalized linear models and generalized linear mixed models
holds many traps for the unwary in terms of definitions, and some casual
definitions in the original glm function, going as far back as the S3
language, aid in the confusion.  For example, the dev.resid function in a
GLM family doesn't return the deviance residuals - it returns the square of
the deviance residuals, which should be named the "unit deviances".

Given a response vector and the predicted mean vector and a distribution
family one can define the unit deviances, which play a role similar to the
squared residual in the Gaussian family.  The sum of these unit deviances
is the deviance of a generalized linear model, but it is not the deviance
of a generalized linear mixed model, because the likelihood for a GLMM
involves both a "fidelity to the data" term *and* a "complexity of the
model" term, which is the size of the random effects vector in a certain
metric.

So if indeed we used an inappropriate definition of deviance the mistake is
ours and we should correct it.

On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com> wrote:

> You say you are comparing conditional deviances rather than marginal
> deviances.  Can you expand on that a bit further?  How are you evaluating
> the conditional deviances?
>
> The models are being fit according to what you describe as the marginal
> deviance - what I would call the deviance.  It is not surprising that what
> you are calling the conditional deviance is inconsistent with the nesting
> of the models because they weren't fit according to that criterion.
>
> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>        end
> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>   y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>   Distribution: Bernoulli{Float64}
>   Link: LogitLink()
>
>    logLik    deviance     AIC       AICc        BIC
>  -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
>
> Variance components:
>       Column   Variance Std.Dev.
> id (Intercept)  0.270823 0.520406
>
>  Number of obs: 2217; levels of grouping factors: 331
>
> Fixed-effects parameters:
> ????????????????????????????????????????????????????
>                   Coef.  Std. Error      z  Pr(>|z|)
> ????????????????????????????????????????????????????
> (Intercept)   0.0969256   0.140211    0.69    0.4894
> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
> x2            0.0744891   0.0133743   5.57    <1e-07
> x3           -0.548392    0.0914109  -6.00    <1e-08
> x4: B         0.390359    0.0803063   4.86    <1e-05
> x4: C         0.299932    0.0991249   3.03    0.0025
> ????????????????????????????????????????????????????
>
> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>        end
> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>   y ~ 1 + x1 + x2 + x3 + (1 | id)
>   Distribution: Bernoulli{Float64}
>   Link: LogitLink()
>
>    logLik    deviance     AIC       AICc        BIC
>  -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
>
> Variance components:
>       Column   Variance Std.Dev.
> id (Intercept)  0.274331 0.523766
>
>  Number of obs: 2217; levels of grouping factors: 331
>
> Fixed-effects parameters:
> ????????????????????????????????????????????????????
>                   Coef.  Std. Error      z  Pr(>|z|)
> ????????????????????????????????????????????????????
> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
> x2            0.0694393   0.0131541   5.28    <1e-06
> x3           -0.556903    0.0904798  -6.15    <1e-09
> ????????????????????????????????????????????????????
>
> julia> MixedModels.likelihoodratiotest(m02, m01)
> Model Formulae
> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> ??????????????????????????????????????????????????
>      model-dof   deviance       ??  ??-dof  P(>??)
> ??????????????????????????????????????????????????
> [1]          5  2944.0654
> [2]          7  2900.8511  43.2144       2  <1e-09
> ??????????????????????????????????????????????????
>
> I would note that your data are so imbalanced with respect to id that it
> is not surprising that you get unstable results.  (I changed your id column
> from integers to a factor so that 33 becomes S033.)
>
> 331?2 DataFrame
>  Row ? id      nrow
>      ? String  Int64
> ?????????????????????
>    1 ? S033     1227
>    2 ? S134       46
>    3 ? S295       45
>    4 ? S127       41
>    5 ? S125       33
>    6 ? S228       31
>    7 ? S193       23
>    8 ? S064       18
>    9 ? S281       16
>   10 ? S055       13
>   11 ? S035       13
>   12 ? S091       12
>   13 ? S175       11
>   14 ? S284       10
>   15 ? S159       10
>   ?  ?   ?       ?
>  317 ? S324        1
>  318 ? S115        1
>  319 ? S192        1
>  320 ? S201        1
>  321 ? S156        1
>  322 ? S202        1
>  323 ? S067        1
>  324 ? S264        1
>  325 ? S023        1
>  326 ? S090        1
>  327 ? S195        1
>  328 ? S170        1
>  329 ? S241        1
>  330 ? S189        1
>  331 ? S213        1
>      301 rows omitted
>
>
>
> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
> juho.kristian.ruohonen at gmail.com> wrote:
>
>> Hi,
>>
>> I thought it was impossible for deviance to decrease when a term is
>> removed!?!? Yet I'm seeing it happen with this pair of relatively simple
>> Bernoulli GLMMs fit using lme4:glmer():
>>
>> > full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
>> > 6, data = anon)
>>
>> > reduced <- update(full, ~. -x1)
>>
>> > c(full = deviance(full), reduced = deviance(reduced))
>>
>>
>> *     full  reduced*
>> *2808.671 2807.374 *
>>
>> What on earth going on? FYI, I am deliberately comparing conditional
>> deviances rather than marginal ones, because quite a few of the clusters
>> are of inherent interest and likely to recur in future data.
>>
>> My anonymized datafile is attached.
>>
>> Best,
>>
>> Juho
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From dmb@te@ @end|ng |rom gm@||@com  Thu Aug 31 15:45:10 2023
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Thu, 31 Aug 2023 08:45:10 -0500
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
Message-ID: <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>

I have written about how I now understand the evaluation of the likelihood
of a GLMM in an appendix of the in-progress book at
https://juliamixedmodels.github.io/EmbraceUncertainty

It is a difficult area to make sense of.  Even now, after more than 25
years of thinking about these models, I am still not sure exactly how to
define the objective in a GLMM for a family with a dispersion parameter.

On Thu, Aug 31, 2023 at 8:37?AM Douglas Bates <dmbates at gmail.com> wrote:

> I may have attributed the confusion about conditional and marginal
> deviances to you, Juho, when in fact it is the fault of the authors of
> lme4, of whom I am one.  If so, I apologize.
>
> We (the authors of lme4) had a discussion about the definition of deviance
> many years ago and I am not sure what the upshot was.  It may have been
> that we went with this incorrect definition of the "conditional deviance".
> Unfortunately my R skills are sufficiently atrophied that I haven't been
> able to look up what is actually evaluated.
>
> The area of generalized linear models and generalized linear mixed models
> holds many traps for the unwary in terms of definitions, and some casual
> definitions in the original glm function, going as far back as the S3
> language, aid in the confusion.  For example, the dev.resid function in a
> GLM family doesn't return the deviance residuals - it returns the square of
> the deviance residuals, which should be named the "unit deviances".
>
> Given a response vector and the predicted mean vector and a distribution
> family one can define the unit deviances, which play a role similar to the
> squared residual in the Gaussian family.  The sum of these unit deviances
> is the deviance of a generalized linear model, but it is not the deviance
> of a generalized linear mixed model, because the likelihood for a GLMM
> involves both a "fidelity to the data" term *and* a "complexity of the
> model" term, which is the size of the random effects vector in a certain
> metric.
>
> So if indeed we used an inappropriate definition of deviance the mistake
> is ours and we should correct it.
>
> On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com> wrote:
>
>> You say you are comparing conditional deviances rather than marginal
>> deviances.  Can you expand on that a bit further?  How are you evaluating
>> the conditional deviances?
>>
>> The models are being fit according to what you describe as the marginal
>> deviance - what I would call the deviance.  It is not surprising that what
>> you are calling the conditional deviance is inconsistent with the nesting
>> of the models because they weren't fit according to that criterion.
>>
>> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
>>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>        end
>> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>   y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>>   Distribution: Bernoulli{Float64}
>>   Link: LogitLink()
>>
>>    logLik    deviance     AIC       AICc        BIC
>>  -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
>>
>> Variance components:
>>       Column   Variance Std.Dev.
>> id (Intercept)  0.270823 0.520406
>>
>>  Number of obs: 2217; levels of grouping factors: 331
>>
>> Fixed-effects parameters:
>> ????????????????????????????????????????????????????
>>                   Coef.  Std. Error      z  Pr(>|z|)
>> ????????????????????????????????????????????????????
>> (Intercept)   0.0969256   0.140211    0.69    0.4894
>> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
>> x2            0.0744891   0.0133743   5.57    <1e-07
>> x3           -0.548392    0.0914109  -6.00    <1e-08
>> x4: B         0.390359    0.0803063   4.86    <1e-05
>> x4: C         0.299932    0.0991249   3.03    0.0025
>> ????????????????????????????????????????????????????
>>
>> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
>>            fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>        end
>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>   y ~ 1 + x1 + x2 + x3 + (1 | id)
>>   Distribution: Bernoulli{Float64}
>>   Link: LogitLink()
>>
>>    logLik    deviance     AIC       AICc        BIC
>>  -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
>>
>> Variance components:
>>       Column   Variance Std.Dev.
>> id (Intercept)  0.274331 0.523766
>>
>>  Number of obs: 2217; levels of grouping factors: 331
>>
>> Fixed-effects parameters:
>> ????????????????????????????????????????????????????
>>                   Coef.  Std. Error      z  Pr(>|z|)
>> ????????????????????????????????????????????????????
>> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
>> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
>> x2            0.0694393   0.0131541   5.28    <1e-06
>> x3           -0.556903    0.0904798  -6.15    <1e-09
>> ????????????????????????????????????????????????????
>>
>> julia> MixedModels.likelihoodratiotest(m02, m01)
>> Model Formulae
>> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
>> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>> ??????????????????????????????????????????????????
>>      model-dof   deviance       ??  ??-dof  P(>??)
>> ??????????????????????????????????????????????????
>> [1]          5  2944.0654
>> [2]          7  2900.8511  43.2144       2  <1e-09
>> ??????????????????????????????????????????????????
>>
>> I would note that your data are so imbalanced with respect to id that it
>> is not surprising that you get unstable results.  (I changed your id column
>> from integers to a factor so that 33 becomes S033.)
>>
>> 331?2 DataFrame
>>  Row ? id      nrow
>>      ? String  Int64
>> ?????????????????????
>>    1 ? S033     1227
>>    2 ? S134       46
>>    3 ? S295       45
>>    4 ? S127       41
>>    5 ? S125       33
>>    6 ? S228       31
>>    7 ? S193       23
>>    8 ? S064       18
>>    9 ? S281       16
>>   10 ? S055       13
>>   11 ? S035       13
>>   12 ? S091       12
>>   13 ? S175       11
>>   14 ? S284       10
>>   15 ? S159       10
>>   ?  ?   ?       ?
>>  317 ? S324        1
>>  318 ? S115        1
>>  319 ? S192        1
>>  320 ? S201        1
>>  321 ? S156        1
>>  322 ? S202        1
>>  323 ? S067        1
>>  324 ? S264        1
>>  325 ? S023        1
>>  326 ? S090        1
>>  327 ? S195        1
>>  328 ? S170        1
>>  329 ? S241        1
>>  330 ? S189        1
>>  331 ? S213        1
>>      301 rows omitted
>>
>>
>>
>> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
>> juho.kristian.ruohonen at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I thought it was impossible for deviance to decrease when a term is
>>> removed!?!? Yet I'm seeing it happen with this pair of relatively simple
>>> Bernoulli GLMMs fit using lme4:glmer():
>>>
>>> > full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
>>> > 6, data = anon)
>>>
>>> > reduced <- update(full, ~. -x1)
>>>
>>> > c(full = deviance(full), reduced = deviance(reduced))
>>>
>>>
>>> *     full  reduced*
>>> *2808.671 2807.374 *
>>>
>>> What on earth going on? FYI, I am deliberately comparing conditional
>>> deviances rather than marginal ones, because quite a few of the clusters
>>> are of inherent interest and likely to recur in future data.
>>>
>>> My anonymized datafile is attached.
>>>
>>> Best,
>>>
>>> Juho
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Thu Aug 31 16:08:45 2023
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 31 Aug 2023 09:08:45 -0500
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
 <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
Message-ID: <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>

I think this highlights the intersection of two big stumbling blocks:

1. a lot of identities / niceness in classical GLM theory doesn't hold 
in the mixed models case. See also coefficient of determination, clear 
notions of denominator degrees of freedom for F tests, etc.

2. a lot of R and S functionality around GLMs is based on convenient 
computational quantities in classical GLM theory. This leads to some 
infelicity in naming, which is further confused by (1) for mixed models.

I think this highlights a real challenge to many users, also because of 
the way we teach statistics. (I'm teaching a course soon, can everyone 
tell?) Many intro statistics courses state things like "the coefficient 
of determination, R^2, is the squared Pearson correlation, r, and can be 
interpreted as ....". But we don't highlight that that's an identity for 
simple linear regression and not the formal definition of the 
coefficient of determination. We also don't emphasize how many of these 
definitions hinge on concepts that don't have an obvious extension to 
multi-level models or perhaps none of the obvious extensions hold all 
the properties of the classical GLM form. (Most of this is discussed in 
the GLMM FAQ!)

This is a criticism of myself as an instructor as much as anything, but 
it's something I like to emphasize in teaching nowadays and highlight as 
a point 're-education' for students who've had a more traditional education.

Phillip

On 8/31/23 08:45, Douglas Bates wrote:
> I have written about how I now understand the evaluation of the likelihood
> of a GLMM in an appendix of the in-progress book at
> https://juliamixedmodels.github.io/EmbraceUncertainty
>
> It is a difficult area to make sense of.  Even now, after more than 25
> years of thinking about these models, I am still not sure exactly how to
> define the objective in a GLMM for a family with a dispersion parameter.
>
> On Thu, Aug 31, 2023 at 8:37?AM Douglas Bates <dmbates at gmail.com> wrote:
>
>> I may have attributed the confusion about conditional and marginal
>> deviances to you, Juho, when in fact it is the fault of the authors of
>> lme4, of whom I am one.  If so, I apologize.
>>
>> We (the authors of lme4) had a discussion about the definition of deviance
>> many years ago and I am not sure what the upshot was.  It may have been
>> that we went with this incorrect definition of the "conditional deviance".
>> Unfortunately my R skills are sufficiently atrophied that I haven't been
>> able to look up what is actually evaluated.
>>
>> The area of generalized linear models and generalized linear mixed models
>> holds many traps for the unwary in terms of definitions, and some casual
>> definitions in the original glm function, going as far back as the S3
>> language, aid in the confusion.  For example, the dev.resid function in a
>> GLM family doesn't return the deviance residuals - it returns the square of
>> the deviance residuals, which should be named the "unit deviances".
>>
>> Given a response vector and the predicted mean vector and a distribution
>> family one can define the unit deviances, which play a role similar to the
>> squared residual in the Gaussian family.  The sum of these unit deviances
>> is the deviance of a generalized linear model, but it is not the deviance
>> of a generalized linear mixed model, because the likelihood for a GLMM
>> involves both a "fidelity to the data" term *and* a "complexity of the
>> model" term, which is the size of the random effects vector in a certain
>> metric.
>>
>> So if indeed we used an inappropriate definition of deviance the mistake
>> is ours and we should correct it.
>>
>> On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com> wrote:
>>
>>> You say you are comparing conditional deviances rather than marginal
>>> deviances.  Can you expand on that a bit further?  How are you evaluating
>>> the conditional deviances?
>>>
>>> The models are being fit according to what you describe as the marginal
>>> deviance - what I would call the deviance.  It is not surprising that what
>>> you are calling the conditional deviance is inconsistent with the nesting
>>> of the models because they weren't fit according to that criterion.
>>>
>>> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>>         end
>>> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>>    y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>>>    Distribution: Bernoulli{Float64}
>>>    Link: LogitLink()
>>>
>>>     logLik    deviance     AIC       AICc        BIC
>>>   -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
>>>
>>> Variance components:
>>>        Column   Variance Std.Dev.
>>> id (Intercept)  0.270823 0.520406
>>>
>>>   Number of obs: 2217; levels of grouping factors: 331
>>>
>>> Fixed-effects parameters:
>>> ????????????????????????????????????????????????????
>>>                    Coef.  Std. Error      z  Pr(>|z|)
>>> ????????????????????????????????????????????????????
>>> (Intercept)   0.0969256   0.140211    0.69    0.4894
>>> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
>>> x2            0.0744891   0.0133743   5.57    <1e-07
>>> x3           -0.548392    0.0914109  -6.00    <1e-08
>>> x4: B         0.390359    0.0803063   4.86    <1e-05
>>> x4: C         0.299932    0.0991249   3.03    0.0025
>>> ????????????????????????????????????????????????????
>>>
>>> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>>         end
>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>>    y ~ 1 + x1 + x2 + x3 + (1 | id)
>>>    Distribution: Bernoulli{Float64}
>>>    Link: LogitLink()
>>>
>>>     logLik    deviance     AIC       AICc        BIC
>>>   -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
>>>
>>> Variance components:
>>>        Column   Variance Std.Dev.
>>> id (Intercept)  0.274331 0.523766
>>>
>>>   Number of obs: 2217; levels of grouping factors: 331
>>>
>>> Fixed-effects parameters:
>>> ????????????????????????????????????????????????????
>>>                    Coef.  Std. Error      z  Pr(>|z|)
>>> ????????????????????????????????????????????????????
>>> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
>>> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
>>> x2            0.0694393   0.0131541   5.28    <1e-06
>>> x3           -0.556903    0.0904798  -6.15    <1e-09
>>> ????????????????????????????????????????????????????
>>>
>>> julia> MixedModels.likelihoodratiotest(m02, m01)
>>> Model Formulae
>>> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
>>> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>>> ??????????????????????????????????????????????????
>>>       model-dof   deviance       ??  ??-dof  P(>??)
>>> ??????????????????????????????????????????????????
>>> [1]          5  2944.0654
>>> [2]          7  2900.8511  43.2144       2  <1e-09
>>> ??????????????????????????????????????????????????
>>>
>>> I would note that your data are so imbalanced with respect to id that it
>>> is not surprising that you get unstable results.  (I changed your id column
>>> from integers to a factor so that 33 becomes S033.)
>>>
>>> 331?2 DataFrame
>>>   Row ? id      nrow
>>>       ? String  Int64
>>> ?????????????????????
>>>     1 ? S033     1227
>>>     2 ? S134       46
>>>     3 ? S295       45
>>>     4 ? S127       41
>>>     5 ? S125       33
>>>     6 ? S228       31
>>>     7 ? S193       23
>>>     8 ? S064       18
>>>     9 ? S281       16
>>>    10 ? S055       13
>>>    11 ? S035       13
>>>    12 ? S091       12
>>>    13 ? S175       11
>>>    14 ? S284       10
>>>    15 ? S159       10
>>>    ?  ?   ?       ?
>>>   317 ? S324        1
>>>   318 ? S115        1
>>>   319 ? S192        1
>>>   320 ? S201        1
>>>   321 ? S156        1
>>>   322 ? S202        1
>>>   323 ? S067        1
>>>   324 ? S264        1
>>>   325 ? S023        1
>>>   326 ? S090        1
>>>   327 ? S195        1
>>>   328 ? S170        1
>>>   329 ? S241        1
>>>   330 ? S189        1
>>>   331 ? S213        1
>>>       301 rows omitted
>>>
>>>
>>>
>>> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
>>> juho.kristian.ruohonen at gmail.com> wrote:
>>>
>>>> Hi,
>>>>
>>>> I thought it was impossible for deviance to decrease when a term is
>>>> removed!?!? Yet I'm seeing it happen with this pair of relatively simple
>>>> Bernoulli GLMMs fit using lme4:glmer():
>>>>
>>>>> full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, nAGQ =
>>>>> 6, data = anon)
>>>>> reduced <- update(full, ~. -x1)
>>>>> c(full = deviance(full), reduced = deviance(reduced))
>>>>
>>>> *     full  reduced*
>>>> *2808.671 2807.374 *
>>>>
>>>> What on earth going on? FYI, I am deliberately comparing conditional
>>>> deviances rather than marginal ones, because quite a few of the clusters
>>>> are of inherent interest and likely to recur in future data.
>>>>
>>>> My anonymized datafile is attached.
>>>>
>>>> Best,
>>>>
>>>> Juho
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Aug 31 19:42:41 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 31 Aug 2023 13:42:41 -0400
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
 <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
 <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>
Message-ID: <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>

   For what it's worth we did attempt to document what we knew about 
deviance here:

https://github.com/lme4/lme4/blob/master/man/merMod-class.Rd
(formatted version at  https://rdrr.io/cran/lme4/man/merMod-class.html)

in particular the note that says

\item If adaptive Gauss-Hermite quadrature is used, then
     \code{logLik(object)} is currently only proportional to the
     absolute-unconditional log-likelihood.

   To make things worth, this is about "absolute" vs "relative" and 
"conditional" vs "unconditional", "marginal" doesn't even come into it ...

   I will take a look at the example myself if I get a chance, as I find 
the result surprising too ...

   cheers
     Ben Bolker



On 2023-08-31 10:08 a.m., Phillip Alday wrote:
> I think this highlights the intersection of two big stumbling blocks:
> 
> 1. a lot of identities / niceness in classical GLM theory doesn't hold 
> in the mixed models case. See also coefficient of determination, clear 
> notions of denominator degrees of freedom for F tests, etc.
> 
> 2. a lot of R and S functionality around GLMs is based on convenient 
> computational quantities in classical GLM theory. This leads to some 
> infelicity in naming, which is further confused by (1) for mixed models.
> 
> I think this highlights a real challenge to many users, also because of 
> the way we teach statistics. (I'm teaching a course soon, can everyone 
> tell?) Many intro statistics courses state things like "the coefficient 
> of determination, R^2, is the squared Pearson correlation, r, and can be 
> interpreted as ....". But we don't highlight that that's an identity for 
> simple linear regression and not the formal definition of the 
> coefficient of determination. We also don't emphasize how many of these 
> definitions hinge on concepts that don't have an obvious extension to 
> multi-level models or perhaps none of the obvious extensions hold all 
> the properties of the classical GLM form. (Most of this is discussed in 
> the GLMM FAQ!)
> 
> This is a criticism of myself as an instructor as much as anything, but 
> it's something I like to emphasize in teaching nowadays and highlight as 
> a point 're-education' for students who've had a more traditional 
> education.
> 
> Phillip
> 
> On 8/31/23 08:45, Douglas Bates wrote:
>> I have written about how I now understand the evaluation of the 
>> likelihood
>> of a GLMM in an appendix of the in-progress book at
>> https://juliamixedmodels.github.io/EmbraceUncertainty
>>
>> It is a difficult area to make sense of.? Even now, after more than 25
>> years of thinking about these models, I am still not sure exactly how to
>> define the objective in a GLMM for a family with a dispersion parameter.
>>
>> On Thu, Aug 31, 2023 at 8:37?AM Douglas Bates <dmbates at gmail.com> wrote:
>>
>>> I may have attributed the confusion about conditional and marginal
>>> deviances to you, Juho, when in fact it is the fault of the authors of
>>> lme4, of whom I am one.? If so, I apologize.
>>>
>>> We (the authors of lme4) had a discussion about the definition of 
>>> deviance
>>> many years ago and I am not sure what the upshot was.? It may have been
>>> that we went with this incorrect definition of the "conditional 
>>> deviance".
>>> Unfortunately my R skills are sufficiently atrophied that I haven't been
>>> able to look up what is actually evaluated.
>>>
>>> The area of generalized linear models and generalized linear mixed 
>>> models
>>> holds many traps for the unwary in terms of definitions, and some casual
>>> definitions in the original glm function, going as far back as the S3
>>> language, aid in the confusion.? For example, the dev.resid function 
>>> in a
>>> GLM family doesn't return the deviance residuals - it returns the 
>>> square of
>>> the deviance residuals, which should be named the "unit deviances".
>>>
>>> Given a response vector and the predicted mean vector and a distribution
>>> family one can define the unit deviances, which play a role similar 
>>> to the
>>> squared residual in the Gaussian family.? The sum of these unit 
>>> deviances
>>> is the deviance of a generalized linear model, but it is not the 
>>> deviance
>>> of a generalized linear mixed model, because the likelihood for a GLMM
>>> involves both a "fidelity to the data" term *and* a "complexity of the
>>> model" term, which is the size of the random effects vector in a certain
>>> metric.
>>>
>>> So if indeed we used an inappropriate definition of deviance the mistake
>>> is ours and we should correct it.
>>>
>>> On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com> wrote:
>>>
>>>> You say you are comparing conditional deviances rather than marginal
>>>> deviances.? Can you expand on that a bit further?? How are you 
>>>> evaluating
>>>> the conditional deviances?
>>>>
>>>> The models are being fit according to what you describe as the marginal
>>>> deviance - what I would call the deviance.? It is not surprising 
>>>> that what
>>>> you are calling the conditional deviance is inconsistent with the 
>>>> nesting
>>>> of the models because they weren't fit according to that criterion.
>>>>
>>>> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
>>>> ??????????? fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>>> ??????? end
>>>> Minimizing 141?? Time: 0:00:00 ( 1.22 ms/it)
>>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>>> ?? y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>>>> ?? Distribution: Bernoulli{Float64}
>>>> ?? Link: LogitLink()
>>>>
>>>> ??? logLik??? deviance???? AIC?????? AICc??????? BIC
>>>> ? -1450.8163? 2900.8511? 2915.6326? 2915.6833? 2955.5600
>>>>
>>>> Variance components:
>>>> ?????? Column?? Variance Std.Dev.
>>>> id (Intercept)? 0.270823 0.520406
>>>>
>>>> ? Number of obs: 2217; levels of grouping factors: 331
>>>>
>>>> Fixed-effects parameters:
>>>> ????????????????????????????????????????????????????
>>>> ?????????????????? Coef.? Std. Error????? z? Pr(>|z|)
>>>> ????????????????????????????????????????????????????
>>>> (Intercept)?? 0.0969256?? 0.140211??? 0.69??? 0.4894
>>>> x1: 1??????? -0.0449824?? 0.0553361? -0.81??? 0.4163
>>>> x2??????????? 0.0744891?? 0.0133743?? 5.57??? <1e-07
>>>> x3?????????? -0.548392??? 0.0914109? -6.00??? <1e-08
>>>> x4: B???????? 0.390359??? 0.0803063?? 4.86??? <1e-05
>>>> x4: C???????? 0.299932??? 0.0991249?? 3.03??? 0.0025
>>>> ????????????????????????????????????????????????????
>>>>
>>>> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
>>>> ??????????? fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
>>>> ??????? end
>>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
>>>> ?? y ~ 1 + x1 + x2 + x3 + (1 | id)
>>>> ?? Distribution: Bernoulli{Float64}
>>>> ?? Link: LogitLink()
>>>>
>>>> ??? logLik??? deviance???? AIC?????? AICc??????? BIC
>>>> ? -1472.4551? 2944.0654? 2954.9102? 2954.9373? 2983.4297
>>>>
>>>> Variance components:
>>>> ?????? Column?? Variance Std.Dev.
>>>> id (Intercept)? 0.274331 0.523766
>>>>
>>>> ? Number of obs: 2217; levels of grouping factors: 331
>>>>
>>>> Fixed-effects parameters:
>>>> ????????????????????????????????????????????????????
>>>> ?????????????????? Coef.? Std. Error????? z? Pr(>|z|)
>>>> ????????????????????????????????????????????????????
>>>> (Intercept)? -0.448496??? 0.100915?? -4.44??? <1e-05
>>>> x1: 1??????? -0.0527684?? 0.0547746? -0.96??? 0.3354
>>>> x2??????????? 0.0694393?? 0.0131541?? 5.28??? <1e-06
>>>> x3?????????? -0.556903??? 0.0904798? -6.15??? <1e-09
>>>> ????????????????????????????????????????????????????
>>>>
>>>> julia> MixedModels.likelihoodratiotest(m02, m01)
>>>> Model Formulae
>>>> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
>>>> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
>>>> ??????????????????????????????????????????????????
>>>> ????? model-dof?? deviance?????? ??? ??-dof? P(>??)
>>>> ??????????????????????????????????????????????????
>>>> [1]????????? 5? 2944.0654
>>>> [2]????????? 7? 2900.8511? 43.2144?????? 2? <1e-09
>>>> ??????????????????????????????????????????????????
>>>>
>>>> I would note that your data are so imbalanced with respect to id 
>>>> that it
>>>> is not surprising that you get unstable results.? (I changed your id 
>>>> column
>>>> from integers to a factor so that 33 becomes S033.)
>>>>
>>>> 331?2 DataFrame
>>>> ? Row ? id????? nrow
>>>> ????? ? String? Int64
>>>> ?????????????????????
>>>> ??? 1 ? S033???? 1227
>>>> ??? 2 ? S134?????? 46
>>>> ??? 3 ? S295?????? 45
>>>> ??? 4 ? S127?????? 41
>>>> ??? 5 ? S125?????? 33
>>>> ??? 6 ? S228?????? 31
>>>> ??? 7 ? S193?????? 23
>>>> ??? 8 ? S064?????? 18
>>>> ??? 9 ? S281?????? 16
>>>> ?? 10 ? S055?????? 13
>>>> ?? 11 ? S035?????? 13
>>>> ?? 12 ? S091?????? 12
>>>> ?? 13 ? S175?????? 11
>>>> ?? 14 ? S284?????? 10
>>>> ?? 15 ? S159?????? 10
>>>> ?? ?? ??? ??????? ?
>>>> ? 317 ? S324??????? 1
>>>> ? 318 ? S115??????? 1
>>>> ? 319 ? S192??????? 1
>>>> ? 320 ? S201??????? 1
>>>> ? 321 ? S156??????? 1
>>>> ? 322 ? S202??????? 1
>>>> ? 323 ? S067??????? 1
>>>> ? 324 ? S264??????? 1
>>>> ? 325 ? S023??????? 1
>>>> ? 326 ? S090??????? 1
>>>> ? 327 ? S195??????? 1
>>>> ? 328 ? S170??????? 1
>>>> ? 329 ? S241??????? 1
>>>> ? 330 ? S189??????? 1
>>>> ? 331 ? S213??????? 1
>>>> ????? 301 rows omitted
>>>>
>>>>
>>>>
>>>> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
>>>> juho.kristian.ruohonen at gmail.com> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I thought it was impossible for deviance to decrease when a term is
>>>>> removed!?!? Yet I'm seeing it happen with this pair of relatively 
>>>>> simple
>>>>> Bernoulli GLMMs fit using lme4:glmer():
>>>>>
>>>>>> full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial, 
>>>>>> nAGQ =
>>>>>> 6, data = anon)
>>>>>> reduced <- update(full, ~. -x1)
>>>>>> c(full = deviance(full), reduced = deviance(reduced))
>>>>>
>>>>> *???? full? reduced*
>>>>> *2808.671 2807.374 *
>>>>>
>>>>> What on earth going on? FYI, I am deliberately comparing conditional
>>>>> deviances rather than marginal ones, because quite a few of the 
>>>>> clusters
>>>>> are of inherent interest and likely to recur in future data.
>>>>>
>>>>> My anonymized datafile is attached.
>>>>>
>>>>> Best,
>>>>>
>>>>> Juho
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Aug 31 21:38:51 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 31 Aug 2023 22:38:51 +0300
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
 <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
 <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>
 <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
Message-ID: <CAG_dBVeY8OSR1K_gUDzqt2+gLGQ6uWQqHLYPkkPGGtNokj05bA@mail.gmail.com>

...and here I was thinking "unconditional likelihood" was just another
synonym for the "marginal" or "average" likelihood I see discussed in stats
books...

Oh well, Douglas has succinctly solved my main problem. Any further
insights are just icing on the cake.

Thanks again to all,

J

to 31. elok. 2023 klo 20.43 Ben Bolker (bbolker at gmail.com) kirjoitti:

>    For what it's worth we did attempt to document what we knew about
> deviance here:
>
> https://github.com/lme4/lme4/blob/master/man/merMod-class.Rd
> (formatted version at  https://rdrr.io/cran/lme4/man/merMod-class.html)
>
> in particular the note that says
>
> \item If adaptive Gauss-Hermite quadrature is used, then
>      \code{logLik(object)} is currently only proportional to the
>      absolute-unconditional log-likelihood.
>
>    To make things worth, this is about "absolute" vs "relative" and
> "conditional" vs "unconditional", "marginal" doesn't even come into it ...
>
>    I will take a look at the example myself if I get a chance, as I find
> the result surprising too ...
>
>    cheers
>      Ben Bolker
>
>
>
> On 2023-08-31 10:08 a.m., Phillip Alday wrote:
> > I think this highlights the intersection of two big stumbling blocks:
> >
> > 1. a lot of identities / niceness in classical GLM theory doesn't hold
> > in the mixed models case. See also coefficient of determination, clear
> > notions of denominator degrees of freedom for F tests, etc.
> >
> > 2. a lot of R and S functionality around GLMs is based on convenient
> > computational quantities in classical GLM theory. This leads to some
> > infelicity in naming, which is further confused by (1) for mixed models.
> >
> > I think this highlights a real challenge to many users, also because of
> > the way we teach statistics. (I'm teaching a course soon, can everyone
> > tell?) Many intro statistics courses state things like "the coefficient
> > of determination, R^2, is the squared Pearson correlation, r, and can be
> > interpreted as ....". But we don't highlight that that's an identity for
> > simple linear regression and not the formal definition of the
> > coefficient of determination. We also don't emphasize how many of these
> > definitions hinge on concepts that don't have an obvious extension to
> > multi-level models or perhaps none of the obvious extensions hold all
> > the properties of the classical GLM form. (Most of this is discussed in
> > the GLMM FAQ!)
> >
> > This is a criticism of myself as an instructor as much as anything, but
> > it's something I like to emphasize in teaching nowadays and highlight as
> > a point 're-education' for students who've had a more traditional
> > education.
> >
> > Phillip
> >
> > On 8/31/23 08:45, Douglas Bates wrote:
> >> I have written about how I now understand the evaluation of the
> >> likelihood
> >> of a GLMM in an appendix of the in-progress book at
> >> https://juliamixedmodels.github.io/EmbraceUncertainty
> >>
> >> It is a difficult area to make sense of.  Even now, after more than 25
> >> years of thinking about these models, I am still not sure exactly how to
> >> define the objective in a GLMM for a family with a dispersion parameter.
> >>
> >> On Thu, Aug 31, 2023 at 8:37?AM Douglas Bates <dmbates at gmail.com>
> wrote:
> >>
> >>> I may have attributed the confusion about conditional and marginal
> >>> deviances to you, Juho, when in fact it is the fault of the authors of
> >>> lme4, of whom I am one.  If so, I apologize.
> >>>
> >>> We (the authors of lme4) had a discussion about the definition of
> >>> deviance
> >>> many years ago and I am not sure what the upshot was.  It may have been
> >>> that we went with this incorrect definition of the "conditional
> >>> deviance".
> >>> Unfortunately my R skills are sufficiently atrophied that I haven't
> been
> >>> able to look up what is actually evaluated.
> >>>
> >>> The area of generalized linear models and generalized linear mixed
> >>> models
> >>> holds many traps for the unwary in terms of definitions, and some
> casual
> >>> definitions in the original glm function, going as far back as the S3
> >>> language, aid in the confusion.  For example, the dev.resid function
> >>> in a
> >>> GLM family doesn't return the deviance residuals - it returns the
> >>> square of
> >>> the deviance residuals, which should be named the "unit deviances".
> >>>
> >>> Given a response vector and the predicted mean vector and a
> distribution
> >>> family one can define the unit deviances, which play a role similar
> >>> to the
> >>> squared residual in the Gaussian family.  The sum of these unit
> >>> deviances
> >>> is the deviance of a generalized linear model, but it is not the
> >>> deviance
> >>> of a generalized linear mixed model, because the likelihood for a GLMM
> >>> involves both a "fidelity to the data" term *and* a "complexity of the
> >>> model" term, which is the size of the random effects vector in a
> certain
> >>> metric.
> >>>
> >>> So if indeed we used an inappropriate definition of deviance the
> mistake
> >>> is ours and we should correct it.
> >>>
> >>> On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com>
> wrote:
> >>>
> >>>> You say you are comparing conditional deviances rather than marginal
> >>>> deviances.  Can you expand on that a bit further?  How are you
> >>>> evaluating
> >>>> the conditional deviances?
> >>>>
> >>>> The models are being fit according to what you describe as the
> marginal
> >>>> deviance - what I would call the deviance.  It is not surprising
> >>>> that what
> >>>> you are calling the conditional deviance is inconsistent with the
> >>>> nesting
> >>>> of the models because they weren't fit according to that criterion.
> >>>>
> >>>> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
> >>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
> >>>>         end
> >>>> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
> >>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
> >>>>    y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> >>>>    Distribution: Bernoulli{Float64}
> >>>>    Link: LogitLink()
> >>>>
> >>>>     logLik    deviance     AIC       AICc        BIC
> >>>>   -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
> >>>>
> >>>> Variance components:
> >>>>        Column   Variance Std.Dev.
> >>>> id (Intercept)  0.270823 0.520406
> >>>>
> >>>>   Number of obs: 2217; levels of grouping factors: 331
> >>>>
> >>>> Fixed-effects parameters:
> >>>> ????????????????????????????????????????????????????
> >>>>                    Coef.  Std. Error      z  Pr(>|z|)
> >>>> ????????????????????????????????????????????????????
> >>>> (Intercept)   0.0969256   0.140211    0.69    0.4894
> >>>> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
> >>>> x2            0.0744891   0.0133743   5.57    <1e-07
> >>>> x3           -0.548392    0.0914109  -6.00    <1e-08
> >>>> x4: B         0.390359    0.0803063   4.86    <1e-05
> >>>> x4: C         0.299932    0.0991249   3.03    0.0025
> >>>> ????????????????????????????????????????????????????
> >>>>
> >>>> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
> >>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
> >>>>         end
> >>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
> >>>>    y ~ 1 + x1 + x2 + x3 + (1 | id)
> >>>>    Distribution: Bernoulli{Float64}
> >>>>    Link: LogitLink()
> >>>>
> >>>>     logLik    deviance     AIC       AICc        BIC
> >>>>   -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
> >>>>
> >>>> Variance components:
> >>>>        Column   Variance Std.Dev.
> >>>> id (Intercept)  0.274331 0.523766
> >>>>
> >>>>   Number of obs: 2217; levels of grouping factors: 331
> >>>>
> >>>> Fixed-effects parameters:
> >>>> ????????????????????????????????????????????????????
> >>>>                    Coef.  Std. Error      z  Pr(>|z|)
> >>>> ????????????????????????????????????????????????????
> >>>> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
> >>>> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
> >>>> x2            0.0694393   0.0131541   5.28    <1e-06
> >>>> x3           -0.556903    0.0904798  -6.15    <1e-09
> >>>> ????????????????????????????????????????????????????
> >>>>
> >>>> julia> MixedModels.likelihoodratiotest(m02, m01)
> >>>> Model Formulae
> >>>> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
> >>>> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> >>>> ??????????????????????????????????????????????????
> >>>>       model-dof   deviance       ??  ??-dof  P(>??)
> >>>> ??????????????????????????????????????????????????
> >>>> [1]          5  2944.0654
> >>>> [2]          7  2900.8511  43.2144       2  <1e-09
> >>>> ??????????????????????????????????????????????????
> >>>>
> >>>> I would note that your data are so imbalanced with respect to id
> >>>> that it
> >>>> is not surprising that you get unstable results.  (I changed your id
> >>>> column
> >>>> from integers to a factor so that 33 becomes S033.)
> >>>>
> >>>> 331?2 DataFrame
> >>>>   Row ? id      nrow
> >>>>       ? String  Int64
> >>>> ?????????????????????
> >>>>     1 ? S033     1227
> >>>>     2 ? S134       46
> >>>>     3 ? S295       45
> >>>>     4 ? S127       41
> >>>>     5 ? S125       33
> >>>>     6 ? S228       31
> >>>>     7 ? S193       23
> >>>>     8 ? S064       18
> >>>>     9 ? S281       16
> >>>>    10 ? S055       13
> >>>>    11 ? S035       13
> >>>>    12 ? S091       12
> >>>>    13 ? S175       11
> >>>>    14 ? S284       10
> >>>>    15 ? S159       10
> >>>>    ?  ?   ?       ?
> >>>>   317 ? S324        1
> >>>>   318 ? S115        1
> >>>>   319 ? S192        1
> >>>>   320 ? S201        1
> >>>>   321 ? S156        1
> >>>>   322 ? S202        1
> >>>>   323 ? S067        1
> >>>>   324 ? S264        1
> >>>>   325 ? S023        1
> >>>>   326 ? S090        1
> >>>>   327 ? S195        1
> >>>>   328 ? S170        1
> >>>>   329 ? S241        1
> >>>>   330 ? S189        1
> >>>>   331 ? S213        1
> >>>>       301 rows omitted
> >>>>
> >>>>
> >>>>
> >>>> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
> >>>> juho.kristian.ruohonen at gmail.com> wrote:
> >>>>
> >>>>> Hi,
> >>>>>
> >>>>> I thought it was impossible for deviance to decrease when a term is
> >>>>> removed!?!? Yet I'm seeing it happen with this pair of relatively
> >>>>> simple
> >>>>> Bernoulli GLMMs fit using lme4:glmer():
> >>>>>
> >>>>>> full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial,
> >>>>>> nAGQ =
> >>>>>> 6, data = anon)
> >>>>>> reduced <- update(full, ~. -x1)
> >>>>>> c(full = deviance(full), reduced = deviance(reduced))
> >>>>>
> >>>>> *     full  reduced*
> >>>>> *2808.671 2807.374 *
> >>>>>
> >>>>> What on earth going on? FYI, I am deliberately comparing conditional
> >>>>> deviances rather than marginal ones, because quite a few of the
> >>>>> clusters
> >>>>> are of inherent interest and likely to recur in future data.
> >>>>>
> >>>>> My anonymized datafile is attached.
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Juho
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>     [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From i@io m@iii@g oii phys@ii@-courses@org  Sun Sep  3 22:49:53 2023
From: i@io m@iii@g oii phys@ii@-courses@org (i@io m@iii@g oii phys@ii@-courses@org)
Date: Sun, 3 Sep 2023 22:49:53 +0200 (CEST)
Subject: [R-sig-ME] Course - GENERALISED LINEAR MIXED MODELS IN R
Message-ID: <1693774193.55619147@webmail.jimdo.com>


Dear all,
 
We hope this message finds you well. We are excited to announce our upcoming course on (GENERALISED) LINEAR MIXED MODELS IN R, which is set to take place from October 9th to 13th, 2023. To encourage global participation, this course will be conducted online.
 
Course website: https://www.physalia-courses.org/courses-workshops/glmms-in-r/
 
n this course, you will gain hands-on experience in specifying, interpreting, and validating linear and generalized linear mixed models, all within the applied research context of R. The emphasis will be on utilizing the lme4 and glmmTMB regression packages.
 
 
We are excited to inform you that we have just FOUR seats remaining for this course. This is your last chance to secure your spot and deepen your understanding of GLMMs in R.
 
 
By the end of this course, you will:
1. Deepen your understanding of fundamental regression concepts.
2. Grasp the components of the GLMM framework, including distributions, random effects, variance structures, and correlation structures.
3. Gain the ability to select the appropriate model structure for applied analysis of experimental or observational data, with a focus on the R packages lme4 and glmmTMB.
4. Learn how to visualize fitted GLMMs (using the R package effects) and check the assumptions of your model (utilizing the R package DHARMa).
 
 
Best regards,
Carlo
 
 
 
 
--------------------

Carlo Pecoraro, Ph.D


Physalia-courses DIRECTOR

info at physalia-courses.org

mobile: +49 17645230846

Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon ]( https://mas.to/@PhysaliaCourses )
	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Mon Sep  4 10:32:41 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Mon, 4 Sep 2023 11:32:41 +0300
Subject: [R-sig-ME] 
 glmer conditional deviance DECREASING after removal of
 fixed effect??
In-Reply-To: <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
 <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
 <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>
 <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
Message-ID: <CAG_dBVd40nmU3LccNB5WYDZ_fOXS7=5-MeC75OXYi0ixLnTaEw@mail.gmail.com>

Sorry to flog a moribund horse, but it turns out I wasn't alone in my
confusion regarding "marginal" vs "unconditional": even the authors of the
cAIC4 library, in the article
<https://www.jstatsoft.org/article/view/v099i08>introducing said library,
state the following (Appendix B.3, emphasis mine):

Notice that the log-likelihood that by default is calculated by the S3
> method logLik for class ?merMod? (the class of a mixed model fitted by a
> lmer call) is the *marginal log-likelihood*.


 Best,

Juho

to 31. elok. 2023 klo 20.43 Ben Bolker (bbolker at gmail.com) kirjoitti:

>    For what it's worth we did attempt to document what we knew about
> deviance here:
>
> https://github.com/lme4/lme4/blob/master/man/merMod-class.Rd
> (formatted version at  https://rdrr.io/cran/lme4/man/merMod-class.html)
>
> in particular the note that says
>
> \item If adaptive Gauss-Hermite quadrature is used, then
>      \code{logLik(object)} is currently only proportional to the
>      absolute-unconditional log-likelihood.
>
>    To make things worth, this is about "absolute" vs "relative" and
> "conditional" vs "unconditional", "marginal" doesn't even come into it ...
>
>    I will take a look at the example myself if I get a chance, as I find
> the result surprising too ...
>
>    cheers
>      Ben Bolker
>
>
>
> On 2023-08-31 10:08 a.m., Phillip Alday wrote:
> > I think this highlights the intersection of two big stumbling blocks:
> >
> > 1. a lot of identities / niceness in classical GLM theory doesn't hold
> > in the mixed models case. See also coefficient of determination, clear
> > notions of denominator degrees of freedom for F tests, etc.
> >
> > 2. a lot of R and S functionality around GLMs is based on convenient
> > computational quantities in classical GLM theory. This leads to some
> > infelicity in naming, which is further confused by (1) for mixed models.
> >
> > I think this highlights a real challenge to many users, also because of
> > the way we teach statistics. (I'm teaching a course soon, can everyone
> > tell?) Many intro statistics courses state things like "the coefficient
> > of determination, R^2, is the squared Pearson correlation, r, and can be
> > interpreted as ....". But we don't highlight that that's an identity for
> > simple linear regression and not the formal definition of the
> > coefficient of determination. We also don't emphasize how many of these
> > definitions hinge on concepts that don't have an obvious extension to
> > multi-level models or perhaps none of the obvious extensions hold all
> > the properties of the classical GLM form. (Most of this is discussed in
> > the GLMM FAQ!)
> >
> > This is a criticism of myself as an instructor as much as anything, but
> > it's something I like to emphasize in teaching nowadays and highlight as
> > a point 're-education' for students who've had a more traditional
> > education.
> >
> > Phillip
> >
> > On 8/31/23 08:45, Douglas Bates wrote:
> >> I have written about how I now understand the evaluation of the
> >> likelihood
> >> of a GLMM in an appendix of the in-progress book at
> >> https://juliamixedmodels.github.io/EmbraceUncertainty
> >>
> >> It is a difficult area to make sense of.  Even now, after more than 25
> >> years of thinking about these models, I am still not sure exactly how to
> >> define the objective in a GLMM for a family with a dispersion parameter.
> >>
> >> On Thu, Aug 31, 2023 at 8:37?AM Douglas Bates <dmbates at gmail.com>
> wrote:
> >>
> >>> I may have attributed the confusion about conditional and marginal
> >>> deviances to you, Juho, when in fact it is the fault of the authors of
> >>> lme4, of whom I am one.  If so, I apologize.
> >>>
> >>> We (the authors of lme4) had a discussion about the definition of
> >>> deviance
> >>> many years ago and I am not sure what the upshot was.  It may have been
> >>> that we went with this incorrect definition of the "conditional
> >>> deviance".
> >>> Unfortunately my R skills are sufficiently atrophied that I haven't
> been
> >>> able to look up what is actually evaluated.
> >>>
> >>> The area of generalized linear models and generalized linear mixed
> >>> models
> >>> holds many traps for the unwary in terms of definitions, and some
> casual
> >>> definitions in the original glm function, going as far back as the S3
> >>> language, aid in the confusion.  For example, the dev.resid function
> >>> in a
> >>> GLM family doesn't return the deviance residuals - it returns the
> >>> square of
> >>> the deviance residuals, which should be named the "unit deviances".
> >>>
> >>> Given a response vector and the predicted mean vector and a
> distribution
> >>> family one can define the unit deviances, which play a role similar
> >>> to the
> >>> squared residual in the Gaussian family.  The sum of these unit
> >>> deviances
> >>> is the deviance of a generalized linear model, but it is not the
> >>> deviance
> >>> of a generalized linear mixed model, because the likelihood for a GLMM
> >>> involves both a "fidelity to the data" term *and* a "complexity of the
> >>> model" term, which is the size of the random effects vector in a
> certain
> >>> metric.
> >>>
> >>> So if indeed we used an inappropriate definition of deviance the
> mistake
> >>> is ours and we should correct it.
> >>>
> >>> On Thu, Aug 31, 2023 at 7:56?AM Douglas Bates <dmbates at gmail.com>
> wrote:
> >>>
> >>>> You say you are comparing conditional deviances rather than marginal
> >>>> deviances.  Can you expand on that a bit further?  How are you
> >>>> evaluating
> >>>> the conditional deviances?
> >>>>
> >>>> The models are being fit according to what you describe as the
> marginal
> >>>> deviance - what I would call the deviance.  It is not surprising
> >>>> that what
> >>>> you are calling the conditional deviance is inconsistent with the
> >>>> nesting
> >>>> of the models because they weren't fit according to that criterion.
> >>>>
> >>>> julia> m01 = let f = @formula y ~ 1 + x1 + x2 + x3 + x4 + (1|id)
> >>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
> >>>>         end
> >>>> Minimizing 141   Time: 0:00:00 ( 1.22 ms/it)
> >>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
> >>>>    y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> >>>>    Distribution: Bernoulli{Float64}
> >>>>    Link: LogitLink()
> >>>>
> >>>>     logLik    deviance     AIC       AICc        BIC
> >>>>   -1450.8163  2900.8511  2915.6326  2915.6833  2955.5600
> >>>>
> >>>> Variance components:
> >>>>        Column   Variance Std.Dev.
> >>>> id (Intercept)  0.270823 0.520406
> >>>>
> >>>>   Number of obs: 2217; levels of grouping factors: 331
> >>>>
> >>>> Fixed-effects parameters:
> >>>> ????????????????????????????????????????????????????
> >>>>                    Coef.  Std. Error      z  Pr(>|z|)
> >>>> ????????????????????????????????????????????????????
> >>>> (Intercept)   0.0969256   0.140211    0.69    0.4894
> >>>> x1: 1        -0.0449824   0.0553361  -0.81    0.4163
> >>>> x2            0.0744891   0.0133743   5.57    <1e-07
> >>>> x3           -0.548392    0.0914109  -6.00    <1e-08
> >>>> x4: B         0.390359    0.0803063   4.86    <1e-05
> >>>> x4: C         0.299932    0.0991249   3.03    0.0025
> >>>> ????????????????????????????????????????????????????
> >>>>
> >>>> julia> m02 = let f = @formula y ~ 1 + x1 + x2 + x3 + (1|id)
> >>>>             fit(MixedModel, f, dat, Bernoulli(); contrasts, nAGQ=9)
> >>>>         end
> >>>> Generalized Linear Mixed Model fit by maximum likelihood (nAGQ = 9)
> >>>>    y ~ 1 + x1 + x2 + x3 + (1 | id)
> >>>>    Distribution: Bernoulli{Float64}
> >>>>    Link: LogitLink()
> >>>>
> >>>>     logLik    deviance     AIC       AICc        BIC
> >>>>   -1472.4551  2944.0654  2954.9102  2954.9373  2983.4297
> >>>>
> >>>> Variance components:
> >>>>        Column   Variance Std.Dev.
> >>>> id (Intercept)  0.274331 0.523766
> >>>>
> >>>>   Number of obs: 2217; levels of grouping factors: 331
> >>>>
> >>>> Fixed-effects parameters:
> >>>> ????????????????????????????????????????????????????
> >>>>                    Coef.  Std. Error      z  Pr(>|z|)
> >>>> ????????????????????????????????????????????????????
> >>>> (Intercept)  -0.448496    0.100915   -4.44    <1e-05
> >>>> x1: 1        -0.0527684   0.0547746  -0.96    0.3354
> >>>> x2            0.0694393   0.0131541   5.28    <1e-06
> >>>> x3           -0.556903    0.0904798  -6.15    <1e-09
> >>>> ????????????????????????????????????????????????????
> >>>>
> >>>> julia> MixedModels.likelihoodratiotest(m02, m01)
> >>>> Model Formulae
> >>>> 1: y ~ 1 + x1 + x2 + x3 + (1 | id)
> >>>> 2: y ~ 1 + x1 + x2 + x3 + x4 + (1 | id)
> >>>> ??????????????????????????????????????????????????
> >>>>       model-dof   deviance       ??  ??-dof  P(>??)
> >>>> ??????????????????????????????????????????????????
> >>>> [1]          5  2944.0654
> >>>> [2]          7  2900.8511  43.2144       2  <1e-09
> >>>> ??????????????????????????????????????????????????
> >>>>
> >>>> I would note that your data are so imbalanced with respect to id
> >>>> that it
> >>>> is not surprising that you get unstable results.  (I changed your id
> >>>> column
> >>>> from integers to a factor so that 33 becomes S033.)
> >>>>
> >>>> 331?2 DataFrame
> >>>>   Row ? id      nrow
> >>>>       ? String  Int64
> >>>> ?????????????????????
> >>>>     1 ? S033     1227
> >>>>     2 ? S134       46
> >>>>     3 ? S295       45
> >>>>     4 ? S127       41
> >>>>     5 ? S125       33
> >>>>     6 ? S228       31
> >>>>     7 ? S193       23
> >>>>     8 ? S064       18
> >>>>     9 ? S281       16
> >>>>    10 ? S055       13
> >>>>    11 ? S035       13
> >>>>    12 ? S091       12
> >>>>    13 ? S175       11
> >>>>    14 ? S284       10
> >>>>    15 ? S159       10
> >>>>    ?  ?   ?       ?
> >>>>   317 ? S324        1
> >>>>   318 ? S115        1
> >>>>   319 ? S192        1
> >>>>   320 ? S201        1
> >>>>   321 ? S156        1
> >>>>   322 ? S202        1
> >>>>   323 ? S067        1
> >>>>   324 ? S264        1
> >>>>   325 ? S023        1
> >>>>   326 ? S090        1
> >>>>   327 ? S195        1
> >>>>   328 ? S170        1
> >>>>   329 ? S241        1
> >>>>   330 ? S189        1
> >>>>   331 ? S213        1
> >>>>       301 rows omitted
> >>>>
> >>>>
> >>>>
> >>>> On Thu, Aug 31, 2023 at 3:02?AM Juho Kristian Ruohonen <
> >>>> juho.kristian.ruohonen at gmail.com> wrote:
> >>>>
> >>>>> Hi,
> >>>>>
> >>>>> I thought it was impossible for deviance to decrease when a term is
> >>>>> removed!?!? Yet I'm seeing it happen with this pair of relatively
> >>>>> simple
> >>>>> Bernoulli GLMMs fit using lme4:glmer():
> >>>>>
> >>>>>> full <- glmer(y ~ (1|id) + x1 + x2 + x3 + x4, family = binomial,
> >>>>>> nAGQ =
> >>>>>> 6, data = anon)
> >>>>>> reduced <- update(full, ~. -x1)
> >>>>>> c(full = deviance(full), reduced = deviance(reduced))
> >>>>>
> >>>>> *     full  reduced*
> >>>>> *2808.671 2807.374 *
> >>>>>
> >>>>> What on earth going on? FYI, I am deliberately comparing conditional
> >>>>> deviances rather than marginal ones, because quite a few of the
> >>>>> clusters
> >>>>> are of inherent interest and likely to recur in future data.
> >>>>>
> >>>>> My anonymized datafile is attached.
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Juho
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>     [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|ex@ndr@@|e|ebvre @end|ng |rom m@th@cnr@@|r  Mon Sep  4 11:08:41 2023
From: @|ex@ndr@@|e|ebvre @end|ng |rom m@th@cnr@@|r (Alexandra Lefebvre)
Date: Mon, 4 Sep 2023 11:08:41 +0200
Subject: [R-sig-ME] Question regarding the glmer function from the LME4
 package
Message-ID: <E74CADB5-60AF-47F7-A7B3-87770F22FCA4@math.cnrs.fr>

Dear colleagues, 

I am using the LME4 package, in particular the glmer function, in the framework of an EM algorithm. I would need to retrieve individual log-likelihoods (for each observation) and I am wondering if that output can be obtained from the package. 

As an example, here is a short code (in blue) :

require(lme4)
set.seed(1)

theta.star = 2.5
beta.star = -2

z = rnorm(2000); 
x = rbinom(2000, 50, exp(beta.star + z * theta.star) / (1 + exp(beta.star + z * theta.star)))
dat = data.frame(x = x, id = 1: length(x))
fit = glmer(cbind(x, 50-x) ~ 1 + (1 | id), data = dat, family = "binomial")

theta = fit at theta 		# 2.499677
beta = fit at beta 		# -1.988883

#individual loglik
ind.loglik = rep(NA, length(x))
for (i in 1:length(x)) {
  f = function(u) dbinom(x[i], 50, exp(beta + theta * u) / (1 + exp(beta + theta * u))) * dnorm(u)
  ind.loglik[i] = log(integrate(f, -5, 5)$val)
}

As far as I understood you use Laplace or Gauss-Hermite method. I guess each individual log-likelihood is calculated for fitting the model.  Do you know any way for retrieving the vector of individual log-likelihood directly as an output from your package ? 

Alternatively, I read in your notes that The Laplace approximation correction terms for converting a conditional log-likelihood into a marginal log-likelihood are `gm1 at pp$sqrL(1)` and `gm1 at pp$ldL2()). Is it available at an individual level ? 

Furthermore, I am surprised that the results of the following two line codes are not almost equal and therefore I wonder if my understanding of the output in the above code is correct. 
sum(ind.loglik) 	# -6774.249
logLik(fit)	 		# 'log Lik.' -6807.348 (df=2)


King regards, 
Alexandra Lefebvre 

?????????????
Post-doctoral researcher at CIRB (Coll?ge de France) and LJLL (Sorbonne Universit?, Paris, France)
CIRB - Coll?ge de France, 11, place Marcelin-Berthelot, 75231 Paris Cedex 05.
Bat.B niveau 1 - Pi?ce 104.


	[[alternative HTML version deleted]]


From dmb@te@ @end|ng |rom gm@||@com  Mon Sep  4 18:31:37 2023
From: dmb@te@ @end|ng |rom gm@||@com (Douglas Bates)
Date: Mon, 4 Sep 2023 11:31:37 -0500
Subject: [R-sig-ME] Question regarding the glmer function from the LME4
 package
In-Reply-To: <E74CADB5-60AF-47F7-A7B3-87770F22FCA4@math.cnrs.fr>
References: <E74CADB5-60AF-47F7-A7B3-87770F22FCA4@math.cnrs.fr>
Message-ID: <CAO7JsnSZ1AmDEajJ4evxDYgxvAYVg69dOxJnAsGaOd+gASz0kw@mail.gmail.com>

In your simulation it looks like you have a separate random effect (element
of z) for each observation (element of y).  Is that intentional?

It seems that this model, while perhaps theoretically identifiable, is
going to be poorly estimated as it will be difficult to separate the
influence of the random effects from the per-observation noise.

Generally we think of each element of the random effects being associated
with several observations - that `id`, the grouping factor has fewer levels
than observations.  In such cases it is difficult to make sense of
contributions from individual observations to the log-likelihood.  If you
only have one grouping factor from random effects you can evaluate the
log-likelihood as a sum of contributions from each element of the random
effects - which is why Gauss-Hermite integration can be applied to scalar
integrals instead of Laplace's approximation.  But still the log-likelihood
requires integration with respect to the random effects to obtain the
marginal distribution of the observations which is then evaluated at the
observed responses.

I think the simplifications available in the generalized linear model (i.e.
a model without random effects) are a source of confusion here.  In that
case the deviance (negative twice the log-likelihood) can be expressed as
the sum of the "unit deviances" for each observation because the individual
responses are independent in the probability model.  That is not the case
for GLMMs.  We still use the unit deviances in the evaluation of
(approximations to) the deviance of the GLMM but the sum of these unit
deviances is only part of the deviance of the model itself.

I have written about how I understand the GLMM formulation in an appendix
of the in-progress book
https://juliamixedmodels.github.io/EmbraceUncertainty/  We use Julia and
the MixedModels.jl package in that book but the approach is similar to that
in lme4.

On Mon, Sep 4, 2023 at 9:32?AM Alexandra Lefebvre <
alexandra.lefebvre at math.cnrs.fr> wrote:

> Dear colleagues,
>
> I am using the LME4 package, in particular the glmer function, in the
> framework of an EM algorithm. I would need to retrieve individual
> log-likelihoods (for each observation) and I am wondering if that output
> can be obtained from the package.
>
> As an example, here is a short code (in blue) :
>
> require(lme4)
> set.seed(1)
>
> theta.star = 2.5
> beta.star = -2
>
> z = rnorm(2000);
> x = rbinom(2000, 50, exp(beta.star + z * theta.star) / (1 + exp(beta.star
> + z * theta.star)))
> dat = data.frame(x = x, id = 1: length(x))
> fit = glmer(cbind(x, 50-x) ~ 1 + (1 | id), data = dat, family = "binomial")
>
> theta = fit at theta               # 2.499677
> beta = fit at beta                 # -1.988883
>
> #individual loglik
> ind.loglik = rep(NA, length(x))
> for (i in 1:length(x)) {
>   f = function(u) dbinom(x[i], 50, exp(beta + theta * u) / (1 + exp(beta +
> theta * u))) * dnorm(u)
>   ind.loglik[i] = log(integrate(f, -5, 5)$val)
> }
>
> As far as I understood you use Laplace or Gauss-Hermite method. I guess
> each individual log-likelihood is calculated for fitting the model.  Do you
> know any way for retrieving the vector of individual log-likelihood
> directly as an output from your package ?
>
> Alternatively, I read in your notes that The Laplace approximation
> correction terms for converting a conditional log-likelihood into a
> marginal log-likelihood are `gm1 at pp$sqrL(1)` and `gm1 at pp$ldL2()). Is it
> available at an individual level ?
>
> Furthermore, I am surprised that the results of the following two line
> codes are not almost equal and therefore I wonder if my understanding of
> the output in the above code is correct.
> sum(ind.loglik)         # -6774.249
> logLik(fit)                     # 'log Lik.' -6807.348 (df=2)
>
>
> King regards,
> Alexandra Lefebvre
>
> ?????????????
> Post-doctoral researcher at CIRB (Coll?ge de France) and LJLL (Sorbonne
> Universit?, Paris, France)
> CIRB - Coll?ge de France, 11, place Marcelin-Berthelot, 75231 Paris Cedex
> 05.
> Bat.B niveau 1 - Pi?ce 104.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Thu Sep  7 04:30:29 2023
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Wed, 6 Sep 2023 22:30:29 -0400
Subject: [R-sig-ME] Varying random variance from random slopes model?
In-Reply-To: <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
References: <CAG_dBVcmUr4utZ+dTwE+OxNN4aOsYY1s-Spbrqui=X2+hjscHQ@mail.gmail.com>
 <CAO7JsnS+XAKJwiuDNfzTrjCBafkE1K3BN+R-M=6c-q7=-4+gHw@mail.gmail.com>
 <CAO7JsnTVnwKw635wKLbpfvt0XUSCo+FDfFQyBxJ6P8k9OL0svg@mail.gmail.com>
 <CAO7JsnTsRfQKPguEiOGcttUcuMy7vK_x=QEy5rTQZYnMff9xcQ@mail.gmail.com>
 <aeed156c-5906-1b4d-6eb5-aced232864c5@phillipalday.com>
 <e10b4f4b-488b-add1-d60b-11146f243943@gmail.com>
Message-ID: <CANOgrHbau2rf7dvqgt4yGucpa-v++mKmYsiaD1LDbQ6djDNzjw@mail.gmail.com>

Sorry if this one seems confusing.  I?ll be as clear as I can.

I was originally using random intercept LMM to generate a Z score as the
difference between the predicted conditional mean from fixed effects and
the real observation, divided by the SD from the combined residual and
random intercept variances.

I?m now adding random slopes, plural.  AIC suggests much better fit.  But
here?s the problem:

I had naively assumed I could estimate a random effects variance dependent
on the slope terms by estimating the sum of the random intercept plus the
random slope times the value for each of the slope parameters, and then the
variance of that sum across the population.  (I?d then look for a curve
that described this variance as a function of the slope terms.)

However, I had also had the assumption that the SD term for random
intercept in the LMM summary (using lmer) was the standard deviation of the
random effects for intercept.  I now realize that isn?t the case, as the
summary from lmer describes the multivariate Gaussian distribution giving
rise to the random effects, not the random effects themselves.  (Entirely
possible I have that wrong, too!)

So my question is, finally, is there a way to calculate a realistic SD
estimate that varies with the slope parameters?  I was hoping to plug that
into my Z score calculation.

I?m probably missing something basic..

Thanks in advance!

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Sep  9 21:27:49 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 9 Sep 2023 22:27:49 +0300
Subject: [R-sig-ME] Ad-hoc LRT for single term in binomial GLMM,
 with DF from cAIC4
Message-ID: <CAG_dBVeSoQwnRR7X+KmWDvX7T3Eo34qz_KoejzPzwd68vbc2iQ@mail.gmail.com>

Hi,

Conditional setting here, with BLUPs of inherent interest (clusters likely
to recur in future).

When analyzing the importance of fixed effects in a conditional setting, is
there something wrong with using just a basic Deviance comparison of nested
GLMMs? As I understand it, the main difficulty resides in determining the
effective degrees of freedom when the analysis is conditional on the BLUPs.
But nowadays we have the cAIC4 package, which seems to do a respectable job
at estimating those DF.

So, why not just call pchisq(deviance(SmallMod)-deviance(BigMod), df =
BigModCAIC$df-SmallModCAIC$df, lower.tail = FALSE), and be done with it?
Seems more straightforward, as well as conceptually simpler, than that
parametric bootstrap business.

One awkwardness that I do notice about this procedure is that sometimes the
smaller model is estimated to have more effective parameters (a larger df)
than the bigger model. I guess the reason is that sometimes the random
effects manage to "bail the model out and then some" when a fixed effect is
removed. But whether this invalidates the whole procedure, I don't know. My
intuition says no, it doesn't. But I'm a lowly non-statistician. Would
therefore love to hear what the gurus think.

Best,

Juho

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Sep 12 10:35:20 2023
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Tue, 12 Sep 2023 08:35:20 +0000
Subject: [R-sig-ME] Course Announcement: ESM Data Analysis Course
Message-ID: <ccf4ca68e7db43cfbe288fff1963781b@maastrichtuniversity.nl>

Hi all,

For people working with intensive longitudinal data as may be collected by methods such as 'ecological momentary assessment' (EMA) or the 'experience sampling method' (ESM), I am teaching a course December 6-8 on the use of mixed-effects models for the analysis of such data. In case you are interested and would like further details, see the course website at:

https://www.wvbauer.com/doku.php/course_esmda

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, PhD, Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | PO Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31(43)3884170 | https://www.wvbauer.com    


From w@chr|@@oo@thu|zen @end|ng |rom gm@||@com  Thu Sep 14 17:05:09 2023
From: w@chr|@@oo@thu|zen @end|ng |rom gm@||@com (Chris Oosthuizen)
Date: Thu, 14 Sep 2023 17:05:09 +0200
Subject: [R-sig-ME] Predicting the overall population trend from a GLMM with
 many sites (MCMCglmm)
Message-ID: <CANKwuwHygTqa_3QL3n3JcrdHq-f6Fvcw-NG7aiBK-LeiepC99g@mail.gmail.com>

Dear all,

I have intermittent population counts of a single species at many sites
that are situated at different latitudes. I want to estimate the overall
population trend across all sites (how much did the overall population
decline in 30 years?). I would appreciate clarification on precisely how I
should calculate a single, overall population trend estimate from a
random-slope mixed model.

The model we fit is:
model <- MCMCglmm(count ~ year * latitude, random = ~us(1 + year):site,
                rcov=~units, family="poisson", pr = T, data = df?)

If I were interested in site-level effects I would predict with random
effects (set marginal to NULL):
pred <- data.frame(predict(model, newdata=df, type="response",
marginal=NULL, interval="confidence", posterior="all"))

We can also marginalise the random effects ? this prediction is ?at the
population level? and it may have poor site-level predictions if the random
effect is important (e.g. some sites are increasing and others are
decreasing):
pred_margin <- data.frame(predict(model, newdata=df, type="response",
marginal=model$Random$formula, interval="confidence", posterior="all"))

Both predictions above are made using a ?newdata? data frame that contains
?site? ? this seems to be required by the ?predict? function. Thus, we
always end up with site-level data as output in the prediction data frame,
regardless of whether the random effects were marginalised or not.

I don?t know the best statistical approach to obtain a single population
trend estimate. My approach would be to predict with random effects, and
sum the counts per site to get an overall estimate. This is the approach
that a colleague took (although he disregarded the random effects). His
calculations do not use the ?predict? function, but directly calculates
population sizes from the model coefficients, for every posterior draw (to
propagate uncertainty). He then estimates population sizes at two points
(in 1990 and 2020) and asks whether the population decreased between these
two points.
This approach and reproducible code is here:
https://drive.google.com/drive/folders/1_thQQW9Vy3SxGi6WBkk-1CuqSpE6XaYy?usp=sharing

It is important that I get this right, so I hope someone can give me
guidance. Thanks in advance!
Chris

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Thu Sep 14 17:29:08 2023
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Thu, 14 Sep 2023 15:29:08 +0000
Subject: [R-sig-ME] 
 Predicting the overall population trend from a GLMM with
 many sites (MCMCglmm)
In-Reply-To: <CANKwuwHygTqa_3QL3n3JcrdHq-f6Fvcw-NG7aiBK-LeiepC99g@mail.gmail.com>
References: <CANKwuwHygTqa_3QL3n3JcrdHq-f6Fvcw-NG7aiBK-LeiepC99g@mail.gmail.com>
Message-ID: <AS8PR05MB86596B0140925D229B25AA47ACF7A@AS8PR05MB8659.eurprd05.prod.outlook.com>

HI,

Using marginal= ~us(1 + year):site in the predict function does not marginalise sites it marginalises *site effects*: the prediction will stary vary across sites because the sites will be at varying latitudes and latitude has not been marginalised.

On the data scale, the relationship between the expected count and year is not linear and so I think it is easier to work on the link (log) scale where the relationship is linear. On this scale the mean slope is simply

b1+b2*mean(latitude)

where b1 is the main effect of year, and b2 the year by latitude interaction.

If you want to work with the average of the exponentiated slopes (i.e. the expected proportional change in abundance per year) this would require more work, but I?m not sure that is what you want?

Cheers,

Jarrod




From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chris Oosthuizen <w.chris.oosthuizen at gmail.com>
Date: Thursday, 14 September 2023 at 16:06
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Predicting the overall population trend from a GLMM with many sites (MCMCglmm)
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.

Dear all,

I have intermittent population counts of a single species at many sites
that are situated at different latitudes. I want to estimate the overall
population trend across all sites (how much did the overall population
decline in 30 years?). I would appreciate clarification on precisely how I
should calculate a single, overall population trend estimate from a
random-slope mixed model.

The model we fit is:
model <- MCMCglmm(count ~ year * latitude, random = ~us(1 + year):site,
                rcov=~units, family="poisson", pr = T, data = df?)

If I were interested in site-level effects I would predict with random
effects (set marginal to NULL):
pred <- data.frame(predict(model, newdata=df, type="response",
marginal=NULL, interval="confidence", posterior="all"))

We can also marginalise the random effects ? this prediction is ?at the
population level? and it may have poor site-level predictions if the random
effect is important (e.g. some sites are increasing and others are
decreasing):
pred_margin <- data.frame(predict(model, newdata=df, type="response",
marginal=model$Random$formula, interval="confidence", posterior="all"))

Both predictions above are made using a ?newdata? data frame that contains
?site? ? this seems to be required by the ?predict? function. Thus, we
always end up with site-level data as output in the prediction data frame,
regardless of whether the random effects were marginalised or not.

I don?t know the best statistical approach to obtain a single population
trend estimate. My approach would be to predict with random effects, and
sum the counts per site to get an overall estimate. This is the approach
that a colleague took (although he disregarded the random effects). His
calculations do not use the ?predict? function, but directly calculates
population sizes from the model coefficients, for every posterior draw (to
propagate uncertainty). He then estimates population sizes at two points
(in 1990 and 2020) and asks whether the population decreased between these
two points.
This approach and reproducible code is here:
https://drive.google.com/drive/folders/1_thQQW9Vy3SxGi6WBkk-1CuqSpE6XaYy?usp=sharing

It is important that I get this right, so I hope someone can give me
guidance. Thanks in advance!
Chris

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Thu Sep 14 18:02:25 2023
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Thu, 14 Sep 2023 16:02:25 +0000
Subject: [R-sig-ME] 
 Predicting the overall population trend from a GLMM with
 many sites (MCMCglmm)
In-Reply-To: <AS8PR05MB86596B0140925D229B25AA47ACF7A@AS8PR05MB8659.eurprd05.prod.outlook.com>
References: <CANKwuwHygTqa_3QL3n3JcrdHq-f6Fvcw-NG7aiBK-LeiepC99g@mail.gmail.com>
 <AS8PR05MB86596B0140925D229B25AA47ACF7A@AS8PR05MB8659.eurprd05.prod.outlook.com>
Message-ID: <AS8PR05MB865919C7F31509D5EFC965F5ACF7A@AS8PR05MB8659.eurprd05.prod.outlook.com>

Hi,

Thinking about it more, the expected proportional change in abundance per year is perhaps the most readily digestible number for an ecologist. To obtain it (with assumptions):

The slope for site_i is

slope_i = b1+b2*latitude_i+b_i

where b1 is the main year effect, b2 is the year by latitude interaction and b_i is the random slope deviation for site i.

The b_i are assumed normal and independent of latitude. If we assume latitude is also normal with mean m and variance V, then the slopes are normal with mean b1+b2*m (since E[b_i]=0) and variance Vs+V*b2^2 (since b1 and b2 are constants). Here, Vs=VAR(b_i) [i.e. the slope variance from the model].

The exponentiated slopes are log normal with mean equal to exp(b1+b2*m+(Vs+V*b2^2)/2).

You can obtain the posterior for this as b1, b2 and Vs are parameters in the model. You would have to use point estimates for m and V (you haven't modelled latitude) so any uncertainty in the expected proportional change in abundance per year does not include uncertainty about the mean and variance of site's latitudes.

m<-mean(df$latitude)
V<-var(df$latitude)


posterior_mean<-exp(model$Sol["year"]+ model$Sol["year:latitude"]*m+(model$VCV[,"year:year.site"]+V*model$Sol["year:latitude"]^2)/2)

Cheers,

Jarrod


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Jarrod Hadfield <j.hadfield at ed.ac.uk>
Date: Thursday, 14 September 2023 at 16:29
To: Chris Oosthuizen <w.chris.oosthuizen at gmail.com>, r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Predicting the overall population trend from a GLMM with many sites (MCMCglmm)
HI,

Using marginal= ~us(1 + year):site in the predict function does not marginalise sites it marginalises *site effects*: the prediction will stary vary across sites because the sites will be at varying latitudes and latitude has not been marginalised.

On the data scale, the relationship between the expected count and year is not linear and so I think it is easier to work on the link (log) scale where the relationship is linear. On this scale the mean slope is simply

b1+b2*mean(latitude)

where b1 is the main effect of year, and b2 the year by latitude interaction.

If you want to work with the average of the exponentiated slopes (i.e. the expected proportional change in abundance per year) this would require more work, but I?m not sure that is what you want?

Cheers,

Jarrod




From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chris Oosthuizen <w.chris.oosthuizen at gmail.com>
Date: Thursday, 14 September 2023 at 16:06
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Predicting the overall population trend from a GLMM with many sites (MCMCglmm)
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.

Dear all,

I have intermittent population counts of a single species at many sites
that are situated at different latitudes. I want to estimate the overall
population trend across all sites (how much did the overall population
decline in 30 years?). I would appreciate clarification on precisely how I
should calculate a single, overall population trend estimate from a
random-slope mixed model.

The model we fit is:
model <- MCMCglmm(count ~ year * latitude, random = ~us(1 + year):site,
                rcov=~units, family="poisson", pr = T, data = df?)

If I were interested in site-level effects I would predict with random
effects (set marginal to NULL):
pred <- data.frame(predict(model, newdata=df, type="response",
marginal=NULL, interval="confidence", posterior="all"))

We can also marginalise the random effects ? this prediction is ?at the
population level? and it may have poor site-level predictions if the random
effect is important (e.g. some sites are increasing and others are
decreasing):
pred_margin <- data.frame(predict(model, newdata=df, type="response",
marginal=model$Random$formula, interval="confidence", posterior="all"))

Both predictions above are made using a ?newdata? data frame that contains
?site? ? this seems to be required by the ?predict? function. Thus, we
always end up with site-level data as output in the prediction data frame,
regardless of whether the random effects were marginalised or not.

I don?t know the best statistical approach to obtain a single population
trend estimate. My approach would be to predict with random effects, and
sum the counts per site to get an overall estimate. This is the approach
that a colleague took (although he disregarded the random effects). His
calculations do not use the ?predict? function, but directly calculates
population sizes from the model coefficients, for every posterior draw (to
propagate uncertainty). He then estimates population sizes at two points
(in 1990 and 2020) and asks whether the population decreased between these
two points.
This approach and reproducible code is here:
https://drive.google.com/drive/folders/1_thQQW9Vy3SxGi6WBkk-1CuqSpE6XaYy?usp=sharing

It is important that I get this right, so I hope someone can give me
guidance. Thanks in advance!
Chris

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

        [[alternative HTML version deleted]]

	[[alternative HTML version deleted]]


From @v|k @end|ng |rom @@v|on@huj|@@c@||  Sat Sep 16 10:00:35 2023
From: @v|k @end|ng |rom @@v|on@huj|@@c@|| (Avraham N Kluger)
Date: Sat, 16 Sep 2023 08:00:35 +0000
Subject: [R-sig-ME] How to specify a correlation between cross-nested effects
Message-ID: <AS8PR10MB5091B9C9A119F9334935F004D4F5A@AS8PR10MB5091.EURPRD10.PROD.OUTLOOK.COM>

I am trying to model round-robin data, typically analyzed with an ANOVA-based Social Relations Model (SRM), with a mixed model with cross-nested effects.
First, I give a brief background to clarify the motivation behind my mixed model question. One way to analyze SRM data in R is with tripleR package. I use the example data of that package. The data reflect the liking rating each person in a group of ten gave each other. A record with NA is needed in tripleR for self-rating (liking that one would have given to oneself if measured). The model estimates three variances: perceiver (actor), target (partner), and error, and two covariances: perceiver-target and dyadic (error + dyadic). [The perceiver variance reflects differences in liking others; the target variance reflects differences in being liked by others; and the perceiver-target covariance reflects the degree to which people who like others are liked by others. For my purpose, I ignore the dyadic covariance in my question].
Below is the code for the tripleR example (using Group 1 data only for simplicity)
library(TripleR)
library(glmmTMB)
data("multiLikingLong")
df <- multiLikingLong
df <- df[df$group.id ==1, ]
RR(liking_a ~ perceiver.id*target.id, data = df)

It produces the following output

Round-Robin object ('RR'), calculated by TripleR
------------------------------------------------
Univariate analysis of one round robin variable

Univariate analyses for: liking_a
---------
Round robin analysis for a single group; using the formula of Lashley & Bond (1997).

                         estimate standardized    se t.value p.value
actor variance              0.228        0.267 0.126   1.814   0.052
partner variance            0.067        0.079 0.058   1.161   0.138
relationship variance       0.558        0.654 0.098   5.684   0.000
error variance                 NA           NA    NA      NA      NA
actor-partner covariance    0.041        0.329 0.067   0.604   0.561
relationship covariance     0.216        0.388 0.098   2.203   0.028
Actor effect reliability: .777
Partner effect reliability: .506

Next, I get rid of the rows with NA, needed by tripleR, and run a mixed model.

x <- na.omit(df)
m <- glmmTMB(liking_a ~ 1 + (1 |perceiver.id) + (1 |target.id), data = x,
             family = gaussian(link = "identity"))
summary(m)

It yields the following results:

Family: gaussian  ( identity )
Formula:          liking_a ~ 1 + (1 | perceiver.id) + (1 | target.id)
Data: x

     AIC      BIC   logLik deviance df.resid
   231.7    241.7   -111.8    223.7       86

Random effects:

Conditional model:
Groups       Name        Variance Std.Dev.
perceiver.id (Intercept) 0.19986  0.4471
 target.id    (Intercept) 0.06102  0.2470
 Residual                 0.55838  0.7472
Number of obs: 90, groups:  perceiver.id, 10; target.id, 10

Dispersion estimate for gaussian family (sigma^2): 0.558

Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   3.3556     0.1797   18.67   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

The results for the perceiver and target variances are similar but not identical. The results for the residuals are identical. For example, tripleR estimates the perceiver variance as .228 but glmmTMB, .199. Yet, tripleR also estimates the actor-partner covariance and correlation; the standardized correlation is .329. My question is, how can I specify this correlation with glmmTMB?

I found an approximation for the correlation:

cor(
    ranef(m)$cond$perceiver.id,
    ranef(m)$cond$target.id
    )

            (Intercept)
(Intercept)   0.2959082

But, this approximation is based on the random effects whose variances differ from the model's.
Thank you,

Avi Kluger
http://avikluger.wix.com/avi-kluger

	[[alternative HTML version deleted]]


From @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com  Sun Sep 17 11:21:24 2023
From: @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com (Santosh Srinivas)
Date: Sun, 17 Sep 2023 09:21:24 +0000
Subject: [R-sig-ME] Why do lme() models runs so fast and converge as
 compared to lmer()?
Message-ID: <BY3PR06MB7907999186645C8F4FCB4B2CC9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>

Hi, I am running the following similar models using lme() and lmer():

f = y ~ x + year * post_event + (year|user_id)

where,

  *   year (integer) ranges from 0 (for the year 2010) to 10 (for the year2020);
  *   post_event (factor variable) is 1 for years 2013 onwards, and 0 otherwise;
  *   Number of Observations: 3586633; and
  *   Number of Groups: 1109.

The lme4's lmer() runs for several minutes and never succeeds to converge with any optimizer I try, whereas the former seems to converge in a few minutes.

Not sure if I am doing anything wrong, or whether such convergence and performances are generally expected of lme().

Request your help.

Thanks & regards,
sbs




	[[alternative HTML version deleted]]


From @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com  Sun Sep 17 16:34:23 2023
From: @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com (Santosh Srinivas)
Date: Sun, 17 Sep 2023 14:34:23 +0000
Subject: [R-sig-ME] Advice with autoregressive correlation specification in
 lme()
Message-ID: <BY3PR06MB79071376B6200A95E1C98936C9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>

Dear List members, I am running into an error when specifying autoregressive correlation structure in lme(). Here are the model specifications:

m1 = lme(y ~ time, random = ~1+time|fighter_id, data = df, na.action = na.omit)
m2 = update(m1, correlation=corAR1())

m1 runs fine. But, m2 throws the following error:
Error: 'sumLenSq := sum(table(groups)^2)' = 5.44838e+10 is too large.
 Too large or no groups in your correlation structure?

Not sure what the error is as there are enough groups.
Number of Observations: 3586633
Number of Groups: 1109

What are we doing wrong? How can this error be overcome?

Thanks!
sbs

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Sep 18 02:11:40 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 17 Sep 2023 20:11:40 -0400
Subject: [R-sig-ME] Why do lme() models runs so fast and converge as
 compared to lmer()?
In-Reply-To: <BY3PR06MB7907999186645C8F4FCB4B2CC9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>
References: <BY3PR06MB7907999186645C8F4FCB4B2CC9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>
Message-ID: <092c0f6d-6684-2837-b19c-066adf0d8d71@gmail.com>

    This is mildly surprising but not impossible. I haven't looked into 
it/run any experiments yet, but:

  * lme handles a more restricted range of model types, so it's possible 
that its algorithm is faster on simple examples;

  * 'doesn't converge' may not be the issue you think it is.  I would 
improve performance and turn off convergence checking that is known to 
be dodgy for large data sets via control = lmerControl(calc.derivs = 
FALSE)), and more generally try these suggestions: 
https://rdrr.io/cran/lme4/f/vignettes/lmerperf.Rmd

   cheers
    Ben Bolker

On 2023-09-17 5:21 a.m., Santosh Srinivas wrote:
> Hi, I am running the following similar models using lme() and lmer():
> 
> f = y ~ x + year * post_event + (year|user_id)
> 
> where,
> 
>    *   year (integer) ranges from 0 (for the year 2010) to 10 (for the year2020);
>    *   post_event (factor variable) is 1 for years 2013 onwards, and 0 otherwise;
>    *   Number of Observations: 3586633; and
>    *   Number of Groups: 1109.
> 
> The lme4's lmer() runs for several minutes and never succeeds to converge with any optimizer I try, whereas the former seems to converge in a few minutes.
> 
> Not sure if I am doing anything wrong, or whether such convergence and performances are generally expected of lme().
> 
> Request your help.
> 
> Thanks & regards,
> sbs
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From rupprecht @end|ng |rom unbc@c@  Mon Sep 18 07:10:08 2023
From: rupprecht @end|ng |rom unbc@c@ (Meaghan Rupprecht)
Date: Mon, 18 Sep 2023 05:10:08 +0000
Subject: [R-sig-ME] Decreasing size of gamm4 model output (multiple GB when
 saved to .rds)
Message-ID: <YT4PR01MB9832F6BDF81134D62A204DA2A3FBA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>

I am running a Generalized Additive Mixed Model with the R package, gamm4. Each model output includes a mer object and a gam object. I need to compare 26 model structures based on a combination of variables and then conduct model averaging on the best models based on AIC.
The problem is, each .rds file with model output is approximately 5GB. For all 26 models, there is no way I can load them into my R environment for any kind of model comparison or averaging. Similar models run with mgcv::gamm() were only 5.7 MB, which is a much more manageable size for comparisons. (Note: unfortunately I have to stay within the gamm4 package based on model structure, otherwise I would use the mgcv model outputs).
Is there a way to decrease the size of the .rds file to a more reasonable size? Are there arguments within gamm4 or lme4 that could reduce the amount of extra information retained within the model?


	[[alternative HTML version deleted]]


From @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com  Mon Sep 18 13:33:05 2023
From: @@nto@h@b@@r|n|v@@ @end|ng |rom out|ook@com (Santosh Srinivas)
Date: Mon, 18 Sep 2023 11:33:05 +0000
Subject: [R-sig-ME] Why do lme() models runs so fast and converge as
 compared to lmer()?
In-Reply-To: <092c0f6d-6684-2837-b19c-066adf0d8d71@gmail.com>
References: <BY3PR06MB7907999186645C8F4FCB4B2CC9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>
 <092c0f6d-6684-2837-b19c-066adf0d8d71@gmail.com>
Message-ID: <BY3PR06MB79072BE4261896340E1A251BC9FBA@BY3PR06MB7907.namprd06.prod.outlook.com>

Thank you, Dr. Bolker. The advice to set calc.derivs = FALSE is much appreciated.

We tried glmmTMB() for the same model and found it quite fast. Models converged with default optimizers.

Following this, we also tried Julia and were surprised by the orders-of-magnitude improvement in speed.

We are tending to stick to R and use glmmTMB(). We hope that academic journals are generally receptive to using this package for hypothesis testing. From a cursory Google scholar search, it appears that glmmTMB() is used/cited less often (and Julia's MixedModels far and few) as compared to lme() and lmer().

Assuming that models are specified identically, I am hoping the results for hypothesis testing (e.g., significance of a coefficient of theoretical importance) should be identical regardless of whether one uses R's lme(), lmer(), or glmmTMB(), or Julia's MixedModels().

On this note, anything that you suggest we state explicitly in the journal manuscript when presenting the results using glmmTMB() as opposed to lme() or lmer()?

Thanks!
sbs
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Monday, September 18, 2023 2:11 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Why do lme() models runs so fast and converge as compared to lmer()?

    This is mildly surprising but not impossible. I haven't looked into
it/run any experiments yet, but:

  * lme handles a more restricted range of model types, so it's possible
that its algorithm is faster on simple examples;

  * 'doesn't converge' may not be the issue you think it is.  I would
improve performance and turn off convergence checking that is known to
be dodgy for large data sets via control = lmerControl(calc.derivs =
FALSE)), and more generally try these suggestions:
https://rdrr.io/cran/lme4/f/vignettes/lmerperf.Rmd

   cheers
    Ben Bolker

On 2023-09-17 5:21 a.m., Santosh Srinivas wrote:
> Hi, I am running the following similar models using lme() and lmer():
>
> f = y ~ x + year * post_event + (year|user_id)
>
> where,
>
>    *   year (integer) ranges from 0 (for the year 2010) to 10 (for the year2020);
>    *   post_event (factor variable) is 1 for years 2013 onwards, and 0 otherwise;
>    *   Number of Observations: 3586633; and
>    *   Number of Groups: 1109.
>
> The lme4's lmer() runs for several minutes and never succeeds to converge with any optimizer I try, whereas the former seems to converge in a few minutes.
>
> Not sure if I am doing anything wrong, or whether such convergence and performances are generally expected of lme().
>
> Request your help.
>
> Thanks & regards,
> sbs
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of
working hours.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From ||on@@@c@r||@4 @end|ng |rom gm@||@com  Mon Sep 18 09:34:38 2023
From: ||on@@@c@r||@4 @end|ng |rom gm@||@com (Fiona Scarff)
Date: Mon, 18 Sep 2023 15:34:38 +0800
Subject: [R-sig-ME] How to get prediction interval from R package MCMCglmm
 fitwith measurement error *and* a random effect?
Message-ID: <CAP=UNakbZCjr5rOWG16YKW9L0e5L25CT9PM84u6i0oHZykr49g@mail.gmail.com>

How to get prediction interval from R package MCMCglmm fit with
measurement error *and* a random effect?

I am having trouble producing a prediction interval from a model fit
by the R package MCMCglmm, when both a random effect and a measurement
error is specified in the fit. Many thanks in advance for your time
and any suggestions.

I can reproduce the prediction interval examples in the package author
(Jarrod Hadfield)?s MCMCglmm course notes [link
http://cran.nexr.com/web/packages/MCMCglmm/vignettes/CourseNotes.pdf]
p.47, but with my own model structure I get this error:

Error in h(simpleError(msg, call)) :
  error in evaluating the argument 'x' in selecting a method for
function 't': invalid 'times' argument

 ?x? and ?t? aren?t variables I have declared so I imagine they must
be objects called internally by the predict function. In the MCMCglmm
course notes (p.47 again), the author does note that the predict
function for MCMCglmm is currently incomplete and needs further
testing, but should be OK for simpler models. Perhaps my model
structure is an instance of a more elaborate model not yet
accommodated. Is there some other way I can generate a prediction
interval?

For context, I am studying the flying height of birds. We obtain
observations of height from satellite tags attached to birds. The
observations are recorded with large measurement error (often
reporting negative height as if the birds were flying underground).
The variance of the measurement error can be predicted based on the
number and position of available satellites. MCMCglmm has a facility
for users to specify a vector of measurement errors associated with
observations on the response variable. We also have repeat
observations on each tagged bird, so it?s desirable to also
incorporate the flying height preferences of individual birds into the
model.

Here is a reproducible example:

Session info?
MCMCglmm_2.35
R version 4.2.3 (2023-03-15)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Ventura 13.4.1

#Declare some parameters governing the flying height of the birds, for
purposes of simulation
set.seed(756)
alt1 <- 20 # mean of true flying height, in metres above ground level
sig <- 10 #variance in true flying height
# gamma distribution scale parameter:
beta = sig/alt1
#  gamma distribution shape parameter :
alpha = alt1/beta

 #Additional variation in height amongst individual birds
ind.re <- rnorm(n= 20, mean=0, sd = 3) # ?ind.re? denotes individual
random effects

#Create dataframe containing simulation data
#20 tagged birds, with 100 observations each = 2000 observations total
data.sim <- data.frame(BirdID = as.factor(rep(1:20, each=100) ) ) %>%
                        mutate(., sig.obs = rep(5,2000), #std dev of
measurement error, just for this example I'm imposing an identical
error for each observation
            true.alt = #true altitude, drawn from a gamma distribution
                         rgamma(n = 2000, shape = alpha, scale = beta) +
                          ind.re[data.sim$BirdID], #individual
variation amongst birds
             obs.alt = #observed altitude
                             true.alt +
rnorm(n = 2000, mean = 0, sd = sig.obs) # imprecision due to measurement error
                        )

 #declare priors
prior <- list(B = list(mu=0, V=1e10), #for fixed effects
               R = list(V=1, nu=0.002),  #for residuals
               G = list( #random effects
                 G1 = list(V=1, nu=0.002) #first random effect, i.e. BirdID.
               ))

#fit the glmm
m <- MCMCglmm::MCMCglmm(
            fixed = obs.alt ~ 1,
            family = "gaussian",
            random = ~BirdID,
            mev = data.sim$sig.obs, #vector of measurement errors
            prior = prior,
            data = data.sim
)
#get a prediction interval
predict(m,  type = "response", interval = "prediction", level = 0.95)[1:3, ]

Note that if the model is refit without BirdID as a random effect,
(i.e. if we comment out ?random = ~BirdID,? above), or alternatively
without the measurement error vector (?mev =  data.sim$sig.obs,?) then
the predict function works fine:

(Output without random effect specified)
       fit      lwr      upr
1 20.33545 5.284893 33.06830
2 20.72960 6.874275 35.33598
3 20.57229 3.561330 33.84181

 Am I doing something wrong here, or is there a workaround? Many thanks again!
Fiona Scarff
Murdoch University


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 19 04:24:35 2023
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 18 Sep 2023 19:24:35 -0700
Subject: [R-sig-ME] 
 Decreasing size of gamm4 model output (multiple GB when
 saved to .rds)
In-Reply-To: <YT4PR01MB9832F6BDF81134D62A204DA2A3FBA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
References: <YT4PR01MB9832F6BDF81134D62A204DA2A3FBA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <99E542F7-44AA-4E68-8BBA-B67361ED7A1E@comcast.net>

I was puzzled by the fact that you save the output as an rds file. I suspect but am unable to confirm, that your result(s) include some representation of the data. You might instead return the models with the data omitted  

? 
David. 

Sent from my iPhone

> On Sep 17, 2023, at 10:11 PM, Meaghan Rupprecht <rupprecht at unbc.ca> wrote:
> 
> ?I am running a Generalized Additive Mixed Model with the R package, gamm4. Each model output includes a mer object and a gam object. I need to compare 26 model structures based on a combination of variables and then conduct model averaging on the best models based on AIC.
> The problem is, each .rds file with model output is approximately 5GB. For all 26 models, there is no way I can load them into my R environment for any kind of model comparison or averaging. Similar models run with mgcv::gamm() were only 5.7 MB, which is a much more manageable size for comparisons. (Note: unfortunately I have to stay within the gamm4 package based on model structure, otherwise I would use the mgcv model outputs).
> Is there a way to decrease the size of the .rds file to a more reasonable size? Are there arguments within gamm4 or lme4 that could reduce the amount of extra information retained within the model?
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Sep 19 09:21:30 2023
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 19 Sep 2023 07:21:30 +0000
Subject: [R-sig-ME] 
 Decreasing size of gamm4 model output (multiple GB when
 saved to .rds)
In-Reply-To: <99E542F7-44AA-4E68-8BBA-B67361ED7A1E@comcast.net>
References: <YT4PR01MB9832F6BDF81134D62A204DA2A3FBA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>,
 <99E542F7-44AA-4E68-8BBA-B67361ED7A1E@comcast.net>
Message-ID: <7dcb59dbe6fd4de0a6af6a13401857a1@qimrberghofer.edu.au>

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of David Winsemius <dwinsemius at comcast.net>
Sent: Tuesday, 19 September 2023 12:24 PM
To: Meaghan Rupprecht
Cc: R-SIG-Mixed-Models at r-project.org
Subject: Re: [R-sig-ME]  Decreasing size of gamm4 model output (multiple GB when saved to .rds)

> I was puzzled by the fact that you save the output as an rds file. I suspect but am unable to confirm, that your result(s) include some representation of the data. 
> You might instead return the models with the data omitted
> David.

>> On Sep 17, 2023, at 10:11 PM, Meaghan Rupprecht <rupprecht at unbc.ca> wrote:
>>
>> ?I am running a Generalized Additive Mixed Model with the R package, gamm4. Each model output includes a mer object and a gam object. 
>> I need to compare 26 model structures based on a combination of variables and then conduct model averaging on the best models based on AIC.
>> The problem is, each .rds file with model output is approximately 5GB. For all 26 models, there is no way I can load them into my R environment 
>> for any kind of model comparison or averaging. Similar models run with mgcv::gamm() were only 5.7 MB, which is a much more manageable size for comparisons. 
>> (Note: unfortunately I have to stay within the gamm4 package based on model structure, otherwise I would use the mgcv model outputs).
>> Is there a way to decrease the size of the .rds file to a more reasonable size? Are there arguments within gamm4 or lme4 that could reduce the amount of 
>> extra information retained within the model?

I presume this is because gamm4's gam contains "model", which a copy of the data frame. Having little memory on my machine, I was
save()'ing then removing each gamm4 model, while tabulating summaries for each model by hand (can run deviance(), AIC() etc for each). 
Do you have the same random effects fitted in each model? I have no idea if these models can be compared if the cross-validation selected gams
have different edf's with different REs in the mer part. Maybe use gam to choose roughly equivalent polynomial fixed effects, then just do in lmer?

hth, David Duffy

From @v|k @end|ng |rom @@v|on@huj|@@c@||  Tue Sep 19 12:36:22 2023
From: @v|k @end|ng |rom @@v|on@huj|@@c@|| (Avraham N Kluger)
Date: Tue, 19 Sep 2023 10:36:22 +0000
Subject: [R-sig-ME] How to specify a correlation between cross-nested effects
Message-ID: <AS8PR10MB50919CB61CA60D550F3B8EB6D4FAA@AS8PR10MB5091.EURPRD10.PROD.OUTLOOK.COM>

Hi,



I am trying to model round-robin data, typically analyzed with an ANOVA-based Social Relations Model (SRM), with a mixed model with cross-nested effects.

First, I give a brief background to clarify the motivation behind my mixed model question. One way to analyze SRM data in R is with tripleR package. I use the example data of that package. The data reflect the liking rating each person in a group of ten gave each other. A record with NA is needed in tripleR for self-rating (liking that one would have given to oneself if measured). The model estimates three variances: perceiver (actor), target (partner), and error, and two covariances: perceiver-target and dyadic (error + dyadic). [The perceiver variance reflects differences in liking others; the target variance reflects differences in being liked by others; and the perceiver-target covariance reflects the degree to which people who like others are liked by others. For my purpose, I ignore the dyadic covariance in my question].

Below is the code for the tripleR example (using Group 1 data only for simplicity)

library(TripleR)

library(glmmTMB)

data("multiLikingLong")

df <- multiLikingLong

df <- df[df$group.id ==1, ]

RR(liking_a ~ perceiver.id*target.id, data = df)



It produces the following output



Round-Robin object ('RR'), calculated by TripleR

------------------------------------------------

Univariate analysis of one round robin variable



Univariate analyses for: liking_a

---------

Round robin analysis for a single group; using the formula of Lashley & Bond (1997).



                         estimate standardized    se t.value p.value

actor variance              0.228        0.267 0.126   1.814   0.052

partner variance            0.067        0.079 0.058   1.161   0.138

relationship variance       0.558        0.654 0.098   5.684   0.000

error variance                 NA           NA    NA      NA      NA

actor-partner covariance    0.041        0.329 0.067   0.604   0.561

relationship covariance     0.216        0.388 0.098   2.203   0.028

Actor effect reliability: .777

Partner effect reliability: .506



Next, I get rid of the rows with NA, needed by tripleR, and run a mixed model.



x <- na.omit(df)

m <- glmmTMB(liking_a ~ 1 + (1 |perceiver.id) + (1 |target.id), data = x,

             family = gaussian(link = "identity"))

summary(m)



It yields the following results:



Family: gaussian  ( identity )

Formula:          liking_a ~ 1 + (1 | perceiver.id) + (1 | target.id)

Data: x



     AIC      BIC   logLik deviance df.resid

   231.7    241.7   -111.8    223.7       86



Random effects:



Conditional model:

Groups       Name        Variance Std.Dev.

perceiver.id (Intercept) 0.19986  0.4471

target.id    (Intercept) 0.06102  0.2470

Residual                 0.55838  0.7472

Number of obs: 90, groups:  perceiver.id, 10; target.id, 10



Dispersion estimate for gaussian family (sigma^2): 0.558



Conditional model:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)   3.3556     0.1797   18.67   <2e-16 ***

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1



The results for the perceiver and target variances are similar but not identical. The results for the residuals are identical. For example, tripleR estimates the perceiver variance as .228 but glmmTMB, .199. Yet, tripleR also estimates the actor-partner covariance and correlation; the standardized correlation is .329. My question is, how can I specify this correlation with glmmTMB?



I found an approximation for the correlation:



cor(

    ranef(m)$cond$perceiver.id,

    ranef(m)$cond$target.id

    )



            (Intercept)

(Intercept)   0.2959082



But, this approximation is based on the random effects whose variances differ from the model's.

Thank you,



Avi Kluger

http://avikluger.wix.com/avi-kluger


	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Tue Sep 19 13:29:59 2023
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Tue, 19 Sep 2023 11:29:59 +0000
Subject: [R-sig-ME] 
 How to get prediction interval from R package MCMCglmm
 fitwith measurement error *and* a random effect?
In-Reply-To: <CAP=UNakbZCjr5rOWG16YKW9L0e5L25CT9PM84u6i0oHZykr49g@mail.gmail.com>
References: <CAP=UNakbZCjr5rOWG16YKW9L0e5L25CT9PM84u6i0oHZykr49g@mail.gmail.com>
Message-ID: <AS8PR05MB8659610C4E42810112487E3CACFAA@AS8PR05MB8659.eurprd05.prod.outlook.com>

Hi Fiona,

If you set up the measurement error model explicitly (without using mev ? see code below) the predict function should work. Note that the default is to have the random effects marginalised and so if you want them in the prediction interval you will need marginal = NULL or  marginal=~idh(sqrt(sig.obs)):units or marginal=~ BirdID dpending on exactly what you want.

Cheers,

Jarrod

prior <- list(B = list(mu=0, V=1e10), #for fixed effects
               R = list(V=1, nu=0.002),  #for residuals
               G = list( #random effects
                 G1 = list(V=1, nu=0.002) #first random effect, i.e. BirdID.
                 G2 = list(V=1, fix=1) #mev random effects
               ))

#fit the glmm
m <- MCMCglmm::MCMCglmm(
            fixed = obs.alt ~ 1,
            family = "gaussian",
            random = ~BirdID+idh(sqrt(sig.obs)):units,
            prior = prior,
            data = data.sim
)
#get a prediction interval
predict(m,  type = "response", interval = "prediction", level = 0.95)[1:3, ]


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fiona Scarff <fiona.scarff.4 at gmail.com>
Date: Monday, 18 September 2023 at 16:29
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] How to get prediction interval from R package MCMCglmm fitwith measurement error *and* a random effect?
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.

How to get prediction interval from R package MCMCglmm fit with
measurement error *and* a random effect?

I am having trouble producing a prediction interval from a model fit
by the R package MCMCglmm, when both a random effect and a measurement
error is specified in the fit. Many thanks in advance for your time
and any suggestions.

I can reproduce the prediction interval examples in the package author
(Jarrod Hadfield)?s MCMCglmm course notes [link
http://cran.nexr.com/web/packages/MCMCglmm/vignettes/CourseNotes.pdf]<http://cran.nexr.com/web/packages/MCMCglmm/vignettes/CourseNotes.pdf%5d>
p.47, but with my own model structure I get this error:

Error in h(simpleError(msg, call)) :
  error in evaluating the argument 'x' in selecting a method for
function 't': invalid 'times' argument

 ?x? and ?t? aren?t variables I have declared so I imagine they must
be objects called internally by the predict function. In the MCMCglmm
course notes (p.47 again), the author does note that the predict
function for MCMCglmm is currently incomplete and needs further
testing, but should be OK for simpler models. Perhaps my model
structure is an instance of a more elaborate model not yet
accommodated. Is there some other way I can generate a prediction
interval?

For context, I am studying the flying height of birds. We obtain
observations of height from satellite tags attached to birds. The
observations are recorded with large measurement error (often
reporting negative height as if the birds were flying underground).
The variance of the measurement error can be predicted based on the
number and position of available satellites. MCMCglmm has a facility
for users to specify a vector of measurement errors associated with
observations on the response variable. We also have repeat
observations on each tagged bird, so it?s desirable to also
incorporate the flying height preferences of individual birds into the
model.

Here is a reproducible example:

Session info?
MCMCglmm_2.35
R version 4.2.3 (2023-03-15)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Ventura 13.4.1

#Declare some parameters governing the flying height of the birds, for
purposes of simulation
set.seed(756)
alt1 <- 20 # mean of true flying height, in metres above ground level
sig <- 10 #variance in true flying height
# gamma distribution scale parameter:
beta = sig/alt1
#  gamma distribution shape parameter :
alpha = alt1/beta

 #Additional variation in height amongst individual birds
ind.re <- rnorm(n= 20, mean=0, sd = 3) # ?ind.re? denotes individual
random effects

#Create dataframe containing simulation data
#20 tagged birds, with 100 observations each = 2000 observations total
data.sim <- data.frame(BirdID = as.factor(rep(1:20, each=100) ) ) %>%
                        mutate(., sig.obs = rep(5,2000), #std dev of
measurement error, just for this example I'm imposing an identical
error for each observation
            true.alt = #true altitude, drawn from a gamma distribution
                         rgamma(n = 2000, shape = alpha, scale = beta) +
                          ind.re[data.sim$BirdID], #individual
variation amongst birds
             obs.alt = #observed altitude
                             true.alt +
rnorm(n = 2000, mean = 0, sd = sig.obs) # imprecision due to measurement error
                        )

 #declare priors
prior <- list(B = list(mu=0, V=1e10), #for fixed effects
               R = list(V=1, nu=0.002),  #for residuals
               G = list( #random effects
                 G1 = list(V=1, nu=0.002) #first random effect, i.e. BirdID.
               ))

#fit the glmm
m <- MCMCglmm::MCMCglmm(
            fixed = obs.alt ~ 1,
            family = "gaussian",
            random = ~BirdID,
            mev = data.sim$sig.obs, #vector of measurement errors
            prior = prior,
            data = data.sim
)
#get a prediction interval
predict(m,  type = "response", interval = "prediction", level = 0.95)[1:3, ]

Note that if the model is refit without BirdID as a random effect,
(i.e. if we comment out ?random = ~BirdID,? above), or alternatively
without the measurement error vector (?mev =  data.sim$sig.obs,?) then
the predict function works fine:

(Output without random effect specified)
       fit      lwr      upr
1 20.33545 5.284893 33.06830
2 20.72960 6.874275 35.33598
3 20.57229 3.561330 33.84181

 Am I doing something wrong here, or is there a workaround? Many thanks again!
Fiona Scarff
Murdoch University

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 19 17:12:50 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 19 Sep 2023 11:12:50 -0400
Subject: [R-sig-ME] 
 Decreasing size of gamm4 model output (multiple GB when
 saved to .rds)
In-Reply-To: <7dcb59dbe6fd4de0a6af6a13401857a1@qimrberghofer.edu.au>
References: <YT4PR01MB9832F6BDF81134D62A204DA2A3FBA@YT4PR01MB9832.CANPRD01.PROD.OUTLOOK.COM>
 <99E542F7-44AA-4E68-8BBA-B67361ED7A1E@comcast.net>
 <7dcb59dbe6fd4de0a6af6a13401857a1@qimrberghofer.edu.au>
Message-ID: <c6e07fe4-633d-9932-ca8e-6f3b6fc1d9a3@gmail.com>

   You could take a look at the `strip_gamm4_env()` function here: 
https://github.com/bbolker/mmd_utils/blob/master/gamm4_utils.R ; it 
definitely reduces the sizes of stored objects, but you'll have to check 
which model methods actually work on the stripped object ...

   cheers
    Ben Bolker


On 2023-09-19 3:21 a.m., David Duffy wrote:
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of David Winsemius <dwinsemius at comcast.net>
> Sent: Tuesday, 19 September 2023 12:24 PM
> To: Meaghan Rupprecht
> Cc: R-SIG-Mixed-Models at r-project.org
> Subject: Re: [R-sig-ME]  Decreasing size of gamm4 model output (multiple GB when saved to .rds)
> 
>> I was puzzled by the fact that you save the output as an rds file. I suspect but am unable to confirm, that your result(s) include some representation of the data.
>> You might instead return the models with the data omitted
>> David.
> 
>>> On Sep 17, 2023, at 10:11 PM, Meaghan Rupprecht <rupprecht at unbc.ca> wrote:
>>>
>>> ?I am running a Generalized Additive Mixed Model with the R package, gamm4. Each model output includes a mer object and a gam object.
>>> I need to compare 26 model structures based on a combination of variables and then conduct model averaging on the best models based on AIC.
>>> The problem is, each .rds file with model output is approximately 5GB. For all 26 models, there is no way I can load them into my R environment
>>> for any kind of model comparison or averaging. Similar models run with mgcv::gamm() were only 5.7 MB, which is a much more manageable size for comparisons.
>>> (Note: unfortunately I have to stay within the gamm4 package based on model structure, otherwise I would use the mgcv model outputs).
>>> Is there a way to decrease the size of the .rds file to a more reasonable size? Are there arguments within gamm4 or lme4 that could reduce the amount of
>>> extra information retained within the model?
> 
> I presume this is because gamm4's gam contains "model", which a copy of the data frame. Having little memory on my machine, I was
> save()'ing then removing each gamm4 model, while tabulating summaries for each model by hand (can run deviance(), AIC() etc for each).
> Do you have the same random effects fitted in each model? I have no idea if these models can be compared if the cross-validation selected gams
> have different edf's with different REs in the mer part. Maybe use gam to choose roughly equivalent polynomial fixed effects, then just do in lmer?
> 
> hth, David Duffy
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ||on@@@c@r||@4 @end|ng |rom gm@||@com  Wed Sep 20 14:30:45 2023
From: ||on@@@c@r||@4 @end|ng |rom gm@||@com (Fiona Scarff)
Date: Wed, 20 Sep 2023 20:30:45 +0800
Subject: [R-sig-ME] How to obtain a posterior predictive distribution in
 MCMCglmm, and constrain it to non-negative values?
Message-ID: <CAP=UNa=3XfJnkmsdP7C0P0FxVBf0QJxNYznyGOmgrZgr2CcUzg@mail.gmail.com>

In MCMCglmm, how can I obtain a posterior predictive distribution? I
have two random effects; individuals from which observations have been
obtained, and a measurement error. I would like to marginalise only
over the individual random effect, and supply a single trivially small
measurement error for the prediction, so as to get the predicted
distribution of the true (rather than measured) response in any
unspecified individual.

Can I further specify this in such a way as to constrain the
prediction to non-negative values? Naively, I could impose a
distribution like log-normal or poisson when fitting the glmm. But the
model fit needs to be able to handle negative values in the response,
which arise purely due to measurement error.

Many thanks for your time and any suggestions!

Fiona Scarff
Murdoch University


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Sep 20 16:25:30 2023
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 20 Sep 2023 14:25:30 +0000
Subject: [R-sig-ME] How to obtain a posterior predictive distribution in
 MCMCglmm, and constrain it to non-negative values?
In-Reply-To: <CAP=UNa=3XfJnkmsdP7C0P0FxVBf0QJxNYznyGOmgrZgr2CcUzg@mail.gmail.com>
References: <CAP=UNa=3XfJnkmsdP7C0P0FxVBf0QJxNYznyGOmgrZgr2CcUzg@mail.gmail.com>
Message-ID: <AS8PR05MB8659F7C231C051E8477CF56EACF9A@AS8PR05MB8659.eurprd05.prod.outlook.com>

HI,

You can use simulate(model) in exactly the same way as predict(model) to generate posterior predictive distributions with various random effects marginalised using the argument marginal. The only constraints that can be imposed are those that arise from the particular distribution fitted (e.g. if family=?poisson? the outcome is constrained to be non-negative integers) and so arbitrarily imposing a positive constraint is not possible.

Cheers,

Jarrod


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fiona Scarff <fiona.scarff.4 at gmail.com>
Date: Wednesday, 20 September 2023 at 13:31
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] How to obtain a posterior predictive distribution in MCMCglmm, and constrain it to non-negative values?
This email was sent to you by someone outside the University.
You should only click on links or attachments if you are certain that the email is genuine and the content is safe.

In MCMCglmm, how can I obtain a posterior predictive distribution? I
have two random effects; individuals from which observations have been
obtained, and a measurement error. I would like to marginalise only
over the individual random effect, and supply a single trivially small
measurement error for the prediction, so as to get the predicted
distribution of the true (rather than measured) response in any
unspecified individual.

Can I further specify this in such a way as to constrain the
prediction to non-negative values? Naively, I could impose a
distribution like log-normal or poisson when fitting the glmm. But the
model fit needs to be able to handle negative values in the response,
which arise purely due to measurement error.

Many thanks for your time and any suggestions!

Fiona Scarff
Murdoch University

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Wed Sep 20 16:35:00 2023
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Wed, 20 Sep 2023 17:35:00 +0300
Subject: [R-sig-ME] 
 Collinearity diagnostics for (mixed) multinomial models
In-Reply-To: <95fa2733-b3ec-8c23-c71b-850720c7f3c7@mcmaster.ca>
References: <mailman.19600.5.1645786802.52378.r-sig-mixed-models@r-project.org>
 <ec746b24-eb5b-5579-2b24-3c3b492d55d9@mcmaster.ca>
 <CAG_dBVfcpzW5RAs9syWFdL+RvryeAppowexjX_a9zJqRu+PC4Q@mail.gmail.com>
 <7e05d26d-e8af-aa48-8fd4-543c9f3dc3a2@mcmaster.ca>
 <CAG_dBVenhHeF5-hmA7M6xfD2FAeLmqzwc6AL-xrVREZuKyyKpA@mail.gmail.com>
 <67a63dca-f3c0-d766-0a2a-bad1a5fed9c3@mcmaster.ca>
 <CAG_dBVcv+12Q6_dSdX7_2cBPR5PgQmJ5bqZgQoWh88ATCmT6GA@mail.gmail.com>
 <0f03187e-d848-ea43-e370-ead2d403b530@mcmaster.ca>
 <CAG_dBVfv2-8Z0VRvcK4QUP97oh5jOhPd2d=LUj0N_6Ec+appMw@mail.gmail.com>
 <f80557f3-35c7-7b22-ae9c-2f14ff0d7ac0@mcmaster.ca>
 <CAG_dBVe7f5aEB_hA5t-j2u9ZJw-bDQPOchxc3-QTX3VejqXQSQ@mail.gmail.com>
 <d8c397b8-fbec-6c39-fdf5-5047daf6f219@mcmaster.ca>
 <CAG_dBVc2Vw6mQ17ZvXM+vJvvON9D=jHsXp+_3gM7m1zukNAAuQ@mail.gmail.com>
 <dfd31e31-511c-73c0-a8a4-dfc2a3e37b20@phillipalday.com>
 <6ffe007d-b9f4-5fd1-87f9-152697012047@mcmaster.ca>
 <CAG_dBVfUCfbVTpNjGRrn6pMjPw+_z_diy10pgy5dqnqvJsPz2Q@mail.gmail.com>
 <95fa2733-b3ec-8c23-c71b-850720c7f3c7@mcmaster.ca>
Message-ID: <CAG_dBVcsnKVjTt2LythPN-5d8iBQHRhuAxcKE-_E2i9s0CA0Xg@mail.gmail.com>

Dear John, Georges, and other list members,

I gather from the silence of the thread that no solution has emerged as of
yet, and might still be years away. Therefore, since I have to present at
least some collinearity metrics in my thesis, I'm going with the
approximate solution of applying John and Sandy's vif() function to each of
the binary sub-regressions and presenting the C-1 GVIF matrices thus
obtained.

John is of course right that the results will not be exactly correct
because the coefficient estimates of the individually fit Bernoulli models
are not the same as those of the corresponding multinomial. The received
view is that they are "consistent but inefficient" estimates of those
coefficients. Hosmer, Lemeshow and Sturdivant (2013: 282) say "It has been
our experience that the coefficients obtained from separately fit logistic
models are, in general, close to those from the multinomial fit."
Therefore, this approach seems to be best approximation to a solution that
is available to mere mortals at this moment in time.

Best,

J

Hosmer, D.W., Lemeshow, S., Sturdivant, R.X., 2013. *Applied logistic
regression*, Third edition. ed, Wiley series in probability and statistics.
Wiley, Hoboken, New Jersey.



pe 3. helmik. 2023 klo 0.01 John Fox (jfox at mcmaster.ca) kirjoitti:

> Dear Juho,
>
> On 2023-02-02 4:08 p.m., Juho Kristian Ruohonen wrote:
> > Many thanks to John and Philip (and Georges behind the scenes). I'll
> > keep an eye on this thread. If there's a solution before my thesis goes
> > to print, I'll certainly adopt it posthaste.
> >
> > Otherwise, I might just end up reporting all C-1 GVIF^(1/(2*DF))
> > statistics for each binary subregression for each predictor, as
> > calculated by car::vif(). It's a bit messy, but then multinomial models
> > themselves are messy with their C-1 sets of coefficients, and this would
> > be no different. At least it's maximally transparent.
>
> Georges made a similar suggestion in our discussions, but there's a
> problem: the multinomial logit model logits are for each other level of
> the response (say B, C, D) vs the baseline level (A), while the
> individual binary logits would be for, say, A vs. {B, C, D}, B vs. {A,
> C, D}, etc. One could fit binary logit models to subsets of the data, B
> vs. A for those for whom the response is A or B, etc., but I believe the
> coefficients would differ from those for the multinomial logit model.
>
> >
> > That said, I hope our experts reach a breakthrough.
>
> You're more optimistic than I am. Georges has a good explanation for why
> the GVIF works with the multivariate linear model, but the necessary
> properties aren't shared by the multinomial logit model.
>
> Best,
>   John
>
> >
> > Best,
> >
> > Juho
> >
> >
> >
> >
> >
> > ke 1. helmik. 2023 klo 18.19 John Fox (jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>) kirjoitti:
> >
> >     Dear Phillip (and Juho),
> >
> >     You raise a reasonable point but, unfortunately, one that isn't
> really
> >     relevant to the problem at hand.
> >
> >     Applied to a linear model, which is the context in which generalized
> >     variance inflation was originally defined in the paper by me and
> >     Georges
> >     Monette cited in ?car::vif, the GVIF *is* invariant with respect to
> >     inessential changes to the model such as centering regressors or any
> >     change in the bases for the regressor subspaces of terms in the
> model.
> >     The GVIF compares the size of the joint confidence region for the
> >     set of
> >     coefficients for a term in the model to its size in a utopian
> situation
> >     in which the subspace for the term is orthogonal to the subspaces of
> >     the
> >     other terms, and reduces to the usual VIF when the term in
> >     one-dimensional.
> >
> >     Generalized variance inflation has subsequently been extended to some
> >     other regression models, such as generalized linear models, and it
> >     retains these essential invariances (although interpretation isn't as
> >     straightforward).
> >
> >     In response to Juho's original question, I conjectured an extension
> to
> >     multinomial logit models, tested some of its invariance properties,
> but
> >     unfortunately didn't test sufficiently extensively. (I did suggest
> >     additional tests that I didn't perform.) It's clear from Juho's
> example
> >     that my conjecture was wrong.
> >
> >     The reason that I hadn't yet responded to Juho's recent question is
> >     that
> >     Georges and I are still trying to understand why my proposed
> definition
> >     fails for multinomial logit models. It appears to work, for example,
> >     for
> >     multivariate linear models. Neither of us, at this point, has a
> >     solution
> >     to Juho's problem, and it's possible that there isn't one. We're
> >     continuing to discuss the problem, and one of us will post an update
> to
> >     the list if we come up with either a solution or a clear explanation
> of
> >     why my proposal failed.
> >
> >     Thank you for prompting me to reply, if only in a preliminary manner.
> >
> >     Best,
> >        John
> >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >
> >     On 2023-02-01 12:19 a.m., Phillip Alday wrote:
> >      > I haven't seen an answer go by yet, but here's a breadcrumb:
> >      >
> >      > Iacobucci, D., Schneider, M.J., Popovich, D.L. et al. Mean
> centering
> >      > helps alleviate ?micro? but not ?macro? multicollinearity. Behav
> >     Res 48,
> >      > 1308?1317 (2016). https://doi.org/10.3758/s13428-015-0624-x
> >     <https://doi.org/10.3758/s13428-015-0624-x>
> >      >
> >      >
> >      >
> >      > On 26/1/23 8:56 am, Juho Kristian Ruohonen wrote:
> >      >> Dear all,
> >      >>
> >      >> I'm resurrecting this thread because a problem has come up which
> >     might need
> >      >> fixing once someone gets around to writing a relevant R package.
> >      >>
> >      >> In this same thread last March, John Fox showed me how to
> >     compute GVIFs for
> >      >> a *nnet* multinomial model. I then wrote a simple function that
> >     loops
> >      >> through all predictors in such a model and applies John's code
> >     to them,
> >      >> returning the GVIF, DF, and GVIF^(1/(2*Df)) statistic for each
> >     predictor.
> >      >> Available here
> >      >> <https://github.com/jkruohon/StatsMisc/blob/main/gvif_multinom.R
> >     <https://github.com/jkruohon/StatsMisc/blob/main/gvif_multinom.R>>,
> the
> >      >> function seems to work just fine, reproducing John's results
> >     exactly on the
> >      >> carData examples. Likewise, applying this function to my own
> >     research data
> >      >> yielded entirely plausible results.
> >      >>
> >      >> But to my horror, I now discover that *when I refit my
> >     multinomial model
> >      >> with two quantitative predictors centered, the GVIF statistics
> >     change
> >      >> considerably** -- *even though the model has the same fit and
> >     virtually
> >      >> identical coefficients (except for the intercepts) as the
> >     original one. How
> >      >> can this be? The only thing that changes between the two models
> >     is the set
> >      >> of intercepts which, moreover, are specifically excluded from
> >     the GVIF
> >      >> calculations.
> >      >>
> >      >> Below is a minimal example. The anonymized datafile is
> >     downloadable here
> >      >> <https://github.com/jkruohon/StatsMisc/raw/main/d_anon.RData
> >     <https://github.com/jkruohon/StatsMisc/raw/main/d_anon.RData>>.
> >      >>
> >      >>> mod1 <- multinom(y ~., data = d.anon, maxit = 999)
> >      >>> gvif.multinom(mod1) # x6 and x26 top the collinearity list
> >      >>              GVIF DF GVIF^(1/(2df))
> >      >> x6  3.463522e+03  3       3.889732
> >      >> x26 2.988396e+03  3       3.795244
> >      >> x27 1.390830e+03  3       3.341019
> >      >> x2  3.889656e+02  3       2.701792
> >      >> x13 2.930026e+02  3       2.577183
> >      >> x19 2.051250e+04  6       2.287362
> >      >> x25 7.043339e+03  6       2.092417
> >      >> x24 1.078212e+07 12       1.963493
> >      >> x9  2.357662e+01  3       1.693351
> >      >> x17 1.991744e+01  3       1.646413
> >      >> x5  3.869759e+02  6       1.643010
> >      >> x12 1.787075e+01  3       1.616927
> >      >> x18 2.943991e+02  6       1.605997
> >      >> x1  2.700175e+03  9       1.551075
> >      >> x16 2.576739e+04 12       1.526844
> >      >> x7  1.483341e+02  6       1.516829
> >      >> x20 1.159374e+01  3       1.504425
> >      >> x3  1.612637e+04 12       1.497318
> >      >> x28 1.081693e+01  3       1.487136
> >      >> x10 9.706880e+00  3       1.460539
> >      >> x22 9.459035e+00  3       1.454257
> >      >> x15 9.124519e+00  3       1.445556
> >      >> x14 7.017242e+00  3       1.383655
> >      >> x21 6.404687e+00  3       1.362750
> >      >> x8  6.072614e+00  3       1.350712
> >      >> x11 4.797251e+00  3       1.298670
> >      >> x4  3.665742e+03 18       1.256043
> >      >> x23 3.557201e+00  3       1.235525
> >      >>
> >      >> Now we refit the model with the quantitative predictors x6 and
> >     x26 centered:
> >      >>
> >      >>> d.anon$x6 <- d.anon$x6 - mean(d.anon$x6)
> >      >>> d.anon$x26 <- d.anon$x26 - mean(d.anon$x26)
> >      >>> mod2 <- update(mod1, data = d.anon, maxit = 999)
> >      >>> c(logLik(mod1), logLik(mod2))  # same fit to the data
> >      >> [1] -2074.133 -2074.134
> >      >>
> >      >>> gvif.multinom(mod2)
> >      >>              GVIF DF GVIF^(1/(2df))
> >      >> x2  6.196959e+04  3       6.290663
> >      >> x13 3.031115e+04  3       5.583850
> >      >> x27 2.552811e+04  3       5.426291
> >      >> x14 1.642231e+04  3       5.041646
> >      >> x6  1.573721e+04  3       5.005967
> >      >> x26 1.464437e+04  3       4.946277
> >      >> x9  1.262667e+04  3       4.825564
> >      >> x10 5.714321e+03  3       4.228251
> >      >> x19 2.255013e+07  6       4.099798
> >      >> x25 1.227033e+07  6       3.897068
> >      >> x12 3.394139e+03  3       3.876635
> >      >> x15 1.938364e+03  3       3.531067
> >      >> x11 1.685265e+03  3       3.449674
> >      >> x21 8.429450e+02  3       3.073500
> >      >> x23 7.639755e+02  3       3.023523
> >      >> x22 6.887451e+02  3       2.971733
> >      >> x17 5.640312e+02  3       2.874422
> >      >> x20 3.855848e+02  3       2.697864
> >      >> x24 1.444083e+10 12       2.650430
> >      >> x7  7.148911e+04  6       2.538166
> >      >> x18 1.674603e+04  6       2.249017
> >      >> x5  9.662266e+03  6       2.148275
> >      >> x16 6.264044e+07 12       2.112851
> >      >> x1  6.634544e+05  9       2.105882
> >      >> x3  1.558132e+07 12       1.993847
> >      >> x8  6.168472e+01  3       1.987755
> >      >> x4  4.256459e+06 18       1.528059
> >      >> x28 9.783234e+00  3       1.462448
> >      >>
> >      >> And so I'm at my wits' end. The models are virtually identical,
> >     yet the
> >      >> GVIF statistics are very different. I don't know which ones to
> >     trust.
> >      >> Worse, the discrepancy makes me disinclined to trust either of
> >     them --
> >      >> which is a return to Square One, i.e. the situation where GVIF
> >     statistics
> >      >> for multinomial models did not exist. And I don't know which
> >      >> multicollinearity metric I can present in my thesis, if any.
> >      >>
> >      >> I hope someone can help.
> >      >>
> >      >> Best,
> >      >>
> >      >> Juho
> >      >>
> >      >>
> >      >>
> >      >>
> >      >>
> >      >> ke 2. maalisk. 2022 klo 16.35 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>) kirjoitti:
> >      >>
> >      >>> Dear Juho,
> >      >>>
> >      >>> On 2022-03-02 6:23 a.m., Juho Kristian Ruohonen wrote:
> >      >>>> One last comment, John: Sorry if I seemed to be implying that
> >     you (or
> >      >>>> anyone else) should debug my code for me. That wasn't the
> >     idea. I do
> >      >>>> believe that the function locates the intended rows/columns
> >      >>>> successfully. I just wasn't entirely positive what those
> intended
> >      >>>> rows/columns should be when dealing with a multicategory
> factor.
> >      >>>> Presently, it locates every row/column involving the
> multicategory
> >      >>>> factor in question, so the number of rows/columns identified
> >     is the
> >      >>>> number of factor levels minus one, times the number of response
> >      >>>> categories minus one. I hope that's correct.
> >      >>>
> >      >>> OK, that's a fair remark. Yes, what you describe is correct.
> >      >>>
> >      >>> You can also reassure yourself that your function is working
> >     properly by:
> >      >>>
> >      >>> (1) If you haven't already done so, show that you get the same
> >     GVIFs
> >      >>> from your function as from the one I sent you used directly.
> >      >>>
> >      >>> (2) Vary the baseline level of the response variable and
> >     confirm that
> >      >>> you get the same GVIFs.
> >      >>>
> >      >>> (3) Vary the basis for the regressor subspace for a factor,
> >     e.g., either
> >      >>> by using contr.sum() in place of the default contr.treatment()
> >     or by
> >      >>> changing the baseline level of the factor for
> >     contr.treatment(), and
> >      >>> again confirm that the GVIFs are unchanged.
> >      >>>
> >      >>> Best,
> >      >>>    John
> >      >>>
> >      >>>>
> >      >>>> My current plan is to present the output of the new function
> in my
> >      >>>> thesis and credit you for the math. But if *vif()* gets a
> relevant
> >      >>>> update before my project is finished, then I'll use that and
> >     cite the
> >      >>>> /car /package instead.
> >      >>>>
> >      >>>> Thanks again for your help.
> >      >>>>
> >      >>>> Best,
> >      >>>>
> >      >>>> Juho
> >      >>>>
> >      >>>> ti 1. maalisk. 2022 klo 23.54 John Fox (jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >>>> <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>)
> kirjoitti:
> >      >>>>
> >      >>>>      Dear Juho,
> >      >>>>
> >      >>>>      On 2022-03-01 3:13 p.m., Juho Kristian Ruohonen wrote:
> >      >>>>       > Dear John,
> >      >>>>       >
> >      >>>>       > Yes, my function uses your code for the math. I was
> >     just hoping to
> >      >>>>       > verify that it is handling multicategory factors
> >     correctly (your
> >      >>>>       > examples didn't involve any).
> >      >>>>
> >      >>>>      That's not really my point. Your code sets up
> >     computations for the
> >      >>>>      various terms in the model automatically, while the
> >     function I sent
> >      >>>>      requires that you locate the rows/columns for the
> >     intercepts and each
> >      >>>>      focal term manually. If you haven't already done so, you
> >     could check
> >      >>>>      that your function is identifying the correct columns and
> >     getting the
> >      >>>>      corresponding GVIFs.
> >      >>>>
> >      >>>>       >
> >      >>>>       > I guess interactions aren't that important after all,
> >     given that
> >      >>> the
> >      >>>>       > chief concern is usually collinearity among main
> effects.
> >      >>>>
> >      >>>>      I wouldn't say that, but it's not clear what collinearity
> >     means in
> >      >>>>      models with interactions, and if you compute VIFs or
> >     GVIFs for "main
> >      >>>>      effects" in models with interactions, you'll probably get
> >     nonsense.
> >      >>>>
> >      >>>>      As I said, I think that this might be a solvable problem,
> >     but one
> >      >>> that
> >      >>>>      requires thought about what needs to remain invariant.
> >      >>>>
> >      >>>>      I think that we've probably come to end for now.
> >      >>>>
> >      >>>>      John
> >      >>>>
> >      >>>>       >
> >      >>>>       > Many thanks for all your help.
> >      >>>>       >
> >      >>>>       > Best,
> >      >>>>       >
> >      >>>>       > Juho
> >      >>>>       >
> >      >>>>       > ti 1. maalisk. 2022 klo 18.01 John Fox
> >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>       > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>) kirjoitti:
> >      >>>>       >
> >      >>>>       >     Dear Juho,
> >      >>>>       >
> >      >>>>       >     On 2022-03-01 8:24 a.m., Juho Kristian Ruohonen
> wrote:
> >      >>>>       >      > Dear John (Fox, as well as other list members),
> >      >>>>       >      >
> >      >>>>       >      > I've now written a simple function to try and
> >     calculate
> >      >>>>      GVIFS for
> >      >>>>       >     all
> >      >>>>       >      > predictors in a nnet::multinom() object based
> >     on John's
> >      >>>>      example
> >      >>>>       >     code. If
> >      >>>>       >      > its results are correct (see below), I will
> >     proceed to
> >      >>> write a
> >      >>>>       >     version
> >      >>>>       >      > that also works with mixed-effects multinomial
> >     models fit
> >      >>> by
> >      >>>>       >      > brms::brm(). Here's the code:
> >      >>>>       >      >
> >      >>>>       >      >     gvif.multinom <- function(model){
> >      >>>>       >      >        (classes <- model$lev)
> >      >>>>       >      >        (V.all <- vcov(model))
> >      >>>>       >      >        (V.noIntercepts <-
> >     V.all[!grepl("\\(Intercept\\)$",
> >      >>>>       >      >     rownames(V.all), perl = T),
> >      >>>>       >      >
> >       !grepl("\\(Intercept\\)$",
> >      >>>>       >      >     colnames(V.all), perl = T)])
> >      >>>>       >      >        (R <- cov2cor(V.noIntercepts))
> >      >>>>       >      >        (terms <- attr(model$terms,
> "term.labels"))
> >      >>>>       >      >        (gvif <- numeric(length = length(terms)))
> >      >>>>       >      >        (names(gvif) <- terms)
> >      >>>>       >      >        (SE.multiplier <- numeric(length =
> >     length(terms)))
> >      >>>>       >      >        (names(SE.multiplier) <- terms)
> >      >>>>       >      >        #The line below tries to capture all
> >     factor levels
> >      >>>>      into a
> >      >>>>       >     regex
> >      >>>>       >      >     for coef name matching.
> >      >>>>       >      >        (LevelsRegex <- paste0("(",
> >      >>>>      paste(unlist(model$xlevels),
> >      >>>>       >     collapse
> >      >>>>       >      >     = "|"),")?"))
> >      >>>>       >      >
> >      >>>>       >      >        for(i in terms){
> >      >>>>       >      >          #The regex stuff below tries to ensure
> all
> >      >>>>      interaction
> >      >>>>       >      >     coefficients are matched, including those
> >     involving
> >      >>>>      factors.
> >      >>>>       >      >          if(grepl(":", i)){
> >      >>>>       >      >            (termname <- gsub(":",
> >     paste0(LevelsRegex,
> >      >>> ":"), i,
> >      >>>>       >     perl = T))
> >      >>>>       >      >          }else{termname <- i}
> >      >>>>       >      >          (RegexToMatch <- paste0("^(",
> >      >>>>       >     paste(classes[2:length(classes)],
> >      >>>>       >      >     collapse = "|") ,"):", termname,
> >     LevelsRegex, "$"))
> >      >>>>       >      >
> >      >>>>       >      >          #Now the actual calculation:
> >      >>>>       >      >          (indices <- grep(RegexToMatch,
> >     rownames(R), perl
> >      >>>>      = T))
> >      >>>>       >      >          (gvif[i] <- det(R[indices, indices]) *
> >      >>>>      det(R[-indices,
> >      >>>>       >      >     -indices]) / det(R))
> >      >>>>       >      >          (SE.multiplier[i] <-
> >      >>> gvif[i]^(1/(2*length(indices))))
> >      >>>>       >      >        }
> >      >>>>       >      >        #Put the results together and order them
> >     by degree
> >      >>>>      of SE
> >      >>>>       >     inflation:
> >      >>>>       >      >        (result <- cbind(GVIF = gvif,
> >     `GVIF^(1/(2df))` =
> >      >>>>       >     SE.multiplier))
> >      >>>>       >      >
> >     return(result[order(result[,"GVIF^(1/(2df))"],
> >      >>>>      decreasing
> >      >>>>       >     = T),])}
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      > The results seem correct to me when applied to
> >     John's
> >      >>> example
> >      >>>>       >     model fit
> >      >>>>       >      > to the BEPS data. However, that dataset
> contains no
> >      >>> multi-df
> >      >>>>       >     factors, of
> >      >>>>       >      > which my own models have many. Below is a
> >     maximally simple
> >      >>>>       >     example with
> >      >>>>       >      > one multi-df factor (/region/):
> >      >>>>       >      >
> >      >>>>       >      >     mod1 <- multinom(partic ~., data =
> >     carData::Womenlf)
> >      >>>>       >      >     gvif.multinom(mod1)
> >      >>>>       >      >
> >      >>>>       >      >     GVIF GVIF^(1/(2df))
> >      >>>>       >      >     children 1.298794       1.067542
> >      >>>>       >      >     hincome  1.184215       1.043176
> >      >>>>       >      >     region   1.381480       1.020403
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      > These results look plausible to me. Finally,
> >     below is an
> >      >>>>      example
> >      >>>>       >      > involving both a multi-df factor and an
> >     interaction:
> >      >>>>       >      >
> >      >>>>       >      >     mod2 <- update(mod1, ~. +children:region)
> >      >>>>       >      >     gvif.multinom(mod2)
> >      >>>>       >      >
> >      >>>>       >      >                              GVIF GVIF^(1/(2df))
> >      >>>>       >      >     children:region 4.965762e+16      11.053482
> >      >>>>       >      >     region          1.420418e+16      10.221768
> >      >>>>       >      >     children        1.471412e+03       6.193463
> >      >>>>       >      >     hincome         6.462161e+00       1.594390
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      > These results look a bit more dubious. To be
> >     sure, it is
> >      >>> to be
> >      >>>>       >     expected
> >      >>>>       >      > that interaction terms will introduce a lot of
> >      >>>>      collinearity. But an
> >      >>>>       >      > 11-fold increase in SE? I hope someone can tell
> >     me whether
> >      >>>>      this is
> >      >>>>       >      > correct or not!
> >      >>>>       >
> >      >>>>       >     You don't need someone else to check your work
> >     because you
> >      >>>>      could just
> >      >>>>       >     apply the simple function that I sent you
> >     yesterday, which,
> >      >>>>      though not
> >      >>>>       >     automatic, computes the GVIFs in a transparent
> manner.
> >      >>>>       >
> >      >>>>       >     A brief comment on GVIFs for models with
> >     interactions (this
> >      >>>>      isn't the
> >      >>>>       >     place to discuss the question in detail): The Fox
> >     and Monette
> >      >>>>      JASA
> >      >>>>       >     paper
> >      >>>>       >     addresses the question briefly in the context of a
> >     two-way
> >      >>>>      ANOVA, but I
> >      >>>>       >     don't think that the approach suggested there is
> >     easily
> >      >>>>      generalized.
> >      >>>>       >
> >      >>>>       >     The following simple approach pays attention to
> what's
> >      >>>>      invariant under
> >      >>>>       >     different parametrizations of the RHS side of the
> >     model:
> >      >>>>      Simultaneously
> >      >>>>       >     check the collinearity of all of the coefficients
> >     of an
> >      >>>>      interaction
> >      >>>>       >     together with the main effects and, potentially,
> >     lower-order
> >      >>>>       >     interactions that are marginal to it. So, e.g., in
> >     the model
> >      >>>>      y ~ a +
> >      >>>>       >     b +
> >      >>>>       >     a:b + c, you'd check all of the coefficients for
> >     a, b, and
> >      >>>>      a:b together.
> >      >>>>       >
> >      >>>>       >     Alternatively, one could focus in turn on each
> >     explanatory
> >      >>>>      variable and
> >      >>>>       >     check the collinearity of all coefficients to
> >     which it is
> >      >>>>      marginal. So
> >      >>>>       >     in y ~ a + b + c + a:b + a:c + d, when you focus
> >     on a, you'd
> >      >>>>      look at
> >      >>>>       >     all
> >      >>>>       >     of the coefficients for a, b, c, a:b, and a:c.
> >      >>>>       >
> >      >>>>       >     John
> >      >>>>       >
> >      >>>>       >      >
> >      >>>>       >      > Best,
> >      >>>>       >      >
> >      >>>>       >      > Juho
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      >
> >      >>>>       >      > ti 1. maalisk. 2022 klo 0.05 John Fox
> >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >      > <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>) kirjoitti:
> >      >>>>       >      >
> >      >>>>       >      >     Dear Juha,
> >      >>>>       >      >
> >      >>>>       >      >     On 2022-02-28 5:00 p.m., Juho Kristian
> >     Ruohonen wrote:
> >      >>>>       >      >      > Apologies for my misreading, John, and
> >     many thanks
> >      >>>>      for showing
> >      >>>>       >      >     how the
> >      >>>>       >      >      > calculation is done for a single term.
> >      >>>>       >      >      >
> >      >>>>       >      >      > Do you think *vif()* might be updated in
> >     the near
> >      >>>>      future
> >      >>>>       >     with the
> >      >>>>       >      >      > capability of auto-detecting a
> >     multinomial model
> >      >>>>      and returning
> >      >>>>       >      >      > mathematically correct GVIF statistics?
> >      >>>>       >      >
> >      >>>>       >      >     The thought crossed my mind, but I'd want
> >     to do it in a
> >      >>>>       >     general way,
> >      >>>>       >      >     not
> >      >>>>       >      >     just for the multinom() function, and in a
> >     way that
> >      >>> avoids
> >      >>>>       >     incorrect
> >      >>>>       >      >     results such as those currently produced
> >     for "multinom"
> >      >>>>       >     models, albeit
> >      >>>>       >      >     with a warning. I can't guarantee whether
> >     or when I'll
> >      >>> be
> >      >>>>       >     able to do
> >      >>>>       >      >     that.
> >      >>>>       >      >
> >      >>>>       >      >     John
> >      >>>>       >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      > If not, I'll proceed to writing my own
> >     function
> >      >>>>      based on your
> >      >>>>       >      >     example.
> >      >>>>       >      >      > However, /car/ is such an excellent and
> >     widely used
> >      >>>>       >     package that the
> >      >>>>       >      >      > greatest benefit to mankind would
> >     probably accrue
> >      >>>>      if /car /was
> >      >>>>       >      >     upgraded
> >      >>>>       >      >      > with this feature sooner rather than
> later.
> >      >>>>       >      >      >
> >      >>>>       >      >      > Best,
> >      >>>>       >      >      >
> >      >>>>       >      >      > Juho
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      > ma 28. helmik. 2022 klo 17.08 John Fox
> >      >>>>      (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >>>>       >      >      > <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>) kirjoitti:
> >      >>>>       >      >      >
> >      >>>>       >      >      >     Dear Juho,
> >      >>>>       >      >      >
> >      >>>>       >      >      >     On 2022-02-28 2:06 a.m., Juho
> >     Kristian Ruohonen
> >      >>>>      wrote:
> >      >>>>       >      >      >      > Dear Professor Fox and other list
> >     members,
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > Profuse thanks for doing that
> >     detective work
> >      >>> for
> >      >>>>       >     me! I myself
> >      >>>>       >      >      >     thought
> >      >>>>       >      >      >      > the inflation factors reported by
> >      >>>>       >     check_collinearity() were
> >      >>>>       >      >      >     suspiciously
> >      >>>>       >      >      >      > high, but unlike you I lacked the
> >     expertise
> >      >>>>      to identify
> >      >>>>       >      >     what was
> >      >>>>       >      >      >     going on.
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > As for your suggested approach,
> >     have I
> >      >>>>      understood this
> >      >>>>       >      >     correctly:
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > Since there doesn't yet exist an
> >     R function
> >      >>>>      that will
> >      >>>>       >      >     calculate the
> >      >>>>       >      >      >      > (G)VIFS of multinomial models
> >     correctly, my
> >      >>> best
> >      >>>>       >     bet for
> >      >>>>       >      >     now is
> >      >>>>       >      >      >     just to
> >      >>>>       >      >      >      > ignore the fact that such models
> >     partition
> >      >>>>      the data
> >      >>>>       >     into C-1
> >      >>>>       >      >      >     subsets,
> >      >>>>       >      >      >      > and to calculate approximate
> >     GVIFs from the
> >      >>>>      entire
> >      >>>>       >     dataset at
> >      >>>>       >      >      >     once as if
> >      >>>>       >      >      >      > the response were continuous? And
> >     a simple
> >      >>>>      way to
> >      >>>>       >     do this
> >      >>>>       >      >     is to
> >      >>>>       >      >      >      > construct a fake continuous
> >     response, call
> >      >>>>       >      >     *lm(fakeresponse ~.)*,
> >      >>>>       >      >      >     and
> >      >>>>       >      >      >      > apply *car::vif()* on the result?
> >      >>>>       >      >      >
> >      >>>>       >      >      >     No, you misunderstand my suggestion,
> >     which
> >      >>>>      perhaps isn't
> >      >>>>       >      >     surprising
> >      >>>>       >      >      >     given the length of my message. What
> you
> >      >>>>      propose is what I
> >      >>>>       >      >     suggested as
> >      >>>>       >      >      >     a rough approximation *before* I
> >     confirmed that
> >      >>> my
> >      >>>>       >     guess of the
> >      >>>>       >      >      >     solution
> >      >>>>       >      >      >     was correct.
> >      >>>>       >      >      >
> >      >>>>       >      >      >     The R code that I sent yesterday
> >     showed how to
> >      >>>>      compute the
> >      >>>>       >      >     GVIF for a
> >      >>>>       >      >      >     multinomial regression model, and I
> >     suggested
> >      >>>>      that you
> >      >>>>       >     write
> >      >>>>       >      >     either a
> >      >>>>       >      >      >     script or a simple function to do
> >     that. Here's
> >      >>>>      a function
> >      >>>>       >      >     that will
> >      >>>>       >      >      >     work
> >      >>>>       >      >      >     for a model object that responds to
> >     vcov():
> >      >>>>       >      >      >
> >      >>>>       >      >      >     GVIF <- function(model, intercepts,
> >     term){
> >      >>>>       >      >      >         # model: regression model object
> >      >>>>       >      >      >         # intercepts: row/column
> >     positions of
> >      >>>>      intercepts
> >      >>>>       >     in the
> >      >>>>       >      >     coefficient
> >      >>>>       >      >      >     covariance matrix
> >      >>>>       >      >      >         # term: row/column positions of
> the
> >      >>>>      coefficients
> >      >>>>       >     for the
> >      >>>>       >      >     focal term
> >      >>>>       >      >      >         V <- vcov(model)
> >      >>>>       >      >      >         term <- colnames(V)[term]
> >      >>>>       >      >      >         V <- V[-intercepts, -intercepts]
> >      >>>>       >      >      >         V <- cov2cor(V)
> >      >>>>       >      >      >         term <- which(colnames(V) %in%
> term)
> >      >>>>       >      >      >         gvif <- det(V[term,
> >     term])*det(V[-term,
> >      >>>>      -term])/det(V)
> >      >>>>       >      >      >         c(GVIF=gvif,
> >      >>>>       >     "GVIF^(1/(2*p))"=gvif^(1/(2*length(term))))
> >      >>>>       >      >      >     }
> >      >>>>       >      >      >
> >      >>>>       >      >      >     and here's an application to the
> >     multinom()
> >      >>>>      example that I
> >      >>>>       >      >     showed you
> >      >>>>       >      >      >     yesterday:
> >      >>>>       >      >      >
> >      >>>>       >      >      >       > colnames(vcov(m)) # to get
> >     coefficient
> >      >>>>      positions
> >      >>>>       >      >      >        [1] "Labour:(Intercept)"
> >      >>>>       >       "Labour:age"
> >      >>>>       >      >      >
> >      >>>>       >      >      >        [3]
> "Labour:economic.cond.national"
> >      >>>>       >      >      >     "Labour:economic.cond.household"
> >      >>>>       >      >      >        [5] "Labour:Blair"
> >      >>>>       >       "Labour:Hague"
> >      >>>>       >      >      >
> >      >>>>       >      >      >        [7] "Labour:Kennedy"
> >      >>>>       >       "Labour:Europe"
> >      >>>>       >      >      >
> >      >>>>       >      >      >        [9] "Labour:political.knowledge"
> >      >>>>       >      >       "Labour:gendermale"
> >      >>>>       >      >      >
> >      >>>>       >      >      >     [11] "Liberal Democrat:(Intercept)"
> >      >>>>        "Liberal
> >      >>>>       >      >     Democrat:age"
> >      >>>>       >      >      >
> >      >>>>       >      >      >     [13] "Liberal
> >     Democrat:economic.cond.national"
> >      >>>>      "Liberal
> >      >>>>       >      >      >     Democrat:economic.cond.household"
> >      >>>>       >      >      >     [15] "Liberal Democrat:Blair"
> >      >>>>        "Liberal
> >      >>>>       >      >      >     Democrat:Hague"
> >      >>>>       >      >      >
> >      >>>>       >      >      >     [17] "Liberal Democrat:Kennedy"
> >      >>>>        "Liberal
> >      >>>>       >      >      >     Democrat:Europe"
> >      >>>>       >      >      >     [19] "Liberal
> >     Democrat:political.knowledge"
> >      >>>>        "Liberal
> >      >>>>       >      >      >     Democrat:gendermale"
> >      >>>>       >      >      >
> >      >>>>       >      >      >       > GVIF(m, intercepts=c(1, 11),
> >     term=c(2, 12))
> >      >>>>      # GVIF
> >      >>>>       >     for age
> >      >>>>       >      >      >                 GVIF GVIF^(1/(2*p))
> >      >>>>       >      >      >             1.046232       1.011363
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >     Finally, here's what you get for a
> >     linear model
> >      >>>>      with
> >      >>>>       >     the same RHS
> >      >>>>       >      >      >     (where
> >      >>>>       >      >      >     the sqrt(VIF) should be a rough
> >     approximation to
> >      >>>>       >     GVIF^(1/4)
> >      >>>>       >      >     reported by
> >      >>>>       >      >      >     my GVIF() function):
> >      >>>>       >      >      >
> >      >>>>       >      >      >       > m.lm <- lm(as.numeric(vote) ~ .
> >     - vote1,
> >      >>>>      data=BEPS)
> >      >>>>       >      >      >       > sqrt(car::vif(m.lm))
> >      >>>>       >      >      >                           age
> >      >>> economic.cond.national
> >      >>>>       >      >      >     economic.cond.household
> >      >>>>       >      >      >                         Blair
> >      >>>>       >      >      >                      1.006508
> >      >>> 1.124132
> >      >>>>       >      >      >     1.075656
> >      >>>>       >      >      >                      1.118441
> >      >>>>       >      >      >                         Hague
> >      >>>   Kennedy
> >      >>>>       >      >      >     Europe
> >      >>>>       >      >      >           political.knowledge
> >      >>>>       >      >      >                      1.066799
> >      >>> 1.015532
> >      >>>>       >      >      >     1.101741
> >      >>>>       >      >      >                      1.028546
> >      >>>>       >      >      >                        gender
> >      >>>>       >      >      >                      1.017386
> >      >>>>       >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >      >     John
> >      >>>>       >      >      >
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > Best,
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > Juho
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      > ma 28. helmik. 2022 klo 2.23 John
> Fox
> >      >>>>       >     (jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >>>>       >      >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>
> >      >>>>       >      >      >      > <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>>) kirjoitti:
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     Dear Juho,
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     I've now had a chance to
> >     think about this
> >      >>>>       >     problem some
> >      >>>>       >      >     more,
> >      >>>>       >      >      >     and I
> >      >>>>       >      >      >      >     believe that the approach I
> >     suggested is
> >      >>>>      correct. I
> >      >>>>       >      >     also had an
> >      >>>>       >      >      >      >     opportunity to talk the
> >     problem over a
> >      >>>>      bit with
> >      >>>>       >     Georges
> >      >>>>       >      >      >     Monette, who
> >      >>>>       >      >      >      >     coauthored the paper that
> >     introduced
> >      >>>>       >     generalized variance
> >      >>>>       >      >      >     inflation
> >      >>>>       >      >      >      >     factors (GVIFs). On the other
> >     hand, the
> >      >>>>      results
> >      >>>>       >      >     produced by
> >      >>>>       >      >      >      >
> >       performance::check_collinearity() for
> >      >>>>       >     multinomial logit
> >      >>>>       >      >      >     models don't
> >      >>>>       >      >      >      >     seem to be correct (see
> below).
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     Here's an example, using the
> >      >>>>      nnet::multinom()
> >      >>>>       >     function
> >      >>>>       >      >     to fit a
> >      >>>>       >      >      >      >     multinomial logit model, with
> >     alternative
> >      >>>>       >      >     parametrizations of the
> >      >>>>       >      >      >      >     LHS of
> >      >>>>       >      >      >      >     the model:
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > library(nnet) # for
> >     multinom()
> >      >>>>       >      >      >      >       > library(carData) # for
> >     BEPS data set
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > # alternative ordering of
> the
> >      >>>>      response levels:
> >      >>>>       >      >      >      >       > BEPS$vote1 <-
> >     factor(BEPS$vote,
> >      >>>>       >     levels=c("Labour",
> >      >>>>       >      >     "Liberal
> >      >>>>       >      >      >      >     Democrat", "Conservative"))
> >      >>>>       >      >      >      >       > levels(BEPS$vote)
> >      >>>>       >      >      >      >     [1] "Conservative"
>  "Labour"
> >      >>>>        "Liberal
> >      >>>>       >      >     Democrat"
> >      >>>>       >      >      >      >       > levels(BEPS$vote1)
> >      >>>>       >      >      >      >     [1] "Labour"
> >       "Liberal Democrat"
> >      >>>>       >     "Conservative"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > m <- multinom(vote ~ . -
> >     vote1,
> >      >>>>      data=BEPS)
> >      >>>>       >      >      >      >     # weights:  33 (20 variable)
> >      >>>>       >      >      >      >     initial  value 1675.383740
> >      >>>>       >      >      >      >     iter  10 value 1345.935273
> >      >>>>       >      >      >      >     iter  20 value 1150.956807
> >      >>>>       >      >      >      >     iter  30 value 1141.921662
> >      >>>>       >      >      >      >     iter  30 value 1141.921661
> >      >>>>       >      >      >      >     iter  30 value 1141.921661
> >      >>>>       >      >      >      >     final  value 1141.921661
> >      >>>>       >      >      >      >     converged
> >      >>>>       >      >      >      >       > m1 <- multinom(vote1 ~ .
> >     - vote,
> >      >>>>      data=BEPS)
> >      >>>>       >      >      >      >     # weights:  33 (20 variable)
> >      >>>>       >      >      >      >     initial  value 1675.383740
> >      >>>>       >      >      >      >     iter  10 value 1280.439304
> >      >>>>       >      >      >      >     iter  20 value 1165.513772
> >      >>>>       >      >      >      >     final  value 1141.921662
> >      >>>>       >      >      >      >     converged
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > rbind(coef(m), coef(m1))
> >     # compare
> >      >>>>      coefficients
> >      >>>>       >      >      >      >                        (Intercept)
> >      >>> age
> >      >>>>       >      >      >     economic.cond.national
> >      >>>>       >      >      >      >     economic.cond.household
> >      >>>>       >      >      >      >     Labour             0.9515214
> >     -0.021913989
> >      >>>>       >      >     0.5575707
> >      >>>>       >      >      >      >            0.15839096
> >      >>>>       >      >      >      >     Liberal Democrat   1.4119306
> >     -0.016810735
> >      >>>>       >      >     0.1810761
> >      >>>>       >      >      >      >           -0.01196664
> >      >>>>       >      >      >      >     Liberal Democrat   0.4604567
> >     0.005102666
> >      >>>>       >      >       -0.3764928
> >      >>>>       >      >      >      >           -0.17036682
> >      >>>>       >      >      >      >     Conservative      -0.9514466
> >     0.021912305
> >      >>>>       >      >       -0.5575644
> >      >>>>       >      >      >      >           -0.15838744
> >      >>>>       >      >      >      >
> >       Blair       Hague
> >      >>>>       >     Kennedy
> >      >>>>       >      >          Europe
> >      >>>>       >      >      >      >     political.knowledge
> >      >>>>       >      >      >      >     Labour            0.8371764
> >     -0.90775585
> >      >>>>      0.2513436
> >      >>>>       >      >     -0.22781308
> >      >>>>       >      >      >      >     -0.5370612
> >      >>>>       >      >      >      >     Liberal Democrat  0.2937331
> >     -0.82217625
> >      >>>>      0.6710567
> >      >>>>       >      >     -0.20004624
> >      >>>>       >      >      >      >     -0.2034605
> >      >>>>       >      >      >      >     Liberal Democrat -0.5434408
> >     0.08559455
> >      >>>>      0.4197027
> >      >>>>       >      >     0.02776465
> >      >>>>       >      >      >      >     0.3336068
> >      >>>>       >      >      >      >     Conservative     -0.8371670
> >     0.90778068
> >      >>>>      -0.2513735
> >      >>>>       >      >     0.22781092
> >      >>>>       >      >      >      >     0.5370545
> >      >>>>       >      >      >      >                         gendermale
> >      >>>>       >      >      >      >     Labour            0.13765774
> >      >>>>       >      >      >      >     Liberal Democrat  0.12640823
> >      >>>>       >      >      >      >     Liberal Democrat -0.01125898
> >      >>>>       >      >      >      >     Conservative     -0.13764849
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > c(logLik(m), logLik(m1))
> >     # same fit
> >      >>>>      to the data
> >      >>>>       >      >      >      >     [1] -1141.922 -1141.922
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > # covariance matrices for
> >      >>> coefficients:
> >      >>>>       >      >      >      >       > V <- vcov(m)
> >      >>>>       >      >      >      >       > V1 <- vcov(m1)
> >      >>>>       >      >      >      >       > cbind(colnames(V),
> >     colnames(V1)) #
> >      >>>>      compare
> >      >>>>       >      >      >      >             [,1]
> >      >>>>       >         [,2]
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >        [1,] "Labour:(Intercept)"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:(Intercept)"
> >      >>>>       >      >      >      >        [2,] "Labour:age"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:age"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >        [3,]
> >     "Labour:economic.cond.national"
> >      >>>>       >      >     "Liberal
> >      >>>>       >      >      >      >
>  Democrat:economic.cond.national"
> >      >>>>       >      >      >      >        [4,]
> >     "Labour:economic.cond.household"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >
>  Democrat:economic.cond.household"
> >      >>>>       >      >      >      >        [5,] "Labour:Blair"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:Blair"
> >      >>>>       >      >      >      >        [6,] "Labour:Hague"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:Hague"
> >      >>>>       >      >      >      >        [7,] "Labour:Kennedy"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:Kennedy"
> >      >>>>       >      >      >      >        [8,] "Labour:Europe"
> >      >>>>       >      >     "Liberal
> >      >>>>       >      >      >      >     Democrat:Europe"
> >      >>>>       >      >      >      >        [9,]
> >     "Labour:political.knowledge"
> >      >>>>       >      >       "Liberal
> >      >>>>       >      >      >      >     Democrat:political.knowledge"
> >      >>>>       >      >      >      >     [10,] "Labour:gendermale"
> >      >>>>       >        "Liberal
> >      >>>>       >      >      >      >     Democrat:gendermale"
> >      >>>>       >      >      >      >     [11,] "Liberal
> >     Democrat:(Intercept)"
> >      >>>>       >      >      >      >     "Conservative:(Intercept)"
> >      >>>>       >      >      >      >     [12,] "Liberal Democrat:age"
> >      >>>>       >      >      >       "Conservative:age"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     [13,] "Liberal
> >      >>>>      Democrat:economic.cond.national"
> >      >>>>       >      >      >      >
> >       "Conservative:economic.cond.national"
> >      >>>>       >      >      >      >     [14,] "Liberal
> >      >>>>      Democrat:economic.cond.household"
> >      >>>>       >      >      >      >
> >       "Conservative:economic.cond.household"
> >      >>>>       >      >      >      >     [15,] "Liberal Democrat:Blair"
> >      >>>>       >      >      >       "Conservative:Blair"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     [16,] "Liberal Democrat:Hague"
> >      >>>>       >      >      >       "Conservative:Hague"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     [17,] "Liberal
> Democrat:Kennedy"
> >      >>>>       >      >      >       "Conservative:Kennedy"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     [18,] "Liberal
> Democrat:Europe"
> >      >>>>       >      >      >     "Conservative:Europe"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     [19,] "Liberal
> >      >>> Democrat:political.knowledge"
> >      >>>>       >      >      >      >
> >       "Conservative:political.knowledge"
> >      >>>>       >      >      >      >     [20,] "Liberal
> >     Democrat:gendermale"
> >      >>>>       >      >      >      >     "Conservative:gendermale"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > int <- c(1, 11) # remove
> >     intercepts
> >      >>>>       >      >      >      >       > colnames(V)[int]
> >      >>>>       >      >      >      >     [1] "Labour:(Intercept)"
> >      >>>   "Liberal
> >      >>>>       >      >     Democrat:(Intercept)"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > colnames(V1)[int]
> >      >>>>       >      >      >      >     [1] "Liberal
> >     Democrat:(Intercept)"
> >      >>>>       >      >     "Conservative:(Intercept)"
> >      >>>>       >      >      >      >       > V <- V[-int, -int]
> >      >>>>       >      >      >      >       > V1 <- V1[-int, -int]
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > age <- c(1, 10) # locate
> age
> >      >>>>      coefficients
> >      >>>>       >      >      >      >       > colnames(V)[age]
> >      >>>>       >      >      >      >     [1] "Labour:age"
> >       "Liberal
> >      >>>>      Democrat:age"
> >      >>>>       >      >      >      >       > colnames(V1)[age]
> >      >>>>       >      >      >      >     [1] "Liberal Democrat:age"
> >      >>>>      "Conservative:age"
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > V <- cov2cor(V) # compute
> >     coefficient
> >      >>>>       >     correlations
> >      >>>>       >      >      >      >       > V1 <- cov2cor(V1)
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > # compare GVIFs:
> >      >>>>       >      >      >      >       > c(det(V[age,
> >     age])*det(V[-age,
> >      >>>>      -age])/det(V),
> >      >>>>       >      >      >      >     +   det(V1[age,
> >     age])*det(V1[-age,
> >      >>>>      -age])/det(V1))
> >      >>>>       >      >      >      >     [1] 1.046232 1.046229
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     For curiosity, I applied
> >     car::vif() and
> >      >>>>       >      >      >      >
> >       performance::check_collinearity() to
> >      >>> these
> >      >>>>       >     models to
> >      >>>>       >      >     see what
> >      >>>>       >      >      >     they
> >      >>>>       >      >      >      >     would
> >      >>>>       >      >      >      >     do. Both returned the wrong
> >     answer. vif()
> >      >>>>       >     produced a
> >      >>>>       >      >     warning, but
> >      >>>>       >      >      >      >     check_collinearity() didn't:
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > car::vif(m1)
> >      >>>>       >      >      >      >                           age
> >      >>>>      economic.cond.national
> >      >>>>       >      >      >      >     economic.cond.household
> >      >>>>       >      >      >      >                     15.461045
> >      >>>>        22.137772
> >      >>>>       >      >      >      >       16.693877
> >      >>>>       >      >      >      >                         Blair
> >      >>>>          Hague
> >      >>>>       >      >      >      >       Kennedy
> >      >>>>       >      >      >      >                     14.681562
> >      >>>>      7.483039
> >      >>>>       >      >      >      >       15.812067
> >      >>>>       >      >      >      >                        Europe
> >      >>>>        political.knowledge
> >      >>>>       >      >      >      >     gender
> >      >>>>       >      >      >      >                      6.502119
> >      >>>>      4.219507
> >      >>>>       >      >      >      >     2.313885
> >      >>>>       >      >      >      >     Warning message:
> >      >>>>       >      >      >      >     In vif.default(m1) : No
> >     intercept: vifs
> >      >>>>      may not be
> >      >>>>       >      >     sensible.
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       >
> >     performance::check_collinearity(m)
> >      >>>>       >      >      >      >     # Check for Multicollinearity
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     Low Correlation
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >                           Term
> VIF
> >      >>> Increased SE
> >      >>>>       >     Tolerance
> >      >>>>       >      >      >      >                            age
> 1.72
> >      >>>>        1.31
> >      >>>>       >        0.58
> >      >>>>       >      >      >      >         economic.cond.national
> 1.85
> >      >>>>        1.36
> >      >>>>       >        0.54
> >      >>>>       >      >      >      >        economic.cond.household
> 1.86
> >      >>>>        1.37
> >      >>>>       >        0.54
> >      >>>>       >      >      >      >                          Blair
> 1.63
> >      >>>>        1.28
> >      >>>>       >        0.61
> >      >>>>       >      >      >      >                          Hague
> 1.94
> >      >>>>        1.39
> >      >>>>       >        0.52
> >      >>>>       >      >      >      >                        Kennedy
> 1.70
> >      >>>>        1.30
> >      >>>>       >        0.59
> >      >>>>       >      >      >      >                         Europe
> 2.01
> >      >>>>        1.42
> >      >>>>       >        0.50
> >      >>>>       >      >      >      >            political.knowledge
> 1.94
> >      >>>>        1.39
> >      >>>>       >        0.52
> >      >>>>       >      >      >      >                         gender
> 1.78
> >      >>>>        1.33
> >      >>>>       >        0.56
> >      >>>>       >      >      >      >       >
> >     performance::check_collinearity(m1)
> >      >>>>       >      >      >      >     # Check for Multicollinearity
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     Low Correlation
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >                           Term
> VIF
> >      >>> Increased SE
> >      >>>>       >     Tolerance
> >      >>>>       >      >      >      >                            age
> 1.19
> >      >>>>        1.09
> >      >>>>       >        0.84
> >      >>>>       >      >      >      >         economic.cond.national
> 1.42
> >      >>>>        1.19
> >      >>>>       >        0.70
> >      >>>>       >      >      >      >        economic.cond.household
> 1.32
> >      >>>>        1.15
> >      >>>>       >        0.76
> >      >>>>       >      >      >      >                          Blair
> 1.50
> >      >>>>        1.22
> >      >>>>       >        0.67
> >      >>>>       >      >      >      >                          Hague
> 1.30
> >      >>>>        1.14
> >      >>>>       >        0.77
> >      >>>>       >      >      >      >                        Kennedy
> 1.19
> >      >>>>        1.09
> >      >>>>       >        0.84
> >      >>>>       >      >      >      >                         Europe
> 1.34
> >      >>>>        1.16
> >      >>>>       >        0.75
> >      >>>>       >      >      >      >            political.knowledge
> 1.30
> >      >>>>        1.14
> >      >>>>       >        0.77
> >      >>>>       >      >      >      >                         gender
> 1.23
> >      >>>>        1.11
> >      >>>>       >        0.81
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     I looked at the code for
> >     vif() and
> >      >>>>       >     check_collinearity() to
> >      >>>>       >      >      >     see where
> >      >>>>       >      >      >      >     they went wrong. Both failed
> >     to handle
> >      >>>>      the two
> >      >>>>       >      >     intercepts in
> >      >>>>       >      >      >     the model
> >      >>>>       >      >      >      >     correctly -- vif() thought
> >     there was no
> >      >>>>       >     intercept and
> >      >>>>       >      >      >      >     check_collinearity() just
> >     removed the
> >      >>> first
> >      >>>>       >     intercept
> >      >>>>       >      >     but not the
> >      >>>>       >      >      >      >     second.
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     In examining the code for
> >      >>>>      check_collinearity(), I
> >      >>>>       >      >     discovered a
> >      >>>>       >      >      >      >     couple of
> >      >>>>       >      >      >      >     additional disconcerting
> >     facts. First,
> >      >>>>      part of the
> >      >>>>       >      >     code seems
> >      >>>>       >      >      >     to be
> >      >>>>       >      >      >      >     copied from vif.default().
> >     Second, as a
> >      >>>>       >     consequence,
> >      >>>>       >      >      >      >     check_collinearity() actually
> >     computes
> >      >>>>      GVIFs rather
> >      >>>>       >      >     than VIFs
> >      >>>>       >      >      >     (and
> >      >>>>       >      >      >      >     doesn't reference either the
> >     Fox and
> >      >>>>      Monette paper
> >      >>>>       >      >      >     introducing GVIFs or
> >      >>>>       >      >      >      >     the car package) but doesn't
> >     seem to
> >      >>>>      understand
> >      >>>>       >     that, and,
> >      >>>>       >      >      >     for example,
> >      >>>>       >      >      >      >     takes the squareroot of the
> GVIF
> >      >>>>      (reported in the
> >      >>>>       >      >     column marked
> >      >>>>       >      >      >      >     "Increased SE") rather than
> >     the 2p root
> >      >>>>      (when there
> >      >>>>       >      >     are p > 1
> >      >>>>       >      >      >      >     coefficients in a term).
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     Here's the relevant code from
> >     the two
> >      >>>>      functions
> >      >>>>       >     (where
> >      >>>>       >      >     . . .
> >      >>>>       >      >      >     denotes
> >      >>>>       >      >      >      >     elided lines) -- the default
> >     method for
> >      >>>>      vif() and
> >      >>>>       >      >      >      >     .check_collinearity(),
> >      >>>>       >      >      >      >     which is called by
> >      >>>>      check_collinearity.default():
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       > car:::vif.default
> >      >>>>       >      >      >      >     function (mod, ...)
> >      >>>>       >      >      >      >     {
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >           v <- vcov(mod)
> >      >>>>       >      >      >      >           assign <-
> >     attr(model.matrix(mod),
> >      >>>>      "assign")
> >      >>>>       >      >      >      >           if
> >     (names(coefficients(mod)[1]) ==
> >      >>>>       >     "(Intercept)") {
> >      >>>>       >      >      >      >               v <- v[-1, -1]
> >      >>>>       >      >      >      >               assign <- assign[-1]
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >           else warning("No
> >     intercept: vifs
> >      >>>>      may not be
> >      >>>>       >      >     sensible.")
> >      >>>>       >      >      >      >           terms <-
> labels(terms(mod))
> >      >>>>       >      >      >      >           n.terms <- length(terms)
> >      >>>>       >      >      >      >           if (n.terms < 2)
> >      >>>>       >      >      >      >               stop("model
> >     contains fewer
> >      >>>>      than 2 terms")
> >      >>>>       >      >      >      >           R <- cov2cor(v)
> >      >>>>       >      >      >      >           detR <- det(R)
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >           for (term in 1:n.terms)
> {
> >      >>>>       >      >      >      >               subs <-
> >     which(assign == term)
> >      >>>>       >      >      >      >               result[term, 1] <-
> >      >>>>      det(as.matrix(R[subs,
> >      >>>>       >      >     subs])) *
> >      >>>>       >      >      >      >     det(as.matrix(R[-subs,
> >      >>>>       >      >      >      >                   -subs]))/detR
> >      >>>>       >      >      >      >               result[term, 2] <-
> >     length(subs)
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >     }
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >       >
> >     performance:::.check_collinearity
> >      >>>>       >      >      >      >     function (x, component,
> >     verbose = TRUE)
> >      >>>>       >      >      >      >     {
> >      >>>>       >      >      >      >           v <-
> insight::get_varcov(x,
> >      >>>>      component =
> >      >>>>       >     component,
> >      >>>>       >      >      >     verbose =
> >      >>>>       >      >      >      >     FALSE)
> >      >>>>       >      >      >      >           assign <-
> >     .term_assignments(x,
> >      >>>>      component,
> >      >>>>       >     verbose =
> >      >>>>       >      >      >     verbose)
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >           if
> >     (insight::has_intercept(x)) {
> >      >>>>       >      >      >      >               v <- v[-1, -1]
> >      >>>>       >      >      >      >               assign <- assign[-1]
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >           else {
> >      >>>>       >      >      >      >               if
> (isTRUE(verbose)) {
> >      >>>>       >      >      >      >                   warning("Model
> >     has no
> >      >>>>      intercept. VIFs
> >      >>>>       >      >     may not be
> >      >>>>       >      >      >      >     sensible.",
> >      >>>>       >      >      >      >                       call. =
> FALSE)
> >      >>>>       >      >      >      >               }
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >               . . .
> >      >>>>       >      >      >      >               terms <-
> >      >>>>       >     labels(stats::terms(f[[component]]))
> >      >>>>       >      >      >      >               . . .
> >      >>>>       >      >      >      >           n.terms <- length(terms)
> >      >>>>       >      >      >      >           if (n.terms < 2) {
> >      >>>>       >      >      >      >               if
> (isTRUE(verbose)) {
> >      >>>>       >      >      >      >
> >      >>>>       >       warning(insight::format_message(sprintf("Not
> >      >>>>       >      >      >     enough model
> >      >>>>       >      >      >      >     terms in the %s part of the
> >     model to
> >      >>>>      check for
> >      >>>>       >      >      >     multicollinearity.",
> >      >>>>       >      >      >      >
> >       component)), call. =
> >      >>>>      FALSE)
> >      >>>>       >      >      >      >               }
> >      >>>>       >      >      >      >               return(NULL)
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >           R <- stats::cov2cor(v)
> >      >>>>       >      >      >      >           detR <- det(R)
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >           for (term in 1:n.terms)
> {
> >      >>>>       >      >      >      >               subs <-
> >     which(assign == term)
> >      >>>>       >      >      >      >                   . . .
> >      >>>>       >      >      >      >                   result <-
> c(result,
> >      >>>>       >      >     det(as.matrix(R[subs, subs])) *
> >      >>>>       >      >      >      >
> >       det(as.matrix(R[-subs,
> >      >>>>       >     -subs]))/detR)
> >      >>>>       >      >      >      >                   . . .
> >      >>>>       >      >      >      >           }
> >      >>>>       >      >      >      >           . . .
> >      >>>>       >      >      >      >     }
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     --------- snip -----------
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     So, the upshot of all this is
> >     that you
> >      >>>>      should
> >      >>>>       >     be able
> >      >>>>       >      >     to do
> >      >>>>       >      >      >     what you
> >      >>>>       >      >      >      >     want, but not with either
> >     car::vif() or
> >      >>>>       >      >      >      >
> >       performance::check_collinearity().
> >      >>>>      Instead, either
> >      >>>>       >      >     write your own
> >      >>>>       >      >      >      >     function or do the
> >     computations in a
> >      >>> script.
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     There's also a lesson here
> >     about S3
> >      >>> default
> >      >>>>       >     methods:
> >      >>>>       >      >     The fact
> >      >>>>       >      >      >     that a
> >      >>>>       >      >      >      >     default method returns a
> >     result rather
> >      >>> than
> >      >>>>       >     throwing
> >      >>>>       >      >     an error
> >      >>>>       >      >      >     or a
> >      >>>>       >      >      >      >     warning doesn't mean that the
> >     result is
> >      >>> the
> >      >>>>       >     right answer.
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     I hope this helps,
> >      >>>>       >      >      >      >        John
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >      >     On 2022-02-26 3:45 p.m., Juho
> >     Kristian
> >      >>>>      Ruohonen
> >      >>>>       >     wrote:
> >      >>>>       >      >      >      >      > Dear John W,
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      > Thank you very much for
> >     the tip-off!
> >      >>>>       >     Apologies for not
> >      >>>>       >      >      >     responding
> >      >>>>       >      >      >      >     earlier
> >      >>>>       >      >      >      >      > (gmail apparently decided
> >     to direct
> >      >>>>      your email
> >      >>>>       >      >     right into the
> >      >>>>       >      >      >      >     junk folder).
> >      >>>>       >      >      >      >      > I am very pleased to note
> >     that the
> >      >>>>      package you
> >      >>>>       >      >     mention does
> >      >>>>       >      >      >      >     indeed work
> >      >>>>       >      >      >      >      > with *brms* multinomial
> >     models!
> >      >>>>      Thanks again!
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      > Best,
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      > Juho
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      > pe 25. helmik. 2022 klo
> >     19.23 John
> >      >>>>      Willoughby
> >      >>>>       >      >      >      >     (johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com
> >>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>>
> >      >>>>       >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com
> >>>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>>>
> >      >>>>       >      >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com
> >>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>>
> >      >>>>       >      >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>
> >      >>>>      <mailto:johnwillec at gmail.com <mailto:johnwillec at gmail.com
> >>>
> >      >>>>       >     <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>
> >      >>>>      <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com> <mailto:johnwillec at gmail.com
> >     <mailto:johnwillec at gmail.com>>>>>>)
> >      >>>>       >      >      >      >      > kirjoitti:
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      >> Have you tried the
> >      >>> check_collinearity()
> >      >>>>       >     function
> >      >>>>       >      >     in the
> >      >>>>       >      >      >     performance
> >      >>>>       >      >      >      >      >> package? It's supposed to
> >     work on
> >      >>> brms
> >      >>>>       >     models, but
> >      >>>>       >      >     whether it
> >      >>>>       >      >      >      >     will work on
> >      >>>>       >      >      >      >      >> a multinomial model I
> >     don't know.
> >      >>>>      It works
> >      >>>>       >     well
> >      >>>>       >      >     on mixed
> >      >>>>       >      >      >     models
> >      >>>>       >      >      >      >     generated
> >      >>>>       >      >      >      >      >> by glmmTMB().
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >> John Willoughby
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >> On Fri, Feb 25, 2022 at
> >     3:01 AM
> >      >>>>       >      >      >      >
> >      >>>>        <r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >>>>       >      >      >
> >      >>>>        <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >>>>       >      >      >
> >      >>>>        <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>>>
> >      >>>>       >      >      >      >      >> wrote:
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >>> Send R-sig-mixed-models
> >     mailing list
> >      >>>>       >     submissions to
> >      >>>>       >      >      >      >      >>>
> >     r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> To subscribe or
> >     unsubscribe via the
> >      >>>>      World Wide
> >      >>>>       >      >     Web, visit
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>>
> >      >>>>       >      >      >      >      >>> or, via email, send a
> >     message with
> >      >>>>      subject or
> >      >>>>       >      >     body 'help' to
> >      >>>>       >      >      >      >      >>>
> >      >>>> r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >>>>       >      >      >
> >      >>>>        <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>
> >      >>>>       >      >      >
> >      >>>>        <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-request at r-project.org
> >     <mailto:r-sig-mixed-models-request at r-project.org>>>>>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> You can reach the person
> >     managing
> >      >>>>      the list at
> >      >>>>       >      >      >      >      >>>
> >      >>>> r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >      >>>>        <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>
> >      >>>>       >      >
> >       <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models-owner at r-project.org
> >     <mailto:r-sig-mixed-models-owner at r-project.org>>>>>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> When replying, please
> >     edit your
> >      >>> Subject
> >      >>>>       >     line so it is
> >      >>>>       >      >      >     more specific
> >      >>>>       >      >      >      >      >>> than "Re: Contents of
> >      >>>>      R-sig-mixed-models
> >      >>>>       >     digest..."
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Today's Topics:
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>>     1. Collinearity
> >     diagnostics for
> >      >>>>      (mixed)
> >      >>>>       >      >     multinomial
> >      >>>>       >      >      >     models
> >      >>>>       >      >      >      >      >>>        (Juho Kristian
> >     Ruohonen)
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>
> >      >>>
> >
>  ----------------------------------------------------------------------
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Message: 1
> >      >>>>       >      >      >      >      >>> Date: Fri, 25 Feb 2022
> >     10:23:25
> >      >>> +0200
> >      >>>>       >      >      >      >      >>> From: Juho Kristian
> Ruohonen
> >      >>>>       >      >      >     <juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >>>>       >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>
> >      >>>>       >      >      >
> >       <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >>>>       >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >>>>       >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>
> >      >>>>       >      >      >
> >       <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>
> >      >>>>       >      >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>
> >      >>>>       >     <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>
> >      >>>>      <mailto:juho.kristian.ruohonen at gmail.com
> >     <mailto:juho.kristian.ruohonen at gmail.com>>>>>>>
> >      >>>>       >      >      >      >      >>> To: John Fox
> >     <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>
> >      >>>>       >      >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>
> >      >>>>       >      >     <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca> <mailto:jfox at mcmaster.ca
> >     <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>
> >      >>>>       >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >      >>>>      <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
> >     <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>>>>>>
> >      >>>>       >      >      >      >      >>> Cc:
> >      >>>>      "r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>>"
> >      >>>>       >      >      >      >      >>>
> >      >>>>      <r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>>>>>>>
> >      >>>>       >      >      >      >      >>> Subject: [R-sig-ME]
> >     Collinearity
> >      >>>>       >     diagnostics for
> >      >>>>       >      >     (mixed)
> >      >>>>       >      >      >      >     multinomial
> >      >>>>       >      >      >      >      >>>          models
> >      >>>>       >      >      >      >      >>> Message-ID:
> >      >>>>       >      >      >      >      >>>          <
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >>>>      <mailto:
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>>
> >      >>>>       >
> >      >>>>        <mailto:
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>>>
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>        <mailto:
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>>>>
> >      >>>>       >      >      >
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>        <mailto:
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>        <mailto:
> >      >>>
> >     CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >>
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>
> >     <mailto:
> CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> <mailto:CAG_dBVfZr1-P7Q3kbE8TGPm-_2sJixdGCHCtWM9Q9PEnd8ftZw at mail.gmail.com
> >
> >      >>>>>>>>>
> >      >>>>       >      >      >      >      >>> Content-Type: text/plain;
> >      >>>>      charset="utf-8"
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Dear John (and anyone
> else
> >      >>> qualified to
> >      >>>>       >     comment),
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> I fit lots of
> mixed-effects
> >      >>> multinomial
> >      >>>>       >     models in my
> >      >>>>       >      >      >     research,
> >      >>>>       >      >      >      >     and I
> >      >>>>       >      >      >      >      >> would
> >      >>>>       >      >      >      >      >>> like to see some
> >     (multi)collinearity
> >      >>>>       >     diagnostics
> >      >>>>       >      >     on the
> >      >>>>       >      >      >     fixed
> >      >>>>       >      >      >      >     effects, of
> >      >>>>       >      >      >      >      >>> which there are over 30.
> >     My models
> >      >>>>      are fit
> >      >>>>       >     using the
> >      >>>>       >      >      >     Bayesian
> >      >>>>       >      >      >      >     *brms*
> >      >>>>       >      >      >      >      >>> package because I know
> of no
> >      >>>>      frequentist
> >      >>>>       >     packages
> >      >>>>       >      >     with
> >      >>>>       >      >      >      >     multinomial GLMM
> >      >>>>       >      >      >      >      >>> compatibility.
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> With continuous or
> >     dichotomous
> >      >>>>      outcomes,
> >      >>>>       >     my go-to
> >      >>>>       >      >      >     function for
> >      >>>>       >      >      >      >      >> calculating
> >      >>>>       >      >      >      >      >>> multicollinearity
> >     diagnostics is of
> >      >>>>      course
> >      >>>>       >      >     *vif()* from
> >      >>>>       >      >      >     the *car*
> >      >>>>       >      >      >      >      >> package.
> >      >>>>       >      >      >      >      >>> As expected, however,
> >     this function
> >      >>>>      does not
> >      >>>>       >      >     report sensible
> >      >>>>       >      >      >      >     diagnostics
> >      >>>>       >      >      >      >      >>> for multinomial models
> >     -- not even
> >      >>> for
> >      >>>>       >     standard
> >      >>>>       >      >     ones fit
> >      >>>>       >      >      >     by the
> >      >>>>       >      >      >      >     *nnet*
> >      >>>>       >      >      >      >      >>> package's *multinom()*
> >     function.
> >      >>>>      The reason, I
> >      >>>>       >      >     presume, is
> >      >>>>       >      >      >      >     because a
> >      >>>>       >      >      >      >      >>> multinomial model is not
> >     really one
> >      >>>>      but C-1
> >      >>>>       >      >     regression
> >      >>>>       >      >      >     models
> >      >>>>       >      >      >      >     (where C
> >      >>>>       >      >      >      >      >> is
> >      >>>>       >      >      >      >      >>> the number of response
> >     categories)
> >      >>>>      and the
> >      >>>>       >     *vif()*
> >      >>>>       >      >      >     function is not
> >      >>>>       >      >      >      >      >> designed
> >      >>>>       >      >      >      >      >>> to deal with this
> scenario.
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Therefore, in order to
> >     obtain
> >      >>>>      meaningful
> >      >>>>       >     collinearity
> >      >>>>       >      >      >     metrics,
> >      >>>>       >      >      >      >     my present
> >      >>>>       >      >      >      >      >>> plan is to write a
> >     simple helper
> >      >>>>      function
> >      >>>>       >     that uses
> >      >>>>       >      >      >     *vif() *to
> >      >>>>       >      >      >      >     calculate
> >      >>>>       >      >      >      >      >>> and present
> >     (generalized) variance
> >      >>>>      inflation
> >      >>>>       >      >     metrics for
> >      >>>>       >      >      >     the C-1
> >      >>>>       >      >      >      >      >>> sub-datasets to which
> >     the C-1
> >      >>> component
> >      >>>>       >     binomial
> >      >>>>       >      >     models
> >      >>>>       >      >      >     of the
> >      >>>>       >      >      >      >     overall
> >      >>>>       >      >      >      >      >>> multinomial model are
> >     fit. In other
> >      >>>>      words, it
> >      >>>>       >      >     will partition
> >      >>>>       >      >      >      >     the data
> >      >>>>       >      >      >      >      >> into
> >      >>>>       >      >      >      >      >>> those C-1 subsets, and
> >     then apply
> >      >>>>      *vif()*
> >      >>>>       >     to as
> >      >>>>       >      >     many linear
> >      >>>>       >      >      >      >     regressions
> >      >>>>       >      >      >      >      >>> using a made-up
> >     continuous response
> >      >>> and
> >      >>>>       >     the fixed
> >      >>>>       >      >     effects of
> >      >>>>       >      >      >      >     interest.
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Does this seem like a
> >     sensible
> >      >>>>      approach?
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Best,
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>> Juho
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>>
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >>          [[alternative
> >     HTML version
> >      >>>>      deleted]]
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >>
> >      >>>>      _______________________________________________
> >      >>>>       >      >      >      >      >>
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>>> mailing list
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>>
> >      >>>>       >      >      >      >      >>
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      >       [[alternative HTML
> >     version
> >      >>>>      deleted]]
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >      >      >      >
> >      >>>>      _______________________________________________
> >      >>>>       >      >      >      >      >
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>>
> >      >>>>       >      >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >      >>>>       >      >      >
> >       <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >      >>>>       >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >      >>>>       >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >>>>      <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>>> mailing list
> >      >>>>       >      >      >      >      >
> >      >>>>       >      >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >      >>>>       >      >      >
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >      >>>>       >      >
> >      >>>>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >      >>>>       >
> >       <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>>>
> >      >>>>       >      >      >      >     --
> >      >>>>       >      >      >      >     John Fox, Professor Emeritus
> >      >>>>       >      >      >      >     McMaster University
> >      >>>>       >      >      >      >     Hamilton, Ontario, Canada
> >      >>>>       >      >      >      >     web:
> >      >>>> https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >>>>       >      >      >
> >       <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>>
> >      >>>>       >      >      >      >
> >      >>>>        <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >>>>       >      >      >
> >       <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>>>
> >      >>>>       >      >      >      >
> >      >>>>       >      >      >     --
> >      >>>>       >      >      >     John Fox, Professor Emeritus
> >      >>>>       >      >      >     McMaster University
> >      >>>>       >      >      >     Hamilton, Ontario, Canada
> >      >>>>       >      >      >     web:
> >     https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >>>>       >      >      >
> >       <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>>
> >      >>>>       >      >      >
> >      >>>>       >      >     --
> >      >>>>       >      >     John Fox, Professor Emeritus
> >      >>>>       >      >     McMaster University
> >      >>>>       >      >     Hamilton, Ontario, Canada
> >      >>>>       >      >     web:
> >     https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >      >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>>
> >      >>>>       >      >
> >      >>>>       >
> >      >>>>
> >      >>>
> >
>  ------------------------------------------------------------------------
> >      >>>>       >     --
> >      >>>>       >     John Fox, Professor Emeritus
> >      >>>>       >     McMaster University
> >      >>>>       >     Hamilton, Ontario, Canada
> >      >>>>       >     web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>       >     <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>>
> >      >>>>       >
> >      >>>>      --
> >      >>>>      John Fox, Professor Emeritus
> >      >>>>      McMaster University
> >      >>>>      Hamilton, Ontario, Canada
> >      >>>>      web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>>      <https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>>
> >      >>>>
> >      >>> --
> >      >>> John Fox, Professor Emeritus
> >      >>> McMaster University
> >      >>> Hamilton, Ontario, Canada
> >      >>> web: https://socialsciences.mcmaster.ca/jfox/
> >     <https://socialsciences.mcmaster.ca/jfox/>
> >      >>>
> >      >>>
> >      >>
> >      >>      [[alternative HTML version deleted]]
> >      >>
> >      >> _______________________________________________
> >      >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >>
> >
>

	[[alternative HTML version deleted]]


From m|n@j@h@ng|r|984 @end|ng |rom gm@||@com  Wed Sep 20 19:44:54 2023
From: m|n@j@h@ng|r|984 @end|ng |rom gm@||@com (mina jahan)
Date: Wed, 20 Sep 2023 10:44:54 -0700
Subject: [R-sig-ME] lme4 package
Message-ID: <CAJt0zy8R20f84PSNHrCHX=J5WJyVOY15nTW2y2tk-p3UpzR3ww@mail.gmail.com>

Hi,

I want to use the lme4 package for prediction of a longitudinal continuous
outcome variable. How can I split data into train and test in longitudinal
data to compute predictive performance?


Best regards,
Mina Jahangiri
Ph.D. student of Biostatistics

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Sep 20 19:58:50 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 20 Sep 2023 13:58:50 -0400
Subject: [R-sig-ME] lme4 package
In-Reply-To: <CAJt0zy8R20f84PSNHrCHX=J5WJyVOY15nTW2y2tk-p3UpzR3ww@mail.gmail.com>
References: <CAJt0zy8R20f84PSNHrCHX=J5WJyVOY15nTW2y2tk-p3UpzR3ww@mail.gmail.com>
Message-ID: <31309483-9e2a-420b-a02f-1c33e77f5614@gmail.com>

    Train/test splits for longitudinal data are a little tricky, and not 
something that's dealt with explicitly in lme4.  For example, see the 
'rolling origin' sampler in the tidymodels package: 
https://rsample.tidymodels.org/reference/rolling_origin.html

   The split should also respect cluster identity (i.e., the split 
should be stratified by cluster so that all the observations from a 
cluster end up in the same fold)

   I would guess that many lme4 users rely on the assumptions of the 
model being approximately valid and use predictive performance measures 
based on that assumption ...

   Hopefully someone else on the list will have more practical advice.


On 2023-09-20 1:44 p.m., mina jahan wrote:
> Hi,
> 
> I want to use the lme4 package for prediction of a longitudinal continuous
> outcome variable. How can I split data into train and test in longitudinal
> data to compute predictive performance?
> 
> 
> Best regards,
> Mina Jahangiri
> Ph.D. student of Biostatistics
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From j|ox @end|ng |rom mcm@@ter@c@  Wed Sep 20 22:14:42 2023
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 20 Sep 2023 16:14:42 -0400
Subject: [R-sig-ME] lme4 package
In-Reply-To: <31309483-9e2a-420b-a02f-1c33e77f5614@gmail.com>
References: <CAJt0zy8R20f84PSNHrCHX=J5WJyVOY15nTW2y2tk-p3UpzR3ww@mail.gmail.com>
 <31309483-9e2a-420b-a02f-1c33e77f5614@gmail.com>
Message-ID: <f3c10982-a637-e0d4-878e-5aba65d5c26d@mcmaster.ca>

Dear Ben and Mina,

Georges Monette and I have coincidentally been working recently on a 
general cross-validation package for R, which includes methods (which we 
regards as experimental) for mixed models fit by lme4. In particular, we 
haven't completed a vignette that should explain in more detail some 
considerations involved in cross-validating mixed models. The methods 
for mixed models in the package support cluster-based cross-validation.

The package, named cv, isn't (yet) on CRAN, but can be installed from 
GitHub. See <https://github.com/gmonette/cv> and the associated website 
at <https://gmonette.github.io/cv/>.

Since this is a work in progress, though one that's reasonably far 
along, feedback and suggestions would be welcome.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2023-09-20 1:58 p.m., Ben Bolker wrote:
> Caution: External email.
> 
> 
>  ?? Train/test splits for longitudinal data are a little tricky, and not
> something that's dealt with explicitly in lme4.? For example, see the
> 'rolling origin' sampler in the tidymodels package:
> https://rsample.tidymodels.org/reference/rolling_origin.html
> 
>  ? The split should also respect cluster identity (i.e., the split
> should be stratified by cluster so that all the observations from a
> cluster end up in the same fold)
> 
>  ? I would guess that many lme4 users rely on the assumptions of the
> model being approximately valid and use predictive performance measures
> based on that assumption ...
> 
>  ? Hopefully someone else on the list will have more practical advice.
> 
> 
> On 2023-09-20 1:44 p.m., mina jahan wrote:
>> Hi,
>>
>> I want to use the lme4 package for prediction of a longitudinal 
>> continuous
>> outcome variable. How can I split data into train and test in 
>> longitudinal
>> data to compute predictive performance?
>>
>>
>> Best regards,
>> Mina Jahangiri
>> Ph.D. student of Biostatistics
>>
>> ????? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  > E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Sep 21 01:45:35 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 20 Sep 2023 19:45:35 -0400
Subject: [R-sig-ME] Why do lme() models runs so fast and converge as
 compared to lmer()?
In-Reply-To: <BY3PR06MB79072BE4261896340E1A251BC9FBA@BY3PR06MB7907.namprd06.prod.outlook.com>
References: <BY3PR06MB7907999186645C8F4FCB4B2CC9F4A@BY3PR06MB7907.namprd06.prod.outlook.com>
 <092c0f6d-6684-2837-b19c-066adf0d8d71@gmail.com>
 <BY3PR06MB79072BE4261896340E1A251BC9FBA@BY3PR06MB7907.namprd06.prod.outlook.com>
Message-ID: <fa55da2f-d305-44cb-bcea-23ca01b16941@gmail.com>

    I'm still a little surprised that lme4 is so slow.  Is there a 
possibility that you're using a parallelized BLAS and it's 
over-parallelizing (i.e., hogging lots of memory)?  What is the memory 
usage and CPU performance during your runs (i.e. does it look like 
memory is getting overcommitted and/or lots of threads are running 
simultaneously)?

  e.g. see https://github.com/lme4/lme4/issues/627 ; 
https://github.com/lme4/lme4/issues/726

    lme, lmer, and glmmTMB are all well-respected as far as I know (the 
least-cited and newest of these, glmmTMB, currently has more than 5000 
Google Scholar citations ...)

On 2023-09-18 7:33 a.m., Santosh Srinivas wrote:
> Thank you, Dr. Bolker. The advice to set calc.derivs = FALSE is much 
> appreciated.
> 
> We tried glmmTMB() for the same model and found it quite fast. Models 
> converged with default optimizers.
> 
> Following this, we also tried Julia and were surprised by the 
> orders-of-magnitude improvement in speed.
> 
> We are tending to stick to R and use glmmTMB(). We hope that academic 
> journals are generally receptive to using this package for hypothesis 
> testing. From a cursory Google scholar search, it appears that glmmTMB() 
> is used/cited less often (and Julia's MixedModels far and few) as 
> compared to lme() and lmer().
> 
> Assuming that models are specified identically, I am hoping the results 
> for hypothesis testing (e.g., significance of a coefficient of 
> theoretical importance) should be identical regardless of whether one 
> uses R's lme(), lmer(), or glmmTMB(), or Julia's MixedModels().

   Yes, they should. There are some details such as whether a 
finite-size correction (e.g. Satterthwaite/Kenward-Roger) is applied, 
but given the size of your data set I doubt that's much of an issue)

> 
> On this note, anything that you suggest we state explicitly in the 
> journal manuscript when presenting the results using glmmTMB() as 
> opposed to lme() or lmer()?
> 
> Thanks!
> sbs
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Monday, September 18, 2023 2:11 AM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] Why do lme() models runs so fast and converge 
> as compared to lmer()?
>  ??? This is mildly surprising but not impossible. I haven't looked into
> it/run any experiments yet, but:
> 
>  ? * lme handles a more restricted range of model types, so it's possible
> that its algorithm is faster on simple examples;
> 
>  ? * 'doesn't converge' may not be the issue you think it is.? I would
> improve performance and turn off convergence checking that is known to
> be dodgy for large data sets via control = lmerControl(calc.derivs =
> FALSE)), and more generally try these suggestions:
> https://rdrr.io/cran/lme4/f/vignettes/lmerperf.Rmd 
> <https://rdrr.io/cran/lme4/f/vignettes/lmerperf.Rmd>
> 
>  ?? cheers
>  ??? Ben Bolker
> 
> On 2023-09-17 5:21 a.m., Santosh Srinivas wrote:
>> Hi, I am running the following similar models using lme() and lmer():
>> 
>> f = y ~ x + year * post_event + (year|user_id)
>> 
>> where,
>> 
>>??? *?? year (integer) ranges from 0 (for the year 2010) to 10 (for the year2020);
>>??? *?? post_event (factor variable) is 1 for years 2013 onwards, and 0 otherwise;
>>??? *?? Number of Observations: 3586633; and
>>??? *?? Number of Groups: 1109.
>> 
>> The lme4's lmer() runs for several minutes and never succeeds to converge with any optimizer I try, whereas the former seems to converge in a few minutes.
>> 
>> Not sure if I am doing anything wrong, or whether such convergence and performances are generally expected of lme().
>> 
>> Request your help.
>> 
>> Thanks & regards,
>> sbs
>> 
>> 
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> -- 
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>  ?> E-mail is sent at my convenience; I don't expect replies outside of
> working hours.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From ||on@@@c@r||@4 @end|ng |rom gm@||@com  Fri Sep 22 04:40:36 2023
From: ||on@@@c@r||@4 @end|ng |rom gm@||@com (Fiona Scarff)
Date: Fri, 22 Sep 2023 10:40:36 +0800
Subject: [R-sig-ME] 
 How to get prediction interval from R package MCMCglmm
 fitwith measurement error *and* a random effect?
In-Reply-To: <AS8PR05MB8659610C4E42810112487E3CACFAA@AS8PR05MB8659.eurprd05.prod.outlook.com>
References: <CAP=UNakbZCjr5rOWG16YKW9L0e5L25CT9PM84u6i0oHZykr49g@mail.gmail.com>
 <AS8PR05MB8659610C4E42810112487E3CACFAA@AS8PR05MB8659.eurprd05.prod.outlook.com>
Message-ID: <CAP=UNaku8MSRCX9KAUSnqzWnBRP_yGm-DDF+yLZy0Cgg7yNCZg@mail.gmail.com>

Thanks heaps Jarrod, that worked a treat.

Fiona

On Tue, Sep 19, 2023 at 7:30?PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
> Hi Fiona,
>
>
>
> If you set up the measurement error model explicitly (without using mev ? see code below) the predict function should work. Note that the default is to have the random effects marginalised and so if you want them in the prediction interval you will need marginal = NULL or  marginal=~idh(sqrt(sig.obs)):units or marginal=~ BirdID dpending on exactly what you want.
>
>
>
> Cheers,
>
>
>
> Jarrod
>
>
>
> prior <- list(B = list(mu=0, V=1e10), #for fixed effects
>                R = list(V=1, nu=0.002),  #for residuals
>                G = list( #random effects
>                  G1 = list(V=1, nu=0.002) #first random effect, i.e. BirdID.
>
>                  G2 = list(V=1, fix=1) #mev random effects
>                ))
>
> #fit the glmm
> m <- MCMCglmm::MCMCglmm(
>             fixed = obs.alt ~ 1,
>             family = "gaussian",
>             random = ~BirdID+idh(sqrt(sig.obs)):units,
>             prior = prior,
>             data = data.sim
> )
> #get a prediction interval
> predict(m,  type = "response", interval = "prediction", level = 0.95)[1:3, ]
>
>
>
>
>
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fiona Scarff <fiona.scarff.4 at gmail.com>
> Date: Monday, 18 September 2023 at 16:29
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] How to get prediction interval from R package MCMCglmm fitwith measurement error *and* a random effect?
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> How to get prediction interval from R package MCMCglmm fit with
> measurement error *and* a random effect?
>
> I am having trouble producing a prediction interval from a model fit
> by the R package MCMCglmm, when both a random effect and a measurement
> error is specified in the fit. Many thanks in advance for your time
> and any suggestions.
>
> I can reproduce the prediction interval examples in the package author
> (Jarrod Hadfield)?s MCMCglmm course notes [link
> http://cran.nexr.com/web/packages/MCMCglmm/vignettes/CourseNotes.pdf]
> p.47, but with my own model structure I get this error:
>
> Error in h(simpleError(msg, call)) :
>   error in evaluating the argument 'x' in selecting a method for
> function 't': invalid 'times' argument
>
>  ?x? and ?t? aren?t variables I have declared so I imagine they must
> be objects called internally by the predict function. In the MCMCglmm
> course notes (p.47 again), the author does note that the predict
> function for MCMCglmm is currently incomplete and needs further
> testing, but should be OK for simpler models. Perhaps my model
> structure is an instance of a more elaborate model not yet
> accommodated. Is there some other way I can generate a prediction
> interval?
>
> For context, I am studying the flying height of birds. We obtain
> observations of height from satellite tags attached to birds. The
> observations are recorded with large measurement error (often
> reporting negative height as if the birds were flying underground).
> The variance of the measurement error can be predicted based on the
> number and position of available satellites. MCMCglmm has a facility
> for users to specify a vector of measurement errors associated with
> observations on the response variable. We also have repeat
> observations on each tagged bird, so it?s desirable to also
> incorporate the flying height preferences of individual birds into the
> model.
>
> Here is a reproducible example:
>
> Session info?
> MCMCglmm_2.35
> R version 4.2.3 (2023-03-15)
> Platform: aarch64-apple-darwin20 (64-bit)
> Running under: macOS Ventura 13.4.1
>
> #Declare some parameters governing the flying height of the birds, for
> purposes of simulation
> set.seed(756)
> alt1 <- 20 # mean of true flying height, in metres above ground level
> sig <- 10 #variance in true flying height
> # gamma distribution scale parameter:
> beta = sig/alt1
> #  gamma distribution shape parameter :
> alpha = alt1/beta
>
>  #Additional variation in height amongst individual birds
> ind.re <- rnorm(n= 20, mean=0, sd = 3) # ?ind.re? denotes individual
> random effects
>
> #Create dataframe containing simulation data
> #20 tagged birds, with 100 observations each = 2000 observations total
> data.sim <- data.frame(BirdID = as.factor(rep(1:20, each=100) ) ) %>%
>                         mutate(., sig.obs = rep(5,2000), #std dev of
> measurement error, just for this example I'm imposing an identical
> error for each observation
>             true.alt = #true altitude, drawn from a gamma distribution
>                          rgamma(n = 2000, shape = alpha, scale = beta) +
>                           ind.re[data.sim$BirdID], #individual
> variation amongst birds
>              obs.alt = #observed altitude
>                              true.alt +
> rnorm(n = 2000, mean = 0, sd = sig.obs) # imprecision due to measurement error
>                         )
>
>  #declare priors
> prior <- list(B = list(mu=0, V=1e10), #for fixed effects
>                R = list(V=1, nu=0.002),  #for residuals
>                G = list( #random effects
>                  G1 = list(V=1, nu=0.002) #first random effect, i.e. BirdID.
>                ))
>
> #fit the glmm
> m <- MCMCglmm::MCMCglmm(
>             fixed = obs.alt ~ 1,
>             family = "gaussian",
>             random = ~BirdID,
>             mev = data.sim$sig.obs, #vector of measurement errors
>             prior = prior,
>             data = data.sim
> )
> #get a prediction interval
> predict(m,  type = "response", interval = "prediction", level = 0.95)[1:3, ]
>
> Note that if the model is refit without BirdID as a random effect,
> (i.e. if we comment out ?random = ~BirdID,? above), or alternatively
> without the measurement error vector (?mev =  data.sim$sig.obs,?) then
> the predict function works fine:
>
> (Output without random effect specified)
>        fit      lwr      upr
> 1 20.33545 5.284893 33.06830
> 2 20.72960 6.874275 35.33598
> 3 20.57229 3.561330 33.84181
>
>  Am I doing something wrong here, or is there a workaround? Many thanks again!
> Fiona Scarff
> Murdoch University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From ||on@@@c@r||@4 @end|ng |rom gm@||@com  Fri Sep 22 04:41:31 2023
From: ||on@@@c@r||@4 @end|ng |rom gm@||@com (Fiona Scarff)
Date: Fri, 22 Sep 2023 10:41:31 +0800
Subject: [R-sig-ME] How to obtain a posterior predictive distribution in
 MCMCglmm, and constrain it to non-negative values?
In-Reply-To: <AS8PR05MB8659F7C231C051E8477CF56EACF9A@AS8PR05MB8659.eurprd05.prod.outlook.com>
References: <CAP=UNa=3XfJnkmsdP7C0P0FxVBf0QJxNYznyGOmgrZgr2CcUzg@mail.gmail.com>
 <AS8PR05MB8659F7C231C051E8477CF56EACF9A@AS8PR05MB8659.eurprd05.prod.outlook.com>
Message-ID: <CAP=UNakHTMkLmDz5RiMHR-V++AEMC7Pj2g1oMFHGhsQsSkr6MQ@mail.gmail.com>

Yes, I see. Thanks very much, that's very helpful.

Fiona


On Wed, Sep 20, 2023 at 10:25?PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
> HI,
>
>
>
> You can use simulate(model) in exactly the same way as predict(model) to generate posterior predictive distributions with various random effects marginalised using the argument marginal. The only constraints that can be imposed are those that arise from the particular distribution fitted (e.g. if family=?poisson? the outcome is constrained to be non-negative integers) and so arbitrarily imposing a positive constraint is not possible.
>
>
>
> Cheers,
>
>
>
> Jarrod
>
>
>
>
>
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fiona Scarff <fiona.scarff.4 at gmail.com>
> Date: Wednesday, 20 September 2023 at 13:31
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] How to obtain a posterior predictive distribution in MCMCglmm, and constrain it to non-negative values?
>
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> In MCMCglmm, how can I obtain a posterior predictive distribution? I
> have two random effects; individuals from which observations have been
> obtained, and a measurement error. I would like to marginalise only
> over the individual random effect, and supply a single trivially small
> measurement error for the prediction, so as to get the predicted
> distribution of the true (rather than measured) response in any
> unspecified individual.
>
> Can I further specify this in such a way as to constrain the
> prediction to non-negative values? Naively, I could impose a
> distribution like log-normal or poisson when fitting the glmm. But the
> model fit needs to be able to handle negative values in the response,
> which arise purely due to measurement error.
>
> Many thanks for your time and any suggestions!
>
> Fiona Scarff
> Murdoch University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From GVM962 @end|ng |rom @tudent@bh@m@@c@uk  Thu Sep 21 13:36:35 2023
From: GVM962 @end|ng |rom @tudent@bh@m@@c@uk (Gianni Micucci)
Date: Thu, 21 Sep 2023 11:36:35 +0000
Subject: [R-sig-ME] Mixed model effect for unreplicated design
Message-ID: <LO2P265MB1758037C6341215275348098E6F8A@LO2P265MB1758.GBRP265.PROD.OUTLOOK.COM>

Dear all,
Thanks for taking the time to read and help if you can,
I'll try to be as clear as I can, I am not a stat pro.

I basically study three different fields (agricultural, herbal, pasture) and measured nitrate content (8 replicate per field) in 8 different month, which results in 192 observations.
I am able to plot the evolution of nitrate content as a function of time for the three fields, I would like to know if these fields differ statistically in terms of Nitrate content.
I was told I cannot do ANOVA since these 3 types of fields are not replicated and thus my measures are not independent. I was advise to go for mixed models.
I am afraid the model is however misspecified and don't know if the between field contrasts are being generated.
I wrote a code that generates data, plot them and do the mixed model, please see below.
If anyone could advise me that would be great.

Many thanks again for your help
Best regards
Gianni Micucci


P.S. In addition I get the following warning message:
boundary (singular) fit: see help('isSingular')
when I run the model over the simulated data but not on the real ones, not sure why.



####### Load necessary libraries #####
library(tibble)
library(tidyr)
library(dplyr)

###### Generate data #####
# Set random seed for reproducibility


# Define the number of Field, time points, and unique samples per pond
num_fields <- 3
num_time_points <- 8
num_unique_samples_per_field <- 8

# Set random seed for reproducibility
set.seed(123)


# Create an empty data frame
simulated_data <- data.frame()

# Generate random data
for (field in 1:num_fields) {
  for (time in 1:num_time_points) {
    sampled_samples <- sample(1:num_unique_samples_per_field, num_unique_samples_per_field, replace = FALSE)
    nitrate <- rnorm(num_unique_samples_per_field, mean = 50, sd = 10)
    field_data <- data.frame(
      Field = factor(field),
      Sample = factor(sampled_samples),
      Time = factor(time),
      Nitrate = nitrate
    )
    simulated_data <- rbind(simulated_data, field_data)
  }
}

# Add interaction effect to simulate differences between fields over time
simulated_data$Nitrate <- simulated_data$Nitrate +
  as.numeric(simulated_data$Field) * 5 +    # Field-specific effect
  as.numeric(simulated_data$Time) * 0.5     # Time-specific effect
df <- simulated_data

# Re-organize as per my data
df <- df %>%
  arrange(Field, Time, Sample) %>%
  mutate(Field = factor(Field, levels = c(1, 2, 3), labels = c("Herbal", "Arable", "Pasture"))) %>%
  rename(Month = Time) %>%
  mutate(Month = factor(Month, levels = 1:8, labels = c("April", "May", "June", "July", "August", "September", "October", "November"))) %>%
  select(Field, Month, Sample, Nitrate)


# View the first few rows of the simulated dataset
head(df)


str(df)

# Descriptors
field_summary <- df %>%
  group_by(Field) %>%
  summarise(
    Count_Samples = n(),
    Mean_Nitrate = mean(Nitrate),
    Variance_Nitrate = var(Nitrate)
  )

# Print the summary
print(field_summary)


##### Plot ######
library(ggplot2)
# field with time coloured
ggplot(df, aes(x = Field, y = Nitrate)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +  # Create a single boxplot for each field
  geom_jitter(aes(color = Time), width = 0.2, alpha = 0.5) +  # Overlay data points with jitter and color by Time
  labs(x = "Field", y = "Nitrate")

#Time with field coloured

ggplot(df, aes(x = Time, y = Nitrate)) +
  geom_boxplot(outlier.shape = NA, width = 0.5) +  # Create a single boxplot for each field
  geom_jitter(aes(color = Field), width = 0.2, alpha = 0.5) +  # Overlay data points with jitter and color by Time
  labs(x = "Time", y = "Nitrate")

#plot errorbar x time with three fields on the plot
# Load necessary libraries

# Calculate means and standard errors for Nitrate by Time and Field
summary_data <- df %>%
  group_by(Month, Field) %>%
  summarize(
    Mean_Nitrate = mean(Nitrate),
    SE_Nitrate = sd(Nitrate) / sqrt(n())
  )

# Create the error bar plot
ggplot(summary_data, aes(x = Month, y = Mean_Nitrate, group = Field, color = Field)) +
  geom_errorbar(aes(ymin = Mean_Nitrate - SE_Nitrate, ymax = Mean_Nitrate + SE_Nitrate), width = 0.2) +
  geom_line() +
  geom_point(size = 3) +
  labs(
    title = "Error Bar Plot of Nitrate by Month and Field",
    x = "Month",
    y = "Mean Nitrate",
    color = "Field"
  ) +
  theme(legend.position = "top")


###### Mixed model #####

modele_mixte <- lmer(Nitrate ~ Field + (1 | Month) + (1|Sample), data = df)
summary(modele_mixte)


library(car)
Pvals <- Anova(modele_mixte)

print(Pvals)

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Sep 22 14:57:03 2023
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 22 Sep 2023 14:57:03 +0200
Subject: [R-sig-ME] Mixed model effect for unreplicated design
In-Reply-To: <LO2P265MB1758037C6341215275348098E6F8A@LO2P265MB1758.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB1758037C6341215275348098E6F8A@LO2P265MB1758.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CAJuCY5z8+2rtD5cUTReWQP-wMDijXCOckDo2qdetVL7qYuTC2w@mail.gmail.com>

Dear Gianni,

After a quick look at the code, I think you miscoded the Sample. They
should have a unique identifier. You are reusing the identifiers between
fields.
df$Sample <- interaction(df$Field, df$Sample) should fix that.

Note that your data can only calculate the differences between these three
specific fields. You cannot generalise the differences as effects from the
treatment of the fields. One sample at eight different fields per treatment
would have been a better option than eight samples at one field per
treatment.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 22 sep 2023 om 14:45 schreef Gianni Micucci <GVM962 at student.bham.ac.uk
>:

> Dear all,
> Thanks for taking the time to read and help if you can,
> I'll try to be as clear as I can, I am not a stat pro.
>
> I basically study three different fields (agricultural, herbal, pasture)
> and measured nitrate content (8 replicate per field) in 8 different month,
> which results in 192 observations.
> I am able to plot the evolution of nitrate content as a function of time
> for the three fields, I would like to know if these fields differ
> statistically in terms of Nitrate content.
> I was told I cannot do ANOVA since these 3 types of fields are not
> replicated and thus my measures are not independent. I was advise to go for
> mixed models.
> I am afraid the model is however misspecified and don't know if the
> between field contrasts are being generated.
> I wrote a code that generates data, plot them and do the mixed model,
> please see below.
> If anyone could advise me that would be great.
>
> Many thanks again for your help
> Best regards
> Gianni Micucci
>
>
> P.S. In addition I get the following warning message:
> boundary (singular) fit: see help('isSingular')
> when I run the model over the simulated data but not on the real ones, not
> sure why.
>
>
>
> ####### Load necessary libraries #####
> library(tibble)
> library(tidyr)
> library(dplyr)
>
> ###### Generate data #####
> # Set random seed for reproducibility
>
>
> # Define the number of Field, time points, and unique samples per pond
> num_fields <- 3
> num_time_points <- 8
> num_unique_samples_per_field <- 8
>
> # Set random seed for reproducibility
> set.seed(123)
>
>
> # Create an empty data frame
> simulated_data <- data.frame()
>
> # Generate random data
> for (field in 1:num_fields) {
>   for (time in 1:num_time_points) {
>     sampled_samples <- sample(1:num_unique_samples_per_field,
> num_unique_samples_per_field, replace = FALSE)
>     nitrate <- rnorm(num_unique_samples_per_field, mean = 50, sd = 10)
>     field_data <- data.frame(
>       Field = factor(field),
>       Sample = factor(sampled_samples),
>       Time = factor(time),
>       Nitrate = nitrate
>     )
>     simulated_data <- rbind(simulated_data, field_data)
>   }
> }
>
> # Add interaction effect to simulate differences between fields over time
> simulated_data$Nitrate <- simulated_data$Nitrate +
>   as.numeric(simulated_data$Field) * 5 +    # Field-specific effect
>   as.numeric(simulated_data$Time) * 0.5     # Time-specific effect
> df <- simulated_data
>
> # Re-organize as per my data
> df <- df %>%
>   arrange(Field, Time, Sample) %>%
>   mutate(Field = factor(Field, levels = c(1, 2, 3), labels = c("Herbal",
> "Arable", "Pasture"))) %>%
>   rename(Month = Time) %>%
>   mutate(Month = factor(Month, levels = 1:8, labels = c("April", "May",
> "June", "July", "August", "September", "October", "November"))) %>%
>   select(Field, Month, Sample, Nitrate)
>
>
> # View the first few rows of the simulated dataset
> head(df)
>
>
> str(df)
>
> # Descriptors
> field_summary <- df %>%
>   group_by(Field) %>%
>   summarise(
>     Count_Samples = n(),
>     Mean_Nitrate = mean(Nitrate),
>     Variance_Nitrate = var(Nitrate)
>   )
>
> # Print the summary
> print(field_summary)
>
>
> ##### Plot ######
> library(ggplot2)
> # field with time coloured
> ggplot(df, aes(x = Field, y = Nitrate)) +
>   geom_boxplot(outlier.shape = NA, width = 0.5) +  # Create a single
> boxplot for each field
>   geom_jitter(aes(color = Time), width = 0.2, alpha = 0.5) +  # Overlay
> data points with jitter and color by Time
>   labs(x = "Field", y = "Nitrate")
>
> #Time with field coloured
>
> ggplot(df, aes(x = Time, y = Nitrate)) +
>   geom_boxplot(outlier.shape = NA, width = 0.5) +  # Create a single
> boxplot for each field
>   geom_jitter(aes(color = Field), width = 0.2, alpha = 0.5) +  # Overlay
> data points with jitter and color by Time
>   labs(x = "Time", y = "Nitrate")
>
> #plot errorbar x time with three fields on the plot
> # Load necessary libraries
>
> # Calculate means and standard errors for Nitrate by Time and Field
> summary_data <- df %>%
>   group_by(Month, Field) %>%
>   summarize(
>     Mean_Nitrate = mean(Nitrate),
>     SE_Nitrate = sd(Nitrate) / sqrt(n())
>   )
>
> # Create the error bar plot
> ggplot(summary_data, aes(x = Month, y = Mean_Nitrate, group = Field, color
> = Field)) +
>   geom_errorbar(aes(ymin = Mean_Nitrate - SE_Nitrate, ymax = Mean_Nitrate
> + SE_Nitrate), width = 0.2) +
>   geom_line() +
>   geom_point(size = 3) +
>   labs(
>     title = "Error Bar Plot of Nitrate by Month and Field",
>     x = "Month",
>     y = "Mean Nitrate",
>     color = "Field"
>   ) +
>   theme(legend.position = "top")
>
>
> ###### Mixed model #####
>
> modele_mixte <- lmer(Nitrate ~ Field + (1 | Month) + (1|Sample), data = df)
> summary(modele_mixte)
>
>
> library(car)
> Pvals <- Anova(modele_mixte)
>
> print(Pvals)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Sep 25 10:51:39 2023
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Mon, 25 Sep 2023 09:51:39 +0100
Subject: [R-sig-ME] Course: Introduction to Linear Mixed-Effects Models,
 GLMM and Multivariate GLMM with R
Message-ID: <98c4b960-b47b-38c7-64df-020fafe5c370@highstat.com>

We would like to announce the following on-line statistics course:

Course: Introduction to Linear Mixed-Effects Models, GLMM and 
*Multivariate GLMM* with R

Format: Online live course.

When: 14.00 - 19.00 UK time; 28 and 30 November, 1, 4, 5, 6 and 7 
December 2023

Included: 2 hours face-to-face consultancy via Zoom

Course website: https://www.highstat.com/
Course flyer: https://www.highstat.com/Courses/Flyers/Flyer2023_11_GLMM.pdf


Kind regards,

Alain Zuur



-- 
Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL: www.highstat.com
	[[alternative HTML version deleted]]


From O|||c|e|-F@y@@@| @end|ng |rom hotm@||@|r  Mon Sep 25 21:25:18 2023
From: O|||c|e|-F@y@@@| @end|ng |rom hotm@||@|r (=?iso-8859-1?Q?Fay=E7al_CHAIBEDDRA-TANI?=)
Date: Mon, 25 Sep 2023 19:25:18 +0000
Subject: [R-sig-ME] Random-effect
Message-ID: <AM7P192MB0739A17034C85E96045C4053E1FCA@AM7P192MB0739.EURP192.PROD.OUTLOOK.COM>

Dear lme4 users
i have a question about mixed-effect in Pymer4 (same of lme4 but in python). My model is fitted under machine-learning to get the predicted values (Observed_values = predicted_values + total_residuals) and I want to split my residuals into between-group and within group using random-effect maximum likelihood estimation in Pymer4

and how to define the between and within-group residuals ?

Where the between-group residuals are determined as the average deviation of observed values from median predictions for a given group.

While the within-group residuals are a measure of misfit between an individual observation at a record and the group-specific median prediction. in summary total_residuals = between_group + within_group

So the start of code is like this way?

from pymer4.models import Lmer

model = Lmer('observed_target_values ~ predicted_target_values + (1|group_id) ', data=df)

model.fit()

Best regards

	[[alternative HTML version deleted]]


From |@uren@g|rou@rd @end|ng |rom |ou|@v|||e@edu  Mon Sep 25 21:51:42 2023
From: |@uren@g|rou@rd @end|ng |rom |ou|@v|||e@edu (Girouard, Lauren)
Date: Mon, 25 Sep 2023 19:51:42 +0000
Subject: [R-sig-ME] Upcoming FREE Virtual Workshop: An Introduction to
 Multiple Regression and Multilevel Modeling in R
Message-ID: <SN6PR03MB35522730B944B0B9EAA43B5F88FCA@SN6PR03MB3552.namprd03.prod.outlook.com>

Dear all,



The Louisville Chapter of R-Ladies would like to invite you to a free virtual workshop hosted on Zoom titled ?An Introduction to Multiple Regression and Multilevel Modeling in R?! This panel will take place on Monday 2 October 2023 from 9:00 ? 11:00 AM ET and will be led by Claire Cusack, MS, and Lauren Girouard-Hallam, MA, MS, University of Louisville Clinical and Experimental Psychology doctoral candidates. The workshop will be a great chance to review concepts related to OLS regression in R and receive an introduction to multilevel modeling concepts in R. Multilevel modeling will make up the bulk of the two-hour workshop.


We request that you already have R and R Studio and the provided workshop materials (to be sent 24 hours in advance) downloaded prior to the workshop. We also recommend that you have some experience with linear regression or related concepts in R. Prior multilevel modeling experience is not expected!

When: October 2nd, 2023 at 9:00 AM ET
How to Sign Up: https://forms.gle/LLM8FZ6aCmJ3h8ue8<https://forms.gle/LLM8FZ6aCmJ3h8ue8>
[https://lh6.googleusercontent.com/EdM3DP_J7vQEvlXRPKQv8KrRM_WTLSWmdJMhuEzzkCTg7onTiK0BxAnmVM1-MElgIo8r8djiINI=w1200-h630-p]<https://forms.gle/LLM8FZ6aCmJ3h8ue8>
Contact Information: R Ladies Regression WS<https://forms.gle/LLM8FZ6aCmJ3h8ue8>
Please provide an email to be sent the Zoom link for R Ladies- Louisville's workshop "Regression and Multilevel Modeling in R" to be held on Monday October 2nd at 9:00 AM ET. The materials for the workshop will be sent 24 hours before the workshop. A recording will be available 24 hours after the workshop. DON'T FORGET TO DOUBLE CHECK YOUR EMAIL ADDRESS
forms.gle

If you cannot attend but would like to receive a recording and folder with related resources, please still sign up using your email at the link above! Please reach out with any questions.




Best,

Lauren Girouard-Hallam & Ann Holmes


lauren.girouard at louisville.edu
ann.holmes at louisville.edu


Lauren N. Girouard-Hallam, M.A., M.S.

she, her, hers \ What is this?<https://www.glsen.org/article/pronouns-resource-educators>

Experimental Psychology Doctoral Candidate

Knowledge in Development Research Lab

APA Society for Teaching Psychology GTA Steering Committee

Department of Psychological and Brain Sciences

University of Louisville

Twitter: @LaurenGirouard1

	[[alternative HTML version deleted]]


From n|nj@|np|j@m@ @end|ng |rom out|ook@com  Tue Sep 26 02:37:04 2023
From: n|nj@|np|j@m@ @end|ng |rom out|ook@com (NIP)
Date: Mon, 25 Sep 2023 19:37:04 -0500
Subject: [R-sig-ME] :D
Message-ID: <DM6PR20MB35081BED6E4360E9927B18BDA7C3A@DM6PR20MB3508.namprd20.prod.outlook.com>

Hello!

Could any one help me out, if possible? I'm stuck here. How would 
translate the following command lines to lmer syntax

```

model <- aov(
 ? response ~ treatment*time + Error(id/time),
 ? data = selfesteem2)
summary(model)

```

I've tried this among others without success.

```

anova(lmerTest::lmer(
 ? response ~ treatment*time + (1|id:time),
 ? data = data))

```

-- 
? Joel


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 26 03:10:58 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 25 Sep 2023 21:10:58 -0400
Subject: [R-sig-ME] :D
In-Reply-To: <DM6PR20MB35081BED6E4360E9927B18BDA7C3A@DM6PR20MB3508.namprd20.prod.outlook.com>
References: <DM6PR20MB35081BED6E4360E9927B18BDA7C3A@DM6PR20MB3508.namprd20.prod.outlook.com>
Message-ID: <3bf51228-83c1-0ffd-4a93-253f11342d6c@gmail.com>

   Is there any chance you could give us a reproducible example? (i.e., 
either post your data, or suggest an example based on a data set that's 
built into base R or some common R package ...)

   In general I would think that Error(id/time) would be matched by 
(1|id/time), not by (1|id:time) ...


On 2023-09-25 8:37 p.m., NIP wrote:
> Hello!
> 
> Could any one help me out, if possible? I'm stuck here. How would 
> translate the following command lines to lmer syntax
> 
> ```
> 
> model <- aov(
>  ? response ~ treatment*time + Error(id/time),
>  ? data = selfesteem2)
> summary(model)
> 
> ```
> 
> I've tried this among others without success.
> 
> ```
> 
> anova(lmerTest::lmer(
>  ? response ~ treatment*time + (1|id:time),
>  ? data = data))
> 
> ```
>


