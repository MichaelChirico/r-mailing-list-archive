From bbolker at gmail.com  Fri Jul  1 02:28:47 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 30 Jun 2016 20:28:47 -0400
Subject: [R-sig-ME] Overdispersion and R2 in GLMM
In-Reply-To: <CAPvMryO05ADrZ13v00R+5dSh9YJc4RWysqNQ9F5Gh82R-edvDA@mail.gmail.com>
References: <CAPvMryO05ADrZ13v00R+5dSh9YJc4RWysqNQ9F5Gh82R-edvDA@mail.gmail.com>
Message-ID: <5775B93F.60304@gmail.com>



On 16-06-30 12:40 PM, Teresa Oliveira wrote:
> Dear all,
> 
> I want to estimate RSF

  Can you tell us/remind us what RSF is?  (Remember that this is a very
general mailing list about mixed models, with readers in many different
fields)

> and to obtain the relative probabilities I will use
> the coefficients obtained with GLMMs. I am new in this so I hope I can
> express myself well.
> To construct the GLMM's, I am using glmer(). I will to use the MuMIn
> package to perform model selection [using dredge()].

  I'm getting less and less enthusiastic about this approach, but
comments will have to wait for another day.

> I have two doubts:
> 1) For the top models I get, in order to understand if they are really
> meaningful, I need to estimate R2 [r.squaredGLMM()] and to test for
> overdispersion [overdisp.glmer() with "RVAideMemoire" package], right? Is
> there anything else I must consider (besides de AIC)?

  I would generally suggest looking at graphical diagnostics (e.g. see
?plot.merMod) and plotting the predicted responses of the model along
with the original data.  R^2 values are not bad, but they're very much
harder to interpret in a (G)LMM context.

https://tinyurl.com/glmmFAQ#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms

(the same base URL also has more information about computing overdispersion)

> 
> 2) How do I interpret the results in both tests?
> For a model with all variables I wanted to include (so, before performing
> model selection), I estimated R2 and overdispersion.
> 
> For overdispersion I got this:
> "> overdisp.glmer(lm_set3)
> Residual deviance: 8537.397 on 32658 degrees of freedom (ratio: 0.261)"
> Which value for ratio is acceptable?

  What kind of model are you fitting?
  In general overdispersion values (a) are only relevant
> 
> For R2 I got this:
> "> r.squaredGLMM(lm_set3)
> The result is correct only if all data used by the model has not changed
> since model was fitted.
>         R2m         R2c
> 0.006139516 0.788967246 "
> Is it normal to get values so different? Should I consider both?

  This means that your fixed effects explain almost nothing, but the
combination of fixed and random effects explains almost everything.
Does seem a little concerning.

  Explore your data graphically!

  cheers
    Ben Bolker

> 
> Thank you very much for your time and help!
> 
> Best regards,
> Teresa
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Fri Jul  1 02:45:26 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jul 2016 00:45:26 +0000 (UTC)
Subject: [R-sig-ME] Negative Binomial in glmmadmb
References: <1467301244612.45391@auburn.edu>
Message-ID: <loom.20160701T023605-704@post.gmane.org>

Chad Newbolt <newboch at ...> writes:

>

[snip] 

> Since I have evidence for overdispersion, I'm using negative
> binomial distribution as opposed to Poisson.  My two questions are:
> 1) When I fit using the following global zero inflation model I
> receive the following error:
 
> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
  I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
   data=datum,family="nbinom",zeroInflation = TRUE)

I think you can shorten this a bit to

(Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)

> Parameters were estimated, but standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
> Age * : The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and
> inspect output files; (2) change run parameters: see
> '?admbControl';(3) re-run with debug=TRUE for more information on
> failure mode In addition: Warning message: running command
> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
> -shess' had status 1
 
> However, when I change to zeroInflation = FALSE, I receive no
>  warnings and everything seems to go as should.
 
> Does this simply mean that my data is not zero inflated, hence the
> zero inflated model will not run, or is this something I should be
> concerned about and investigate the cause further?  When I debug I
> see the following warning....Warning -- Hessian does not appear to
> be positive definite Hessian does not appear to be positive
> definite.

> 2) When fitting more simple versions(predictors removed) I receive
> the same error as above when using the family=nbinom; however these
> errors disappear when using family=nbinom1.  Is this indicative of
> an underlying problem or am I OK to use the ouput from the later
> family where variance = ??.  Thanks, Chad [[alternative HTML version
> deleted]]

  Short answer: you should be a little concerned, and you should
not assume that your data are not zero-inflated. These are not
indications about what your model is actually finding, just indications
that ADMB ran into *some* kind of trouble. Unfortunately,
there is no really simple guide to trouble-shooting these kinds of
problems.  Some general suggestions:

* try out the glmmTMB package - it's newer/experimental, but
often more stable
* the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
* it may not help in this case, but centering continuous predictors is 
always worth a shot
* similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
* inspect your data graphically to see whether there are outliers 
or other odd patterns that might be messing up the fit


From bbolker at gmail.com  Fri Jul  1 02:58:33 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Jul 2016 00:58:33 +0000 (UTC)
Subject: [R-sig-ME] Question about zero-inflated Poisson glmer
References: <576B98C4.6000602@gmail.com>
	<CAJuCY5xbiEjCmHjc_3wX2emzJ3NEMTA_qKgC_reWn=zqC7YEng@mail.gmail.com>
	<576BAB84.6080009@gmail.com>
	<CAJuCY5zmK1xCyWOwcCH+Hch_LSdB+AazmUDuPVP6je7ABFU5FA@mail.gmail.com>
	<576BBCFD.8040806@gmail.com>
	<CAJuCY5ycRL6oXs=H5JrEqOHWzd1UsvSNVZM6-MK+V2N=pvbyQA@mail.gmail.com>
	<576BFEBC.3020407@gmail.com>
	<B5AEF3F5-949F-4686-82DA-C234C3C4018B@ufl.edu>
	<576C18F9.9010200@gmail.com> <576C200A.1050405@gmail.com>
	<4D07695C-8CEA-4785-A5B0-46B011625DA0@ufl.edu>
	<576D290A.7090102@gmail.com> <576D3209.6050507@gmail.com>
	<576D3864.1060001@gmail.com> <576D3B1B.3050908@gmail.com>
	<CAGPhqeohy3hB8hfnNcj=6d_D=mRVG9CWk910qfSEsEnnr0N@mail.gmail.com>
Message-ID: <loom.20160701T024714-420@post.gmane.org>

Philipp Singer <killver at ...> writes:

> 
> I have now played around more with the data an the models both using lme4
> and glmmTMB.
> 

[snip]
 
> In lme4, when I do:
>

Note that at this point you're not actually using lme4 at all.
Regular old glm() from base R has predict and simulate methods,
which *silently ignore* (slight design flaw there ...) the
extra re.form argument ...

set.seed(101)
d <- data.frame(x=rpois(100,lambda=5))
m <- glm(x~1,family="poisson",data=d)
p <- predict(m, type='response',re.form=NA)

set.seed(101)
sim1 <- rpois(n=nrow(d),lambda=p)

## if I do simulate(1,m,...) I get "no applicable method for 'simulate' ..."

## either set.seed(101) here to reset random number generator,
## or use the 'seed' argument to simulate() ...

sim2 <- simulate(m,1,re.form=NA,seed=101)[[1]]

all.equal(sim1,sim2)  ## TRUE

> I receive different outcomes? Do I understand these function wrongly?
> 

I get the same answer both ways.  I can't tell whether you're doing
something subtly different (that's why reproducible examples
are so nice, even for simple questions), or whether you're
just failing to reset the random-number seed.


From newboch at auburn.edu  Fri Jul  1 21:47:38 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Fri, 1 Jul 2016 19:47:38 +0000
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <loom.20160701T023605-704@post.gmane.org>
References: <1467301244612.45391@auburn.edu>,
	<loom.20160701T023605-704@post.gmane.org>
Message-ID: <1467402458879.39049@auburn.edu>

Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.

Chad
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Thursday, June 30, 2016 7:45 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Chad Newbolt <newboch at ...> writes:

>

[snip]

> Since I have evidence for overdispersion, I'm using negative
> binomial distribution as opposed to Poisson.  My two questions are:
> 1) When I fit using the following global zero inflation model I
> receive the following error:

> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
  I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
   data=datum,family="nbinom",zeroInflation = TRUE)

I think you can shorten this a bit to

(Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)

> Parameters were estimated, but standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
> Age * : The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and
> inspect output files; (2) change run parameters: see
> '?admbControl';(3) re-run with debug=TRUE for more information on
> failure mode In addition: Warning message: running command
> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
> -shess' had status 1

> However, when I change to zeroInflation = FALSE, I receive no
>  warnings and everything seems to go as should.

> Does this simply mean that my data is not zero inflated, hence the
> zero inflated model will not run, or is this something I should be
> concerned about and investigate the cause further?  When I debug I
> see the following warning....Warning -- Hessian does not appear to
> be positive definite Hessian does not appear to be positive
> definite.

> 2) When fitting more simple versions(predictors removed) I receive
> the same error as above when using the family=nbinom; however these
> errors disappear when using family=nbinom1.  Is this indicative of
> an underlying problem or am I OK to use the ouput from the later
> family where variance = ??.  Thanks, Chad [[alternative HTML version
> deleted]]

  Short answer: you should be a little concerned, and you should
not assume that your data are not zero-inflated. These are not
indications about what your model is actually finding, just indications
that ADMB ran into *some* kind of trouble. Unfortunately,
there is no really simple guide to trouble-shooting these kinds of
problems.  Some general suggestions:

* try out the glmmTMB package - it's newer/experimental, but
often more stable
* the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
* it may not help in this case, but centering continuous predictors is
always worth a shot
* similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
* inspect your data graphically to see whether there are outliers
or other odd patterns that might be messing up the fit

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From killver at gmail.com  Fri Jul  1 21:53:21 2016
From: killver at gmail.com (Philipp Singer)
Date: Fri, 1 Jul 2016 21:53:21 +0200
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <1467402458879.39049@auburn.edu>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu>
Message-ID: <5776CA31.8090407@gmail.com>

Exactly as you would do it in glmmADMB, just replace ADMB with TMB...

Check the github examples: 
https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat

On 01.07.2016 21:47, Chad Newbolt wrote:
> Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.
>
> Chad
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
> Sent: Thursday, June 30, 2016 7:45 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
>
> Chad Newbolt <newboch at ...> writes:
>
> [snip]
>
>> Since I have evidence for overdispersion, I'm using negative
>> binomial distribution as opposed to Poisson.  My two questions are:
>> 1) When I fit using the following global zero inflation model I
>> receive the following error:
>> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
>    I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
>     data=datum,family="nbinom",zeroInflation = TRUE)
>
> I think you can shorten this a bit to
>
> (Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)
>
>> Parameters were estimated, but standard errors were not: the most
>> likely problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
>> Age * : The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and
>> inspect output files; (2) change run parameters: see
>> '?admbControl';(3) re-run with debug=TRUE for more information on
>> failure mode In addition: Warning message: running command
>> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
>> -shess' had status 1
>> However, when I change to zeroInflation = FALSE, I receive no
>>   warnings and everything seems to go as should.
>> Does this simply mean that my data is not zero inflated, hence the
>> zero inflated model will not run, or is this something I should be
>> concerned about and investigate the cause further?  When I debug I
>> see the following warning....Warning -- Hessian does not appear to
>> be positive definite Hessian does not appear to be positive
>> definite.
>> 2) When fitting more simple versions(predictors removed) I receive
>> the same error as above when using the family=nbinom; however these
>> errors disappear when using family=nbinom1.  Is this indicative of
>> an underlying problem or am I OK to use the ouput from the later
>> family where variance = ??.  Thanks, Chad [[alternative HTML version
>> deleted]]
>    Short answer: you should be a little concerned, and you should
> not assume that your data are not zero-inflated. These are not
> indications about what your model is actually finding, just indications
> that ADMB ran into *some* kind of trouble. Unfortunately,
> there is no really simple guide to trouble-shooting these kinds of
> problems.  Some general suggestions:
>
> * try out the glmmTMB package - it's newer/experimental, but
> often more stable
> * the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
> * it may not help in this case, but centering continuous predictors is
> always worth a shot
> * similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
> * inspect your data graphically to see whether there are outliers
> or other odd patterns that might be messing up the fit
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From newboch at auburn.edu  Sat Jul  2 02:29:22 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Sat, 2 Jul 2016 00:29:22 +0000
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <5776CA31.8090407@gmail.com>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu>,<5776CA31.8090407@gmail.com>
Message-ID: <1467419367279.31120@auburn.edu>

I had to use: 

family=list(family="nbinom1", link="log") 

in glmmTMB 

whereas 

family="nbinom1" 

had previously worked in glmmADMB.  Thanks for pointing me towards examples.
________________________________________
From: Philipp Singer <killver at gmail.com>
Sent: Friday, July 1, 2016 2:53 PM
To: Chad Newbolt; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Exactly as you would do it in glmmADMB, just replace ADMB with TMB...

Check the github examples:
https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat

On 01.07.2016 21:47, Chad Newbolt wrote:
> Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.
>
> Chad
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
> Sent: Thursday, June 30, 2016 7:45 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
>
> Chad Newbolt <newboch at ...> writes:
>
> [snip]
>
>> Since I have evidence for overdispersion, I'm using negative
>> binomial distribution as opposed to Poisson.  My two questions are:
>> 1) When I fit using the following global zero inflation model I
>> receive the following error:
>> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
>    I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
>     data=datum,family="nbinom",zeroInflation = TRUE)
>
> I think you can shorten this a bit to
>
> (Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)
>
>> Parameters were estimated, but standard errors were not: the most
>> likely problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
>> Age * : The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and
>> inspect output files; (2) change run parameters: see
>> '?admbControl';(3) re-run with debug=TRUE for more information on
>> failure mode In addition: Warning message: running command
>> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
>> -shess' had status 1
>> However, when I change to zeroInflation = FALSE, I receive no
>>   warnings and everything seems to go as should.
>> Does this simply mean that my data is not zero inflated, hence the
>> zero inflated model will not run, or is this something I should be
>> concerned about and investigate the cause further?  When I debug I
>> see the following warning....Warning -- Hessian does not appear to
>> be positive definite Hessian does not appear to be positive
>> definite.
>> 2) When fitting more simple versions(predictors removed) I receive
>> the same error as above when using the family=nbinom; however these
>> errors disappear when using family=nbinom1.  Is this indicative of
>> an underlying problem or am I OK to use the ouput from the later
>> family where variance = ??.  Thanks, Chad [[alternative HTML version
>> deleted]]
>    Short answer: you should be a little concerned, and you should
> not assume that your data are not zero-inflated. These are not
> indications about what your model is actually finding, just indications
> that ADMB ran into *some* kind of trouble. Unfortunately,
> there is no really simple guide to trouble-shooting these kinds of
> problems.  Some general suggestions:
>
> * try out the glmmTMB package - it's newer/experimental, but
> often more stable
> * the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
> * it may not help in this case, but centering continuous predictors is
> always worth a shot
> * similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
> * inspect your data graphically to see whether there are outliers
> or other odd patterns that might be messing up the fit
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From beermewi at gmail.com  Sat Jul  2 01:37:53 2016
From: beermewi at gmail.com (a y)
Date: Fri, 1 Jul 2016 18:37:53 -0500
Subject: [R-sig-ME] Specifying outcome variable in binomial glmm: single
	responses vs cbind?
Message-ID: <CALM1w4b2_Sq9pT-7Atb==tnYgGfQWRry7kSGUTS+KERGqnagtw@mail.gmail.com>

What is the difference between fitting a binomial glmm (without random item
effects) in the following two ways?

1.
Data formatted in the following way:

(data_long)
ID    correct    condition    itemID
1      1             A               i1
1      0             A               i2
1      1             A               i3
1      1             A               i4
2      0             B               i1
2      1             B               i2
2      1             B               i3
2      0             B               i4

Fitting a model without item random effects:

glmer(correct ~ condition + (1|ID), family = binomial, data = data_long)


2.
Data formatted this way (summing over the correct responses):

(data_short)
ID     sum_correct    condition     itemID
1       3                      A                NA
2       2                      B                NA

Fitting the following model, assuming there were only 4 items  (I've seen
dozens of examples like this):
glmer(cbind(sum_correct, 4 - sum_correct) ~ condition + (1|ID), family =
binomial, data = data_short)

---
I figured these models should be identical, but in my experience they are
very much not. What am I missing? When is the second (more) appropriate?

Thanks for any help,
Andrew

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Jul  2 19:06:30 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 2 Jul 2016 13:06:30 -0400
Subject: [R-sig-ME] Specifying outcome variable in binomial glmm: single
 responses vs cbind?
In-Reply-To: <CALM1w4b2_Sq9pT-7Atb==tnYgGfQWRry7kSGUTS+KERGqnagtw@mail.gmail.com>
References: <CALM1w4b2_Sq9pT-7Atb==tnYgGfQWRry7kSGUTS+KERGqnagtw@mail.gmail.com>
Message-ID: <5777F496.5050504@gmail.com>



On 16-07-01 07:37 PM, a y wrote:
> What is the difference between fitting a binomial glmm (without random item
> effects) in the following two ways?
> 
> 1.
> Data formatted in the following way:
> 
> (data_long)
> ID    correct    condition    itemID
> 1      1             A               i1
> 1      0             A               i2
> 1      1             A               i3
> 1      1             A               i4
> 2      0             B               i1
> 2      1             B               i2
> 2      1             B               i3
> 2      0             B               i4
> 
> Fitting a model without item random effects:
> 
> glmer(correct ~ condition + (1|ID), family = binomial, data = data_long)
> 
> 
> 2.
> Data formatted this way (summing over the correct responses):
> 
> (data_short)
> ID     sum_correct    condition     itemID
> 1       3                      A                NA
> 2       2                      B                NA
> 
> Fitting the following model, assuming there were only 4 items  (I've seen
> dozens of examples like this):
> glmer(cbind(sum_correct, 4 - sum_correct) ~ condition + (1|ID), family =
> binomial, data = data_short)
> 
> ---
> I figured these models should be identical, but in my experience they are
> very much not. What am I missing? When is the second (more) appropriate?
> 
> Thanks for any help,
> Andrew
> 

  I believe they should give different likelihoods but identical
parameter estimates, *differences* among likelihoods (i.e. among
competing models fitted with the same data), etc..  That is,
disaggregating the data leads to an extra additive constant in the
log-likelihood. I would be very interested to see a counter-example to
that statement!  In general, the second form should be quicker to fit,
provide residuals that are easier to interpret, etc..


From quentin.schorpp at thuenen.de  Sat Jul  2 19:46:08 2016
From: quentin.schorpp at thuenen.de (Quentin Schorpp)
Date: Sat, 2 Jul 2016 19:46:08 +0200 (CEST)
Subject: [R-sig-ME] (no subject)
Message-ID: <3a30f2a6285ec6786841c472c1025d89.squirrel@webmail.thuenen.de>

Hello,

I read if the null model, a model that only contains an intercept term, is
the best fit (within a candiadte set of models), it means that the data
was not able to sufficiently answer the research questions.

However i do not remember the article. Does anyboy know a such a citation,
and is it even true?

kind regards,
Quentin


From beermewi at gmail.com  Sat Jul  2 20:48:06 2016
From: beermewi at gmail.com (a y)
Date: Sat, 2 Jul 2016 13:48:06 -0500
Subject: [R-sig-ME] Specifying outcome variable in binomial glmm: single
	responses vs cbind?
In-Reply-To: <CALM1w4b2_Sq9pT-7Atb==tnYgGfQWRry7kSGUTS+KERGqnagtw@mail.gmail.com>
References: <CALM1w4b2_Sq9pT-7Atb==tnYgGfQWRry7kSGUTS+KERGqnagtw@mail.gmail.com>
Message-ID: <CALM1w4Z938rGk9GUSk_XCF=i0HVvwFfDpjt4J7K=ASrsBWyzpQ@mail.gmail.com>

I answered my own question, so feel free to disregard this topic.

On Fri, Jul 1, 2016 at 6:37 PM, a y <beermewi at gmail.com> wrote:

> What is the difference between fitting a binomial glmm (without random
> item effects) in the following two ways?
>
> 1.
> Data formatted in the following way:
>
> (data_long)
> ID    correct    condition    itemID
> 1      1             A               i1
> 1      0             A               i2
> 1      1             A               i3
> 1      1             A               i4
> 2      0             B               i1
> 2      1             B               i2
> 2      1             B               i3
> 2      0             B               i4
>
> Fitting a model without item random effects:
>
> glmer(correct ~ condition + (1|ID), family = binomial, data = data_long)
>
>
> 2.
> Data formatted this way (summing over the correct responses):
>
> (data_short)
> ID     sum_correct    condition     itemID
> 1       3                      A                NA
> 2       2                      B                NA
>
> Fitting the following model, assuming there were only 4 items  (I've seen
> dozens of examples like this):
> glmer(cbind(sum_correct, 4 - sum_correct) ~ condition + (1|ID), family =
> binomial, data = data_short)
>
> ---
> I figured these models should be identical, but in my experience they are
> very much not. What am I missing? When is the second (more) appropriate?
>
> Thanks for any help,
> Andrew
>

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Sat Jul  2 21:29:17 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Sat, 2 Jul 2016 20:29:17 +0100
Subject: [R-sig-ME] Overdispersion and R2 in GLMM
In-Reply-To: <5775B93F.60304@gmail.com>
References: <CAPvMryO05ADrZ13v00R+5dSh9YJc4RWysqNQ9F5Gh82R-edvDA@mail.gmail.com>
	<5775B93F.60304@gmail.com>
Message-ID: <CAPvMryP5XBXsBSGy0gJu88Eb6-+RXXxX-m0-919Q0g0POFCDAA@mail.gmail.com>

1) A RSF is any function proportional to the probability of selection of
habitat, so it is used to examine habitat selection. The coefficients with
a random intercept for individual (to account for, for instance,
differences in behaviour) will provide coefficients for each resource
variable included with which it is possible to evaluate selection or
avoidance of each variable.

2) I am using glmer() function in "lme4" package. Generalized linear mixed
model fit by maximum likelihood (Laplace Approximation) ['glmerMod'];
Family: binomial ( logit ).

3) Which values (a) are you referring to?
How do I know if ratio value is normal?

4) Yes, I am doing some preliminary analyses to my data and I was trying
different random factors, some of them nested, and those different values
only appear using nested random factors, so I guess I am not using the
right ones!


2016-07-01 1:28 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

>
>
> On 16-06-30 12:40 PM, Teresa Oliveira wrote:
> > Dear all,
> >
> > I want to estimate RSF
>
>   Can you tell us/remind us what RSF is?  (Remember that this is a very
> general mailing list about mixed models, with readers in many different
> fields)
>
> > and to obtain the relative probabilities I will use
> > the coefficients obtained with GLMMs. I am new in this so I hope I can
> > express myself well.
> > To construct the GLMM's, I am using glmer(). I will to use the MuMIn
> > package to perform model selection [using dredge()].
>
>   I'm getting less and less enthusiastic about this approach, but
> comments will have to wait for another day.
>
> > I have two doubts:
> > 1) For the top models I get, in order to understand if they are really
> > meaningful, I need to estimate R2 [r.squaredGLMM()] and to test for
> > overdispersion [overdisp.glmer() with "RVAideMemoire" package], right? Is
> > there anything else I must consider (besides de AIC)?
>
>   I would generally suggest looking at graphical diagnostics (e.g. see
> ?plot.merMod) and plotting the predicted responses of the model along
> with the original data.  R^2 values are not bad, but they're very much
> harder to interpret in a (G)LMM context.
>
>
> https://tinyurl.com/glmmFAQ#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms
>
> (the same base URL also has more information about computing
> overdispersion)
>
> >
> > 2) How do I interpret the results in both tests?
> > For a model with all variables I wanted to include (so, before performing
> > model selection), I estimated R2 and overdispersion.
> >
> > For overdispersion I got this:
> > "> overdisp.glmer(lm_set3)
> > Residual deviance: 8537.397 on 32658 degrees of freedom (ratio: 0.261)"
> > Which value for ratio is acceptable?
>
>   What kind of model are you fitting?
>   In general overdispersion values (a) are only relevant
> >
> > For R2 I got this:
> > "> r.squaredGLMM(lm_set3)
> > The result is correct only if all data used by the model has not changed
> > since model was fitted.
> >         R2m         R2c
> > 0.006139516 0.788967246 "
> > Is it normal to get values so different? Should I consider both?
>
>   This means that your fixed effects explain almost nothing, but the
> combination of fixed and random effects explains almost everything.
> Does seem a little concerning.
>
>   Explore your data graphically!
>
>   cheers
>     Ben Bolker
>
> >
> > Thank you very much for your time and help!
> >
> > Best regards,
> > Teresa
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From aizick.adeniyi89 at gmail.com  Sun Jul  3 18:14:56 2016
From: aizick.adeniyi89 at gmail.com (Isaac Adeniyi)
Date: Sun, 3 Jul 2016 17:14:56 +0100
Subject: [R-sig-ME] Help concerning GLMM estimation needed
Message-ID: <CANMfBzUpg1=62MCFJFaP8N1K5+9EHfxzEHX8EXtbGkYZEJyhsw@mail.gmail.com>

Dear all,

Good day all. I have used lme4 quite a lot and i must say that it is a
wonderful work.
I would like to use glmer with other distributions like the
generalized poisson and com-poisson distribution. I am having hard
time understanding how to approximate the logliklihood  and expressing
the mathematics involved. I would love you to point me in a direction
that will be helpful. Materials such as links to websites, papers and
textbooks will be helpful. Also,can you give some hints on how I can
modify the glmer codes to make it work for these distributions. Thanks
a lot for the help.


From bbolker at gmail.com  Mon Jul  4 04:03:05 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 3 Jul 2016 22:03:05 -0400
Subject: [R-sig-ME] Help concerning GLMM estimation needed
In-Reply-To: <CANMfBzUpg1=62MCFJFaP8N1K5+9EHfxzEHX8EXtbGkYZEJyhsw@mail.gmail.com>
References: <CANMfBzUpg1=62MCFJFaP8N1K5+9EHfxzEHX8EXtbGkYZEJyhsw@mail.gmail.com>
Message-ID: <5779C3D9.3000604@gmail.com>


  This is going to be a bit of a challenge.  glmer really depends on
extensions of the machinery used in GLM (see e.g. McCullagh and Nelder
or Barnett and Dobson or ...)  *If* the distribution is in the
exponential family, then you should be able to define a new family
argument for it following the existing ones (binomial, Poisson, Gamma,
etc.), which defines the mean-variance relationship.  However, many
extensions of the exponential family (e.g. negative binomial with an
unspecified shape parameter) won't work without additional machinery.
(You could do what glmer.nb does, wrapping an internal loop that
estimates an exponential family model with a fixed parameter inside an
outer loop ...)

The machinery of Laplace approximation is described e.g. in

Madsen, Henrik, and Poul Thyregod. Introduction to General and
Generalized Linear Models. CRC Press, 2011.

 For mixed models using arbitrary conditional distributions, a better
start might be the TMB or glmmTMB projects (see kaskr/adcomp and
glmmTMB/glmmTMB on Github).  Or you could look into generalized
estimating equation machinery, which only needs to know the
mean-variance relationship.


On 16-07-03 12:14 PM, Isaac Adeniyi wrote:
> Dear all,
> 
> Good day all. I have used lme4 quite a lot and i must say that it is a
> wonderful work.
> I would like to use glmer with other distributions like the
> generalized poisson and com-poisson distribution. I am having hard
> time understanding how to approximate the logliklihood  and expressing
> the mathematics involved. I would love you to point me in a direction
> that will be helpful. Materials such as links to websites, papers and
> textbooks will be helpful. Also,can you give some hints on how I can
> modify the glmer codes to make it work for these distributions. Thanks
> a lot for the help.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From aizick.adeniyi89 at gmail.com  Mon Jul  4 12:36:49 2016
From: aizick.adeniyi89 at gmail.com (Isaac Adeniyi)
Date: Mon, 4 Jul 2016 11:36:49 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 115, Issue 4
In-Reply-To: <mailman.1.1467626401.11543.r-sig-mixed-models@r-project.org>
References: <mailman.1.1467626401.11543.r-sig-mixed-models@r-project.org>
Message-ID: <CANMfBzVHnqB-nYWOio-HvTg-Eu=3z8+YvdO=crC1o7EAZvi+KA@mail.gmail.com>

Thank you very much. I believe this will go a long way to help me.<div
id="DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2"><br />
<table style="border-top: 1px solid #D3D4DE;">
	<tr>
        <td style="width: 55px; padding-top: 13px;"><a
href="https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail"
target="_blank"><img
src="https://ipmcdn.avast.com/images/2016/icons/icon-envelope-tick-round-orange_184x116-v1.png"
width="46" height="29" style="width: 46px; height: 29px;" /></a></td>
		<td style="width: 470px; padding-top: 12px; color: #41424e;
font-size: 13px; font-family: Arial, Helvetica, sans-serif;
line-height: 18px;">Virus-free. <a
href="https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail"
target="_blank" style="color: #4453ea;">www.avast.com</a>
		</td>
	</tr>
</table><a href="#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2" width="1"
height="1"></a></div>

On 7/4/16, r-sig-mixed-models-request at r-project.org
<r-sig-mixed-models-request at r-project.org> wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Help concerning GLMM estimation needed (Isaac Adeniyi)
>    2. Re: Help concerning GLMM estimation needed (Ben Bolker)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 3 Jul 2016 17:14:56 +0100
> From: Isaac Adeniyi <aizick.adeniyi89 at gmail.com>
> To: R-Sig-Mixed-Models at r-project.org
> Subject: [R-sig-ME] Help concerning GLMM estimation needed
> Message-ID:
> 	<CANMfBzUpg1=62MCFJFaP8N1K5+9EHfxzEHX8EXtbGkYZEJyhsw at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> Dear all,
>
> Good day all. I have used lme4 quite a lot and i must say that it is a
> wonderful work.
> I would like to use glmer with other distributions like the
> generalized poisson and com-poisson distribution. I am having hard
> time understanding how to approximate the logliklihood  and expressing
> the mathematics involved. I would love you to point me in a direction
> that will be helpful. Materials such as links to websites, papers and
> textbooks will be helpful. Also,can you give some hints on how I can
> modify the glmer codes to make it work for these distributions. Thanks
> a lot for the help.
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sun, 3 Jul 2016 22:03:05 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Help concerning GLMM estimation needed
> Message-ID: <5779C3D9.3000604 at gmail.com>
> Content-Type: text/plain; charset=windows-1252
>
>
>   This is going to be a bit of a challenge.  glmer really depends on
> extensions of the machinery used in GLM (see e.g. McCullagh and Nelder
> or Barnett and Dobson or ...)  *If* the distribution is in the
> exponential family, then you should be able to define a new family
> argument for it following the existing ones (binomial, Poisson, Gamma,
> etc.), which defines the mean-variance relationship.  However, many
> extensions of the exponential family (e.g. negative binomial with an
> unspecified shape parameter) won't work without additional machinery.
> (You could do what glmer.nb does, wrapping an internal loop that
> estimates an exponential family model with a fixed parameter inside an
> outer loop ...)
>
> The machinery of Laplace approximation is described e.g. in
>
> Madsen, Henrik, and Poul Thyregod. Introduction to General and
> Generalized Linear Models. CRC Press, 2011.
>
>  For mixed models using arbitrary conditional distributions, a better
> start might be the TMB or glmmTMB projects (see kaskr/adcomp and
> glmmTMB/glmmTMB on Github).  Or you could look into generalized
> estimating equation machinery, which only needs to know the
> mean-variance relationship.
>
>
> On 16-07-03 12:14 PM, Isaac Adeniyi wrote:
>> Dear all,
>>
>> Good day all. I have used lme4 quite a lot and i must say that it is a
>> wonderful work.
>> I would like to use glmer with other distributions like the
>> generalized poisson and com-poisson distribution. I am having hard
>> time understanding how to approximate the logliklihood  and expressing
>> the mathematics involved. I would love you to point me in a direction
>> that will be helpful. Materials such as links to websites, papers and
>> textbooks will be helpful. Also,can you give some hints on how I can
>> modify the glmer codes to make it work for these distributions. Thanks
>> a lot for the help.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 115, Issue 4
> **************************************************
>


From M.Fairbrother at bristol.ac.uk  Mon Jul  4 20:11:55 2016
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 4 Jul 2016 19:11:55 +0100
Subject: [R-sig-ME] Specifying outcome variable in binomial glmm: single
 responses vs cbind?
Message-ID: <CAAH-yP9=jS=AxtAUd8WUnfMUA=JWQCPY5R21Cq5esH71Wty+Lw@mail.gmail.com>

Hi Ben,
This thread is relevant in this regard:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024241.html
At least on my machine, I found a substantial difference in the parameter
estimates. The second form seemed more reliable than the first, as you'll
see from the thread.
Do you get the same result?
Best wishes,
Malcolm



Date: Sat, 2 Jul 2016 13:06:30 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Specifying outcome variable in binomial glmm:
>         single responses vs cbind?
>
>
>
> On 16-07-01 07:37 PM, a y wrote:
> > What is the difference between fitting a binomial glmm (without random
> item
> > effects) in the following two ways?
> >
> > 1.
> > Data formatted in the following way:
> >
> > (data_long)
> > ID    correct    condition    itemID
> > 1      1             A               i1
> > 1      0             A               i2
> > 1      1             A               i3
> > 1      1             A               i4
> > 2      0             B               i1
> > 2      1             B               i2
> > 2      1             B               i3
> > 2      0             B               i4
> >
> > Fitting a model without item random effects:
> >
> > glmer(correct ~ condition + (1|ID), family = binomial, data = data_long)
> >
> >
> > 2.
> > Data formatted this way (summing over the correct responses):
> >
> > (data_short)
> > ID     sum_correct    condition     itemID
> > 1       3                      A                NA
> > 2       2                      B                NA
> >
> > Fitting the following model, assuming there were only 4 items  (I've seen
> > dozens of examples like this):
> > glmer(cbind(sum_correct, 4 - sum_correct) ~ condition + (1|ID), family =
> > binomial, data = data_short)
> >
> > ---
> > I figured these models should be identical, but in my experience they are
> > very much not. What am I missing? When is the second (more) appropriate?
> >
> > Thanks for any help,
> > Andrew
> >
>
>   I believe they should give different likelihoods but identical
> parameter estimates, *differences* among likelihoods (i.e. among
> competing models fitted with the same data), etc..  That is,
> disaggregating the data leads to an extra additive constant in the
> log-likelihood. I would be very interested to see a counter-example to
> that statement!  In general, the second form should be quicker to fit,
> provide residuals that are easier to interpret, etc..
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jul  4 22:10:11 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Jul 2016 16:10:11 -0400
Subject: [R-sig-ME] Specifying outcome variable in binomial glmm: single
 responses vs cbind?
In-Reply-To: <CAAH-yP9=jS=AxtAUd8WUnfMUA=JWQCPY5R21Cq5esH71Wty+Lw@mail.gmail.com>
References: <CAAH-yP9=jS=AxtAUd8WUnfMUA=JWQCPY5R21Cq5esH71Wty+Lw@mail.gmail.com>
Message-ID: <577AC2A3.6060508@gmail.com>


  Really interesting (and somewhat disconcerting).

  Running it with glmmTMB (which uses Laplace!) gives different results
from glmer with nAGQ=1 -- suggesting some issue not just with Laplace,
but with lme4's implementation thereof?? (I don't think the problem is
an optimization failure ...)
   It makes *some* sense that Gauss-Hermite quadrature would be useful
for this case (since binary data is far from fitting a Normality
assumption), but that doesn't necessarily hold up to scrutiny since what
needs to be approximately Normal is not the likelihood per point, but
the likelihood per conditional mode [which should be the same, up to a
constant, for the aggregated and disaggregated data ...]

  Doug Bates, if you're reading would you be willing to try this out
with MixedModels.jl ... ?

  Ben Bolker



On 16-07-04 02:11 PM, Malcolm Fairbrother wrote:
> Hi Ben,
> This thread is relevant in this regard:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024241.html
> At least on my machine, I found a substantial difference in the
> parameter estimates. The second form seemed more reliable than the
> first, as you'll see from the thread.
> Do you get the same result?
> Best wishes,
> Malcolm
> 
> 
> 
>     Date: Sat, 2 Jul 2016 13:06:30 -0400
>     From: Ben Bolker <bbolker at gmail.com <mailto:bbolker at gmail.com>>
>     To: r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>
>     Subject: Re: [R-sig-ME] Specifying outcome variable in binomial glmm:
>             single responses vs cbind?
> 
> 
> 
>     On 16-07-01 07:37 PM, a y wrote:
>     > What is the difference between fitting a binomial glmm (without
>     random item
>     > effects) in the following two ways?
>     >
>     > 1.
>     > Data formatted in the following way:
>     >
>     > (data_long)
>     > ID    correct    condition    itemID
>     > 1      1             A               i1
>     > 1      0             A               i2
>     > 1      1             A               i3
>     > 1      1             A               i4
>     > 2      0             B               i1
>     > 2      1             B               i2
>     > 2      1             B               i3
>     > 2      0             B               i4
>     >
>     > Fitting a model without item random effects:
>     >
>     > glmer(correct ~ condition + (1|ID), family = binomial, data =
>     data_long)
>     >
>     >
>     > 2.
>     > Data formatted this way (summing over the correct responses):
>     >
>     > (data_short)
>     > ID     sum_correct    condition     itemID
>     > 1       3                      A                NA
>     > 2       2                      B                NA
>     >
>     > Fitting the following model, assuming there were only 4 items 
>     (I've seen
>     > dozens of examples like this):
>     > glmer(cbind(sum_correct, 4 - sum_correct) ~ condition + (1|ID),
>     family =
>     > binomial, data = data_short)
>     >
>     > ---
>     > I figured these models should be identical, but in my experience
>     they are
>     > very much not. What am I missing? When is the second (more)
>     appropriate?
>     >
>     > Thanks for any help,
>     > Andrew
>     >
> 
>       I believe they should give different likelihoods but identical
>     parameter estimates, *differences* among likelihoods (i.e. among
>     competing models fitted with the same data), etc..  That is,
>     disaggregating the data leads to an extra additive constant in the
>     log-likelihood. I would be very interested to see a counter-example to
>     that statement!  In general, the second form should be quicker to fit,
>     provide residuals that are easier to interpret, etc..
>


From newboch at auburn.edu  Tue Jul  5 19:03:09 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Tue, 5 Jul 2016 17:03:09 +0000
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <1467419367279.31120@auburn.edu>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu>, <5776CA31.8090407@gmail.com>,
	<1467419367279.31120@auburn.edu>
Message-ID: <1467738189249.56708@auburn.edu>

Can aictabs be used in conjunction with the glmmTMB package and/or there any alternatives that will quickly accomplish the same thing? I've tried aictabs and does not seem to work at first attempt.

Chad
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
Sent: Friday, July 1, 2016 7:29 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

I had to use:

family=list(family="nbinom1", link="log")

in glmmTMB

whereas

family="nbinom1"

had previously worked in glmmADMB.  Thanks for pointing me towards examples.
________________________________________
From: Philipp Singer <killver at gmail.com>
Sent: Friday, July 1, 2016 2:53 PM
To: Chad Newbolt; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Exactly as you would do it in glmmADMB, just replace ADMB with TMB...

Check the github examples:
https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat

On 01.07.2016 21:47, Chad Newbolt wrote:
> Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.
>
> Chad
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
> Sent: Thursday, June 30, 2016 7:45 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
>
> Chad Newbolt <newboch at ...> writes:
>
> [snip]
>
>> Since I have evidence for overdispersion, I'm using negative
>> binomial distribution as opposed to Poisson.  My two questions are:
>> 1) When I fit using the following global zero inflation model I
>> receive the following error:
>> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
>    I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
>     data=datum,family="nbinom",zeroInflation = TRUE)
>
> I think you can shorten this a bit to
>
> (Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)
>
>> Parameters were estimated, but standard errors were not: the most
>> likely problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
>> Age * : The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and
>> inspect output files; (2) change run parameters: see
>> '?admbControl';(3) re-run with debug=TRUE for more information on
>> failure mode In addition: Warning message: running command
>> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
>> -shess' had status 1
>> However, when I change to zeroInflation = FALSE, I receive no
>>   warnings and everything seems to go as should.
>> Does this simply mean that my data is not zero inflated, hence the
>> zero inflated model will not run, or is this something I should be
>> concerned about and investigate the cause further?  When I debug I
>> see the following warning....Warning -- Hessian does not appear to
>> be positive definite Hessian does not appear to be positive
>> definite.
>> 2) When fitting more simple versions(predictors removed) I receive
>> the same error as above when using the family=nbinom; however these
>> errors disappear when using family=nbinom1.  Is this indicative of
>> an underlying problem or am I OK to use the ouput from the later
>> family where variance = ??.  Thanks, Chad [[alternative HTML version
>> deleted]]
>    Short answer: you should be a little concerned, and you should
> not assume that your data are not zero-inflated. These are not
> indications about what your model is actually finding, just indications
> that ADMB ran into *some* kind of trouble. Unfortunately,
> there is no really simple guide to trouble-shooting these kinds of
> problems.  Some general suggestions:
>
> * try out the glmmTMB package - it's newer/experimental, but
> often more stable
> * the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
> * it may not help in this case, but centering continuous predictors is
> always worth a shot
> * similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
> * inspect your data graphically to see whether there are outliers
> or other odd patterns that might be messing up the fit
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mbrooks at ufl.edu  Tue Jul  5 19:10:27 2016
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Tue, 5 Jul 2016 19:10:27 +0200
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <1467738189249.56708@auburn.edu>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu> <5776CA31.8090407@gmail.com>
	<1467419367279.31120@auburn.edu> <1467738189249.56708@auburn.edu>
Message-ID: <55DA7E66-1AF6-4C46-BAAA-5E87FB3998C9@ufl.edu>

Hi Chad,

I?ve been using AICtab from the bbmle package. If you have any NAs, you may need to be vigilant that the various models really are using the same data. I haven?t carefully checked that part of the functionality yet.

cheers,
Mollie

------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/


> On 5Jul 2016, at 19:03, Chad Newbolt <newboch at auburn.edu> wrote:
> 
> Can aictabs be used in conjunction with the glmmTMB package and/or there any alternatives that will quickly accomplish the same thing? I've tried aictabs and does not seem to work at first attempt.
> 
> Chad
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Chad Newbolt <newboch at auburn.edu>
> Sent: Friday, July 1, 2016 7:29 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
> 
> I had to use:
> 
> family=list(family="nbinom1", link="log")
> 
> in glmmTMB
> 
> whereas
> 
> family="nbinom1"
> 
> had previously worked in glmmADMB.  Thanks for pointing me towards examples.
> ________________________________________
> From: Philipp Singer <killver at gmail.com>
> Sent: Friday, July 1, 2016 2:53 PM
> To: Chad Newbolt; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
> 
> Exactly as you would do it in glmmADMB, just replace ADMB with TMB...
> 
> Check the github examples:
> https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat
> 
> On 01.07.2016 21:47, Chad Newbolt wrote:
>> Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.
>> 
>> Chad
>> ________________________________________
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
>> Sent: Thursday, June 30, 2016 7:45 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
>> 
>> Chad Newbolt <newboch at ...> writes:
>> 
>> [snip]
>> 
>>> Since I have evidence for overdispersion, I'm using negative
>>> binomial distribution as opposed to Poisson.  My two questions are:
>>> 1) When I fit using the following global zero inflation model I
>>> receive the following error:
>>> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
>>   I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
>>    data=datum,family="nbinom",zeroInflation = TRUE)
>> 
>> I think you can shorten this a bit to
>> 
>> (Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)
>> 
>>> Parameters were estimated, but standard errors were not: the most
>>> likely problem is that the curvature at MLE was zero or negative
>>> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
>>> Age * : The function maximizer failed (couldn't find parameter file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and
>>> inspect output files; (2) change run parameters: see
>>> '?admbControl';(3) re-run with debug=TRUE for more information on
>>> failure mode In addition: Warning message: running command
>>> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
>>> -shess' had status 1
>>> However, when I change to zeroInflation = FALSE, I receive no
>>>  warnings and everything seems to go as should.
>>> Does this simply mean that my data is not zero inflated, hence the
>>> zero inflated model will not run, or is this something I should be
>>> concerned about and investigate the cause further?  When I debug I
>>> see the following warning....Warning -- Hessian does not appear to
>>> be positive definite Hessian does not appear to be positive
>>> definite.
>>> 2) When fitting more simple versions(predictors removed) I receive
>>> the same error as above when using the family=nbinom; however these
>>> errors disappear when using family=nbinom1.  Is this indicative of
>>> an underlying problem or am I OK to use the ouput from the later
>>> family where variance = ??.  Thanks, Chad [[alternative HTML version
>>> deleted]]
>>   Short answer: you should be a little concerned, and you should
>> not assume that your data are not zero-inflated. These are not
>> indications about what your model is actually finding, just indications
>> that ADMB ran into *some* kind of trouble. Unfortunately,
>> there is no really simple guide to trouble-shooting these kinds of
>> problems.  Some general suggestions:
>> 
>> * try out the glmmTMB package - it's newer/experimental, but
>> often more stable
>> * the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
>> * it may not help in this case, but centering continuous predictors is
>> always worth a shot
>> * similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
>> * inspect your data graphically to see whether there are outliers
>> or other odd patterns that might be messing up the fit
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Tue Jul  5 22:59:20 2016
From: drmccloy at uw.edu (Daniel McCloy)
Date: Tue, 5 Jul 2016 13:59:20 -0700
Subject: [R-sig-ME] afex package & bootstrapping
Message-ID: <577C1FA8.6090701@uw.edu>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

I'm using afex to get bootstrapped p-values. The model fit is quite
fast, but the bootstrapped p-values are taking forever and I wonder if
I'm doing something stupid.  Relevant details from the model summary:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
Family: binomial  ( probit )
Formula: press ~ truth * revb * gend * attn + (1 | subj)
Number of obs: 20480, groups:  subj, 16

I set the script to use all 12 cores of my local machine and run over
the weekend:

library(afex)
library(parallel)
cl <- makeForkCluster(nnodes=12, outfile="cluster-log.txt")
form <- formula(press ~ truth*revb*gend*attn + (1|subj))
rev_mod <- mixed(form, data=revb_df, family=binomial(link="probit"),
                 method="PB", check.contrasts=FALSE, cl=cl,
                 args.test=list(nsim=1000, cl=cl, seed=1234, details=2),
                 control=glmerControl(optCtrl=list(maxfun=30000)))

After running for 3.5 days, all 12 cores are still maxed out, RAM usage
looks fine (around 16GB in use of the 32GB total), and the afex output
looks like this:

Fitting 16 (g)lmer() models.
Obtaining 15 p-values:
[Reference distribution with   996 samples; computing time: 159891.87 secs.
.

(the single period on the 4th line is part of the output).  The first 2
lines appeared before I left work on friday (i.e., within about 15
minutes of starting the script).  So presumably it has been working on
the p-values for the remaining 80+ hours.  I don't know exactly when the
"computing time" line appeared, but its estimate works out to about 44
hours...  is that just for the first of the 15 p-values, or for all of
them?  Is creating a cluster with all 12 cores a foolish idea?  (Am I
thereby strangling the multithreading abilities of some underlying
linalg library, effectively slowing things down?)  The dataset and
number of iterations just don't seem all that huge to me but maybe I'm
being naive.

- -- dan

Daniel McCloy
http://dan.mccloy.info
Postdoctoral Research Associate
Institute for Learning & Brain Sciences
University of Washington
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXfB+cAAoJEEzlbMQqUVLOIuUH/Rb920Pcbedb6WaudG0KyifM
T3hQEALxFLyHttrbRAC1CrHgD4XClrTNQJGs3jcr+F23T/JYaR1jizFJ6SOBLi5i
niB+F5z2nD5yLsYSAHvvvfkcHTGCsFmUwp2tvThxYySAjehpzKzcm30ZSVcZH3qN
VpaWR0fBH3rmqwiUqE6IT3Nbt+wV9F2G/SK+wyX9waSwRN1SpiiCwQ1AIxU5s6SI
BSRL96nBLf93OLUgGZ22Lvu9w/AR7xNT6uNE2R9XdSMWF7/u+/eEgw/GVDWe+1l+
NYKN28qoynBeEagMfeZt+JCq6OG9yIWv4z6cE7EpPtTbxMqebrIQUrFU4uIGoAI=
=nuKw
-----END PGP SIGNATURE-----


From singmann at psychologie.uzh.ch  Wed Jul  6 14:04:40 2016
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Wed, 6 Jul 2016 14:04:40 +0200
Subject: [R-sig-ME] afex package & bootstrapping
In-Reply-To: <577C1FA8.6090701@uw.edu>
References: <577C1FA8.6090701@uw.edu>
Message-ID: <4998a65d-a228-a1b2-5e86-0a8ad14f66b2@psychologie.uzh.ch>

Hi Dan,

Your code looks reasonable to me. details = 2 is probably responsible 
for the following message which shows you the time it took to calculate 
the reference distribution for the first p-value:
"Reference distribution with   996 samples; computing time: 159891.87 secs."

The one period in the output also shows you that the first of 15 
p-values has been successfully calculated and the next is being calculating.

So it seems that calculating the reference distribution for the first 
p-values took around 44 hours on your 12 cores.

Unfortunately, the speed up by using parallel computation is not linear 
when calculating the reference distribution using pbkrtest::PBmodcomp 
(which mixed uses as for the computation). This is most likely due to 
the fact that some models sometimes are faster than others and then the 
cores idle before starting with the next model until all cores can start 
the next model (I didn't look at the code of PBmodcomp, but that seems 
somewhat likely).

On my 8 cores one can nevertheless see a considerable speed up when 
using multicore compared to when not, using an example model (16 samples 
is obviously a stupid example):

require(afex)
require("mlmRev")
require(parallel)
(nc <- detectCores()) # 8 in my case
cl <- makeCluster(rep("localhost", nc))

mixed(use ~ age + I(age^2) + urban + livch + (1 | district), family = 
binomial, method = "PB", data = Contraception, args.test = list(nsim = 
16, cl = cl, details = 2))

## Contrasts set to contr.sum for the following variables: use, urban, 
livch, district
## Numerical variables NOT centered on 0 (i.e., interpretation of all 
main effects might be difficult if in interactions): age
## Fitting 5 (g)lmer() models:
## [.....]
## Obtaining 4 p-values:
## [Reference distribution with    16 samples; computing time: 33.29 secs.
## .Reference distribution with    16 samples; computing time: 37.25 secs.
## .Reference distribution with    16 samples; computing time: 41.06 secs.
## .Reference distribution with    16 samples; computing time: 27.92 secs.
## .]

mixed(use ~ age + I(age^2) + urban + livch + (1 | district), family = 
binomial, method = "PB", data = Contraception, args.test = list(nsim = 
16, details = 2))
## Contrasts set to contr.sum for the following variables: use, urban, 
livch, district
## Numerical variables NOT centered on 0 (i.e., interpretation of all 
main effects might be difficult if in interactions): age
## Fitting 5 (g)lmer() models:
## [.....]
## Obtaining 4 p-values:
## [Reference distribution with    16 samples; computing time: 143.49 secs.
## .Reference distribution with    16 samples; computing time: 201.51 secs.
## .Reference distribution with    16 samples; computing time: 185.76 secs.
## .Reference distribution with    16 samples; computing time: 120.80 secs.
## .]


You can see a speed up from around 150 to 35 seconds per p-value which 
corresponds to around a fourfold increase in speed, but not anywhere 
near an eightfold increase. So you cannot do much other than wait if you 
want to use parametric bootstrap and not e.g., "LRT" (or use a machine 
with more cores, but given the assumed problem, the speed up will most 
likely be less and less).

Hope that helps,
Henrik  (author of afex)



Am 05.07.2016 um 22:59 schrieb Daniel McCloy:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> I'm using afex to get bootstrapped p-values. The model fit is quite
> fast, but the bootstrapped p-values are taking forever and I wonder if
> I'm doing something stupid.  Relevant details from the model summary:
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> Family: binomial  ( probit )
> Formula: press ~ truth * revb * gend * attn + (1 | subj)
> Number of obs: 20480, groups:  subj, 16
>
> I set the script to use all 12 cores of my local machine and run over
> the weekend:
>
> library(afex)
> library(parallel)
> cl <- makeForkCluster(nnodes=12, outfile="cluster-log.txt")
> form <- formula(press ~ truth*revb*gend*attn + (1|subj))
> rev_mod <- mixed(form, data=revb_df, family=binomial(link="probit"),
>                  method="PB", check.contrasts=FALSE, cl=cl,
>                  args.test=list(nsim=1000, cl=cl, seed=1234, details=2),
>                  control=glmerControl(optCtrl=list(maxfun=30000)))
>
> After running for 3.5 days, all 12 cores are still maxed out, RAM usage
> looks fine (around 16GB in use of the 32GB total), and the afex output
> looks like this:
>
> Fitting 16 (g)lmer() models.
> Obtaining 15 p-values:
> [Reference distribution with   996 samples; computing time: 159891.87 secs.
> .
>
> (the single period on the 4th line is part of the output).  The first 2
> lines appeared before I left work on friday (i.e., within about 15
> minutes of starting the script).  So presumably it has been working on
> the p-values for the remaining 80+ hours.  I don't know exactly when the
> "computing time" line appeared, but its estimate works out to about 44
> hours...  is that just for the first of the 15 p-values, or for all of
> them?  Is creating a cluster with all 12 cores a foolish idea?  (Am I
> thereby strangling the multithreading abilities of some underlying
> linalg library, effectively slowing things down?)  The dataset and
> number of iterations just don't seem all that huge to me but maybe I'm
> being naive.
>
> - -- dan
>
> Daniel McCloy
> http://dan.mccloy.info
> Postdoctoral Research Associate
> Institute for Learning & Brain Sciences
> University of Washington
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXfB+cAAoJEEzlbMQqUVLOIuUH/Rb920Pcbedb6WaudG0KyifM
> T3hQEALxFLyHttrbRAC1CrHgD4XClrTNQJGs3jcr+F23T/JYaR1jizFJ6SOBLi5i
> niB+F5z2nD5yLsYSAHvvvfkcHTGCsFmUwp2tvThxYySAjehpzKzcm30ZSVcZH3qN
> VpaWR0fBH3rmqwiUqE6IT3Nbt+wV9F2G/SK+wyX9waSwRN1SpiiCwQ1AIxU5s6SI
> BSRL96nBLf93OLUgGZ22Lvu9w/AR7xNT6uNE2R9XdSMWF7/u+/eEgw/GVDWe+1l+
> NYKN28qoynBeEagMfeZt+JCq6OG9yIWv4z6cE7EpPtTbxMqebrIQUrFU4uIGoAI=
> =nuKw
> -----END PGP SIGNATURE-----
>


From newboch at auburn.edu  Wed Jul  6 15:21:36 2016
From: newboch at auburn.edu (Chad Newbolt)
Date: Wed, 6 Jul 2016 13:21:36 +0000
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <55DA7E66-1AF6-4C46-BAAA-5E87FB3998C9@ufl.edu>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu>
	<5776CA31.8090407@gmail.com> <1467419367279.31120@auburn.edu>
	<1467738189249.56708@auburn.edu>,
	<55DA7E66-1AF6-4C46-BAAA-5E87FB3998C9@ufl.edu>
Message-ID: <1467811296646.22435@auburn.edu>

Which graphical package is recommended to be used in conjunction with glmmTMB?  ggplot2?  Specifically, I would like to use the predict function but have been having a few issues.  As stated, I'm a relative novice with R (even more so with graphical packages in R) and trying to learn largely on my own so please excuse simplicity of questions.



Thanks,



Chad

________________________________
From: Mollie Brooks <mbrooks at ufl.edu>
Sent: Tuesday, July 5, 2016 12:10 PM
To: Chad Newbolt
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Hi Chad,

I?ve been using AICtab from the bbmle package. If you have any NAs, you may need to be vigilant that the various models really are using the same data. I haven?t carefully checked that part of the functionality yet.

cheers,
Mollie

------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/


On 5Jul 2016, at 19:03, Chad Newbolt <newboch at auburn.edu<mailto:newboch at auburn.edu>> wrote:

Can aictabs be used in conjunction with the glmmTMB package and/or there any alternatives that will quickly accomplish the same thing? I've tried aictabs and does not seem to work at first attempt.

Chad
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Chad Newbolt <newboch at auburn.edu<mailto:newboch at auburn.edu>>
Sent: Friday, July 1, 2016 7:29 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

I had to use:

family=list(family="nbinom1", link="log")

in glmmTMB

whereas

family="nbinom1"

had previously worked in glmmADMB.  Thanks for pointing me towards examples.
________________________________________
From: Philipp Singer <killver at gmail.com<mailto:killver at gmail.com>>
Sent: Friday, July 1, 2016 2:53 PM
To: Chad Newbolt; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Exactly as you would do it in glmmADMB, just replace ADMB with TMB...

Check the github examples:
https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat

On 01.07.2016 21:47, Chad Newbolt wrote:
Thanks so much for the response.  I know this is probably very simple but how do I denote the family as negative binomial using glmmTMB?  I've dug through text regarding this package and have had trouble coming up with anything that works.

Chad
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Thursday, June 30, 2016 7:45 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb

Chad Newbolt <newboch at ...> writes:

[snip]

Since I have evidence for overdispersion, I'm using negative
binomial distribution as opposed to Poisson.  My two questions are:
1) When I fit using the following global zero inflation model I
receive the following error:
fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+
  I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire),
   data=datum,family="nbinom",zeroInflation = TRUE)

I think you can shorten this a bit to

(Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)

Parameters were estimated, but standard errors were not: the most
likely problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge +
Age * : The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and
inspect output files; (2) change run parameters: see
'?admbControl';(3) re-run with debug=TRUE for more information on
failure mode In addition: Warning message: running command
'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit
-shess' had status 1
However, when I change to zeroInflation = FALSE, I receive no
 warnings and everything seems to go as should.
Does this simply mean that my data is not zero inflated, hence the
zero inflated model will not run, or is this something I should be
concerned about and investigate the cause further?  When I debug I
see the following warning....Warning -- Hessian does not appear to
be positive definite Hessian does not appear to be positive
definite.
2) When fitting more simple versions(predictors removed) I receive
the same error as above when using the family=nbinom; however these
errors disappear when using family=nbinom1.  Is this indicative of
an underlying problem or am I OK to use the ouput from the later
family where variance = ??.  Thanks, Chad [[alternative HTML version
deleted]]
  Short answer: you should be a little concerned, and you should
not assume that your data are not zero-inflated. These are not
indications about what your model is actually finding, just indications
that ADMB ran into *some* kind of trouble. Unfortunately,
there is no really simple guide to trouble-shooting these kinds of
problems.  Some general suggestions:

* try out the glmmTMB package - it's newer/experimental, but
often more stable
* the ?admbControl man page suggests trying shess=FALSE and noinit=FALSE
* it may not help in this case, but centering continuous predictors is
always worth a shot
* similarly, poly(Age,2) is a little more stable than (Age+I(Age^2))
* inspect your data graphically to see whether there are outliers
or other odd patterns that might be messing up the fit

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jul  6 17:27:50 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Jul 2016 11:27:50 -0400
Subject: [R-sig-ME] Negative Binomial in glmmadmb
In-Reply-To: <1467811296646.22435@auburn.edu>
References: <1467301244612.45391@auburn.edu>
	<loom.20160701T023605-704@post.gmane.org>
	<1467402458879.39049@auburn.edu>
	<5776CA31.8090407@gmail.com> <1467419367279.31120@auburn.edu>
	<1467738189249.56708@auburn.edu>
	<55DA7E66-1AF6-4C46-BAAA-5E87FB3998C9@ufl.edu>
	<1467811296646.22435@auburn.edu>
Message-ID: <577D2376.6000203@gmail.com>


  I guess the question is what you want to plot ... do you want to plot
graphical diagnostics (Q-Q, residuals vs fitted, etc.) as in the
standard R plot.* methods for models, predictions, effects, ... ?

   Keep in mind that glmmTMB is brand new -- if you're having issues
with the predictions, you should probably let the developers know what
they are by posting an issue at
https://github.com/glmmTMB/glmmTMB/issues ...

   cheers
      Ben Bolker

On 16-07-06 09:21 AM, Chad Newbolt wrote:
> Which graphical package is recommended to be used in conjunction with
> glmmTMB?  ggplot2?  Specifically, I would like to use the predict
> function but have been having a few issues.  As stated, I'm a
> relative novice with R (even more so with graphical packages in R)
> and trying to learn largely on my own so please excuse simplicity of
> questions.
> 
> 
> 
> Thanks,
> 
> 
> 
> Chad
> 
> ________________________________ From: Mollie Brooks
> <mbrooks at ufl.edu> Sent: Tuesday, July 5, 2016 12:10 PM To: Chad
> Newbolt Cc: r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME]
> Negative Binomial in glmmadmb
> 
> Hi Chad,
> 
> I?ve been using AICtab from the bbmle package. If you have any NAs,
> you may need to be vigilant that the various models really are using
> the same data. I haven?t carefully checked that part of the
> functionality yet.
> 
> cheers, Mollie
> 
> ------------------------ Mollie Brooks, PhD Postdoctoral Researcher,
> Population Ecology Research Group Department of Evolutionary Biology
> & Environmental Studies, University of Z?rich 
> http://www.popecol.org/team/mollie-brooks/
> 
> 
> On 5Jul 2016, at 19:03, Chad Newbolt
> <newboch at auburn.edu<mailto:newboch at auburn.edu>> wrote:
> 
> Can aictabs be used in conjunction with the glmmTMB package and/or
> there any alternatives that will quickly accomplish the same thing?
> I've tried aictabs and does not seem to work at first attempt.
> 
> Chad ________________________________________ From:
> R-sig-mixed-models
> <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>>
> on behalf of Chad Newbolt
> <newboch at auburn.edu<mailto:newboch at auburn.edu>> Sent: Friday, July 1,
> 2016 7:29 PM To:
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>
> 
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
> 
> I had to use:
> 
> family=list(family="nbinom1", link="log")
> 
> in glmmTMB
> 
> whereas
> 
> family="nbinom1"
> 
> had previously worked in glmmADMB.  Thanks for pointing me towards
> examples. ________________________________________ From: Philipp
> Singer <killver at gmail.com<mailto:killver at gmail.com>> Sent: Friday,
> July 1, 2016 2:53 PM To: Chad Newbolt;
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>
> 
Subject: Re: [R-sig-ME] Negative Binomial in glmmadmb
> 
> Exactly as you would do it in glmmADMB, just replace ADMB with
> TMB...
> 
> Check the github examples: 
> https://github.com/glmmTMB/glmmTMB/tree/master/glmmTMB/tests/testthat
>
>  On 01.07.2016 21:47, Chad Newbolt wrote: Thanks so much for the
> response.  I know this is probably very simple but how do I denote
> the family as negative binomial using glmmTMB?  I've dug through text
> regarding this package and have had trouble coming up with anything
> that works.
> 
> Chad ________________________________________ From:
> R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com> Sent: Thursday, June 30,
> 2016 7:45 PM To: r-sig-mixed-models at r-project.org Subject: Re:
> [R-sig-ME] Negative Binomial in glmmadmb
> 
> Chad Newbolt <newboch at ...> writes:
> 
> [snip]
> 
> Since I have evidence for overdispersion, I'm using negative binomial
> distribution as opposed to Poisson.  My two questions are: 1) When I
> fit using the following global zero inflation model I receive the
> following error: 
> fit1=glmmadmb(Fawn~Age+I(Age^2)+BodySize+SSCM+AvgAge+Age*AvgAge+ 
> I(Age^2)*AvgAge+BodySize*AvgAge+SSCM*AvgAge+(1|Sire), 
> data=datum,family="nbinom",zeroInflation = TRUE)
> 
> I think you can shorten this a bit to
> 
> (Age+I(Age^2)+BodySize+SSCM)*AvgAge + (1|Sire)
> 
> Parameters were estimated, but standard errors were not: the most 
> likely problem is that the curvature at MLE was zero or negative 
> Error in glmmadmb(Fawn ~ Age + I(Age^2) + BodySize + SSCM + AvgAge + 
> Age * : The function maximizer failed (couldn't find parameter file) 
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3)
> re-run with debug=TRUE for more information on failure mode In
> addition: Warning message: running command 
> 'C:\windows\system32\cmd.exe /c glmmadmb -maxfn 500 -maxph 5 -noinit 
> -shess' had status 1 However, when I change to zeroInflation = FALSE,
> I receive no warnings and everything seems to go as should. Does this
> simply mean that my data is not zero inflated, hence the zero
> inflated model will not run, or is this something I should be 
> concerned about and investigate the cause further?  When I debug I 
> see the following warning....Warning -- Hessian does not appear to be
> positive definite Hessian does not appear to be positive definite. 2)
> When fitting more simple versions(predictors removed) I receive the
> same error as above when using the family=nbinom; however these 
> errors disappear when using family=nbinom1.  Is this indicative of an
> underlying problem or am I OK to use the ouput from the later family
> where variance = ??.  Thanks, Chad [[alternative HTML version 
> deleted]] Short answer: you should be a little concerned, and you
> should not assume that your data are not zero-inflated. These are
> not indications about what your model is actually finding, just
> indications that ADMB ran into *some* kind of trouble.
> Unfortunately, there is no really simple guide to trouble-shooting
> these kinds of problems.  Some general suggestions:
> 
> * try out the glmmTMB package - it's newer/experimental, but often
> more stable * the ?admbControl man page suggests trying shess=FALSE
> and noinit=FALSE * it may not help in this case, but centering
> continuous predictors is always worth a shot * similarly, poly(Age,2)
> is a little more stable than (Age+I(Age^2)) * inspect your data
> graphically to see whether there are outliers or other odd patterns
> that might be messing up the fit
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From joaquin.aldabe at gmail.com  Thu Jul  7 20:17:32 2016
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 7 Jul 2016 15:17:32 -0300
Subject: [R-sig-ME] correlated samples
Message-ID: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>

Dear all, I?m a basic user of mixed models but there are things that I?ve
found hard to understand. On of these is how the model solves the
correlations among samples taken in the same site or levels of other kind
of grouping variable.

I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and part
of Pinheiro and Bates (2000). But still don?t understand the way that GLMM
include the correlation effect in the predictions of the model.

I really appreciate any comment and/or bibliographic reference that help me
understand this.

Thanks in advanced,
Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Thu Jul  7 23:58:40 2016
From: hannah.hlx at gmail.com (li li)
Date: Thu, 7 Jul 2016 17:58:40 -0400
Subject: [R-sig-ME] Fixed Effects in lme function
Message-ID: <CAHLnndY4vVhVGJer4sr4k1sSTasW3+ibJcZY2FvtcCtjAudCpw@mail.gmail.com>

 Dear all,
    For the data below, I would like to fit a model with common random
slope and  common random intercept as shown below. I am interested in
obtaining
separate fixed effect estimates (intercept and slope and corresponding
hypothesis test)
for each method. Instead of performing the analysis method by method, can I
use the syntax as below, specifically, the part "fixed = response ~
method/time"?
    I know this is legitimate specification if there is no random effects
involved.
   Thanks so much in advance!
      Hanna

lme(fixed= response ~ method/time, random=~ 1+time | lot, data=dat,
weights= varIdent(form=~1|method),   control = lmeControl(opt = "optim"),
na.action = na.exclude)



  response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Jul  8 14:02:59 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 8 Jul 2016 14:02:59 +0200
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
Message-ID: <CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>

Dear Joaquin,

I'd recommend Zuur et al 2009, section 5.4

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Dear all, I?m a basic user of mixed models but there are things that I?ve
> found hard to understand. On of these is how the model solves the
> correlations among samples taken in the same site or levels of other kind
> of grouping variable.
>
> I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and part
> of Pinheiro and Bates (2000). But still don?t understand the way that GLMM
> include the correlation effect in the predictions of the model.
>
> I really appreciate any comment and/or bibliographic reference that help me
> understand this.
>
> Thanks in advanced,
> Joaqu?n.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Sun Jul 10 01:20:23 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Sun, 10 Jul 2016 00:20:23 +0100
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
Message-ID: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>

Dear list members,

I am developing GLMM's in order to assess habitat selection (using GLMMs'
coeficients to construct Resource selection functions). I have (telemetry)
data from 5 study areas, and each area has a different number of
individuals monitored.

To develop GLMM's, the dependend variable is binary (1-used locations;
0-available locations), and I have a initial set of 14 continuous variables
(8 land cover variables; 2 distance variables, to artificial areas and
water sources; 4 topographic variables): a buffer was placed around each
location and the area of each land cover within that buffer was accounted
for; distances were measured from each point to the nearest feature, and
topographic variables were obtained using DEM rasters. I tested for
correlation using Spearman's Rank, so not all 14 were used in the GLMMs.
All variables were transformed using z-score.

As random effect, I used individual ID. I thought at the beggining to use
study area as a random effect but I only had 5 levels and there was almost
no variance when that random effect was used.

I constructed a GLMM with 9 variables (not correlated) and a random effect,
then used "dredge()" function and "model.avg(dredge)" to sort models by AIC
values. This was the result (only models of AICc lower than 2 represented):

[1]Call:
model.avg(object = dredge.m1.1)

Component model call:
glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
family =
     binomial(link = "logit"))

Component models:
          df   logLik    AICc  delta weight
123578     8 -4309.94 8635.89   0.00   0.14
1235789    9 -4309.22 8636.44   0.55   0.10
123789     8 -4310.52 8637.04   1.14   0.08
1235678    9 -4309.75 8637.50   1.61   0.06
12378      7 -4311.78 8637.57   1.67   0.06
1234578    9 -4309.79 8637.58   1.69   0.06

Variables 1 and 2 represent the distance variables; from 3 to 8 land cover
variables, and 9 is a topographic variable. Weights seem to be very low,
even if I average all those models as it seems to be common when delta
values are low. Even with this weights, I constructed GLMMs for each of the
combinations, and the results were simmilar for all 6 combinations. Here
are the results for the first one (GLMM + overdispersion + r-squared):

Random effects:
 Groups    Name        Variance Std.Dev.
 ID.CODE_1 (Intercept) 13.02    3.608
Number of obs: 32670, groups:  ID.CODE_1, 55

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.54891    0.51174  -1.073 0.283433
3       -0.22232    0.04059  -5.478 4.31e-08 ***
5       -0.05433    0.02837  -1.915 0.055460 .
7       -0.13108    0.02825  -4.640 3.49e-06 ***
8       -0.15864    0.08670  -1.830 0.067287 .
1         0.28438    0.02853   9.968  < 2e-16 ***
2         0.11531    0.03021   3.817 0.000135 ***
Residual deviance: 0.256
r.squaredGLMM():
       R2m        R2c
0.01063077 0.80039950
This is what I get from this analysis:

1) Variance and SD of the random effect seems fine (definitely better than
the "0" I got when using Study Areas as random effect);

2) Estimate values make sense from what I know of the species and the
knowledge I have of the study areas;

3) Overdispersion values seem good, and R-squared values don't seem very
good (at least when considering only fixed effects) but, as I read in
several places, AIC and r-squared are not always in agreement.

4) Weight values seem very low. Does it mean the models are not good?

Then what I did was construct a GLM ("glm()"), so no random effect was
used. I used the same set of variables used in [1], and here are the
results (only models of AICc lower than 2 represented):

[2] Call:
model.avg(object = dredge.glm_m1.1)

Component model call:
glm(formula = Used ~ <512 unique rhs>, family = binomial(link = "logit"),
data =
     All_SA_Used_RP_Area_z)

Component models:
          df   logLik     AICc   delta weight
12345678   9 -9251.85 18521.70    0.00   0.52
123456789 10 -9251.77 18523.54    1.84   0.21
1345678    8 -9253.84 18523.69    1.99   0.19

In this case, weight values are higher.

Does this mean that it is better not to use a random effect? (I am not sure
I can compare GLMM with GLM results, correct me if I am doing wrong
assumptions)

Thank you very much in advance for your time and help. I hope I made myself
clear enough so you can understand what I am asking!

Best regards,
Teresa

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Jul 11 02:58:19 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 Jul 2016 10:58:19 +1000
Subject: [R-sig-ME] Course in Alice Springs: Data exploration, regression,
	GLM & GAM
Message-ID: <906c4aef-28d3-9c29-d5e0-bb015ba7c53a@highstat.com>

We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with introduction to R
Where: Charles Darwin University, Alice Springs, Australia
When:   1-5 August 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_08AliceSprings_RGG.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email:highstat at highstat.com
URL:www.highstat.com


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jul 11 03:06:17 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 Jul 2016 21:06:17 -0400
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
 effects?
In-Reply-To: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
Message-ID: <5782F109.4000505@gmail.com>



On 16-07-09 07:20 PM, Teresa Oliveira wrote:
> Dear list members,
> 
> I am developing GLMM's in order to assess habitat selection (using GLMMs'
> coeficients to construct Resource selection functions). I have (telemetry)
> data from 5 study areas, and each area has a different number of
> individuals monitored.
> 
> To develop GLMM's, the dependend variable is binary (1-used locations;
> 0-available locations), and I have a initial set of 14 continuous variables
> (8 land cover variables; 2 distance variables, to artificial areas and
> water sources; 4 topographic variables): a buffer was placed around each
> location and the area of each land cover within that buffer was accounted
> for; distances were measured from each point to the nearest feature, and
> topographic variables were obtained using DEM rasters. I tested for
> correlation using Spearman's Rank, so not all 14 were used in the GLMMs.
> All variables were transformed using z-score.
> 
> As random effect, I used individual ID. I thought at the beggining to use
> study area as a random effect but I only had 5 levels and there was almost
> no variance when that random effect was used.
> 
> I constructed a GLMM with 9 variables (not correlated) and a random effect,
> then used "dredge()" function and "model.avg(dredge)" to sort models by AIC
> values. This was the result (only models of AICc lower than 2 represented):
> 
> [1]Call:
> model.avg(object = dredge.m1.1)
> 
> Component model call:
> glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
> family =
>      binomial(link = "logit"))
> 
> Component models:
>           df   logLik    AICc  delta weight
> 123578     8 -4309.94 8635.89   0.00   0.14
> 1235789    9 -4309.22 8636.44   0.55   0.10
> 123789     8 -4310.52 8637.04   1.14   0.08
> 1235678    9 -4309.75 8637.50   1.61   0.06
> 12378      7 -4311.78 8637.57   1.67   0.06
> 1234578    9 -4309.79 8637.58   1.69   0.06
> 
> Variables 1 and 2 represent the distance variables; from 3 to 8 land cover
> variables, and 9 is a topographic variable. Weights seem to be very low,
> even if I average all those models as it seems to be common when delta
> values are low. 

Well as far as we can tell from this, variables 4-9 aren't doing much
(on the other hand, variables 1-3 seem to be in all of the top models
you've shown us -- although presumably there are a bunch more models
that are almost like these, and similar in weight, with other
permutations of [123] + [some combination of 456789] ...)


Even with this weights, I constructed GLMMs for each of the
> combinations, and the results were simmilar for all 6 combinations. Here
> are the results for the first one (GLMM + overdispersion + r-squared):
> 
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  ID.CODE_1 (Intercept) 13.02    3.608
> Number of obs: 32670, groups:  ID.CODE_1, 55
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|),
> (Intercept) -0.54891    0.51174  -1.073 0.283433
> 3       -0.22232    0.04059  -5.478 4.31e-08 ***
> 5       -0.05433    0.02837  -1.915 0.055460 .
> 7       -0.13108    0.02825  -4.640 3.49e-06 ***
> 8       -0.15864    0.08670  -1.830 0.067287 .
> 1         0.28438    0.02853   9.968  < 2e-16 ***
> 2         0.11531    0.03021   3.817 0.000135 ***
> Residual deviance: 0.256
> r.squaredGLMM():
>        R2m        R2c
> 0.01063077 0.80039950
> This is what I get from this analysis:
> 
> 1) Variance and SD of the random effect seems fine (definitely better than
> the "0" I got when using Study Areas as random effect);

  yes -- SD of the random effects is much larger than any of the fixed
effects, which means that the differences among individuals are large
(presumably that means you have very different numbers of presences for
different number of individuals [all individuals sharing a common pool
of pseudo-absences ???)
> 
> 2) Estimate values make sense from what I know of the species and the
> knowledge I have of the study areas;

  Good!
> 
> 3) Overdispersion values seem good, and R-squared values don't seem very
> good (at least when considering only fixed effects) but, as I read in
> several places, AIC and r-squared are not always in agreement.

  Overdispersion is meaningless for binary data.
> 
> 4) Weight values seem very low. Does it mean the models are not good?

  It means there are many approximately equivalent models.  Nothing in
this output tells you very much about absolute goodness of fit (which is
tricky for binary data).
> 
> Then what I did was construct a GLM ("glm()"), so no random effect was
> used. I used the same set of variables used in [1], and here are the
> results (only models of AICc lower than 2 represented):
> 
> [2] Call:
> model.avg(object = dredge.glm_m1.1)
> 
> Component model call:
> glm(formula = Used ~ <512 unique rhs>, family = binomial(link = "logit"),
> data =
>      All_SA_Used_RP_Area_z)
> 
> Component models:
>           df   logLik     AICc   delta weight
> 12345678   9 -9251.85 18521.70    0.00   0.52
> 123456789 10 -9251.77 18523.54    1.84   0.21
> 1345678    8 -9253.84 18523.69    1.99   0.19
> 
> In this case, weight values are higher.
> 
> Does this mean that it is better not to use a random effect? (I am not sure
> I can compare GLMM with GLM results, correct me if I am doing wrong
> assumptions)

  No.  You could do a likelihood ratio test with anova(), but note that
the AICc values for the glm() fits are 10,000 (!!) units higher than the
glmer fits.

  While it will potentially greatly complicate your life, I think you
should at least *consider* interactions between your environment
variables and ID, i.e. allow for the possibility that different
individuals respond differently to habitat variation.

  Ben Bolker


From cdemars at ualberta.ca  Mon Jul 11 04:15:00 2016
From: cdemars at ualberta.ca (Craig DeMars)
Date: Sun, 10 Jul 2016 20:15:00 -0600
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
In-Reply-To: <5782F109.4000505@gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
	<5782F109.4000505@gmail.com>
Message-ID: <CAM1YihCCBTz=5LSoHd9x7cm64Ce2Xq_UreebU17F4KzaCV-EtA@mail.gmail.com>

I would add some caution when interpreting the estimated values when using
random-intercept only GLMMs for RSFs. The standard errors for the fixed
effects do not reflect the animal as the sampling unit (see Schielzeth and
Forstmeier 2009).  Thus, if your objective is to make inference to the
larger population of animals, the standard errors for the fixed effects are
far too narrow (i.e. overconfident). It is more appropriate to use 2-stage
approaches or GLMMs that use random slopes for the variables of interest.

Random-intercept only models are somewhat abused in the RSF literature in
this regard, in my opinion......

On Sun, Jul 10, 2016 at 7:06 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 16-07-09 07:20 PM, Teresa Oliveira wrote:
> > Dear list members,
> >
> > I am developing GLMM's in order to assess habitat selection (using GLMMs'
> > coeficients to construct Resource selection functions). I have
> (telemetry)
> > data from 5 study areas, and each area has a different number of
> > individuals monitored.
> >
> > To develop GLMM's, the dependend variable is binary (1-used locations;
> > 0-available locations), and I have a initial set of 14 continuous
> variables
> > (8 land cover variables; 2 distance variables, to artificial areas and
> > water sources; 4 topographic variables): a buffer was placed around each
> > location and the area of each land cover within that buffer was accounted
> > for; distances were measured from each point to the nearest feature, and
> > topographic variables were obtained using DEM rasters. I tested for
> > correlation using Spearman's Rank, so not all 14 were used in the GLMMs.
> > All variables were transformed using z-score.
> >
> > As random effect, I used individual ID. I thought at the beggining to use
> > study area as a random effect but I only had 5 levels and there was
> almost
> > no variance when that random effect was used.
> >
> > I constructed a GLMM with 9 variables (not correlated) and a random
> effect,
> > then used "dredge()" function and "model.avg(dredge)" to sort models by
> AIC
> > values. This was the result (only models of AICc lower than 2
> represented):
> >
> > [1]Call:
> > model.avg(object = dredge.m1.1)
> >
> > Component model call:
> > glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
> > family =
> >      binomial(link = "logit"))
> >
> > Component models:
> >           df   logLik    AICc  delta weight
> > 123578     8 -4309.94 8635.89   0.00   0.14
> > 1235789    9 -4309.22 8636.44   0.55   0.10
> > 123789     8 -4310.52 8637.04   1.14   0.08
> > 1235678    9 -4309.75 8637.50   1.61   0.06
> > 12378      7 -4311.78 8637.57   1.67   0.06
> > 1234578    9 -4309.79 8637.58   1.69   0.06
> >
> > Variables 1 and 2 represent the distance variables; from 3 to 8 land
> cover
> > variables, and 9 is a topographic variable. Weights seem to be very low,
> > even if I average all those models as it seems to be common when delta
> > values are low.
>
> Well as far as we can tell from this, variables 4-9 aren't doing much
> (on the other hand, variables 1-3 seem to be in all of the top models
> you've shown us -- although presumably there are a bunch more models
> that are almost like these, and similar in weight, with other
> permutations of [123] + [some combination of 456789] ...)
>
>
> Even with this weights, I constructed GLMMs for each of the
> > combinations, and the results were simmilar for all 6 combinations. Here
> > are the results for the first one (GLMM + overdispersion + r-squared):
> >
> > Random effects:
> >  Groups    Name        Variance Std.Dev.
> >  ID.CODE_1 (Intercept) 13.02    3.608
> > Number of obs: 32670, groups:  ID.CODE_1, 55
> >
> > Fixed effects:
> >             Estimate Std. Error z value Pr(>|z|),
> > (Intercept) -0.54891    0.51174  -1.073 0.283433
> > 3       -0.22232    0.04059  -5.478 4.31e-08 ***
> > 5       -0.05433    0.02837  -1.915 0.055460 .
> > 7       -0.13108    0.02825  -4.640 3.49e-06 ***
> > 8       -0.15864    0.08670  -1.830 0.067287 .
> > 1         0.28438    0.02853   9.968  < 2e-16 ***
> > 2         0.11531    0.03021   3.817 0.000135 ***
> > Residual deviance: 0.256
> > r.squaredGLMM():
> >        R2m        R2c
> > 0.01063077 0.80039950
> > This is what I get from this analysis:
> >
> > 1) Variance and SD of the random effect seems fine (definitely better
> than
> > the "0" I got when using Study Areas as random effect);
>
>   yes -- SD of the random effects is much larger than any of the fixed
> effects, which means that the differences among individuals are large
> (presumably that means you have very different numbers of presences for
> different number of individuals [all individuals sharing a common pool
> of pseudo-absences ???)
> >
> > 2) Estimate values make sense from what I know of the species and the
> > knowledge I have of the study areas;
>
>   Good!
> >
> > 3) Overdispersion values seem good, and R-squared values don't seem very
> > good (at least when considering only fixed effects) but, as I read in
> > several places, AIC and r-squared are not always in agreement.
>
>   Overdispersion is meaningless for binary data.
> >
> > 4) Weight values seem very low. Does it mean the models are not good?
>
>   It means there are many approximately equivalent models.  Nothing in
> this output tells you very much about absolute goodness of fit (which is
> tricky for binary data).
> >
> > Then what I did was construct a GLM ("glm()"), so no random effect was
> > used. I used the same set of variables used in [1], and here are the
> > results (only models of AICc lower than 2 represented):
> >
> > [2] Call:
> > model.avg(object = dredge.glm_m1.1)
> >
> > Component model call:
> > glm(formula = Used ~ <512 unique rhs>, family = binomial(link = "logit"),
> > data =
> >      All_SA_Used_RP_Area_z)
> >
> > Component models:
> >           df   logLik     AICc   delta weight
> > 12345678   9 -9251.85 18521.70    0.00   0.52
> > 123456789 10 -9251.77 18523.54    1.84   0.21
> > 1345678    8 -9253.84 18523.69    1.99   0.19
> >
> > In this case, weight values are higher.
> >
> > Does this mean that it is better not to use a random effect? (I am not
> sure
> > I can compare GLMM with GLM results, correct me if I am doing wrong
> > assumptions)
>
>   No.  You could do a likelihood ratio test with anova(), but note that
> the AICc values for the glm() fits are 10,000 (!!) units higher than the
> glmer fits.
>
>   While it will potentially greatly complicate your life, I think you
> should at least *consider* interactions between your environment
> variables and ID, i.e. allow for the possibility that different
> individuals respond differently to habitat variation.
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Craig DeMars, Ph.D.
Postdoctoral Fellow
Department of Biological Sciences
University of Alberta
Phone: 780-221-3971

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Mon Jul 11 11:53:38 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Mon, 11 Jul 2016 10:53:38 +0100
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
In-Reply-To: <5782F109.4000505@gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
	<5782F109.4000505@gmail.com>
Message-ID: <CAPvMryOdMUULXMD1L6XCQftk52Qqtdk3FVYc4m5ZLuaS-0+MRA@mail.gmail.com>

Regarding SD: yes, I have several individuals with different number of
locations between them. But, for instance, when I consider study areas, I
have a very low variance (usually between 0-0.2, and SD is also 0 or, for
instance, 0.3, when variance is 0.1). Shouldn't I consider study areas as
random effect? I mean, is the "variance" value enough to include/exclude a
random effect?

How should I test for goodness of fit?

Regarding interactions: yes, I may construct models including interactions
between ID and other variables, but first I think it is better to find a
"strong" global model, and find which variables are most important.


Thank you very much for your help!!
Teresa

2016-07-11 2:06 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

>
>
> On 16-07-09 07:20 PM, Teresa Oliveira wrote:
> > Dear list members,
> >
> > I am developing GLMM's in order to assess habitat selection (using GLMMs'
> > coeficients to construct Resource selection functions). I have
> (telemetry)
> > data from 5 study areas, and each area has a different number of
> > individuals monitored.
> >
> > To develop GLMM's, the dependend variable is binary (1-used locations;
> > 0-available locations), and I have a initial set of 14 continuous
> variables
> > (8 land cover variables; 2 distance variables, to artificial areas and
> > water sources; 4 topographic variables): a buffer was placed around each
> > location and the area of each land cover within that buffer was accounted
> > for; distances were measured from each point to the nearest feature, and
> > topographic variables were obtained using DEM rasters. I tested for
> > correlation using Spearman's Rank, so not all 14 were used in the GLMMs.
> > All variables were transformed using z-score.
> >
> > As random effect, I used individual ID. I thought at the beggining to use
> > study area as a random effect but I only had 5 levels and there was
> almost
> > no variance when that random effect was used.
> >
> > I constructed a GLMM with 9 variables (not correlated) and a random
> effect,
> > then used "dredge()" function and "model.avg(dredge)" to sort models by
> AIC
> > values. This was the result (only models of AICc lower than 2
> represented):
> >
> > [1]Call:
> > model.avg(object = dredge.m1.1)
> >
> > Component model call:
> > glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
> > family =
> >      binomial(link = "logit"))
> >
> > Component models:
> >           df   logLik    AICc  delta weight
> > 123578     8 -4309.94 8635.89   0.00   0.14
> > 1235789    9 -4309.22 8636.44   0.55   0.10
> > 123789     8 -4310.52 8637.04   1.14   0.08
> > 1235678    9 -4309.75 8637.50   1.61   0.06
> > 12378      7 -4311.78 8637.57   1.67   0.06
> > 1234578    9 -4309.79 8637.58   1.69   0.06
> >
> > Variables 1 and 2 represent the distance variables; from 3 to 8 land
> cover
> > variables, and 9 is a topographic variable. Weights seem to be very low,
> > even if I average all those models as it seems to be common when delta
> > values are low.
>
> Well as far as we can tell from this, variables 4-9 aren't doing much
> (on the other hand, variables 1-3 seem to be in all of the top models
> you've shown us -- although presumably there are a bunch more models
> that are almost like these, and similar in weight, with other
> permutations of [123] + [some combination of 456789] ...)
>
>
> Even with this weights, I constructed GLMMs for each of the
> > combinations, and the results were simmilar for all 6 combinations. Here
> > are the results for the first one (GLMM + overdispersion + r-squared):
> >
> > Random effects:
> >  Groups    Name        Variance Std.Dev.
> >  ID.CODE_1 (Intercept) 13.02    3.608
> > Number of obs: 32670, groups:  ID.CODE_1, 55
> >
> > Fixed effects:
> >             Estimate Std. Error z value Pr(>|z|),
> > (Intercept) -0.54891    0.51174  -1.073 0.283433
> > 3       -0.22232    0.04059  -5.478 4.31e-08 ***
> > 5       -0.05433    0.02837  -1.915 0.055460 .
> > 7       -0.13108    0.02825  -4.640 3.49e-06 ***
> > 8       -0.15864    0.08670  -1.830 0.067287 .
> > 1         0.28438    0.02853   9.968  < 2e-16 ***
> > 2         0.11531    0.03021   3.817 0.000135 ***
> > Residual deviance: 0.256
> > r.squaredGLMM():
> >        R2m        R2c
> > 0.01063077 0.80039950
> > This is what I get from this analysis:
> >
> > 1) Variance and SD of the random effect seems fine (definitely better
> than
> > the "0" I got when using Study Areas as random effect);
>
>   yes -- SD of the random effects is much larger than any of the fixed
> effects, which means that the differences among individuals are large
> (presumably that means you have very different numbers of presences for
> different number of individuals [all individuals sharing a common pool
> of pseudo-absences ???)
> >
> > 2) Estimate values make sense from what I know of the species and the
> > knowledge I have of the study areas;
>
>   Good!
> >
> > 3) Overdispersion values seem good, and R-squared values don't seem very
> > good (at least when considering only fixed effects) but, as I read in
> > several places, AIC and r-squared are not always in agreement.
>
>   Overdispersion is meaningless for binary data.
> >
> > 4) Weight values seem very low. Does it mean the models are not good?
>
>   It means there are many approximately equivalent models.  Nothing in
> this output tells you very much about absolute goodness of fit (which is
> tricky for binary data).
> >
> > Then what I did was construct a GLM ("glm()"), so no random effect was
> > used. I used the same set of variables used in [1], and here are the
> > results (only models of AICc lower than 2 represented):
> >
> > [2] Call:
> > model.avg(object = dredge.glm_m1.1)
> >
> > Component model call:
> > glm(formula = Used ~ <512 unique rhs>, family = binomial(link = "logit"),
> > data =
> >      All_SA_Used_RP_Area_z)
> >
> > Component models:
> >           df   logLik     AICc   delta weight
> > 12345678   9 -9251.85 18521.70    0.00   0.52
> > 123456789 10 -9251.77 18523.54    1.84   0.21
> > 1345678    8 -9253.84 18523.69    1.99   0.19
> >
> > In this case, weight values are higher.
> >
> > Does this mean that it is better not to use a random effect? (I am not
> sure
> > I can compare GLMM with GLM results, correct me if I am doing wrong
> > assumptions)
>
>   No.  You could do a likelihood ratio test with anova(), but note that
> the AICc values for the glm() fits are 10,000 (!!) units higher than the
> glmer fits.
>
>   While it will potentially greatly complicate your life, I think you
> should at least *consider* interactions between your environment
> variables and ID, i.e. allow for the possibility that different
> individuals respond differently to habitat variation.
>
>   Ben Bolker
>

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Mon Jul 11 12:01:17 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Mon, 11 Jul 2016 11:01:17 +0100
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
In-Reply-To: <CAM1YihCCBTz=5LSoHd9x7cm64Ce2Xq_UreebU17F4KzaCV-EtA@mail.gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
	<5782F109.4000505@gmail.com>
	<CAM1YihCCBTz=5LSoHd9x7cm64Ce2Xq_UreebU17F4KzaCV-EtA@mail.gmail.com>
Message-ID: <CAPvMryOeiEG2O24NArJBPU349P0ngrtvdW0+vYvb+L=Fktd1GA@mail.gmail.com>

So, you are saying that the estimate values I get for the fixed effects,
and SD, do not have in account the random intercept (in this case, ID)?

What do you mean by "2-stage approaches"?
Regarding random slopes, are they represented by, for instance, (Variable
1|ID)?

I have seen a lot of studies where everyone uses GLMM to construct RSF, but
I have also read that they are not appropriate for RSF, however no one
seems sure about the right approach...

Thank you very much for your help!!
Teresa

2016-07-11 3:15 GMT+01:00 Craig DeMars <cdemars at ualberta.ca>:

> I would add some caution when interpreting the estimated values when using
> random-intercept only GLMMs for RSFs. The standard errors for the fixed
> effects do not reflect the animal as the sampling unit (see Schielzeth and
> Forstmeier 2009).  Thus, if your objective is to make inference to the
> larger population of animals, the standard errors for the fixed effects are
> far too narrow (i.e. overconfident). It is more appropriate to use 2-stage
> approaches or GLMMs that use random slopes for the variables of interest.
>
> Random-intercept only models are somewhat abused in the RSF literature in
> this regard, in my opinion......
>
> On Sun, Jul 10, 2016 at 7:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>>
>>
>> On 16-07-09 07:20 PM, Teresa Oliveira wrote:
>> > Dear list members,
>> >
>> > I am developing GLMM's in order to assess habitat selection (using
>> GLMMs'
>> > coeficients to construct Resource selection functions). I have
>> (telemetry)
>> > data from 5 study areas, and each area has a different number of
>> > individuals monitored.
>> >
>> > To develop GLMM's, the dependend variable is binary (1-used locations;
>> > 0-available locations), and I have a initial set of 14 continuous
>> variables
>> > (8 land cover variables; 2 distance variables, to artificial areas and
>> > water sources; 4 topographic variables): a buffer was placed around each
>> > location and the area of each land cover within that buffer was
>> accounted
>> > for; distances were measured from each point to the nearest feature, and
>> > topographic variables were obtained using DEM rasters. I tested for
>> > correlation using Spearman's Rank, so not all 14 were used in the GLMMs.
>> > All variables were transformed using z-score.
>> >
>> > As random effect, I used individual ID. I thought at the beggining to
>> use
>> > study area as a random effect but I only had 5 levels and there was
>> almost
>> > no variance when that random effect was used.
>> >
>> > I constructed a GLMM with 9 variables (not correlated) and a random
>> effect,
>> > then used "dredge()" function and "model.avg(dredge)" to sort models by
>> AIC
>> > values. This was the result (only models of AICc lower than 2
>> represented):
>> >
>> > [1]Call:
>> > model.avg(object = dredge.m1.1)
>> >
>> > Component model call:
>> > glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
>> > family =
>> >      binomial(link = "logit"))
>> >
>> > Component models:
>> >           df   logLik    AICc  delta weight
>> > 123578     8 -4309.94 8635.89   0.00   0.14
>> > 1235789    9 -4309.22 8636.44   0.55   0.10
>> > 123789     8 -4310.52 8637.04   1.14   0.08
>> > 1235678    9 -4309.75 8637.50   1.61   0.06
>> > 12378      7 -4311.78 8637.57   1.67   0.06
>> > 1234578    9 -4309.79 8637.58   1.69   0.06
>> >
>> > Variables 1 and 2 represent the distance variables; from 3 to 8 land
>> cover
>> > variables, and 9 is a topographic variable. Weights seem to be very low,
>> > even if I average all those models as it seems to be common when delta
>> > values are low.
>>
>> Well as far as we can tell from this, variables 4-9 aren't doing much
>> (on the other hand, variables 1-3 seem to be in all of the top models
>> you've shown us -- although presumably there are a bunch more models
>> that are almost like these, and similar in weight, with other
>> permutations of [123] + [some combination of 456789] ...)
>>
>>
>> Even with this weights, I constructed GLMMs for each of the
>> > combinations, and the results were simmilar for all 6 combinations. Here
>> > are the results for the first one (GLMM + overdispersion + r-squared):
>> >
>> > Random effects:
>> >  Groups    Name        Variance Std.Dev.
>> >  ID.CODE_1 (Intercept) 13.02    3.608
>> > Number of obs: 32670, groups:  ID.CODE_1, 55
>> >
>> > Fixed effects:
>> >             Estimate Std. Error z value Pr(>|z|),
>> > (Intercept) -0.54891    0.51174  -1.073 0.283433
>> > 3       -0.22232    0.04059  -5.478 4.31e-08 ***
>> > 5       -0.05433    0.02837  -1.915 0.055460 .
>> > 7       -0.13108    0.02825  -4.640 3.49e-06 ***
>> > 8       -0.15864    0.08670  -1.830 0.067287 .
>> > 1         0.28438    0.02853   9.968  < 2e-16 ***
>> > 2         0.11531    0.03021   3.817 0.000135 ***
>> > Residual deviance: 0.256
>> > r.squaredGLMM():
>> >        R2m        R2c
>> > 0.01063077 0.80039950
>> > This is what I get from this analysis:
>> >
>> > 1) Variance and SD of the random effect seems fine (definitely better
>> than
>> > the "0" I got when using Study Areas as random effect);
>>
>>   yes -- SD of the random effects is much larger than any of the fixed
>> effects, which means that the differences among individuals are large
>> (presumably that means you have very different numbers of presences for
>> different number of individuals [all individuals sharing a common pool
>> of pseudo-absences ???)
>> >
>> > 2) Estimate values make sense from what I know of the species and the
>> > knowledge I have of the study areas;
>>
>>   Good!
>> >
>> > 3) Overdispersion values seem good, and R-squared values don't seem very
>> > good (at least when considering only fixed effects) but, as I read in
>> > several places, AIC and r-squared are not always in agreement.
>>
>>   Overdispersion is meaningless for binary data.
>> >
>> > 4) Weight values seem very low. Does it mean the models are not good?
>>
>>   It means there are many approximately equivalent models.  Nothing in
>> this output tells you very much about absolute goodness of fit (which is
>> tricky for binary data).
>> >
>> > Then what I did was construct a GLM ("glm()"), so no random effect was
>> > used. I used the same set of variables used in [1], and here are the
>> > results (only models of AICc lower than 2 represented):
>> >
>> > [2] Call:
>> > model.avg(object = dredge.glm_m1.1)
>> >
>> > Component model call:
>> > glm(formula = Used ~ <512 unique rhs>, family = binomial(link =
>> "logit"),
>> > data =
>> >      All_SA_Used_RP_Area_z)
>> >
>> > Component models:
>> >           df   logLik     AICc   delta weight
>> > 12345678   9 -9251.85 18521.70    0.00   0.52
>> > 123456789 10 -9251.77 18523.54    1.84   0.21
>> > 1345678    8 -9253.84 18523.69    1.99   0.19
>> >
>> > In this case, weight values are higher.
>> >
>> > Does this mean that it is better not to use a random effect? (I am not
>> sure
>> > I can compare GLMM with GLM results, correct me if I am doing wrong
>> > assumptions)
>>
>>   No.  You could do a likelihood ratio test with anova(), but note that
>> the AICc values for the glm() fits are 10,000 (!!) units higher than the
>> glmer fits.
>>
>>   While it will potentially greatly complicate your life, I think you
>> should at least *consider* interactions between your environment
>> variables and ID, i.e. allow for the possibility that different
>> individuals respond differently to habitat variation.
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Craig DeMars, Ph.D.
> Postdoctoral Fellow
> Department of Biological Sciences
> University of Alberta
> Phone: 780-221-3971
>
>

	[[alternative HTML version deleted]]


From cdemars at ualberta.ca  Mon Jul 11 18:40:20 2016
From: cdemars at ualberta.ca (Craig DeMars)
Date: Mon, 11 Jul 2016 10:40:20 -0600
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
In-Reply-To: <CAPvMryOeiEG2O24NArJBPU349P0ngrtvdW0+vYvb+L=Fktd1GA@mail.gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
	<5782F109.4000505@gmail.com>
	<CAM1YihCCBTz=5LSoHd9x7cm64Ce2Xq_UreebU17F4KzaCV-EtA@mail.gmail.com>
	<CAPvMryOeiEG2O24NArJBPU349P0ngrtvdW0+vYvb+L=Fktd1GA@mail.gmail.com>
Message-ID: <CAM1YihArtVcrohCAAuQA58P2=hQ6Rqc-FBAsg_VGOY6JTSkyAA@mail.gmail.com>

In an telemetry-based RSF using a random-intercept only GLMM, the standard
errors are calculated assuming the individual telemetry location (or
random/available location) is the sampling unit, not the animal. That is
partially the reason that some studies using this approach report
incredibly small p-values for their fixed effects when they have only, say,
a sample of < 30 animals.  These results are highly unlikely given the
small sample size of actual animals and that most wildlife populations will
have a degree of variability in selection among individuals. The
random-intercept only approach does not appropriately reflect this
individual-level variation.  A random-slope model will calculate slopes at
the individual animal level and therefore standard errors in this approach
will reflect individual-level variation. The drawback to these models is
you are often limited in the number of variables that you can specify as
random slopes.

A 2-stage approach is where you fit a GLM for each individual animal.
Population inferences are gained by averaging parameter estimates across
individuals.  You can account for differences in sample sizes per
individual by calculating averages that are weighted by sample size or the
inverse of the variance (giving more weight to individuals with more
precise estimates). I can guarantee that the resulting standard errors will
be more conservative (and more appropriate) than those calculated from a
random-intercept GLMM.

On Mon, Jul 11, 2016 at 4:01 AM, Teresa Oliveira <
mteresaoliveira92 at gmail.com> wrote:

> So, you are saying that the estimate values I get for the fixed effects,
> and SD, do not have in account the random intercept (in this case, ID)?
>
> What do you mean by "2-stage approaches"?
> Regarding random slopes, are they represented by, for instance, (Variable
> 1|ID)?
>
> I have seen a lot of studies where everyone uses GLMM to construct RSF,
> but I have also read that they are not appropriate for RSF, however no one
> seems sure about the right approach...
>
> Thank you very much for your help!!
> Teresa
>
> 2016-07-11 3:15 GMT+01:00 Craig DeMars <cdemars at ualberta.ca>:
>
>> I would add some caution when interpreting the estimated values when
>> using random-intercept only GLMMs for RSFs. The standard errors for the
>> fixed effects do not reflect the animal as the sampling unit (see
>> Schielzeth and Forstmeier 2009).  Thus, if your objective is to make
>> inference to the larger population of animals, the standard errors for the
>> fixed effects are far too narrow (i.e. overconfident). It is more
>> appropriate to use 2-stage approaches or GLMMs that use random slopes for
>> the variables of interest.
>>
>> Random-intercept only models are somewhat abused in the RSF literature in
>> this regard, in my opinion......
>>
>> On Sun, Jul 10, 2016 at 7:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>>
>>>
>>> On 16-07-09 07:20 PM, Teresa Oliveira wrote:
>>> > Dear list members,
>>> >
>>> > I am developing GLMM's in order to assess habitat selection (using
>>> GLMMs'
>>> > coeficients to construct Resource selection functions). I have
>>> (telemetry)
>>> > data from 5 study areas, and each area has a different number of
>>> > individuals monitored.
>>> >
>>> > To develop GLMM's, the dependend variable is binary (1-used locations;
>>> > 0-available locations), and I have a initial set of 14 continuous
>>> variables
>>> > (8 land cover variables; 2 distance variables, to artificial areas and
>>> > water sources; 4 topographic variables): a buffer was placed around
>>> each
>>> > location and the area of each land cover within that buffer was
>>> accounted
>>> > for; distances were measured from each point to the nearest feature,
>>> and
>>> > topographic variables were obtained using DEM rasters. I tested for
>>> > correlation using Spearman's Rank, so not all 14 were used in the
>>> GLMMs.
>>> > All variables were transformed using z-score.
>>> >
>>> > As random effect, I used individual ID. I thought at the beggining to
>>> use
>>> > study area as a random effect but I only had 5 levels and there was
>>> almost
>>> > no variance when that random effect was used.
>>> >
>>> > I constructed a GLMM with 9 variables (not correlated) and a random
>>> effect,
>>> > then used "dredge()" function and "model.avg(dredge)" to sort models
>>> by AIC
>>> > values. This was the result (only models of AICc lower than 2
>>> represented):
>>> >
>>> > [1]Call:
>>> > model.avg(object = dredge.m1.1)
>>> >
>>> > Component model call:
>>> > glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
>>> > family =
>>> >      binomial(link = "logit"))
>>> >
>>> > Component models:
>>> >           df   logLik    AICc  delta weight
>>> > 123578     8 -4309.94 8635.89   0.00   0.14
>>> > 1235789    9 -4309.22 8636.44   0.55   0.10
>>> > 123789     8 -4310.52 8637.04   1.14   0.08
>>> > 1235678    9 -4309.75 8637.50   1.61   0.06
>>> > 12378      7 -4311.78 8637.57   1.67   0.06
>>> > 1234578    9 -4309.79 8637.58   1.69   0.06
>>> >
>>> > Variables 1 and 2 represent the distance variables; from 3 to 8 land
>>> cover
>>> > variables, and 9 is a topographic variable. Weights seem to be very
>>> low,
>>> > even if I average all those models as it seems to be common when delta
>>> > values are low.
>>>
>>> Well as far as we can tell from this, variables 4-9 aren't doing much
>>> (on the other hand, variables 1-3 seem to be in all of the top models
>>> you've shown us -- although presumably there are a bunch more models
>>> that are almost like these, and similar in weight, with other
>>> permutations of [123] + [some combination of 456789] ...)
>>>
>>>
>>> Even with this weights, I constructed GLMMs for each of the
>>> > combinations, and the results were simmilar for all 6 combinations.
>>> Here
>>> > are the results for the first one (GLMM + overdispersion + r-squared):
>>> >
>>> > Random effects:
>>> >  Groups    Name        Variance Std.Dev.
>>> >  ID.CODE_1 (Intercept) 13.02    3.608
>>> > Number of obs: 32670, groups:  ID.CODE_1, 55
>>> >
>>> > Fixed effects:
>>> >             Estimate Std. Error z value Pr(>|z|),
>>> > (Intercept) -0.54891    0.51174  -1.073 0.283433
>>> > 3       -0.22232    0.04059  -5.478 4.31e-08 ***
>>> > 5       -0.05433    0.02837  -1.915 0.055460 .
>>> > 7       -0.13108    0.02825  -4.640 3.49e-06 ***
>>> > 8       -0.15864    0.08670  -1.830 0.067287 .
>>> > 1         0.28438    0.02853   9.968  < 2e-16 ***
>>> > 2         0.11531    0.03021   3.817 0.000135 ***
>>> > Residual deviance: 0.256
>>> > r.squaredGLMM():
>>> >        R2m        R2c
>>> > 0.01063077 0.80039950
>>> > This is what I get from this analysis:
>>> >
>>> > 1) Variance and SD of the random effect seems fine (definitely better
>>> than
>>> > the "0" I got when using Study Areas as random effect);
>>>
>>>   yes -- SD of the random effects is much larger than any of the fixed
>>> effects, which means that the differences among individuals are large
>>> (presumably that means you have very different numbers of presences for
>>> different number of individuals [all individuals sharing a common pool
>>> of pseudo-absences ???)
>>> >
>>> > 2) Estimate values make sense from what I know of the species and the
>>> > knowledge I have of the study areas;
>>>
>>>   Good!
>>> >
>>> > 3) Overdispersion values seem good, and R-squared values don't seem
>>> very
>>> > good (at least when considering only fixed effects) but, as I read in
>>> > several places, AIC and r-squared are not always in agreement.
>>>
>>>   Overdispersion is meaningless for binary data.
>>> >
>>> > 4) Weight values seem very low. Does it mean the models are not good?
>>>
>>>   It means there are many approximately equivalent models.  Nothing in
>>> this output tells you very much about absolute goodness of fit (which is
>>> tricky for binary data).
>>> >
>>> > Then what I did was construct a GLM ("glm()"), so no random effect was
>>> > used. I used the same set of variables used in [1], and here are the
>>> > results (only models of AICc lower than 2 represented):
>>> >
>>> > [2] Call:
>>> > model.avg(object = dredge.glm_m1.1)
>>> >
>>> > Component model call:
>>> > glm(formula = Used ~ <512 unique rhs>, family = binomial(link =
>>> "logit"),
>>> > data =
>>> >      All_SA_Used_RP_Area_z)
>>> >
>>> > Component models:
>>> >           df   logLik     AICc   delta weight
>>> > 12345678   9 -9251.85 18521.70    0.00   0.52
>>> > 123456789 10 -9251.77 18523.54    1.84   0.21
>>> > 1345678    8 -9253.84 18523.69    1.99   0.19
>>> >
>>> > In this case, weight values are higher.
>>> >
>>> > Does this mean that it is better not to use a random effect? (I am not
>>> sure
>>> > I can compare GLMM with GLM results, correct me if I am doing wrong
>>> > assumptions)
>>>
>>>   No.  You could do a likelihood ratio test with anova(), but note that
>>> the AICc values for the glm() fits are 10,000 (!!) units higher than the
>>> glmer fits.
>>>
>>>   While it will potentially greatly complicate your life, I think you
>>> should at least *consider* interactions between your environment
>>> variables and ID, i.e. allow for the possibility that different
>>> individuals respond differently to habitat variation.
>>>
>>>   Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Craig DeMars, Ph.D.
>> Postdoctoral Fellow
>> Department of Biological Sciences
>> University of Alberta
>> Phone: 780-221-3971
>>
>>
>


-- 
Craig DeMars, Ph.D.
Postdoctoral Fellow
Department of Biological Sciences
University of Alberta
Phone: 780-221-3971

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Jul 11 21:36:31 2016
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 11 Jul 2016 16:36:31 -0300
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
	<CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>
	<CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
Message-ID: <CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>

>
> Sorrry, I hadn?t copied the whole group. Here it goes: Thanks Thierry,
> I?ve been there a couple of times. I?ll try again. I think there is a
> mistake in page 112 when says: It is relatively easy to show that Vi is
> normally distributed with mean X i ? ? and variance V i in mathematical
> notation...
>
> It should say Yi instead of Vi, right?
>
> Cheers,
> Joaqu?n .
>
> 2016-07-08 9:02 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Joaquin,
>>
>> I'd recommend Zuur et al 2009, section 5.4
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>
>>> Dear all, I?m a basic user of mixed models but there are things that I?ve
>>> found hard to understand. On of these is how the model solves the
>>> correlations among samples taken in the same site or levels of other kind
>>> of grouping variable.
>>>
>>> I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and
>>> part
>>> of Pinheiro and Bates (2000). But still don?t understand the way that
>>> GLMM
>>> include the correlation effect in the predictions of the model.
>>>
>>> I really appreciate any comment and/or bibliographic reference that help
>>> me
>>> understand this.
>>>
>>> Thanks in advanced,
>>> Joaqu?n.
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jul 12 15:52:27 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 12 Jul 2016 15:52:27 +0200
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
	<CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>
	<CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
	<CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>
Message-ID: <CAJuCY5yq6pu89e2=MxVpWTT0P5YOetRfUVeRmvKABFq9dyjpOA@mail.gmail.com>

Dear Joaquin,

Yes. I think you have found a typo. The prior to equation 5.13 should read "It
is relatively easy to show that $Y_i$ is normally distributed ..."

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-11 21:36 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Sorrry, I hadn?t copied the whole group. Here it goes: Thanks Thierry,
>> I?ve been there a couple of times. I?ll try again. I think there is a
>> mistake in page 112 when says: It is relatively easy to show that Vi is
>> normally distributed with mean X i ? ? and variance V i in mathematical
>> notation...
>>
>> It should say Yi instead of Vi, right?
>>
>> Cheers,
>> Joaqu?n .
>>
>> 2016-07-08 9:02 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>>> Dear Joaquin,
>>>
>>> I'd recommend Zuur et al 2009, section 5.4
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>>
>>>> Dear all, I?m a basic user of mixed models but there are things that
>>>> I?ve
>>>> found hard to understand. On of these is how the model solves the
>>>> correlations among samples taken in the same site or levels of other
>>>> kind
>>>> of grouping variable.
>>>>
>>>> I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and
>>>> part
>>>> of Pinheiro and Bates (2000). But still don?t understand the way that
>>>> GLMM
>>>> include the correlation effect in the predictions of the model.
>>>>
>>>> I really appreciate any comment and/or bibliographic reference that
>>>> help me
>>>> understand this.
>>>>
>>>> Thanks in advanced,
>>>> Joaqu?n.
>>>>
>>>> --
>>>> *Joaqu?n Aldabe*
>>>>
>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>>
>>>> *Departamento de Conservaci?n*
>>>> Aves Uruguay
>>>> BirdLife International
>>>> Canelones 1164, Montevideo
>>>>
>>>> https://sites.google.com/site/joaquin.aldabe
>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>

	[[alternative HTML version deleted]]


From mteresaoliveira92 at gmail.com  Mon Jul 11 21:07:12 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Mon, 11 Jul 2016 20:07:12 +0100
Subject: [R-sig-ME] GLMM- relationship between AICc weight and random
	effects?
In-Reply-To: <CAM1YihArtVcrohCAAuQA58P2=hQ6Rqc-FBAsg_VGOY6JTSkyAA@mail.gmail.com>
References: <CAPvMryObwxU=Sb0aZtAjNDwBVgbxZoOs82tN19G04igm1ukqng@mail.gmail.com>
	<5782F109.4000505@gmail.com>
	<CAM1YihCCBTz=5LSoHd9x7cm64Ce2Xq_UreebU17F4KzaCV-EtA@mail.gmail.com>
	<CAPvMryOeiEG2O24NArJBPU349P0ngrtvdW0+vYvb+L=Fktd1GA@mail.gmail.com>
	<CAM1YihArtVcrohCAAuQA58P2=hQ6Rqc-FBAsg_VGOY6JTSkyAA@mail.gmail.com>
Message-ID: <CAPvMryN=8aTL5ARW0Oouspi=UtFSS+BZQ5BmJcG=Kqdt7+nKxw@mail.gmail.com>

Thank you very much for your help! It makes more sense now why I get low
variance levels (which would be nice if they were "true")..

So, it doesn't matter which random effect I use, it will always consider
the number of locations?

A related problem, regarding random effects:
The random effects I want to consider and the results I get are confusing
me. For instance, at first, I wanted to include study area as a random
effect (RE), because I thought it would be adequate to consider possible
differences between study areas. However, I got variance values very low
and high SD.
The other two RE I wanted to consider were related with individual ID: the
differences were in the way "availability" was defined for each. One way
assumed that 1) all study area was available for each animal (thus a set of
"available" units was randomly selected for each animal, which I think is
the most common way); the other way assumed that 2) there were zones
(within home ranges) not available for all animals. From these two ways, I
considered only one at the time.
When I consider study area and individual ID, assuming 1), variance is 0 or
very low. When I consider individual ID, assuming 2), variance is higher
and SD is small.

For instance, here is a result I got for a given model (with the higher AIC
weight), using study area as a RE:

"AIC      BIC   logLik deviance df.resid
 18928.6  18995.8  -9456.3  18912.6    32662

Random effects:
 Groups     Name        Variance Std.Dev.
 Study.Area (Intercept) 0.3208   0.5664
Number of obs: 32670, groups:  Study.Area, 5

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.79438    0.25637 -10.900  < 2e-16 ***
LC2_z       -0.60546    0.02487 -24.348  < 2e-16 ***
LC3_z       -0.11825    0.03205  -3.690 0.000224 ***
LC8_z        0.06528    0.01908   3.422 0.000622 ***
DH_z         0.30449    0.02236  13.620  < 2e-16 ***
DW_z         0.04872    0.02089   2.332 0.019695 *
TPI_z        0.02082    0.01745   1.193 0.232845         "


Altough someone advised me not to include study area as RE, because there
were only five levels.
This model has a high AIC (when considering the other models), variance is
low and SD is high but SD for the estimates is low, when looking at the
intercept.

Another example, this time considering ID (1) as a RE:

"AIC      BIC   logLik deviance df.resid
 18978.7  19045.8  -9481.3  18962.7    32662

Random effects:
 Groups Name        Variance Std.Dev.
 ID_1   (Intercept) 0.165    0.4063
Number of obs: 32670, groups:  ID_1, 26

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -2.60211    0.08917 -29.180  < 2e-16 ***
LC2_z       -0.60123    0.02483 -24.210  < 2e-16 ***
LC3_z       -0.12135    0.03205  -3.786 0.000153 ***
LC8_z        0.05541    0.01915   2.893 0.003817 **
DH_z         0.29363    0.02296  12.789  < 2e-16 ***
DW_z         0.05232    0.02103   2.487 0.012875 *

TPI_z        0.02117    0.01746   1.213 0.225280        "

This result is simmilar to the first one.

Another and last example, this time considering ID (2) as a RE:

"  AIC      BIC   logLik deviance df.resid
  8641.4   8708.6  -4312.7   8625.4    32662

Random effects:
 Groups    Name        Variance Std.Dev.
 ID.CODE_1 (Intercept) 13.09    3.618
Number of obs: 32670, groups:  ID.CODE_1, 55

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.53513    0.51271  -1.044 0.296615
LC2_z       -0.19914    0.03782  -5.265 1.40e-07 ***
LC3_z       -0.02111    0.04195  -0.503 0.614810
LC8_z       -0.12183    0.02767  -4.403 1.07e-05 ***
DH_z         0.28389    0.02853   9.951  < 2e-16 ***
DW_z         0.11496    0.03021   3.806 0.000141 ***
TPI_z       -0.04058    0.02574  -1.576 0.114972              "


This time, AIC is lower and variance higher, but SD of the interept
estimate is very high!

Based on this, which one should be more useful? How can I interpret the
"good" variance/SD of the random effects but with "bad" SD intercept
estimate? And the reverse.
And honestly I think it is very weird that study areas are not different,
and I don't know if I should considerd it anyway or not.


2016-07-11 17:40 GMT+01:00 Craig DeMars <cdemars at ualberta.ca>:

> In an telemetry-based RSF using a random-intercept only GLMM, the standard
> errors are calculated assuming the individual telemetry location (or
> random/available location) is the sampling unit, not the animal. That is
> partially the reason that some studies using this approach report
> incredibly small p-values for their fixed effects when they have only, say,
> a sample of < 30 animals.  These results are highly unlikely given the
> small sample size of actual animals and that most wildlife populations will
> have a degree of variability in selection among individuals. The
> random-intercept only approach does not appropriately reflect this
> individual-level variation.  A random-slope model will calculate slopes at
> the individual animal level and therefore standard errors in this approach
> will reflect individual-level variation. The drawback to these models is
> you are often limited in the number of variables that you can specify as
> random slopes.
>
> A 2-stage approach is where you fit a GLM for each individual animal.
> Population inferences are gained by averaging parameter estimates across
> individuals.  You can account for differences in sample sizes per
> individual by calculating averages that are weighted by sample size or the
> inverse of the variance (giving more weight to individuals with more
> precise estimates). I can guarantee that the resulting standard errors will
> be more conservative (and more appropriate) than those calculated from a
> random-intercept GLMM.
>
> On Mon, Jul 11, 2016 at 4:01 AM, Teresa Oliveira <
> mteresaoliveira92 at gmail.com> wrote:
>
>> So, you are saying that the estimate values I get for the fixed effects,
>> and SD, do not have in account the random intercept (in this case, ID)?
>>
>> What do you mean by "2-stage approaches"?
>> Regarding random slopes, are they represented by, for instance, (Variable
>> 1|ID)?
>>
>> I have seen a lot of studies where everyone uses GLMM to construct RSF,
>> but I have also read that they are not appropriate for RSF, however no one
>> seems sure about the right approach...
>>
>> Thank you very much for your help!!
>> Teresa
>>
>> 2016-07-11 3:15 GMT+01:00 Craig DeMars <cdemars at ualberta.ca>:
>>
>>> I would add some caution when interpreting the estimated values when
>>> using random-intercept only GLMMs for RSFs. The standard errors for the
>>> fixed effects do not reflect the animal as the sampling unit (see
>>> Schielzeth and Forstmeier 2009).  Thus, if your objective is to make
>>> inference to the larger population of animals, the standard errors for the
>>> fixed effects are far too narrow (i.e. overconfident). It is more
>>> appropriate to use 2-stage approaches or GLMMs that use random slopes for
>>> the variables of interest.
>>>
>>> Random-intercept only models are somewhat abused in the RSF literature
>>> in this regard, in my opinion......
>>>
>>> On Sun, Jul 10, 2016 at 7:06 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>>
>>>>
>>>> On 16-07-09 07:20 PM, Teresa Oliveira wrote:
>>>> > Dear list members,
>>>> >
>>>> > I am developing GLMM's in order to assess habitat selection (using
>>>> GLMMs'
>>>> > coeficients to construct Resource selection functions). I have
>>>> (telemetry)
>>>> > data from 5 study areas, and each area has a different number of
>>>> > individuals monitored.
>>>> >
>>>> > To develop GLMM's, the dependend variable is binary (1-used locations;
>>>> > 0-available locations), and I have a initial set of 14 continuous
>>>> variables
>>>> > (8 land cover variables; 2 distance variables, to artificial areas and
>>>> > water sources; 4 topographic variables): a buffer was placed around
>>>> each
>>>> > location and the area of each land cover within that buffer was
>>>> accounted
>>>> > for; distances were measured from each point to the nearest feature,
>>>> and
>>>> > topographic variables were obtained using DEM rasters. I tested for
>>>> > correlation using Spearman's Rank, so not all 14 were used in the
>>>> GLMMs.
>>>> > All variables were transformed using z-score.
>>>> >
>>>> > As random effect, I used individual ID. I thought at the beggining to
>>>> use
>>>> > study area as a random effect but I only had 5 levels and there was
>>>> almost
>>>> > no variance when that random effect was used.
>>>> >
>>>> > I constructed a GLMM with 9 variables (not correlated) and a random
>>>> effect,
>>>> > then used "dredge()" function and "model.avg(dredge)" to sort models
>>>> by AIC
>>>> > values. This was the result (only models of AICc lower than 2
>>>> represented):
>>>> >
>>>> > [1]Call:
>>>> > model.avg(object = dredge.m1.1)
>>>> >
>>>> > Component model call:
>>>> > glmer(formula = Used ~ <512 unique rhs>, data = All_SA_Used_RP_Area_z,
>>>> > family =
>>>> >      binomial(link = "logit"))
>>>> >
>>>> > Component models:
>>>> >           df   logLik    AICc  delta weight
>>>> > 123578     8 -4309.94 8635.89   0.00   0.14
>>>> > 1235789    9 -4309.22 8636.44   0.55   0.10
>>>> > 123789     8 -4310.52 8637.04   1.14   0.08
>>>> > 1235678    9 -4309.75 8637.50   1.61   0.06
>>>> > 12378      7 -4311.78 8637.57   1.67   0.06
>>>> > 1234578    9 -4309.79 8637.58   1.69   0.06
>>>> >
>>>> > Variables 1 and 2 represent the distance variables; from 3 to 8 land
>>>> cover
>>>> > variables, and 9 is a topographic variable. Weights seem to be very
>>>> low,
>>>> > even if I average all those models as it seems to be common when delta
>>>> > values are low.
>>>>
>>>> Well as far as we can tell from this, variables 4-9 aren't doing much
>>>> (on the other hand, variables 1-3 seem to be in all of the top models
>>>> you've shown us -- although presumably there are a bunch more models
>>>> that are almost like these, and similar in weight, with other
>>>> permutations of [123] + [some combination of 456789] ...)
>>>>
>>>>
>>>> Even with this weights, I constructed GLMMs for each of the
>>>> > combinations, and the results were simmilar for all 6 combinations.
>>>> Here
>>>> > are the results for the first one (GLMM + overdispersion + r-squared):
>>>> >
>>>> > Random effects:
>>>> >  Groups    Name        Variance Std.Dev.
>>>> >  ID.CODE_1 (Intercept) 13.02    3.608
>>>> > Number of obs: 32670, groups:  ID.CODE_1, 55
>>>> >
>>>> > Fixed effects:
>>>> >             Estimate Std. Error z value Pr(>|z|),
>>>> > (Intercept) -0.54891    0.51174  -1.073 0.283433
>>>> > 3       -0.22232    0.04059  -5.478 4.31e-08 ***
>>>> > 5       -0.05433    0.02837  -1.915 0.055460 .
>>>> > 7       -0.13108    0.02825  -4.640 3.49e-06 ***
>>>> > 8       -0.15864    0.08670  -1.830 0.067287 .
>>>> > 1         0.28438    0.02853   9.968  < 2e-16 ***
>>>> > 2         0.11531    0.03021   3.817 0.000135 ***
>>>> > Residual deviance: 0.256
>>>> > r.squaredGLMM():
>>>> >        R2m        R2c
>>>> > 0.01063077 0.80039950
>>>> > This is what I get from this analysis:
>>>> >
>>>> > 1) Variance and SD of the random effect seems fine (definitely better
>>>> than
>>>> > the "0" I got when using Study Areas as random effect);
>>>>
>>>>   yes -- SD of the random effects is much larger than any of the fixed
>>>> effects, which means that the differences among individuals are large
>>>> (presumably that means you have very different numbers of presences for
>>>> different number of individuals [all individuals sharing a common pool
>>>> of pseudo-absences ???)
>>>> >
>>>> > 2) Estimate values make sense from what I know of the species and the
>>>> > knowledge I have of the study areas;
>>>>
>>>>   Good!
>>>> >
>>>> > 3) Overdispersion values seem good, and R-squared values don't seem
>>>> very
>>>> > good (at least when considering only fixed effects) but, as I read in
>>>> > several places, AIC and r-squared are not always in agreement.
>>>>
>>>>   Overdispersion is meaningless for binary data.
>>>> >
>>>> > 4) Weight values seem very low. Does it mean the models are not good?
>>>>
>>>>   It means there are many approximately equivalent models.  Nothing in
>>>> this output tells you very much about absolute goodness of fit (which is
>>>> tricky for binary data).
>>>> >
>>>> > Then what I did was construct a GLM ("glm()"), so no random effect was
>>>> > used. I used the same set of variables used in [1], and here are the
>>>> > results (only models of AICc lower than 2 represented):
>>>> >
>>>> > [2] Call:
>>>> > model.avg(object = dredge.glm_m1.1)
>>>> >
>>>> > Component model call:
>>>> > glm(formula = Used ~ <512 unique rhs>, family = binomial(link =
>>>> "logit"),
>>>> > data =
>>>> >      All_SA_Used_RP_Area_z)
>>>> >
>>>> > Component models:
>>>> >           df   logLik     AICc   delta weight
>>>> > 12345678   9 -9251.85 18521.70    0.00   0.52
>>>> > 123456789 10 -9251.77 18523.54    1.84   0.21
>>>> > 1345678    8 -9253.84 18523.69    1.99   0.19
>>>> >
>>>> > In this case, weight values are higher.
>>>> >
>>>> > Does this mean that it is better not to use a random effect? (I am
>>>> not sure
>>>> > I can compare GLMM with GLM results, correct me if I am doing wrong
>>>> > assumptions)
>>>>
>>>>   No.  You could do a likelihood ratio test with anova(), but note that
>>>> the AICc values for the glm() fits are 10,000 (!!) units higher than the
>>>> glmer fits.
>>>>
>>>>   While it will potentially greatly complicate your life, I think you
>>>> should at least *consider* interactions between your environment
>>>> variables and ID, i.e. allow for the possibility that different
>>>> individuals respond differently to habitat variation.
>>>>
>>>>   Ben Bolker
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>>
>>> --
>>> Craig DeMars, Ph.D.
>>> Postdoctoral Fellow
>>> Department of Biological Sciences
>>> University of Alberta
>>> Phone: 780-221-3971
>>>
>>>
>>
>
>
> --
> Craig DeMars, Ph.D.
> Postdoctoral Fellow
> Department of Biological Sciences
> University of Alberta
> Phone: 780-221-3971
>
>

	[[alternative HTML version deleted]]


From joseph.tharayil at nih.gov  Tue Jul 12 18:46:04 2016
From: joseph.tharayil at nih.gov (Tharayil, Joseph (NIH/NINDS) [F])
Date: Tue, 12 Jul 2016 16:46:04 +0000
Subject: [R-sig-ME] glmmADMB
Message-ID: <D3AA970B.AC6%joseph.tharayil@nih.gov>

Hello all,

I am an undergraduate at the NIH summer internship program, working on
statistical models of seizure frequency. I am trying to use your R
package, glmmADMB, for zero-inflated poisson and negative binomial mixed
models. I have two questions:

  1. Does the zero inflation parameter returned by glmmadmb() refer to
     the fraction of instances in which ?extra? zeros are observed?
  2. I often come across error messages containing the following phrase:
     "Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
     zeroInflation = TRUE,  : the function maximizer failed (couldn't
     find parameter file)?. It seems as though using different data sets,
     or changing the size of the data set, or using a poisson instead of
     negative binomial model, solves the problem. Two examples of a full
     error message, and a minimal code example are shown below.

I would really appreciate any assistance you are able to provide.

Thank you,
Joseph Tharayil
Summer Student
Clinical Epilepsy Section
NINDS, NIH

Minimal code example:

observations<-rnbinom(100000,size=10, mu=100000)
randzeros<-rbinom(100000,1,.80)
zeroinfl<-observations*randzeros
testpatients<-c()
k<-0
for(i in 1:1000)
{
  for(j in 1:100)
  {
    k<-k+1
    testpatients[k]<-i
  }
}
testpatients<-as.factor(testpatients)
testdf<-as.data.frame(cbind(zeroinfl,testpatients))
testdf$testpatients<-as.factor(testdf$testpatients)
testZINB<-glmmadmb(zeroinfl~1+(1|testpatients),data=testdf,zeroInflation=TRUE,family='nbinom')

Error message examples:
Example 1:
Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
zeroInflation = TRUE,  :
   The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run
with debug=TRUE for more information on failure mode
In addition: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
status 1
Example 2:
Need to increase the maximum number of separable calls allowed to at
least 20001
Current value is 20000
Use the -ndi N command line option
Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
zeroInflation = TRUE,  :
   The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run
with debug=TRUE for more information on failure mode
In addition: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
status 1


	[[alternative HTML version deleted]]


From mbrooks at ufl.edu  Tue Jul 12 19:36:14 2016
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Tue, 12 Jul 2016 19:36:14 +0200
Subject: [R-sig-ME] glmmADMB
In-Reply-To: <D3AA970B.AC6%joseph.tharayil@nih.gov>
References: <D3AA970B.AC6%joseph.tharayil@nih.gov>
Message-ID: <EA009108-D9F6-402E-8EBB-4D3405CD7539@ufl.edu>

Hi Joseph,

> On 12Jul 2016, at 18:46, Tharayil, Joseph (NIH/NINDS) [F] <joseph.tharayil at nih.gov> wrote:
> 
> Hello all,
> 
> I am an undergraduate at the NIH summer internship program, working on
> statistical models of seizure frequency. I am trying to use your R
> package, glmmADMB, for zero-inflated poisson and negative binomial mixed
> models. I have two questions:
> 
>  1. Does the zero inflation parameter returned by glmmadmb() refer to
>     the fraction of instances in which ?extra? zeros are observed?

Yes, this is correct.

>  2. I often come across error messages containing the following phrase:
>     "Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
>     zeroInflation = TRUE,  : the function maximizer failed (couldn't
>     find parameter file)?. It seems as though using different data sets,
>     or changing the size of the data set, or using a poisson instead of
>     negative binomial model, solves the problem. Two examples of a full
>     error message, and a minimal code example are shown below.
> 
The function maximizer can fail when the model is difficult to fit to the data for any number of reasons. Maybe Dave Fournier has some expert advice on this. 

To solve the problem in error example 2, you could us the argument extra.args to adjust the command line option ndi. This controls memory allocation.
testZINB<-glmmadmb(zeroinfl~1+(1|testpatients),data=testdf,zeroInflation=TRUE,family='nbinom', extra.args="-ndi 1000000")
For this big of a data set, the negative binomial is really slow. If you really need to deal with data sets this big and if glmmADMB is prohibitively slow on your computer, you could try glmmTMB instead. See https://github.com/glmmTMB/glmmTMB <https://github.com/glmmTMB/glmmTMB> for installation instructions.

testZINB<-glmmTMB(zeroinfl~1+(1|testpatients),data=testdf,zi=~1,family='nbinom1')

cheers,
Mollie

> I would really appreciate any assistance you are able to provide.
> 
> Thank you,
> Joseph Tharayil
> Summer Student
> Clinical Epilepsy Section
> NINDS, NIH
> 
> Minimal code example:
> 
> observations<-rnbinom(100000,size=10, mu=100000)
> randzeros<-rbinom(100000,1,.80)
> zeroinfl<-observations*randzeros
> testpatients<-c()
> k<-0
> for(i in 1:1000)
> {
>  for(j in 1:100)
>  {
>    k<-k+1
>    testpatients[k]<-i
>  }
> }
> testpatients<-as.factor(testpatients)
> testdf<-as.data.frame(cbind(zeroinfl,testpatients))
> testdf$testpatients<-as.factor(testdf$testpatients)
> testZINB<-glmmadmb(zeroinfl~1+(1|testpatients),data=testdf,zeroInflation=TRUE,family='nbinom')
> 
> Error message examples:
> Example 1:
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
> zeroInflation = TRUE,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run
> with debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
> status 1
> Example 2:
> Need to increase the maximum number of separable calls allowed to at
> least 20001
> Current value is 20000
> Use the -ndi N command line option
> Error in glmmadmb(zeroinfl ~ 1 + (1 | testpatients), data = testdf,
> zeroInflation = TRUE,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run
> with debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
> status 1
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------
Mollie Brooks, PhD
Postdoctoral Researcher, Population Ecology Research Group
Department of Evolutionary Biology & Environmental Studies, University of Z?rich
http://www.popecol.org/team/mollie-brooks/

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Tue Jul 12 19:42:02 2016
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 12 Jul 2016 14:42:02 -0300
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAJuCY5yq6pu89e2=MxVpWTT0P5YOetRfUVeRmvKABFq9dyjpOA@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
	<CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>
	<CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
	<CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>
	<CAJuCY5yq6pu89e2=MxVpWTT0P5YOetRfUVeRmvKABFq9dyjpOA@mail.gmail.com>
Message-ID: <CAMM93=LaVz5+J4ynETEABqXPmOhrF9HuzwRuED=hY_J4EVj_YQ@mail.gmail.com>

By the way..I don?t see why it is relatively easy to show that Yi is
normally distributed..(in fact, the Y variable is count so it should be
poisson). This is in section 5.4 (p. 112) of Zuur et al (2009).
Thanks,
joaqu?n.

2016-07-12 10:52 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Joaquin,
>
> Yes. I think you have found a typo. The prior to equation 5.13 should read
> "It is relatively easy to show that $Y_i$ is normally distributed ..."
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-07-11 21:36 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>
>> Sorrry, I hadn?t copied the whole group. Here it goes: Thanks Thierry,
>>> I?ve been there a couple of times. I?ll try again. I think there is a
>>> mistake in page 112 when says: It is relatively easy to show that Vi is
>>> normally distributed with mean X i ? ? and variance V i in mathematical
>>> notation...
>>>
>>> It should say Yi instead of Vi, right?
>>>
>>> Cheers,
>>> Joaqu?n .
>>>
>>> 2016-07-08 9:02 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>>
>>>> Dear Joaquin,
>>>>
>>>> I'd recommend Zuur et al 2009, section 5.4
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>>>
>>>>> Dear all, I?m a basic user of mixed models but there are things that
>>>>> I?ve
>>>>> found hard to understand. On of these is how the model solves the
>>>>> correlations among samples taken in the same site or levels of other
>>>>> kind
>>>>> of grouping variable.
>>>>>
>>>>> I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and
>>>>> part
>>>>> of Pinheiro and Bates (2000). But still don?t understand the way that
>>>>> GLMM
>>>>> include the correlation effect in the predictions of the model.
>>>>>
>>>>> I really appreciate any comment and/or bibliographic reference that
>>>>> help me
>>>>> understand this.
>>>>>
>>>>> Thanks in advanced,
>>>>> Joaqu?n.
>>>>>
>>>>> --
>>>>> *Joaqu?n Aldabe*
>>>>>
>>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>>>
>>>>> *Departamento de Conservaci?n*
>>>>> Aves Uruguay
>>>>> BirdLife International
>>>>> Canelones 1164, Montevideo
>>>>>
>>>>> https://sites.google.com/site/joaquin.aldabe
>>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From kristen.whitbeck at gmail.com  Tue Jul 12 20:38:19 2016
From: kristen.whitbeck at gmail.com (Kristen Whitbeck)
Date: Tue, 12 Jul 2016 12:38:19 -0600
Subject: [R-sig-ME] Vegan
Message-ID: <C720031B-6FD7-4240-ADEA-C30DE3099B01@gmail.com>

Can someone please tell me what the last version of R supports the vegan package?

Thank you!

Kris

Sent from my iPhone

From romunov at gmail.com  Tue Jul 12 20:58:38 2016
From: romunov at gmail.com (romunov)
Date: Tue, 12 Jul 2016 20:58:38 +0200
Subject: [R-sig-ME] Vegan
In-Reply-To: <C720031B-6FD7-4240-ADEA-C30DE3099B01@gmail.com>
References: <C720031B-6FD7-4240-ADEA-C30DE3099B01@gmail.com>
Message-ID: <CAHT1vpjJoRpSMS4DdxOp1ZfvatjPQdXhD+7j5vsdkDtDOwrr_w@mail.gmail.com>

`vegan` depends on R 3.0.0 or later.
https://cran.r-project.org/web/packages/vegan/index.html


Cheers,
Roman

On Tue, Jul 12, 2016 at 8:38 PM, Kristen Whitbeck <
kristen.whitbeck at gmail.com> wrote:

> Can someone please tell me what the last version of R supports the vegan
> package?
>
> Thank you!
>
> Kris
>
> Sent from my iPhone
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Jul 12 22:43:54 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Jul 2016 16:43:54 -0400
Subject: [R-sig-ME] Vegan
In-Reply-To: <CAHT1vpjJoRpSMS4DdxOp1ZfvatjPQdXhD+7j5vsdkDtDOwrr_w@mail.gmail.com>
References: <C720031B-6FD7-4240-ADEA-C30DE3099B01@gmail.com>
	<CAHT1vpjJoRpSMS4DdxOp1ZfvatjPQdXhD+7j5vsdkDtDOwrr_w@mail.gmail.com>
Message-ID: <CABghstQbG4grRo06vYStJPQSf-4puqFADsFMmHtVmLRJKF-KMg@mail.gmail.com>

PS this is more of an R-help question than an R-sig-mixed-models question ...
If you really mean the "last" version of R that supports vegan, I
would say the answer is "the latest available version", i.e. version
3.3.1 (and the development version), since there is no "less-than" or
"less-than-or-equal" condition on the page linked by Roman.  If you
mean "earliest", see Roman's question.  If you need to install vegan
on an earlier version you *can* do it by retrieving an archived
version, but it's probably to going to be a big nuisance all around.

On Tue, Jul 12, 2016 at 2:58 PM, romunov <romunov at gmail.com> wrote:
> `vegan` depends on R 3.0.0 or later.
> https://cran.r-project.org/web/packages/vegan/index.html
>
>
> Cheers,
> Roman
>
> On Tue, Jul 12, 2016 at 8:38 PM, Kristen Whitbeck <
> kristen.whitbeck at gmail.com> wrote:
>
>> Can someone please tell me what the last version of R supports the vegan
>> package?
>>
>> Thank you!
>>
>> Kris
>>
>> Sent from my iPhone
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> In God we trust, all others bring data.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Wed Jul 13 09:50:09 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 13 Jul 2016 09:50:09 +0200
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAMM93=LaVz5+J4ynETEABqXPmOhrF9HuzwRuED=hY_J4EVj_YQ@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
	<CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>
	<CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
	<CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>
	<CAJuCY5yq6pu89e2=MxVpWTT0P5YOetRfUVeRmvKABFq9dyjpOA@mail.gmail.com>
	<CAMM93=LaVz5+J4ynETEABqXPmOhrF9HuzwRuED=hY_J4EVj_YQ@mail.gmail.com>
Message-ID: <CAJuCY5xZd-qfEN1ORtZfys7PszPLbmE=NmXdm=v8bnZxO60jEQ@mail.gmail.com>

Dear Joaquin,

You can derive eqn. 5.13 from the assumptions in eqn. 5.8, which assumes
that Yi follows a normal distribution.

Note that the example is use in a chapter which introduces **linear** mixed
models. Hence a normal distribution is assumed for the sake of simplicity.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-12 19:42 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> By the way..I don?t see why it is relatively easy to show that Yi is
> normally distributed..(in fact, the Y variable is count so it should be
> poisson). This is in section 5.4 (p. 112) of Zuur et al (2009).
> Thanks,
> joaqu?n.
>
> 2016-07-12 10:52 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Joaquin,
>>
>> Yes. I think you have found a typo. The prior to equation 5.13 should
>> read "It is relatively easy to show that $Y_i$ is normally distributed
>> ..."
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-07-11 21:36 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>
>>> Sorrry, I hadn?t copied the whole group. Here it goes: Thanks Thierry,
>>>> I?ve been there a couple of times. I?ll try again. I think there is a
>>>> mistake in page 112 when says: It is relatively easy to show that Vi is
>>>> normally distributed with mean X i ? ? and variance V i in mathematical
>>>> notation...
>>>>
>>>> It should say Yi instead of Vi, right?
>>>>
>>>> Cheers,
>>>> Joaqu?n .
>>>>
>>>> 2016-07-08 9:02 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>>>
>>>>> Dear Joaquin,
>>>>>
>>>>> I'd recommend Zuur et al 2009, section 5.4
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>>> and Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be able
>>>>> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> 2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>>>>
>>>>>> Dear all, I?m a basic user of mixed models but there are things that
>>>>>> I?ve
>>>>>> found hard to understand. On of these is how the model solves the
>>>>>> correlations among samples taken in the same site or levels of other
>>>>>> kind
>>>>>> of grouping variable.
>>>>>>
>>>>>> I?ve consulted Bolker (2015) in G. Fox et al Ed., Zuur et al 2009 and
>>>>>> part
>>>>>> of Pinheiro and Bates (2000). But still don?t understand the way that
>>>>>> GLMM
>>>>>> include the correlation effect in the predictions of the model.
>>>>>>
>>>>>> I really appreciate any comment and/or bibliographic reference that
>>>>>> help me
>>>>>> understand this.
>>>>>>
>>>>>> Thanks in advanced,
>>>>>> Joaqu?n.
>>>>>>
>>>>>> --
>>>>>> *Joaqu?n Aldabe*
>>>>>>
>>>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>>>>
>>>>>> *Departamento de Conservaci?n*
>>>>>> Aves Uruguay
>>>>>> BirdLife International
>>>>>> Canelones 1164, Montevideo
>>>>>>
>>>>>> https://sites.google.com/site/joaquin.aldabe
>>>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> *Joaqu?n Aldabe*
>>>>
>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>>
>>>> *Departamento de Conservaci?n*
>>>> Aves Uruguay
>>>> BirdLife International
>>>> Canelones 1164, Montevideo
>>>>
>>>> https://sites.google.com/site/joaquin.aldabe
>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>>
>>>>
>>>
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>
>>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Jul 13 10:14:37 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 13 Jul 2016 18:14:37 +1000
Subject: [R-sig-ME] correlated samples
In-Reply-To: <CAJuCY5xZd-qfEN1ORtZfys7PszPLbmE=NmXdm=v8bnZxO60jEQ@mail.gmail.com>
References: <CAMM93=JNagp1Du8u1-jLM1m_r8ow0wa+mr9-1T9GO=f9wNXuFQ@mail.gmail.com>
	<CAJuCY5yFaBQdBnDna4sCLGeu4rDepzeZEpVvOkfym1tx3pjvWA@mail.gmail.com>
	<CAMM93=KP6_Wn6U756A88Qv1D8m+0C+krc3t0K8BFia7S5Db63Q@mail.gmail.com>
	<CAMM93=JHKMkbh1GeoHZa12uPK=3eUE83kboNXOADWydEkSMd_w@mail.gmail.com>
	<CAJuCY5yq6pu89e2=MxVpWTT0P5YOetRfUVeRmvKABFq9dyjpOA@mail.gmail.com>
	<CAMM93=LaVz5+J4ynETEABqXPmOhrF9HuzwRuED=hY_J4EVj_YQ@mail.gmail.com>
	<CAJuCY5xZd-qfEN1ORtZfys7PszPLbmE=NmXdm=v8bnZxO60jEQ@mail.gmail.com>
Message-ID: <b88e1331-2b0b-d2df-d39f-d574a5d3fa82@highstat.com>

Joaquin,

I don;t know where you get the first Vi from. My final pdf shows an Y_i, 
as you can see in the snapshot below.





However....downloading the pdf seems that the online version of the book 
does have a V_i. I guess the editing company of Springer messed up the 
text (or I didn't double check their corrections good enough).

Thierry is right in stating that the equations are for a linear mixed 
effects model with a random intercept. If there are two random 
intercepts then the equations change (See Chapter 20 in the same book).

I did look at similar expressions for the intraclass correlation for (1 
way nested and 2-way nested) Poisson GLMM. They are given in our 2012 
book. You can also find them in Nzoufras (2009). I tried to derive them 
for ZIP models, but that was quite difficult. The following two papers 
do simulation to calculate the intra-class correlation for Bernoulli GLMMs:

Goldstein H, Browne W, Rasbash J (2002) Partitioning Variation in 
Multilevel Models.
Understanding Statistics 1: 223?231.

Browne WJ, Subramanian SV, Jones K (2005) Variance partitioning in 
multilevel logistic models that
exhibit overdispersion. Journal Royal Statistical Society. Series A 168: 
599?613.

I'm sure there will be some more recent material on intraclass 
correlations for complicated GLMMs.

Alain





On 13/07/2016 17:50, Thierry Onkelinx wrote:
> Dear Joaquin,
>
> You can derive eqn. 5.13 from the assumptions in eqn. 5.8, which 
> assumes that Yi follows a normal distribution.
>
> Note that the example is use in a chapter which introduces **linear** 
> mixed models. Hence a normal distribution is assumed for the sake of 
> simplicity.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-07-12 19:42 GMT+02:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com 
> <mailto:joaquin.aldabe at gmail.com>>:
>
>     By the way..I don?t see why it is relatively easy to show that Yi
>     is normally distributed..(in fact, the Y variable is count so it
>     should be poisson). This is in section 5.4 (p. 112) of Zuur et al
>     (2009).
>     Thanks,
>     joaqu?n.
>
>     2016-07-12 10:52 GMT-03:00 Thierry Onkelinx
>     <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>:
>
>         Dear Joaquin,
>
>         Yes. I think you have found a typo. The prior to equation 5.13
>         should read "It is relatively easy to show that $Y_i$ is
>         normally distributed ..."
>
>         Best regards,
>
>         ir. Thierry Onkelinx
>         Instituut voor natuur- en bosonderzoek / Research Institute
>         for Nature and Forest
>         team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>         Assurance
>         Kliniekstraat 25
>         1070 Anderlecht
>         Belgium
>
>         To call in the statistician after the experiment is done may
>         be no more than asking him to perform a post-mortem
>         examination: he may be able to say what the experiment died
>         of. ~ Sir Ronald Aylmer Fisher
>         The plural of anecdote is not data. ~ Roger Brinner
>         The combination of some data and an aching desire for an
>         answer does not ensure that a reasonable answer can be
>         extracted from a given body of data. ~ John Tukey
>
>         2016-07-11 21:36 GMT+02:00 Joaqu?n Aldabe
>         <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>:
>
>                 Sorrry, I hadn?t copied the whole group. Here it goes:
>                 Thanks Thierry, I?ve been there a couple of times.
>                 I?ll try again. I think there is a mistake in page 112
>                 when says: It is relatively easy to show that Vi is
>                 normally distributed with mean X i ? ? and variance V
>                 i in mathematical notation...
>
>                 It should say Yi instead of Vi, right?
>
>                 Cheers,
>                 Joaqu?n .
>
>                 2016-07-08 9:02 GMT-03:00 Thierry Onkelinx
>                 <thierry.onkelinx at inbo.be
>                 <mailto:thierry.onkelinx at inbo.be>>:
>
>                     Dear Joaquin,
>
>                     I'd recommend Zuur et al 2009, section 5.4
>
>                     Best regards,
>
>                     ir. Thierry Onkelinx
>                     Instituut voor natuur- en bosonderzoek / Research
>                     Institute for Nature and Forest
>                     team Biometrie & Kwaliteitszorg / team Biometrics
>                     & Quality Assurance
>                     Kliniekstraat 25
>                     1070 Anderlecht
>                     Belgium
>
>                     To call in the statistician after the experiment
>                     is done may be no more than asking him to perform
>                     a post-mortem examination: he may be able to say
>                     what the experiment died of. ~ Sir Ronald Aylmer
>                     Fisher
>                     The plural of anecdote is not data. ~ Roger Brinner
>                     The combination of some data and an aching desire
>                     for an answer does not ensure that a reasonable
>                     answer can be extracted from a given body of data.
>                     ~ John Tukey
>
>                     2016-07-07 20:17 GMT+02:00 Joaqu?n Aldabe
>                     <joaquin.aldabe at gmail.com
>                     <mailto:joaquin.aldabe at gmail.com>>:
>
>                         Dear all, I?m a basic user of mixed models but
>                         there are things that I?ve
>                         found hard to understand. On of these is how
>                         the model solves the
>                         correlations among samples taken in the same
>                         site or levels of other kind
>                         of grouping variable.
>
>                         I?ve consulted Bolker (2015) in G. Fox et al
>                         Ed., Zuur et al 2009 and part
>                         of Pinheiro and Bates (2000). But still don?t
>                         understand the way that GLMM
>                         include the correlation effect in the
>                         predictions of the model.
>
>                         I really appreciate any comment and/or
>                         bibliographic reference that help me
>                         understand this.
>
>                         Thanks in advanced,
>                         Joaqu?n.
>
>                         --
>                         *Joaqu?n Aldabe*
>
>                         *Grupo Biodiversidad, Ambiente y Sociedad*
>                         Centro Universitario de la Regi?n Este,
>                         Universidad de la Rep?blica
>                         Ruta 15 (y Ruta 9), Km 28.500, Departamento de
>                         Rocha
>
>                         *Departamento de Conservaci?n*
>                         Aves Uruguay
>                         BirdLife International
>                         Canelones 1164, Montevideo
>
>                         https://sites.google.com/site/joaquin.aldabe
>                         <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>                         [[alternative HTML version deleted]]
>
>                         _______________________________________________
>                         R-sig-mixed-models at r-project.org
>                         <mailto:R-sig-mixed-models at r-project.org>
>                         mailing list
>                         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
>                 -- 
>                 *Joaqu?n Aldabe*
>
>                 /Grupo Biodiversidad, Ambiente y Sociedad/
>                 Centro Universitario de la Regi?n Este, Universidad de
>                 la Rep?blica
>                 Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>                 /Departamento de Conservaci?n/
>                 Aves Uruguay
>                 BirdLife International
>                 Canelones 1164, Montevideo
>
>                 https://sites.google.com/site/joaquin.aldabe
>                 <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>
>
>
>             -- 
>             *Joaqu?n Aldabe*
>
>             /Grupo Biodiversidad, Ambiente y Sociedad/
>             Centro Universitario de la Regi?n Este, Universidad de la
>             Rep?blica
>             Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>             /Departamento de Conservaci?n/
>             Aves Uruguay
>             BirdLife International
>             Canelones 1164, Montevideo
>
>             https://sites.google.com/site/joaquin.aldabe
>             <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>
>
>
>
>     -- 
>     *Joaqu?n Aldabe*
>
>     /Grupo Biodiversidad, Ambiente y Sociedad/
>     Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     /Departamento de Conservaci?n/
>     Aves Uruguay
>     BirdLife International
>     Canelones 1164, Montevideo
>
>     https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From mteresaoliveira92 at gmail.com  Thu Jul 14 00:10:53 2016
From: mteresaoliveira92 at gmail.com (Teresa Oliveira)
Date: Wed, 13 Jul 2016 23:10:53 +0100
Subject: [R-sig-ME] K-fold cross validation of GLMMs
Message-ID: <CAPvMryNAP=pp6K4tjqD-qw=F-qxRdi0gqod2uaP4EWASMzWJGw@mail.gmail.com>

Dear list members,

I would like to know if you have knowledge about any R-package that allows
to perform k-fold cross validation of a GLMM (developed with
"lme4::glmer()")?

If there is none, which other kind of cross validation do you think is
appropriate, and which packages are available?
Or which other way to validate GLMMs, rather than cross validation, do you
propose?

Thank you very much in advance for your help!

Best regards,
Teresa

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Fri Jul 15 11:16:13 2016
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Fri, 15 Jul 2016 11:16:13 +0200
Subject: [R-sig-ME] lme: several slopes, same variance, no correlation
In-Reply-To: <906c4aef-28d3-9c29-d5e0-bb015ba7c53a@highstat.com>
References: <906c4aef-28d3-9c29-d5e0-bb015ba7c53a@highstat.com>
Message-ID: <85fecf0f-893a-ba42-0c07-36b98eb9261e@maw.ru.nl>

Dear list,

I am trying to fit a model with 4 crossed (no hierarchy) random effects 
which all four are considered to be independent draws from one and the 
same normal distribution. So, all four have the same variance and the 
correlations are zero. In lmer I could specify something like:

lmer(y ~ 1+ (x1|id1) + (x2|id2) + (x3|id3) + (id4|id4))

but then four different variances would be estimated and also all the 
covariances.

Would it be possible to estimate such a model in lme, where one can have 
all kinds of correlation structures? Thanks for any help!

Ben.


From thierry.onkelinx at inbo.be  Fri Jul 15 11:44:25 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 15 Jul 2016 11:44:25 +0200
Subject: [R-sig-ME] lme: several slopes, same variance, no correlation
In-Reply-To: <85fecf0f-893a-ba42-0c07-36b98eb9261e@maw.ru.nl>
References: <906c4aef-28d3-9c29-d5e0-bb015ba7c53a@highstat.com>
	<85fecf0f-893a-ba42-0c07-36b98eb9261e@maw.ru.nl>
Message-ID: <CAJuCY5y9ge5y-KD3Xc7PPA-FwgrAm-K9zmVt=4u45r9Z5XaOTw@mail.gmail.com>

Dear Ben,

Crossed random effects are doable but not easy in nlme. It is described
somewhere in Pinheiro and Bates (2000).

However, correlation structures in nlme work only on the residuals within
the same level of the random effects. In case of nested random effects the
most detailed level is used. The residuals of observations from different
random effect levels are assumed to be independent! I'm not sure how it
works with crossed random effects but it won't surprise me if it would use
the levels of id1:id2:id3:id4. That is something you may, or may not, want.

I'd suggest that you think on how the correlation structure should work
before you try the crossed random effects in nlme. If the correlation
structure doesn't make sense, then you don't have to bother the switch from
lme4 to nlme.

Another option would be to switch to INLA (www.rinla.org) which allows for
correlated random effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-15 11:16 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:

> Dear list,
>
> I am trying to fit a model with 4 crossed (no hierarchy) random effects
> which all four are considered to be independent draws from one and the same
> normal distribution. So, all four have the same variance and the
> correlations are zero. In lmer I could specify something like:
>
> lmer(y ~ 1+ (x1|id1) + (x2|id2) + (x3|id3) + (id4|id4))
>
> but then four different variances would be estimated and also all the
> covariances.
>
> Would it be possible to estimate such a model in lme, where one can have
> all kinds of correlation structures? Thanks for any help!
>
> Ben.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Jul 15 17:12:25 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 15 Jul 2016 15:12:25 +0000
Subject: [R-sig-ME] lme: several slopes, same variance, no correlation
In-Reply-To: <CAJuCY5y9ge5y-KD3Xc7PPA-FwgrAm-K9zmVt=4u45r9Z5XaOTw@mail.gmail.com>
References: <906c4aef-28d3-9c29-d5e0-bb015ba7c53a@highstat.com>
	<85fecf0f-893a-ba42-0c07-36b98eb9261e@maw.ru.nl>
	<CAJuCY5y9ge5y-KD3Xc7PPA-FwgrAm-K9zmVt=4u45r9Z5XaOTw@mail.gmail.com>
Message-ID: <CAO7JsnQWVbvifuS3yo09dBLaVOqa9fKOY8YCSqsgh5BqZaDiSg@mail.gmail.com>

I wouldn't recommend using lme to fit models with multiple crossed
random-effects terms.  The example in Pinheiro and Bates (2000) has only a
few levels in one of the two grouping factors, which is necessary for the
method used there to work.

The methods used in lme4 are much more effective for crossed grouping
factors. (And, I might add,  the methods used in the MixedModels package
for Julia are even more effective).  As Thierry has pointed out in this
group many times, starting with a very complex model for your data is
usually not a good approach.

On Fri, Jul 15, 2016 at 4:45 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Ben,
>
> Crossed random effects are doable but not easy in nlme. It is described
> somewhere in Pinheiro and Bates (2000).
>
> However, correlation structures in nlme work only on the residuals within
> the same level of the random effects. In case of nested random effects the
> most detailed level is used. The residuals of observations from different
> random effect levels are assumed to be independent! I'm not sure how it
> works with crossed random effects but it won't surprise me if it would use
> the levels of id1:id2:id3:id4. That is something you may, or may not, want.
>
> I'd suggest that you think on how the correlation structure should work
> before you try the crossed random effects in nlme. If the correlation
> structure doesn't make sense, then you don't have to bother the switch from
> lme4 to nlme.
>
> Another option would be to switch to INLA (www.rinla.org) which allows for
> correlated random effects.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-07-15 11:16 GMT+02:00 Ben Pelzer <b.pelzer at maw.ru.nl>:
>
> > Dear list,
> >
> > I am trying to fit a model with 4 crossed (no hierarchy) random effects
> > which all four are considered to be independent draws from one and the
> same
> > normal distribution. So, all four have the same variance and the
> > correlations are zero. In lmer I could specify something like:
> >
> > lmer(y ~ 1+ (x1|id1) + (x2|id2) + (x3|id3) + (id4|id4))
> >
> > but then four different variances would be estimated and also all the
> > covariances.
> >
> > Would it be possible to estimate such a model in lme, where one can have
> > all kinds of correlation structures? Thanks for any help!
> >
> > Ben.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From alexander.shenkin at ouce.ox.ac.uk  Fri Jul 15 17:16:11 2016
From: alexander.shenkin at ouce.ox.ac.uk (Alexander Shenkin)
Date: Fri, 15 Jul 2016 16:16:11 +0100
Subject: [R-sig-ME] Factors in nlme: singularity in backsolve error
Message-ID: <e141e68d-9d4a-fd69-e8ab-3778d61a1043@ouce.ox.ac.uk>

Hello all,

I am parameterizing exponential fits for some metabolic scaling models. 
I have done this in lmer already, without problem, using logged 
dependent and independent variables.  However, I would now like to 
incorporate other parameters that aren't necessarily exponentially 
related to the dependent variable.  Hence, I've turned to nlme, but I 
don't have much experience with it.  Apologies in advance for newbie 
mistakes.

With the code below, I am getting the following error.  I'm guessing 
that it has something to do with the 'site' factor being misspecified:

Error in nlme.formula(dep ~ scaling_fun(alpha, beta, ind, site), data = 
scale_df,  :
   Singularity in backsolve at level 0, block 1

When I fit a simpler function that does not involve 'site', the model 
seems to work correctly.

Any thoughts would be greatly appreciated!  I've added the dput object 
at the bottom of the email to avoid distraction...

Thanks,
Allie


 > head(scale_df)
           dep        ind spp site
2  0.28069471 -0.0322841 157    A
3 -0.69719050 -1.2568901 183    A
4  0.29252012  0.1592420 246    A
5  0.72030740 -0.3282789 154    A
6 -0.08601891  0.3623756 110    A
7  0.30793594  0.2230840 154    A


scaling_fun <- function(alpha, beta, ind, site) {
     return(beta + ind^alpha + site*(ind^alpha))
}

# results in singularity in backsolve error

nlme(dep ~ trait_scaling_fun(alpha, beta, ind, site),
      data = scale_df,
      fixed = list(alpha + beta + site ~ 1), random = alpha ~ 1|spp,
      start = list(fixed = c(0.7, 0, 1)))


##############################
# simpler function converges #
##############################

scaling_fun <- function(alpha, beta, ind) {
     return(beta + ind^alpha)
}

nlme(dep ~ scaling_fun(alpha, beta, ind),
      data = scale_df,
      fixed = list(alpha + beta ~ 1), random = alpha ~ 1|spp,
      start = list(fixed = c(0.7, 0)))


# dput for data

scale_df = structure(list(dep = structure(c(0.280694709349609, 
-0.697190504779316,
0.29252012378561, 0.720307403285465, -0.0860189064012942, 
0.307935942585907,
0.862281389721553, -0.265859454130292, -0.662753116661401, 
-0.281590648203109,
1.17791119955669, 0.631729125553481, -0.556750637034717, 
-0.666643297610538,
0.78495323332528, 0.355622302250686, -1.26351337875593, 0.343598303486811,
-1.17350365646135, 0.660405635460007, -0.0444581036277384, 
0.722773887452235,
-0.0522058979055465, 0.65594868736652, -0.471798559774723, 
0.580581816047275,
0.514408011465886, -0.736138172672309, 0.70774857676606, 
-0.0810467855114514,
2.87816317587089, -0.224750322639999, -0.497119013269447, 
0.031618943500335,
1.93466683745019, 1.0320275291612, 0.874248439252774, -0.327339718896358,
-0.854016320390115, -1.14806351731618, -0.380316794335449, 
0.298626272822636,
-0.600084009068698, 0.836832381353764, -1.02141473458357, 
-0.0626961141428343,
-1.28013982373819, -0.126310567347687, -0.998914167194147, 
-0.966356030272785,
-0.0311625866367497, -0.456212263484603, 2.22345644904786, 
1.06808914728274,
2.04676618838053, 2.57057502230498, -1.1354565673953, -0.617861267279932,
-1.29433182429494, 0.0191424880072437, -0.31539529665173, 
-0.161941249027648,
-0.582100497448459, 1.62041284412996, 4.12468548155128, 0.181382553309611,
0.395970527486673, 0.949165316445473, 0.536508784640814, 1.88628468601066,
0.460108411105217, 1.50237201805536, -0.248693954731227, 0.604338152411222,
-0.511271387322619, -0.273625967472597, 2.54906943158448, 1.25797640582933,
-0.615499666866161, -0.83022966646613, -0.569798846726899, 
1.41607035018281,
0.806876783115155, 3.03500743372039, 0.371311069097266, 0.605523223251687,
0.960528362908707, 0.536545286280021, -1.07783545300095, 0.145069857506269,
-0.390394315762374, -0.524314770428875, -0.205267560118326, 
2.8197556390129,
0.548519073742583, 2.25991992849428, -0.274997856331803, 
-0.748248845217783,
1.27303941400619, 0.23884797601163, -0.582228991340883, -0.380185805876727,
-0.0858712197617979, -0.181441660791883, -0.122600427784157,
1.44111920784939, 0.163470634515893, -0.322754741867578, -1.08355296391174,
-0.27943230825155, -0.367498411981987, -1.25029544932326, 1.96800896885018,
0.741382953698137, 0.525448033325593, 0.58486584900894, -1.39293857038504,
0.0401527810688047, -0.428292900882259, -0.384773565802791, 
-0.347537789997483,
0.259461537066455, 1.04953062690743, 0.905652281045827, 0.921052829745329,
0.52450347921673, 1.71595979136317, -0.474652211889487, 0.986966207710898,
-0.256654313404628, 2.99291703386829, -0.874752003654369, 1.01178420482112,
5.77381325416311, -0.167933435302975, -0.746365585369451, 2.80467857407177,
1.95866740218257, -0.503053147492697, -0.0160574809046825, 
0.0121332489691898,
0.155574669334708, 0.916506565829058, -0.448074058381429, 
0.316834873904141,
1.04981848557227, -0.824609748750358, 1.06744876285501, 0.063863664699137,
-0.765846025184139, -0.557645050339089, 0.647420847566618, 
-0.481436855350583,
0.145702813289175, 0.0908652712388498, -1.18095990275663, 
-1.06285986971149,
0.152516462446235, -0.301967070920705, -0.517918792168663, 
0.184004599405834,
-0.566811364523435, 1.6331783242747, 0.690245821132717, -1.42142389781947,
0.491457304176974, 0.0627154091195769, -1.18747542803504, 
-1.82414795780551,
-0.54473248220664, -0.38718643742941, 0.202890301793843, 
-0.937796467882627,
-0.977104998380747, -0.226054462319793, -0.2570514108737, 
-0.605519390336332,
0.893219084521843, 1.2406495934532, -0.486391839711066, 0.0164259858282593,
-0.412489997094812, 0.956475434372077, 0.170823095308925, 1.12234696851596,
0.864881638376067, 2.94395902271581, -0.653625296526159, 
0.0344781331483653,
-1.11047554289386, 0.0240754964789988, 1.76294743083037, 
-0.628386617245746,
0.192639895843502, -0.0927451932802299, -0.540571719710502, 
-1.15181016752959,
0.700555244490985, -0.755243667920522, 0.00602960712621028, 
-0.586868245391815,
-1.17155166667398, 1.56392615917735, 1.97004404631982, -0.280915309650685,
-1.09667960854681, -1.26761042957248, 0.390167171160699, 
-0.868437544908412,
0.197261528411407, -1.05462502319379, 0.458230531075614, 0.670664261262915,
-1.26355771555643, 0.0544626276730709, -0.49989719331403, 
-0.73427888393413,
-1.18799702275245, -1.3936130622378, -0.934938915880832, 
-0.531815063104187,
-1.33502744780389, -1.085565964999, -0.449461886445409, -1.43582054600884,
-0.794423040257847, -1.56211060016727, -1.43010121209506, 
-1.10083462220113,
-1.01314643463123, -1.19811510591181, -1.37565527646516, -1.02664156130493,
-1.62967267575906, -1.50150574382491, -1.62882785195591, -1.12359789668463,
-1.02398490326148, -0.683499336412734, -1.1155545604915, -1.53360659069892,
-1.52610133563353, -1.81097302479998, -0.948446274692255, 
-0.419546048614108,
-1.16932468032093, -0.595422041225307, -1.22737900938278, 
-1.28673992555364,
-1.05512677626171, -1.57557323497678, -1.4766946827855, -1.57668824537509,
-1.67142161688021, -1.72152348613828, -0.711645696230758, 
-0.766535980524732,
-1.08905113531769, -1.35316559445918, -1.30885914425461, -1.61047595500881,
-1.59760049766984, -1.6142112883589, -1.39999819034864, -0.440030335981056,
-0.19564891994752, -1.23448123395016, -0.692666934199905, 
-0.96869628836432,
-1.42647633086653, -0.819947428887185, -0.870491162400872, 
-1.13186316445368,
-1.31536639789785, -0.106780345783472, -1.34173728791556, 1.22625909771354,
1.37982852819105, 0.273104569490682, 1.90808233104915, 0.638422159751792,
0.660885352597854, -0.424886845771443, 0.00042860845924302, 
0.545140506066279,
0.136397731561079, 1.00695758951666, -1.24917788259541, 
-0.0605209308736711,
-1.05532600435696, -0.602964427120747, 1.04776665949433, 
-0.852428413815971,
0.83212090285218, 0.195305492380899, 1.02775755445631, 0.140274631965342,
0.176679362074364, 0.0219452557235226, -0.493395579450221, 
0.00664958388467811,
-0.406358793092381, 1.61195643785565, -0.746014740839289, 0.55469286672927,
0.311803194810194, 0.267929653276485, -0.108631151585054, 
-0.27545070897134,
1.66808467737734, 0.413698916068735, 0.476741830667972, 0.449627013023383,
-1.06761893237941, -0.654520314456918, 0.244263943352045, 
-0.355457763818747,
1.65477719162908, -0.682875622056975, -0.592661905670813, 1.26758657033146,
1.5767017934966, 0.529018946178275, 0.845073921558493, -0.348403367842978,
0.868892260109614, 0.119903351368414, 1.1244419562376, 1.15855607750289,
1.85097015161797, 1.16296132699817, 1.04113374483116, -0.831136183842197,
1.16570524825761, 0.214085647908677, -0.193445673416235, 0.205325290939172,
0.807867170100101, 0.211944635191694, 1.01903833452256, 0.581515608742661,
-0.974294411550401, -0.0653578433223884, -0.407272960790088,
1.64357613943039, -0.411002962687008, 1.00606886817971, 0.31992987519873,
0.574580679321335, -0.620942679148953, 0.409192244773901, 
0.00488543951394021,
-0.186426274273604, 1.17953640790635, -0.385619455756059, 
-0.0895609553579481,
0.777527991507575, 1.89696362786571, 2.62789700445807, 1.48857113802541,
-0.191049329070274, 0.472885020910262, 0.953200081084007, 
-0.573874399465063,
0.39582312427189, 2.73340372487198, 0.451643036437629, 0.322328118551198,
2.41612502144468, 2.44313584825065, 0.791039923156798, 1.77391333560054,
0.678584228379532, 1.34117549430457, 1.02560460915508, 0.642953566577357,
0.6327160646872, 0.50920127124515, 1.26542872863897, 0.0513291757520665,
1.55913957405783, -0.346674887091317, 0.977805034363923, 0.18481458582038,
0.89380652637702, -1.35984199639655, -0.597199729998613, 0.476124154483983,
0.20382213848194, 0.86625758376961, 1.81576370038761, -1.14986784324603,
-0.890658192055045, -0.690103903496631, -1.34792259851183, 
-1.17277627037773,
-1.0232707668005, -1.07601506735639, -1.03419875253434, -1.25465531843128,
-0.908238115191498, -1.14888293768223, -1.30516701279404, 
-0.959154271504791,
-0.3606188318332, -1.04295641838087, -1.12344997609438, -0.657745265539639,
-1.41046953794939, -0.497392498376635, -0.696910242295569, 
-0.79994809305917,
-0.804048698121188, -0.97867617698862, -0.605950164307889, 
-1.2529239165814,
-1.05824118171373, -0.739898241678675, -1.3700045895137, 
-0.907918586540374,
-0.0398672197549609, -0.848902846699456, -1.19548457643008, 
-0.771068776601233,
-1.23790437612789, -0.843259415629804, -1.34109470352155, 
-0.585935748553824,
-1.18194756416151, -0.615789961562636, -1.05572577647201, 
-1.20921702465334,
-0.858056601314504, -1.00905885844125, -1.4075681417088, -1.51741859735151,
-0.614902309207153, -0.584063095404852, -1.07771848178745, 
-0.487689111687606,
-0.898600085149827, -0.417964362181435, -0.417964362181435, 
-0.863814796557971,
-0.613668504598238, -0.927173429103902, -0.669736198478399, 
-1.04537229065607,
-0.0171362011083743, -0.902905529489174, -0.751999926891823,
-0.661935376847641, -0.292306155060246, -0.720123706185327, 
-1.44984333068773,
-1.20609086253812, -0.38786397451965, -0.606124145901586, 
-0.570194590926828,
-0.555598194042265, -1.29979056344798, -1.05384597250481, 
-0.919468542032538,
-0.805603652782657, -1.41844766043539, -1.07175900822383, 
-0.946797457139922,
-0.828724319228962, -1.35293541590241, -1.13689539904128, 
-0.0798785843494353,
-0.618331634124303, -1.4559931897786, -1.28355330735043, -1.18554433269035,
0.0275586777219822, -1.20481537984552, -1.19024513862434, 
-0.395235767461283,
0.173381346382336, -0.572762255164991, 0.295292095379503, 
-1.31089510954771,
-0.344143720486926, -0.831061609120973, -0.977390370945667, 
-1.10149327988756,
-1.22275975457248, -1.33834521638168, -1.19157963477974, 
-0.600156277847245,
-0.614748187765859, -0.334699889183784, -1.15753800754865, 
0.517156155164548,
-0.851381825394844, -1.34285436618629, -0.465564394208394, 
-0.857524846029498,
-1.23380675705904, -1.12582955730158, -0.456185133090216, 0.23190642474228,
-0.984542065676207, -0.77473508935259, -1.01321825674572, -1.2622364069534,
-1.23803897205162, -0.559758221202299, -0.617857643563247, 
-0.729003550279869,
1.67033204887905, 1.12343207191695, -1.28987472337684, 2.0565586571076,
1.41831394144223, -0.79327474118706, -0.844458165979936, 1.36162646313719,
-0.735512619154859, 0.457415170349701, 1.10256412021404, 
-0.448778199917757,
0.635659979331729, 0.109707699307732, 0.571517444621334, 0.130565845156641,
1.14015671592146, 0.438918139189911, 0.48245879856675, -0.36344252273592,
0.359469359816509, 0.961985442469504, -0.414918795726815, 0.50782962629854,
0.140676974228199, -0.165812716346512, -0.424918313974613, 
0.42504278510862,
1.05196638494678, -0.393350736608016, 1.11771810459841, 1.43391168791847,
0.39340397596376, -0.709672569088468, -0.144338248059084, 
0.0775307115107999,
1.44356408445035, -0.552115474298283, 1.53938158728436, -0.701883587307108,
-0.511433954141368, -0.321205045336655, 1.3077446149256, 
-0.500856144844018,
-1.35028194740113, 0.0689021854703949, -1.05663439286345, 
-0.479361494389175,
-1.14712646963448, -0.33976856614697, -0.507349510671996, 
-0.0259999489797301,
-0.686791114098016, -0.0660192693974952, 0.958536171714724, 
-1.19425028261728,
-1.30201800698104, 0.0181862986910217, -0.323169846214161, 
-0.202267550155569,
-0.270093592196032, -0.477254499566796, 0.343629416747284, 
0.258301427656493,
-0.108507399582493, -0.518547267380918, 0.784352752216299, 
1.28156350529702,
-0.0256570974228843, -0.991083038992896, -0.487725059199562,
-0.422621679257172, -0.684418686964736, -1.19892127178684, 
0.240114999970401,
2.01218082075944, -0.236079750988335, 1.37283957051306, -0.75599578784428,
0.623580279836249, 0.708113106342748, -0.688153841083081, 3.60722906673547,
0.759049637554329, 1.4411579949362, 1.08909900092446, 1.6246620814854,
-0.647246307456457, 0.370499849449406, 0.652972877878095, 
-1.04587057320382,
0.0240362239588807, -0.564302132865917, -0.00719208739026172,
-0.802264523635872, -0.502056532221687, -0.531100031965904, 
0.134731185000183,
0.464741362416112, 0.0858545743494743, -0.203380824028566, 
-0.139617643642184,
0.0290979826069877, 0.307708207664093, 2.22672128459229, -1.22464809677757,
-1.10218061681262, 0.904737955147255, 0.972129130855392, 
-0.226595107037789,
0.410779833414035, -0.0831945498868851, 4.80336110525691, 
-1.20383802572621,
1.11015423685492, 0.272998753752381, 1.05834570185903, -1.04379953686758,
1.14094437312265, -0.166836699017191, -0.829479403350024, 
-0.544895495862237,
-0.256760348818661, 1.13183594065731, -0.306740700327563, 
-0.965005061283116,
-1.22682429772968, -0.90066572612443, 0.914781029105528, 1.50164156261844,
1.43392799973895, 0.76675185329739, -0.614541255047314, 1.59124682310782,
-0.292903109178336, 0.0437947277942228, 0.909638870833166, 
0.157439402274253,
-0.649023057842128, -0.89904283658918, -0.0494456615615109, 
-0.862661876601541,
1.79534325310167, 1.48776342093183, -0.170268098255415, 0.244234371640275,
0.0656365425837528, 3.04859243927187, -0.377879879379748, 
-0.57984475996934,
0.434312783276935, -0.741370663180875, 1.49604414859944, 
-0.343376197892771,
0.50226906215812, -0.902293716502219, 0.00523088901025858, 
0.654483332297671,
-0.170339481430111, 0.569385500260194, 1.29708132747283, 0.949891709243599,
1.20192717443625, -0.766434795856235, 3.54615434428768, -0.627194078598971,
-0.801089674979064, -0.0156250162179901, -0.0913233365645065,
-1.576270790215, 1.06019312010792, -0.241573857379441, -1.04878400540424,
1.78135316587079, 1.75136314621452, 0.121059484084754, -0.729585197945405,
-0.253763588678462, -0.765335513857749, -0.0682249843684433,
-0.757514694726899, 0.525240178263924, -0.728620523204325, 
2.33556017567608,
0.831482474057568, 0.267723083429966, 3.06414117686316, 0.516536741692109,
0.397979235532163, 1.62540741520308, -0.824322291436025, 0.87883692183814,
-0.595905611378605, 0.819628688272022, 0.0130998672563871, 
0.27866740023993,
0.327826922666158, -0.91217335427202, -0.0128997998821542, 
1.15361199011977,
-0.652123923400212, 0.994679625975757, 0.425444003449748, 1.0209709004156,
0.748675438295394, -0.418172442758958, -0.247421605889191, 
0.115407071389731,
-0.939588835555946, 0.415957718219395, -0.210853857347349, 
-1.01689729422553,
-0.118672444729454, -0.670536021957206, 0.512127117097271, 
-0.933737443761046,
-0.325407928293206, 1.99066909971259, 2.11822588799375, 1.89578238367564,
-0.170422993077358, -0.0937119632635209, 0.963642858067328, 
-1.18957320152876,
0.575037959739622, -0.598232718509322, 0.0865829904633331, 
0.140316763193935,
0.246977670608818, 0.320664180323731, -0.626286121471306, 
-0.997899468341695,
1.95830331119489, -0.131272700828542, 0.232379419567843, 
-0.985173539576702,
-0.421302206906856, 0.719866793214859, -0.808528893389443, 
1.49610940062615,
-0.322184668631678, -0.397844427788061, 2.25066389072725, 
-0.718298922628435,
1.7336715373154, -0.0490072846030716, -1.38509092720132, -1.2673299761835,
-0.13298402797288, 0.716003617037563, 0.552069356380146, 1.00257592453502,
-0.295043364377787, 0.950213996305332, 0.495790542757127, 0.57661021943655,
-0.420378246127038, -0.717375856671705, 2.86757862340638, 
0.539020158310173,
-1.07377878731358, 1.1768421077863, 0.249601351958952, -1.02511717045039,
1.45126647442164, -1.29170021969669, 0.421802881497714, -0.294788388358285,
3.13607505464184, 0.531654963997734, 0.541089679177317, -0.154443762799115,
-0.678742469446553, -1.2968841742999, 0.603209991887586, 
-0.889599767420185,
0.574983037297298, 0.888294795357737, -0.981200601088735, 
-0.248800774377499,
2.23872202487327, 1.45807901070214, 1.70947150738919, 0.842698757529027,
0.629457655482024, 1.48346552344249, -0.910220708656389, -0.91104462395209,
-0.967812554610126, 0.333303577393829, -1.23289939141487, 
-0.623948441249796,
-1.04557765707376, -0.511149584993588, 0.657917102535818, 1.72349601168195,
-0.505551130665463, -0.722207697897722, -0.826154616230647, 
0.438821379956384,
0.692250428907892, 0.369702384394565, 0.526982261432735, 
-0.199848590151177,
-0.500972808833397, 0.690034724978254, -0.300285672765374, 
2.18931317864781,
0.359962106949574, -0.274359391989523, -0.578477526168633, 
-0.106353704075415,
0.126543379888488, -0.530977640306322, 1.8021888590031, 0.91371639163851,
-0.419473507839852, -0.636642704272862, 0.070574820953649, 
-0.363102753245237,
0.0784513887767794, -0.606742912164582, -1.38485656500315, 
-0.358942491040509,
0.14414325698563, -0.0586691624262829, 0.208305530911087, 
-0.00640100211613056,
-0.162313210537066, 0.722114360564238, 0.841186462360913, 
-0.175214926423166,
-0.733000440953664, 0.756173176638179, 0.759264225082295, 
-0.326797072459469,
-0.832117865342888, -0.806384912082174, 1.07151282993077, 
0.236865489028706,
-0.357787477083334, 0.180039069927537, -1.01862572197358, 
-0.943922931154998,
0.571036310590255, 0.0758243131539529, -0.0155964444689164, 
0.508435963327637,
-0.900451810217602, -0.0894419454719398, -0.354777105248062,
0.754081289897291, 0.624467605018215, -0.534161069048875, 
-1.14831307445649,
-1.28543905099042, 0.435061812416575, -0.766819447435734, 
0.500219186135188,
-1.03642620903013, 2.12313575629967, 0.876201936584842, -0.037367788496134,
-0.511406317864558, -1.29263144300578, -1.281373053822, -0.231606941618388,
1.0270793305418, 1.10904020302581, -0.6242548359575, 0.163451962008105,
-0.20586520466426, 0.131665031446973, -0.263156156848662, 0.86818662592479,
-0.759536348783918, -1.03546204964, -0.702032586059559, -0.769461675438033,
1.02762245412912, 0.89948746366051, 0.783190529671046, -1.34065131726446,
-1.43247863929325, 0.589340070423619, 0.766923092825367, 1.19227523001165,
0.491068864745838, -0.92639769882172, 0.535940059205437, -1.30884332264566,
0.116859814976594, 0.325910252332917, 1.07023758286568, 0.55536987714887,
-0.0312433573485808, -1.07925151983716, -0.602062409484926, 
0.362069664768365,
0.611270190860704, -0.487133706728766, -1.04016426308067, 
0.549828966583864,
0.464684478827522, 0.0233754636460338, -0.423388563082668, 
1.05691867046465,
-0.144737921460911, 1.07731088886499, 0.8010888195835, -0.628247003372029,
-1.06003677995511, 0.938048793594014, 1.3772110568739, 1.37165471665825,
0.67047120889471, -0.722632622717748, 2.03747110312245, -0.540915113375918,
2.1839349928197, -1.03583488295698, 0.694983867158175, -0.845376245686622,
0.0812659357920631, -0.290238014918826, -0.788703711337302, 
1.16284681818975,
-0.391078306224855, -1.01536636228426, 0.756046471133255, 
-0.497306106220214,
-0.389680294002286, -0.948221054776585, -0.574223937984445, 
-0.740551178777692,
-0.086257682593323, -1.02077727468241, 2.10825047525659, 1.48053924017256,
-1.06064183851885, 0.264599318172967, -0.274780900769782, 
-0.562783015381503,
0.0747242652473198, -1.06692305214069, 1.34114707801284, 
-0.214786021744423,
-1.00660578744318, -0.619734561974843, 0.13883383360632, -1.04446106115123,
-1.16646901520906, 0.053439688163081, -0.33244489064943, 
-0.146391879488098,
-0.417834371990972, -0.410436675023389, -0.230692724853316, 
-0.303296189568602,
0.154776202108604, -0.759784832019004, 1.76953915496648, 
-0.581705843221114,
-0.290550611444112, 1.22453794657615, -0.313242436099215, 
0.280361303638651,
1.16941715267016, 0.671368282201419, 1.17660382154998, 1.32063041970405,
1.83708244744656, 0.767212806762993, 0.319221830621221, 0.711990041471,
0.54261827797175, 0.320845426207599, 0.0755812981633723, 0.216445367962462,
-0.248821258024012, -0.0896546285357983, -0.0546349754076262,
-0.258921320080528, 0.587985680867172, -0.753321654054947, 
1.06836890962014,
0.129668082323122, 0.437038272562228, 0.512841479900359, 
-0.0339534723408688,
-0.224575904615199, 0.0166529230882547, 0.545015632823714, 
0.0875276207265216,
0.370872999818545, -0.621989052426517, -0.144215006896801, 
-0.260695447170179,
-0.597150007022914, -0.196861390450694, -0.179084733400039, 
0.0474693158209794,
-0.445157234240807, 0.228044591488753, 0.550149913314531, 
-0.0298135611035657,
-0.112556863534103, 1.37623259452526, -0.441313218213333, 
0.699681221358181,
2.81486831067775, 1.28723894766397, 0.332527373874222, 0.0405597227285201,
1.00386457223451, -0.805639258354661, -0.232028562703358, 
-0.108806568471449,
0.460506445228382, 1.45536791171866), .Dim = c(1031L, 1L), 
"`scaled:center`" = 4.44880503362187, "`scaled:scale`" = 2.29257418665355),
     ind = structure(c(-0.0322840994850495, -1.25689007787688,
     0.159241954007512, -0.328278909428099, 0.362375647105683,
     0.223083971838366, 0.815073591724465, 0.51327496197861, 
-0.989914366947856,
     0.269514530260805, 0.652566637245927, 1.12267604127312, 
-0.287652170808465,
     0.385590926316902, 1.44188613042739, -0.165771954949562,
     -1.23367479866566, 1.55215870668069, -0.926072349117003,
     0.408806205528122, 0.0315579183458044, 0.983384366005806,
     -0.177379594555172, 0.205672512429951, -0.316671269822489,
     0.292729809472024, 1.36063265318812, -0.363101828244928,
     -0.229613972780416, 0.194064872824341, 1.31420209476568,
     -0.206398693569196, -1.11179458280676, 1.62180454431434,
     1.65662746313117, 1.11687222147032, 1.12847986107593, 
0.333356548091658,
     -0.409532386667367, 0.890523249160928, 0.739623934288001,
     -0.00906882027383001, -0.136752855935538, 0.902130888766538,
     -1.21626333925725, 1.29679063535727, -0.194791053963586,
     -0.751957755032856, -0.949287628328222, -0.409532386667367,
     1.50572814825825, -0.0264802796822445, 0.629351358034708,
     1.05883402344227, 2.0454833899191, 2.13254068696118, 
-0.705527196610417,
     -0.177379594555172, -0.972502907539442, 0.159241954007512,
     0.884719429358123, -0.659096638187978, -0.572039341145904,
     1.19812569870959, 2.18477506518642, 0.217280152035561, 
-1.16983278083481,
     1.71466566115922, 0.815073591724465, 3.98395920405593, 
1.49412050865264,
     0.461040583753366, -0.769369214441271, 2.0396795701163, 
-0.235417792583221,
     -0.0671070183018789, 1.07624548285068, 4.20450435656252,
     -0.705527196610417, -0.154164315343952, 0.130222854993487,
     0.768643033302025, -0.136752855935538, 2.79997996428374,
     0.28692598966922, 0.0721846569654384, 1.66243128293398, 
0.77444685310483,
     -1.23367479866566, 0.333356548091658, -0.0438917390906594,
     -0.154164315343952, -0.148360495541147, 1.41286703141337,
     1.90619171465178, -0.29345599061127, -1.22787097886286, 
0.844092690738489,
     1.20392951851239, -0.0496955588934642, -0.136752855935538,
     0.25210307085239, 1.72046948096203, 0.623547538231903, 
-0.368905648047733,
     0.954365266991782, -0.879641790694564, -1.18144042044042,
     -1.14661750162359, -0.746153935230051, -0.0380879192878545,
     -0.798388313455295, 1.64501982352556, 2.96248691876227, 
0.530686421387025,
     1.15169514028715, -0.171575774752367, 0.820877411527269,
     -0.444355305484197, 2.08030630873593, 0.600332259020684,
     1.34322119377971, 1.07624548285068, 1.47090522944142, 
3.06115185540996,
     1.41286703141337, 0.52488260158422, 1.40706321161056, 
-0.0961261173159034,
     0.594528439217879, 3.52545743963435, 1.97003373248264, 
0.432021484739342,
     3.01472129698752, 0.118615215387878, 0.0721846569654384,
     0.00253881933177994, -0.711331016413222, 0.217280152035561,
     0.815073591724465, -0.218006333174806, -0.212202513372001,
     2.23700944341166, 0.194064872824341, 0.0083426391345845,
     2.79417614448093, -0.432747665878587, 1.29098681555447, 
-0.107733756921513,
     0.118615215387878, -0.438551485681392, -0.194791053963586,
     -0.206398693569196, 0.217280152035561, 1.16330277989276,
     -0.54302024213188, -0.51980496292066, 0.658370457048732,
     -0.29345599061127, -0.345690368836514, 1.32580973437129,
     -0.252829251991635, 2.90444872073423, 1.43027849082178, 
-0.960895267933832,
     -0.154164315343952, 0.745427754090806, -0.711331016413222,
     -0.897053250102978, 0.0083426391345845, 2.58523863157996,
     1.81913441760971, -0.775173034244076, -0.798388313455295,
     -0.27024071140005, 0.281122169866415, 0.339160367894463,
     1.05883402344227, 0.907934708569343, -0.960895267933832,
     0.902130888766538, 0.51327496197861, 1.20392951851239, 
0.124419035190682,
     1.54055106707508, 0.0489693777542189, 1.58698162549751, 
0.25210307085239,
     -0.299259810414075, -1.11179458280676, -0.218006333174806,
     1.82493823741252, -0.339886549033709, -0.624273719371149,
     0.25210307085239, -0.27024071140005, -0.618469899568344,
     0.507471142175805, -0.386317107456148, 0.263710710458, 
-1.17563660063761,
     -0.165771954949562, -0.595254620357124, 2.167363605778, 
-0.560431701540295,
     -0.81579977286371, -0.908660889708588, 0.907934708569343,
     0.971776726400196, -0.165771954949562, -0.119341396527123,
     1.47670904924422, 0.832485051132879, -1.01312964615908, 
0.27531835006361,
     -0.897053250102978, -0.601058440159929, -1.07116784418713,
     -0.972502907539442, -1.05956020458152, -0.339886549033709,
     -0.868034151088954, -1.0421487451731, -0.392120927258953,
     -1.14661750162359, 0.176653413415927, -1.19885187984883,
     -1.25689007787688, -1.07116784418713, -1.07697166398993,
     -0.688115737202002, -0.589450800554319, -1.02473728576469,
     -1.23947861846847, -1.25689007787688, -1.08857930359554,
     -0.421140026272977, -0.368905648047733, -1.01893346596188,
     -0.339886549033709, -1.0363449253703, -1.09438312339834,
     -1.22787097886286, -0.630077539173953, -0.618469899568344,
     -0.583646980751514, -0.693919557004807, -0.316671269822489,
     -1.07697166398993, -0.125145216329928, -1.26849771748249,
     -1.06536402438432, -1.08277548379273, -0.833211232272124,
     -1.12920604221517, -0.775173034244076, -0.647488998582368,
     -0.873837970891759, -1.08277548379273, -0.943483808525417,
     -1.21045951945444, -1.26269389767969, -1.11179458280676,
     -0.966699087736637, -0.444355305484197, 0.582920799612269,
     -1.11759840260956, -0.711331016413222, -0.943483808525417,
     -0.81579977286371, -1.05956020458152, -0.641685178779563,
     -0.931876168919808, -1.26269389767969, 0.0895961163738533,
     -0.467570584695416, 0.153438134204707, 0.664174276851537,
     -0.734546295624441, 0.722212474879586, -0.902857069905783,
     -1.01893346596188, -0.978306727342247, -0.937679988722612,
     -0.780976854046881, -0.972502907539442, -0.577843160948709,
     -0.978306727342247, -0.368905648047733, -0.635881358976758,
     -0.873837970891759, 0.693193375865562, -1.11759840260956,
     -0.775173034244076, -0.82740741246932, -0.717134836216027,
     -0.81579977286371, -0.299259810414075, -0.25863307179444,
     -0.693919557004807, -0.548824061934685, -0.618469899568344,
     -0.0380879192878545, -0.676508097596392, -0.171575774752367,
     -0.310867450019684, -0.670704277793587, 0.118615215387878,
     -0.415336206470172, 0.304337449077634, -0.873837970891759,
     -0.786780673849685, 0.873111789752514, -0.572039341145904,
     -0.740350115427246, -0.769369214441271, -0.0671070183018789,
     0.698997195668367, -0.693919557004807, -0.821603592666515,
     1.04142256403386, 0.25210307085239, -0.705527196610417, 
0.54809788079544,
     -0.432747665878587, -0.537216422329075, -0.699723376807612,
     0.321748908486049, 0.466844403556171, 0.710604835273976,
     0.495863502570196, 0.675781916457147, -0.618469899568344,
     1.23875243732922, -0.235417792583221, 0.675781916457147,
     0.553901700598245, 1.49412050865264, -0.200594873766391,
     1.28518299575166, 1.41286703141337, -0.995718186750661, 
1.38965175220215,
     0.269514530260805, 1.20392951851239, -0.0845184777102936,
     1.51733578786386, -0.27024071140005, 0.188261053021536, 
-0.142556675738343,
     0.0721846569654384, 1.23875243732922, 0.739623934288001,
     2.88123344152301, 0.745427754090806, -0.55462788173749, 
0.194064872824341,
     1.53474724727227, 0.635155177837513, 3.7053758535213, 
0.965972906597391,
     1.87136879583495, 1.97583755228544, -0.351494188639318, 
0.223083971838366,
     1.76109621958166, 1.30259445516008, 0.739623934288001, 
2.07450248893313,
     3.64733765549325, -0.00906882027383001, 1.40125939180776,
     0.461040583753366, 2.81739142369215, 1.929406993863, 1.97003373248264,
     1.55796252648349, -0.299259810414075, 1.65662746313117, 
1.81333059780691,
     1.47090522944142, -0.601058440159929, 1.2097333383152, 
-0.200594873766391,
     0.954365266991782, -0.618469899568344, -0.403728566864563,
     1.06463784324507, 0.600332259020684, 1.5695701660891, 
0.919542348174953,
     -1.23367479866566, -0.943483808525417, -0.403728566864563,
     -1.14081368182078, -1.11759840260956, -1.03054110556749,
     -1.00732582635627, -1.07697166398993, -1.03054110556749,
     -0.931876168919808, -1.25689007787688, -1.17563660063761,
     -0.809995953060905, -0.409532386667367, -0.635881358976758,
     -1.22206715906005, -0.392120927258953, -1.11179458280676,
     -0.287652170808465, -1.21626333925725, -1.03054110556749,
     -1.07116784418713, -1.05375638477871, -1.0421487451731, 
-1.08277548379273,
     -1.21626333925725, -1.04795256497591, -1.31492827590493,
     -0.955091448131027, -0.467570584695416, -0.601058440159929,
     -1.10018694320115, -1.19304806004603, -0.757761574835661,
     -0.438551485681392, -1.164028961032, -1.01312964615908, 
-1.24528243827127,
     -0.490785863906636, -0.879641790694564, -1.09438312339834,
     -1.0421487451731, -0.409532386667367, -1.19885187984883,
     -1.05956020458152, -0.55462788173749, -0.763565394638466,
     -0.995718186750661, -0.763565394638466, -0.763565394638466,
     -0.374709467850538, -0.937679988722612, -1.07116784418713,
     -1.03054110556749, -0.891249430300173, -0.879641790694564,
     -0.966699087736637, 0.0779884767682434, -1.29751681649652,
     -0.937679988722612, -0.728742475821636, -0.81579977286371,
     -1.11179458280676, -1.00152200655347, -1.21626333925725,
     -0.444355305484197, -1.26269389767969, -0.79258449365249,
     -0.467570584695416, -0.960895267933832, -1.01312964615908,
     -1.04795256497591, -0.751957755032856, -1.2743015372853,
     -1.2743015372853, -1.19885187984883, -0.479178224301026,
     -1.30912445610213, -0.885445610497369, -0.212202513372001,
     -0.699723376807612, -1.19885187984883, -1.03054110556749,
     -1.00732582635627, -1.164028961032, -1.30332063629932, 
-1.00152200655347,
     -0.572039341145904, -0.659096638187978, -1.32653591551054,
     -0.357298008442123, -0.775173034244076, -0.363101828244928,
     -0.653292818385173, -1.2743015372853, -0.8041921332581, 
0.0663808371626334,
     -0.908660889708588, -0.844818871877734, -0.560431701540295,
     -0.682311917399197, -0.0787146579074886, -0.908660889708588,
     0.28692598966922, -0.931876168919808, -1.03054110556749,
     -0.159968135146757, -0.618469899568344, -0.496589683709441,
     -1.18144042044042, -0.351494188639318, -0.00326500047102503,
     -0.548824061934685, -0.647488998582368, -0.589450800554319,
     -1.01893346596188, -0.873837970891759, -0.455962945089807,
     -0.455962945089807, -0.484982044103831, 2.97989837817069,
     0.437825304542147, -1.28590917689091, 1.22714479772361, 
-0.345690368836514,
     2.08030630873593, 1.05303020363946, 1.30259445516008, 
-0.0787146579074886,
     0.606136078823489, 0.925346167977757, -0.508197323315051,
     1.15169514028715, -0.525608782723465, -0.194791053963586,
     -0.252829251991635, -0.0554993786962692, 0.0141464589373895,
     0.565509340203854, -0.426943846075782, -0.374709467850538,
     1.26196771654044, 0.194064872824341, 0.571313160006659, 
-0.223810152977611,
     0.443629124344951, -0.82740741246932, -0.305063630216879,
     -0.368905648047733, 0.356571827302878, 0.948561447188977,
     0.408806205528122, -0.200594873766391, -0.119341396527123,
     -0.27024071140005, 0.159241954007512, 0.327552728288854,
     -0.444355305484197, 1.97003373248264, -0.833211232272124,
     0.24049543124678, 0.170849593613122, 0.0779884767682434,
     -0.612666079765539, -0.374709467850538, -0.212202513372001,
     -0.769369214441271, 1.453493770033, -0.931876168919808, 
-0.119341396527123,
     -0.891249430300173, 0.170849593613122, -0.53141260252627,
     0.339160367894463, 0.971776726400196, -0.902857069905783,
     -1.164028961032, -0.0671070183018789, -0.421140026272977,
     -0.467570584695416, -0.664900457990783, -0.734546295624441,
     -0.0729108381046839, 0.716408655076781, 0.484255862964586,
     -0.241221612386026, -0.415336206470172, 0.432021484739342,
     -0.310867450019684, -0.937679988722612, -0.537216422329075,
     -0.014872640076635, -0.844818871877734, -0.484982044103831,
     -0.212202513372001, 0.385590926316902, -0.363101828244928,
     0.182457233218731, -0.479178224301026, -0.316671269822489,
     -0.734546295624441, -0.8041921332581, 2.7535494058613, 
0.542294060992635,
     3.03793657619874, 1.04722638383666, 1.73207712056764, 
-0.682311917399197,
     0.867307969949709, -0.682311917399197, -0.839015052074929,
     -0.978306727342247, -0.479178224301026, -0.577843160948709,
     -0.670704277793587, 0.0199502787401944, -0.717134836216027,
     0.00253881933177994, -0.252829251991635, 0.298533629274829,
     -0.583646980751514, -0.357298008442123, -0.212202513372001,
     0.391394746119707, 1.05883402344227, -0.763565394638466,
     -0.775173034244076, 1.18071423930117, 0.948561447188977,
     -0.241221612386026, 0.403002385725317, -0.455962945089807,
     5.06346968737765, -0.879641790694564, 0.913738528372148,
     0.588724619415074, 0.368179466908488, -0.386317107456148,
     0.51327496197861, 1.05883402344227, -0.873837970891759, 
0.826681231330074,
     -0.514001143117855, -0.508197323315051, 0.565509340203854,
     -0.937679988722612, 0.199868692627146, -0.734546295624441,
     -0.241221612386026, -0.223810152977611, -0.421140026272977,
     -0.455962945089807, 1.37804411259654, 1.41867085121617, 
-0.688115737202002,
     -0.29345599061127, 1.81913441760971, -0.27024071140005, 
-0.601058440159929,
     -0.154164315343952, -0.653292818385173, -0.305063630216879,
     0.826681231330074, 1.59858926510312, -0.560431701540295,
     -0.0322840994850495, -0.357298008442123, 0.965972906597391,
     -0.403728566864563, -0.438551485681392, -0.386317107456148,
     -0.821603592666515, 0.751231573893611, -0.467570584695416,
     -0.339886549033709, -0.949287628328222, -0.630077539173953,
     0.339160367894463, 0.0489693777542189, -0.206398693569196,
     -0.00326500047102503, -0.833211232272124, 0.269514530260805,
     -0.780976854046881, 1.5753739858919, -1.02473728576469, 
-0.780976854046881,
     0.321748908486049, -0.0729108381046839, -0.984110547145052,
     0.455236763950561, 0.27531835006361, -0.821603592666515,
     0.582920799612269, 0.339160367894463, -0.0903222975130984,
     -0.165771954949562, -0.0787146579074886, -0.53141260252627,
     0.495863502570196, -1.03054110556749, 0.344964187697268,
     -1.11759840260956, 1.5695701660891, 0.675781916457147, 
0.333356548091658,
     4.20450435656252, 1.91779935425739, -0.949287628328222, 
0.397198565922512,
     -1.19304806004603, 0.228887791641171, -0.931876168919808,
     0.832485051132879, -0.601058440159929, -0.125145216329928,
     0.182457233218731, -0.839015052074929, -0.200594873766391,
     1.99324901169386, -0.978306727342247, -0.0380879192878545,
     -0.25863307179444, -0.757761574835661, 0.443629124344951,
     -0.577843160948709, 0.368179466908488, -0.339886549033709,
     -1.12920604221517, -0.287652170808465, -0.0438917390906594,
     -1.25108625807408, 1.0936569422591, 0.0431655579514139, 
-0.502393503512246,
     -0.856426511483344, -0.136752855935538, 0.223083971838366,
     -0.101929937118708, 0.263710710458, -0.873837970891759, 
-0.51980496292066,
     -0.374709467850538, -0.757761574835661, -0.734546295624441,
     -0.28184835100566, -0.82740741246932, 0.687389556062757,
     0.420413845133732, -0.0671070183018789, -0.722938656018832,
     -0.618469899568344, 2.76515704546691, 0.0083426391345845,
     -0.421140026272977, -0.351494188639318, -0.955091448131027,
     1.91199553445459, -0.595254620357124, 1.46510140963861, 
-0.618469899568344,
     0.0953999361766579, 3.18883589107166, -0.235417792583221,
     3.15401297225484, 0.0489693777542189, -1.10018694320115,
     -0.125145216329928, -0.194791053963586, 0.199868692627146,
     1.0936569422591, 0.53649024118983, -0.368905648047733, 
1.77270385918727,
     0.617743718429098, 1.12267604127312, -0.142556675738343,
     -0.635881358976758, 4.08842796050642, -0.25863307179444,
     -0.0729108381046839, 2.71292266724166, -0.548824061934685,
     0.571313160006659, 0.884719429358123, -0.914464709511393,
     0.623547538231903, -0.0903222975130984, 5.27240720027862,
     1.88297643544056, -0.473374404498221, -0.339886549033709,
     -0.82740741246932, -0.798388313455295, -0.212202513372001,
     -0.699723376807612, 0.675781916457147, 0.0315579183458044,
     -0.653292818385173, -0.81579977286371, 1.00079582541422,
     0.768643033302025, 4.72684813881496, 0.199868692627146, 
0.571313160006659,
     0.426217664936537, -0.415336206470172, -0.502393503512246,
     -0.572039341145904, 1.22134097792081, -1.06536402438432,
     -0.287652170808465, -0.142556675738343, -0.328278909428099,
     -0.357298008442123, 3.12499387324081, 0.170849593613122,
     -0.159968135146757, -0.351494188639318, 0.00253881933177994,
     -0.595254620357124, 0.553901700598245, 1.11106840166751,
     -0.833211232272124, -0.0613031984990739, 0.687389556062757,
     -0.868034151088954, 1.94101463346861, 0.194064872824341,
     -0.380513287653343, -0.148360495541147, -0.676508097596392,
     -0.27024071140005, -0.833211232272124, 1.29098681555447,
     0.507471142175805, -0.450159125287002, -0.717134836216027,
     -0.873837970891759, 0.269514530260805, -0.659096638187978,
     -0.891249430300173, -0.908660889708588, 0.472648223358976,
     -0.229613972780416, -1.07697166398993, -0.624273719371149,
     -0.780976854046881, 1.27357535614605, -0.0613031984990739,
     1.34322119377971, 0.577116979809464, -0.415336206470172,
     1.05883402344227, 0.0779884767682434, -0.751957755032856,
     -0.0845184777102936, -0.821603592666515, 0.855700330344099,
     -0.978306727342247, -0.218006333174806, -0.833211232272124,
     -0.734546295624441, -0.955091448131027, 1.25036007693483,
     -0.920268529314198, 0.199868692627146, -0.897053250102978,
     -1.03054110556749, -1.22206715906005, -0.931876168919808,
     -0.455962945089807, -0.177379594555172, 0.27531835006361,
     -0.995718186750661, -0.926072349117003, -0.757761574835661,
     -0.839015052074929, 0.385590926316902, -1.14081368182078,
     1.00659964521703, 0.716408655076781, 0.664174276851537, 
-0.728742475821636,
     -0.943483808525417, -0.891249430300173, -0.740350115427246,
     0.51327496197861, 0.362375647105683, -0.502393503512246,
     -0.374709467850538, -0.374709467850538, 1.15169514028715,
     0.890523249160928, 0.716408655076781, -0.0380879192878545,
     -0.717134836216027, -0.264436891597245, -0.27024071140005,
     0.844092690738489, -0.276044531202855, 0.77444685310483,
     -0.537216422329075, -0.525608782723465, 0.194064872824341,
     0.77444685310483, 0.832485051132879, 0.147634314401902, 
-1.13500986201798,
     -0.455962945089807, -0.960895267933832, -1.0421487451731,
     -0.496589683709441, 0.902130888766538, 0.646762817443122,
     -0.798388313455295, -0.0554993786962692, -0.879641790694564,
     0.397198565922512, 0.983384366005806, 0.54809788079544, 
-0.502393503512246,
     1.12267604127312, -0.177379594555172, 0.0779884767682434,
     -0.421140026272977, 1.35482883338532, -0.386317107456148,
     0.188261053021536, -0.676508097596392, 0.124419035190682,
     0.472648223358976, -0.496589683709441, 0.553901700598245,
     1.25036007693483, 0.130222854993487, -0.339886549033709,
     1.58698162549751, 0.815073591724465, 0.693193375865562, 
-0.55462788173749,
     1.23875243732922, -0.705527196610417, -0.821603592666515,
     -0.537216422329075, -0.780976854046881, -0.136752855935538,
     2.83480288310057, -0.444355305484197, 1.02981492442825, 
0.611939898626293,
     -0.444355305484197, -0.426943846075782, -1.03054110556749,
     -0.287652170808465, -0.728742475821636, -0.415336206470172,
     2.96248691876227, 2.83480288310057, -0.345690368836514, 
0.037361738148609,
     -0.339886549033709, 0.333356548091658, 0.118615215387878,
     -0.450159125287002, 1.38965175220215, -0.0903222975130984,
     -0.809995953060905, -0.241221612386026, -0.276044531202855,
     -0.914464709511393, -0.241221612386026, -0.194791053963586,
     -0.0729108381046839, -0.0729108381046839, -0.00906882027383001,
     -0.154164315343952, 0.861504150146904, 0.443629124344951,
     0.263710710458, -0.821603592666515, 2.06289484932752, 
-0.856426511483344,
     -0.148360495541147, 0.165045773810317, -0.351494188639318,
     0.466844403556171, -0.688115737202002, 0.107007575782268,
     0.890523249160928, 1.01820728482264, 1.07624548285068, 
0.234691611443976,
     0.223083971838366, 0.0083426391345845, 0.107007575782268,
     0.0663808371626334, -1.34394737491895, -0.908660889708588,
     -1.2743015372853, 0.530686421387025, -1.03054110556749, 
-0.188987234160782,
     -1.21045951945444, -1.06536402438432, 1.38965175220215, 
-1.30912445610213,
     -1.0421487451731, -0.392120927258953, 0.25210307085239, 
0.472648223358976,
     0.344964187697268, -0.247025432188831, 0.449432944147756,
     1.32000591456849, -0.0438917390906594, -0.5662355213431,
     -0.148360495541147, -0.624273719371149, -0.589450800554319,
     -0.165771954949562, -0.0845184777102936, 0.165045773810317,
     0.188261053021536, -0.374709467850538, -0.432747665878587,
     -0.0380879192878545, 0.478452043161781, -0.223810152977611,
     1.47090522944142, 0.582920799612269, -0.119341396527123,
     -0.426943846075782, -0.107733756921513, 0.0721846569654384,
     -0.775173034244076, -0.107733756921513, 0.141830494599097,
     0.27531835006361, 0.00253881933177994), .Dim = c(1031L, 1L
     ), "`scaled:center`" = 16.3281280310378, "`scaled:scale`" = 
8.61501592034884),
     spp = structure(c(157L, 183L, 246L, 154L, 110L, 154L, 186L,
     154L, 165L, 245L, 110L, 275L, 246L, 154L, 55L, 157L, 183L,
     55L, 183L, 275L, 157L, 55L, 246L, 154L, 245L, 110L, 110L,
     246L, 245L, 245L, 186L, 245L, 183L, 275L, 186L, 186L, 186L,
     110L, 246L, 275L, 55L, 157L, 157L, 55L, 183L, 275L, 270L,
     80L, 99L, 80L, 141L, 75L, 160L, 10L, 70L, 265L, 64L, 78L,
     147L, 75L, 239L, 64L, 101L, 239L, 70L, 99L, 222L, 226L, 114L,
     265L, 23L, 160L, 241L, 114L, 270L, 20L, 226L, 70L, 241L,
     75L, 101L, 114L, 147L, 226L, 50L, 180L, 71L, 270L, 141L,
     51L, 180L, 101L, 160L, 10L, 10L, 20L, 51L, 50L, 51L, 71L,
     64L, 180L, 265L, 71L, 20L, 239L, 99L, 222L, 222L, 80L, 241L,
     147L, 70L, 239L, 114L, 114L, 227L, 173L, 37L, 81L, 81L, 239L,
     197L, 114L, 265L, 239L, 63L, 197L, 63L, 227L, 265L, 197L,
     179L, 179L, 70L, 173L, 70L, 179L, 227L, 81L, 20L, 37L, 265L,
     20L, 37L, 265L, 46L, 44L, 63L, 43L, 210L, 124L, 240L, 63L,
     105L, 262L, 262L, 210L, 98L, 62L, 237L, 236L, 209L, 168L,
     2L, 124L, 263L, 240L, 2L, 63L, 168L, 44L, 263L, 263L, 162L,
     105L, 236L, 2L, 236L, 98L, 105L, 209L, 136L, 260L, 264L,
     46L, 2L, 184L, 2L, 69L, 86L, 260L, 264L, 136L, 237L, 209L,
     86L, 136L, 236L, 168L, 86L, 98L, 44L, 69L, 237L, 185L, 185L,
     184L, 237L, 264L, 86L, 260L, 44L, 69L, 236L, 116L, 208L,
     92L, 13L, 13L, 266L, 249L, 201L, 266L, 249L, 79L, 201L, 90L,
     123L, 25L, 145L, 214L, 13L, 72L, 134L, 134L, 214L, 208L,
     212L, 8L, 92L, 92L, 134L, 212L, 208L, 153L, 214L, 8L, 211L,
     8L, 90L, 133L, 133L, 211L, 201L, 25L, 145L, 92L, 92L, 153L,
     72L, 90L, 72L, 123L, 266L, 79L, 211L, 145L, 212L, 153L, 25L,
     116L, 249L, 123L, 79L, 116L, 61L, 273L, 150L, 57L, 156L,
     156L, 156L, 174L, 57L, 156L, 247L, 156L, 274L, 200L, 166L,
     61L, 111L, 247L, 166L, 166L, 247L, 200L, 200L, 200L, 174L,
     166L, 56L, 56L, 56L, 274L, 274L, 274L, 274L, 61L, 166L, 247L,
     57L, 150L, 150L, 174L, 150L, 273L, 150L, 174L, 273L, 111L,
     174L, 200L, 56L, 56L, 247L, 111L, 61L, 61L, 273L, 273L, 156L,
     71L, 24L, 77L, 1L, 135L, 234L, 131L, 63L, 135L, 1L, 234L,
     9L, 192L, 71L, 234L, 192L, 43L, 131L, 63L, 43L, 132L, 43L,
     132L, 238L, 89L, 89L, 159L, 238L, 159L, 24L, 24L, 135L, 1L,
     63L, 238L, 89L, 131L, 192L, 71L, 135L, 9L, 9L, 9L, 205L,
     26L, 205L, 259L, 258L, 26L, 259L, 258L, 269L, 26L, 258L,
     205L, 259L, 269L, 135L, 212L, 145L, 33L, 201L, 253L, 25L,
     253L, 253L, 272L, 153L, 34L, 133L, 153L, 242L, 242L, 34L,
     219L, 72L, 88L, 76L, 76L, 76L, 15L, 17L, 220L, 145L, 15L,
     201L, 83L, 88L, 153L, 133L, 102L, 83L, 33L, 34L, 193L, 212L,
     220L, 214L, 214L, 17L, 88L, 73L, 220L, 193L, 17L, 272L, 15L,
     242L, 93L, 93L, 257L, 39L, 25L, 25L, 39L, 93L, 35L, 72L,
     214L, 83L, 211L, 102L, 102L, 93L, 145L, 211L, 219L, 72L,
     257L, 272L, 39L, 133L, 257L, 212L, 219L, 72L, 193L, 33L,
     83L, 271L, 47L, 146L, 149L, 233L, 195L, 83L, 278L, 201L,
     120L, 163L, 253L, 254L, 112L, 195L, 88L, 163L, 278L, 253L,
     266L, 271L, 14L, 120L, 14L, 149L, 88L, 47L, 112L, 112L, 83L,
     254L, 14L, 254L, 163L, 233L, 47L, 253L, 253L, 88L, 148L,
     130L, 169L, 127L, 117L, 169L, 65L, 127L, 130L, 169L, 254L,
     228L, 172L, 148L, 187L, 204L, 19L, 204L, 117L, 228L, 187L,
     148L, 204L, 117L, 187L, 65L, 172L, 172L, 19L, 19L, 254L,
     65L, 191L, 191L, 190L, 130L, 127L, 228L, 254L, 94L, 229L,
     118L, 118L, 191L, 229L, 252L, 94L, 213L, 224L, 252L, 172L,
     158L, 231L, 38L, 213L, 224L, 230L, 213L, 191L, 38L, 94L,
     228L, 230L, 158L, 158L, 172L, 191L, 38L, 172L, 224L, 228L,
     38L, 230L, 229L, 252L, 41L, 107L, 4L, 152L, 41L, 107L, 107L,
     6L, 126L, 6L, 6L, 255L, 276L, 4L, 104L, 140L, 152L, 125L,
     104L, 151L, 196L, 104L, 57L, 199L, 276L, 4L, 57L, 60L, 40L,
     95L, 50L, 140L, 171L, 40L, 125L, 196L, 196L, 216L, 140L,
     40L, 95L, 125L, 50L, 171L, 178L, 82L, 178L, 74L, 204L, 194L,
     82L, 276L, 82L, 204L, 126L, 74L, 60L, 194L, 178L, 74L, 57L,
     95L, 126L, 50L, 68L, 60L, 40L, 255L, 216L, 194L, 41L, 68L,
     255L, 68L, 204L, 235L, 68L, 250L, 41L, 41L, 161L, 31L, 256L,
     85L, 267L, 66L, 38L, 255L, 139L, 85L, 161L, 215L, 268L, 204L,
     161L, 250L, 221L, 68L, 250L, 255L, 221L, 221L, 139L, 215L,
     4L, 104L, 256L, 104L, 3L, 3L, 267L, 66L, 96L, 235L, 256L,
     38L, 4L, 103L, 4L, 104L, 41L, 31L, 68L, 268L, 119L, 103L,
     187L, 119L, 187L, 53L, 215L, 267L, 235L, 119L, 204L, 113L,
     53L, 268L, 181L, 113L, 68L, 181L, 204L, 113L, 255L, 53L,
     139L, 38L, 68L, 103L, 68L, 187L, 31L, 36L, 206L, 177L, 128L,
     225L, 190L, 189L, 28L, 218L, 11L, 177L, 54L, 137L, 202L,
     121L, 202L, 129L, 206L, 121L, 177L, 91L, 190L, 189L, 169L,
     189L, 129L, 202L, 169L, 203L, 137L, 42L, 22L, 190L, 21L,
     106L, 138L, 194L, 251L, 138L, 36L, 21L, 194L, 137L, 54L,
     218L, 203L, 251L, 128L, 251L, 36L, 128L, 28L, 11L, 28L, 42L,
     138L, 206L, 169L, 22L, 218L, 91L, 203L, 106L, 106L, 91L,
     22L, 243L, 27L, 128L, 128L, 164L, 223L, 243L, 164L, 279L,
     16L, 194L, 164L, 207L, 27L, 223L, 244L, 188L, 45L, 143L,
     232L, 84L, 45L, 194L, 217L, 232L, 54L, 207L, 217L, 232L,
     176L, 45L, 217L, 143L, 243L, 144L, 143L, 49L, 176L, 176L,
     175L, 223L, 194L, 128L, 16L, 169L, 188L, 244L, 188L, 169L,
     84L, 54L, 244L, 49L, 166L, 108L, 52L, 166L, 166L, 56L, 273L,
     155L, 155L, 155L, 155L, 273L, 108L, 5L, 5L, 273L, 100L, 155L,
     100L, 97L, 59L, 59L, 100L, 198L, 165L, 171L, 171L, 171L,
     165L, 100L, 198L, 67L, 273L, 97L, 277L, 67L, 67L, 5L, 5L,
     97L, 165L, 108L, 198L, 182L, 182L, 182L, 59L, 277L, 108L,
     165L, 52L, 97L, 5L, 277L, 100L, 59L, 182L, 198L, 52L, 273L,
     56L, 56L, 198L, 165L, 67L, 166L, 277L, 59L, 56L, 52L, 171L,
     277L, 182L, 67L, 171L, 155L, 166L, 97L, 52L, 56L, 122L, 248L,
     12L, 47L, 142L, 142L, 32L, 7L, 248L, 87L, 122L, 122L, 7L,
     170L, 170L, 29L, 12L, 7L, 32L, 261L, 48L, 170L, 87L, 48L,
     29L, 142L, 12L, 261L, 47L, 87L, 261L, 29L, 248L, 48L, 122L,
     32L, 47L, 274L, 97L, 109L, 30L, 115L, 58L, 58L, 58L, 115L,
     56L, 274L, 56L, 55L, 273L, 273L, 274L, 56L, 274L, 274L, 274L,
     166L, 55L, 58L, 274L, 273L, 273L, 56L, 277L, 115L, 115L,
     58L, 55L, 18L, 18L, 166L, 166L, 277L, 109L, 56L, 274L, 115L,
     200L, 55L, 18L, 18L, 58L, 277L, 277L, 200L, 277L, 200L, 167L,
     273L, 200L, 274L, 274L), .Label = c("1", "2", "3", "4", "5",
     "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16",
     "17", "18", "19", "20", "21", "22", "23", "24", "25", "26",
     "27", "28", "29", "30", "31", "32", "33", "34", "35", "36",
     "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
     "47", "48", "49", "50", "51", "52", "53", "54", "55", "56",
     "57", "58", "59", "60", "61", "62", "63", "64", "65", "66",
     "67", "68", "69", "70", "71", "72", "73", "74", "75", "76",
     "77", "78", "79", "80", "81", "82", "83", "84", "85", "86",
     "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
     "97", "98", "99", "100", "101", "102", "103", "104", "105",
     "106", "107", "108", "109", "110", "111", "112", "113", "114",
     "115", "116", "117", "118", "119", "120", "121", "122", "123",
     "124", "125", "126", "127", "128", "129", "130", "131", "132",
     "133", "134", "135", "136", "137", "138", "139", "140", "141",
     "142", "143", "144", "145", "146", "147", "148", "149", "150",
     "151", "152", "153", "154", "155", "156", "157", "158", "159",
     "160", "161", "162", "163", "164", "165", "166", "167", "168",
     "169", "170", "171", "172", "173", "174", "175", "176", "177",
     "178", "179", "180", "181", "182", "183", "184", "185", "186",
     "187", "188", "189", "190", "191", "192", "193", "194", "195",
     "196", "197", "198", "199", "200", "201", "202", "203", "204",
     "205", "206", "207", "208", "209", "210", "211", "212", "213",
     "214", "215", "216", "217", "218", "219", "220", "221", "222",
     "223", "224", "225", "226", "227", "228", "229", "230", "231",
     "232", "233", "234", "235", "236", "237", "238", "239", "240",
     "241", "242", "243", "244", "245", "246", "247", "248", "249",
     "250", "251", "252", "253", "254", "255", "256", "257", "258",
     "259", "260", "261", "262", "263", "264", "265", "266", "267",
     "268", "269", "270", "271", "272", "273", "274", "275", "276",
     "277", "278", "279"), class = "factor"), site = structure(c(1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
     19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
     19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
     19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
     19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L, 19L,
     19L, 19L, 19L, 19L, 19L, 19L, 20L, 20L, 20L, 20L, 20L, 20L,
     20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
     20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L, 20L,
     20L, 20L, 20L, 20L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
     18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
     18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 18L,
     18L, 18L, 18L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
     17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
     17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L, 17L,
     17L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
     11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
     11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
     11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
     11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
     11L, 11L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
     16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
     16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
     16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L,
     16L, 16L, 16L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L,
     15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
     12L, 12L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 13L, 13L,
     13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
     13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,
     13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 8L, 8L,
     8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
     8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
     8L, 8L, 8L, 8L, 8L, 8L, 8L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
     7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
     7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 5L, 5L,
     5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
     5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
     5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
     5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
     5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
     6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
     6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
     6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
     6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
     6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
     6L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
     10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
     10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
     10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
     10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
     10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 9L, 9L, 9L, 9L,
     9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
     9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
     9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
     9L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 14L, 14L, 14L, 14L, 14L, 14L,
     14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
     14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
     14L, 14L, 14L, 14L, 14L, 14L, 14L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     2L, 2L, 2L, 2L, 2L), .Label = c("A", "B", "C", "D", "E",
     "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "Q", "R",
     "S", "T", "U"), class = "factor")), .Names = c("dep", "ind",
"spp", "site"), row.names = c(2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L,
36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L,
49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L,
62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L,
75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L,
88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L,
112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L,
123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L,
134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L, 142L, 143L, 144L,
145L, 146L, 147L, 148L, 149L, 150L, 151L, 152L, 153L, 154L, 155L,
156L, 157L, 158L, 159L, 160L, 162L, 163L, 164L, 165L, 166L, 167L,
168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L, 177L, 178L,
179L, 180L, 181L, 182L, 184L, 185L, 186L, 187L, 188L, 189L, 190L,
191L, 192L, 193L, 194L, 195L, 196L, 197L, 198L, 199L, 200L, 201L,
202L, 203L, 204L, 205L, 206L, 207L, 208L, 209L, 210L, 211L, 212L,
213L, 214L, 215L, 216L, 217L, 218L, 219L, 220L, 221L, 222L, 223L,
224L, 225L, 226L, 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L,
235L, 236L, 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L,
246L, 247L, 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L,
257L, 258L, 259L, 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L,
268L, 269L, 270L, 271L, 272L, 273L, 274L, 275L, 276L, 277L, 279L,
280L, 290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 298L, 299L,
300L, 301L, 302L, 303L, 304L, 305L, 306L, 307L, 308L, 309L, 310L,
311L, 312L, 313L, 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L,
322L, 323L, 324L, 325L, 326L, 327L, 328L, 329L, 330L, 331L, 332L,
333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L, 341L, 342L, 343L,
344L, 345L, 346L, 347L, 348L, 349L, 350L, 352L, 353L, 354L, 355L,
356L, 357L, 358L, 359L, 360L, 361L, 362L, 363L, 364L, 365L, 366L,
367L, 368L, 369L, 370L, 371L, 372L, 373L, 374L, 375L, 376L, 377L,
378L, 379L, 380L, 382L, 383L, 384L, 385L, 386L, 387L, 389L, 390L,
391L, 392L, 393L, 394L, 395L, 396L, 397L, 398L, 399L, 400L, 401L,
402L, 403L, 404L, 405L, 406L, 407L, 408L, 409L, 410L, 411L, 412L,
413L, 414L, 415L, 416L, 418L, 419L, 420L, 422L, 423L, 424L, 425L,
427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L, 435L, 436L, 437L,
438L, 439L, 440L, 442L, 443L, 444L, 445L, 446L, 447L, 448L, 449L,
450L, 451L, 452L, 453L, 454L, 455L, 456L, 458L, 459L, 460L, 462L,
463L, 464L, 465L, 466L, 467L, 468L, 469L, 470L, 472L, 473L, 474L,
475L, 476L, 477L, 479L, 480L, 481L, 482L, 483L, 484L, 485L, 486L,
487L, 489L, 490L, 491L, 492L, 493L, 494L, 495L, 496L, 497L, 498L,
499L, 501L, 502L, 503L, 504L, 505L, 506L, 507L, 508L, 509L, 510L,
511L, 512L, 513L, 514L, 515L, 516L, 517L, 518L, 519L, 520L, 521L,
522L, 523L, 524L, 525L, 526L, 527L, 528L, 529L, 530L, 531L, 532L,
533L, 534L, 535L, 536L, 537L, 538L, 539L, 540L, 541L, 542L, 543L,
544L, 545L, 546L, 547L, 548L, 549L, 550L, 551L, 552L, 553L, 554L,
555L, 556L, 557L, 558L, 559L, 560L, 561L, 562L, 563L, 564L, 565L,
566L, 567L, 568L, 569L, 570L, 571L, 572L, 573L, 574L, 575L, 576L,
578L, 579L, 580L, 581L, 582L, 583L, 584L, 585L, 586L, 587L, 588L,
589L, 590L, 591L, 592L, 593L, 594L, 595L, 596L, 597L, 598L, 599L,
600L, 601L, 602L, 603L, 604L, 605L, 606L, 607L, 608L, 609L, 610L,
611L, 612L, 613L, 614L, 615L, 616L, 617L, 618L, 619L, 620L, 621L,
622L, 623L, 624L, 625L, 626L, 627L, 628L, 629L, 630L, 631L, 632L,
633L, 634L, 635L, 636L, 637L, 638L, 639L, 640L, 641L, 642L, 643L,
644L, 645L, 646L, 647L, 648L, 649L, 650L, 651L, 652L, 653L, 654L,
655L, 656L, 657L, 658L, 659L, 660L, 661L, 662L, 663L, 664L, 665L,
666L, 667L, 668L, 669L, 670L, 671L, 672L, 673L, 674L, 675L, 676L,
677L, 678L, 679L, 680L, 681L, 682L, 683L, 684L, 685L, 686L, 687L,
688L, 690L, 691L, 692L, 693L, 694L, 695L, 696L, 697L, 698L, 699L,
700L, 701L, 702L, 703L, 704L, 705L, 706L, 707L, 708L, 709L, 710L,
711L, 712L, 713L, 714L, 715L, 716L, 717L, 718L, 719L, 720L, 721L,
722L, 723L, 724L, 725L, 726L, 727L, 728L, 729L, 730L, 731L, 732L,
733L, 734L, 735L, 736L, 737L, 738L, 739L, 740L, 741L, 742L, 743L,
744L, 745L, 746L, 747L, 748L, 749L, 750L, 751L, 752L, 753L, 754L,
755L, 756L, 757L, 758L, 760L, 761L, 762L, 763L, 764L, 765L, 766L,
767L, 768L, 777L, 778L, 779L, 780L, 781L, 782L, 783L, 784L, 785L,
786L, 787L, 788L, 789L, 790L, 791L, 792L, 793L, 794L, 795L, 796L,
797L, 798L, 799L, 800L, 801L, 802L, 803L, 804L, 805L, 806L, 807L,
808L, 809L, 810L, 811L, 812L, 813L, 814L, 815L, 816L, 817L, 818L,
819L, 820L, 821L, 822L, 823L, 824L, 825L, 826L, 827L, 828L, 829L,
830L, 831L, 832L, 833L, 834L, 835L, 836L, 837L, 838L, 839L, 840L,
841L, 842L, 847L, 848L, 849L, 850L, 851L, 852L, 853L, 854L, 855L,
856L, 857L, 858L, 859L, 860L, 861L, 862L, 863L, 864L, 865L, 866L,
867L, 868L, 869L, 870L, 871L, 872L, 873L, 874L, 875L, 876L, 877L,
878L, 879L, 880L, 882L, 883L, 884L, 885L, 886L, 887L, 888L, 889L,
890L, 891L, 892L, 893L, 894L, 896L, 897L, 898L, 899L, 900L, 902L,
903L, 904L, 905L, 906L, 907L, 908L, 909L, 910L, 911L, 912L, 913L,
914L, 915L, 916L, 917L, 918L, 919L, 920L, 921L, 922L, 923L, 924L,
925L, 926L, 927L, 928L, 929L, 930L, 931L, 932L, 933L, 934L, 935L,
936L, 937L, 938L, 939L, 940L, 941L, 942L, 943L, 944L, 945L, 946L,
947L, 948L, 949L, 950L, 951L, 952L, 953L, 954L, 955L, 956L, 957L,
958L, 959L, 960L, 961L, 962L, 963L, 964L, 965L, 966L, 967L, 968L,
969L, 970L, 971L, 972L, 973L, 974L, 975L, 976L, 977L, 978L, 979L,
980L, 981L, 982L, 983L, 984L, 985L, 986L, 987L, 988L, 989L, 990L,
991L, 992L, 993L, 994L, 995L, 996L, 997L, 998L, 999L, 1000L,
1001L, 1002L, 1003L, 1004L, 1005L, 1006L, 1007L, 1008L, 1009L,
1010L, 1011L, 1012L, 1013L, 1014L, 1015L, 1016L, 1017L, 1018L,
1019L, 1024L, 1025L, 1026L, 1027L, 1028L, 1029L, 1030L, 1031L,
1032L, 1033L, 1034L, 1035L, 1036L, 1037L, 1038L, 1039L, 1040L,
1041L, 1042L, 1043L, 1044L, 1045L, 1046L, 1047L, 1048L, 1049L,
1050L, 1051L, 1052L, 1053L, 1054L, 1055L, 1056L, 1057L, 1058L,
1059L, 1060L, 1061L, 1062L, 1063L, 1064L, 1065L, 1066L, 1067L,
1069L, 1070L, 1071L, 1073L, 1074L, 1075L, 1076L, 1077L, 1078L,
1080L, 1081L, 1082L), class = "data.frame")


From bbolker at gmail.com  Fri Jul 15 18:07:23 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 15 Jul 2016 16:07:23 +0000 (UTC)
Subject: [R-sig-ME] K-fold cross validation of GLMMs
References: <CAPvMryNAP=pp6K4tjqD-qw=F-qxRdi0gqod2uaP4EWASMzWJGw@mail.gmail.com>
Message-ID: <loom.20160715T164234-254@post.gmane.org>

Teresa Oliveira <mteresaoliveira92 at ...> writes:

> 
> Dear list members,
> 
> I would like to know if you have knowledge about any R-package that allows
> to perform k-fold cross validation of a GLMM (developed with
> "lme4::glmer()")?
> 
> If there is none, which other kind of cross validation do you think is
> appropriate, and which packages are available?
> Or which other way to validate GLMMs, rather than cross validation, do you
> propose?
> 
> Thank you very much in advance for your help!
> 
> Best regards,
> Teresa

  I don't know of a package offhand.  (I haven't tried, but I
*strongly* recommend the 'sos' package; the findFn() command does
a full-text search of packages on CRAN ...)

  This is going to be a little bit tricky because you really ought
to cross-validate at the level of the grouping factor, not at the
level of the individual observation (this is assuming you have
only a single grouping factor, or at worst nested grouping factors).
Given a specified loss/objective function, it shouldn't be too hard
to put together a loop that would do this; it might even be possible
to use the modular structure of merMod objects to avoid redoing some
of the expensive computations each time round.
  Perhaps someone has done some of this and could share code ... ?


From shebrahimi_3622 at yahoo.com  Sat Jul 16 05:50:25 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Sat, 16 Jul 2016 03:50:25 +0000 (UTC)
Subject: [R-sig-ME] cross validation for discrete time survival analysis
In-Reply-To: <18389920.95090.1468638905767.JavaMail.yahoo@mail.yahoo.com>
References: <2082726117.1626150.1468323505133.JavaMail.yahoo.ref@mail.yahoo.com>
	<2082726117.1626150.1468323505133.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTTT=JEiJsZCAwKUC-tgQm8x=uQ37fp_Aojf49nGOO9qJg@mail.gmail.com>
	<398951196.1820955.1468332795112.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTRNUjJ6YjXHExhSow-3edciyoK+=R=NhZg77ET8ssL6LQ@mail.gmail.com>
	<888544502.3206200.1468512834710.JavaMail.yahoo@mail.yahoo.com>
	<475069987.3339139.1468523368368.JavaMail.yahoo@mail.yahoo.com>
	<590508458.3680687.1468550627850.JavaMail.yahoo@mail.yahoo.com>
	<1041593015.3668892.1468551465655.JavaMail.yahoo@mail.yahoo.com>
	<404681957.3563921.1468552844309.JavaMail.yahoo@mail.yahoo.com>
	<1072898021.3609015.1468559774467.JavaMail.yahoo@mail.yahoo.com>
	<1295208167.3620691.1468560399025.JavaMail.yahoo@mail.yahoo.com>
	<1742164238.3652376.1468577707758.JavaMail.yahoo@mail.yahoo.com>
	<1664168494.3988717.1468600842928.JavaMail.yahoo@mail.yahoo.com>
	<18389920.95090.1468638905767.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1469054561.84641.1468641025575.JavaMail.yahoo@mail.yahoo.com>

Dear Mr./Ms.

Greetings
I would be very grateful if you could let me know how to do cross validation when estimating a discrete time survival analysis in R.
library(readxl)require(lme4)
setwd("D:/Nasdaq")df=read_excel("Book1.xlsx",sheet = 1)model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial)p <- as.numeric(predict(model, type="response")>0.5)acc=mean(p==df$EVENT)

Thanks in advance.Best regards,   

   

   
	[[alternative HTML version deleted]]


From manica.mattia at gmail.com  Sat Jul 16 12:29:54 2016
From: manica.mattia at gmail.com (Mattia Manica)
Date: Sat, 16 Jul 2016 12:29:54 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 115, Issue 19
In-Reply-To: <mailman.1.1468663201.26617.r-sig-mixed-models@r-project.org>
References: <mailman.1.1468663201.26617.r-sig-mixed-models@r-project.org>
Message-ID: <CAJHvU7Rq5pTOW=XChGoAOx_J3BYVgkYjO7ed_M6u0nA9_XEtgw@mail.gmail.com>

Dear Teresa,

I hope this paper would be helpful Wenger et al 2012 "Assessing
transferability of ecological models: an underappreciated aspect of
statistical validation"
http://depts.washington.edu/oldenlab/wordpress/wp-content/uploads/2013/03/MethodsEE_2012.pdf

Regards

On Sat, Jul 16, 2016 at 12:00 PM, <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: K-fold cross validation of GLMMs (Ben Bolker)
>    2. cross validation for discrete time survival analysis
>       (shahla ebrahimi)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 15 Jul 2016 16:07:23 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] K-fold cross validation of GLMMs
> Message-ID: <loom.20160715T164234-254 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> Teresa Oliveira <mteresaoliveira92 at ...> writes:
>
> >
> > Dear list members,
> >
> > I would like to know if you have knowledge about any R-package that
> allows
> > to perform k-fold cross validation of a GLMM (developed with
> > "lme4::glmer()")?
> >
> > If there is none, which other kind of cross validation do you think is
> > appropriate, and which packages are available?
> > Or which other way to validate GLMMs, rather than cross validation, do
> you
> > propose?
> >
> > Thank you very much in advance for your help!
> >
> > Best regards,
> > Teresa
>
>   I don't know of a package offhand.  (I haven't tried, but I
> *strongly* recommend the 'sos' package; the findFn() command does
> a full-text search of packages on CRAN ...)
>
>   This is going to be a little bit tricky because you really ought
> to cross-validate at the level of the grouping factor, not at the
> level of the individual observation (this is assuming you have
> only a single grouping factor, or at worst nested grouping factors).
> Given a specified loss/objective function, it shouldn't be too hard
> to put together a loop that would do this; it might even be possible
> to use the modular structure of merMod objects to avoid redoing some
> of the expensive computations each time round.
>   Perhaps someone has done some of this and could share code ... ?
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 16 Jul 2016 03:50:25 +0000 (UTC)
> From: shahla ebrahimi <shebrahimi_3622 at yahoo.com>
> To: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] cross validation for discrete time survival
>         analysis
> Message-ID:
>         <1469054561.84641.1468641025575.JavaMail.yahoo at mail.yahoo.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear Mr./Ms.
>
> Greetings
> I would be very grateful if you could let me know how to do cross
> validation when estimating a discrete time survival analysis in R.
> library(readxl)require(lme4)
> setwd("D:/Nasdaq")df=read_excel("Book1.xlsx",sheet = 1)model <-
> glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial)p
> <- as.numeric(predict(model, type="response")>0.5)acc=mean(p==df$EVENT)
>
> Thanks in advance.Best regards,
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 115, Issue 19
> ***************************************************
>

	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Mon Jul 18 11:46:50 2016
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Mon, 18 Jul 2016 11:46:50 +0200
Subject: [R-sig-ME] LaplacesDemon back on CRAN
Message-ID: <nmi8i9$eu9$1@ger.gmane.org>

Dear all,

It may be of interest to some on this list that after 3 years 
LaplacesDemon is back on CRAN: 
https://cran.r-project.org/package=LaplacesDemon

LaplacesDemon provides a complete environment for Bayesian inference 
using a variety of different samplers.

Unfortunately, the original authors and maintainers Byron Hall and 
Martina Hall of Statisticat have ceased the development so the version 
on CRAN is basically identical to the last version published on GitHub 
in 2015.

I have moved the package to a new GitHub repository and only serve as 
maintainer to ensure it stays on CRAN. Given this I welcome all 
contributions, especially example models of any type. To contribute 
visit: https://github.com/LaplacesDemonR/LaplacesDemon

Cheers,
Henrik


From jannik at vindelov.dk  Mon Jul 18 19:08:08 2016
From: jannik at vindelov.dk (=?utf-8?Q?Jannik_Vindel=C3=B8v?=)
Date: Mon, 18 Jul 2016 19:08:08 +0200
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
	correlated responses
Message-ID: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>

Dear List,

I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.

Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.  

I would like to answer questions such as:
1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same) 
3) Are the responses correlated and by how much?

I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).

To make my request more specific, I add a synthetic data set that can be used for the analysis:

# Packages
library(dplyr)

# Design
df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))

# Responses
set.seed(1905) # start from the same place everytime
df_sim <- df_sim %>%
  mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
                rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
         pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
                rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
         Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
         Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
         Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
         Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
         NFS = 100 - Moi - Fat # all must sum to 100%
  )

My first attempt has been the following:

MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
                 family = rep("gaussian", 4),
                 rcov = ~us(System:trait):units,
                 data = df_sim,
                 nitt = 10000,
                 thin = 10,
                 burnin = 3000,
                 verbose = FALSE)

But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual. 
Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?

Any help would be appreciated.

Thanks

Jannik

From j.hadfield at ed.ac.uk  Tue Jul 19 07:21:01 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 19 Jul 2016 06:21:01 +0100
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
 correlated responses
In-Reply-To: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
References: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
Message-ID: <462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>

Dear Jannik,

For the compositional variables it makes sense to drop one dimension, it 
doesn't matter which. For example if you drop NFS you can derive its 
variance, and covariance with the remaining two as:

VAR(NFS) = VAR(1-Moi-Fat) = VAR(Moi)+VAR(Fat)+2COV(Moi, Fat)

COV(Moi, NFS) = COV(Moi, 1-Moi-Fat) = -[VAR(Moi)+COV(Moi, Fat)]

COV(Fat, NFS) = COV(Fat, 1-Moi-Fat) = -[VAR(Fat)+COV(Moi, Fat)]

If you want separate residual covariance matrices for each system then use:

rcov=~us(at.level(System, "Bulk"):trait):units+us(at.level(System, "DVS"):trait):units

you will also want a System*trait term in the fixed effects to allow the mean responses to differ across the systems.

As I understand your design, no culture is found in both systems and so the correlation between a culture's performance in the two cultures is not estimable. The formula

random=~us(at.level(System, "Bulk"):trait):culture+us(at.level(System, "DVS"):trait):culture

lets the between culture covariances matrices differ between the systems.

random=~us(trait):culture

forces the between culture covariances matrices to be the same in the two systems. *If* cultures appeared in both systems this formula also assumes that the performance of a culture in the two systems is expected to be the same.

HOWEVER, with only 5 cultures per system, I would say you don't have enough information to allow system specific covariance matrices. With 10 cultures in total, even estimating a single between culture covariance matrices is pushing it I think.

Cheers,

Jarrod
  

On 18/07/2016 18:08, Jannik Vindel?v wrote:
> Dear List,
>
> I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.
>
> Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.
>
> I would like to answer questions such as:
> 1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
> 2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same)
> 3) Are the responses correlated and by how much?
>
> I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).
>
> To make my request more specific, I add a synthetic data set that can be used for the analysis:
>
> # Packages
> library(dplyr)
>
> # Design
> df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
> df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))
>
> # Responses
> set.seed(1905) # start from the same place everytime
> df_sim <- df_sim %>%
>    mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
>                  rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
>           pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
>                  rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
>           Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
>           Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
>           Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
>           Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
>           NFS = 100 - Moi - Fat # all must sum to 100%
>    )
>
> My first attempt has been the following:
>
> MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
>                   family = rep("gaussian", 4),
>                   rcov = ~us(System:trait):units,
>                   data = df_sim,
>                   nitt = 10000,
>                   thin = 10,
>                   burnin = 3000,
>                   verbose = FALSE)
>
> But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual.
> Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?
>
> Any help would be appreciated.
>
> Thanks
>
> Jannik
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From shebrahimi_3622 at yahoo.com  Tue Jul 19 08:07:24 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Tue, 19 Jul 2016 06:07:24 +0000 (UTC)
Subject: [R-sig-ME] cross validation on discrete time survival analysis
In-Reply-To: <1469054561.84641.1468641025575.JavaMail.yahoo@mail.yahoo.com>
References: <2082726117.1626150.1468323505133.JavaMail.yahoo.ref@mail.yahoo.com>
	<2082726117.1626150.1468323505133.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTTT=JEiJsZCAwKUC-tgQm8x=uQ37fp_Aojf49nGOO9qJg@mail.gmail.com>
	<398951196.1820955.1468332795112.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTRNUjJ6YjXHExhSow-3edciyoK+=R=NhZg77ET8ssL6LQ@mail.gmail.com>
	<888544502.3206200.1468512834710.JavaMail.yahoo@mail.yahoo.com>
	<475069987.3339139.1468523368368.JavaMail.yahoo@mail.yahoo.com>
	<590508458.3680687.1468550627850.JavaMail.yahoo@mail.yahoo.com>
	<1041593015.3668892.1468551465655.JavaMail.yahoo@mail.yahoo.com>
	<404681957.3563921.1468552844309.JavaMail.yahoo@mail.yahoo.com>
	<1072898021.3609015.1468559774467.JavaMail.yahoo@mail.yahoo.com>
	<1295208167.3620691.1468560399025.JavaMail.yahoo@mail.yahoo.com>
	<1742164238.3652376.1468577707758.JavaMail.yahoo@mail.yahoo.com>
	<1664168494.3988717.1468600842928.JavaMail.yahoo@mail.yahoo.com>
	<18389920.95090.1468638905767.JavaMail.yahoo@mail.yahoo.com>
	<1469054561.84641.1468641025575.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1856196443.1538289.1468908444286.JavaMail.yahoo@mail.yahoo.com>



   Dear Mr./Ms.Greetings
I would be very grateful if you could let me know how to do cross validation when estimating a discrete time survival analysis in R.
ID TIME EVENT  x1       x2    x3      x4       x5
1   1   0   1.281   0.023   0.875   1.216   0.061
1   2   0   1.270   0.006   0.821   1.005   -0.014
1   3   0   1.053   -0.059  0.922   0.729   0.020
1   4   0   1.113   -0.015  0.859   0.810   0.076
1   5   1   1.220   -0.059  0.887   0.484   0.010
2   1   0   1.062   0.107   0.815   0.836   0.200
2   2   0   1.056   0.082   0.879   0.687   0.143
2   3   0   0.971   0.076   0.907   0.810   0.166
2   4   0   1.059   0.130   0.818   0.876   0.234
2   5   0   1.125   0.148   0.759   1.080   0.276
2   6   0   1.600   0.262   0.546   1.313   0.369
2   7   0   1.576   0.262   0.564   1.156   0.349
2   8   0   1.544   0.241   0.591   1.077   0.326
2   9   0   1.722   0.215   0.552   0.841   0.293
2   10  0   1.723   0.209   0.534   0.787   0.293
2   11  0   1.631   0.186   0.548   0.728   0.274
2   12  0   2.172   0.319   0.441   0.947   0.427
3   1   0   0.874   -0.035  0.794   0.610   -0.003
3   2   1   0.825   -0.142  0.952   0.573   -0.019 require(lme4) model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial) p <- as.numeric(predict(model, type="response")>0.5) acc=mean(p==df$EVENT)
Thanks in advance.Best regards,   

   

   

   
	[[alternative HTML version deleted]]


From jannik at vindelov.dk  Tue Jul 19 23:48:29 2016
From: jannik at vindelov.dk (=?utf-8?Q?Jannik_Vindel=C3=B8v?=)
Date: Tue, 19 Jul 2016 23:48:29 +0200
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
	correlated responses
In-Reply-To: <462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
References: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
	<462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
Message-ID: <6B66F7E7-76D2-450C-955C-C0B15D93DB2D@vindelov.dk>

Thank you so much Jarrod.

I was not aware of the at.level() trick :-)

Adding the trait*System to the fixed effects as suggested:

fixed = trait*Culture + trait*System

Makes some "fixed effect not estimable and have been removed ?. I assume because of the Strong Correlation between System and Culture? But I think it does not matter, as I can estimate the system performance as the contrast between "Bulk Cultures" and "DVS Cultures ??

On a different note, I would like to use the posteriors as priors for the next data set, do you have any advice on how to proceed? I was thinking of using a distribution fitting routine such as fitdistr() in the MASS package to fit an inverse gamma to the rcov chains and translate the parameters into the inverse wishart?

Thank you for your help...

Jannik

Den 19. jul. 2016 kl. 07.21 skrev Jarrod Hadfield <j.hadfield at ed.ac.uk>:

Dear Jannik,

For the compositional variables it makes sense to drop one dimension, it doesn't matter which. For example if you drop NFS you can derive its variance, and covariance with the remaining two as:

VAR(NFS) = VAR(1-Moi-Fat) = VAR(Moi)+VAR(Fat)+2COV(Moi, Fat)

COV(Moi, NFS) = COV(Moi, 1-Moi-Fat) = -[VAR(Moi)+COV(Moi, Fat)]

COV(Fat, NFS) = COV(Fat, 1-Moi-Fat) = -[VAR(Fat)+COV(Moi, Fat)]

If you want separate residual covariance matrices for each system then use:

rcov=~us(at.level(System, "Bulk"):trait):units+us(at.level(System, "DVS"):trait):units

you will also want a System*trait term in the fixed effects to allow the mean responses to differ across the systems.

As I understand your design, no culture is found in both systems and so the correlation between a culture's performance in the two cultures is not estimable. The formula

random=~us(at.level(System, "Bulk"):trait):culture+us(at.level(System, "DVS"):trait):culture

lets the between culture covariances matrices differ between the systems.

random=~us(trait):culture

forces the between culture covariances matrices to be the same in the two systems. *If* cultures appeared in both systems this formula also assumes that the performance of a culture in the two systems is expected to be the same.

HOWEVER, with only 5 cultures per system, I would say you don't have enough information to allow system specific covariance matrices. With 10 cultures in total, even estimating a single between culture covariance matrices is pushing it I think.

Cheers,

Jarrod

On 18/07/2016 18:08, Jannik Vindel?v wrote:
> Dear List,
> 
> I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.
> 
> Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.
> 
> I would like to answer questions such as:
> 1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
> 2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same)
> 3) Are the responses correlated and by how much?
> 
> I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).
> 
> To make my request more specific, I add a synthetic data set that can be used for the analysis:
> 
> # Packages
> library(dplyr)
> 
> # Design
> df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
> df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))
> 
> # Responses
> set.seed(1905) # start from the same place everytime
> df_sim <- df_sim %>%
>   mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
>                 rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
>          pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
>                 rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
>          Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
>          Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
>          Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
>          Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
>          NFS = 100 - Moi - Fat # all must sum to 100%
>   )
> 
> My first attempt has been the following:
> 
> MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
>                  family = rep("gaussian", 4),
>                  rcov = ~us(System:trait):units,
>                  data = df_sim,
>                  nitt = 10000,
>                  thin = 10,
>                  burnin = 3000,
>                  verbose = FALSE)
> 
> But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual.
> Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?
> 
> Any help would be appreciated.
> 
> Thanks
> 
> Jannik
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jannik at vindelov.dk  Wed Jul 20 07:57:29 2016
From: jannik at vindelov.dk (=?utf-8?Q?Jannik_Vindel=C3=B8v?=)
Date: Wed, 20 Jul 2016 07:57:29 +0200
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
	correlated responses
In-Reply-To: <462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
References: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
	<462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
Message-ID: <D84C1203-BA55-4846-B181-A0781884D265@vindelov.dk>

Dear Jarrod,

You have shown me how to estimate the variance and covariance of NFS to the other responses.
I would also like to do a posterior predictive check of this NFS, i.e. calculate the 95% confidence and prediction credible intervals for NFS and compare this to the actual measurements (per culture).

Is it possible to calculate posterior credible intervals if NFS is not included in the model e.g. from the MCMC chains? (MCMCglmm throws an error if NFS is included in th MCMCglmm call: "ill-conditioned G/R structure ?)

I was thinking, if for each culture, I could calculate NFS = 100 - Moi - Fat at each step in the posterior prediction chains, I would arrive at the posterior predictive chain for NFS... 

Is it possible for the predict method, as it is, to return the posterior prediction chains instead of the summaries (e.g. mean, lwr, upr) for a given culture? Or is it easy to do this by ? hand"?

Thank you for your support and thank you for making and maintaining such a great package?

/Jannik  

Den 19. jul. 2016 kl. 07.21 skrev Jarrod Hadfield <j.hadfield at ed.ac.uk>:

Dear Jannik,

For the compositional variables it makes sense to drop one dimension, it doesn't matter which. For example if you drop NFS you can derive its variance, and covariance with the remaining two as:

VAR(NFS) = VAR(1-Moi-Fat) = VAR(Moi)+VAR(Fat)+2COV(Moi, Fat)

COV(Moi, NFS) = COV(Moi, 1-Moi-Fat) = -[VAR(Moi)+COV(Moi, Fat)]

COV(Fat, NFS) = COV(Fat, 1-Moi-Fat) = -[VAR(Fat)+COV(Moi, Fat)]

If you want separate residual covariance matrices for each system then use:

rcov=~us(at.level(System, "Bulk"):trait):units+us(at.level(System, "DVS"):trait):units

you will also want a System*trait term in the fixed effects to allow the mean responses to differ across the systems.

As I understand your design, no culture is found in both systems and so the correlation between a culture's performance in the two cultures is not estimable. The formula

random=~us(at.level(System, "Bulk"):trait):culture+us(at.level(System, "DVS"):trait):culture

lets the between culture covariances matrices differ between the systems.

random=~us(trait):culture

forces the between culture covariances matrices to be the same in the two systems. *If* cultures appeared in both systems this formula also assumes that the performance of a culture in the two systems is expected to be the same.

HOWEVER, with only 5 cultures per system, I would say you don't have enough information to allow system specific covariance matrices. With 10 cultures in total, even estimating a single between culture covariance matrices is pushing it I think.

Cheers,

Jarrod

On 18/07/2016 18:08, Jannik Vindel?v wrote:
> Dear List,
> 
> I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.
> 
> Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.
> 
> I would like to answer questions such as:
> 1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
> 2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same)
> 3) Are the responses correlated and by how much?
> 
> I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).
> 
> To make my request more specific, I add a synthetic data set that can be used for the analysis:
> 
> # Packages
> library(dplyr)
> 
> # Design
> df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
> df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))
> 
> # Responses
> set.seed(1905) # start from the same place everytime
> df_sim <- df_sim %>%
>   mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
>                 rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
>          pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
>                 rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
>          Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
>          Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
>          Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
>          Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
>          NFS = 100 - Moi - Fat # all must sum to 100%
>   )
> 
> My first attempt has been the following:
> 
> MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
>                  family = rep("gaussian", 4),
>                  rcov = ~us(System:trait):units,
>                  data = df_sim,
>                  nitt = 10000,
>                  thin = 10,
>                  burnin = 3000,
>                  verbose = FALSE)
> 
> But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual.
> Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?
> 
> Any help would be appreciated.
> 
> Thanks
> 
> Jannik
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Jul 20 08:02:50 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 20 Jul 2016 07:02:50 +0100
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
 correlated responses
In-Reply-To: <6B66F7E7-76D2-450C-955C-C0B15D93DB2D@vindelov.dk>
References: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
	<462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
	<6B66F7E7-76D2-450C-955C-C0B15D93DB2D@vindelov.dk>
Message-ID: <4f721483-8c37-bca1-4089-acd22284d01c@ed.ac.uk>

Hi,

The "fixed effect not estimable and have been removed" warning can be 
ignored. It willonly issue this when effects are confounded, not just 
strongly correlated. It is because you have fitted the trait intercepts 
twice. trait+trait:Culture + trait:System will probably get rid of the 
warning, but the model will be the same as before.

You could do as you say regrding the priors. You could also analyse both 
data-sets together if the model is not too complicated.

Cheers,

Jarrod




On 19/07/2016 22:48, Jannik Vindel?v wrote:
> Thank you so much Jarrod.
>
> I was not aware of the at.level() trick :-)
>
> Adding the trait*System to the fixed effects as suggested:
>
> fixed = trait*Culture + trait*System
>
> Makes some "fixed effect not estimable and have been removed ?. I assume because of the Strong Correlation between System and Culture? But I think it does not matter, as I can estimate the system performance as the contrast between "Bulk Cultures" and "DVS Cultures ??
>
> On a different note, I would like to use the posteriors as priors for the next data set, do you have any advice on how to proceed? I was thinking of using a distribution fitting routine such as fitdistr() in the MASS package to fit an inverse gamma to the rcov chains and translate the parameters into the inverse wishart?
>
> Thank you for your help...
>
> Jannik
>
> Den 19. jul. 2016 kl. 07.21 skrev Jarrod Hadfield <j.hadfield at ed.ac.uk>:
>
> Dear Jannik,
>
> For the compositional variables it makes sense to drop one dimension, it doesn't matter which. For example if you drop NFS you can derive its variance, and covariance with the remaining two as:
>
> VAR(NFS) = VAR(1-Moi-Fat) = VAR(Moi)+VAR(Fat)+2COV(Moi, Fat)
>
> COV(Moi, NFS) = COV(Moi, 1-Moi-Fat) = -[VAR(Moi)+COV(Moi, Fat)]
>
> COV(Fat, NFS) = COV(Fat, 1-Moi-Fat) = -[VAR(Fat)+COV(Moi, Fat)]
>
> If you want separate residual covariance matrices for each system then use:
>
> rcov=~us(at.level(System, "Bulk"):trait):units+us(at.level(System, "DVS"):trait):units
>
> you will also want a System*trait term in the fixed effects to allow the mean responses to differ across the systems.
>
> As I understand your design, no culture is found in both systems and so the correlation between a culture's performance in the two cultures is not estimable. The formula
>
> random=~us(at.level(System, "Bulk"):trait):culture+us(at.level(System, "DVS"):trait):culture
>
> lets the between culture covariances matrices differ between the systems.
>
> random=~us(trait):culture
>
> forces the between culture covariances matrices to be the same in the two systems. *If* cultures appeared in both systems this formula also assumes that the performance of a culture in the two systems is expected to be the same.
>
> HOWEVER, with only 5 cultures per system, I would say you don't have enough information to allow system specific covariance matrices. With 10 cultures in total, even estimating a single between culture covariance matrices is pushing it I think.
>
> Cheers,
>
> Jarrod
>
> On 18/07/2016 18:08, Jannik Vindel?v wrote:
>> Dear List,
>>
>> I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.
>>
>> Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.
>>
>> I would like to answer questions such as:
>> 1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
>> 2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same)
>> 3) Are the responses correlated and by how much?
>>
>> I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).
>>
>> To make my request more specific, I add a synthetic data set that can be used for the analysis:
>>
>> # Packages
>> library(dplyr)
>>
>> # Design
>> df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
>> df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))
>>
>> # Responses
>> set.seed(1905) # start from the same place everytime
>> df_sim <- df_sim %>%
>>    mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
>>                  rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
>>           pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
>>                  rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
>>           Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
>>           Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
>>           Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
>>           Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
>>           NFS = 100 - Moi - Fat # all must sum to 100%
>>    )
>>
>> My first attempt has been the following:
>>
>> MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
>>                   family = rep("gaussian", 4),
>>                   rcov = ~us(System:trait):units,
>>                   data = df_sim,
>>                   nitt = 10000,
>>                   thin = 10,
>>                   burnin = 3000,
>>                   verbose = FALSE)
>>
>> But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual.
>> Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?
>>
>> Any help would be appreciated.
>>
>> Thanks
>>
>> Jannik
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Jul 20 08:10:08 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 20 Jul 2016 07:10:08 +0100
Subject: [R-sig-ME] Question regarding MCMCglmm model structure for
 correlated responses
In-Reply-To: <D84C1203-BA55-4846-B181-A0781884D265@vindelov.dk>
References: <839FDE60-7361-452C-BC0C-0804ACA2ADC2@vindelov.dk>
	<462efbe3-3370-442c-5fc3-6bb880d0832b@ed.ac.uk>
	<D84C1203-BA55-4846-B181-A0781884D265@vindelov.dk>
Message-ID: <2f96216c-bad9-5273-0805-9fa53ccccc33@ed.ac.uk>

Hi,

You will have to do this by hand. If you want the posterior predictive 
distribution for the sample covariances (i.e. the covariances you 
oberserve in the data) then I would

1/ for MCMC iteration i generate the full 3x3 covariance matrix from the 
estimated 2x2 covariance matrix, using the rules that I showed you.

2/ draw n samples from this covariance matrix using mvrnorm where n is 
your sample size.

3/ calculate the covariance of the samples using cov and store

4/ go back to 1/ and repeat for i+1

You end up with a posterior predictive distribution for the sample 
covariance matrix (although technically you would have to multiply your 
empirical covariance matrix and the result of 3 by (n+1)/n to get the 
sample covariance matrix).

Cheers,

Jarrod



On 20/07/2016 06:57, Jannik Vindel?v wrote:
> Dear Jarrod,
>
> You have shown me how to estimate the variance and covariance of NFS to the other responses.
> I would also like to do a posterior predictive check of this NFS, i.e. calculate the 95% confidence and prediction credible intervals for NFS and compare this to the actual measurements (per culture).
>
> Is it possible to calculate posterior credible intervals if NFS is not included in the model e.g. from the MCMC chains? (MCMCglmm throws an error if NFS is included in th MCMCglmm call: "ill-conditioned G/R structure ?)
>
> I was thinking, if for each culture, I could calculate NFS = 100 - Moi - Fat at each step in the posterior prediction chains, I would arrive at the posterior predictive chain for NFS...
>
> Is it possible for the predict method, as it is, to return the posterior prediction chains instead of the summaries (e.g. mean, lwr, upr) for a given culture? Or is it easy to do this by ? hand"?
>
> Thank you for your support and thank you for making and maintaining such a great package?
>
> /Jannik
>
> Den 19. jul. 2016 kl. 07.21 skrev Jarrod Hadfield <j.hadfield at ed.ac.uk>:
>
> Dear Jannik,
>
> For the compositional variables it makes sense to drop one dimension, it doesn't matter which. For example if you drop NFS you can derive its variance, and covariance with the remaining two as:
>
> VAR(NFS) = VAR(1-Moi-Fat) = VAR(Moi)+VAR(Fat)+2COV(Moi, Fat)
>
> COV(Moi, NFS) = COV(Moi, 1-Moi-Fat) = -[VAR(Moi)+COV(Moi, Fat)]
>
> COV(Fat, NFS) = COV(Fat, 1-Moi-Fat) = -[VAR(Fat)+COV(Moi, Fat)]
>
> If you want separate residual covariance matrices for each system then use:
>
> rcov=~us(at.level(System, "Bulk"):trait):units+us(at.level(System, "DVS"):trait):units
>
> you will also want a System*trait term in the fixed effects to allow the mean responses to differ across the systems.
>
> As I understand your design, no culture is found in both systems and so the correlation between a culture's performance in the two cultures is not estimable. The formula
>
> random=~us(at.level(System, "Bulk"):trait):culture+us(at.level(System, "DVS"):trait):culture
>
> lets the between culture covariances matrices differ between the systems.
>
> random=~us(trait):culture
>
> forces the between culture covariances matrices to be the same in the two systems. *If* cultures appeared in both systems this formula also assumes that the performance of a culture in the two systems is expected to be the same.
>
> HOWEVER, with only 5 cultures per system, I would say you don't have enough information to allow system specific covariance matrices. With 10 cultures in total, even estimating a single between culture covariance matrices is pushing it I think.
>
> Cheers,
>
> Jarrod
>
> On 18/07/2016 18:08, Jannik Vindel?v wrote:
>> Dear List,
>>
>> I need to compare two systems ("Bulk" and "DVS"), each consisting of a number of "Cultures" (e.g. Bulk: B1 - B5 and DVS: A - E). I have repeated measurements of each culture in each system (more from the Bulk system than the DVS system) with regards to pH and composition variables. The composition variables: Moi, Fat, NFS, are highly correlated because they need to add to 100%. pH may also be correlated to the composition variables.
>>
>> Furthermore, I assume that the residual variance of all composition variables can be estimated together within each system (sigma comp). And I assume, that the residual variance will be the same for each culture within a system, but not between systems.
>>
>> I would like to answer questions such as:
>> 1) Are the performance of the systems the same? (i.e. do Bulk and DVS systems have the same mean and culture variance within each response variable)?
>> 2) Are the performance of the cultures within each system the same? (i.e. do they have the same mean, assuming the variance to be the same)
>> 3) Are the responses correlated and by how much?
>>
>> I assume that I can use MCMCglmm to do the analysis, as it handles multiple responses and marginal contrasts (means and variance) are straight forward to calculate from the MCMC chains. But I?am unsure how to specify the fixed, random and residual covariance in the function interface (e.g. how do I tell the function to estimate the same variance for the composition variables?).
>>
>> To make my request more specific, I add a synthetic data set that can be used for the analysis:
>>
>> # Packages
>> library(dplyr)
>>
>> # Design
>> df_sim <- data.frame(System = c(rep("Bulk", 75), rep("DVS", 25)), Culture = c(rep(c("B1", "B2", "B3", "B4", "B5"), each = 15), rep(c("A", "B", "C", "D", "E"), each = 5)))
>> df_sim$Culture <- ordered(df_sim$Culture, levels = c("B1", "B2", "B3", "B4", "B5", "A", "B", "C", "D", "E"))
>>
>> # Responses
>> set.seed(1905) # start from the same place everytime
>> df_sim <- df_sim %>%
>>    mutate(pH = c(rep(rnorm(n = 5, mean = 5.3, sd = 0.1), each = 15), # Bulk 0.1 pHU higher than DVS on average
>>                  rep(rnorm(n = 5, mean = 5.2, sd = 0.05), each = 5)), # DVS between cultures more consistent
>>           pH = c(rnorm(n = 75, mean = pH, sd = 0.1), # Bulk have larger within culture variation
>>                  rnorm(n = 25, mean = pH, sd = 0.05)), # DVS have smaller within culture variation
>>           Moi = rep(rnorm(n = 5, mean = 40, sd = 0.1), each = 20), # all cultures, regardless of system, are on average identical
>>           Moi = rnorm(n = 100, mean = Moi, sd = 0.05), # and with same noise
>>           Fat = rep(rnorm(n = 5, mean = 25, sd = 0.01), each = 20), # all cultures are on average identical
>>           Fat = rnorm(n = 100, mean = Fat, sd = 0.05), # and with same noise
>>           NFS = 100 - Moi - Fat # all must sum to 100%
>>    )
>>
>> My first attempt has been the following:
>>
>> MCMCglmm(fixed = cbind(pH, Moi, Fat, NFS) ~ trait*Culture - 1,
>>                   family = rep("gaussian", 4),
>>                   rcov = ~us(System:trait):units,
>>                   data = df_sim,
>>                   nitt = 10000,
>>                   thin = 10,
>>                   burnin = 3000,
>>                   verbose = FALSE)
>>
>> But this does not take into account the Moi, Fat, NFS used to estimate a common composition residual.
>> Is there a way to specify this in the rcov formula? Am I using the right family for the residuals, when i know the are correlated 100 = Moi + Fat + NFS? Is MCMCglmm the right tool or am I asking to much of the package?
>>
>> Any help would be appreciated.
>>
>> Thanks
>>
>> Jannik
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From sophia.kyriakou17 at gmail.com  Thu Jul 21 01:33:53 2016
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Thu, 21 Jul 2016 02:33:53 +0300
Subject: [R-sig-ME] PQL and crossed designs
Message-ID: <CAO4gA+oGZhW=4AyQoK64PoJL4Q2vdZmERcMEnmqdg1N2WrESBA@mail.gmail.com>

Dear List,

I need to fit a generalized linear model with crossed random effects using
penalized quasi-likelihood. I realize that this has troubled many people so
far, and I was wondering if anyone has figured out how to use MASS::glmmPQL
in order to fit a model e.g. on the salamander mating data.

Following
http://rstudio-pubs-static.s3.amazonaws.com/38992_0a51aebca767491690f2b97e05c5aa05.html

I tried

library(hglm)
data(salamander)

salamander$dummy <- factor(rep(1, nrow(salamander)))
salamanderG <- groupedData(Mate ~ 1 | dummy, salamander)
glmmPQL(Mate ~ 0 + TypeF:TypeM, data = salamanderG, family = binomial,
random = pdBlocked(list(pdIdent(~Male-1), pdIdent(~Female- 1))))

but as expected I get the error

Error in getGroups.data.frame(dataMix, groups) : invalid formula for groups

Any help is much appreciated.

Thanks,
Sophia

	[[alternative HTML version deleted]]


From daniel_rubi at ymail.com  Thu Jul 21 20:13:23 2016
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Thu, 21 Jul 2016 18:13:23 +0000 (UTC)
Subject: [R-sig-ME] Repeated measures with a non-linear time effect
References: <2076721448.3492264.1469124803329.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>

Hi,
I have repeated measures from two groups (treatment and control), three subjects in each, over three time points.

Here's the data in an R data.frame:df <- data.frame(subject=rep(c("T1","T2","T3","C1","C2","C3"),3), group=rep(c(rep("T",3),rep("C",3)),3), time=c(rep(1,6),rep(2,6),rep(3,6)), measure=c(0,253,155,16,232,251,1035,1014,760,98,239,87,371,60,47,0,260,190), col=rep(c(rep("red",3),rep("blue",3)),3), stringsAsFactors=F)


The plot shows the time x group interaction:

R code for producing the plot:
plot(df$time,df$measure,col=df$col,xlab="time",ylab="measure")
legend("topleft",legend=c("treatment","control"),col=c("red","blue"),pch=1)


My question is what model to use to capture the?time x group interaction.
I thought:library(lmerTest)fit <- lmer(measure~time+group+time*group+(time|subject),data=df)
might do it.
But the summary of this model doesn't really capture that:> summary(fit)Linear mixed model fit by REMLt-tests use Satterthwaite approximations to degrees of freedom ['lmerMod']Formula: measure ~ time + group + time * group + (time | subject)?Data: df
REML criterion at convergence: 210

Scaled residuals:?
? ?Min ? ? 1Q Median ? ? 3Q ? ?Max?
-1.228 -0.448 -0.163 ?0.275 ?1.923

Random effects:
?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
?subject ?(Intercept) 0.00e+00 0.00e+00 ? ??
? ? ? ? ? time ? ? ? ?3.06e-16 1.75e-08 ?NaN
?Residual ? ? ? ? ? ? 1.05e+05 3.25e+02 ? ??
Number of obs: 18, groups: ?subject, 6

Fixed effects:
? ? ? ? ? ? Estimate Std. Error ? ? df t value Pr(>|t|)
(Intercept) ? 168.89 ? ? 286.35 ?13.78 ? ?0.59 ? ? 0.56
time ? ? ? ? ? -8.17 ? ? 132.55 ?13.78 ? -0.06 ? ? 0.95
groupT ? ? ? ?218.33 ? ? 404.96 ?13.78 ? ?0.54 ? ? 0.60
time:groupT ? ?19.83 ? ? 187.46 ?13.78 ? ?0.11 ? ? 0.92

Correlation of Fixed Effects:
? ? ? ? ? ? (Intr) time ? groupT
time ? ? ? ?-0.926 ? ? ? ? ? ? ?
groupT ? ? ?-0.707 ?0.655 ? ? ??
time:groupT ?0.655 -0.707 -0.926


So my question is what model to use?

Thanks a lot,Dan

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 4502 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160721/d988a14b/attachment.png>

From albrechj at staff.uni-marburg.de  Thu Jul 21 21:27:25 2016
From: albrechj at staff.uni-marburg.de (=?utf-8?Q?J=C3=B6rg_Albrecht?=)
Date: Thu, 21 Jul 2016 21:27:25 +0200
Subject: [R-sig-ME] Repeated measures with a non-linear time effect
In-Reply-To: <2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>
References: <2076721448.3492264.1469124803329.JavaMail.yahoo.ref@mail.yahoo.com>
	<2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <AA673FFF-C1DE-4514-8FB0-E7590D29C33E@staff.uni-marburg.de>

Hi Dan,

most likely the model treats your time covariate as a continuous predictor. Try str(df), then time should appear as integer (int). If you specify time as a factor (with three levels: 1, 2, 3) the model will be able to estimate the time x treatment interaction separately for each time point. However, you still have to decide whether treating time as a factorial variable makes sense for your dataset.

Best,

J?rg


> Am 21.07.2016 um 20:13 schrieb Daniel Rubi via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
> 
> Hi,
> I have repeated measures from two groups (treatment and control), three subjects in each, over three time points.
> 
> Here's the data in an R data.frame:df <- data.frame(subject=rep(c("T1","T2","T3","C1","C2","C3"),3), group=rep(c(rep("T",3),rep("C",3)),3), time=c(rep(1,6),rep(2,6),rep(3,6)), measure=c(0,253,155,16,232,251,1035,1014,760,98,239,87,371,60,47,0,260,190), col=rep(c(rep("red",3),rep("blue",3)),3), stringsAsFactors=F)
> 
> 
> The plot shows the time x group interaction:
> 
> R code for producing the plot:
> plot(df$time,df$measure,col=df$col,xlab="time",ylab="measure")
> legend("topleft",legend=c("treatment","control"),col=c("red","blue"),pch=1)
> 
> 
> My question is what model to use to capture the time x group interaction.
> I thought:library(lmerTest)fit <- lmer(measure~time+group+time*group+(time|subject),data=df)
> might do it.
> But the summary of this model doesn't really capture that:> summary(fit)Linear mixed model fit by REMLt-tests use Satterthwaite approximations to degrees of freedom ['lmerMod']Formula: measure ~ time + group + time * group + (time | subject) Data: df
> REML criterion at convergence: 210
> 
> Scaled residuals: 
>    Min     1Q Median     3Q    Max 
> -1.228 -0.448 -0.163  0.275  1.923
> 
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  subject  (Intercept) 0.00e+00 0.00e+00     
>           time        3.06e-16 1.75e-08  NaN
>  Residual             1.05e+05 3.25e+02     
> Number of obs: 18, groups:  subject, 6
> 
> Fixed effects:
>             Estimate Std. Error     df t value Pr(>|t|)
> (Intercept)   168.89     286.35  13.78    0.59     0.56
> time           -8.17     132.55  13.78   -0.06     0.95
> groupT        218.33     404.96  13.78    0.54     0.60
> time:groupT    19.83     187.46  13.78    0.11     0.92
> 
> Correlation of Fixed Effects:
>             (Intr) time   groupT
> time        -0.926              
> groupT      -0.707  0.655       
> time:groupT  0.655 -0.707 -0.926
> 
> 
> So my question is what model to use?
> 
> Thanks a lot,Dan
> 
> <Rplot.png>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From daniel_rubi at ymail.com  Thu Jul 21 21:50:30 2016
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Thu, 21 Jul 2016 19:50:30 +0000 (UTC)
Subject: [R-sig-ME] Repeated measures with a non-linear time effect
In-Reply-To: <AA673FFF-C1DE-4514-8FB0-E7590D29C33E@staff.uni-marburg.de>
References: <2076721448.3492264.1469124803329.JavaMail.yahoo.ref@mail.yahoo.com>
	<2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>
	<AA673FFF-C1DE-4514-8FB0-E7590D29C33E@staff.uni-marburg.de>
Message-ID: <1959317684.3546915.1469130630673.JavaMail.yahoo@mail.yahoo.com>

Hi?J?rg,
Unfortunately setting time as integer doesn't change anything whereas setting it as a factor means that the number of random effects will be equal to the number of samples.
Perhaps this is an alternative:fit1 <- gls(measure~time*group,correlation=corSymm(form=~1|subject),weight=varIdent(form=~1|time),data=df)
as it does capture the group and interaction effects but I think I need to contrast it with a null model and I'm not sure what would that null model be.
Any idea?
 

    On Thursday, July 21, 2016 3:27 PM, J?rg Albrecht <albrechj at staff.uni-marburg.de> wrote:
 

 Hi Dan,

most likely the model treats your time covariate as a continuous predictor. Try str(df), then time should appear as integer (int). If you specify time as a factor (with three levels: 1, 2, 3) the model will be able to estimate the time x treatment interaction separately for each time point. However, you still have to decide whether treating time as a factorial variable makes sense for your dataset.

Best,

J?rg


> Am 21.07.2016 um 20:13 schrieb Daniel Rubi via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
> 
> Hi,
> I have repeated measures from two groups (treatment and control), three subjects in each, over three time points.
> 
> Here's the data in an R data.frame:df <- data.frame(subject=rep(c("T1","T2","T3","C1","C2","C3"),3), group=rep(c(rep("T",3),rep("C",3)),3), time=c(rep(1,6),rep(2,6),rep(3,6)), measure=c(0,253,155,16,232,251,1035,1014,760,98,239,87,371,60,47,0,260,190), col=rep(c(rep("red",3),rep("blue",3)),3), stringsAsFactors=F)
> 
> 
> The plot shows the time x group interaction:
> 
> R code for producing the plot:
> plot(df$time,df$measure,col=df$col,xlab="time",ylab="measure")
> legend("topleft",legend=c("treatment","control"),col=c("red","blue"),pch=1)
> 
> 
> My question is what model to use to capture the time x group interaction.
> I thought:library(lmerTest)fit <- lmer(measure~time+group+time*group+(time|subject),data=df)
> might do it.
> But the summary of this model doesn't really capture that:> summary(fit)Linear mixed model fit by REMLt-tests use Satterthwaite approximations to degrees of freedom ['lmerMod']Formula: measure ~ time + group + time * group + (time | subject) Data: df
> REML criterion at convergence: 210
> 
> Scaled residuals: 
>? ? Min? ? 1Q Median? ? 3Q? ? Max 
> -1.228 -0.448 -0.163? 0.275? 1.923
> 
> Random effects:
>? Groups? Name? ? ? ? Variance Std.Dev. Corr
>? subject? (Intercept) 0.00e+00 0.00e+00? ? 
>? ? ? ? ? time? ? ? ? 3.06e-16 1.75e-08? NaN
>? Residual? ? ? ? ? ? 1.05e+05 3.25e+02? ? 
> Number of obs: 18, groups:? subject, 6
> 
> Fixed effects:
>? ? ? ? ? ? Estimate Std. Error? ? df t value Pr(>|t|)
> (Intercept)? 168.89? ? 286.35? 13.78? ? 0.59? ? 0.56
> time? ? ? ? ? -8.17? ? 132.55? 13.78? -0.06? ? 0.95
> groupT? ? ? ? 218.33? ? 404.96? 13.78? ? 0.54? ? 0.60
> time:groupT? ? 19.83? ? 187.46? 13.78? ? 0.11? ? 0.92
> 
> Correlation of Fixed Effects:
>? ? ? ? ? ? (Intr) time? groupT
> time? ? ? ? -0.926? ? ? ? ? ? ? 
> groupT? ? ? -0.707? 0.655? ? ? 
> time:groupT? 0.655 -0.707 -0.926
> 
> 
> So my question is what model to use?
> 
> Thanks a lot,Dan
> 
> <Rplot.png>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


  
	[[alternative HTML version deleted]]


From albrechj at staff.uni-marburg.de  Thu Jul 21 22:47:22 2016
From: albrechj at staff.uni-marburg.de (=?utf-8?Q?J=C3=B6rg_Albrecht?=)
Date: Thu, 21 Jul 2016 22:47:22 +0200
Subject: [R-sig-ME] Repeated measures with a non-linear time effect
In-Reply-To: <1959317684.3546915.1469130630673.JavaMail.yahoo@mail.yahoo.com>
References: <2076721448.3492264.1469124803329.JavaMail.yahoo.ref@mail.yahoo.com>
	<2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>
	<AA673FFF-C1DE-4514-8FB0-E7590D29C33E@staff.uni-marburg.de>
	<1959317684.3546915.1469130630673.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A3129B40-BCF6-498B-A652-9499B0D517B7@staff.uni-marburg.de>

Hi Dan,

that was a misunderstanding. I meant you should code time as a factor and run a modified version of the model (see code below).

library(lme4)
library(lattice)
library(multcomp)

df <- data.frame(subject = rep(c("T1", "T2", "T3", "C1", "C2", "C3"), 3),
                 group = rep(c(rep("T", 3), rep("C", 3)), 3),
                 time = c(rep(1, 6), rep(2, 6), rep(3, 6)),
                 measure = c(0, 253, 155, 16, 232, 251, 1035, 1014, 760, 98, 239, 87, 371, 60, 47, 0, 260, 190),
                 col = rep(c(rep("red", 3), rep("blue", 3)), 3), stringsAsFactors = FALSE)
df$time <- as.factor(df$time)
xyplot(measure ~ time|subject, data = df)

# using the lme4 package
fit <- lmer(measure ~ time * group + (1|subject), data = df)
summary(fit)
cftest(fit)

# using anova
fit <- aov(measure ~ time * group + Error(subject), data = df)
summary(fit)

Both models are able to detect the interaction between treatment and time.

Hope this helps.

Best,

J?rg

?
J?rg Albrecht, PhD
Postdoctoral researcher
Institute of Nature Conservation
Polish Academy of Sciences
Mickiewicza 33
31-120 Krakow, Poland
www.carpathianbear.pl <http://www.carpathianbear.pl/>
www.globeproject.pl <http://www.globeproject.pl/>
www.iop.krakow.pl <http://www.iop.krakow.pl/>
> Am 21.07.2016 um 21:50 schrieb Daniel Rubi <daniel_rubi at ymail.com>:
> 
> Hi J?rg,
> 
> Unfortunately setting time as integer doesn't change anything whereas setting it as a factor means that the number of random effects will be equal to the number of samples.
> 
> Perhaps this is an alternative:
> fit1 <- gls(measure~time*group,correlation=corSymm(form=~1|subject),weight=varIdent(form=~1|time),data=df)
> 
> as it does capture the group and interaction effects but I think I need to contrast it with a null model and I'm not sure what would that null model be.
> 
> Any idea?
> 
> 
> 
> On Thursday, July 21, 2016 3:27 PM, J?rg Albrecht <albrechj at staff.uni-marburg.de> wrote:
> 
> 
> Hi Dan,
> 
> most likely the model treats your time covariate as a continuous predictor. Try str(df), then time should appear as integer (int). If you specify time as a factor (with three levels: 1, 2, 3) the model will be able to estimate the time x treatment interaction separately for each time point. However, you still have to decide whether treating time as a factorial variable makes sense for your dataset.
> 
> Best,
> 
> J?rg
> 
> 
> > Am 21.07.2016 um 20:13 schrieb Daniel Rubi via R-sig-mixed-models <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>:
> > 
> > Hi,
> > I have repeated measures from two groups (treatment and control), three subjects in each, over three time points.
> > 
> > Here's the data in an R data.frame:df <- data.frame(subject=rep(c("T1","T2","T3","C1","C2","C3"),3), group=rep(c(rep("T",3),rep("C",3)),3), time=c(rep(1,6),rep(2,6),rep(3,6)), measure=c(0,253,155,16,232,251,1035,1014,760,98,239,87,371,60,47,0,260,190), col=rep(c(rep("red",3),rep("blue",3)),3), stringsAsFactors=F)
> > 
> > 
> > The plot shows the time x group interaction:
> > 
> > R code for producing the plot:
> > plot(df$time,df$measure,col=df$col,xlab="time",ylab="measure")
> > legend("topleft",legend=c("treatment","control"),col=c("red","blue"),pch=1)
> > 
> > 
> > My question is what model to use to capture the time x group interaction.
> > I thought:library(lmerTest)fit <- lmer(measure~time+group+time*group+(time|subject),data=df)
> > might do it.
> > But the summary of this model doesn't really capture that:> summary(fit)Linear mixed model fit by REMLt-tests use Satterthwaite approximations to degrees of freedom ['lmerMod']Formula: measure ~ time + group + time * group + (time | subject) Data: df
> > REML criterion at convergence: 210
> > 
> > Scaled residuals: 
> >    Min    1Q Median    3Q    Max 
> > -1.228 -0.448 -0.163  0.275  1.923
> > 
> > Random effects:
> >  Groups  Name        Variance Std.Dev. Corr
> >  subject  (Intercept) 0.00e+00 0.00e+00    
> >          time        3.06e-16 1.75e-08  NaN
> >  Residual            1.05e+05 3.25e+02    
> > Number of obs: 18, groups:  subject, 6
> > 
> > Fixed effects:
> >            Estimate Std. Error    df t value Pr(>|t|)
> > (Intercept)  168.89    286.35  13.78    0.59    0.56
> > time          -8.17    132.55  13.78  -0.06    0.95
> > groupT        218.33    404.96  13.78    0.54    0.60
> > time:groupT    19.83    187.46  13.78    0.11    0.92
> > 
> > Correlation of Fixed Effects:
> >            (Intr) time  groupT
> > time        -0.926              
> > groupT      -0.707  0.655      
> > time:groupT  0.655 -0.707 -0.926
> > 
> > 
> > So my question is what model to use?
> > 
> > Thanks a lot,Dan
> > 
> > <Rplot.png>_______________________________________________
> 
> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 


	[[alternative HTML version deleted]]


From daniel_rubi at ymail.com  Thu Jul 21 23:28:50 2016
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Thu, 21 Jul 2016 21:28:50 +0000 (UTC)
Subject: [R-sig-ME] Repeated measures with a non-linear time effect
In-Reply-To: <A3129B40-BCF6-498B-A652-9499B0D517B7@staff.uni-marburg.de>
References: <2076721448.3492264.1469124803329.JavaMail.yahoo.ref@mail.yahoo.com>
	<2076721448.3492264.1469124803329.JavaMail.yahoo@mail.yahoo.com>
	<AA673FFF-C1DE-4514-8FB0-E7590D29C33E@staff.uni-marburg.de>
	<1959317684.3546915.1469130630673.JavaMail.yahoo@mail.yahoo.com>
	<A3129B40-BCF6-498B-A652-9499B0D517B7@staff.uni-marburg.de>
Message-ID: <1044568082.3505722.1469136530523.JavaMail.yahoo@mail.yahoo.com>

Thanks a lot 

    On Thursday, July 21, 2016 4:47 PM, J?rg Albrecht <albrechj at staff.uni-marburg.de> wrote:
 

 Hi Dan,
that was a misunderstanding. I meant you should code time as a factor and run a modified version of the model (see code below).
library(lme4)library(lattice)library(multcomp)
df <- data.frame(subject = rep(c("T1", "T2", "T3", "C1", "C2", "C3"), 3),? ? ? ? ? ? ? ? ?group = rep(c(rep("T", 3), rep("C", 3)), 3),? ? ? ? ? ? ? ? ?time = c(rep(1, 6), rep(2, 6), rep(3, 6)),? ? ? ? ? ? ? ? ?measure = c(0, 253, 155, 16, 232, 251, 1035, 1014, 760, 98, 239, 87, 371, 60, 47, 0, 260, 190),? ? ? ? ? ? ? ? ?col = rep(c(rep("red", 3), rep("blue", 3)), 3), stringsAsFactors = FALSE)df$time <- as.factor(df$time)xyplot(measure ~ time|subject, data = df)
# using the lme4 packagefit <- lmer(measure ~ time * group + (1|subject), data = df)summary(fit)cftest(fit)
# using anovafit <- aov(measure ~ time * group + Error(subject), data = df)summary(fit)
Both models are able to detect the interaction between treatment and time.
Hope this helps.
Best,
J?rg
?J?rg Albrecht, PhDPostdoctoral researcherInstitute of Nature Conservation
Polish Academy of Sciences
Mickiewicza 33
31-120 Krakow, Poland
www.carpathianbear.pl
www.globeproject.pl
www.iop.krakow.pl

Am 21.07.2016 um 21:50 schrieb Daniel Rubi <daniel_rubi at ymail.com>:
Hi?J?rg,
Unfortunately setting time as integer doesn't change anything whereas setting it as a factor means that the number of random effects will be equal to the number of samples.
Perhaps this is an alternative:fit1 <- gls(measure~time*group,correlation=corSymm(form=~1|subject),weight=varIdent(form=~1|time),data=df)
as it does capture the group and interaction effects but I think I need to contrast it with a null model and I'm not sure what would that null model be.
Any idea?
 

    On Thursday, July 21, 2016 3:27 PM, J?rg Albrecht <albrechj at staff.uni-marburg.de> wrote:
 

 Hi Dan,

most likely the model treats your time covariate as a continuous predictor. Try str(df), then time should appear as integer (int). If you specify time as a factor (with three levels: 1, 2, 3) the model will be able to estimate the time x treatment interaction separately for each time point. However, you still have to decide whether treating time as a factorial variable makes sense for your dataset.

Best,

J?rg


> Am 21.07.2016 um 20:13 schrieb Daniel Rubi via R-sig-mixed-models <r-sig-mixed-models at r-project.org>:
> 
> Hi,
> I have repeated measures from two groups (treatment and control), three subjects in each, over three time points.
> 
> Here's the data in an R data.frame:df <- data.frame(subject=rep(c("T1","T2","T3","C1","C2","C3"),3), group=rep(c(rep("T",3),rep("C",3)),3), time=c(rep(1,6),rep(2,6),rep(3,6)), measure=c(0,253,155,16,232,251,1035,1014,760,98,239,87,371,60,47,0,260,190), col=rep(c(rep("red",3),rep("blue",3)),3), stringsAsFactors=F)
> 
> 
> The plot shows the time x group interaction:
> 
> R code for producing the plot:
> plot(df$time,df$measure,col=df$col,xlab="time",ylab="measure")
> legend("topleft",legend=c("treatment","control"),col=c("red","blue"),pch=1)
> 
> 
> My question is what model to use to capture the time x group interaction.
> I thought:library(lmerTest)fit <- lmer(measure~time+group+time*group+(time|subject),data=df)
> might do it.
> But the summary of this model doesn't really capture that:> summary(fit)Linear mixed model fit by REMLt-tests use Satterthwaite approximations to degrees of freedom ['lmerMod']Formula: measure ~ time + group + time * group + (time | subject) Data: df
> REML criterion at convergence: 210
> 
> Scaled residuals: 
>? ? Min? ? 1Q Median? ? 3Q? ? Max 
> -1.228 -0.448 -0.163? 0.275? 1.923
> 
> Random effects:
>? Groups? Name? ? ? ? Variance Std.Dev. Corr
>? subject? (Intercept) 0.00e+00 0.00e+00? ? 
>? ? ? ? ? time? ? ? ? 3.06e-16 1.75e-08? NaN
>? Residual? ? ? ? ? ? 1.05e+05 3.25e+02? ? 
> Number of obs: 18, groups:? subject, 6
> 
> Fixed effects:
>? ? ? ? ? ? Estimate Std. Error? ? df t value Pr(>|t|)
> (Intercept)? 168.89? ? 286.35? 13.78? ? 0.59? ? 0.56
> time? ? ? ? ? -8.17? ? 132.55? 13.78? -0.06? ? 0.95
> groupT? ? ? ? 218.33? ? 404.96? 13.78? ? 0.54? ? 0.60
> time:groupT? ? 19.83? ? 187.46? 13.78? ? 0.11? ? 0.92
> 
> Correlation of Fixed Effects:
>? ? ? ? ? ? (Intr) time? groupT
> time? ? ? ? -0.926? ? ? ? ? ? ? 
> groupT? ? ? -0.707? 0.655? ? ? 
> time:groupT? 0.655 -0.707 -0.926
> 
> 
> So my question is what model to use?
> 
> Thanks a lot,Dan
> 
> <Rplot.png>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   



  
	[[alternative HTML version deleted]]


From patrick.schratz at gmail.com  Mon Jul 25 12:25:57 2016
From: patrick.schratz at gmail.com (Patrick Johann Schratz)
Date: Mon, 25 Jul 2016 12:25:57 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
Message-ID: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>

Link to data: <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>  
(1170 obs, 9 variables, .Rd file) [plain link in case sth goes wrong 
with the hyperlink: https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]

Simply read it in using `readRDS(file)`.

I?m trying to setup a GLMM using the `glmmPQL` function from the `MASS` 
package including a random effects part and accounting for spatial 
autocorrelation. However, R (Version: 3.3.1) crashes upon execution.

     library(nlme)

     # setup model formula
     fo <- hail ~ prec_nov_apr + t_min_nov_apr + srad_nov_apr + age

     # setup corSpatial object
     correl = corSpatial(value = c(10000, 0.1), form = ~ry + rx, nugget 
= TRUE,
                         fixed = FALSE, type = "exponential")
     correl = Initialize(correl, data = d)

     # fit model
     fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
                     correlation = correl, family = binomial)

What I tried so far:

- reduce number of observation
- play with `corSpatial` parameters (range and nugget)
- reduce number of fixed predictors
- execute code on Windows, Linux (Debian) and Mac R installations


While I get no error message on my local pc (RStudio just crashes), 
running the script on a server returns the following error message:

`R: malloc.c:3540: _int_malloc: Assertion (fwd->size & 0x4) == 0' 
failed. Aborted`

Debugging leads me to a "glibc" c++ library problem. I also run valgrind 
on it. If you need the output, just ask!

Help ist highly appreciated!
Cheers, Patrick

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Mon Jul 25 12:36:11 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Mon, 25 Jul 2016 10:36:11 +0000
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
Message-ID: <D4357EB9-395A-4E4B-BEC0-7F349181DA7D@unisa.edu.au>

Hi Patrick,

can you send us your sessionInfo()? Knowing the R version is important, but a few other details matter for debugging this type of problem!

Best,
Phillip

> On 25 Jul 2016, at 19:55, Patrick Johann Schratz <patrick.schratz at gmail.com> wrote:
> 
> Link to data: <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>  
> (1170 obs, 9 variables, .Rd file) [plain link in case sth goes wrong 
> with the hyperlink: https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
> 
> Simply read it in using `readRDS(file)`.
> 
> I?m trying to setup a GLMM using the `glmmPQL` function from the `MASS` 
> package including a random effects part and accounting for spatial 
> autocorrelation. However, R (Version: 3.3.1) crashes upon execution.
> 
>     library(nlme)
> 
>     # setup model formula
>     fo <- hail ~ prec_nov_apr + t_min_nov_apr + srad_nov_apr + age
> 
>     # setup corSpatial object
>     correl = corSpatial(value = c(10000, 0.1), form = ~ry + rx, nugget 
> = TRUE,
>                         fixed = FALSE, type = "exponential")
>     correl = Initialize(correl, data = d)
> 
>     # fit model
>     fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>                     correlation = correl, family = binomial)
> 
> What I tried so far:
> 
> - reduce number of observation
> - play with `corSpatial` parameters (range and nugget)
> - reduce number of fixed predictors
> - execute code on Windows, Linux (Debian) and Mac R installations
> 
> 
> While I get no error message on my local pc (RStudio just crashes), 
> running the script on a server returns the following error message:
> 
> `R: malloc.c:3540: _int_malloc: Assertion (fwd->size & 0x4) == 0' 
> failed. Aborted`
> 
> Debugging leads me to a "glibc" c++ library problem. I also run valgrind 
> on it. If you need the output, just ask!
> 
> Help ist highly appreciated!
> Cheers, Patrick
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From patrick.schratz at gmail.com  Mon Jul 25 12:38:32 2016
From: patrick.schratz at gmail.com (Patrick Johann Schratz)
Date: Mon, 25 Jul 2016 12:38:32 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
Message-ID: <3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>

MacbookPro:

 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-apple-darwin15.5.0 (64-bit)
Running under: OS X 10.11.6 (El Capitan)

locale:
[1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128 MASS_7.3-45 
gstat_1.1-3  sp_1.2-3

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 
FNN_1.1          spacetime_1.1-5  zoo_1.7-13       assertthat_0.1 
grid_3.3.1       pacman_0.4.1     minqa_1.2.4      nloptr_1.0.4
[12] xts_0.9-7        splines_3.3.1    tools_3.3.1



Am 25.07.16 um 12:34 schrieb Phillip Alday:
> Hi Patrick,
>
> can you send us your sessionInfo()? Knowing the R version is important, but a few other details matter for debugging this type of problem!
>
> Best,
> Phillip
>
>
>> On 25 Jul 2016, at 19:55, Patrick Johann Schratz <patrick.schratz at gmail.com> wrote:
>>
>> Link to data: <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>> (1170 obs, 9 variables, .Rd file) [plain link in case sth goes wrong
>> with the hyperlink: https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>>
>> Simply read it in using `readRDS(file)`.
>>
>> I?m trying to setup a GLMM using the `glmmPQL` function from the `MASS`
>> package including a random effects part and accounting for spatial
>> autocorrelation. However, R (Version: 3.3.1) crashes upon execution.
>>
>>      library(nlme)
>>
>>      # setup model formula
>>      fo <- hail ~ prec_nov_apr + t_min_nov_apr + srad_nov_apr + age
>>
>>      # setup corSpatial object
>>      correl = corSpatial(value = c(10000, 0.1), form = ~ry + rx, nugget
>> = TRUE,
>>                          fixed = FALSE, type = "exponential")
>>      correl = Initialize(correl, data = d)
>>
>>      # fit model
>>      fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>>                      correlation = correl, family = binomial)
>>
>> What I tried so far:
>>
>> - reduce number of observation
>> - play with `corSpatial` parameters (range and nugget)
>> - reduce number of fixed predictors
>> - execute code on Windows, Linux (Debian) and Mac R installations
>>
>>
>> While I get no error message on my local pc (RStudio just crashes),
>> running the script on a server returns the following error message:
>>
>> `R: malloc.c:3540: _int_malloc: Assertion (fwd->size & 0x4) == 0'
>> failed. Aborted`
>>
>> Debugging leads me to a "glibc" c++ library problem. I also run valgrind
>> on it. If you need the output, just ask!
>>
>> Help ist highly appreciated!
>> Cheers, Patrick
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Mon Jul 25 13:36:17 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Jul 2016 13:36:17 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
Message-ID: <CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>

Dear Patrick,

It seems like the correlation structure makes the model unstable. I get
convergence when setting fixed = TRUE, but the estimate are very unstable.

I'd suggest to have a look at the INLA package which allows to fit
spatially correlated random intercepts. It's described in "Spatial and
Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti, 2015)

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz <patrick.schratz at gmail.com
>:

> MacbookPro:
>
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-apple-darwin15.5.0 (64-bit)
> Running under: OS X 10.11.6 (El Capitan)
>
> locale:
> [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128 MASS_7.3-45
> gstat_1.1-3  sp_1.2-3
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
> spacetime_1.1-5  zoo_1.7-13       assertthat_0.1 grid_3.3.1
>  pacman_0.4.1     minqa_1.2.4      nloptr_1.0.4
> [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
>
>
>
> Am 25.07.16 um 12:34 schrieb Phillip Alday:
>
>> Hi Patrick,
>>
>> can you send us your sessionInfo()? Knowing the R version is important,
>> but a few other details matter for debugging this type of problem!
>>
>> Best,
>> Phillip
>>
>>
>> On 25 Jul 2016, at 19:55, Patrick Johann Schratz <
>>> patrick.schratz at gmail.com> wrote:
>>>
>>> Link to data: <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>>> (1170 obs, 9 variables, .Rd file) [plain link in case sth goes wrong
>>> with the hyperlink:
>>> https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>>>
>>> Simply read it in using `readRDS(file)`.
>>>
>>> I?m trying to setup a GLMM using the `glmmPQL` function from the `MASS`
>>> package including a random effects part and accounting for spatial
>>> autocorrelation. However, R (Version: 3.3.1) crashes upon execution.
>>>
>>>      library(nlme)
>>>
>>>      # setup model formula
>>>      fo <- hail ~ prec_nov_apr + t_min_nov_apr + srad_nov_apr + age
>>>
>>>      # setup corSpatial object
>>>      correl = corSpatial(value = c(10000, 0.1), form = ~ry + rx, nugget
>>> = TRUE,
>>>                          fixed = FALSE, type = "exponential")
>>>      correl = Initialize(correl, data = d)
>>>
>>>      # fit model
>>>      fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>>>                      correlation = correl, family = binomial)
>>>
>>> What I tried so far:
>>>
>>> - reduce number of observation
>>> - play with `corSpatial` parameters (range and nugget)
>>> - reduce number of fixed predictors
>>> - execute code on Windows, Linux (Debian) and Mac R installations
>>>
>>>
>>> While I get no error message on my local pc (RStudio just crashes),
>>> running the script on a server returns the following error message:
>>>
>>> `R: malloc.c:3540: _int_malloc: Assertion (fwd->size & 0x4) == 0'
>>> failed. Aborted`
>>>
>>> Debugging leads me to a "glibc" c++ library problem. I also run valgrind
>>> on it. If you need the output, just ask!
>>>
>>> Help ist highly appreciated!
>>> Cheers, Patrick
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jul 25 14:19:46 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Jul 2016 08:19:46 -0400
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
Message-ID: <579603E2.6090803@gmail.com>



  This example crashes for me too under Ubuntu 14.04 (virtual), r-devel,
with

fit5 <- glmmPQL(fo, random = ~1 | date, data = d,
+                 correl = correl, family = binomial)
iteration 1
*** Error in `/usr/local/lib/R/bin/exec/R': corrupted double-linked
list: 0x0000000007bef0d0 ***

  This was asked on Stack Overflow as well:

http://stackoverflow.com/questions/38509095/glmmpql-crashes-on-inclusion-of-corspatial-object

 I was going to suggest INLA as well.  I was working up to providing a
worked example, but it's non-trivial to set up (understatement): see
e.g.
https://www.math.ntnu.no/inla/r-inla.org/tutorials/spde/spde-tutorial.pdf

  Another non-trivial approach:
https://github.com/bbolker/mixedmodels-misc/blob/master/notes/corr_braindump.rmd
(use lme4's modular structure to incorporate nlme-based corStruct
information within models) -- this would be less efficient since it
would involve computing the Cholesky decomposition of a 1000x1000 matrix
at each step (and, indeed, might crash in the same place that glmmPQL
did), where INLA uses some very very clever computational tricks ...







On 16-07-25 07:36 AM, Thierry Onkelinx wrote:
> Dear Patrick,
> 
> It seems like the correlation structure makes the model unstable. I get
> convergence when setting fixed = TRUE, but the estimate are very unstable.
> 
> I'd suggest to have a look at the INLA package which allows to fit
> spatially correlated random intercepts. It's described in "Spatial and
> Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti, 2015)
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz <patrick.schratz at gmail.com
>> :
> 
>> MacbookPro:
>>
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-apple-darwin15.5.0 (64-bit)
>> Running under: OS X 10.11.6 (El Capitan)
>>
>> locale:
>> [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128 MASS_7.3-45
>> gstat_1.1-3  sp_1.2-3
>>
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
>> spacetime_1.1-5  zoo_1.7-13       assertthat_0.1 grid_3.3.1
>>  pacman_0.4.1     minqa_1.2.4      nloptr_1.0.4
>> [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
>>
>>
>>
>> Am 25.07.16 um 12:34 schrieb Phillip Alday:
>>
>>> Hi Patrick,
>>>
>>> can you send us your sessionInfo()? Knowing the R version is important,
>>> but a few other details matter for debugging this type of problem!
>>>
>>> Best,
>>> Phillip
>>>
>>>
>>> On 25 Jul 2016, at 19:55, Patrick Johann Schratz <
>>>> patrick.schratz at gmail.com> wrote:
>>>>
>>>> Link to data: <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>>>> (1170 obs, 9 variables, .Rd file) [plain link in case sth goes wrong
>>>> with the hyperlink:
>>>> https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>>>>
>>>> Simply read it in using `readRDS(file)`.
>>>>
>>>> I?m trying to setup a GLMM using the `glmmPQL` function from the `MASS`
>>>> package including a random effects part and accounting for spatial
>>>> autocorrelation. However, R (Version: 3.3.1) crashes upon execution.
>>>>
>>>>      library(nlme)
>>>>
>>>>      # setup model formula
>>>>      fo <- hail ~ prec_nov_apr + t_min_nov_apr + srad_nov_apr + age
>>>>
>>>>      # setup corSpatial object
>>>>      correl = corSpatial(value = c(10000, 0.1), form = ~ry + rx, nugget
>>>> = TRUE,
>>>>                          fixed = FALSE, type = "exponential")
>>>>      correl = Initialize(correl, data = d)
>>>>
>>>>      # fit model
>>>>      fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>>>>                      correlation = correl, family = binomial)
>>>>
>>>> What I tried so far:
>>>>
>>>> - reduce number of observation
>>>> - play with `corSpatial` parameters (range and nugget)
>>>> - reduce number of fixed predictors
>>>> - execute code on Windows, Linux (Debian) and Mac R installations
>>>>
>>>>
>>>> While I get no error message on my local pc (RStudio just crashes),
>>>> running the script on a server returns the following error message:
>>>>
>>>> `R: malloc.c:3540: _int_malloc: Assertion (fwd->size & 0x4) == 0'
>>>> failed. Aborted`
>>>>
>>>> Debugging leads me to a "glibc" c++ library problem. I also run valgrind
>>>> on it. If you need the output, just ask!
>>>>
>>>> Help ist highly appreciated!
>>>> Cheers, Patrick
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From patrick.schratz at gmail.com  Mon Jul 25 15:38:08 2016
From: patrick.schratz at gmail.com (Patrick Johann Schratz)
Date: Mon, 25 Jul 2016 15:38:08 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
Message-ID: <2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>

Dear Thierry,

thanks for your answer.

I also recognized that the spatial correlation structure is causing the 
problems as the random effects seem to work without any problems when 
omitting the spatial correlations part.
However, trying the formula with a random effect of 2 levels 
(=evaluation) instead of 4(=date) works:

/fit <- glmmPQL(fo, random = ~1 | evaluation, data = d, //
//                correlation = correl, family = binomial)/

Which gives me troubles tracking down the problem. glmmPQL should be 
able to handle 4 level random effects in combination with spatial 
correlation structures?

Setting "fixed = TRUE" in the corSpatial setup still causes the fitting 
of glmmPQL() to break in my case (with "date" as random effect). Did you 
also change other values of the corSpatial setup?

Thanks for your link to the R-INLA package. Looks very promising. 
However it will take me quite some time to adapt my code to R-INLA?s 
syntax and I doubt I have the time right now.

Best regards,
Patrick



Am 25.07.16 um 13:36 schrieb Thierry Onkelinx:
> Dear Patrick,
>
> It seems like the correlation structure makes the model unstable. I 
> get convergence when setting fixed = TRUE, but the estimate are very 
> unstable.
>
> I'd suggest to have a look at the INLA package which allows to fit 
> spatially correlated random intercepts. It's described in "Spatial and 
> Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti, 
> 2015)
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz 
> <patrick.schratz at gmail.com <mailto:patrick.schratz at gmail.com>>:
>
>     MacbookPro:
>
>     > sessionInfo()
>     R version 3.3.1 (2016-06-21)
>     Platform: x86_64-apple-darwin15.5.0 (64-bit)
>     Running under: OS X 10.11.6 (El Capitan)
>
>     locale:
>     [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets methods base
>
>     other attached packages:
>     [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128
>     MASS_7.3-45 gstat_1.1-3  sp_1.2-3
>
>     loaded via a namespace (and not attached):
>      [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1   
>           spacetime_1.1-5  zoo_1.7-13  assertthat_0.1 grid_3.3.1     
>      pacman_0.4.1  minqa_1.2.4      nloptr_1.0.4
>     [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
>
>
>
>     Am 25.07.16 um 12:34 schrieb Phillip Alday:
>
>         Hi Patrick,
>
>         can you send us your sessionInfo()? Knowing the R version is
>         important, but a few other details matter for debugging this
>         type of problem!
>
>         Best,
>         Phillip
>
>
>             On 25 Jul 2016, at 19:55, Patrick Johann Schratz
>             <patrick.schratz at gmail.com
>             <mailto:patrick.schratz at gmail.com>> wrote:
>
>             Link to data:
>             <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>             (1170 obs, 9 variables, .Rd file) [plain link in case sth
>             goes wrong
>             with the hyperlink:
>             https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>
>             Simply read it in using `readRDS(file)`.
>
>             I?m trying to setup a GLMM using the `glmmPQL` function
>             from the `MASS`
>             package including a random effects part and accounting for
>             spatial
>             autocorrelation. However, R (Version: 3.3.1) crashes upon
>             execution.
>
>                  library(nlme)
>
>                  # setup model formula
>                  fo <- hail ~ prec_nov_apr + t_min_nov_apr +
>             srad_nov_apr + age
>
>                  # setup corSpatial object
>                  correl = corSpatial(value = c(10000, 0.1), form = ~ry
>             + rx, nugget
>             = TRUE,
>                                      fixed = FALSE, type = "exponential")
>                  correl = Initialize(correl, data = d)
>
>                  # fit model
>                  fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>                                  correlation = correl, family = binomial)
>
>             What I tried so far:
>
>             - reduce number of observation
>             - play with `corSpatial` parameters (range and nugget)
>             - reduce number of fixed predictors
>             - execute code on Windows, Linux (Debian) and Mac R
>             installations
>
>
>             While I get no error message on my local pc (RStudio just
>             crashes),
>             running the script on a server returns the following error
>             message:
>
>             `R: malloc.c:3540: _int_malloc: Assertion (fwd->size &
>             0x4) == 0'
>             failed. Aborted`
>
>             Debugging leads me to a "glibc" c++ library problem. I
>             also run valgrind
>             on it. If you need the output, just ask!
>
>             Help ist highly appreciated!
>             Cheers, Patrick
>
>                     [[alternative HTML version deleted]]
>
>             _______________________________________________
>             R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


	[[alternative HTML version deleted]]


From patrick.schratz at gmail.com  Mon Jul 25 16:33:48 2016
From: patrick.schratz at gmail.com (Patrick Johann Schratz)
Date: Mon, 25 Jul 2016 16:33:48 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <448a6df9-9573-ad94-5c2a-42719a33fe29@gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
	<2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
	<op.yk5sqoqwsgx3xe@armadillo50>
	<448a6df9-9573-ad94-5c2a-42719a33fe29@gmail.com>
Message-ID: <4fcab26b-6bb1-4940-256d-ca8657f863fb@gmail.com>

Hi Paul,

indeed - thats the reason! What a simple error causing me headaches 
since weeks.

Actually I thought I removed all NA?s in the "date" column but did not 
check explicitly for it. Caused by a different date format using "/" 
instead of "-" for some entries in the data set.

Kind of embarrassing...

Thank you all for your replies guys!!


Am 25.07.16 um 16:33 schrieb Patrick Johann Schratz:
> Hi Paul,
>
> indeed - thats the reason! What a simple error causing me headaches 
> since weeks.
>
> Actually I thought I removed all NA?s in the "date" column but did not 
> check explicitly for it. Caused by a different date format using "/" 
> instead of "-" for some entries in the data set.
>
> Kind of embarrassing...
>
> Thank you all for your replies guys!!
>
>
> Am 25.07.16 um 15:50 schrieb Paul Debes:
>> Hi Patrick,
>>
>> Maybe the NA entries in the random "date" predictor are causing the 
>> crash?
>> When I run the model on a subset without NA for "date" it runs. 
>> Probably not what you want but it may help at least a bit.
>>
>> Hope this works for you too.
>> Paul
>>
>> str(data)
>> data$hail = as.integer(as.character(data$hail))
>>
>> # removing NA data in "date"
>> data.sub = data[!is.na(data$date),]
>>
>> library("MASS")
>> library("nlme")
>>
>> # changed 'ry' to 'rlat' and 'rx' to 'rlon'
>> correl = corSpatial(value = c(10000, 0.1), form = ~rlat + rlon, 
>> nugget = TRUE, fixed = FALSE, type = "exponential")
>> correl = Initialize(correl, data = data.sub)
>>
>> model = glmmPQL(hail ~ 1 + prec_nov_apr + t_min_nov_apr + 
>> srad_nov_apr + age,
>>     random = ~ 1 | date,
>>     data = data.sub,
>>     correlation = correl,
>>     family = binomial)
>>
>> summary(model)
>> Linear mixed-effects model fit by maximum likelihood
>>  Data: data.sub
>>   AIC BIC logLik
>>    NA  NA     NA
>>
>> Random effects:
>>  Formula: ~1 | date
>>         (Intercept) Residual
>> StdDev:   0.7641223 1.042385
>>
>> Correlation Structure: Exponential spatial correlation
>>  Formula: ~rlat + rlon | date
>>  Parameter estimate(s):
>>        range       nugget
>> 159.37292936   0.05719671
>> Variance function:
>>  Structure: fixed weights
>>  Formula: ~invwt
>> Fixed effects: hail ~ 1 + prec_nov_apr + t_min_nov_apr + srad_nov_apr 
>> + age
>>                   Value Std.Error   DF   t-value p-value
>> (Intercept)   -8.686290 1.0712635 1056 -8.108453  0.0000
>> prec_nov_apr   0.043263 0.0057295 1056  7.550986  0.0000
>> t_min_nov_apr  0.197124 0.0772288 1056  2.552470  0.0108
>> srad_nov_apr   0.000183 0.0004113 1056  0.445830  0.6558
>> age            0.002953 0.0053051 1056  0.556672  0.5779
>>  Correlation:
>>               (Intr) prc_n_ t_mn__ srd_n_
>> prec_nov_apr  -0.740
>> t_min_nov_apr  0.021 -0.308
>> srad_nov_apr  -0.575  0.162 -0.207
>> age           -0.012 -0.095  0.105 -0.074
>>
>> Standardized Within-Group Residuals:
>>        Min         Q1        Med         Q3        Max
>> -1.1957073 -0.4895324 -0.3471985 -0.1436912 12.5749006
>>
>> Number of Observations: 1064
>> Number of Groups: 4
>>
>>
>>
>> On Mon, 25 Jul 2016 16:38:08 +0300, Patrick Johann Schratz 
>> <patrick.schratz at gmail.com> wrote:
>>
>>> Dear Thierry,
>>>
>>> thanks for your answer.
>>>
>>> I also recognized that the spatial correlation structure is causing the
>>> problems as the random effects seem to work without any problems when
>>> omitting the spatial correlations part.
>>> However, trying the formula with a random effect of 2 levels
>>> (=evaluation) instead of 4(=date) works:
>>>
>>> /fit <- glmmPQL(fo, random = ~1 | evaluation, data = d, //
>>> //                correlation = correl, family = binomial)/
>>>
>>> Which gives me troubles tracking down the problem. glmmPQL should be
>>> able to handle 4 level random effects in combination with spatial
>>> correlation structures?
>>>
>>> Setting "fixed = TRUE" in the corSpatial setup still causes the fitting
>>> of glmmPQL() to break in my case (with "date" as random effect). Did 
>>> you
>>> also change other values of the corSpatial setup?
>>>
>>> Thanks for your link to the R-INLA package. Looks very promising.
>>> However it will take me quite some time to adapt my code to R-INLA?s
>>> syntax and I doubt I have the time right now.
>>>
>>> Best regards,
>>> Patrick
>>>
>>>
>>>
>>> Am 25.07.16 um 13:36 schrieb Thierry Onkelinx:
>>>> Dear Patrick,
>>>>
>>>> It seems like the correlation structure makes the model unstable. I
>>>> get convergence when setting fixed = TRUE, but the estimate are very
>>>> unstable.
>>>>
>>>> I'd suggest to have a look at the INLA package which allows to fit
>>>> spatially correlated random intercepts. It's described in "Spatial and
>>>> Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti,
>>>> 2015)
>>>>
>>>> Best regards,
>>>>
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body
>>>> of data. ~ John Tukey
>>>>
>>>> 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz
>>>> <patrick.schratz at gmail.com <mailto:patrick.schratz at gmail.com>>:
>>>>
>>>>     MacbookPro:
>>>>
>>>>     > sessionInfo()
>>>>     R version 3.3.1 (2016-06-21)
>>>>     Platform: x86_64-apple-darwin15.5.0 (64-bit)
>>>>     Running under: OS X 10.11.6 (El Capitan)
>>>>
>>>>     locale:
>>>>     [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>>>>
>>>>     attached base packages:
>>>>     [1] stats     graphics  grDevices utils     datasets methods base
>>>>
>>>>     other attached packages:
>>>>     [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128
>>>>     MASS_7.3-45 gstat_1.1-3  sp_1.2-3
>>>>
>>>>     loaded via a namespace (and not attached):
>>>>      [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
>>>>           spacetime_1.1-5  zoo_1.7-13  assertthat_0.1 grid_3.3.1
>>>>      pacman_0.4.1  minqa_1.2.4      nloptr_1.0.4
>>>>     [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
>>>>
>>>>
>>>>
>>>>     Am 25.07.16 um 12:34 schrieb Phillip Alday:
>>>>
>>>>         Hi Patrick,
>>>>
>>>>         can you send us your sessionInfo()? Knowing the R version is
>>>>         important, but a few other details matter for debugging this
>>>>         type of problem!
>>>>
>>>>         Best,
>>>>         Phillip
>>>>
>>>>
>>>>             On 25 Jul 2016, at 19:55, Patrick Johann Schratz
>>>>             <patrick.schratz at gmail.com
>>>>             <mailto:patrick.schratz at gmail.com>> wrote:
>>>>
>>>>             Link to data:
>>>> <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>>>>             (1170 obs, 9 variables, .Rd file) [plain link in case sth
>>>>             goes wrong
>>>>             with the hyperlink:
>>>> https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>>>>
>>>>             Simply read it in using `readRDS(file)`.
>>>>
>>>>             I?m trying to setup a GLMM using the `glmmPQL` function
>>>>             from the `MASS`
>>>>             package including a random effects part and accounting for
>>>>             spatial
>>>>             autocorrelation. However, R (Version: 3.3.1) crashes upon
>>>>             execution.
>>>>
>>>>                  library(nlme)
>>>>
>>>>                  # setup model formula
>>>>                  fo <- hail ~ prec_nov_apr + t_min_nov_apr +
>>>>             srad_nov_apr + age
>>>>
>>>>                  # setup corSpatial object
>>>>                  correl = corSpatial(value = c(10000, 0.1), form = ~ry
>>>>             + rx, nugget
>>>>             = TRUE,
>>>>                                      fixed = FALSE, type = 
>>>> "exponential")
>>>>                  correl = Initialize(correl, data = d)
>>>>
>>>>                  # fit model
>>>>                  fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data 
>>>> = d,
>>>>                                  correlation = correl, family = 
>>>> binomial)
>>>>
>>>>             What I tried so far:
>>>>
>>>>             - reduce number of observation
>>>>             - play with `corSpatial` parameters (range and nugget)
>>>>             - reduce number of fixed predictors
>>>>             - execute code on Windows, Linux (Debian) and Mac R
>>>>             installations
>>>>
>>>>
>>>>             While I get no error message on my local pc (RStudio just
>>>>             crashes),
>>>>             running the script on a server returns the following error
>>>>             message:
>>>>
>>>>             `R: malloc.c:3540: _int_malloc: Assertion (fwd->size &
>>>>             0x4) == 0'
>>>>             failed. Aborted`
>>>>
>>>>             Debugging leads me to a "glibc" c++ library problem. I
>>>>             also run valgrind
>>>>             on it. If you need the output, just ask!
>>>>
>>>>             Help ist highly appreciated!
>>>>             Cheers, Patrick
>>>>
>>>>                     [[alternative HTML version deleted]]
>>>>
>>>>             _______________________________________________
>>>>             R-sig-mixed-models at r-project.org
>>>>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>     _______________________________________________
>>>>     R-sig-mixed-models at r-project.org
>>>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>


From thierry.onkelinx at inbo.be  Mon Jul 25 22:54:15 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Jul 2016 22:54:15 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
	<2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
Message-ID: <CAJuCY5wHtD=QC8QwOJBVRq71Qj8n4u7S9pawS_=DCpetCfpTOw@mail.gmail.com>

De

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-25 15:38 GMT+02:00 Patrick Johann Schratz <patrick.schratz at gmail.com
>:

> Dear Thierry,
>
> thanks for your answer.
>
> I also recognized that the spatial correlation structure is causing the
> problems as the random effects seem to work without any problems when
> omitting the spatial correlations part.
> However, trying the formula with a random effect of 2 levels
> (=evaluation) instead of 4(=date) works:
>
> /fit <- glmmPQL(fo, random = ~1 | evaluation, data = d, //
> //                correlation = correl, family = binomial)/
>
> Which gives me troubles tracking down the problem. glmmPQL should be
> able to handle 4 level random effects in combination with spatial
> correlation structures?
>
> Setting "fixed = TRUE" in the corSpatial setup still causes the fitting
> of glmmPQL() to break in my case (with "date" as random effect). Did you
> also change other values of the corSpatial setup?
>
> Thanks for your link to the R-INLA package. Looks very promising.
> However it will take me quite some time to adapt my code to R-INLA?s
> syntax and I doubt I have the time right now.
>
> Best regards,
> Patrick
>
>
>
> Am 25.07.16 um 13:36 schrieb Thierry Onkelinx:
> > Dear Patrick,
> >
> > It seems like the correlation structure makes the model unstable. I
> > get convergence when setting fixed = TRUE, but the estimate are very
> > unstable.
> >
> > I'd suggest to have a look at the INLA package which allows to fit
> > spatially correlated random intercepts. It's described in "Spatial and
> > Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti,
> > 2015)
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz
> > <patrick.schratz at gmail.com <mailto:patrick.schratz at gmail.com>>:
> >
> >     MacbookPro:
> >
> >     > sessionInfo()
> >     R version 3.3.1 (2016-06-21)
> >     Platform: x86_64-apple-darwin15.5.0 (64-bit)
> >     Running under: OS X 10.11.6 (El Capitan)
> >
> >     locale:
> >     [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
> >
> >     attached base packages:
> >     [1] stats     graphics  grDevices utils     datasets methods base
> >
> >     other attached packages:
> >     [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128
> >     MASS_7.3-45 gstat_1.1-3  sp_1.2-3
> >
> >     loaded via a namespace (and not attached):
> >      [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
> >           spacetime_1.1-5  zoo_1.7-13  assertthat_0.1 grid_3.3.1
> >      pacman_0.4.1  minqa_1.2.4      nloptr_1.0.4
> >     [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
> >
> >
> >
> >     Am 25.07.16 um 12:34 schrieb Phillip Alday:
> >
> >         Hi Patrick,
> >
> >         can you send us your sessionInfo()? Knowing the R version is
> >         important, but a few other details matter for debugging this
> >         type of problem!
> >
> >         Best,
> >         Phillip
> >
> >
> >             On 25 Jul 2016, at 19:55, Patrick Johann Schratz
> >             <patrick.schratz at gmail.com
> >             <mailto:patrick.schratz at gmail.com>> wrote:
> >
> >             Link to data:
> >             <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
> >             (1170 obs, 9 variables, .Rd file) [plain link in case sth
> >             goes wrong
> >             with the hyperlink:
> >             https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
> >
> >             Simply read it in using `readRDS(file)`.
> >
> >             I?m trying to setup a GLMM using the `glmmPQL` function
> >             from the `MASS`
> >             package including a random effects part and accounting for
> >             spatial
> >             autocorrelation. However, R (Version: 3.3.1) crashes upon
> >             execution.
> >
> >                  library(nlme)
> >
> >                  # setup model formula
> >                  fo <- hail ~ prec_nov_apr + t_min_nov_apr +
> >             srad_nov_apr + age
> >
> >                  # setup corSpatial object
> >                  correl = corSpatial(value = c(10000, 0.1), form = ~ry
> >             + rx, nugget
> >             = TRUE,
> >                                      fixed = FALSE, type = "exponential")
> >                  correl = Initialize(correl, data = d)
> >
> >                  # fit model
> >                  fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
> >                                  correlation = correl, family = binomial)
> >
> >             What I tried so far:
> >
> >             - reduce number of observation
> >             - play with `corSpatial` parameters (range and nugget)
> >             - reduce number of fixed predictors
> >             - execute code on Windows, Linux (Debian) and Mac R
> >             installations
> >
> >
> >             While I get no error message on my local pc (RStudio just
> >             crashes),
> >             running the script on a server returns the following error
> >             message:
> >
> >             `R: malloc.c:3540: _int_malloc: Assertion (fwd->size &
> >             0x4) == 0'
> >             failed. Aborted`
> >
> >             Debugging leads me to a "glibc" c++ library problem. I
> >             also run valgrind
> >             on it. If you need the output, just ask!
> >
> >             Help ist highly appreciated!
> >             Cheers, Patrick
> >
> >                     [[alternative HTML version deleted]]
> >
> >             _______________________________________________
> >             R-sig-mixed-models at r-project.org
> >             <mailto:R-sig-mixed-models at r-project.org> mailing list
> >             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jul 25 22:56:53 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 25 Jul 2016 22:56:53 +0200
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
	<2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
Message-ID: <CAJuCY5x3eN0un4zvHY=PtqfV8Ni36jARW0r0MmE7ugrUt9UKkw@mail.gmail.com>

Dear Patrick,

I've put a quick and dirty example of your model fit with INLA on
http://rpubs.com/INBOstats/spde

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-25 15:38 GMT+02:00 Patrick Johann Schratz <patrick.schratz at gmail.com
>:

> Dear Thierry,
>
> thanks for your answer.
>
> I also recognized that the spatial correlation structure is causing the
> problems as the random effects seem to work without any problems when
> omitting the spatial correlations part.
> However, trying the formula with a random effect of 2 levels
> (=evaluation) instead of 4(=date) works:
>
> /fit <- glmmPQL(fo, random = ~1 | evaluation, data = d, //
> //                correlation = correl, family = binomial)/
>
> Which gives me troubles tracking down the problem. glmmPQL should be
> able to handle 4 level random effects in combination with spatial
> correlation structures?
>
> Setting "fixed = TRUE" in the corSpatial setup still causes the fitting
> of glmmPQL() to break in my case (with "date" as random effect). Did you
> also change other values of the corSpatial setup?
>
> Thanks for your link to the R-INLA package. Looks very promising.
> However it will take me quite some time to adapt my code to R-INLA?s
> syntax and I doubt I have the time right now.
>
> Best regards,
> Patrick
>
>
>
> Am 25.07.16 um 13:36 schrieb Thierry Onkelinx:
> > Dear Patrick,
> >
> > It seems like the correlation structure makes the model unstable. I
> > get convergence when setting fixed = TRUE, but the estimate are very
> > unstable.
> >
> > I'd suggest to have a look at the INLA package which allows to fit
> > spatially correlated random intercepts. It's described in "Spatial and
> > Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti,
> > 2015)
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> > 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz
> > <patrick.schratz at gmail.com <mailto:patrick.schratz at gmail.com>>:
> >
> >     MacbookPro:
> >
> >     > sessionInfo()
> >     R version 3.3.1 (2016-06-21)
> >     Platform: x86_64-apple-darwin15.5.0 (64-bit)
> >     Running under: OS X 10.11.6 (El Capitan)
> >
> >     locale:
> >     [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
> >
> >     attached base packages:
> >     [1] stats     graphics  grDevices utils     datasets methods base
> >
> >     other attached packages:
> >     [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128
> >     MASS_7.3-45 gstat_1.1-3  sp_1.2-3
> >
> >     loaded via a namespace (and not attached):
> >      [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
> >           spacetime_1.1-5  zoo_1.7-13  assertthat_0.1 grid_3.3.1
> >      pacman_0.4.1  minqa_1.2.4      nloptr_1.0.4
> >     [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
> >
> >
> >
> >     Am 25.07.16 um 12:34 schrieb Phillip Alday:
> >
> >         Hi Patrick,
> >
> >         can you send us your sessionInfo()? Knowing the R version is
> >         important, but a few other details matter for debugging this
> >         type of problem!
> >
> >         Best,
> >         Phillip
> >
> >
> >             On 25 Jul 2016, at 19:55, Patrick Johann Schratz
> >             <patrick.schratz at gmail.com
> >             <mailto:patrick.schratz at gmail.com>> wrote:
> >
> >             Link to data:
> >             <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
> >             (1170 obs, 9 variables, .Rd file) [plain link in case sth
> >             goes wrong
> >             with the hyperlink:
> >             https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
> >
> >             Simply read it in using `readRDS(file)`.
> >
> >             I?m trying to setup a GLMM using the `glmmPQL` function
> >             from the `MASS`
> >             package including a random effects part and accounting for
> >             spatial
> >             autocorrelation. However, R (Version: 3.3.1) crashes upon
> >             execution.
> >
> >                  library(nlme)
> >
> >                  # setup model formula
> >                  fo <- hail ~ prec_nov_apr + t_min_nov_apr +
> >             srad_nov_apr + age
> >
> >                  # setup corSpatial object
> >                  correl = corSpatial(value = c(10000, 0.1), form = ~ry
> >             + rx, nugget
> >             = TRUE,
> >                                      fixed = FALSE, type = "exponential")
> >                  correl = Initialize(correl, data = d)
> >
> >                  # fit model
> >                  fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
> >                                  correlation = correl, family = binomial)
> >
> >             What I tried so far:
> >
> >             - reduce number of observation
> >             - play with `corSpatial` parameters (range and nugget)
> >             - reduce number of fixed predictors
> >             - execute code on Windows, Linux (Debian) and Mac R
> >             installations
> >
> >
> >             While I get no error message on my local pc (RStudio just
> >             crashes),
> >             running the script on a server returns the following error
> >             message:
> >
> >             `R: malloc.c:3540: _int_malloc: Assertion (fwd->size &
> >             0x4) == 0'
> >             failed. Aborted`
> >
> >             Debugging leads me to a "glibc" c++ library problem. I
> >             also run valgrind
> >             on it. If you need the output, just ask!
> >
> >             Help ist highly appreciated!
> >             Cheers, Patrick
> >
> >                     [[alternative HTML version deleted]]
> >
> >             _______________________________________________
> >             R-sig-mixed-models at r-project.org
> >             <mailto:R-sig-mixed-models at r-project.org> mailing list
> >             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jul 25 23:01:43 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Jul 2016 17:01:43 -0400
Subject: [R-sig-ME] glmmPQL crashes on inclusion of corSpatial object
In-Reply-To: <CAJuCY5x3eN0un4zvHY=PtqfV8Ni36jARW0r0MmE7ugrUt9UKkw@mail.gmail.com>
References: <92be10bc-9e0c-26e1-6872-40b18d34ac20@gmail.com>
	<8B60A999-01EC-4A6B-BDF7-86FD16A0FE75@unisa.edu.au>
	<3f017143-9e31-9744-ccfd-e140efb22768@gmail.com>
	<CAJuCY5ywv=VTQGJtzinq8s6tuJV6NHg=mVp5F-D5RkS6wxzuwg@mail.gmail.com>
	<2a841ead-9123-e70d-40de-842bc4f0cf43@gmail.com>
	<CAJuCY5x3eN0un4zvHY=PtqfV8Ni36jARW0r0MmE7ugrUt9UKkw@mail.gmail.com>
Message-ID: <57967E37.3030008@gmail.com>


  that's amazing! thank you.

On 16-07-25 04:56 PM, Thierry Onkelinx wrote:
> Dear Patrick,
> 
> I've put a quick and dirty example of your model fit with INLA on
> http://rpubs.com/INBOstats/spde
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2016-07-25 15:38 GMT+02:00 Patrick Johann Schratz <patrick.schratz at gmail.com
>> :
> 
>> Dear Thierry,
>>
>> thanks for your answer.
>>
>> I also recognized that the spatial correlation structure is causing the
>> problems as the random effects seem to work without any problems when
>> omitting the spatial correlations part.
>> However, trying the formula with a random effect of 2 levels
>> (=evaluation) instead of 4(=date) works:
>>
>> /fit <- glmmPQL(fo, random = ~1 | evaluation, data = d, //
>> //                correlation = correl, family = binomial)/
>>
>> Which gives me troubles tracking down the problem. glmmPQL should be
>> able to handle 4 level random effects in combination with spatial
>> correlation structures?
>>
>> Setting "fixed = TRUE" in the corSpatial setup still causes the fitting
>> of glmmPQL() to break in my case (with "date" as random effect). Did you
>> also change other values of the corSpatial setup?
>>
>> Thanks for your link to the R-INLA package. Looks very promising.
>> However it will take me quite some time to adapt my code to R-INLA?s
>> syntax and I doubt I have the time right now.
>>
>> Best regards,
>> Patrick
>>
>>
>>
>> Am 25.07.16 um 13:36 schrieb Thierry Onkelinx:
>>> Dear Patrick,
>>>
>>> It seems like the correlation structure makes the model unstable. I
>>> get convergence when setting fixed = TRUE, but the estimate are very
>>> unstable.
>>>
>>> I'd suggest to have a look at the INLA package which allows to fit
>>> spatially correlated random intercepts. It's described in "Spatial and
>>> Spatio-Temporal Bayesian models with R-INLA" (Blangiardo & Cameletti,
>>> 2015)
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>>
>>> 2016-07-25 12:38 GMT+02:00 Patrick Johann Schratz
>>> <patrick.schratz at gmail.com <mailto:patrick.schratz at gmail.com>>:
>>>
>>>     MacbookPro:
>>>
>>>     > sessionInfo()
>>>     R version 3.3.1 (2016-06-21)
>>>     Platform: x86_64-apple-darwin15.5.0 (64-bit)
>>>     Running under: OS X 10.11.6 (El Capitan)
>>>
>>>     locale:
>>>     [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>>>
>>>     attached base packages:
>>>     [1] stats     graphics  grDevices utils     datasets methods base
>>>
>>>     other attached packages:
>>>     [1] lme4_1.1-12  Matrix_1.2-6 tibble_1.1   nlme_3.1-128
>>>     MASS_7.3-45 gstat_1.1-3  sp_1.2-3
>>>
>>>     loaded via a namespace (and not attached):
>>>      [1] Rcpp_0.12.6      lattice_0.20-33  intervals_0.15.1 FNN_1.1
>>>           spacetime_1.1-5  zoo_1.7-13  assertthat_0.1 grid_3.3.1
>>>      pacman_0.4.1  minqa_1.2.4      nloptr_1.0.4
>>>     [12] xts_0.9-7        splines_3.3.1    tools_3.3.1
>>>
>>>
>>>
>>>     Am 25.07.16 um 12:34 schrieb Phillip Alday:
>>>
>>>         Hi Patrick,
>>>
>>>         can you send us your sessionInfo()? Knowing the R version is
>>>         important, but a few other details matter for debugging this
>>>         type of problem!
>>>
>>>         Best,
>>>         Phillip
>>>
>>>
>>>             On 25 Jul 2016, at 19:55, Patrick Johann Schratz
>>>             <patrick.schratz at gmail.com
>>>             <mailto:patrick.schratz at gmail.com>> wrote:
>>>
>>>             Link to data:
>>>             <https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0>
>>>             (1170 obs, 9 variables, .Rd file) [plain link in case sth
>>>             goes wrong
>>>             with the hyperlink:
>>>             https://www.dropbox.com/s/yi3vf0bmqvydr8h/data.Rd?dl=0]
>>>
>>>             Simply read it in using `readRDS(file)`.
>>>
>>>             I?m trying to setup a GLMM using the `glmmPQL` function
>>>             from the `MASS`
>>>             package including a random effects part and accounting for
>>>             spatial
>>>             autocorrelation. However, R (Version: 3.3.1) crashes upon
>>>             execution.
>>>
>>>                  library(nlme)
>>>
>>>                  # setup model formula
>>>                  fo <- hail ~ prec_nov_apr + t_min_nov_apr +
>>>             srad_nov_apr + age
>>>
>>>                  # setup corSpatial object
>>>                  correl = corSpatial(value = c(10000, 0.1), form = ~ry
>>>             + rx, nugget
>>>             = TRUE,
>>>                                      fixed = FALSE, type = "exponential")
>>>                  correl = Initialize(correl, data = d)
>>>
>>>                  # fit model
>>>                  fit5 <- MASS::glmmPQL(fo, random = ~1 | date, data = d,
>>>                                  correlation = correl, family = binomial)
>>>
>>>             What I tried so far:
>>>
>>>             - reduce number of observation
>>>             - play with `corSpatial` parameters (range and nugget)
>>>             - reduce number of fixed predictors
>>>             - execute code on Windows, Linux (Debian) and Mac R
>>>             installations
>>>
>>>
>>>             While I get no error message on my local pc (RStudio just
>>>             crashes),
>>>             running the script on a server returns the following error
>>>             message:
>>>
>>>             `R: malloc.c:3540: _int_malloc: Assertion (fwd->size &
>>>             0x4) == 0'
>>>             failed. Aborted`
>>>
>>>             Debugging leads me to a "glibc" c++ library problem. I
>>>             also run valgrind
>>>             on it. If you need the output, just ask!
>>>
>>>             Help ist highly appreciated!
>>>             Cheers, Patrick
>>>
>>>                     [[alternative HTML version deleted]]
>>>
>>>             _______________________________________________
>>>             R-sig-mixed-models at r-project.org
>>>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>     _______________________________________________
>>>     R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From saah500 at york.ac.uk  Tue Jul 26 09:50:18 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 26 Jul 2016 10:50:18 +0300
Subject: [R-sig-ME] When can the intercept be removed from regression models
Message-ID: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>

Good morning,

I am in a dilemma regarding the inclusion of the intercept in my mixed
effects logistic regression models.  Most statisticians that I talked to
insist that I shouldn?t remove the constant from my models.  One of the
pros is that the models would be of good fit since the R2 value would be
improved. Conversely, removing the constant means that there is no
guarantee that we would end up in getting biased coefficients since the
slopes would be forced to originate from the 0.

I found only one textbook which does not state it but rather seems to imply
that sometimes we can remove the constant. This is the reference provided
below.

Cornillon, P.A., Guyader, A., Husson, F., J?gou, N., Josse, J., Kloareg,
M., LOber, E and Rouvi?re, L. (2012). *R for Statistics*: CRC Press. Taylor
& Francis Group.



On p.136, it says that ?The p-value of less than 5% for the constant
(intercept) indicates that the constant must appear in the model?.  So
based on this, I am assuming that a p-value of more than 5% for the
intercept would mean that the intercept should be removed.

I would appreciate it if someone could help me with this conundrum.

-- 
Shadiya

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jul 26 10:32:03 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 26 Jul 2016 10:32:03 +0200
Subject: [R-sig-ME] When can the intercept be removed from regression
	models
In-Reply-To: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
Message-ID: <CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>

Dear Shadiya,

Thou shall always keep the intercept in the model. Its p-value doesn't
matter.

I use two exceptions against that rule:
1. There is a physical/biological/... reason why the intercept should be 0
2. Removing the intercept gives a different, more convenient
parametrisation (but not does not changes the model fit!)

Note that in logistic regression you use a logit transformation. Hence
forcing the model thru the origin on the logit scale, forces the model to
50% probability at the original scale. I haven't seen an example where that
makes sense.

Bottom line: only remove the intercept when you really know what you are
doing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Good morning,
>
> I am in a dilemma regarding the inclusion of the intercept in my mixed
> effects logistic regression models.  Most statisticians that I talked to
> insist that I shouldn?t remove the constant from my models.  One of the
> pros is that the models would be of good fit since the R2 value would be
> improved. Conversely, removing the constant means that there is no
> guarantee that we would end up in getting biased coefficients since the
> slopes would be forced to originate from the 0.
>
> I found only one textbook which does not state it but rather seems to imply
> that sometimes we can remove the constant. This is the reference provided
> below.
>
> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N., Josse, J., Kloareg,
> M., LOber, E and Rouvi?re, L. (2012). *R for Statistics*: CRC Press. Taylor
> & Francis Group.
>
>
>
> On p.136, it says that ?The p-value of less than 5% for the constant
> (intercept) indicates that the constant must appear in the model?.  So
> based on this, I am assuming that a p-value of more than 5% for the
> intercept would mean that the intercept should be removed.
>
> I would appreciate it if someone could help me with this conundrum.
>
> --
> Shadiya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Tue Jul 26 11:40:26 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 26 Jul 2016 12:40:26 +0300
Subject: [R-sig-ME] When can the intercept be removed from regression
	models
In-Reply-To: <CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
Message-ID: <F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>

Thanks Thierry for your response. 

I tried the model before and after removing the intercept a while ago and I remember that the coefficients were pretty much the same. The only salient difference was that the levels of the first categorical variable in the model formula were all given in the output table instead of the reference level being embedded in the intercept as in the model with intercept.

It would be nice to find examples from the literature where the intercept is removed from the model. Can you think of any?

Shadiya

Sent from my iPhone

> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Shadiya,
> 
> Thou shall always keep the intercept in the model. Its p-value doesn't matter.
> 
> I use two exceptions against that rule:
> 1. There is a physical/biological/... reason why the intercept should be 0
> 2. Removing the intercept gives a different, more convenient parametrisation (but not does not changes the model fit!)
> 
> Note that in logistic regression you use a logit transformation. Hence forcing the model thru the origin on the logit scale, forces the model to 50% probability at the original scale. I haven't seen an example where that makes sense.
> 
> Bottom line: only remove the intercept when you really know what you are doing. 
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>> Good morning,
>> 
>> I am in a dilemma regarding the inclusion of the intercept in my mixed
>> effects logistic regression models.  Most statisticians that I talked to
>> insist that I shouldn?t remove the constant from my models.  One of the
>> pros is that the models would be of good fit since the R2 value would be
>> improved. Conversely, removing the constant means that there is no
>> guarantee that we would end up in getting biased coefficients since the
>> slopes would be forced to originate from the 0.
>> 
>> I found only one textbook which does not state it but rather seems to imply
>> that sometimes we can remove the constant. This is the reference provided
>> below.
>> 
>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N., Josse, J., Kloareg,
>> M., LOber, E and Rouvi?re, L. (2012). *R for Statistics*: CRC Press. Taylor
>> & Francis Group.
>> 
>> 
>> 
>> On p.136, it says that ?The p-value of less than 5% for the constant
>> (intercept) indicates that the constant must appear in the model?.  So
>> based on this, I am assuming that a p-value of more than 5% for the
>> intercept would mean that the intercept should be removed.
>> 
>> I would appreciate it if someone could help me with this conundrum.
>> 
>> --
>> Shadiya
>> 
>>         [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Jul 26 12:08:02 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 26 Jul 2016 12:08:02 +0200
Subject: [R-sig-ME] When can the intercept be removed from
	regression	models
In-Reply-To: <F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
	<F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
Message-ID: <22423.13954.813534.279148@stat.math.ethz.ch>

>>>>> Shadiya Al Hashmi <saah500 at york.ac.uk>
>>>>>     on Tue, 26 Jul 2016 12:40:26 +0300 writes:

    > Thanks Thierry for your response.  I tried the model
    > before and after removing the intercept a while ago and I
    > remember that the coefficients were pretty much the same.

but other things are *not* pretty much the same, and you
really really really should obey the advice by Thierry:

   ALWAYS KEEP THE INTERCEPT IN THE MODEL !!!

(at least until you become a very experience stastician / data
 scientist / .. )
 

    >> p-value doesn't matter.
    >  The only salient difference was that the levels of
    > the first categorical variable in the model formula were
    > all given in the output table instead of the reference
    > level being embedded in the intercept as in the model with
    > intercept.

    > It would be nice to find examples from the literature
    > where the intercept is removed from the model. 

hopefully *not*!  at least not apart from the exceptions that
Thierry mentions below.

    > Can you think of any?

    > Shadiya

    > Sent from my iPhone

    >> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx
    >> <thierry.onkelinx at inbo.be> wrote:
    >> 
    >> Dear Shadiya,
    >> 
    >> Thou shall always keep the intercept in the model. Its
    >> p-value doesn't matter.
    >> 
    >> I use two exceptions against that rule: 1. There is a
    >> physical/biological/... reason why the intercept should
    >> be 0 2. Removing the intercept gives a different, more
    >> convenient parametrisation (but not does not changes the
    >> model fit!)
    >> 
    >> Note that in logistic regression you use a logit
    >> transformation. Hence forcing the model thru the origin
    >> on the logit scale, forces the model to 50% probability
    >> at the original scale. I haven't seen an example where
    >> that makes sense.
    >> 
    >> Bottom line: only remove the intercept when you really
    >> know what you are doing.
    >> 
    >> Best regards,
    >> 
    >> ir. Thierry Onkelinx Instituut voor natuur- en
    >> bosonderzoek / Research Institute for Nature and Forest
    >> team Biometrie & Kwaliteitszorg / team Biometrics &
    >> Quality Assurance Kliniekstraat 25 1070 Anderlecht
    >> Belgium
    >> 
    >> To call in the statistician after the experiment is done
    >> may be no more than asking him to perform a post-mortem
    >> examination: he may be able to say what the experiment
    >> died of. ~ Sir Ronald Aylmer Fisher The plural of
    >> anecdote is not data. ~ Roger Brinner The combination of
    >> some data and an aching desire for an answer does not
    >> ensure that a reasonable answer can be extracted from a
    >> given body of data. ~ John Tukey
    >> 
    >> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi
    >> <saah500 at york.ac.uk>:
    >>> Good morning,
    >>> 
    >>> I am in a dilemma regarding the inclusion of the
    >>> intercept in my mixed effects logistic regression
    >>> models.  Most statisticians that I talked to insist that
    >>> I shouldn?t remove the constant from my models.  One of
    >>> the pros is that the models would be of good fit since
    >>> the R2 value would be improved. Conversely, removing the
    >>> constant means that there is no guarantee that we would
    >>> end up in getting biased coefficients since the slopes
    >>> would be forced to originate from the 0.
    >>> 
    >>> I found only one textbook which does not state it but
    >>> rather seems to imply that sometimes we can remove the
    >>> constant. This is the reference provided below.
    >>> 
    >>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N.,
    >>> Josse, J., Kloareg, M., LOber, E and Rouvi?re,
    >>> L. (2012). *R for Statistics*: CRC Press. Taylor &
    >>> Francis Group.
    >>> 
    >>> 
    >>> 
    >>> On p.136, it says that ?The p-value of less than 5% for
    >>> the constant (intercept) indicates that the constant
    >>> must appear in the model?.  So based on this, I am
    >>> assuming that a p-value of more than 5% for the
    >>> intercept would mean that the intercept should be
    >>> removed.
    >>> 
    >>> I would appreciate it if someone could help me with this
    >>> conundrum.
    >>> 
    >>> --
    >>> Shadiya


From saah500 at york.ac.uk  Tue Jul 26 12:18:48 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 26 Jul 2016 13:18:48 +0300
Subject: [R-sig-ME] When can the intercept be removed from regression
	models
In-Reply-To: <op.yk7coux2sgx3xe@armadillo50>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
	<F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
	<op.yk7coux2sgx3xe@armadillo50>
Message-ID: <CACrevp=GGSmH4GqqesgkVeMj0sC-edzeoibLsEFRSMzOxhbjcw@mail.gmail.com>

Thanks a lot Paul. Will check it out!

Best,

Shadiya

On 26 July 2016 at 12:59, Paul Debes <paul.debes at utu.fi> wrote:

> Hi Shadiya,
>
> It is discussed in:
> Nelder, J. A. (1994). The statistics of linear models: back to basics.
> Statistics and Computing, 4(4), 221-234. doi: 10.1007/Bf00156745
>
> Best,
> Paul
>
>
> On Tue, 26 Jul 2016 12:40:26 +0300, Shadiya Al Hashmi <saah500 at york.ac.uk>
> wrote:
>
> Thanks Thierry for your response.
>>
>> I tried the model before and after removing the intercept a while ago and
>> I remember that the coefficients were pretty much the same. The only
>> salient difference was that the levels of the first categorical variable in
>> the model formula were all given in the output table instead of the
>> reference level being embedded in the intercept as in the model with
>> intercept.
>>
>> It would be nice to find examples from the literature where the intercept
>> is removed from the model. Can you think of any?
>>
>> Shadiya
>>
>> Sent from my iPhone
>>
>> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>>> wrote:
>>>
>>> Dear Shadiya,
>>>
>>> Thou shall always keep the intercept in the model. Its p-value doesn't
>>> matter.
>>>
>>> I use two exceptions against that rule:
>>> 1. There is a physical/biological/... reason why the intercept should be
>>> 0
>>> 2. Removing the intercept gives a different, more convenient
>>> parametrisation (but not does not changes the model fit!)
>>>
>>> Note that in logistic regression you use a logit transformation. Hence
>>> forcing the model thru the origin on the logit scale, forces the model to
>>> 50% probability at the original scale. I haven't seen an example where that
>>> makes sense.
>>>
>>> Bottom line: only remove the intercept when you really know what you are
>>> doing.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>>>
>>>> Good morning,
>>>>
>>>> I am in a dilemma regarding the inclusion of the intercept in my mixed
>>>> effects logistic regression models.  Most statisticians that I talked to
>>>> insist that I shouldn?t remove the constant from my models.  One of the
>>>> pros is that the models would be of good fit since the R2 value would be
>>>> improved. Conversely, removing the constant means that there is no
>>>> guarantee that we would end up in getting biased coefficients since the
>>>> slopes would be forced to originate from the 0.
>>>>
>>>> I found only one textbook which does not state it but rather seems to
>>>> imply
>>>> that sometimes we can remove the constant. This is the reference
>>>> provided
>>>> below.
>>>>
>>>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N., Josse, J., Kloareg,
>>>> M., LOber, E and Rouvi?re, L. (2012). *R for Statistics*: CRC Press.
>>>> Taylor
>>>> & Francis Group.
>>>>
>>>>
>>>>
>>>> On p.136, it says that ?The p-value of less than 5% for the constant
>>>> (intercept) indicates that the constant must appear in the model?.  So
>>>> based on this, I am assuming that a p-value of more than 5% for the
>>>> intercept would mean that the intercept should be removed.
>>>>
>>>> I would appreciate it if someone could help me with this conundrum.
>>>>
>>>> --
>>>> Shadiya
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Paul V. Debes
> DFG Research Fellow
>
> Division of Genetics and Physiology
> Department of Biology
> University of Turku
> 20014 Finland
>
> Email: paul.debes at utu.fi
>

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Tue Jul 26 12:22:24 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 26 Jul 2016 13:22:24 +0300
Subject: [R-sig-ME] When can the intercept be removed from regression
	models
In-Reply-To: <22423.13954.813534.279148@stat.math.ethz.ch>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
	<F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
	<22423.13954.813534.279148@stat.math.ethz.ch>
Message-ID: <CACrevpkQr_-W2qVzxHNtV-2nUM6f5uETMgcvyBmncDgjPQ-OMA@mail.gmail.com>

Thanks Martin:)

I will update my models with the intercept and that for sure will take some
time.

Best,

Shadiya




On 26 July 2016 at 13:08, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Shadiya Al Hashmi <saah500 at york.ac.uk>
> >>>>>     on Tue, 26 Jul 2016 12:40:26 +0300 writes:
>
>     > Thanks Thierry for your response.  I tried the model
>     > before and after removing the intercept a while ago and I
>     > remember that the coefficients were pretty much the same.
>
> but other things are *not* pretty much the same, and you
> really really really should obey the advice by Thierry:
>
>    ALWAYS KEEP THE INTERCEPT IN THE MODEL !!!
>
> (at least until you become a very experience stastician / data
>  scientist / .. )
>
>
>     >> p-value doesn't matter.
>     >  The only salient difference was that the levels of
>     > the first categorical variable in the model formula were
>     > all given in the output table instead of the reference
>     > level being embedded in the intercept as in the model with
>     > intercept.
>
>     > It would be nice to find examples from the literature
>     > where the intercept is removed from the model.
>
> hopefully *not*!  at least not apart from the exceptions that
> Thierry mentions below.
>
>     > Can you think of any?
>
>     > Shadiya
>
>     > Sent from my iPhone
>
>     >> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx
>     >> <thierry.onkelinx at inbo.be> wrote:
>     >>
>     >> Dear Shadiya,
>     >>
>     >> Thou shall always keep the intercept in the model. Its
>     >> p-value doesn't matter.
>     >>
>     >> I use two exceptions against that rule: 1. There is a
>     >> physical/biological/... reason why the intercept should
>     >> be 0 2. Removing the intercept gives a different, more
>     >> convenient parametrisation (but not does not changes the
>     >> model fit!)
>     >>
>     >> Note that in logistic regression you use a logit
>     >> transformation. Hence forcing the model thru the origin
>     >> on the logit scale, forces the model to 50% probability
>     >> at the original scale. I haven't seen an example where
>     >> that makes sense.
>     >>
>     >> Bottom line: only remove the intercept when you really
>     >> know what you are doing.
>     >>
>     >> Best regards,
>     >>
>     >> ir. Thierry Onkelinx Instituut voor natuur- en
>     >> bosonderzoek / Research Institute for Nature and Forest
>     >> team Biometrie & Kwaliteitszorg / team Biometrics &
>     >> Quality Assurance Kliniekstraat 25 1070 Anderlecht
>     >> Belgium
>     >>
>     >> To call in the statistician after the experiment is done
>     >> may be no more than asking him to perform a post-mortem
>     >> examination: he may be able to say what the experiment
>     >> died of. ~ Sir Ronald Aylmer Fisher The plural of
>     >> anecdote is not data. ~ Roger Brinner The combination of
>     >> some data and an aching desire for an answer does not
>     >> ensure that a reasonable answer can be extracted from a
>     >> given body of data. ~ John Tukey
>     >>
>     >> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi
>     >> <saah500 at york.ac.uk>:
>     >>> Good morning,
>     >>>
>     >>> I am in a dilemma regarding the inclusion of the
>     >>> intercept in my mixed effects logistic regression
>     >>> models.  Most statisticians that I talked to insist that
>     >>> I shouldn?t remove the constant from my models.  One of
>     >>> the pros is that the models would be of good fit since
>     >>> the R2 value would be improved. Conversely, removing the
>     >>> constant means that there is no guarantee that we would
>     >>> end up in getting biased coefficients since the slopes
>     >>> would be forced to originate from the 0.
>     >>>
>     >>> I found only one textbook which does not state it but
>     >>> rather seems to imply that sometimes we can remove the
>     >>> constant. This is the reference provided below.
>     >>>
>     >>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N.,
>     >>> Josse, J., Kloareg, M., LOber, E and Rouvi?re,
>     >>> L. (2012). *R for Statistics*: CRC Press. Taylor &
>     >>> Francis Group.
>     >>>
>     >>>
>     >>>
>     >>> On p.136, it says that ?The p-value of less than 5% for
>     >>> the constant (intercept) indicates that the constant
>     >>> must appear in the model?.  So based on this, I am
>     >>> assuming that a p-value of more than 5% for the
>     >>> intercept would mean that the intercept should be
>     >>> removed.
>     >>>
>     >>> I would appreciate it if someone could help me with this
>     >>> conundrum.
>     >>>
>     >>> --
>     >>> Shadiya
>
>


-- 
Shadiya al-Hashmi

PhD candidate
Department of Language & Linguistic Science
University of York, Heslington, York YO10 5DD
email: saah500 at york.ac.uk

	[[alternative HTML version deleted]]


From shebrahimi_3622 at yahoo.com  Tue Jul 26 12:27:54 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Tue, 26 Jul 2016 10:27:54 +0000 (UTC)
Subject: [R-sig-ME] cross validation on discrete time survival analysis
In-Reply-To: <1856196443.1538289.1468908444286.JavaMail.yahoo@mail.yahoo.com>
References: <2082726117.1626150.1468323505133.JavaMail.yahoo.ref@mail.yahoo.com>
	<2082726117.1626150.1468323505133.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTTT=JEiJsZCAwKUC-tgQm8x=uQ37fp_Aojf49nGOO9qJg@mail.gmail.com>
	<398951196.1820955.1468332795112.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTRNUjJ6YjXHExhSow-3edciyoK+=R=NhZg77ET8ssL6LQ@mail.gmail.com>
	<888544502.3206200.1468512834710.JavaMail.yahoo@mail.yahoo.com>
	<475069987.3339139.1468523368368.JavaMail.yahoo@mail.yahoo.com>
	<590508458.3680687.1468550627850.JavaMail.yahoo@mail.yahoo.com>
	<1041593015.3668892.1468551465655.JavaMail.yahoo@mail.yahoo.com>
	<404681957.3563921.1468552844309.JavaMail.yahoo@mail.yahoo.com>
	<1072898021.3609015.1468559774467.JavaMail.yahoo@mail.yahoo.com>
	<1295208167.3620691.1468560399025.JavaMail.yahoo@mail.yahoo.com>
	<1742164238.3652376.1468577707758.JavaMail.yahoo@mail.yahoo.com>
	<1664168494.3988717.1468600842928.JavaMail.yahoo@mail.yahoo.com>
	<18389920.95090.1468638905767.JavaMail.yahoo@mail.yahoo.com>
	<1469054561.84641.1468641025575.JavaMail.yahoo@mail.yahoo.com>
	<1856196443.1538289.1468908444286.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <418996742.5797549.1469528874696.JavaMail.yahoo@mail.yahoo.com>

Dear Dr.


Greetings
I would be very grateful if you could let me know how to do cross validation when estimating a discrete time survival analysis in R.
ID TIME EVENT  x1       x2    x3      x4       x5
1   1   0   1.281   0.023   0.875   1.216   0.061
1   2   0   1.270   0.006   0.821   1.005   -0.014
1   3   0   1.053   -0.059  0.922   0.729   0.020
1   4   0   1.113   -0.015  0.859   0.810   0.076
1   5   1   1.220   -0.059  0.887   0.484   0.010
2   1   0   1.062   0.107   0.815   0.836   0.200
2   2   0   1.056   0.082   0.879   0.687   0.143
2   3   0   0.971   0.076   0.907   0.810   0.166
2   4   0   1.059   0.130   0.818   0.876   0.234
2   5   0   1.125   0.148   0.759   1.080   0.276
2   6   0   1.600   0.262   0.546   1.313   0.369
2   7   0   1.576   0.262   0.564   1.156   0.349
2   8   0   1.544   0.241   0.591   1.077   0.326
2   9   0   1.722   0.215   0.552   0.841   0.293
2   10  0   1.723   0.209   0.534   0.787   0.293
2   11  0   1.631   0.186   0.548   0.728   0.274
2   12  0   2.172   0.319   0.441   0.947   0.427
3   1   0   0.874   -0.035  0.794   0.610   -0.003
3   2   1   0.825   -0.142  0.952   0.573   -0.019
 require(lme4) model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial) p <- as.numeric(predict(model, type="response")>0.5) acc=mean(p==df$EVENT)
Is it right to do this:

accuracy = function(pred, test_data){
num.correct.negatives = sum((pred == test_data$EVENT) & (test_data$EVENT==0))
num.correct.positives = sum((p == test_data$EVENT) & (test_data$EVENT==1))
num.false.negatives = sum((pred != test_data$EVENT) & (test_data$EVENT==1))
num.false.positives = sum((pred != test_data$EVENT) & (test_data$EVENT==0))

ppv = num.correct.positives / (num.false.positives + num.correct.positives)
npv = num.correct.negatives / (num.false.negatives + num.correct.negatives)
return(list(ppv = ppv, npv = npv))
}
df = read.table(file='clipboard', header=T)
idx_train =  sapply(unique(df$ID), function(x){
   sample(which(df$ID %in% x), 1)
  }
)

#if you wish to sample based only on time. Note that k=5 here.
#idx_train = which(df$TIME %in% sample(unique(df$TIME), 5))
df_train = df[idx_train, ]
df_test = df[-idx_train,]

#perform training on training dataset
require(lme4)
model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df_train, family=binomial)
p <- as.numeric(predict(model, newdata = df_test, type="response")>0.5)

#cross validate
accuracy(p, df_test)

Thanks in advance.Best regards,   
   
	[[alternative HTML version deleted]]


From tom.fritzsche at uni-potsdam.de  Tue Jul 26 12:31:12 2016
From: tom.fritzsche at uni-potsdam.de (Tom Fritzsche)
Date: Tue, 26 Jul 2016 12:31:12 +0200
Subject: [R-sig-ME] When can the intercept be removed from regression
	models
In-Reply-To: <22423.13954.813534.279148@stat.math.ethz.ch>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
	<F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
	<22423.13954.813534.279148@stat.math.ethz.ch>
Message-ID: <CAGLQsKfa7PkkxmdwRNkVQ2iL8ag_KF+JUCoWzF_BwA7K2LGSKQ@mail.gmail.com>

Hi,

since all the stats experts are on this list, I have to ask a question
in relation to models without intercept.

In my layman's conception in a model without intercept like this one:

glmer(response ~ 0 + condition + (1 | study_participant ) + (1 |
test_item), data=data_frame, family=binomial,
control=glmerControl(optimizer="bobyqa"))

the levels of the predictor condition are not estimated in relation to
the intercept but against zero absolute. With binomial data this seems
quite handy as for each condition level the model tells me whether
performance was significantly different from chance (like multiple
intercepts), something a binomial test could do as well (albeit
without accounting for the random components structure).
This can be (and in psycholinguistic research often is) a research question.

Or is this total nonsense?

I have to say that I am confused when int comes to the intercepts in
the random components ....

Tom

---

Tom Fritzsche
University of Potsdam
Department of Linguistics
Karl-Liebknecht-Stra?e 24-25
14476 Potsdam
Germany

office: 14.140
phone: +49 331 977 2296
fax: +49 331 977 2095
e-mail: tom.fritzsche at uni-potsdam.de
web:    www.ling.uni-potsdam.de/~fritzsche




2016-07-26 12:08 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>>>>>> Shadiya Al Hashmi <saah500 at york.ac.uk>
>>>>>>     on Tue, 26 Jul 2016 12:40:26 +0300 writes:
>
>     > Thanks Thierry for your response.  I tried the model
>     > before and after removing the intercept a while ago and I
>     > remember that the coefficients were pretty much the same.
>
> but other things are *not* pretty much the same, and you
> really really really should obey the advice by Thierry:
>
>    ALWAYS KEEP THE INTERCEPT IN THE MODEL !!!
>
> (at least until you become a very experience stastician / data
>  scientist / .. )
>
>
>     >> p-value doesn't matter.
>     >  The only salient difference was that the levels of
>     > the first categorical variable in the model formula were
>     > all given in the output table instead of the reference
>     > level being embedded in the intercept as in the model with
>     > intercept.
>
>     > It would be nice to find examples from the literature
>     > where the intercept is removed from the model.
>
> hopefully *not*!  at least not apart from the exceptions that
> Thierry mentions below.
>
>     > Can you think of any?
>
>     > Shadiya
>
>     > Sent from my iPhone
>
>     >> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx
>     >> <thierry.onkelinx at inbo.be> wrote:
>     >>
>     >> Dear Shadiya,
>     >>
>     >> Thou shall always keep the intercept in the model. Its
>     >> p-value doesn't matter.
>     >>
>     >> I use two exceptions against that rule: 1. There is a
>     >> physical/biological/... reason why the intercept should
>     >> be 0 2. Removing the intercept gives a different, more
>     >> convenient parametrisation (but not does not changes the
>     >> model fit!)
>     >>
>     >> Note that in logistic regression you use a logit
>     >> transformation. Hence forcing the model thru the origin
>     >> on the logit scale, forces the model to 50% probability
>     >> at the original scale. I haven't seen an example where
>     >> that makes sense.
>     >>
>     >> Bottom line: only remove the intercept when you really
>     >> know what you are doing.
>     >>
>     >> Best regards,
>     >>
>     >> ir. Thierry Onkelinx Instituut voor natuur- en
>     >> bosonderzoek / Research Institute for Nature and Forest
>     >> team Biometrie & Kwaliteitszorg / team Biometrics &
>     >> Quality Assurance Kliniekstraat 25 1070 Anderlecht
>     >> Belgium
>     >>
>     >> To call in the statistician after the experiment is done
>     >> may be no more than asking him to perform a post-mortem
>     >> examination: he may be able to say what the experiment
>     >> died of. ~ Sir Ronald Aylmer Fisher The plural of
>     >> anecdote is not data. ~ Roger Brinner The combination of
>     >> some data and an aching desire for an answer does not
>     >> ensure that a reasonable answer can be extracted from a
>     >> given body of data. ~ John Tukey
>     >>
>     >> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi
>     >> <saah500 at york.ac.uk>:
>     >>> Good morning,
>     >>>
>     >>> I am in a dilemma regarding the inclusion of the
>     >>> intercept in my mixed effects logistic regression
>     >>> models.  Most statisticians that I talked to insist that
>     >>> I shouldn?t remove the constant from my models.  One of
>     >>> the pros is that the models would be of good fit since
>     >>> the R2 value would be improved. Conversely, removing the
>     >>> constant means that there is no guarantee that we would
>     >>> end up in getting biased coefficients since the slopes
>     >>> would be forced to originate from the 0.
>     >>>
>     >>> I found only one textbook which does not state it but
>     >>> rather seems to imply that sometimes we can remove the
>     >>> constant. This is the reference provided below.
>     >>>
>     >>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N.,
>     >>> Josse, J., Kloareg, M., LOber, E and Rouvi?re,
>     >>> L. (2012). *R for Statistics*: CRC Press. Taylor &
>     >>> Francis Group.
>     >>>
>     >>>
>     >>>
>     >>> On p.136, it says that ?The p-value of less than 5% for
>     >>> the constant (intercept) indicates that the constant
>     >>> must appear in the model?.  So based on this, I am
>     >>> assuming that a p-value of more than 5% for the
>     >>> intercept would mean that the intercept should be
>     >>> removed.
>     >>>
>     >>> I would appreciate it if someone could help me with this
>     >>> conundrum.
>     >>>
>     >>> --
>     >>> Shadiya
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Jul 26 15:12:59 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Jul 2016 09:12:59 -0400
Subject: [R-sig-ME] When can the intercept be removed from regression
 models
In-Reply-To: <CAGLQsKfa7PkkxmdwRNkVQ2iL8ag_KF+JUCoWzF_BwA7K2LGSKQ@mail.gmail.com>
References: <CACrevpmO53dPWJghdxDR6eXErx_Dpm3xorvFJ7LQ8QGavJcq9Q@mail.gmail.com>
	<CAJuCY5yYKCuMcqo8Mox00zi5JKOrf8AYfTXE2L-LQ2qds2LwMg@mail.gmail.com>
	<F6F370E5-5B16-4D37-8631-EFCBE9B59981@york.ac.uk>
	<22423.13954.813534.279148@stat.math.ethz.ch>
	<CAGLQsKfa7PkkxmdwRNkVQ2iL8ag_KF+JUCoWzF_BwA7K2LGSKQ@mail.gmail.com>
Message-ID: <451b61fa-b00b-1ed6-b7ba-7edac04f4dce@gmail.com>


  Comments below.

On 16-07-26 06:31 AM, Tom Fritzsche wrote:
> Hi,
> 
> since all the stats experts are on this list, I have to ask a question
> in relation to models without intercept.
> 
> In my layman's conception in a model without intercept like this one:
> 
> glmer(response ~ 0 + condition + (1 | study_participant ) + (1 |
> test_item), data=data_frame, family=binomial,
> control=glmerControl(optimizer="bobyqa"))
> 
> the levels of the predictor condition are not estimated in relation to
> the intercept but against zero absolute. With binomial data this seems
> quite handy as for each condition level the model tells me whether
> performance was significantly different from chance (like multiple
> intercepts), something a binomial test could do as well (albeit
> without accounting for the random components structure).
> This can be (and in psycholinguistic research often is) a research question.

  In this case (where the model has a categorical variable as a main
effect), you're right that the overall model fit is identical whether we
use 0+condition or 1+condition; the model is just differently
parameterized.  I think that in general computing these individual
effects *after* model-fitting, e.g. via the effects or lsmeans package,
is more sensible.  Also keep in mind that if you're comparing lots of
individual levels to zero (1) you might want to take multiple
comparisons into account (see multcomp package), (2) don't fall in the
trap of saying that two levels are different because one is
significantly different from zero and the other isn't.

> 
> Or is this total nonsense?
> 
> I have to say that I am confused when int comes to the intercepts in
> the random components ....
> 
> Tom
> 
> ---
> 
> Tom Fritzsche
> University of Potsdam
> Department of Linguistics
> Karl-Liebknecht-Stra?e 24-25
> 14476 Potsdam
> Germany
> 
> office: 14.140
> phone: +49 331 977 2296
> fax: +49 331 977 2095
> e-mail: tom.fritzsche at uni-potsdam.de
> web:    www.ling.uni-potsdam.de/~fritzsche
> 
> 
> 
> 
> 2016-07-26 12:08 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>>>>>>> Shadiya Al Hashmi <saah500 at york.ac.uk>
>>>>>>>     on Tue, 26 Jul 2016 12:40:26 +0300 writes:
>>
>>     > Thanks Thierry for your response.  I tried the model
>>     > before and after removing the intercept a while ago and I
>>     > remember that the coefficients were pretty much the same.
>>
>> but other things are *not* pretty much the same, and you
>> really really really should obey the advice by Thierry:
>>
>>    ALWAYS KEEP THE INTERCEPT IN THE MODEL !!!
>>
>> (at least until you become a very experience stastician / data
>>  scientist / .. )
>>
>>
>>     >> p-value doesn't matter.
>>     >  The only salient difference was that the levels of
>>     > the first categorical variable in the model formula were
>>     > all given in the output table instead of the reference
>>     > level being embedded in the intercept as in the model with
>>     > intercept.
>>
>>     > It would be nice to find examples from the literature
>>     > where the intercept is removed from the model.
>>
>> hopefully *not*!  at least not apart from the exceptions that
>> Thierry mentions below.
>>
>>     > Can you think of any?
>>
>>     > Shadiya
>>
>>     > Sent from my iPhone
>>
>>     >> On Jul 26, 2016, at 11:32 AM, Thierry Onkelinx
>>     >> <thierry.onkelinx at inbo.be> wrote:
>>     >>
>>     >> Dear Shadiya,
>>     >>
>>     >> Thou shall always keep the intercept in the model. Its
>>     >> p-value doesn't matter.
>>     >>
>>     >> I use two exceptions against that rule: 1. There is a
>>     >> physical/biological/... reason why the intercept should
>>     >> be 0 2. Removing the intercept gives a different, more
>>     >> convenient parametrisation (but not does not changes the
>>     >> model fit!)
>>     >>
>>     >> Note that in logistic regression you use a logit
>>     >> transformation. Hence forcing the model thru the origin
>>     >> on the logit scale, forces the model to 50% probability
>>     >> at the original scale. I haven't seen an example where
>>     >> that makes sense.
>>     >>
>>     >> Bottom line: only remove the intercept when you really
>>     >> know what you are doing.
>>     >>
>>     >> Best regards,
>>     >>
>>     >> ir. Thierry Onkelinx Instituut voor natuur- en
>>     >> bosonderzoek / Research Institute for Nature and Forest
>>     >> team Biometrie & Kwaliteitszorg / team Biometrics &
>>     >> Quality Assurance Kliniekstraat 25 1070 Anderlecht
>>     >> Belgium
>>     >>
>>     >> To call in the statistician after the experiment is done
>>     >> may be no more than asking him to perform a post-mortem
>>     >> examination: he may be able to say what the experiment
>>     >> died of. ~ Sir Ronald Aylmer Fisher The plural of
>>     >> anecdote is not data. ~ Roger Brinner The combination of
>>     >> some data and an aching desire for an answer does not
>>     >> ensure that a reasonable answer can be extracted from a
>>     >> given body of data. ~ John Tukey
>>     >>
>>     >> 2016-07-26 9:50 GMT+02:00 Shadiya Al Hashmi
>>     >> <saah500 at york.ac.uk>:
>>     >>> Good morning,
>>     >>>
>>     >>> I am in a dilemma regarding the inclusion of the
>>     >>> intercept in my mixed effects logistic regression
>>     >>> models.  Most statisticians that I talked to insist that
>>     >>> I shouldn?t remove the constant from my models.  One of
>>     >>> the pros is that the models would be of good fit since
>>     >>> the R2 value would be improved. Conversely, removing the
>>     >>> constant means that there is no guarantee that we would
>>     >>> end up in getting biased coefficients since the slopes
>>     >>> would be forced to originate from the 0.
>>     >>>
>>     >>> I found only one textbook which does not state it but
>>     >>> rather seems to imply that sometimes we can remove the
>>     >>> constant. This is the reference provided below.
>>     >>>
>>     >>> Cornillon, P.A., Guyader, A., Husson, F., J?gou, N.,
>>     >>> Josse, J., Kloareg, M., LOber, E and Rouvi?re,
>>     >>> L. (2012). *R for Statistics*: CRC Press. Taylor &
>>     >>> Francis Group.
>>     >>>
>>     >>>
>>     >>>
>>     >>> On p.136, it says that ?The p-value of less than 5% for
>>     >>> the constant (intercept) indicates that the constant
>>     >>> must appear in the model?.  So based on this, I am
>>     >>> assuming that a p-value of more than 5% for the
>>     >>> intercept would mean that the intercept should be
>>     >>> removed.
>>     >>>
>>     >>> I would appreciate it if someone could help me with this
>>     >>> conundrum.
>>     >>>
>>     >>> --
>>     >>> Shadiya
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From simonakf at gmail.com  Tue Jul 26 16:53:05 2016
From: simonakf at gmail.com (Simona Kralj Fiser)
Date: Tue, 26 Jul 2016 16:53:05 +0200
Subject: [R-sig-ME] individual variation in reaction norm
Message-ID: <CAPkBqkn1QiRH+aZr3Qi=kUMEFuiXi4c_u39oJn95o9MESoxq6A@mail.gmail.com>

I wanted to analyse individual variance in reaction norm for activity in a
novel environment test. I measured ACTIVITY in trial 1 and then again on
the same individuals (ID) on trial2 (=trialN). I used below scripts and
compared their DICs. However, I am not even sure what is the difference
between models, and which tells me the variance in the reaction norm? In
one case DIC is even negative. I guess that's bad?Any hints?



E.g.



prior.1<-list(R=list(V=1, nu=0.002),G=list(G1=list(V=1, nu=0.002)))

*ma2rs<- MCMCglmm(ACTIVITY~ trialN, random=~idh(trialN):ID, data = F,
family="gaussian", prior = prior.1, nitt=530000,thin=5000,burnin=30000,
verbose = FALSE)*



summary(ma2rs)

Iterations = 30001:525001

 Thinning interval  = 5000

 Sample size  = 100



 DIC:
*84.24017 *



 G-structure:  ~us(trialN):ID



                   post.mean l-95% CI u-95% CI eff.samp

trialN:trialN.ID   0.02541 0.008237  0.04164      100



 R-structure:  ~units



      post.mean l-95% CI u-95% CI eff.samp

units    0.0862  0.06513   0.1306      100



 Location effects: ACTIVITY ~ trialN



            post.mean l-95% CI u-95% CI eff.samp pMCMC

(Intercept)   1.31808  1.16730  1.48222      100 <0.01 **

trialN       0.11417  0.01064  0.21595      100  0.02 *

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



> posterior.mode(ma1rs$VCV)

trialN:trialN.ID              units

        0.02282208         0.08220128

> HPDinterval(ma1rs$VCV)

                         lower      upper

trialN:trialN.ID 0.008236589 0.04163621

units              0.065134787 0.13057164

attr(,"Probability")

[1] 0.95



*ma3rs<- MCMCglmm(ACTIVITY ~ trialN, random=~ID, data = F,
family="gaussian", prior = prior.1, nitt=530000,thin=5000,burnin=30000,
verbose = FALSE)*

summary(ma3rs)

Iterations = 30001:525001

 Thinning interval  = 5000

 Sample size  = 100



 DIC: *55.74573*



 G-structure:  ~ID



   post.mean l-95% CI u-95% CI eff.samp

ID   0.09563  0.03688   0.1353      100



 R-structure:  ~units



      post.mean l-95% CI u-95% CI eff.samp

units   0.06223  0.04318  0.08476    133.3



 Location effects: ACTIVITY ~ trialN



            post.mean l-95% CI u-95% CI eff.samp pMCMC

(Intercept)    1.3194   1.2170   1.4839      100 <0.01 **

trialN        0.1110   0.0329   0.1783      100  0.02 *

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> posterior.mode(ma3rs$VCV)

        ID      units

0.10238123 0.05860673

> HPDinterval(ma3rs$VCV)

           lower      upper

ID    0.03688181 0.13526359

units 0.04318352 0.08476018

attr(,"Probability")

[1] 0.95



*ma4rs<- MCMCglmm(ACTIVITY ~ trialN, random=~trialN:ID, data = F,
family="gaussian", prior = prior.1, nitt=530000,thin=5000,burnin=30000,
verbose = FALSE)*

summary(ma4rs)

Iterations = 30001:525001

 Thinning interval  = 5000

 Sample size  = 100



* DIC: -76.73263 *



 G-structure:  ~trialN:ID



           post.mean  l-95% CI u-95% CI eff.samp

trialN:ID     0.073 0.0004997   0.1634      100



 R-structure:  ~units



      post.mean  l-95% CI u-95% CI eff.samp

units   0.08064 0.0006196    0.174      100



 Location effects: ACTIVITY ~ trialN



            post.mean l-95% CI u-95% CI eff.samp pMCMC

(Intercept)   1.31570  1.11754  1.53055      100 <0.01 **

trialN       0.10979 -0.01834  0.25725      100  0.12

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> posterior.mode(ma4rs$VCV)

 trialN:ID       units

0.002223456 0.003016048

> HPDinterval(ma4rs$VCV)

                  lower     upper

trialN:ID 0.0004997280 0.1633640

units      0.0006195642 0.1739676

attr(,"Probability")

[1] 0.95


-- 
Thanks.
S

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Wed Jul 27 12:29:45 2016
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 27 Jul 2016 10:29:45 +0000
Subject: [R-sig-ME] Function to get residuals & fitted values from Poisson
 GLMM with OLRE
Message-ID: <DE2F10C5-273D-42EB-9999-656BCF7E64B2@glasgow.ac.uk>

Hi all,

I?ve written a function which some might find useful. It outputs ?corrected? Pearson residuals from a glmer fit of the form

   fit <- glmer(y ~ . + (1 | obs), family = ?poisson?)

where "(1 | obs)? fits an observation level random effect (OLRE), i.e. length(obs) == length(y).*

The function is called residfitted.olre and can be found here: 
https://github.com/pcdjohnson/miscR

The default behaviour of residuals(fit) and fitted(fit) is to treat the OLRE as part of the fitted values, but for most practical purposes I want the OLRE to be in the residuals and not in the fitted values. In particular, if I?m using a residuals-vs-fitted-values plot to assess the fit, the default residuals and fitted functions used by plot(fit) will generally produce nasty-looking plots showing a trend and severe heteroscedasticity even from well fitting models. The ?corrected? residuals fix this problem.

There?s also example code below the function showing how this it allows interpretable residuals-vs-fitted plots to be produced from a Poisson GLMM with an OLRE (aka a Poisson-lognormal GLMM).

The same problem affects a binomial GLMM with an OLRE, but I haven?t (yet) made the function work for binomial GLMMs for the reason covered in this post:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q1/021818.html
(basically I don?t know what the variance function is for a mixture of binomial + logit-normal ? anyone know?).

Hope someone finds it useful,
Paul

*Refs:
https://peerj.com/articles/616/
http://www.ncbi.nlm.nih.gov/pubmed/11393830


From talischen at hotmail.com  Wed Jul 27 22:44:31 2016
From: talischen at hotmail.com (Chen Chun)
Date: Wed, 27 Jul 2016 20:44:31 +0000
Subject: [R-sig-ME] How can a mixed model differentiate the fixed effect and
 random effect when there is only one group of control in the data?
Message-ID: <HE1PR01MB0987A9D120D0DFF74DC2AE0CAC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>

Dear all,


I have a data set where experiments were conducted in groups of animals and each group was assigned to one treatment (treatment vs. control). In my data, unfortunately I have only one control group, so the model would be:

lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)


I am wondering whether in this case the mixed model would still be able to provide unbiased estimate of the fixed effect and random group effect for the control group. I have written a simulation code for 5 treatment groups vs. 1 control group (see below). Seems that the linear mixed model is still able to provide unbiased estimate. Can someone give me more insight about why lmer could identify the fixed and random effect when there is only one group from one treatment arm?


Thanks


Chun Chen


library(lme4)
set.seed(320)
N_group <- 6
N_per_group <- 20
NO_con_group <-1
beta_t <- 3
beta_c <- 0
intercept <- 2

res <- matrix(NA, nrow=1000, ncol=2)
for(k in 1:1000) {
    random_error1 <- rnorm(N_per_group*(N_group-NO_con_group), mean = 0, sd = 1)
    random_error2 <- rnorm(N_per_group*NO_con_group, mean = 0, sd = 1)
    group_error <- rnorm(N_group, mean = 0, sd = 5)

    yt <- intercept + beta_t + rep(group_error[1:(N_group-NO_con_group)], each=N_per_group) + random_error1
    y_c <- intercept + beta_c + rep(group_error[(N_group-NO_con_group+1):N_group], each=N_per_group) + random_error2
    y <- c(yt, y_c)

    dat <- data.frame(out=y, treatment=c(rep("treat", N_per_group*(N_group-NO_con_group)), rep("con",N_per_group*NO_con_group)), group=rep(letters[1:N_group], each=N_per_group))

    fit <- lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)
    summary(fit)
    res[k,1] <- fixef(fit)[1]
    res[k,2] <- fixef(fit)[2]
}

colMeans(res)  ##---similar to intercept  and beta_t


	[[alternative HTML version deleted]]


From talischen at hotmail.com  Wed Jul 27 22:48:01 2016
From: talischen at hotmail.com (Chen Chun)
Date: Wed, 27 Jul 2016 20:48:01 +0000
Subject: [R-sig-ME] simulation of factor-specific random effect variance
 estimation, the order of assigned variance matters?
Message-ID: <HE1PR01MB0987934FF6046773E8C7B318AC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>

Dear all,

I have a nested data structure and I would like to estimate factor-specific random effect variance. Inspired by the article:

http://rstudio-pubs-static.s3.amazonaws.com/6B98_c0ae95A0AAA44A3Aa8a9b6ba9703fcf5.html<http://rstudio-pubs-static.s3.amazonaws.com/6298_c0ae951011144131a8a9b6ba9703fcf5.html>

I conducted some simulations:

###############
##--generate data-----
ngroup <- 25
nrep<- 5
##----random effect of group---
meanh <- 0
sigmahA <- 1   ##--these are the two assigned variance of the random factor group for each class (A, B)
sigmahB <- 3

##----residual random error---
meanR <- 0
sigmaR <- 0.2

##---simulate smaple--------------------------------------------------
set.seed(55)
out_A   <- NA
out_B   <- NA
raneff_groupA <- rnorm(ngroup, meanh, sigmahA)
raneff_groupB <- rnorm(ngroup, meanh, sigmahB)
groupID      <- seq(1, ngroup)
for (i in 1:ngroup) {
    raneff_red_A <- rnorm(nrep, meanR, sigmaR)
    temp_A       <- 0 + raneff_groupA[i] + raneff_red_A
    raneff_red_B   <- rnorm(nrep, meanR, sigmaR)
    temp_B   <- 1 + raneff_groupB[i] + raneff_red_B
    out_A <- rbind(out_A, cbind(groupID[i], raneff_groupA[i], raneff_red_A, temp_A))
    out_B   <- rbind(out_B, cbind(groupID[i], raneff_groupB[i], raneff_red_B, temp_B))
}
out_A <- out_A[-1,]
out_B   <- out_B[-1,]

dat <- data.frame(groupID=c(out_A[,1], out_B[,1]), prog=c(rep("A",nrow(out_A)), rep("B",nrow(out_B))), out=c(out_A[,"temp_A"], out_B[,"temp_B"]), raneff_haul=c(out_A[,2], out_B[,2]), error=c(out_A[,3], out_B[,3]))

library(lattice)
bwplot(out~paste(prog,groupID), data=dat)

##--apply model-----
fit2 <- lme(out ~ prog-1, random = list(groupID = pdDiag(~prog)), method = "REML", data = dat)
summary(fit2)

This code gives the expected model output: as estimated variance of groups for A and B are:  1.07957 2.835139, similar to assigned value
###############
###############
Model output:
Linear mixed-effects model fit by REML
Data: dat
       AIC      BIC    logLik
  202.7263 220.2934 -96.36314

Random effects:
Formula: ~prog | groupID
Structure: Diagonal
        (Intercept)    progB  Residual
StdDev:     1.07957 2.835139 0.1959905

Fixed effects: out ~ prog - 1
          Value Std.Error  DF   t-value p-value
progA 0.0316535 0.2166244 224 0.1461215  0.8840
progB 1.1446339 0.6069982 224 1.8857287  0.0606
Correlation:
      progA
progB 0.355

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.29868033 -0.63163428  0.03981236  0.64863494  2.63613133

Number of Observations: 250
Number of Groups: 25
#########################



However, it I dont make any other changes, but simply to switch the order of the simulation variance:

sigmahA <- 3
sigmahB <- 1

, generate the data and apply the model, the model gives very confusing result:
###############
###############
Model output:
Linear mixed-effects model fit by REML
Data: dat
      AIC      BIC    logLik
  261.763 279.3301 -125.8815

Random effects:
Formula: ~prog | groupID
Structure: Diagonal
        (Intercept)    progB  Residual
StdDev:    3.187986 3.295383 0.1959864

Fixed effects: out ~ prog - 1
          Value Std.Error  DF   t-value p-value
progA 0.1455012 0.6378382 224 0.2281162  0.8198
progB 1.0590270 0.9171802 224 1.1546553  0.2495
Correlation:
      progA
progB 0.695

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.30847626 -0.63592816  0.03830767  0.64349268  2.63737406

Number of Observations: 250
Number of Groups: 25
#########################



The model output gives equal variance. The same situation happens if I run the same code in the article (link above) and also simply change the order of the variance assigned to the groups.

Can someone help me to figure out why the order of assigning the variance matters? And why the second case does not gives the expected results?

Thanks

Regards,
Chun Chen


	[[alternative HTML version deleted]]


From ajmackey at gmail.com  Wed Jul 27 23:07:08 2016
From: ajmackey at gmail.com (Aaron Mackey)
Date: Wed, 27 Jul 2016 17:07:08 -0400
Subject: [R-sig-ME] How can a mixed model differentiate the fixed effect
 and random effect when there is only one group of control in the data?
In-Reply-To: <HE1PR01MB0987A9D120D0DFF74DC2AE0CAC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB0987A9D120D0DFF74DC2AE0CAC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>
Message-ID: <CAErFSoie102d0zwosgfcOhH9=S3mSuDqZorVHoaRiWD7wjGT0Q@mail.gmail.com>

because the random effect in your model is independent of the fixed effect,
the mixed model has six groups from which to estimate the variance of the
random effect. If you had asked for the random effect group variances to be
different between treatments  ~ (1|treatment:group) then you'd be in
trouble.

hope that helps,
-Aaron

On Wed, Jul 27, 2016 at 4:44 PM, Chen Chun <talischen at hotmail.com> wrote:

> Dear all,
>
>
> I have a data set where experiments were conducted in groups of animals
> and each group was assigned to one treatment (treatment vs. control). In my
> data, unfortunately I have only one control group, so the model would be:
>
> lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)
>
>
> I am wondering whether in this case the mixed model would still be able to
> provide unbiased estimate of the fixed effect and random group effect for
> the control group. I have written a simulation code for 5 treatment groups
> vs. 1 control group (see below). Seems that the linear mixed model is still
> able to provide unbiased estimate. Can someone give me more insight about
> why lmer could identify the fixed and random effect when there is only one
> group from one treatment arm?
>
>
> Thanks
>
>
> Chun Chen
>
>
> library(lme4)
> set.seed(320)
> N_group <- 6
> N_per_group <- 20
> NO_con_group <-1
> beta_t <- 3
> beta_c <- 0
> intercept <- 2
>
> res <- matrix(NA, nrow=1000, ncol=2)
> for(k in 1:1000) {
>     random_error1 <- rnorm(N_per_group*(N_group-NO_con_group), mean = 0,
> sd = 1)
>     random_error2 <- rnorm(N_per_group*NO_con_group, mean = 0, sd = 1)
>     group_error <- rnorm(N_group, mean = 0, sd = 5)
>
>     yt <- intercept + beta_t + rep(group_error[1:(N_group-NO_con_group)],
> each=N_per_group) + random_error1
>     y_c <- intercept + beta_c +
> rep(group_error[(N_group-NO_con_group+1):N_group], each=N_per_group) +
> random_error2
>     y <- c(yt, y_c)
>
>     dat <- data.frame(out=y, treatment=c(rep("treat",
> N_per_group*(N_group-NO_con_group)), rep("con",N_per_group*NO_con_group)),
> group=rep(letters[1:N_group], each=N_per_group))
>
>     fit <- lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)
>     summary(fit)
>     res[k,1] <- fixef(fit)[1]
>     res[k,2] <- fixef(fit)[2]
> }
>
> colMeans(res)  ##---similar to intercept  and beta_t
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tguy at ufl.edu  Thu Jul 28 04:03:41 2016
From: tguy at ufl.edu (Guy,Travis J)
Date: Thu, 28 Jul 2016 02:03:41 +0000
Subject: [R-sig-ME] model advice
Message-ID: <1469671421430.15990@ufl.edu>

Hello!

I'm a master's student studying pollination networks. I have been furiously trying to learn about linear mixed models and glmms, but I have some specific questions relating to my project analysis that I am hoping someone can help me with


Here's the short of my project. I can provide more details if need be. I am looking at 16 pollination metrics (ex. specialization). A few of the metrics are count data (ex. floral abundance) and several are proportions (limited to be between 0 and 1). I am interested in how rainfall (high and low location) and wildlife exclusion (treatment) affect the pollination metrics. I have constructed 12 networks in total. 6 networks in the low rainfall area having 3 networks with wildlife excluded and 3 networks allowing wildlife. Then there are 6 networks in the high rainfall area again have 3 networks with wildlife excluded and 3 with wildlife included. So sample size is obviously small. It's a block design with 3 blocks in the low rainfall and 3 blocks in the south location. Each block has the wildlife excluded treatment and the wildlife allowed treatment.

Here are my questions:

The majority of my metrics fit model assumptions (normality of residuals, variance within groups, normality within groups, normality of random effects, and linearity/absence of heteroskedasticity). However I have some where normality appear to be violated and the fitted vs residuals plot is no good. Various transformations (log, ln, sqrt,arcsin(sqrt)) don't seem to help.  >From reading papers by Dr. Ben Bolker, this is where it appears GLMMs come in.

So for the metrics that fit model assumptions my plan is to fit this model

    metric.model <- lmer(metric ~ Treatment + Location + (1 |Blocks), data = UHURUnets)?

but for those where model assumptions aren't met, I'm not sure how one picks which exponential family to use and which link to use. How does one go about deciding what family and link to use?

I read in Dr. Bolker's TREE paper that binomial distribution and logit link are best for proportions. Is this generally the case?

NODF.M1 <- glmer(weighted_NODF ~ Treatment + Location + (1|Blocks), data = UHURUnets, family = binomial(link = "logit")?

For the count data (ex. floral abundance, insect abundance), it seems like I should use Poisson and log link according to that same paper paper.

No.Fl.units.M1 <- glmer(number_of_floral_units ~ Treatment + Location + (1|Blocks), data = UHURUnets, family = poisson(link = "log")?

But what distribution and link would one use for continuous data that is not in proportions?

And once you have made a GLMM model, I am assuming it is okay that this model still does not fit the normality assumptions or the residual vs fitted plots. Is this true?

My models (both glmms and lmer) currently only have random intercepts. I have read that it might be wise to also have random slopes as well because the pollination metric could vary for each treatment and location depending on which block it is in.

So then I believe I would have a model like this
?
Vuln.LL.M3 <- glmer(vulnerability.LL ~ Treatment + Location + (1 + Treatment|Blocks) + (1 + Location|Blocks), family = gaussian(link = log), data = UHURUnets)

I am not sure if this is correct. I get 2 warnings (failed to converge and unable to evaluated scaled gradient). Interestingly I appear to not get these warnings if I am running linear mixed models (lmer). Am I doing this correctly?

Lastly, is it appropriate to use interaction terms in GLMMs and lmers? I imagine that the rainfall level my interact with the treatment to influence the pollination metric.

 metric.model <- glmer(metric ~ Treatment*Location + (1 |Blocks), data = UHURUnets, family = gaussian(link = log)??)

Many thanks in advance for your help!

Cheers,
Travis




	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Thu Jul 28 09:22:22 2016
From: paul.debes at utu.fi (Paul Debes)
Date: Thu, 28 Jul 2016 10:22:22 +0300
Subject: [R-sig-ME] simulation of factor-specific random effect variance
 estimation, the order of assigned variance matters?
In-Reply-To: <HE1PR01MB0987934FF6046773E8C7B318AC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB0987934FF6046773E8C7B318AC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>
Message-ID: <op.ylaurkyesgx3xe@armadillo50>

Hi Chen,

I think you may only have to change the random effect specification from  
variance contrast to variance means:

random = list(groupID = pdDiag(~prog))
to
random = list(groupID = pdDiag(~0+prog))

It may also be good to change "groupID" from a continuous covariate to a  
factor.
This should give the expected standard deviations for the random-term  
groups in both simulations.
Just as a note, please be aware that you do not specify variance but  
standard deviation in your simulations (model output is also in standard  
deviation).

Best,
Paul


On Wed, 27 Jul 2016 23:48:01 +0300, Chen Chun <talischen at hotmail.com>  
wrote:

> Dear all,
>
> I have a nested data structure and I would like to estimate  
> factor-specific random effect variance. Inspired by the article:
>
> http://rstudio-pubs-static.s3.amazonaws.com/6B98_c0ae95A0AAA44A3Aa8a9b6ba9703fcf5.html<http://rstudio-pubs-static.s3.amazonaws.com/6298_c0ae951011144131a8a9b6ba9703fcf5.html>
>
> I conducted some simulations:
>
> ###############
> ##--generate data-----
> ngroup <- 25
> nrep<- 5
> ##----random effect of group---
> meanh <- 0
> sigmahA <- 1   ##--these are the two assigned variance of the random  
> factor group for each class (A, B)
> sigmahB <- 3
>
> ##----residual random error---
> meanR <- 0
> sigmaR <- 0.2
>
> ##---simulate smaple--------------------------------------------------
> set.seed(55)
> out_A   <- NA
> out_B   <- NA
> raneff_groupA <- rnorm(ngroup, meanh, sigmahA)
> raneff_groupB <- rnorm(ngroup, meanh, sigmahB)
> groupID      <- seq(1, ngroup)
> for (i in 1:ngroup) {
>     raneff_red_A <- rnorm(nrep, meanR, sigmaR)
>     temp_A       <- 0 + raneff_groupA[i] + raneff_red_A
>     raneff_red_B   <- rnorm(nrep, meanR, sigmaR)
>     temp_B   <- 1 + raneff_groupB[i] + raneff_red_B
>     out_A <- rbind(out_A, cbind(groupID[i], raneff_groupA[i],  
> raneff_red_A, temp_A))
>     out_B   <- rbind(out_B, cbind(groupID[i], raneff_groupB[i],  
> raneff_red_B, temp_B))
> }
> out_A <- out_A[-1,]
> out_B   <- out_B[-1,]
>
> dat <- data.frame(groupID=c(out_A[,1], out_B[,1]),  
> prog=c(rep("A",nrow(out_A)), rep("B",nrow(out_B))),  
> out=c(out_A[,"temp_A"], out_B[,"temp_B"]), raneff_haul=c(out_A[,2],  
> out_B[,2]), error=c(out_A[,3], out_B[,3]))
>
> library(lattice)
> bwplot(out~paste(prog,groupID), data=dat)
>
> ##--apply model-----
> fit2 <- lme(out ~ prog-1, random = list(groupID = pdDiag(~prog)), method  
> = "REML", data = dat)
> summary(fit2)
>
> This code gives the expected model output: as estimated variance of  
> groups for A and B are:  1.07957 2.835139, similar to assigned value
> ###############
> ###############
> Model output:
> Linear mixed-effects model fit by REML
> Data: dat
>        AIC      BIC    logLik
>   202.7263 220.2934 -96.36314
>
> Random effects:
> Formula: ~prog | groupID
> Structure: Diagonal
>         (Intercept)    progB  Residual
> StdDev:     1.07957 2.835139 0.1959905
>
> Fixed effects: out ~ prog - 1
>           Value Std.Error  DF   t-value p-value
> progA 0.0316535 0.2166244 224 0.1461215  0.8840
> progB 1.1446339 0.6069982 224 1.8857287  0.0606
> Correlation:
>       progA
> progB 0.355
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.29868033 -0.63163428  0.03981236  0.64863494  2.63613133
>
> Number of Observations: 250
> Number of Groups: 25
> #########################
>
>
>
> However, it I dont make any other changes, but simply to switch the  
> order of the simulation variance:
>
> sigmahA <- 3
> sigmahB <- 1
>
> , generate the data and apply the model, the model gives very confusing  
> result:
> ###############
> ###############
> Model output:
> Linear mixed-effects model fit by REML
> Data: dat
>       AIC      BIC    logLik
>   261.763 279.3301 -125.8815
>
> Random effects:
> Formula: ~prog | groupID
> Structure: Diagonal
>         (Intercept)    progB  Residual
> StdDev:    3.187986 3.295383 0.1959864
>
> Fixed effects: out ~ prog - 1
>           Value Std.Error  DF   t-value p-value
> progA 0.1455012 0.6378382 224 0.2281162  0.8198
> progB 1.0590270 0.9171802 224 1.1546553  0.2495
> Correlation:
>       progA
> progB 0.695
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.30847626 -0.63592816  0.03830767  0.64349268  2.63737406
>
> Number of Observations: 250
> Number of Groups: 25
> #########################
>
>
>
> The model output gives equal variance. The same situation happens if I  
> run the same code in the article (link above) and also simply change the  
> order of the variance assigned to the groups.
>
> Can someone help me to figure out why the order of assigning the  
> variance matters? And why the second case does not gives the expected  
> results?
>
> Thanks
>
> Regards,
> Chun Chen
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
20014 Finland

Email: paul.debes at utu.fi


From talischen at hotmail.com  Thu Jul 28 11:44:09 2016
From: talischen at hotmail.com (Chen Chun)
Date: Thu, 28 Jul 2016 09:44:09 +0000
Subject: [R-sig-ME] simulation of factor-specific random effect variance
 estimation, the order of assigned variance matters?
In-Reply-To: <op.ylaurkyesgx3xe@armadillo50>
References: <HE1PR01MB0987934FF6046773E8C7B318AC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>,
	<op.ylaurkyesgx3xe@armadillo50>
Message-ID: <VI1PR01MB0989ECFE3777AF95E0E96263AC000@VI1PR01MB0989.eurprd01.prod.exchangelabs.com>

Thank you Paul for the help. It's now working as I expected. and for lmer(), I guess the correct term should be (0 + prog | groupID)?


Regards,

Chun


________________________________
??????: Paul Debes <paul.debes at utu.fi>
????????: 2016??7??28?? 7:22
??????: r-sig-mixed-models at r-project.org
????: Chen Chun
????: Re: [R-sig-ME] simulation of factor-specific random effect variance estimation, the order of assigned variance matters?

Hi Chen,

I think you may only have to change the random effect specification from
variance contrast to variance means:

random = list(groupID = pdDiag(~prog))
to
random = list(groupID = pdDiag(~0+prog))

It may also be good to change "groupID" from a continuous covariate to a
factor.
This should give the expected standard deviations for the random-term
groups in both simulations.
Just as a note, please be aware that you do not specify variance but
standard deviation in your simulations (model output is also in standard
deviation).

Best,
Paul


On Wed, 27 Jul 2016 23:48:01 +0300, Chen Chun <talischen at hotmail.com>
wrote:

> Dear all,
>
> I have a nested data structure and I would like to estimate
> factor-specific random effect variance. Inspired by the article:
>
> http://rstudio-pubs-static.s3.amazonaws.com/6B98_c0ae95A0AAA44A3Aa8a9b6ba9703fcf5.html<http://rstudio-pubs-static.s3.amazonaws.com/6298_c0ae951011144131a8a9b6ba9703fcf5.html>
>
> I conducted some simulations:
>
> ###############
> ##--generate data-----
> ngroup <- 25
> nrep<- 5
> ##----random effect of group---
> meanh <- 0
> sigmahA <- 1   ##--these are the two assigned variance of the random
> factor group for each class (A, B)
> sigmahB <- 3
>
> ##----residual random error---
> meanR <- 0
> sigmaR <- 0.2
>
> ##---simulate smaple--------------------------------------------------
> set.seed(55)
> out_A   <- NA
> out_B   <- NA
> raneff_groupA <- rnorm(ngroup, meanh, sigmahA)
> raneff_groupB <- rnorm(ngroup, meanh, sigmahB)
> groupID      <- seq(1, ngroup)
> for (i in 1:ngroup) {
>     raneff_red_A <- rnorm(nrep, meanR, sigmaR)
>     temp_A       <- 0 + raneff_groupA[i] + raneff_red_A
>     raneff_red_B   <- rnorm(nrep, meanR, sigmaR)
>     temp_B   <- 1 + raneff_groupB[i] + raneff_red_B
>     out_A <- rbind(out_A, cbind(groupID[i], raneff_groupA[i],
> raneff_red_A, temp_A))
>     out_B   <- rbind(out_B, cbind(groupID[i], raneff_groupB[i],
> raneff_red_B, temp_B))
> }
> out_A <- out_A[-1,]
> out_B   <- out_B[-1,]
>
> dat <- data.frame(groupID=c(out_A[,1], out_B[,1]),
> prog=c(rep("A",nrow(out_A)), rep("B",nrow(out_B))),
> out=c(out_A[,"temp_A"], out_B[,"temp_B"]), raneff_haul=c(out_A[,2],
> out_B[,2]), error=c(out_A[,3], out_B[,3]))
>
> library(lattice)
> bwplot(out~paste(prog,groupID), data=dat)
>
> ##--apply model-----
> fit2 <- lme(out ~ prog-1, random = list(groupID = pdDiag(~prog)), method
> = "REML", data = dat)
> summary(fit2)
>
> This code gives the expected model output: as estimated variance of
> groups for A and B are:  1.07957 2.835139, similar to assigned value
> ###############
> ###############
> Model output:
> Linear mixed-effects model fit by REML
> Data: dat
>        AIC      BIC    logLik
>   202.7263 220.2934 -96.36314
>
> Random effects:
> Formula: ~prog | groupID
> Structure: Diagonal
>         (Intercept)    progB  Residual
> StdDev:     1.07957 2.835139 0.1959905
>
> Fixed effects: out ~ prog - 1
>           Value Std.Error  DF   t-value p-value
> progA 0.0316535 0.2166244 224 0.1461215  0.8840
> progB 1.1446339 0.6069982 224 1.8857287  0.0606
> Correlation:
>       progA
> progB 0.355
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.29868033 -0.63163428  0.03981236  0.64863494  2.63613133
>
> Number of Observations: 250
> Number of Groups: 25
> #########################
>
>
>
> However, it I dont make any other changes, but simply to switch the
> order of the simulation variance:
>
> sigmahA <- 3
> sigmahB <- 1
>
> , generate the data and apply the model, the model gives very confusing
> result:
> ###############
> ###############
> Model output:
> Linear mixed-effects model fit by REML
> Data: dat
>       AIC      BIC    logLik
>   261.763 279.3301 -125.8815
>
> Random effects:
> Formula: ~prog | groupID
> Structure: Diagonal
>         (Intercept)    progB  Residual
> StdDev:    3.187986 3.295383 0.1959864
>
> Fixed effects: out ~ prog - 1
>           Value Std.Error  DF   t-value p-value
> progA 0.1455012 0.6378382 224 0.2281162  0.8198
> progB 1.0590270 0.9171802 224 1.1546553  0.2495
> Correlation:
>       progA
> progB 0.695
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.30847626 -0.63592816  0.03830767  0.64349268  2.63737406
>
> Number of Observations: 250
> Number of Groups: 25
> #########################
>
>
>
> The model output gives equal variance. The same situation happens if I
> run the same code in the article (link above) and also simply change the
> order of the variance assigned to the groups.
>
> Can someone help me to figure out why the order of assigning the
> variance matters? And why the second case does not gives the expected
> results?
>
> Thanks
>
> Regards,
> Chun Chen
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
20014 Finland

Email: paul.debes at utu.fi

	[[alternative HTML version deleted]]


From talischen at hotmail.com  Thu Jul 28 12:18:27 2016
From: talischen at hotmail.com (Chen Chun)
Date: Thu, 28 Jul 2016 10:18:27 +0000
Subject: [R-sig-ME] =?gb2312?b?tPC4tDogIEhvdyBjYW4gYSBtaXhlZCBtb2RlbCBk?=
 =?gb2312?b?aWZmZXJlbnRpYXRlIHRoZSBmaXhlZCBlZmZlY3QgYW5kIHJhbmRvbSBlZmZl?=
 =?gb2312?b?Y3Qgd2hlbiB0aGVyZSBpcyBvbmx5IG9uZSBncm91cCBvZiBjb250cm9sIGlu?=
 =?gb2312?b?IHRoZSBkYXRhPw==?=
In-Reply-To: <CAErFSoie102d0zwosgfcOhH9=S3mSuDqZorVHoaRiWD7wjGT0Q@mail.gmail.com>
References: <HE1PR01MB0987A9D120D0DFF74DC2AE0CAC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>,
	<CAErFSoie102d0zwosgfcOhH9=S3mSuDqZorVHoaRiWD7wjGT0Q@mail.gmail.com>
Message-ID: <VI1PR01MB0989FB5C3D0615012C4D253AAC000@VI1PR01MB0989.eurprd01.prod.exchangelabs.com>

Thank you Aaron for the help. It's clear to me now.


Regards,

Chun


________________________________
??????: Aaron Mackey <ajmackey at gmail.com>
????????: 2016??7??27?? 21:07
??????: Chen Chun
????: r-sig-mixed-models at r-project.org
????: Re: [R-sig-ME] How can a mixed model differentiate the fixed effect and random effect when there is only one group of control in the data?

because the random effect in your model is independent of the fixed effect, the mixed model has six groups from which to estimate the variance of the random effect. If you had asked for the random effect group variances to be different between treatments  ~ (1|treatment:group) then you'd be in trouble.

hope that helps,
-Aaron

On Wed, Jul 27, 2016 at 4:44 PM, Chen Chun <talischen at hotmail.com<mailto:talischen at hotmail.com>> wrote:
Dear all,


I have a data set where experiments were conducted in groups of animals and each group was assigned to one treatment (treatment vs. control). In my data, unfortunately I have only one control group, so the model would be:

lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)


I am wondering whether in this case the mixed model would still be able to provide unbiased estimate of the fixed effect and random group effect for the control group. I have written a simulation code for 5 treatment groups vs. 1 control group (see below). Seems that the linear mixed model is still able to provide unbiased estimate. Can someone give me more insight about why lmer could identify the fixed and random effect when there is only one group from one treatment arm?


Thanks


Chun Chen


library(lme4)
set.seed(320)
N_group <- 6
N_per_group <- 20
NO_con_group <-1
beta_t <- 3
beta_c <- 0
intercept <- 2

res <- matrix(NA, nrow=1000, ncol=2)
for(k in 1:1000) {
    random_error1 <- rnorm(N_per_group*(N_group-NO_con_group), mean = 0, sd = 1)
    random_error2 <- rnorm(N_per_group*NO_con_group, mean = 0, sd = 1)
    group_error <- rnorm(N_group, mean = 0, sd = 5)

    yt <- intercept + beta_t + rep(group_error[1:(N_group-NO_con_group)], each=N_per_group) + random_error1
    y_c <- intercept + beta_c + rep(group_error[(N_group-NO_con_group+1):N_group], each=N_per_group) + random_error2
    y <- c(yt, y_c)

    dat <- data.frame(out=y, treatment=c(rep("treat", N_per_group*(N_group-NO_con_group)), rep("con",N_per_group*NO_con_group)), group=rep(letters[1:N_group], each=N_per_group))

    fit <- lmer(out ~ treatment + (1| group),  REML = TRUE, data=dat)
    summary(fit)
    res[k,1] <- fixef(fit)[1]
    res[k,2] <- fixef(fit)[2]
}

colMeans(res)  ##---similar to intercept  and beta_t


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From paul.debes at utu.fi  Thu Jul 28 12:34:09 2016
From: paul.debes at utu.fi (Paul Debes)
Date: Thu, 28 Jul 2016 13:34:09 +0300
Subject: [R-sig-ME] simulation of factor-specific random effect variance
 estimation, the order of assigned variance matters?
In-Reply-To: <VI1PR01MB0989ECFE3777AF95E0E96263AC000@VI1PR01MB0989.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB0987934FF6046773E8C7B318AC0F0@HE1PR01MB0987.eurprd01.prod.exchangelabs.com>
	<op.ylaurkyesgx3xe@armadillo50>
	<VI1PR01MB0989ECFE3777AF95E0E96263AC000@VI1PR01MB0989.eurprd01.prod.exchangelabs.com>
Message-ID: <op.yla3m7u9sgx3xe@armadillo50>

Hi Chun (sorry for previously confusing your first and last name),

The lmer term you suggest fits an unstructured covariance matrix (i.e.,  
also the covariance for the "groupID " random effects between "prog"  
levels), whereas the lme term is fitting a diagonal covariance matrix  
(where the covariance is restrained to be zero).  The latter is more  
parsimonious (one less parameter) and corresponds to what you simulated -  
no covariance. I hope someone else can help you how to specify the same  
diagonal covariance matrix for lmer to have equivalent models between  
packages. Unfortunately, I don't know how that works using lmer.

Best,
Paul



On Thu, 28 Jul 2016 12:44:09 +0300, Chen Chun <talischen at hotmail.com>  
wrote:

>
> Thank you Paul for the help. It's now working as I expected. and for  
> lmer(), I guess the correct term should be (0 + prog | groupID)?
>
>
>
> Regards,
>
> Chun
>
>
>???: Paul Debes <paul.debes at utu.fi>
> ????: 2016?7?28? 7:22
> ???: r-sig-mixed-models at r-project.org
> ??: Chen Chun
> ??: Re: [R-sig-ME] simulation of factor-specific random effect  
> variance estimation, the order of assigned variance matters?
>> Hi Chen,
>
> I think you may only have to change the random effect specification from  
> variance contrast to variance means:
>
> random = list(groupID = pdDiag(~prog))
> to
> random = list(groupID = pdDiag(~0+prog))
>
> It may also be good to change "groupID" from a continuous covariate to a  
> factor.
> This should give the expected standard deviations for the random-term  
> groups in both simulations.
> Just as a note, please be aware that you do not specify variance but  
> standard deviation in your simulations (model output is also in standard  
> deviation).
>
> Best,
> Paul
>
>
> On Wed, 27 Jul 2016 23:48:01 +0300, Chen Chun <talischen at hotmail.com>  
> wrote:
>
>> Dear all,
>>
>> I have a nested data structure and I would like to estimate  
>> factor-specific random effect variance. Inspired by the article:
>>
>> http://rstudio-pubs-static.s3.amazonaws.com/6B98_c0ae95A0AAA44A3Aa8a9b6ba9703fcf5.html<http://rstudio-pubs->static.s3.amazonaws.com/6298_c0ae951011144131a8a9b6ba9703fcf5.html>
>>
>> I conducted some simulations:
>>
>> ###############
>> ##--generate data-----
>> ngroup <- 25
>> nrep<- 5
>> ##----random effect of group---
>> meanh <- 0
>> sigmahA <- 1   ##--these are the two assigned variance of the random  
>> factor group for each class (A, B)
>> sigmahB <- 3
>>
>> ##----residual random error---
>> meanR <- 0
>> sigmaR <- 0.2
>>
>> ##---simulate smaple--------------------------------------------------
>> set.seed(55)
>> out_A   <- NA
>> out_B   <- NA
>> raneff_groupA <- rnorm(ngroup, meanh, sigmahA)
>> raneff_groupB <- rnorm(ngroup, meanh, sigmahB)
>> groupID      <- seq(1, ngroup)
>> for (i in 1:ngroup) {
>>     raneff_red_A <- rnorm(nrep, meanR, sigmaR)
>>     temp_A       <- 0 + raneff_groupA[i] + raneff_red_A
>>     raneff_red_B   <- rnorm(nrep, meanR, sigmaR)
>>     temp_B   <- 1 + raneff_groupB[i] + raneff_red_B
>>     out_A <- rbind(out_A, cbind(groupID[i], raneff_groupA[i],  
>> raneff_red_A, temp_A))
>>     out_B   <- rbind(out_B, cbind(groupID[i], raneff_groupB[i],  
>> raneff_red_B, temp_B))
>> }
>> out_A <- out_A[-1,]
>> out_B   <- out_B[-1,]
>>
>> dat <- data.frame(groupID=c(out_A[,1], out_B[,1]),  
>> prog=c(rep("A",nrow(out_A)), rep("B",nrow(out_B))),  
>> out=c(out_A[,"temp_A"], out_B[,"temp_B"]), raneff_haul=c(out_A[,2],  
>> out_B[,2]), error=c(out_A[,3], out_B[,3]))
>>
>> library(lattice)
>> bwplot(out~paste(prog,groupID), data=dat)
>>
>> ##--apply model-----
>> fit2 <- lme(out ~ prog-1, random = list(groupID = pdDiag(~prog)),  
>> method = "REML", data = dat)
>> summary(fit2)
>>
>> This code gives the expected model output: as estimated variance of  
>> groups for A and B are:  1.07957 2.835139, similar to assigned value
>> ###############
>> ###############
>> Model output:
>> Linear mixed-effects model fit by REML
>> Data: dat
>>        AIC      BIC    logLik
>>   202.7263 220.2934 -96.36314
>>
>> Random effects:
>> Formula: ~prog | groupID
>> Structure: Diagonal
>>         (Intercept)    progB  Residual
>> StdDev:     1.07957 2.835139 0.1959905
>>
>> Fixed effects: out ~ prog - 1
>>           Value Std.Error  DF   t-value p-value
>> progA 0.0316535 0.2166244 224 0.1461215  0.8840
>> progB 1.1446339 0.6069982 224 1.8857287  0.0606
>> Correlation:
>>       progA
>> progB 0.355
>>
>> Standardized Within-Group Residuals:
>>         Min          Q1         Med          Q3         Max
>> -2.29868033 -0.63163428  0.03981236  0.64863494  2.63613133
>>
>> Number of Observations: 250
>> Number of Groups: 25
>> #########################
>>
>>
>>
>> However, it I dont make any other changes, but simply to switch the  
>> order of the simulation variance:
>>
>> sigmahA <- 3
>> sigmahB <- 1
>>
>> , generate the data and apply the model, the model gives very confusing  
>> result:
>> ###############
>> ###############
>> Model output:
>> Linear mixed-effects model fit by REML
>> Data: dat
>>       AIC      BIC    logLik
>>   261.763 279.3301 -125.8815
>>
>> Random effects:
>> Formula: ~prog | groupID
>> Structure: Diagonal
>>         (Intercept)    progB  Residual
>> StdDev:    3.187986 3.295383 0.1959864
>>
>> Fixed effects: out ~ prog - 1
>>           Value Std.Error  DF   t-value p-value
>> progA 0.1455012 0.6378382 224 0.2281162  0.8198
>> progB 1.0590270 0.9171802 224 1.1546553  0.2495
>> Correlation:
>>       progA
>> progB 0.695
>>
>> Standardized Within-Group Residuals:
>>         Min          Q1         Med          Q3         Max
>> -2.30847626 -0.63592816  0.03830767  0.64349268  2.63737406
>>
>> Number of Observations: 250
>> Number of Groups: 25
>> #########################
>>
>>
>>
>> The model output gives equal variance. The same situation happens if I  
>> run the same code in the article (link above) and also simply change  
>> the order of the variance assigned to the groups.
>>
>> Can someone help me to figure out why the order of assigning the  
>> variance matters? And why the second case does not gives the expected  
>> results?
>>
>> Thanks
>>
>> Regards,
>> Chun Chen
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --Paul V. Debes
> DFG Research Fellow
>
> Division of Genetics and Physiology
> Department of Biology
> University of Turku
> 20014 Finland
>
> Email: paul.debes at utu.fi



-- 
Paul V. Debes
DFG Research Fellow

Division of Genetics and Physiology
Department of Biology
University of Turku
20014 Finland

Email: paul.debes at utu.fi

From xavierpiulachs at hotmail.com  Fri Jul 29 21:09:28 2016
From: xavierpiulachs at hotmail.com (xavier piulachs)
Date: Fri, 29 Jul 2016 19:09:28 +0000
Subject: [R-sig-ME] Random slope does not improve hierarchical fitting
	across time
Message-ID: <DB5PR03MB1205DD20DF1E4C28AC3D54BAC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>

Dear members of mixed-models list,


I'm adressing you in order to ask a question about Hierarchical and ZI counts measured over time.
To have preliminar results, I'm modeling longitudinal data with a Negative Binomial GLMM, via
lme4 and glmmADBM packages (very similar results). I have considered two possibilities:


1) A single random intercept:
glmer.0.int.NB <- glmer.nb(counts ~ obstime + (1|id), data = tr.j)    # lme4 package

tr.j$ID <- as.factor(tr.j$id)
glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), data = tr.j, family = "nbinom")
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.9652     0.1222 -7.9005   0.0000
obstime       0.0238     0.0073  3.2735   0.0011


2) Random intercept and random slope effects:
glmer.0.slp.NB <- glmer.nb(counts ~ obstime + (obstime|id), data = tr.j)   #  lme4 package

glmmADMB.0.slp.NB <- glmmadmb(claimyr ~ obstime + (obstime|ID), data = tr.j, family = "nbinom")
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -0.9401     0.1190 -7.9005   0.0000
obstime       0.0230     0.0075  3.0540   0.0023


Surprisingly, the anova test indicates non significant improvement by fitting second model:

anova(glmer.0.int.NB, glmer.0.slp.NB)  # LRT: p-value = 0.2725 > 0.05
anova(glmmADMB.0.int.NB, glmmADMB.0.slp.NB) # LRT: p-value = 0.1042 > 0.05


As far as I know, when dealing repeated measurements across time, we expect that outcomes closer in time to be

more correlated (it is indeed a more realistic approach), so I'm totally disconcerted by this result.

Can anyone explain what could be the reason?


Best,

Xavier


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Jul 29 21:48:26 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 Jul 2016 15:48:26 -0400
Subject: [R-sig-ME] Random slope does not improve hierarchical fitting
 across time
In-Reply-To: <DB5PR03MB1205DD20DF1E4C28AC3D54BAC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>
References: <DB5PR03MB1205DD20DF1E4C28AC3D54BAC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>
Message-ID: <5dec4b95-5ce6-2bda-7699-664d5630130d@gmail.com>



On 16-07-29 03:09 PM, xavier piulachs wrote:
> Dear members of mixed-models list,
> 
> 
> I'm adressing you in order to ask a question about Hierarchical and ZI counts measured over time.
> To have preliminar results, I'm modeling longitudinal data with a Negative Binomial GLMM, via
> lme4 and glmmADBM packages (very similar results). I have considered two possibilities:
> 
> 
> 1) A single random intercept:
> glmer.0.int.NB <- glmer.nb(counts ~ obstime + (1|id), data = tr.j)    # lme4 package
> 
> tr.j$ID <- as.factor(tr.j$id)
> glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), data = tr.j, family = "nbinom")
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -0.9652     0.1222 -7.9005   0.0000
> obstime       0.0238     0.0073  3.2735   0.0011
> 
> 
> 2) Random intercept and random slope effects:
> glmer.0.slp.NB <- glmer.nb(counts ~ obstime + (obstime|id), data = tr.j)   #  lme4 package
> 
> glmmADMB.0.slp.NB <- glmmadmb(claimyr ~ obstime + (obstime|ID), data = tr.j, family = "nbinom")
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -0.9401     0.1190 -7.9005   0.0000
> obstime       0.0230     0.0075  3.0540   0.0023
> 
> 
> Surprisingly, the anova test indicates non significant improvement by fitting second model:
> 
> anova(glmer.0.int.NB, glmer.0.slp.NB)  # LRT: p-value = 0.2725 > 0.05
> anova(glmmADMB.0.int.NB, glmmADMB.0.slp.NB) # LRT: p-value = 0.1042 > 0.05
> 
> 
> As far as I know, when dealing repeated measurements across time, we expect that outcomes closer in time to be
> more correlated (it is indeed a more realistic approach), so I'm totally disconcerted by this result.
> Can anyone explain what could be the reason?

  A few comments:

- most important: just because an effect is 'really' in the model (e.g.,
in this case, the effect of time really does vary among individuals)
doesn't mean it will have a statistically significant effect. In most
observational/complex fields (population biology, social sciences),
*all* of the effects are really non-zero. The purpose of significance
tests is to see which effects can be distinguished from noise.

- your explanation ("outcomes closer in time are more correlated") isn't
a very precise description of what the (obstime|ID) term in the model is
doing.  Your description is of an autoregressive model; the (obstime|ID)
model is a random-slope model (slopes with respect to time vary among
individuals).  You might want to check out the glmmTMB package for
autoregressive models ...
- glmmADMB's default correlation structure is diagonal, glmer.nb's is
unstructured; if you use (obstime||ID) in glmer.nb or 	corStruct="full"
in glmmadmb you should get more similar results (I would generally
recommend "full" as the default ...)
- likelihood ratio tests (which is what anova() is doing) generally give
conservative p-values when applied to random-effect variances (boundary
issues -- see http://tinyurl.com/glmmFAQ.html or Bolker (2009) or
Pinheiro and Bates 2000 for more discussion) -- so the p-values should
probably be approximately halved


From xavierpiulachs at hotmail.com  Fri Jul 29 22:32:05 2016
From: xavierpiulachs at hotmail.com (xavier piulachs)
Date: Fri, 29 Jul 2016 20:32:05 +0000
Subject: [R-sig-ME] Random slope does not improve hierarchical fitting
 across time
In-Reply-To: <5dec4b95-5ce6-2bda-7699-664d5630130d@gmail.com>
References: <DB5PR03MB1205DD20DF1E4C28AC3D54BAC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>,
	<5dec4b95-5ce6-2bda-7699-664d5630130d@gmail.com>
Message-ID: <DB5PR03MB1205FF0188DA8D5F9327D25FC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>

Dear Ben,


First of all, many thanks for your quick response. Moreover, I'm aware that you are an expertise in this field, so I'm doubly happy of receiving your comments.

I have two doubts about what you say (the clue point is maybe the first):


1) The effect of time is in the model as fixed effect (and it is significant), ok. But I also would expect that each subject, i = 1,...,n, has:

   a) His underlying baseline level (ie, a subject-specific baseline effect = beta0 + random intercept = beta0 + ui0) ,and

   b) A particular trend-evolution across time (a subject especific slope = fixed effect of time + random slope = beta_t + uit).

It is indeed very common when dealing repeated measurements across time (a particular case of longitudinal models) to have these two significant

effects.  In fact, always I have fitted longitudinal measurements over time (with unstructure matrix correlation by default), I got that random intercept

and slope model improves the accuracy of considering a single random intercept. So I think this is compatible with the idea of an autoregressive model.

Is it correct?


 2) I have fitted the GLMM with the option corStruct = "full":

glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), corStruct = "full", data = tr.j, family = "nbinom")

And I get the following R error message:

Parameters were estimated, but standard errors were not: the most likely problem is that the curvature at MLE was zero or negative

The function maximizer failed (couldn't find parameter file)


Best,


Xavier


________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Ben Bolker <bbolker at gmail.com>
Enviado: viernes, 29 de julio de 2016 19:48
Para: r-sig-mixed-models at r-project.org
Asunto: Re: [R-sig-ME] Random slope does not improve hierarchical fitting across time



On 16-07-29 03:09 PM, xavier piulachs wrote:
> Dear members of mixed-models list,
>
>
> I'm adressing you in order to ask a question about Hierarchical and ZI counts measured over time.
> To have preliminar results, I'm modeling longitudinal data with a Negative Binomial GLMM, via
> lme4 and glmmADBM packages (very similar results). I have considered two possibilities:
>
>
> 1) A single random intercept:
> glmer.0.int.NB <- glmer.nb(counts ~ obstime + (1|id), data = tr.j)    # lme4 package
>
> tr.j$ID <- as.factor(tr.j$id)
> glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), data = tr.j, family = "nbinom")
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -0.9652     0.1222 -7.9005   0.0000
> obstime       0.0238     0.0073  3.2735   0.0011
>
>
> 2) Random intercept and random slope effects:
> glmer.0.slp.NB <- glmer.nb(counts ~ obstime + (obstime|id), data = tr.j)   #  lme4 package
>
> glmmADMB.0.slp.NB <- glmmadmb(claimyr ~ obstime + (obstime|ID), data = tr.j, family = "nbinom")
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -0.9401     0.1190 -7.9005   0.0000
> obstime       0.0230     0.0075  3.0540   0.0023
>
>
> Surprisingly, the anova test indicates non significant improvement by fitting second model:
>
> anova(glmer.0.int.NB, glmer.0.slp.NB)  # LRT: p-value = 0.2725 > 0.05
> anova(glmmADMB.0.int.NB, glmmADMB.0.slp.NB) # LRT: p-value = 0.1042 > 0.05
>
>
> As far as I know, when dealing repeated measurements across time, we expect that outcomes closer in time to be
> more correlated (it is indeed a more realistic approach), so I'm totally disconcerted by this result.
> Can anyone explain what could be the reason?

  A few comments:

- most important: just because an effect is 'really' in the model (e.g.,
in this case, the effect of time really does vary among individuals)
doesn't mean it will have a statistically significant effect. In most
observational/complex fields (population biology, social sciences),
*all* of the effects are really non-zero. The purpose of significance
tests is to see which effects can be distinguished from noise.

- your explanation ("outcomes closer in time are more correlated") isn't
a very precise description of what the (obstime|ID) term in the model is
doing.  Your description is of an autoregressive model; the (obstime|ID)
model is a random-slope model (slopes with respect to time vary among
individuals).  You might want to check out the glmmTMB package for
autoregressive models ...
- glmmADMB's default correlation structure is diagonal, glmer.nb's is
unstructured; if you use (obstime||ID) in glmer.nb or    corStruct="full"
in glmmadmb you should get more similar results (I would generally
recommend "full" as the default ...)
- likelihood ratio tests (which is what anova() is doing) generally give
conservative p-values when applied to random-effect variances (boundary
issues -- see http://tinyurl.com/glmmFAQ.html or Bolker (2009) or
Pinheiro and Bates 2000 for more discussion) -- so the p-values should
probably be approximately halved

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From aravindjayaramanagri at gmail.com  Sat Jul 30 07:41:03 2016
From: aravindjayaramanagri at gmail.com (Aravind J.)
Date: Sat, 30 Jul 2016 11:11:03 +0530
Subject: [R-sig-ME] Replicating analysis in asreml in lme4
Message-ID: <CA+0rMg=bpxedA1m3wMm0rcSketuf+KY=4CY=R25evm=G10f5Qw@mail.gmail.com>

Dear members,

I am trying to reproduce analyse an alpha lattice design (an unbalanced
design) in  `lme4`.

https://cran.r-project.org/web/packages/agridat/agridat.pdf#page.184

library(agridat)
library(lme4)

The model can be fitted in lme4

# genotypes - fixed
model <- lmer(yield ~ 0 + gen + rep + (1|rep:block), dat)
# genotypes - random
model <- lmer(yield ~ 0 + (1|gen) + rep + (1|rep:block), dat)

However further calculations seem to required `asreml`.

library(asreml)

m3 <- asreml(yield ~ 1 + rep, data=dat, random=~ gen + rep:block)
sg2 <- summary(m3)$varcomp[1,'component']
vblup <- predict(m3, classify="gen")$pred$avsed ^ 2

m3 <- asreml(yield ~ 1 + gen + rep, data=dat, random = ~ rep:block)
vblue <- predict(m3, classify="gen")$pred$avsed ^ 2
sg2 / (sg2 + vblue/2)
1-(vblup / 2 / sg2)

Here `avsed` is the "mean variance of difference of adjusted means" (BLUP
or BLUE). Is it possible to replicate the last part also in `lme4`?

`avsed` can be computed from the "variance-covariance matrix of adjusted
means" for genotypes. (
https://static-content.springer.com/esm/art%3A10.1186%2F1471-2164-14-860/MediaObjects/12864_2013_5591_MOESM1_ESM.doc).
How to get that matrix from lme4?


Warm Regards,

-- 
J.Aravind
Division of Germplasm Conservation,
ICAR-National Bureau of Plant Genetic Resources,
New Delhi - 110 012
<aravindj at nbpgr.ernet.in>

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Sat Jul 30 11:38:23 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Sat, 30 Jul 2016 09:38:23 +0000
Subject: [R-sig-ME] Random slope does not improve hierarchical fitting
 across time
In-Reply-To: <DB5PR03MB1205FF0188DA8D5F9327D25FC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>
References: <DB5PR03MB1205DD20DF1E4C28AC3D54BAC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>
	, <5dec4b95-5ce6-2bda-7699-664d5630130d@gmail.com>
	<DB5PR03MB1205FF0188DA8D5F9327D25FC7010@DB5PR03MB1205.eurprd03.prod.outlook.com>
Message-ID: <1469871503.14768.11.camel@unisa.edu.au>

Dear Xavier,

Both of your issues speak towards insufficient data (power too low) or
a model specification not suited for the data. See Bates et al
Parsimonious Mixed Models (http://arxiv.org/abs/1506.04967) for a
discussion on some of these issues.

Bottom line: you can't estimate all of your parameters precisely enough
(large standard errors or inability to estimate them) with the data you
have (either because there's not enough or because it isn't well
described by your model specification) and so you fail to get to
achieve significance.?

Best,
Phillip

On Fri, 2016-07-29 at 20:32 +0000, xavier piulachs wrote:
> Dear Ben,
> 
> 
> First of all, many thanks for your quick response. Moreover, I'm
> aware that you are an expertise in this field, so I'm doubly happy of
> receiving your comments.
> 
> I have two doubts about what you say (the clue point is maybe the
> first):
> 
> 
> 1) The effect of time is in the model as fixed effect (and it is
> significant), ok. But I also would expect that each subject, i =
> 1,...,n, has:
> 
> ???a) His underlying baseline level (ie, a subject-specific baseline
> effect = beta0 + random intercept = beta0 + ui0) ,and
> 
> ???b) A particular trend-evolution across time (a subject especific
> slope = fixed effect of time + random slope = beta_t + uit).
> 
> It is indeed very common when dealing repeated measurements across
> time (a particular case of longitudinal models) to have these two
> significant
> 
> effects.??In fact, always I have fitted longitudinal measurements
> over time (with unstructure matrix correlation by default), I got
> that random intercept
> 
> and slope model improves the accuracy of considering a single random
> intercept. So I think this is compatible with the idea of an
> autoregressive model.
> 
> Is it correct?
> 
> 
> ?2) I have fitted the GLMM with the option corStruct = "full":
> 
> glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), corStruct =
> "full", data = tr.j, family = "nbinom")
> 
> And I get the following R error message:
> 
> Parameters were estimated, but standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
> 
> The function maximizer failed (couldn't find parameter file)
> 
> 
> Best,
> 
> 
> Xavier
> 
> 
> ________________________________
> De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en
> nombre de Ben Bolker <bbolker at gmail.com>
> Enviado: viernes, 29 de julio de 2016 19:48
> Para: r-sig-mixed-models at r-project.org
> Asunto: Re: [R-sig-ME] Random slope does not improve hierarchical
> fitting across time
> 
> 
> 
> On 16-07-29 03:09 PM, xavier piulachs wrote:
> > 
> > Dear members of mixed-models list,
> > 
> > 
> > I'm adressing you in order to ask a question about Hierarchical and
> > ZI counts measured over time.
> > To have preliminar results, I'm modeling longitudinal data with a
> > Negative Binomial GLMM, via
> > lme4 and glmmADBM packages (very similar results). I have
> > considered two possibilities:
> > 
> > 
> > 1) A single random intercept:
> > glmer.0.int.NB <- glmer.nb(counts ~ obstime + (1|id), data =
> > tr.j)????# lme4 package
> > 
> > tr.j$ID <- as.factor(tr.j$id)
> > glmmADMB.0.int.NB <- glmmadmb(claimyr ~ obstime + (1|ID), data =
> > tr.j, family = "nbinom")
> > ????????????Estimate Std. Error z value Pr(>|z|)
> > (Intercept)??-0.9652?????0.1222 -7.9005???0.0000
> > obstime???????0.0238?????0.0073??3.2735???0.0011
> > 
> > 
> > 2) Random intercept and random slope effects:
> > glmer.0.slp.NB <- glmer.nb(counts ~ obstime + (obstime|id), data =
> > tr.j)???#??lme4 package
> > 
> > glmmADMB.0.slp.NB <- glmmadmb(claimyr ~ obstime + (obstime|ID),
> > data = tr.j, family = "nbinom")
> > ????????????Estimate Std. Error z value Pr(>|z|)
> > (Intercept)??-0.9401?????0.1190 -7.9005???0.0000
> > obstime???????0.0230?????0.0075??3.0540???0.0023
> > 
> > 
> > Surprisingly, the anova test indicates non significant improvement
> > by fitting second model:
> > 
> > anova(glmer.0.int.NB, glmer.0.slp.NB)??# LRT: p-value = 0.2725 >
> > 0.05
> > anova(glmmADMB.0.int.NB, glmmADMB.0.slp.NB) # LRT: p-value = 0.1042
> > > 0.05
> > 
> > 
> > As far as I know, when dealing repeated measurements across time,
> > we expect that outcomes closer in time to be
> > more correlated (it is indeed a more realistic approach), so I'm
> > totally disconcerted by this result.
> > Can anyone explain what could be the reason?
> ? A few comments:
> 
> - most important: just because an effect is 'really' in the model
> (e.g.,
> in this case, the effect of time really does vary among individuals)
> doesn't mean it will have a statistically significant effect. In most
> observational/complex fields (population biology, social sciences),
> *all* of the effects are really non-zero. The purpose of significance
> tests is to see which effects can be distinguished from noise.
> 
> - your explanation ("outcomes closer in time are more correlated")
> isn't
> a very precise description of what the (obstime|ID) term in the model
> is
> doing.??Your description is of an autoregressive model; the
> (obstime|ID)
> model is a random-slope model (slopes with respect to time vary among
> individuals).??You might want to check out the glmmTMB package for
> autoregressive models ...
> - glmmADMB's default correlation structure is diagonal, glmer.nb's is
> unstructured; if you use (obstime||ID) in glmer.nb
> or????corStruct="full"
> in glmmadmb you should get more similar results (I would generally
> recommend "full" as the default ...)
> - likelihood ratio tests (which is what anova() is doing) generally
> give
> conservative p-values when applied to random-effect variances
> (boundary
> issues -- see http://tinyurl.com/glmmFAQ.html or Bolker (2009) or
> Pinheiro and Bates 2000 for more discussion) -- so the p-values
> should
> probably be approximately halved
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From annmarieraymondi at u.boisestate.edu  Wed Jul 20 01:28:31 2016
From: annmarieraymondi at u.boisestate.edu (Ann Marie Raymondi)
Date: Tue, 19 Jul 2016 18:28:31 -0500
Subject: [R-sig-ME] lme4 random effects for repeated measures,
	unbalanced data
Message-ID: <CAKm59J-jadP-8mUga7B8DwSO+=kzEBr-nthibwBM8JdcDUe9PA@mail.gmail.com>

Hello Listers,

I have a vegetation data set that consists of 150 plots that were sampled
1-3 times over a three year period.  Plots are my unit of observation and
they are unbalanced (since plots were sampled either once, twice, or three
times).  I would like to use mixed-effects models in order to account for
variation in both plots and sampling year and to keep my sample size large
(instead of conducting my analysis within individual years). Here is an
example of the grouping of my data:

Plot_ID       Plot     Year
2012_101   101     2012
2013_101   101     2013
2014_101   101     2014
2012_201   201     2012
2013_201   201     2013
2013_301   301     2013

My response variables are cover of vegetation functional groups and
predictors include variables related to fire and treatment history.
Additionally, I am not interested in how plots change over time per se, but
rather, in aggregating sampling from all three years to increase my sample
size and to account for the spatial/temporal correlation that arises from
doing so.  It is my assumption that treating plot as a random effect
(intercept only) accounts for variation that arises from potential spatial
autocorrelation, but my main question is how to account for the repeated
measures and if I need to account for the grouping of cells within sampling
years:

Potential model:

model<-lmer(response~covariates + (1|Plot) + (1|Year).

However, I know that is not appropriate to use a random effect with only
three levels, year in this case.  I'm hoping for recommendations on how to
incorporate year as a random effect.  Is including (Year |  Plot)
 recommended?  And if so, how might I interpret that effect, i.e., is it
accounting for variation introduced by different sampling year or variation
in plots over sampling year?

Thank you in advance for any help/suggestions!

Ann Marie

	[[alternative HTML version deleted]]


From celiasofiamoreira at gmail.com  Fri Jul 22 23:18:31 2016
From: celiasofiamoreira at gmail.com (=?UTF-8?Q?C=C3=A9lia_Sofia_Moreira?=)
Date: Fri, 22 Jul 2016 22:18:31 +0100
Subject: [R-sig-ME] Fwd: Multinomial response variable
In-Reply-To: <CAJhU6eEea677Evite3YadG66f3=pbXWrw3oRJngiQtFvnePPKA@mail.gmail.com>
References: <CAJhU6eEea677Evite3YadG66f3=pbXWrw3oRJngiQtFvnePPKA@mail.gmail.com>
Message-ID: <CAJhU6eGrPnDmt3kc_AoCchB0SG54kgnPhpVZEmpe5KNLL72upw@mail.gmail.com>

Dear All,

Thank you very much for the lme4 R package. It is really, really useful!

I have a problem concerning this package. I want to study the following
model given by the formula:
'y ~ time + (1| id)',
where 'y', 'time', and 'id' are factors, nominal but non ordered, with 4, 2
and 60 levels, respectively.

Thus, to perform the model using lme4, I would need 'family=multinomial'.
However, for the best of my knowledge, this family is not available in
lme4. Can you please suggest me an alternative option to conduct this
study? Do you plan to extend lme4 to this family in a near future?

Kind regards,
  celia

	[[alternative HTML version deleted]]


From orzack at freshpond.org  Sat Jul 30 00:12:45 2016
From: orzack at freshpond.org (Steven Orzack)
Date: Fri, 29 Jul 2016 18:12:45 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
	invertible
Message-ID: <fd5f7d1d-a498-bfde-c670-514b21cdb858@freshpond.org>

  I am analyzing time series of a statistic (coefficient of variation or 
CV) generated by a Monte Carlo simulation of population dynamics. A 
given simulation might generate thousands of such time series.

For any given time series, the sequential estimates of CV are correlated 
with one another (because they are based on partially overlapping sets 
of the population numbers). Accordingly, I am using gls models with 
autocorrelated errors to analyze each time series.

Although the stochastic process generating all sample paths is the same, 
any given sample path might consist of a time series of CV for which 
AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced 
by ar() (see below).

In practice, I have seen time series for which AR(0), AR(1), AR(2) 
generate the smallest AIC value and so always just using a specific 
order (e.g., AR(1)) does not seem appropriate. This is especially so 
because I am developing methods that would apply to time series for 
which the generating dynamics are not known.

For any given sample path y, the code is

#assess order of AR model using ar. use order with smallest AIC
arorder <- ar(moving_statistics$CV, order.max = 5)$order

#evaluate model with constant and time
if (arorder < 1) {
summary(int_model <- lm(CV ~ 1, data = moving_statistics))
summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))

#extract statistics for sample path y
pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
pvalue_cv$slope_time[y] <- time_model$coefficients[2]
} else {
summary(int_model <- gls(CV ~ 1, data = moving_statistics, correlation = 
corARMA(p=arorder), method="ML"))
summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics, 
correlation = corARMA(p=arorder), method="ML"))
#extract statistics for sample path y
pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
pvalue_cv$slope_time[y] <- time_model$coefficients[2]
}


When I run the simulation, there are some sample paths for which AR(2) 
has the lowest AIC and so this is the model called, as in

summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics, 
correlation = corARMA(p=2), method="ML"))


This call appears to always generate this error message

Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
   Coefficient matrix not invertible

Here are my questions:

1. how does ar generate an AIC value for p =2 even though the 
coefficient matrix is not invertible and so the model fit fails?

2. Is there a way to actually fit such a model, say, by adjusting 
tolerances?

3. a related thread 
(http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)

indicates that there are too many parameters being estimated given the 
length of the time series.

Is there a numerical criterion that can be queried before the gls call 
so that I can test for invertibility and fit, say, a lower order model 
(e.g., AR(1)), so as to avoid an error?

I cannot figure out from the code for gls what actually generates the 
error message. A pointer to the specific numerical criterion that 
generates this error would be very much appreciated.

In the stackoverflow thread, this is mentioned:

The general rule of thumb is that you should have at least 10 times as 
many data points as parameters, and that's for standard fixed 
effect/regression parameters. (Generally variance structure parameters 
such as AR parameters are even a bit harder/require a bit more data than 
regression parameters to estimate.)

Where in the literature is this rule discussed?

4. If the only option is to fit a lower order model of error, say, 
AR(1), instead of AR(2), what kind of bias does this generate in the 
analysis?




Many thanks in advance,

S.

-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From bbolker at gmail.com  Sat Jul 30 16:22:20 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 30 Jul 2016 10:22:20 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
 invertible
In-Reply-To: <fd5f7d1d-a498-bfde-c670-514b21cdb858@freshpond.org>
References: <fd5f7d1d-a498-bfde-c670-514b21cdb858@freshpond.org>
Message-ID: <c4c5b58e-39f0-89f9-f443-2002b10c443f@gmail.com>



On 16-07-29 06:12 PM, Steven Orzack wrote:
>  I am analyzing time series of a statistic (coefficient of variation or
> CV) generated by a Monte Carlo simulation of population dynamics. A
> given simulation might generate thousands of such time series.
> 
> For any given time series, the sequential estimates of CV are correlated
> with one another (because they are based on partially overlapping sets
> of the population numbers). Accordingly, I am using gls models with
> autocorrelated errors to analyze each time series.
> 
> Although the stochastic process generating all sample paths is the same,
> any given sample path might consist of a time series of CV for which
> AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced
> by ar() (see below).
> 
> In practice, I have seen time series for which AR(0), AR(1), AR(2)
> generate the smallest AIC value and so always just using a specific
> order (e.g., AR(1)) does not seem appropriate. This is especially so
> because I am developing methods that would apply to time series for
> which the generating dynamics are not known.
> 
> For any given sample path y, the code is
> 
> #assess order of AR model using ar. use order with smallest AIC
> arorder <- ar(moving_statistics$CV, order.max = 5)$order
> 
> #evaluate model with constant and time
> if (arorder < 1) {
> summary(int_model <- lm(CV ~ 1, data = moving_statistics))
> summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))
> 
> #extract statistics for sample path y
> pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
> pvalue_cv$slope_time[y] <- time_model$coefficients[2]
> } else {
> summary(int_model <- gls(CV ~ 1, data = moving_statistics, correlation =
> corARMA(p=arorder), method="ML"))
> summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
> correlation = corARMA(p=arorder), method="ML"))
> #extract statistics for sample path y
> pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
> pvalue_cv$slope_time[y] <- time_model$coefficients[2]
> }
> 
> 
> When I run the simulation, there are some sample paths for which AR(2)
> has the lowest AIC and so this is the model called, as in
> 
> summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
> correlation = corARMA(p=2), method="ML"))
> 
> 
> This call appears to always generate this error message
> 
> Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
>   Coefficient matrix not invertible
> 
> Here are my questions:
> 
> 1. how does ar generate an AIC value for p =2 even though the
> coefficient matrix is not invertible and so the model fit fails?

  gls and ar are using different algorithms.  Furthermore, I think ar()
is assuming a constant mean whereas your gls() has a linear effect of
time, so they're actually trying to fit different models.


> 2. Is there a way to actually fit such a model, say, by adjusting
> tolerances?

  Don't know.  I would start by debugging my way through the gls code to
say where it is actually breaking.  I don't think I have much to say
other than what I already said in the SO thread you reference below.
> 
> 3. a related thread
> (http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)
> 
> 
> indicates that there are too many parameters being estimated given the
> length of the time series.
> 
> Is there a numerical criterion that can be queried before the gls call
> so that I can test for invertibility and fit, say, a lower order model
> (e.g., AR(1)), so as to avoid an error?

  You could certainly wrap this attempt in a try() or tryCatch() clause
so that it wouldn't break your simulation run and you could then fall
back on AR(1) ...

> 
> I cannot figure out from the code for gls what actually generates the
> error message. A pointer to the specific numerical criterion that
> generates this error would be very much appreciated.

  Unpacking the nlme source code and searching for the error message
finds it on line 557 of src/corStruct.c:

   F77_CALL(dqrdc2) (coef, &P, &P, &P,  &sqrt_eps, &i, qraux, pivot, w\
ork);
            if (i < P)
                error(_("Coefficient matrix not invertible" ));


https://svn.r-project.org/R/trunk/src/appl/dqrdc2.f

says that dqrdc2 is a Householder transformation, but you'd really have
to figure this out for yourself ...

  the i parameter corresponds to a k argument inside the FORTRAN
function: "k contains the number of columns of x judged to be linearly
independent." so it looks like you end up with a rank-deficient matrix
at some point.
> 
> In the stackoverflow thread, this is mentioned:
> 
> The general rule of thumb is that you should have at least 10 times as
> many data points as parameters, and that's for standard fixed
> effect/regression parameters. (Generally variance structure parameters
> such as AR parameters are even a bit harder/require a bit more data than
> regression parameters to estimate.)
> 
> Where in the literature is this rule discussed?

  I got it from Frank Harrell's _Regression Modeling Strategies_ book.

> 4. If the only option is to fit a lower order model of error, say,
> AR(1), instead of AR(2), what kind of bias does this generate in the
> analysis?
> 

   Don't know.  Since you're running simulations, you could find out ...
> 
> 
> Many thanks in advance,
> 
> S.
>


From bbolker at gmail.com  Sat Jul 30 17:07:35 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 30 Jul 2016 11:07:35 -0400
Subject: [R-sig-ME] Fwd: Multinomial response variable
In-Reply-To: <CAJhU6eGrPnDmt3kc_AoCchB0SG54kgnPhpVZEmpe5KNLL72upw@mail.gmail.com>
References: <CAJhU6eEea677Evite3YadG66f3=pbXWrw3oRJngiQtFvnePPKA@mail.gmail.com>
	<CAJhU6eGrPnDmt3kc_AoCchB0SG54kgnPhpVZEmpe5KNLL72upw@mail.gmail.com>
Message-ID: <6bed1014-35a7-adc0-5e39-88881da64d07@gmail.com>


  I think I replied privately that MCMCglmm can handle multinomial
models, and that library(sos); findFn("{multinomial mixed model}") finds
the mme package ...

  There are no immediate plans to make lme4 do multinomial models. It
can probably be done reasonably straightforwardly by decomposing the
problem into a series of parallel binomial models, but it's enough of a
nuisance and an effort to do it that it's pretty low on the development
list ...

On 16-07-22 05:18 PM, C?lia Sofia Moreira wrote:
> Dear All,
> 
> Thank you very much for the lme4 R package. It is really, really useful!
> 
> I have a problem concerning this package. I want to study the following
> model given by the formula:
> 'y ~ time + (1| id)',
> where 'y', 'time', and 'id' are factors, nominal but non ordered, with 4, 2
> and 60 levels, respectively.
> 
> Thus, to perform the model using lme4, I would need 'family=multinomial'.
> However, for the best of my knowledge, this family is not available in
> lme4. Can you please suggest me an alternative option to conduct this
> study? Do you plan to extend lme4 to this family in a near future?
> 
> Kind regards,
>   celia
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Sat Jul 30 17:16:07 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 30 Jul 2016 11:16:07 -0400
Subject: [R-sig-ME] lme4 random effects for repeated measures,
 unbalanced data
In-Reply-To: <CAKm59J-jadP-8mUga7B8DwSO+=kzEBr-nthibwBM8JdcDUe9PA@mail.gmail.com>
References: <CAKm59J-jadP-8mUga7B8DwSO+=kzEBr-nthibwBM8JdcDUe9PA@mail.gmail.com>
Message-ID: <de3be868-c64c-052c-00db-436e3abd5708@gmail.com>



On 16-07-19 07:28 PM, Ann Marie Raymondi wrote:
> Hello Listers,
> 
> I have a vegetation data set that consists of 150 plots that were sampled
> 1-3 times over a three year period.  Plots are my unit of observation and
> they are unbalanced (since plots were sampled either once, twice, or three
> times).  I would like to use mixed-effects models in order to account for
> variation in both plots and sampling year and to keep my sample size large
> (instead of conducting my analysis within individual years). Here is an
> example of the grouping of my data:
> 
> Plot_ID       Plot     Year
> 2012_101   101     2012
> 2013_101   101     2013
> 2014_101   101     2014
> 2012_201   201     2012
> 2013_201   201     2013
> 2013_301   301     2013
> 
> My response variables are cover of vegetation functional groups and
> predictors include variables related to fire and treatment history.
> Additionally, I am not interested in how plots change over time per se, but
> rather, in aggregating sampling from all three years to increase my sample
> size and to account for the spatial/temporal correlation that arises from
> doing so.  It is my assumption that treating plot as a random effect
> (intercept only) accounts for variation that arises from potential spatial
> autocorrelation, but my main question is how to account for the repeated
> measures and if I need to account for the grouping of cells within sampling
> years:
> 
> Potential model:
> 
> model<-lmer(response~covariates + (1|Plot) + (1|Year).
> 
> However, I know that is not appropriate to use a random effect with only
> three levels, year in this case.  I'm hoping for recommendations on how to
> incorporate year as a random effect.  Is including (Year |  Plot)
>  recommended?  And if so, how might I interpret that effect, i.e., is it
> accounting for variation introduced by different sampling year or variation
> in plots over sampling year?

> Thank you in advance for any help/suggestions!
>

  Include Year as a fixed effect.  You could try to include (Year|Plot),
but it will overlap with the residual error (since each plot is measured
once per year), so it probably won't work (without some more fussing
around).  You'll probably get most of the signal by including Year as a
fixed effect.


From timothy.gregoire at yale.edu  Sun Jul 31 14:14:07 2016
From: timothy.gregoire at yale.edu (Gregoire, Timothy)
Date: Sun, 31 Jul 2016 12:14:07 +0000
Subject: [R-sig-ME] try lme instead
Message-ID: <BLUPR0801MB1650228029042DAD416F40CBE3030@BLUPR0801MB1650.namprd08.prod.outlook.com>

With lme of the nlme package you can specify a correlation argument to account for longitudinal correlation. Try a CAR1 correlation.

Tim 

Timothy G. Gregoire
J. P. Weyerhaeuser Professor of Forest Management
School of Forestry & Environmental Studies
Yale University
360 Prospect St, New Haven, CT, U.S.A. 06511
Ph: 1.203.432.9398 mob: 1.203.508.4014? fax:1.203.432.3809


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Sunday, July 31, 2016 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 115, Issue 39

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=CwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=0bsxPbgQhfwtIO1cgoQfJt24FzLV6A7sHDNIpLCPdZY&s=1hHtoI5s_g99seFW7TN4ouNfHYBmeuLcge-Zu332o24&e=
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: lme4 random effects for repeated measures, unbalanced
      data (Ben Bolker)


----------------------------------------------------------------------

Message: 1
Date: Sat, 30 Jul 2016 11:16:07 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lme4 random effects for repeated measures,
	unbalanced data
Message-ID: <de3be868-c64c-052c-00db-436e3abd5708 at gmail.com>
Content-Type: text/plain; charset=windows-1252



On 16-07-19 07:28 PM, Ann Marie Raymondi wrote:
> Hello Listers,
> 
> I have a vegetation data set that consists of 150 plots that were 
> sampled
> 1-3 times over a three year period.  Plots are my unit of observation 
> and they are unbalanced (since plots were sampled either once, twice, 
> or three times).  I would like to use mixed-effects models in order to 
> account for variation in both plots and sampling year and to keep my 
> sample size large (instead of conducting my analysis within individual 
> years). Here is an example of the grouping of my data:
> 
> Plot_ID       Plot     Year
> 2012_101   101     2012
> 2013_101   101     2013
> 2014_101   101     2014
> 2012_201   201     2012
> 2013_201   201     2013
> 2013_301   301     2013
> 
> My response variables are cover of vegetation functional groups and 
> predictors include variables related to fire and treatment history.
> Additionally, I am not interested in how plots change over time per 
> se, but rather, in aggregating sampling from all three years to 
> increase my sample size and to account for the spatial/temporal 
> correlation that arises from doing so.  It is my assumption that 
> treating plot as a random effect (intercept only) accounts for 
> variation that arises from potential spatial autocorrelation, but my 
> main question is how to account for the repeated measures and if I 
> need to account for the grouping of cells within sampling
> years:
> 
> Potential model:
> 
> model<-lmer(response~covariates + (1|Plot) + (1|Year).
> 
> However, I know that is not appropriate to use a random effect with 
> only three levels, year in this case.  I'm hoping for recommendations 
> on how to incorporate year as a random effect.  Is including (Year |  
> Plot)  recommended?  And if so, how might I interpret that effect, 
> i.e., is it accounting for variation introduced by different sampling 
> year or variation in plots over sampling year?

> Thank you in advance for any help/suggestions!
>

  Include Year as a fixed effect.  You could try to include (Year|Plot), but it will overlap with the residual error (since each plot is measured once per year), so it probably won't work (without some more fussing around).  You'll probably get most of the signal by including Year as a fixed effect.



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=CwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=0bsxPbgQhfwtIO1cgoQfJt24FzLV6A7sHDNIpLCPdZY&s=1hHtoI5s_g99seFW7TN4ouNfHYBmeuLcge-Zu332o24&e= 

------------------------------

End of R-sig-mixed-models Digest, Vol 115, Issue 39


From bbolker at gmail.com  Sun Jul 31 14:17:49 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 31 Jul 2016 08:17:49 -0400
Subject: [R-sig-ME] try lme instead
In-Reply-To: <BLUPR0801MB1650228029042DAD416F40CBE3030@BLUPR0801MB1650.namprd08.prod.outlook.com>
References: <BLUPR0801MB1650228029042DAD416F40CBE3030@BLUPR0801MB1650.namprd08.prod.outlook.com>
Message-ID: <CABghstQkziv0K9B0TNfzvvexPZ=eqMfEOUN-kqVi=eiPPi4Qtw@mail.gmail.com>

  Worth a try, but fitting a correlation model to time series with 3
points won't add very much information to the model (correlation
models are more effective for long time series) ...

On Sun, Jul 31, 2016 at 8:14 AM, Gregoire, Timothy
<timothy.gregoire at yale.edu> wrote:
> With lme of the nlme package you can specify a correlation argument to account for longitudinal correlation. Try a CAR1 correlation.
>
> Tim
>
> Timothy G. Gregoire
> J. P. Weyerhaeuser Professor of Forest Management
> School of Forestry & Environmental Studies
> Yale University
> 360 Prospect St, New Haven, CT, U.S.A. 06511
> Ph: 1.203.432.9398 mob: 1.203.508.4014  fax:1.203.432.3809
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
> Sent: Sunday, July 31, 2016 6:00 AM
> To: r-sig-mixed-models at r-project.org
> Subject: R-sig-mixed-models Digest, Vol 115, Issue 39
>
> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=CwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=0bsxPbgQhfwtIO1cgoQfJt24FzLV6A7sHDNIpLCPdZY&s=1hHtoI5s_g99seFW7TN4ouNfHYBmeuLcge-Zu332o24&e=
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: lme4 random effects for repeated measures, unbalanced
>       data (Ben Bolker)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 30 Jul 2016 11:16:07 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] lme4 random effects for repeated measures,
>         unbalanced data
> Message-ID: <de3be868-c64c-052c-00db-436e3abd5708 at gmail.com>
> Content-Type: text/plain; charset=windows-1252
>
>
>
> On 16-07-19 07:28 PM, Ann Marie Raymondi wrote:
>> Hello Listers,
>>
>> I have a vegetation data set that consists of 150 plots that were
>> sampled
>> 1-3 times over a three year period.  Plots are my unit of observation
>> and they are unbalanced (since plots were sampled either once, twice,
>> or three times).  I would like to use mixed-effects models in order to
>> account for variation in both plots and sampling year and to keep my
>> sample size large (instead of conducting my analysis within individual
>> years). Here is an example of the grouping of my data:
>>
>> Plot_ID       Plot     Year
>> 2012_101   101     2012
>> 2013_101   101     2013
>> 2014_101   101     2014
>> 2012_201   201     2012
>> 2013_201   201     2013
>> 2013_301   301     2013
>>
>> My response variables are cover of vegetation functional groups and
>> predictors include variables related to fire and treatment history.
>> Additionally, I am not interested in how plots change over time per
>> se, but rather, in aggregating sampling from all three years to
>> increase my sample size and to account for the spatial/temporal
>> correlation that arises from doing so.  It is my assumption that
>> treating plot as a random effect (intercept only) accounts for
>> variation that arises from potential spatial autocorrelation, but my
>> main question is how to account for the repeated measures and if I
>> need to account for the grouping of cells within sampling
>> years:
>>
>> Potential model:
>>
>> model<-lmer(response~covariates + (1|Plot) + (1|Year).
>>
>> However, I know that is not appropriate to use a random effect with
>> only three levels, year in this case.  I'm hoping for recommendations
>> on how to incorporate year as a random effect.  Is including (Year |
>> Plot)  recommended?  And if so, how might I interpret that effect,
>> i.e., is it accounting for variation introduced by different sampling
>> year or variation in plots over sampling year?
>
>> Thank you in advance for any help/suggestions!
>>
>
>   Include Year as a fixed effect.  You could try to include (Year|Plot), but it will overlap with the residual error (since each plot is measured once per year), so it probably won't work (without some more fussing around).  You'll probably get most of the signal by including Year as a fixed effect.
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=CwICAg&c=-dg2m7zWuuDZ0MUcV7Sdqw&r=atRKEKX5W2zm-GsIgYzLo4oYM9D-Qn-eMFObHZtnEnI&m=0bsxPbgQhfwtIO1cgoQfJt24FzLV6A7sHDNIpLCPdZY&s=1hHtoI5s_g99seFW7TN4ouNfHYBmeuLcge-Zu332o24&e=
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 115, Issue 39
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Mon Aug  1 03:50:24 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 31 Jul 2016 21:50:24 -0400
Subject: [R-sig-ME] Replicating analysis in asreml in lme4
In-Reply-To: <CA+0rMg=bpxedA1m3wMm0rcSketuf+KY=4CY=R25evm=G10f5Qw@mail.gmail.com>
References: <CA+0rMg=bpxedA1m3wMm0rcSketuf+KY=4CY=R25evm=G10f5Qw@mail.gmail.com>
Message-ID: <a9e6fc12-c3c0-f381-ca8e-aff6b08a0a3d@gmail.com>


 Try the lsmeans package ...

On 16-07-30 01:41 AM, Aravind J. wrote:
> Dear members,
> 
> I am trying to reproduce analyse an alpha lattice design (an unbalanced
> design) in  `lme4`.
> 
> https://cran.r-project.org/web/packages/agridat/agridat.pdf#page.184
> 
> library(agridat)
> library(lme4)
> 
> The model can be fitted in lme4
> 
> # genotypes - fixed
> model <- lmer(yield ~ 0 + gen + rep + (1|rep:block), dat)
> # genotypes - random
> model <- lmer(yield ~ 0 + (1|gen) + rep + (1|rep:block), dat)
> 
> However further calculations seem to required `asreml`.
> 
> library(asreml)
> 
> m3 <- asreml(yield ~ 1 + rep, data=dat, random=~ gen + rep:block)
> sg2 <- summary(m3)$varcomp[1,'component']
> vblup <- predict(m3, classify="gen")$pred$avsed ^ 2
> 
> m3 <- asreml(yield ~ 1 + gen + rep, data=dat, random = ~ rep:block)
> vblue <- predict(m3, classify="gen")$pred$avsed ^ 2
> sg2 / (sg2 + vblue/2)
> 1-(vblup / 2 / sg2)
> 
> Here `avsed` is the "mean variance of difference of adjusted means" (BLUP
> or BLUE). Is it possible to replicate the last part also in `lme4`?
> 
> `avsed` can be computed from the "variance-covariance matrix of adjusted
> means" for genotypes. (
> https://static-content.springer.com/esm/art%3A10.1186%2F1471-2164-14-860/MediaObjects/12864_2013_5591_MOESM1_ESM.doc).
> How to get that matrix from lme4?
> 
> 
> Warm Regards,
>


From shebrahimi_3622 at yahoo.com  Mon Aug  1 03:55:27 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Mon, 1 Aug 2016 01:55:27 +0000 (UTC)
Subject: [R-sig-ME] cross validation on discrete time survival analysis
In-Reply-To: <418996742.5797549.1469528874696.JavaMail.yahoo@mail.yahoo.com>
References: <2082726117.1626150.1468323505133.JavaMail.yahoo.ref@mail.yahoo.com>
	<2082726117.1626150.1468323505133.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTTT=JEiJsZCAwKUC-tgQm8x=uQ37fp_Aojf49nGOO9qJg@mail.gmail.com>
	<398951196.1820955.1468332795112.JavaMail.yahoo@mail.yahoo.com>
	<CAFyVWTRNUjJ6YjXHExhSow-3edciyoK+=R=NhZg77ET8ssL6LQ@mail.gmail.com>
	<888544502.3206200.1468512834710.JavaMail.yahoo@mail.yahoo.com>
	<475069987.3339139.1468523368368.JavaMail.yahoo@mail.yahoo.com>
	<590508458.3680687.1468550627850.JavaMail.yahoo@mail.yahoo.com>
	<1041593015.3668892.1468551465655.JavaMail.yahoo@mail.yahoo.com>
	<404681957.3563921.1468552844309.JavaMail.yahoo@mail.yahoo.com>
	<1072898021.3609015.1468559774467.JavaMail.yahoo@mail.yahoo.com>
	<1295208167.3620691.1468560399025.JavaMail.yahoo@mail.yahoo.com>
	<1742164238.3652376.1468577707758.JavaMail.yahoo@mail.yahoo.com>
	<1664168494.3988717.1468600842928.JavaMail.yahoo@mail.yahoo.com>
	<18389920.95090.1468638905767.JavaMail.yahoo@mail.yahoo.com>
	<1469054561.84641.1468641025575.JavaMail.yahoo@mail.yahoo.com>
	<1856196443.1538289.1468908444286.JavaMail.yahoo@mail.yahoo.com>
	<418996742.5797549.1469528874696.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <667548526.1260234.1470016528069.JavaMail.yahoo@mail.yahoo.com>

Dear Dr.

Greetings
I would be very grateful if you could let me know how to do cross validation when estimating a discrete time survival analysis in R.
ID TIME EVENT  x1       x2    x3      x4       x5
1   1   0   1.281   0.023   0.875   1.216   0.061
1   2   0   1.270   0.006   0.821   1.005   -0.014
1   3   0   1.053   -0.059  0.922   0.729   0.020
1   4   0   1.113   -0.015  0.859   0.810   0.076
1   5   1   1.220   -0.059  0.887   0.484   0.010
2   1   0   1.062   0.107   0.815   0.836   0.200
2   2   0   1.056   0.082   0.879   0.687   0.143
2   3   0   0.971   0.076   0.907   0.810   0.166
2   4   0   1.059   0.130   0.818   0.876   0.234
2   5   0   1.125   0.148   0.759   1.080   0.276
2   6   0   1.600   0.262   0.546   1.313   0.369
2   7   0   1.576   0.262   0.564   1.156   0.349
2   8   0   1.544   0.241   0.591   1.077   0.326
2   9   0   1.722   0.215   0.552   0.841   0.293
2   10  0   1.723   0.209   0.534   0.787   0.293
2   11  0   1.631   0.186   0.548   0.728   0.274
2   12  0   2.172   0.319   0.441   0.947   0.427
3   1   0   0.874   -0.035  0.794   0.610   -0.003
3   2   1   0.825   -0.142  0.952   0.573   -0.019
 require(lme4) model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial) p <- as.numeric(predict(model, type="response")>0.5) acc=mean(p==df$EVENT)
Is it right to do this:

accuracy = function(pred, test_data){
num.correct.negatives = sum((pred == test_data$EVENT) & (test_data$EVENT==0))
num.correct.positives = sum((p == test_data$EVENT) & (test_data$EVENT==1))
num.false.negatives = sum((pred != test_data$EVENT) & (test_data$EVENT==1))
num.false.positives = sum((pred != test_data$EVENT) & (test_data$EVENT==0))

ppv = num.correct.positives / (num.false.positives + num.correct.positives)
npv = num.correct.negatives / (num.false.negatives + num.correct.negatives)
return(list(ppv = ppv, npv = npv))
}
df = read.table(file='clipboard', header=T)
idx_train =  sapply(unique(df$ID), function(x){
   sample(which(df$ID %in% x), 1)
  }
)

#if you wish to sample based only on time. Note that k=5 here.
#idx_train = which(df$TIME %in% sample(unique(df$TIME), 5))
df_train = df[idx_train, ]
df_test = df[-idx_train,]

#perform training on training dataset
require(lme4)
model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df_train, family=binomial)
p <- as.numeric(predict(model, newdata = df_test, type="response")>0.5)

#cross validate
accuracy(p, df_test)

Thanks in advance.Best regards,   
   

   
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Aug  1 04:06:08 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 31 Jul 2016 22:06:08 -0400
Subject: [R-sig-ME] model advice
In-Reply-To: <1469671421430.15990@ufl.edu>
References: <1469671421430.15990@ufl.edu>
Message-ID: <778395be-ba6a-e736-51fd-b18a8aa2b6f6@gmail.com>



On 16-07-27 10:03 PM, Guy,Travis J wrote: > Hello!  >

> I'm a master's student studying pollination networks. I have been
furiously trying to learn about linear mixed models and glmms, but I
have some specific questions relating to my project analysis that I am
hoping someone can help me with


> Here's the short of my project. I can provide more details if need
  be. I am looking at 16 pollination metrics (ex. specialization). A
  few of the metrics are count data (ex. floral abundance) and several
  are proportions (limited to be between 0 and 1). I am interested in
  how rainfall (high and low location) and wildlife exclusion
  (treatment) affect the pollination metrics. I have constructed 12
  networks in total. 6 networks in the low rainfall area having 3
  networks with wildlife excluded and 3 networks allowing
  wildlife. Then there are 6 networks in the high rainfall area again
  have 3 networks with wildlife excluded and 3 with wildlife
  included. So sample size is obviously small. It's a block design
  with 3 blocks in the low rainfall and 3 blocks in the south
  location. Each block has the wildlife excluded treatment and the
  wildlife allowed treatment.

> Here are my questions:

> The majority of my metrics fit model assumptions (normality of
  residuals, variance within groups, normality within groups,
  normality of random effects, and linearity/absence of
  heteroskedasticity). However I have some where normality appear to
  be violated and the fitted vs residuals plot is no good. Various
  transformations (log, ln, sqrt,arcsin(sqrt)) don't seem to help.
  From reading papers by Dr. Ben Bolker, this is where it appears
  GLMMs come in.

> So for the metrics that fit model assumptions my plan is to fit this model

  metric.model <- lmer(metric ~ Treatment + Location + (1 |Blocks),
    data = UHURUnets)

>  but for those where model assumptions aren't met, I'm not sure how
> one picks which exponential family to use and which link to use. How
> does one go about deciding what family and link to use?

   This is really a general question about generalized linear models,
not about GLMMs - there are a fair number of questions (& answers)
on CrossValidated:

http://stats.stackexchange.com/search?q=glm+which+distribution

> I read in Dr. Bolker's TREE paper that binomial distribution and
  logit link are best for proportions. Is this generally the case?

   That depends.  If you know the denominator (i.e. maximum possible
number, also referred to as N), which would seem to be the case (in
your case it would be the total number of species available for
pollination, I guess?), then binomial/logit makes sense.

  If your response is weighted (as suggested by
the variable name) it might get a little tricky, but as long
as it seems sensible to set a maximum number on the possible
responses it should be OK (although you will get warnings).
You do need to include the N, in this case probably via a 'weights'
argument

> NODF.M1 <- glmer(weighted_NODF ~ Treatment + Location + (1|Blocks),
  data = UHURUnets, family = binomial(link = "logit")?


> For the count data (ex. floral abundance, insect abundance), it
  seems like I should use Poisson and log link according to that same
  paper paper.

> No.Fl.units.M1 <- glmer(number_of_floral_units ~ Treatment +
  Location + (1|Blocks), data = UHURUnets, family = poisson(link =
  "log")?

seems reasonable, although you should make sure to account for
overdispersion


> But what distribution and link would one use for continuous data
  that is not in proportions?

Generally your best hope for continuous data is a transformation.
You can use a Gamma for data that are positive, but log-transformation
followed by a linear mixed model is often reasonable too.  We would
probably need more information.

> And once you have made a GLMM model, I am assuming it is okay that
  this model still does not fit the normality assumptions or the
  residual vs fitted plots. Is this true?

well, the residuals should still **approximately** fit these
assumptions (worst for binary data)

> My models (both glmms and lmer) currently only have random
  intercepts. I have read that it might be wise to also have random
  slopes as well because the pollination metric could vary for each
  treatment and location depending on which block it is in.

Yes, although it can be hard to get enough data to make this
worthwhile.

> So then I believe I would have a model like this
> ?
> Vuln.LL.M3 <- glmer(vulnerability.LL ~ Treatment + Location + (1 +
Treatment|Blocks) + (1 + Location|Blocks), family = gaussian(link =
log), data = UHURUnets)

> I am not sure if this is correct. I get 2 warnings (failed to converge
and unable to evaluated scaled gradient). Interestingly I appear to not
get these warnings if I am running linear mixed models (lmer). Am I
doing this correctly?

  Probably. There are lots of false positives.  See ?convergence

> Lastly, is it appropriate to use interaction terms in GLMMs and lmers?
I imagine that the rainfall level my interact with the treatment to
influence the pollination metric.


>  metric.model <- glmer(metric ~ Treatment*Location + (1 |Blocks), data
= UHURUnets, family = gaussian(link = log)??)
>

  Definitely OK.


From arianna.cecchetti at uac.pt  Mon Aug  1 15:26:36 2016
From: arianna.cecchetti at uac.pt (Arianna Cecchetti)
Date: Mon, 1 Aug 2016 13:26:36 +0000
Subject: [R-sig-ME] MCMCglmm function
In-Reply-To: <8DC65324-9455-492F-B7CF-A0FC5200B9D8@uac.pt>
References: <8DC65324-9455-492F-B7CF-A0FC5200B9D8@uac.pt>
Message-ID: <F911113C-2A01-4234-AB90-D7041CB94398@uac.pt>

Dear Prof. Bolker,

I am trying to find the best model to fit a set of data which are temporally correlated and which involve a factor response variable including three levels. I would like to test a GLMM and possibly compare it with a multinomial GEE.
However, all the examples I found for GLMM using a factor as response variable are binomial and family options for the glmer function in R do not include multinomial. When I run it without specifying the family it automatically performs a LMM with a Gaussian distribution and besides not being sure it is a suitable option the output doesn?t show the levels of each explanatory factor variable.
I found that the multinomial family is an option for the MCMCglmm function which also deals with temporal correlation, however when it comes to select the random effect I have a doubt and I am not sure I am understanding how to set it correctly. I have been reading the function help file in R and the paper ?GLMMs in action? however I have still doubts.

The data I am using are temporally correlated at sequence level (i.e. all data are correlated within each sequence cluster) and I set this variable as random effect. Do all fixed variable need to be included at once in the random specification?

It didn?t seem so in one example, so I was trying the following code. However, it failed giving the error ?unexpected input in model <- ?? guessing there is a syntax error but I have not been able to detect it. I include a subset of the data.

trial <- read.csv(?swd.csv?, sep=?,? , header=T)
trial$Dolphins.response=as.factor(trial$Dolphins.response)
trial$Behaviour=as.factor(trial$Behaviour)
trial$N.Sequence=as.factor(trial$N.Sequence)

model <- MCMCglmm(Dolphins.response~Species + Boat.placement + Behaviour + Calves + Group.size + N.Swimmers , random=~idh(N.Swimmers):N.Sequence, data=trial, family=?multinomial?,  verbose=FALSE)


Any suggestion to get me on the right track is very much appreciated!

Thank you very much!

Best wishes,

Arianna




From orzack at freshpond.org  Sun Jul 31 18:27:28 2016
From: orzack at freshpond.org (Steven Orzack)
Date: Sun, 31 Jul 2016 12:27:28 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
	invertible
Message-ID: <a1caa164-36e3-1683-86c6-5bf63a1432cf@freshpond.org>

  Ben, Many thanks for the informative reply. I will work on this in the 
next few days and update. Once upon a time, I knew about Householder 
transformations. I will try to dust off that part of my brain.....

I am especially interested in the fact that ar and gls are using 
different algorithms. If you could expand on that, it would very 
helpful. I will also investigate.

any information and thoughts are most welcome.



S.

On 16-07-29 06:12 PM, Steven Orzack wrote:

 > I am analyzing time series of a statistic (coefficient of variation or
 > CV) generated by a Monte Carlo simulation of population dynamics. A
 > given simulation might generate thousands of such time series.
 >
 > For any given time series, the sequential estimates of CV are correlated
 > with one another (because they are based on partially overlapping sets
 > of the population numbers). Accordingly, I am using gls models with
 > autocorrelated errors to analyze each time series.
 >
 > Although the stochastic process generating all sample paths is the same,
 > any given sample path might consist of a time series of CV for which
 > AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced
 > by ar() (see below).
 >
 > In practice, I have seen time series for which AR(0), AR(1), AR(2)
 > generate the smallest AIC value and so always just using a specific
 > order (e.g., AR(1)) does not seem appropriate. This is especially so
 > because I am developing methods that would apply to time series for
 > which the generating dynamics are not known.
 >
 > For any given sample path y, the code is
 >
 > #assess order of AR model using ar. use order with smallest AIC
 > arorder <- ar(moving_statistics$CV, order.max = 5)$order
 >
 > #evaluate model with constant and time
 > if (arorder < 1) {
 > summary(int_model <- lm(CV ~ 1, data = moving_statistics))
 > summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))
 >
 > #extract statistics for sample path y
 > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
 > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
 > } else {
 > summary(int_model <- gls(CV ~ 1, data = moving_statistics, correlation =
 > corARMA(p=arorder), method="ML"))
 > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
 > correlation = corARMA(p=arorder), method="ML"))
 > #extract statistics for sample path y
 > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
 > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
 > }
 >
 >
 > When I run the simulation, there are some sample paths for which AR(2)
 > has the lowest AIC and so this is the model called, as in
 >
 > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
 > correlation = corARMA(p=2), method="ML"))
 >
 >
 > This call appears to always generate this error message
 >
 > Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
 >   Coefficient matrix not invertible
 >
 > Here are my questions:
 >
 > 1. how does ar generate an AIC value for p =2 even though the
 > coefficient matrix is not invertible and so the model fit fails?

   gls and ar are using different algorithms.  Furthermore, I think ar()
is assuming a constant mean whereas your gls() has a linear effect of
time, so they're actually trying to fit different models.


 > 2. Is there a way to actually fit such a model, say, by adjusting
 > tolerances?

   Don't know.  I would start by debugging my way through the gls code to
say where it is actually breaking.  I don't think I have much to say
other than what I already said in the SO thread you reference below.
 >
 > 3. a related thread
 > 
(http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)
 >
 >
 > indicates that there are too many parameters being estimated given the
 > length of the time series.
 >
 > Is there a numerical criterion that can be queried before the gls call
 > so that I can test for invertibility and fit, say, a lower order model
 > (e.g., AR(1)), so as to avoid an error?

   You could certainly wrap this attempt in a try() or tryCatch() clause
so that it wouldn't break your simulation run and you could then fall
back on AR(1) ...

 >
 > I cannot figure out from the code for gls what actually generates the
 > error message. A pointer to the specific numerical criterion that
 > generates this error would be very much appreciated.

   Unpacking the nlme source code and searching for the error message
finds it on line 557 of src/corStruct.c:

    F77_CALL(dqrdc2) (coef, &P, &P, &P,  &sqrt_eps, &i, qraux, pivot, w\
ork);
             if (i < P)
                 error(_("Coefficient matrix not invertible" ));


https://svn.r-project.org/R/trunk/src/appl/dqrdc2.f

says that dqrdc2 is a Householder transformation, but you'd really have
to figure this out for yourself ...

   the i parameter corresponds to a k argument inside the FORTRAN
function: "k contains the number of columns of x judged to be linearly
independent." so it looks like you end up with a rank-deficient matrix
at some point.
 >
 > In the stackoverflow thread, this is mentioned:
 >
 > The general rule of thumb is that you should have at least 10 times as
 > many data points as parameters, and that's for standard fixed
 > effect/regression parameters. (Generally variance structure parameters
 > such as AR parameters are even a bit harder/require a bit more data than
 > regression parameters to estimate.)
 >
 > Where in the literature is this rule discussed?

   I got it from Frank Harrell's _Regression Modeling Strategies_ book.

 > 4. If the only option is to fit a lower order model of error, say,
 > AR(1), instead of AR(2), what kind of bias does this generate in the
 > analysis?
 >

    Don't know.  Since you're running simulations, you could find out ...
 >
 >
 > Many thanks in advance,
 >
 > S.
 >

-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From bbolker at gmail.com  Mon Aug  1 17:16:59 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 1 Aug 2016 11:16:59 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
 invertible
In-Reply-To: <a1caa164-36e3-1683-86c6-5bf63a1432cf@freshpond.org>
References: <a1caa164-36e3-1683-86c6-5bf63a1432cf@freshpond.org>
Message-ID: <0bca5d0e-bd74-d2c7-c049-fedb4434c98c@gmail.com>



On 16-07-31 12:27 PM, Steven Orzack wrote:
>  Ben, Many thanks for the informative reply. I will work on this in the
> next few days and update. Once upon a time, I knew about Householder
> transformations. I will try to dust off that part of my brain.....
> 
> I am especially interested in the fact that ar and gls are using
> different algorithms. If you could expand on that, it would very
> helpful. I will also investigate.
> 
> any information and thoughts are most welcome.


  gls uses generalized least squares -- described in detail in Pinheiro
and Bates 2000 -- basically, nonlinear optimization over the correlation
parameter, minimizing the sums of squares of the 'whitened' residuals.
   For ar, see ?ar: the default solves the Yule-Walker equations (see
ar.yw) ...

  As I hinted, if I had to do this I would (1) build my own brute-force
AR solver (probably based on nlme::corARMA), (2) use try() to catch the
cases where AR(2) failed and revert to AR(1)


> 
> 
> 
> S.
> 
> On 16-07-29 06:12 PM, Steven Orzack wrote:
> 
>> I am analyzing time series of a statistic (coefficient of variation or
>> CV) generated by a Monte Carlo simulation of population dynamics. A
>> given simulation might generate thousands of such time series.
>>
>> For any given time series, the sequential estimates of CV are correlated
>> with one another (because they are based on partially overlapping sets
>> of the population numbers). Accordingly, I am using gls models with
>> autocorrelated errors to analyze each time series.
>>
>> Although the stochastic process generating all sample paths is the same,
>> any given sample path might consist of a time series of CV for which
>> AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced
>> by ar() (see below).
>>
>> In practice, I have seen time series for which AR(0), AR(1), AR(2)
>> generate the smallest AIC value and so always just using a specific
>> order (e.g., AR(1)) does not seem appropriate. This is especially so
>> because I am developing methods that would apply to time series for
>> which the generating dynamics are not known.
>>
>> For any given sample path y, the code is
>>
>> #assess order of AR model using ar. use order with smallest AIC
>> arorder <- ar(moving_statistics$CV, order.max = 5)$order
>>
>> #evaluate model with constant and time
>> if (arorder < 1) {
>> summary(int_model <- lm(CV ~ 1, data = moving_statistics))
>> summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))
>>
>> #extract statistics for sample path y
>> pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
>> pvalue_cv$slope_time[y] <- time_model$coefficients[2]
>> } else {
>> summary(int_model <- gls(CV ~ 1, data = moving_statistics, correlation =
>> corARMA(p=arorder), method="ML"))
>> summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
>> correlation = corARMA(p=arorder), method="ML"))
>> #extract statistics for sample path y
>> pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
>> pvalue_cv$slope_time[y] <- time_model$coefficients[2]
>> }
>>
>>
>> When I run the simulation, there are some sample paths for which AR(2)
>> has the lowest AIC and so this is the model called, as in
>>
>> summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
>> correlation = corARMA(p=2), method="ML"))
>>
>>
>> This call appears to always generate this error message
>>
>> Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
>>   Coefficient matrix not invertible
>>
>> Here are my questions:
>>
>> 1. how does ar generate an AIC value for p =2 even though the
>> coefficient matrix is not invertible and so the model fit fails?
> 
>   gls and ar are using different algorithms.  Furthermore, I think ar()
> is assuming a constant mean whereas your gls() has a linear effect of
> time, so they're actually trying to fit different models.
> 
> 
>> 2. Is there a way to actually fit such a model, say, by adjusting
>> tolerances?
> 
>   Don't know.  I would start by debugging my way through the gls code to
> say where it is actually breaking.  I don't think I have much to say
> other than what I already said in the SO thread you reference below.
>>
>> 3. a related thread
>>
> (http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)
> 
>>
>>
>> indicates that there are too many parameters being estimated given the
>> length of the time series.
>>
>> Is there a numerical criterion that can be queried before the gls call
>> so that I can test for invertibility and fit, say, a lower order model
>> (e.g., AR(1)), so as to avoid an error?
> 
>   You could certainly wrap this attempt in a try() or tryCatch() clause
> so that it wouldn't break your simulation run and you could then fall
> back on AR(1) ...
> 
>>
>> I cannot figure out from the code for gls what actually generates the
>> error message. A pointer to the specific numerical criterion that
>> generates this error would be very much appreciated.
> 
>   Unpacking the nlme source code and searching for the error message
> finds it on line 557 of src/corStruct.c:
> 
>    F77_CALL(dqrdc2) (coef, &P, &P, &P,  &sqrt_eps, &i, qraux, pivot, w\
> ork);
>             if (i < P)
>                 error(_("Coefficient matrix not invertible" ));
> 
> 
> https://svn.r-project.org/R/trunk/src/appl/dqrdc2.f
> 
> says that dqrdc2 is a Householder transformation, but you'd really have
> to figure this out for yourself ...
> 
>   the i parameter corresponds to a k argument inside the FORTRAN
> function: "k contains the number of columns of x judged to be linearly
> independent." so it looks like you end up with a rank-deficient matrix
> at some point.
>>
>> In the stackoverflow thread, this is mentioned:
>>
>> The general rule of thumb is that you should have at least 10 times as
>> many data points as parameters, and that's for standard fixed
>> effect/regression parameters. (Generally variance structure parameters
>> such as AR parameters are even a bit harder/require a bit more data than
>> regression parameters to estimate.)
>>
>> Where in the literature is this rule discussed?
> 
>   I got it from Frank Harrell's _Regression Modeling Strategies_ book.
> 
>> 4. If the only option is to fit a lower order model of error, say,
>> AR(1), instead of AR(2), what kind of bias does this generate in the
>> analysis?
>>
> 
>    Don't know.  Since you're running simulations, you could find out ...
>>
>>
>> Many thanks in advance,
>>
>> S.
>>
>


From bbolker at gmail.com  Mon Aug  1 20:48:15 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 1 Aug 2016 14:48:15 -0400
Subject: [R-sig-ME] MCMCglmm function
In-Reply-To: <F911113C-2A01-4234-AB90-D7041CB94398@uac.pt>
References: <8DC65324-9455-492F-B7CF-A0FC5200B9D8@uac.pt>
	<F911113C-2A01-4234-AB90-D7041CB94398@uac.pt>
Message-ID: <28473d2b-7593-8443-578f-cea26b2f9925@gmail.com>


  Just a quick reminder: while I (a) answer a lot of the posts here and
(b) spend a lot of time encouraging people to post here rather than
e-mailing me privately, this is *not* my e-mail: "Dear list" or "Dear
kind and generous mixed model gurus" (or something like that) would be a
better salutation ...

  have you looked at the section on multinomial models (p. 95) in
vignette("CourseNotes",package="MCMCglmm") yet ... ?

  good luck,
   Ben Bolker

On 16-08-01 09:26 AM, Arianna Cecchetti wrote:
> Dear Prof. Bolker,
> 
> I am trying to find the best model to fit a set of data which are temporally correlated and which involve a factor response variable including three levels. I would like to test a GLMM and possibly compare it with a multinomial GEE.
> However, all the examples I found for GLMM using a factor as response variable are binomial and family options for the glmer function in R do not include multinomial. When I run it without specifying the family it automatically performs a LMM with a Gaussian distribution and besides not being sure it is a suitable option the output doesn?t show the levels of each explanatory factor variable.
> I found that the multinomial family is an option for the MCMCglmm function which also deals with temporal correlation, however when it comes to select the random effect I have a doubt and I am not sure I am understanding how to set it correctly. I have been reading the function help file in R and the paper ?GLMMs in action? however I have still doubts.
> 
> The data I am using are temporally correlated at sequence level (i.e. all data are correlated within each sequence cluster) and I set this variable as random effect. Do all fixed variable need to be included at once in the random specification?
> 
> It didn?t seem so in one example, so I was trying the following code. However, it failed giving the error ?unexpected input in model <- ?? guessing there is a syntax error but I have not been able to detect it. I include a subset of the data.
> 
> trial <- read.csv(?swd.csv?, sep=?,? , header=T)
> trial$Dolphins.response=as.factor(trial$Dolphins.response)
> trial$Behaviour=as.factor(trial$Behaviour)
> trial$N.Sequence=as.factor(trial$N.Sequence)
> 
> model <- MCMCglmm(Dolphins.response~Species + Boat.placement + Behaviour + Calves + Group.size + N.Swimmers , random=~idh(N.Swimmers):N.Sequence, data=trial, family=?multinomial?,  verbose=FALSE)
> 
> 
> Any suggestion to get me on the right track is very much appreciated!
> 
> Thank you very much!
> 
> Best wishes,
> 
> Arianna
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From selebatsom at yahoo.co.uk  Wed Aug  3 11:40:20 2016
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
Subject: [R-sig-ME] lme for data that is not normally distributed
References: <127496753.15122202.1470217220406.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <127496753.15122202.1470217220406.JavaMail.yahoo@mail.yahoo.com>

?Hello
I have some data that I would to analyse with mixed models (lme). As a standard procedure I tested for the normality of the data and it is not normal. Any ideas of how deals with this kind of data? I have a sample below and the model that I was hoping to use (if?the data?was normal)
m <- lme(Distance~Time,random=~1|ID,data=data).


 

 
|

 
| ID |

 
| Time |

 
| Distance |

  
|

 
| 10187A |

 
| Pre_dry |

 
| 4.31287 |

  
|

 
| 10187A |

 
| Pre_dry |

 
| 6.867578 |

  
|

 
| 10187A |

 
| Pre_dry |

 
| 4.640427 |

  
|

 
| 10187A |

 
| Post_dry |

 
| 4.497807 |

  
|

 
| 10187A |

 
| Post_dry |

 
| 9.726069 |

  
|

 
| 10187A |

 
| Post_dry |

 
| 5.150089 |

 


Regards,
Moses SELEBATSO?
	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Aug  3 12:05:44 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 3 Aug 2016 19:35:44 +0930
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
Message-ID: <d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>



> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
> From: moses selebatso <selebatsom at yahoo.co.uk>
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme for data that is not normally distributed
> Message-ID:
> 	<127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com>
> Content-Type: text/plain; charset="UTF-8"
>
> ?Hello
> I have some data that I would to analyse with mixed models (lme). As a standard procedure I tested for the normality of the data and it is not normal. Any ideas of how deals with this kind of data? I have a sample below and the model that I was hoping to use (if?the data?was normal)
> m <- lme(Distance~Time,random=~1|ID,data=data).


Checking normality of the response variable before doing the analysis is 
a misconception. Why should it be normally distributed? Fit your model 
and check your residuals for normality.


Alain

>
>   
>
>   
> |
>
>   
> | ID |
>
>   
> | Time |
>
>   
> | Distance |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Pre_dry |
>
>   
> | 4.31287 |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Pre_dry |
>
>   
> | 6.867578 |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Pre_dry |
>
>   
> | 4.640427 |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Post_dry |
>
>   
> | 4.497807 |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Post_dry |
>
>   
> | 9.726069 |
>
>    
> |
>
>   
> | 10187A |
>
>   
> | Post_dry |
>
>   
> | 5.150089 |
>
>   
>
>
> Regards,
> Moses SELEBATSO?
> 	[[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 116, Issue 4
> **************************************************
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From selebatsom at yahoo.co.uk  Wed Aug  3 15:25:35 2016
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Wed, 3 Aug 2016 13:25:35 +0000 (UTC)
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
	<d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
Message-ID: <2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>

Thank very much?for?your helpful advice. I ran?the model and tested the residuals. They are not normally distributed, and I am still stuck with how I proceed.?I tried to copy the output on the email, but I get an error message that the message format cannot sent.
Regards,
Moses?? 

    On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd <highstat at highstat.com> wrote:
 
 

 

> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
> From: moses selebatso <selebatsom at yahoo.co.uk>
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme for data that is not normally distributed
> Message-ID:
> ??? <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com>
> Content-Type: text/plain; charset="UTF-8"
>
> ?Hello
> I have some data that I would to analyse with mixed models (lme). As a standard procedure I tested for the normality of the data and it is not normal. Any ideas of how deals with this kind of data? I have a sample below and the model that I was hoping to use (if?the data?was normal)
> m <- lme(Distance~Time,random=~1|ID,data=data).


Checking normality of the response variable before doing the analysis is 
a misconception. Why should it be normally distributed? Fit your model 
and check your residuals for normality.


Alain

>
>? 
>
>? 
> |
>
>? 
> | ID |
>
>? 
> | Time |
>
>? 
> | Distance |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Pre_dry |
>
>? 
> | 4.31287 |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Pre_dry |
>
>? 
> | 6.867578 |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Pre_dry |
>
>? 
> | 4.640427 |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Post_dry |
>
>? 
> | 4.497807 |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Post_dry |
>
>? 
> | 9.726069 |
>
>? ? 
> |
>
>? 
> | 10187A |
>
>? 
> | Post_dry |
>
>? 
> | 5.150089 |
>
>? 
>
>
> Regards,
> Moses SELEBATSO?
> ??? [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 116, Issue 4
> **************************************************
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:? 0044 1358 788177
Email: highstat at highstat.com
URL:? www.highstat.com

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



  
	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Aug  3 15:41:19 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 3 Aug 2016 23:11:19 +0930
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <1470230115.93735.YahooMailIosMobile@web450606.mail.ir2.yahoo.com>
References: <1470230115.93735.YahooMailIosMobile@web450606.mail.ir2.yahoo.com>
Message-ID: <0476ef24-4d29-19c5-c513-a3f7e24f62bf@highstat.com>

Moses....your question assumes that we are telepathic and can see your 
results. In order to get advise from other people it would be useful if 
you can visualise your results. Or provide a reproducible example. Based 
on a p-value from a normality test no one can tell you what to do.

Distance is strictly positive? Try a gamma?

Alain


Does type = "response" work for an lme?



On 03/08/2016 22:45, moses selebatso wrote:
> Thank very much for your helpful advice. I ran the model and tested 
> the residuals. They are not normally distributed, and I am still stuck 
> with how I proceed. See below
>
> m1<- lme(Distance~Time,random=~1|ID,data=data)
> res1=residuals(m1,type="response")
>
> shapiro.test(res1)
> 	Shapiro-Wilk normality test
>
> data:  res1
> W = 0.89575, p-value = 1.594e-13
> //
> /Regards,/
> /
> /
> *Moses **SELEBATSO*
> /Home: (+267) 318 5219 (H) /
> /Mobile: (+267) 716 39370 or (+267) 738 39370/
> /"Those who will ALWAYS agree with you may be oppressed by you"/
>
>
> On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd wrote:
>
>
>
>
>
>     > Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
>     > From: moses selebatso <selebatsom at yahoo.co.uk <javascript:return>>
>     > To: R-sig-mixed-models <r-sig-mixed-models at r-project.org
>     <javascript:return>>
>     > Subject: [R-sig-ME] lme for data that is not normally distributed
>     > Message-ID:
>     > <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com
>     <javascript:return>>
>     > Content-Type: text/plain; charset="UTF-8"
>     >
>     > ?Hello
>     > I have some data that I would to analyse with mixed models
>     (lme). As a standard procedure I tested for the normality of the
>     data and it is not normal. Any ideas of how deals with this kind
>     of data? I have a sample below and the model that I was hoping to
>     use (if?the data?was normal)
>     > m <- lme(Distance~Time,random=~1|ID,data=data).
>
>
>     Checking normality of the response variable before doing the
>     analysis is
>     a misconception. Why should it be normally distributed? Fit your
>     model
>     and check your residuals for normality.
>
>
>     Alain
>
>     >
>     >
>     >
>     >
>     > |
>     >
>     >
>     > | ID |
>     >
>     >
>     > | Time |
>     >
>     >
>     > | Distance |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Pre_dry |
>     >
>     >
>     > | 4.31287 |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Pre_dry |
>     >
>     >
>     > | 6.867578 |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Pre_dry |
>     >
>     >
>     > | 4.640427 |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Post_dry |
>     >
>     >
>     > | 4.497807 |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Post_dry |
>     >
>     >
>     > | 9.726069 |
>     >
>     >
>     > |
>     >
>     >
>     > | 10187A |
>     >
>     >
>     > | Post_dry |
>     >
>     >
>     > | 5.150089 |
>     >
>     >
>     >
>     >
>     > Regards,
>     > Moses SELEBATSO?
>     > [[alternative HTML version deleted]]
>     >
>     >
>     >
>     > ------------------------------
>     >
>     > Subject: Digest Footer
>     >
>     > _______________________________________________
>     > R-sig-mixed-models mailing list
>     > R-sig-mixed-models at r-project.org <javascript:return>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>     > ------------------------------
>     >
>     > End of R-sig-mixed-models Digest, Vol 116, Issue 4
>     > **************************************************
>     >
>
>     -- 
>     Dr. Alain F. Zuur
>
>     First author of:
>     1. Beginner's Guide to GAMM with R (2014).
>     2. Beginner's Guide to GLM and GLMM with R (2013).
>     3. Beginner's Guide to GAM with R (2012).
>     4. Zero Inflated Models and GLMM with R (2012).
>     5. A Beginner's Guide to R (2009).
>     6. Mixed effects models and extensions in ecology with R (2009).
>     7. Analysing Ecological Data (2007).
>
>     Highland Statistics Ltd.
>     9 St Clair Wynd
>     UK - AB41 6DZ Newburgh
>     Tel: 0044 1358 788177
>     Email: highstat at highstat.com <javascript:return>
>     URL: www.highstat.com
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org <javascript:return> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Wed Aug  3 15:54:51 2016
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 3 Aug 2016 13:54:51 +0000
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
	<d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
	<2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <288F9D7C-D80D-4320-972F-B8031C04F611@glasgow.ac.uk>

Hi Moses,

I wouldn?t test normality of residuals ? better to assess them by eye. I know this sounds ad hoc but given that almost no real distribution in nature is perfectly normal, the question should be ?how non-normal can the residuals be before seriously harming my inferences??. This is a more difficult question to answer and basically requires experience. A test conflates the degree of non-normality and sample size  so a significant result can mean ?quite normal but high n? while a non-significant result can mean ?very non-normal but low n?:

set.seed(1)
x <- rpois(1000, 50)
hist(x)  # looks beautifully normal
shapiro.test(x) # significantly non-normal
hist(log(x[1:20])) # looks pretty bad
shapiro.test(log(x[1:20])) # passes the test

Given that your distance response measure is (probably) constrained to be positive, there?s a good change that it?s right-skewed and potentially made more normal by log-transformation (if there are no zero distances).

A good way to visually assess residuals is to plot them against the fitted values, then compare these to residuals simulated from the fitted model ? they should look similar, give or take sampling variation. You can do this with a function I recently wrote called sim.residplot (available here: https://github.com/pcdjohnson/GLMMmisc), although you?ll have to refit your model using lmer in the lme4 package:

library(lme4)
library(GLMMmisc)
m <- lmer(Distance ~ Time + (1 | ID), data = data)
sim.residplot(m) # repeat a few times to allow for sampling variation

Good luck,
Paul



> On 3 Aug 2016, at 14:25, moses selebatso via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> Thank very much for your helpful advice. I ran the model and tested the residuals. They are not normally distributed, and I am still stuck with how I proceed. I tried to copy the output on the email, but I get an error message that the message format cannot sent.
> Regards,
> Moses   
> 
>    On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd <highstat at highstat.com> wrote:
> 
> 
> 
> 
> 
>> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
>> From: moses selebatso <selebatsom at yahoo.co.uk>
>> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] lme for data that is not normally distributed
>> Message-ID:
>>     <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com>
>> Content-Type: text/plain; charset="UTF-8"
>> 
>> ?Hello
>> I have some data that I would to analyse with mixed models (lme). As a standard procedure I tested for the normality of the data and it is not normal. Any ideas of how deals with this kind of data? I have a sample below and the model that I was hoping to use (if?the data?was normal)
>> m <- lme(Distance~Time,random=~1|ID,data=data).
> 
> 
> Checking normality of the response variable before doing the analysis is 
> a misconception. Why should it be normally distributed? Fit your model 
> and check your residuals for normality.
> 
> 
> Alain
> 
>> 
>>   
>> 
>>   
>> |
>> 
>>   
>> | ID |
>> 
>>   
>> | Time |
>> 
>>   
>> | Distance |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Pre_dry |
>> 
>>   
>> | 4.31287 |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Pre_dry |
>> 
>>   
>> | 6.867578 |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Pre_dry |
>> 
>>   
>> | 4.640427 |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Post_dry |
>> 
>>   
>> | 4.497807 |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Post_dry |
>> 
>>   
>> | 9.726069 |
>> 
>>     
>> |
>> 
>>   
>> | 10187A |
>> 
>>   
>> | Post_dry |
>> 
>>   
>> | 5.150089 |
>> 
>>   
>> 
>> 
>> Regards,
>> Moses SELEBATSO?
>>     [[alternative HTML version deleted]]
>> 
>> 
>> 
>> ------------------------------
>> 
>> Subject: Digest Footer
>> 
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> ------------------------------
>> 
>> End of R-sig-mixed-models Digest, Vol 116, Issue 4
>> **************************************************
>> 
> 
> -- 
> Dr. Alain F. Zuur
> 
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
> 
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:  0044 1358 788177
> Email: highstat at highstat.com
> URL:  www.highstat.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From selebatsom at yahoo.co.uk  Wed Aug  3 21:58:23 2016
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Wed, 3 Aug 2016 19:58:23 +0000 (UTC)
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <288F9D7C-D80D-4320-972F-B8031C04F611@glasgow.ac.uk>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
	<d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
	<2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>
	<288F9D7C-D80D-4320-972F-B8031C04F611@glasgow.ac.uk>
Message-ID: <1383813049.14015841.1470254303778.JavaMail.yahoo@mail.yahoo.com>

Thank you both Paul and Alain for your help.?You both point?out that I shouldn't test for?normality before running a model. I appreciate that. Paul I have tried you new scripts and, I guess you were right about experience in visually assessing for normality. Not straight forward. Below is the plot, for your appreciation.
library(lme4)
install.packages("devtools")
library(devtools)
devtools::install_github("pcdjohnson/GLMMmisc")
library(GLMMmisc)
data<-read.csv("clipboard",sep="\t")
m <- lmer(Distance ~ Time + (1 | ID), data = data)
sim.residplot(m)?
Regards,
Moses SELEBATSO Home:?? ?(+267) 318 5219 (H)??Mobile: ?(+267) 716 39370? or? (+267) 738 39370"Those who will?ALWAYS agree with you may be oppressed by you" 

    On Wednesday, 3 August 2016, 15:54, Paul Johnson <paul.johnson at glasgow.ac.uk> wrote:
 
 

 Hi Moses,

I wouldn?t test normality of residuals ? better to assess them by eye. I know this sounds ad hoc but given that almost no real distribution in nature is perfectly normal, the question should be ?how non-normal can the residuals be before seriously harming my inferences??. This is a more difficult question to answer and basically requires experience. A test conflates the degree of non-normality and sample size? so a significant result can mean ?quite normal but high n? while a non-significant result can mean ?very non-normal but low n?:

set.seed(1)
x <- rpois(1000, 50)
hist(x)? # looks beautifully normal
shapiro.test(x) # significantly non-normal
hist(log(x[1:20])) # looks pretty bad
shapiro.test(log(x[1:20])) # passes the test

Given that your distance response measure is (probably) constrained to be positive, there?s a good change that it?s right-skewed and potentially made more normal by log-transformation (if there are no zero distances).

A good way to visually assess residuals is to plot them against the fitted values, then compare these to residuals simulated from the fitted model ? they should look similar, give or take sampling variation. You can do this with a function I recently wrote called sim.residplot (available here: https://github.com/pcdjohnson/GLMMmisc), although you?ll have to refit your model using lmer in the lme4 package:

library(lme4)
library(GLMMmisc)
m <- lmer(Distance ~ Time + (1 | ID), data = data)
sim.residplot(m) # repeat a few times to allow for sampling variation

Good luck,
Paul



> On 3 Aug 2016, at 14:25, moses selebatso via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> Thank very much for your helpful advice. I ran the model and tested the residuals. They are not normally distributed, and I am still stuck with how I proceed. I tried to copy the output on the email, but I get an error message that the message format cannot sent.
> Regards,
> Moses? 
> 
>? ? On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd <highstat at highstat.com> wrote:
> 
> 
> 
> 
> 
>> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC)
>> From: moses selebatso <selebatsom at yahoo.co.uk>
>> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] lme for data that is not normally distributed
>> Message-ID:
>>? ? <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com>
>> Content-Type: text/plain; charset="UTF-8"
>> 
>> ?Hello
>> I have some data that I would to analyse with mixed models (lme). As a standard procedure I tested for the normality of the data and it is not normal. Any ideas of how deals with this kind of data? I have a sample below and the model that I was hoping to use (if?the data?was normal)
>> m <- lme(Distance~Time,random=~1|ID,data=data).
> 
> 
> Checking normality of the response variable before doing the analysis is 
> a misconception. Why should it be normally distributed? Fit your model 
> and check your residuals for normality.
> 
> 
> Alain
> 
>> 
>>? 
>> 
>>? 
>> |
>> 
>>? 
>> | ID |
>> 
>>? 
>> | Time |
>> 
>>? 
>> | Distance |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Pre_dry |
>> 
>>? 
>> | 4.31287 |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Pre_dry |
>> 
>>? 
>> | 6.867578 |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Pre_dry |
>> 
>>? 
>> | 4.640427 |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Post_dry |
>> 
>>? 
>> | 4.497807 |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Post_dry |
>> 
>>? 
>> | 9.726069 |
>> 
>>? ? 
>> |
>> 
>>? 
>> | 10187A |
>> 
>>? 
>> | Post_dry |
>> 
>>? 
>> | 5.150089 |
>> 
>>? 
>> 
>> 
>> Regards,
>> Moses SELEBATSO?
>>? ? [[alternative HTML version deleted]]
>> 
>> 
>> 
>> ------------------------------
>> 
>> Subject: Digest Footer
>> 
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> ------------------------------
>> 
>> End of R-sig-mixed-models Digest, Vol 116, Issue 4
>> **************************************************
>> 
> 
> -- 
> Dr. Alain F. Zuur
> 
> First author of:
> 1. Beginner's Guide to GAMM with R (2014).
> 2. Beginner's Guide to GLM and GLMM with R (2013).
> 3. Beginner's Guide to GAM with R (2012).
> 4. Zero Inflated Models and GLMM with R (2012).
> 5. A Beginner's Guide to R (2009).
> 6. Mixed effects models and extensions in ecology with R (2009).
> 7. Analysing Ecological Data (2007).
> 
> Highland Statistics Ltd.
> 9 St Clair Wynd
> UK - AB41 6DZ Newburgh
> Tel:? 0044 1358 788177
> Email: highstat at highstat.com
> URL:? www.highstat.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



 
  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: datauri-file.png
Type: image/png
Size: 41046 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160803/eea4cd66/attachment-0001.png>

From bbolker at gmail.com  Wed Aug  3 22:14:46 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 3 Aug 2016 16:14:46 -0400
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <1383813049.14015841.1470254303778.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
	<d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
	<2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>
	<288F9D7C-D80D-4320-972F-B8031C04F611@glasgow.ac.uk>
	<1383813049.14015841.1470254303778.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1fa3c8b1-1d43-fe0e-20cb-26df72afc37f@gmail.com>

   For what it's worth, this graph is assessing
linearity/heteroscedasticity rather than Normality (you would want a Q-Q
plot, not a fitted vs residuals plot, for that).  This doesn't look too
terrible, but there does seem to be a bit of 'flare' at the
large-fitted-value end, which supports Paul's suggestion that you try a
log transformation ...

On 16-08-03 03:58 PM, moses selebatso via R-sig-mixed-models wrote:
> Thank you both Paul and Alain for your help. You both point out that
> I shouldn't test for normality before running a model. I appreciate
> that. Paul I have tried you new scripts and, I guess you were right
> about experience in visually assessing for normality. Not straight
> forward. Below is the plot, for your appreciation. library(lme4) 
> install.packages("devtools") library(devtools) 
> devtools::install_github("pcdjohnson/GLMMmisc") library(GLMMmisc) 
> data<-read.csv("clipboard",sep="\t") m <- lmer(Distance ~ Time + (1 |
> ID), data = data) sim.residplot(m) Regards, Moses SELEBATSO Home:
> (+267) 318 5219 (H)  Mobile:  (+267) 716 39370  or  (+267) 738
> 39370"Those who will ALWAYS agree with you may be oppressed by you"
> 
> On Wednesday, 3 August 2016, 15:54, Paul Johnson
> <paul.johnson at glasgow.ac.uk> wrote:
> 
> 
> 
> Hi Moses,
> 
> I wouldn?t test normality of residuals ? better to assess them by
> eye. I know this sounds ad hoc but given that almost no real
> distribution in nature is perfectly normal, the question should be
> ?how non-normal can the residuals be before seriously harming my
> inferences??. This is a more difficult question to answer and
> basically requires experience. A test conflates the degree of
> non-normality and sample size  so a significant result can mean
> ?quite normal but high n? while a non-significant result can mean
> ?very non-normal but low n?:
> 
> set.seed(1) x <- rpois(1000, 50) hist(x)  # looks beautifully normal 
> shapiro.test(x) # significantly non-normal hist(log(x[1:20])) # looks
> pretty bad shapiro.test(log(x[1:20])) # passes the test
> 
> Given that your distance response measure is (probably) constrained
> to be positive, there?s a good change that it?s right-skewed and
> potentially made more normal by log-transformation (if there are no
> zero distances).
> 
> A good way to visually assess residuals is to plot them against the
> fitted values, then compare these to residuals simulated from the
> fitted model ? they should look similar, give or take sampling
> variation. You can do this with a function I recently wrote called
> sim.residplot (available here:
> https://github.com/pcdjohnson/GLMMmisc), although you?ll have to
> refit your model using lmer in the lme4 package:
> 
> library(lme4) library(GLMMmisc) m <- lmer(Distance ~ Time + (1 | ID),
> data = data) sim.residplot(m) # repeat a few times to allow for
> sampling variation
> 
> Good luck, Paul
> 
> 
> 
>> On 3 Aug 2016, at 14:25, moses selebatso via R-sig-mixed-models
>> <r-sig-mixed-models at r-project.org> wrote:
>> 
>> Thank very much for your helpful advice. I ran the model and tested
>> the residuals. They are not normally distributed, and I am still
>> stuck with how I proceed. I tried to copy the output on the email,
>> but I get an error message that the message format cannot sent. 
>> Regards, Moses
>> 
>> On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd
>> <highstat at highstat.com> wrote:
>> 
>> 
>> 
>> 
>> 
>>> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC) From: moses selebatso
>>> <selebatsom at yahoo.co.uk> To: R-sig-mixed-models
>>> <r-sig-mixed-models at r-project.org> Subject: [R-sig-ME] lme for
>>> data that is not normally distributed Message-ID: 
>>> <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com> 
>>> Content-Type: text/plain; charset="UTF-8"
>>> 
>>> ?Hello I have some data that I would to analyse with mixed models
>>> (lme). As a standard procedure I tested for the normality of the
>>> data and it is not normal. Any ideas of how deals with this kind
>>> of data? I have a sample below and the model that I was hoping to
>>> use (if?the data?was normal) m <-
>>> lme(Distance~Time,random=~1|ID,data=data).
>> 
>> 
>> Checking normality of the response variable before doing the
>> analysis is a misconception. Why should it be normally distributed?
>> Fit your model and check your residuals for normality.
>> 
>> 
>> Alain
>> 
>>> 
>>> 
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | ID |
>>> 
>>> 
>>> | Time |
>>> 
>>> 
>>> | Distance |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Pre_dry |
>>> 
>>> 
>>> | 4.31287 |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Pre_dry |
>>> 
>>> 
>>> | 6.867578 |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Pre_dry |
>>> 
>>> 
>>> | 4.640427 |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Post_dry |
>>> 
>>> 
>>> | 4.497807 |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Post_dry |
>>> 
>>> 
>>> | 9.726069 |
>>> 
>>> 
>>> |
>>> 
>>> 
>>> | 10187A |
>>> 
>>> 
>>> | Post_dry |
>>> 
>>> 
>>> | 5.150089 |
>>> 
>>> 
>>> 
>>> 
>>> Regards, Moses SELEBATSO? [[alternative HTML version deleted]]
>>> 
>>> 
>>> 
>>> ------------------------------
>>> 
>>> Subject: Digest Footer
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models mailing list R-sig-mixed-models at r-project.org 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> ------------------------------
>>> 
>>> End of R-sig-mixed-models Digest, Vol 116, Issue 4 
>>> **************************************************
>>> 
>> 
>> -- Dr. Alain F. Zuur
>> 
>> First author of: 1. Beginner's Guide to GAMM with R (2014). 2.
>> Beginner's Guide to GLM and GLMM with R (2013). 3. Beginner's Guide
>> to GAM with R (2012). 4. Zero Inflated Models and GLMM with R
>> (2012). 5. A Beginner's Guide to R (2009). 6. Mixed effects models
>> and extensions in ecology with R (2009). 7. Analysing Ecological
>> Data (2007).
>> 
>> Highland Statistics Ltd. 9 St Clair Wynd UK - AB41 6DZ Newburgh 
>> Tel:  0044 1358 788177 Email: highstat at highstat.com URL:
>> www.highstat.com
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john.maindonald at anu.edu.au  Wed Aug  3 23:20:21 2016
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 3 Aug 2016 21:20:21 +0000
Subject: [R-sig-ME] lme for data that is not normally distributed
In-Reply-To: <1fa3c8b1-1d43-fe0e-20cb-26df72afc37f@gmail.com>
References: <mailman.1.1470218401.24786.r-sig-mixed-models@r-project.org>
	<d381ae8c-164c-23e8-cb9b-5a422fa5100a@highstat.com>
	<2008232223.15419061.1470230735832.JavaMail.yahoo@mail.yahoo.com>
	<288F9D7C-D80D-4320-972F-B8031C04F611@glasgow.ac.uk>
	<1383813049.14015841.1470254303778.JavaMail.yahoo@mail.yahoo.com>
	<1fa3c8b1-1d43-fe0e-20cb-26df72afc37f@gmail.com>
Message-ID: <F21258A0-3B21-4D55-9B09-0D020CFC5407@anu.edu.au>

A point to note is that it is the distribution of the relevant sampling
distribution, not the normality of the residuals as given by the
function resid(), that matters for reliance on the standard errors
and t-statistics of parameters.  In Moses? example, the ID effects
are what will matter for this purpose.  

(In highly unbalanced designs, the estimated effects can have very 
non-normal distributions, even under strict model assumptions, and 
simulation may be the only way to get good insight on what is to be 
expected under those circumstances.)

The plot of residuals against fitted values is useful in checking
linearity (for heteroscedasticity this is more fraught because again
it is homogeneity for the relevant sampling distribution that matters),
and for checking leverage effects (a few IDs with an over-riding 
potential influence on the fitted response).

John Maindonald             email: john.maindonald at anu.edu.au

> On 4/08/2016, at 08:14, Ben Bolker <bbolker at gmail.com> wrote:
> 
>   For what it's worth, this graph is assessing
> linearity/heteroscedasticity rather than Normality (you would want a Q-Q
> plot, not a fitted vs residuals plot, for that).  This doesn't look too
> terrible, but there does seem to be a bit of 'flare' at the
> large-fitted-value end, which supports Paul's suggestion that you try a
> log transformation ...
> 
> On 16-08-03 03:58 PM, moses selebatso via R-sig-mixed-models wrote:
>> Thank you both Paul and Alain for your help. You both point out that
>> I shouldn't test for normality before running a model. I appreciate
>> that. Paul I have tried you new scripts and, I guess you were right
>> about experience in visually assessing for normality. Not straight
>> forward. Below is the plot, for your appreciation. library(lme4) 
>> install.packages("devtools") library(devtools) 
>> devtools::install_github("pcdjohnson/GLMMmisc") library(GLMMmisc) 
>> data<-read.csv("clipboard",sep="\t") m <- lmer(Distance ~ Time + (1 |
>> ID), data = data) sim.residplot(m) Regards, Moses SELEBATSO Home:
>> (+267) 318 5219 (H)  Mobile:  (+267) 716 39370  or  (+267) 738
>> 39370"Those who will ALWAYS agree with you may be oppressed by you"
>> 
>> On Wednesday, 3 August 2016, 15:54, Paul Johnson
>> <paul.johnson at glasgow.ac.uk> wrote:
>> 
>> 
>> 
>> Hi Moses,
>> 
>> I wouldn?t test normality of residuals ? better to assess them by
>> eye. I know this sounds ad hoc but given that almost no real
>> distribution in nature is perfectly normal, the question should be
>> ?how non-normal can the residuals be before seriously harming my
>> inferences??. This is a more difficult question to answer and
>> basically requires experience. A test conflates the degree of
>> non-normality and sample size  so a significant result can mean
>> ?quite normal but high n? while a non-significant result can mean
>> ?very non-normal but low n?:
>> 
>> set.seed(1) x <- rpois(1000, 50) hist(x)  # looks beautifully normal 
>> shapiro.test(x) # significantly non-normal hist(log(x[1:20])) # looks
>> pretty bad shapiro.test(log(x[1:20])) # passes the test
>> 
>> Given that your distance response measure is (probably) constrained
>> to be positive, there?s a good change that it?s right-skewed and
>> potentially made more normal by log-transformation (if there are no
>> zero distances).
>> 
>> A good way to visually assess residuals is to plot them against the
>> fitted values, then compare these to residuals simulated from the
>> fitted model ? they should look similar, give or take sampling
>> variation. You can do this with a function I recently wrote called
>> sim.residplot (available here:
>> https://github.com/pcdjohnson/GLMMmisc), although you?ll have to
>> refit your model using lmer in the lme4 package:
>> 
>> library(lme4) library(GLMMmisc) m <- lmer(Distance ~ Time + (1 | ID),
>> data = data) sim.residplot(m) # repeat a few times to allow for
>> sampling variation
>> 
>> Good luck, Paul
>> 
>> 
>> 
>>> On 3 Aug 2016, at 14:25, moses selebatso via R-sig-mixed-models
>>> <r-sig-mixed-models at r-project.org> wrote:
>>> 
>>> Thank very much for your helpful advice. I ran the model and tested
>>> the residuals. They are not normally distributed, and I am still
>>> stuck with how I proceed. I tried to copy the output on the email,
>>> but I get an error message that the message format cannot sent. 
>>> Regards, Moses
>>> 
>>> On Wednesday, 3 August 2016, 12:15, Highland Statistics Ltd
>>> <highstat at highstat.com> wrote:
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> Date: Wed, 3 Aug 2016 09:40:20 +0000 (UTC) From: moses selebatso
>>>> <selebatsom at yahoo.co.uk> To: R-sig-mixed-models
>>>> <r-sig-mixed-models at r-project.org> Subject: [R-sig-ME] lme for
>>>> data that is not normally distributed Message-ID: 
>>>> <127496753.15122202.1470217220406.JavaMail.yahoo at mail.yahoo.com> 
>>>> Content-Type: text/plain; charset="UTF-8"
>>>> 
>>>> ?Hello I have some data that I would to analyse with mixed models
>>>> (lme). As a standard procedure I tested for the normality of the
>>>> data and it is not normal. Any ideas of how deals with this kind
>>>> of data? I have a sample below and the model that I was hoping to
>>>> use (if?the data?was normal) m <-
>>>> lme(Distance~Time,random=~1|ID,data=data).
>>> 
>>> 
>>> Checking normality of the response variable before doing the
>>> analysis is a misconception. Why should it be normally distributed?
>>> Fit your model and check your residuals for normality.
>>> 
>>> 
>>> Alain
>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | ID |
>>>> 
>>>> 
>>>> | Time |
>>>> 
>>>> 
>>>> | Distance |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Pre_dry |
>>>> 
>>>> 
>>>> | 4.31287 |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Pre_dry |
>>>> 
>>>> 
>>>> | 6.867578 |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Pre_dry |
>>>> 
>>>> 
>>>> | 4.640427 |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Post_dry |
>>>> 
>>>> 
>>>> | 4.497807 |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Post_dry |
>>>> 
>>>> 
>>>> | 9.726069 |
>>>> 
>>>> 
>>>> |
>>>> 
>>>> 
>>>> | 10187A |
>>>> 
>>>> 
>>>> | Post_dry |
>>>> 
>>>> 
>>>> | 5.150089 |
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Regards, Moses SELEBATSO? [[alternative HTML version deleted]]
>>>> 
>>>> 
>>>> 
>>>> ------------------------------
>>>> 
>>>> Subject: Digest Footer
>>>> 
>>>> _______________________________________________ 
>>>> R-sig-mixed-models mailing list R-sig-mixed-models at r-project.org 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>>> ------------------------------
>>>> 
>>>> End of R-sig-mixed-models Digest, Vol 116, Issue 4 
>>>> **************************************************
>>>> 
>>> 
>>> -- Dr. Alain F. Zuur
>>> 
>>> First author of: 1. Beginner's Guide to GAMM with R (2014). 2.
>>> Beginner's Guide to GLM and GLMM with R (2013). 3. Beginner's Guide
>>> to GAM with R (2012). 4. Zero Inflated Models and GLMM with R
>>> (2012). 5. A Beginner's Guide to R (2009). 6. Mixed effects models
>>> and extensions in ecology with R (2009). 7. Analysing Ecological
>>> Data (2007).
>>> 
>>> Highland Statistics Ltd. 9 St Clair Wynd UK - AB41 6DZ Newburgh 
>>> Tel:  0044 1358 788177 Email: highstat at highstat.com URL:
>>> www.highstat.com
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From daniel_rubi at ymail.com  Fri Aug  5 18:37:30 2016
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Fri, 5 Aug 2016 16:37:30 +0000 (UTC)
Subject: [R-sig-ME] Setting average as baseline rather than a dummy variable
 in a negative binomial glm
References: <1712239083.12635907.1470415050291.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1712239083.12635907.1470415050291.JavaMail.yahoo@mail.yahoo.com>

Hi,
I first posted this in?cross validated, but thought this forum is better suited for this question.

I have binomial data (meaning k successes out of n trials) for a set of conditions. I would like to fit a glm in order to quantify the effect of each condition on the success.Since the data are overdisperesed I thought of using a negative binomial glm (glm.nb from the R MASS package does that).Code snippet (though not really overdisperesed):set.seed(1)
df <- data.frame(k = as.integer(runif(200,1,20)),
                 n = as.integer(runif(200,100,200)),
                 cond = rep(LETTERS[1:20],10),
                 stringsAsFactors = F)
df$cond <- as.factor(df$cond)
library(MASS)
fit <- glm.nb(k ~ cond + offset(n), data = df)
Obviously cond A will be set as baseline and all effects will be relative to it. However, this makes interpretation very difficult for me. Therefore my question is how do I fit a glm.nb model where the effects are relative to the mean across all conditions rather than the dummy variable set as baseline?
Thanks a lot,Dan
	[[alternative HTML version deleted]]


From aitor.gaston at upm.es  Fri Aug  5 21:29:40 2016
From: aitor.gaston at upm.es (=?utf-8?Q?Aitor_Gast=C3=B3n?=)
Date: Fri, 5 Aug 2016 21:29:40 +0200
Subject: [R-sig-ME] Setting average as baseline rather than a dummy
	variable in a negative binomial glm
In-Reply-To: <1712239083.12635907.1470415050291.JavaMail.yahoo@mail.yahoo.com>
References: <1712239083.12635907.1470415050291.JavaMail.yahoo.ref@mail.yahoo.com>
	<1712239083.12635907.1470415050291.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <10FC725384494DB491413C1AC05A67C9@botanica1>

You can change the contrasts type using contrasts.

I always use the default contrast in R (treatment), but I guess that you are 
looking for sum contrast, running

options(contrasts=c("contr.sum","contr.poly"))

before you fit the model will change to sum contrasts, i.e., the intercept 
shows the grand mean and the coefficients of each level are the difference 
between the grand mean and each level.

Aitor

-----Mensaje original----- 
From: Daniel Rubi via R-sig-mixed-models
Sent: Friday, August 05, 2016 6:37 PM
To: R-sig-mixed-models
Subject: [R-sig-ME] Setting average as baseline rather than a dummy variable 
in a negative binomial glm

Hi,
I first posted this in cross validated, but thought this forum is better 
suited for this question.

I have binomial data (meaning k successes out of n trials) for a set of 
conditions. I would like to fit a glm in order to quantify the effect of 
each condition on the success.Since the data are overdisperesed I thought of 
using a negative binomial glm (glm.nb from the R MASS package does 
that).Code snippet (though not really overdisperesed):set.seed(1)
df <- data.frame(k = as.integer(runif(200,1,20)),
                 n = as.integer(runif(200,100,200)),
                 cond = rep(LETTERS[1:20],10),
                 stringsAsFactors = F)
df$cond <- as.factor(df$cond)
library(MASS)
fit <- glm.nb(k ~ cond + offset(n), data = df)
Obviously cond A will be set as baseline and all effects will be relative to 
it. However, this makes interpretation very difficult for me. Therefore my 
question is how do I fit a glm.nb model where the effects are relative to 
the mean across all conditions rather than the dummy variable set as 
baseline?
Thanks a lot,Dan
[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cddesjardins at gmail.com  Fri Aug  5 21:49:14 2016
From: cddesjardins at gmail.com (Christopher David Desjardins)
Date: Fri, 5 Aug 2016 14:49:14 -0500
Subject: [R-sig-ME] Question about misspecified multilevel model
Message-ID: <CALrjt78-GT8yiCfg=7hYRVAq-je+UJZ7=mBGO3ga7EAKB1wQpg@mail.gmail.com>

Hi,

I have a question that's potentially off-topic but that I'm hoping that
someone here can shed some insight on.

Assume that I know that I know my true model and that my true is a
three-level model. My observations are such that I have a measurement on a
student nested within a classroom nested within a school. The true model
would be:

Y_ijk = pi_0jk + e_ijk  # student within classroom within schools (1st
level)

pi_0jk = beta_j0k + r_p0k  # classroom within schools (2nd level)

beta_j0k = gamma_pq0 + u_pqk  # schools (3rd level)

The model in lmer would be:
classroom <- read.csv("http://www-personal.umich.edu/~bwest/classroom.csv")
library("lme4")
correct.mod <- lmer(mathgain ~ (1 | schoolid/classid), data = classroom)

What I am wondering about is, if I were to omit that second level, the
whole classroom within schools equation, where would that variance that
would end up as the random intercept go? Would it go to the random
intercept for school or would it go down to the residual?  The model I am
referring to is below:

misspecified.mod <- lmer(mathgain ~ (1 | schoolid), data = classroom)
summary(correct.mod); summary(misspecified.mod)

It looks like the variances for both the residual and the random intercept
for school change. But maybe they do in a predictable way?

If someone could suggest a paper has an answer or better that would be very
helpful.

Chris

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Sat Aug  6 07:50:33 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Sat, 6 Aug 2016 05:50:33 +0000
Subject: [R-sig-ME] Question about misspecified multilevel model
In-Reply-To: <CALrjt78-GT8yiCfg=7hYRVAq-je+UJZ7=mBGO3ga7EAKB1wQpg@mail.gmail.com>
References: <CALrjt78-GT8yiCfg=7hYRVAq-je+UJZ7=mBGO3ga7EAKB1wQpg@mail.gmail.com>
Message-ID: <0AB241FE-8722-4AED-8CB2-7C6AAAC1366A@unisa.edu.au>

Hi Chris,

Since you have a concrete example why not just calculate the models and see what happens? The intercept-only model that you proposed is quite simple and fast to compute:

Random effects:
 Groups           Name        Variance Std.Dev.
 classid:schoolid (Intercept)   99.23   9.961  
 schoolid         (Intercept)   77.49   8.803  
 Residual                     1028.23  32.066  
Number of obs: 1190, groups:  classid:schoolid, 312; schoolid, 107

Now, if you do a model with just classroom, then you want this model:

class.mod <- lmer(mathgain ~ (1 | schoolid:classid), data = classroom)

(I'm assuming that classid isn't globally unique, but rather only unique within schools, otherwise the / and : operators add a bit of unnecessary overhead, but that's a different issue)

which has the following random effects: 

Random effects:
 Groups           Name        Variance Std.Dev.
 schoolid:classid (Intercept)  180     13.42   
 Residual                     1025     32.02   
Number of obs: 1190, groups:  schoolid:classid, 312

As you can see, the classid absorbed most of the variance. If you look at the fixed effects, then you'll see slight differences in the error estimates there as well -- models with incomplete random-effect structures typically have error estimates that are two small and are thus anti-conversative. This can be attributed to the variance-bias tradeoff or equivalently overfitting (see e.g. the new book Statistical Rethinking or any of the other classics mentioned here such as Pinheiro & Bates or Gelman & Hill). Roughly, leaving out random effects structure implies that the data are independent in in a way that they are not, which leads you to overestimate how much information you actually have and thus how little error.

Now, if you're curious you can also compare log likelihood if you refit the models via ML*:

> anova(class.mod,correct.mod,refit=TRUE)
refitting model(s) with ML (instead of REML)
Data: classroom
Models:
class.mod: mathgain ~ (1 | schoolid:classid)
correct.mod: mathgain ~ (1 | schoolid/classid)
            Df   AIC   BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)   
class.mod    3 11785 11800 -5889.5    11779                            
correct.mod  4 11779 11800 -5885.7    11771 7.5906      1   0.005867 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

And you see that the model fits while tantalisingly close are nonetheless significantly different. 

Now, I'm not sure what will happen with more complex fixed-effects or random-effects structures, but my guess is that generally the variance will be allocated to whatever variable is "close enough" (here classroom is close enough to school because a collection of classrooms makes up a school) and if there are none close enough, the remaining variance will just contribute to the residual variance (which didn't happen here).

* The fixed-effects model matrix is the same for both models so that you could potentially compare REML-fitted models, but that also gets you into all sorts of fun debate about the pros and cons of REML and it's just easier to avoid all the issues with comparisons of REML-fit

Best,
Phillip

> On 6 Aug 2016, at 05:19, Christopher David Desjardins <cddesjardins at gmail.com> wrote:
> 
> Hi,
> 
> I have a question that's potentially off-topic but that I'm hoping that
> someone here can shed some insight on.
> 
> Assume that I know that I know my true model and that my true is a
> three-level model. My observations are such that I have a measurement on a
> student nested within a classroom nested within a school. The true model
> would be:
> 
> Y_ijk = pi_0jk + e_ijk  # student within classroom within schools (1st
> level)
> 
> pi_0jk = beta_j0k + r_p0k  # classroom within schools (2nd level)
> 
> beta_j0k = gamma_pq0 + u_pqk  # schools (3rd level)
> 
> The model in lmer would be:
> classroom <- read.csv("http://www-personal.umich.edu/~bwest/classroom.csv")
> library("lme4")
> correct.mod <- lmer(mathgain ~ (1 | schoolid/classid), data = classroom)
> 
> What I am wondering about is, if I were to omit that second level, the
> whole classroom within schools equation, where would that variance that
> would end up as the random intercept go? Would it go to the random
> intercept for school or would it go down to the residual?  The model I am
> referring to is below:
> 
> misspecified.mod <- lmer(mathgain ~ (1 | schoolid), data = classroom)
> summary(correct.mod); summary(misspecified.mod)
> 
> It looks like the variances for both the residual and the random intercept
> for school change. But maybe they do in a predictable way?
> 
> If someone could suggest a paper has an answer or better that would be very
> helpful.
> 
> Chris
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cddesjardins at gmail.com  Sat Aug  6 17:19:09 2016
From: cddesjardins at gmail.com (Christopher David Desjardins)
Date: Sat, 6 Aug 2016 10:19:09 -0500
Subject: [R-sig-ME] Question about misspecified multilevel model
In-Reply-To: <0AB241FE-8722-4AED-8CB2-7C6AAAC1366A@unisa.edu.au>
References: <CALrjt78-GT8yiCfg=7hYRVAq-je+UJZ7=mBGO3ga7EAKB1wQpg@mail.gmail.com>
	<0AB241FE-8722-4AED-8CB2-7C6AAAC1366A@unisa.edu.au>
Message-ID: <CALrjt79=63Wzw4qfWpkMqwrW6XO=3qJb-75U5-=qPLLE17Hrzg@mail.gmail.com>

Thanks, Phillip. The concrete example was meant to be just an example, so
you would know what I am talking about. I am thinking about
misspecification in general. Thanks for the detailed response to that. I am
cutting your response below.

On Saturday, August 6, 2016, Phillip Alday <Phillip.Alday at unisa.edu.au>
wrote:

> Hi Chris,




>  Now, I'm not sure what will happen with more complex fixed-effects or
> random-effects structures, but my guess is that generally the variance will
> be allocated to whatever variable is "close enough" (here classroom is
> close enough to school because a collection of classrooms makes up a
> school) and if there are none close enough, the remaining variance will
> just contribute to the residual variance (which didn't happen here).
>

This is what I am wondering about out and this is what I expected happens
but wasn't sure if it was just for this example and wasn't sure if there
was a mathematical reason why.



>
> * The fixed-effects model matrix is the same for both models so that you
> could potentially compare REML-fitted models, but that also gets you into
> all sorts of fun debate about the pros and cons of REML and it's just
> easier to avoid all the issues with comparisons of REML-fit
>
> Best,
> Phillip
>
> > On 6 Aug 2016, at 05:19, Christopher David Desjardins <
> cddesjardins at gmail.com <javascript:;>> wrote:
> >
> > Hi,
> >
> > I have a question that's potentially off-topic but that I'm hoping that
> > someone here can shed some insight on.
> >
> > Assume that I know that I know my true model and that my true is a
> > three-level model. My observations are such that I have a measurement on
> a
> > student nested within a classroom nested within a school. The true model
> > would be:
> >
> > Y_ijk = pi_0jk + e_ijk  # student within classroom within schools (1st
> > level)
> >
> > pi_0jk = beta_j0k + r_p0k  # classroom within schools (2nd level)
> >
> > beta_j0k = gamma_pq0 + u_pqk  # schools (3rd level)
> >
> > The model in lmer would be:
> > classroom <- read.csv("http://www-personal.
> umich.edu/~bwest/classroom.csv")
> > library("lme4")
> > correct.mod <- lmer(mathgain ~ (1 | schoolid/classid), data = classroom)
> >
> > What I am wondering about is, if I were to omit that second level, the
> > whole classroom within schools equation, where would that variance that
> > would end up as the random intercept go? Would it go to the random
> > intercept for school or would it go down to the residual?  The model I am
> > referring to is below:
> >
> > misspecified.mod <- lmer(mathgain ~ (1 | schoolid), data = classroom)
> > summary(correct.mod); summary(misspecified.mod)
> >
> > It looks like the variances for both the residual and the random
> intercept
> > for school change. But maybe they do in a predictable way?
> >
> > If someone could suggest a paper has an answer or better that would be
> very
> > helpful.
> >
> > Chris
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <javascript:;> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
https://cddesja.github.io/

	[[alternative HTML version deleted]]


From meir.barneron at gmail.com  Thu Aug  4 11:22:52 2016
From: meir.barneron at gmail.com (Meir Barneron)
Date: Thu, 4 Aug 2016 12:22:52 +0300
Subject: [R-sig-ME] (no subject)
Message-ID: <CAGZ4N0JKXswb959mfr3g3Fs6ebmqV6vZgmqdn30DrVNQAAJrSw@mail.gmail.com>

Hi everyone,

I am relatively new in MEMs, and trying to tigure out what is the best
model fo my data. The data itself is relatively simple but the design more
complicated..

To make it simpler, I am interested in investigating if there is a
difference between two measures made at two point in time (1 and 2), that
is all. My dependent variable is a grade. I do not enter into details in
order to keep it as simple as possible. My theory predicts that the grades
will be smaller at time 2 compared to time 1.

Basically I have 30 subjects, and 100 Items and I want to make sure that
there is an effect after controlling for subjects and items. Here is the
design.
Before the experiment I randomly selected 30 subjects from a pool. I also
randomly selected 100 items from a pool. Next,  I randomly divided the 30
subjects into 5 groups of 6 subjects. I also randomly divided the 100
items into 5 groups of 20 items. The groups do not have any theoretical
relations and all was divided totally randomly.

Then I assigned one group of 20 items to one group of 6 subjects. Within
each group, each 6 subjects saw each 20 items. For each Items, each subject
gave me one grade at Time 1, and one at Time 2.

My question is how to model this design. One possibility I have tried
if to ignore the group and took into account only the subjects and the
items.
This is my syntax:
model1 <- lmer(Grade ~ 1 + Time +
                 (1 + Time | Subject) +
                 (1 + Time | Item),
               REML=F, data = NITE1)

Does anyone have an idea how to take the "group" into account?
Alternaltvely, do you think the model I built is sufficient?

Thank you in advance

Meir

	[[alternative HTML version deleted]]


From bencebagok at gmail.com  Mon Aug  8 19:06:22 2016
From: bencebagok at gmail.com (=?UTF-8?Q?Bence_Bag=C3=B3?=)
Date: Mon, 8 Aug 2016 19:06:22 +0200
Subject: [R-sig-ME] glmer
Message-ID: <CAJBnzzeCo7HQVDYaN-goeTfyamJey20+gxaYk+Rr8FTQMvwhEg@mail.gmail.com>

Dear Community,

I'm working with lme4 package, and have a question regarding glmer
function. I would like to compare effect sizes of a within and a between
subject study - in the within subject study df is twice as big as in the
between subject one. I was wondering whether there is a way to calculate
standardized effect size.

Thank you very much for your help in advance!

Best regards,
Bence Bago

	[[alternative HTML version deleted]]


From drmccloy at uw.edu  Mon Aug  8 20:12:23 2016
From: drmccloy at uw.edu (Dan McCloy)
Date: Mon, 8 Aug 2016 11:12:23 -0700
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAGZ4N0JKXswb959mfr3g3Fs6ebmqV6vZgmqdn30DrVNQAAJrSw@mail.gmail.com>
References: <CAGZ4N0JKXswb959mfr3g3Fs6ebmqV6vZgmqdn30DrVNQAAJrSw@mail.gmail.com>
Message-ID: <CAOE0pYkN4fQRM70o=iDUVk9F4WZwvBPk8hqBqzGWffarQYDBYA@mail.gmail.com>

The GLMM FAQ has some information about specifying nested random effects.
See especially the "model specification" table [1] and the "nested or
crossed" section [2].  Something like this may be what you're looking for:

grade ~ Time + (Time | SubjectGroup / Subject) + (Time | ItemGroup / Item)

Given that you've assigned groups randomly, I'm unsure if there will be
much benefit to modeling the groups this way (unless maybe "grade" for one
subject/item is somehow influenced by the other subjects or items in the
group?).  Anyway, the dataset is small enough that it will be easy to try
and see what happens.  Also note that if "Time" has only two values, it can
be treated as a factor (like "pre" and "post" treatment).

[1]:
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#model-specification
[2]:
https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#nested-or-crossed

-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Associate
Institute for Learning and Brain Sciences
University of Washington


On Thu, Aug 4, 2016 at 2:22 AM, Meir Barneron <meir.barneron at gmail.com>
wrote:

> Hi everyone,
>
> I am relatively new in MEMs, and trying to tigure out what is the best
> model fo my data. The data itself is relatively simple but the design more
> complicated..
>
> To make it simpler, I am interested in investigating if there is a
> difference between two measures made at two point in time (1 and 2), that
> is all. My dependent variable is a grade. I do not enter into details in
> order to keep it as simple as possible. My theory predicts that the grades
> will be smaller at time 2 compared to time 1.
>
> Basically I have 30 subjects, and 100 Items and I want to make sure that
> there is an effect after controlling for subjects and items. Here is the
> design.
> Before the experiment I randomly selected 30 subjects from a pool. I also
> randomly selected 100 items from a pool. Next,  I randomly divided the 30
> subjects into 5 groups of 6 subjects. I also randomly divided the 100
> items into 5 groups of 20 items. The groups do not have any theoretical
> relations and all was divided totally randomly.
>
> Then I assigned one group of 20 items to one group of 6 subjects. Within
> each group, each 6 subjects saw each 20 items. For each Items, each subject
> gave me one grade at Time 1, and one at Time 2.
>
> My question is how to model this design. One possibility I have tried
> if to ignore the group and took into account only the subjects and the
> items.
> This is my syntax:
> model1 <- lmer(Grade ~ 1 + Time +
>                  (1 + Time | Subject) +
>                  (1 + Time | Item),
>                REML=F, data = NITE1)
>
> Does anyone have an idea how to take the "group" into account?
> Alternaltvely, do you think the model I built is sufficient?
>
> Thank you in advance
>
> Meir
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pmille13 at nd.edu  Mon Aug  8 19:47:42 2016
From: pmille13 at nd.edu (Patrick Miller)
Date: Mon, 8 Aug 2016 13:47:42 -0400
Subject: [R-sig-ME] Making lme4 faster for specific case of sparse x
Message-ID: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>

Hello,

For my dissertation, I'm working on extending boosted decision trees to
clustered data.

In one of the approaches I'm considering, I use *lmer* to estimate random
effects within each gradient descent iteration in boosting. As you might
expect, this is computationally intensive. However, my intuition is that
this step could be made faster because my use case is very specific.
Namely, in each iteration, *X = Z*, and *X* is a sparse matrix of 0s and 1s
(with an intercept).

I was wondering if anyone had suggestions or (theoretical) guidance on this
problem. For instance, is it possible that this special case permits faster
optimization via specific derivatives? I'm not expecting this to be
implemented in lmer or anything, and I'm happy to work out a basic
implementation myself for this case.

I've read the vignette on speeding up the performance of lmer, and
setting calc.derivs
= FALSE resulted in about a 15% performance improvement for free, which was
great. I was just wondering if it was possible to go further.

Thanks in advance,

- Patrick

-- 
Patrick Miller
Ph.D. Candidate, Quantitative Psychology
University of Notre Dame

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Aug  9 00:08:13 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 08 Aug 2016 22:08:13 +0000
Subject: [R-sig-ME] Making lme4 faster for specific case of sparse x
In-Reply-To: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>
References: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>
Message-ID: <CAO7JsnR8ULbEgsHGo+MT0L_q1M70D_7jbXhuM6xrxzNdZdm9Cg@mail.gmail.com>

If X == Z don't you have problems with estimability?  It seems that mle
would always correspond to all random effects being zero.

Perhaps I misunderstand the situation.  Could you provide a bit more detail
on how it comes about that X == Z?

On Mon, Aug 8, 2016 at 5:01 PM Patrick Miller <pmille13 at nd.edu> wrote:

> Hello,
>
> For my dissertation, I'm working on extending boosted decision trees to
> clustered data.
>
> In one of the approaches I'm considering, I use *lmer* to estimate random
> effects within each gradient descent iteration in boosting. As you might
> expect, this is computationally intensive. However, my intuition is that
> this step could be made faster because my use case is very specific.
> Namely, in each iteration, *X = Z*, and *X* is a sparse matrix of 0s and 1s
> (with an intercept).
>
> I was wondering if anyone had suggestions or (theoretical) guidance on this
> problem. For instance, is it possible that this special case permits faster
> optimization via specific derivatives? I'm not expecting this to be
> implemented in lmer or anything, and I'm happy to work out a basic
> implementation myself for this case.
>
> I've read the vignette on speeding up the performance of lmer, and
> setting calc.derivs
> = FALSE resulted in about a 15% performance improvement for free, which was
> great. I was just wondering if it was possible to go further.
>
> Thanks in advance,
>
> - Patrick
>
> --
> Patrick Miller
> Ph.D. Candidate, Quantitative Psychology
> University of Notre Dame
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pierces1 at msu.edu  Tue Aug  9 14:21:08 2016
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 9 Aug 2016 08:21:08 -0400
Subject: [R-sig-ME] glmer
In-Reply-To: <CAJBnzzeCo7HQVDYaN-goeTfyamJey20+gxaYk+Rr8FTQMvwhEg@mail.gmail.com>
References: <CAJBnzzeCo7HQVDYaN-goeTfyamJey20+gxaYk+Rr8FTQMvwhEg@mail.gmail.com>
Message-ID: <000001d1f238$825b7fe0$87127fa0$@msu.edu>

Bence,

There are many different effect size measures, some standardized and some unstandardized (Kelley & Preacher, 2012). Each has its own interpretation, uses, advantages, and disadvantages. Some of them have been adapted for use with mixed models, others haven?t. I think you need to first be clearer about what effect size measure you want to use, then folks on this list can be more helpful about the computational side of estimating the relevant effect size measure from a model fitted by lme4. 

Kelley, K., & Preacher, K. J. (2012). On effect size. Psychological Methods, 17(2), 137-152. doi:10.1037/a0028086

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Bence Bag? [mailto:bencebagok at gmail.com] 
Sent: Monday, August 08, 2016 1:06 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] glmer

Dear Community,

I'm working with lme4 package, and have a question regarding glmer
function. I would like to compare effect sizes of a within and a between
subject study - in the within subject study df is twice as big as in the
between subject one. I was wondering whether there is a way to calculate
standardized effect size.

Thank you very much for your help in advance!

Best regards,
Bence Bago

	[[alternative HTML version deleted]]


From pmille13 at nd.edu  Tue Aug  9 15:34:54 2016
From: pmille13 at nd.edu (Patrick Miller)
Date: Tue, 9 Aug 2016 09:34:54 -0400
Subject: [R-sig-ME] Making lme4 faster for specific case of sparse x
In-Reply-To: <CAO7JsnR8ULbEgsHGo+MT0L_q1M70D_7jbXhuM6xrxzNdZdm9Cg@mail.gmail.com>
References: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>
	<CAO7JsnR8ULbEgsHGo+MT0L_q1M70D_7jbXhuM6xrxzNdZdm9Cg@mail.gmail.com>
Message-ID: <CAPb3xuV=TyJBPcVv2tHbqB22V-fkJ3GwpsFmJ31s+_aVnY_59g@mail.gmail.com>

Thanks for that clarification.  In my situation, the effect of each
predictor in X was allowed to vary by a single grouping variable. The lmer
formula is something like the following:

y ~ 1 + X1 + X2 + X3 + ... + ( 1 + X1 + X2 + X3 + ... | id)

- Patrick

On Mon, Aug 8, 2016 at 6:08 PM, Douglas Bates <bates at stat.wisc.edu> wrote:

> If X == Z don't you have problems with estimability?  It seems that mle
> would always correspond to all random effects being zero.
>
> Perhaps I misunderstand the situation.  Could you provide a bit more
> detail on how it comes about that X == Z?
>
> On Mon, Aug 8, 2016 at 5:01 PM Patrick Miller <pmille13 at nd.edu> wrote:
>
>> Hello,
>>
>> For my dissertation, I'm working on extending boosted decision trees to
>> clustered data.
>>
>> In one of the approaches I'm considering, I use *lmer* to estimate random
>> effects within each gradient descent iteration in boosting. As you might
>> expect, this is computationally intensive. However, my intuition is that
>> this step could be made faster because my use case is very specific.
>> Namely, in each iteration, *X = Z*, and *X* is a sparse matrix of 0s and
>> 1s
>> (with an intercept).
>>
>> I was wondering if anyone had suggestions or (theoretical) guidance on
>> this
>> problem. For instance, is it possible that this special case permits
>> faster
>> optimization via specific derivatives? I'm not expecting this to be
>> implemented in lmer or anything, and I'm happy to work out a basic
>> implementation myself for this case.
>>
>> I've read the vignette on speeding up the performance of lmer, and
>> setting calc.derivs
>> = FALSE resulted in about a 15% performance improvement for free, which
>> was
>> great. I was just wondering if it was possible to go further.
>>
>> Thanks in advance,
>>
>> - Patrick
>>
>> --
>> Patrick Miller
>> Ph.D. Candidate, Quantitative Psychology
>> University of Notre Dame
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


-- 
Patrick Miller
Ph.D. Candidate, Quantitative Psychology
University of Notre Dame

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Aug  9 18:33:27 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 09 Aug 2016 16:33:27 +0000
Subject: [R-sig-ME] Making lme4 faster for specific case of sparse x
In-Reply-To: <CAPb3xuV=TyJBPcVv2tHbqB22V-fkJ3GwpsFmJ31s+_aVnY_59g@mail.gmail.com>
References: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>
	<CAO7JsnR8ULbEgsHGo+MT0L_q1M70D_7jbXhuM6xrxzNdZdm9Cg@mail.gmail.com>
	<CAPb3xuV=TyJBPcVv2tHbqB22V-fkJ3GwpsFmJ31s+_aVnY_59g@mail.gmail.com>
Message-ID: <CAO7JsnSsqr6Kd8mE3aWAaCSz4mSg0p8vVZo+gDPm6sCxmG4k8A@mail.gmail.com>

On Tue, Aug 9, 2016 at 8:36 AM Patrick Miller <pmille13 at nd.edu> wrote:

> Thanks for that clarification.  In my situation, the effect of each
> predictor in X was allowed to vary by a single grouping variable. The lmer
> formula is something like the following:
>
> y ~ 1 + X1 + X2 + X3 + ... + ( 1 + X1 + X2 + X3 + ... | id)
>

Okay - that's not the same as X == Z but we'll let that slide.

It is extremely unlikely that you will be able to fit such a model and get
a meaningful result.  Suppose that you have p columns in the fixed-effects
model matrix, X ,and k levels of the id factor.  The covariance matrix of
the random effects will be p by p with p*(p + 1) / 2 distinct elements to
estimate.  It is difficult to estimate large covariance matrices with any
accuracy.  You would need k to be very, very large to have any hope of
doing so.

To make it worthwhile using a sparse representation of X you would need p
to be large - in the hundreds or thousands - which would leave you trying
to estimate tens of thousands of covariance parameters.

It is just not on.

If you feel you must fit this model because of the "keep it maximal" advice
of Barr et al. (2013), remember that they reached that conclusion on the
basis of a simulation of a model with one covariate.  That is, they were
comparing fitting 1 by 1 covariance matrix with fitting a 2 by 2 covariance
matrix.  To conclude on the basis of such a small simulation that everyone
must always use the maximal model, even when it would involve tens or
hundreds of covariance parameters, is quite a leap.

On Mon, Aug 8, 2016 at 6:08 PM, Douglas Bates <bates at stat.wisc.edu> wrote:

> If X == Z don't you have problems with estimability?  It seems that mle
>> would always correspond to all random effects being zero.
>>
>> Perhaps I misunderstand the situation.  Could you provide a bit more
>> detail on how it comes about that X == Z?
>>
>> On Mon, Aug 8, 2016 at 5:01 PM Patrick Miller <pmille13 at nd.edu> wrote:
>>
>>> Hello,
>>>
>>> For my dissertation, I'm working on extending boosted decision trees to
>>> clustered data.
>>>
>>> In one of the approaches I'm considering, I use *lmer* to estimate random
>>> effects within each gradient descent iteration in boosting. As you might
>>> expect, this is computationally intensive. However, my intuition is that
>>> this step could be made faster because my use case is very specific.
>>> Namely, in each iteration, *X = Z*, and *X* is a sparse matrix of 0s and
>>> 1s
>>> (with an intercept).
>>>
>>> I was wondering if anyone had suggestions or (theoretical) guidance on
>>> this
>>> problem. For instance, is it possible that this special case permits
>>> faster
>>> optimization via specific derivatives? I'm not expecting this to be
>>> implemented in lmer or anything, and I'm happy to work out a basic
>>> implementation myself for this case.
>>>
>>> I've read the vignette on speeding up the performance of lmer, and
>>> setting calc.derivs
>>> = FALSE resulted in about a 15% performance improvement for free, which
>>> was
>>> great. I was just wondering if it was possible to go further.
>>>
>>> Thanks in advance,
>>>
>>> - Patrick
>>>
>>> --
>>> Patrick Miller
>>> Ph.D. Candidate, Quantitative Psychology
>>> University of Notre Dame
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>
> --
> Patrick Miller
> Ph.D. Candidate, Quantitative Psychology
> University of Notre Dame
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 10 01:28:16 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 9 Aug 2016 19:28:16 -0400
Subject: [R-sig-ME] Making lme4 faster for specific case of sparse x
In-Reply-To: <CAO7JsnSsqr6Kd8mE3aWAaCSz4mSg0p8vVZo+gDPm6sCxmG4k8A@mail.gmail.com>
References: <CAPb3xuUnJ24Lea9HJe7F+2OBMchx+SeVKXdvLcUx1rUsssjkOA@mail.gmail.com>
	<CAO7JsnR8ULbEgsHGo+MT0L_q1M70D_7jbXhuM6xrxzNdZdm9Cg@mail.gmail.com>
	<CAPb3xuV=TyJBPcVv2tHbqB22V-fkJ3GwpsFmJ31s+_aVnY_59g@mail.gmail.com>
	<CAO7JsnSsqr6Kd8mE3aWAaCSz4mSg0p8vVZo+gDPm6sCxmG4k8A@mail.gmail.com>
Message-ID: <6d3e401d-b2dc-cfff-0aeb-3f1d78320bd5@gmail.com>


 A few more thoughts:

  I'm not quite sure why a sparse representation of X is only worthwhile
when p is very large.  I haven't done the arithmetic on the storage
required in the sparse representation (column pointers, locations,
values) ... so I decided to do an experiment

> z <- data.frame(f=factor(sample(8,size=10000,replace=TRUE)))
> m <- model.matrix(~f,data=z)
> m2 <- Matrix::sparse.model.matrix(~f,data=z)
> print(object.size(m),units="Mb")
1.1 Mb
> print(object.size(m2),units="Mb")
0.8 Mb

  This is only about a 35% improvement, but (while not an order of
magnitude) that might not be trivial ...

  Depending on what stays fixed between gradient descent steps, you
might be able to save time by updating individual components of the
stuff returned by lFormula() (see ?modular), and especially mkReTrms().

  You can probably save time by switching to the BOBYQA implementation
in nloptr.

  If you *do* have a large variance-covariance matrix, you might be able
to specialize to a diagonal, compound-symmetry, or factor-analytic
variance-covariance matrix (see Steve Walker's lme4ord package on github)





On 16-08-09 12:33 PM, Douglas Bates wrote:
> On Tue, Aug 9, 2016 at 8:36 AM Patrick Miller <pmille13 at nd.edu> wrote:
> 
>> Thanks for that clarification.  In my situation, the effect of each
>> predictor in X was allowed to vary by a single grouping variable. The lmer
>> formula is something like the following:
>>
>> y ~ 1 + X1 + X2 + X3 + ... + ( 1 + X1 + X2 + X3 + ... | id)
>>
> 
> Okay - that's not the same as X == Z but we'll let that slide.
> 
> It is extremely unlikely that you will be able to fit such a model and get
> a meaningful result.  Suppose that you have p columns in the fixed-effects
> model matrix, X ,and k levels of the id factor.  The covariance matrix of
> the random effects will be p by p with p*(p + 1) / 2 distinct elements to
> estimate.  It is difficult to estimate large covariance matrices with any
> accuracy.  You would need k to be very, very large to have any hope of
> doing so.
> 
> To make it worthwhile using a sparse representation of X you would need p
> to be large - in the hundreds or thousands - which would leave you trying
> to estimate tens of thousands of covariance parameters.
> 
> It is just not on.
> 
> If you feel you must fit this model because of the "keep it maximal" advice
> of Barr et al. (2013), remember that they reached that conclusion on the
> basis of a simulation of a model with one covariate.  That is, they were
> comparing fitting 1 by 1 covariance matrix with fitting a 2 by 2 covariance
> matrix.  To conclude on the basis of such a small simulation that everyone
> must always use the maximal model, even when it would involve tens or
> hundreds of covariance parameters, is quite a leap.
> 
> On Mon, Aug 8, 2016 at 6:08 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> 
>> If X == Z don't you have problems with estimability?  It seems that mle
>>> would always correspond to all random effects being zero.
>>>
>>> Perhaps I misunderstand the situation.  Could you provide a bit more
>>> detail on how it comes about that X == Z?
>>>
>>> On Mon, Aug 8, 2016 at 5:01 PM Patrick Miller <pmille13 at nd.edu> wrote:
>>>
>>>> Hello,
>>>>
>>>> For my dissertation, I'm working on extending boosted decision trees to
>>>> clustered data.
>>>>
>>>> In one of the approaches I'm considering, I use *lmer* to estimate random
>>>> effects within each gradient descent iteration in boosting. As you might
>>>> expect, this is computationally intensive. However, my intuition is that
>>>> this step could be made faster because my use case is very specific.
>>>> Namely, in each iteration, *X = Z*, and *X* is a sparse matrix of 0s and
>>>> 1s
>>>> (with an intercept).
>>>>
>>>> I was wondering if anyone had suggestions or (theoretical) guidance on
>>>> this
>>>> problem. For instance, is it possible that this special case permits
>>>> faster
>>>> optimization via specific derivatives? I'm not expecting this to be
>>>> implemented in lmer or anything, and I'm happy to work out a basic
>>>> implementation myself for this case.
>>>>
>>>> I've read the vignette on speeding up the performance of lmer, and
>>>> setting calc.derivs
>>>> = FALSE resulted in about a 15% performance improvement for free, which
>>>> was
>>>> great. I was just wondering if it was possible to go further.
>>>>
>>>> Thanks in advance,
>>>>
>>>> - Patrick
>>>>
>>>> --
>>>> Patrick Miller
>>>> Ph.D. Candidate, Quantitative Psychology
>>>> University of Notre Dame
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>>
>> --
>> Patrick Miller
>> Ph.D. Candidate, Quantitative Psychology
>> University of Notre Dame
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gaughra at tcd.ie  Wed Aug 10 12:36:03 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Wed, 10 Aug 2016 11:36:03 +0100
Subject: [R-sig-ME] Unable to standardize global glmmadmb model
Message-ID: <CAN=0SEnLA6LBydEwjWqD8gdzpGQZc0D-D+Pb_Zun1n=S=gswNg@mail.gmail.com>

Hello Mixed-Modellers,

I have getting the following error message when trying to standardize my
global glmmadmb model for dredging:

Error in (function (classes, fdef, mtable)  : unable to find an inherited
method for function ?standardize? for signature ?"glmmadmb"?

Is it not possible to standardise a glmmadmb model or is the problem with
the structure of the model itself?

globalmod    <- glmmadmb(field_count ~ habitat
#categorical - 7 levels
                     +
season_wt
#categorial - 3 levels
                     +
sex
#categorial - 2 levels
                     +
ageclass
#categorial - 3 levels
                     +
slope
#continuous, not scaled nor centred
                     +
NSEW
#catagorical - 4 levels
                     +
month_fix
#continuous, not scaled nor centred,
                     + num_fields
                  #continuous, not scaled nor centred
                     + habitat:ageclass
                     + habitat:sex
                     + offset(log(origarea))
                     + offset(log(PropAvlHab))

+(1|individual_id)
#repeated obs from same individual

+(1|field_id)
#repeated obs in same field,
                     family="nbinom",
                     zeroInflation=TRUE,
                     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
                     debug=TRUE,
                     data = dframe1)

no of observations =9220

Many thanks,

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From shebrahimi_3622 at yahoo.com  Wed Aug 10 13:33:15 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Wed, 10 Aug 2016 11:33:15 +0000 (UTC)
Subject: [R-sig-ME] cross validation for lme4
References: <757782822.14527003.1470828795658.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <757782822.14527003.1470828795658.JavaMail.yahoo@mail.yahoo.com>

Dear Mr./Ms
Greetings
I would be very grateful if you could let me have access to codes implementing cross validation while estimating a glmer.
Best regards,
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 10 23:01:31 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Aug 2016 17:01:31 -0400
Subject: [R-sig-ME] simulate for glmmADMB
In-Reply-To: <20160810134435.254CC1880D2@r-forge.r-project.org>
References: <20160810134435.254CC1880D2@r-forge.r-project.org>
Message-ID: <eb5167d3-0fdb-e461-076d-bc2b083bedf0@mcmaster.ca>


 [cc'ing to r-sig-mixed-models]

On 16-08-10 09:44 AM, Chris wrote:
> I'm hoping to do some posterior predictive simulation with a ZIP
> model fit in GLMMADMB  (to better assess model fit and to compare its
> predictive ability with models fit with glmer).  I understand there
> is no simulate method implemented yet for glmmADMB, and the "predict"
> method (and code that I've been able to locate, such as on your
> wikidot GLMM page) does not appear to include random effects.  My
> model has a single random effect (intercept only) that I would like
> to include (so that I have output analogous to that of the "simulate"
> method in lme4).  Given that it is not an incredibly complex model,
> I'm wondering if this is something that I can tackle myself;  I'm
> assuming I would have to adapt the "predict" code to include the
> estimates of the random intercepts and their variability (which
> appear to be "U" and "sd_U" in the fitted glmmADMB model object) and
> perhaps as well  the zero-inflation coefficient (pz" and "sd_pz"?).
> Can you help to point me in the right direction as to how I might
> achieve this?

  I think you're on the right track.  I would look at
glmmADMB:::predict.glmmadmb (or just use it) for constructing the
fixed-effects part of the simulation.  Then for a single random
intercept, you can either simulate from the estimated distribution of
conditional modes *unconditionally* (which is what lme4 does),

  uvals <- rnorm(length(fm$U),mean=0,sd=sqrt(c(VarCorr(fm)[[1]]))

where fm is the fitted model, or simulate *conditionally* on the
observed values

  uvals <- rnorm(length(fm$U),mean=fm$U,sd=fm$sd_U)

Then add uvals to the predictions (pred_vals <- pred_vals +
uvals[grpvar]); transform back to the response scale (e.g. exp-transform
for NB models); add zero-inflation if necessary

val <- ifelse(runif(nobs)<fm$pz,0,rnbinom(nobs,mu=pred_vals,size=fm$alpha))

if you use NB1 or some more exotic distribution it may be harder to
simulate ...

  cheers
    Ben Bolker

> 
> Many thanks, Chris
>


From drmccloy at uw.edu  Thu Aug 11 18:48:55 2016
From: drmccloy at uw.edu (Dan McCloy)
Date: Thu, 11 Aug 2016 09:48:55 -0700
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAGZ4N0+Pk9t9AwhGb6RrU1_Jm6xpd40LA3V2hAyq9iQx4Fz96w@mail.gmail.com>
References: <CAGZ4N0JKXswb959mfr3g3Fs6ebmqV6vZgmqdn30DrVNQAAJrSw@mail.gmail.com>
	<CAOE0pYkN4fQRM70o=iDUVk9F4WZwvBPk8hqBqzGWffarQYDBYA@mail.gmail.com>
	<CAGZ4N0+Pk9t9AwhGb6RrU1_Jm6xpd40LA3V2hAyq9iQx4Fz96w@mail.gmail.com>
Message-ID: <CAOE0pYk=sBG9j50GXH=4DUvSogG7D=db58Q2VqsKr9Usr4erqg@mail.gmail.com>

[please keep mailing list in cc]

I don't know much about your study design details, and there are situations
where it would matter to include such nested groupings.  For example,
imagine that some of the "items" were problems with very similar solutions,
and after solving one of them, it was easier to solve subsequent ones of
the same type.  The random grouping of items might have led to one fairly
homogeneous item group (that would be easier) and other item groups that
were more heterogeneous (and harder).  In such a circumstance, the nested
grouping would capture the extent to which the random groupings yielded
non-balanced groups (with respect to some dimension that is desirable to
balance, such as "difficulty" in this example).

If you are worried about this possibility, then use the nested group syntax
as previously suggested.  On the other hand, if you are confident in your
assertion that "the groups do not have any theoretical relations and all
was divided totally randomly" and thus believe that the groups are
equivalent/balanced on all the dimensions that matter, then it is unlikely
that modeling the nesting is going to yield different answers / better
model fits / etc.  But as I said before, your dataset is small enough that
you could just try it both ways and compare the two models...



On Thu, Aug 11, 2016 at 12:32 AM, Meir Barneron <meir.barneron at gmail.com>
wrote:

> Hey Dan,
>
> thank you very much for your answer.
> If I understood you, your advice is to run a model only with a random error
> on subjects and items because the group were created in a random manner?
>
> thanks again
>
> Meir
>
> 2016-08-08 21:12 GMT+03:00 Dan McCloy <drmccloy at uw.edu>:
>
>> The GLMM FAQ has some information about specifying nested random
>> effects.  See especially the "model specification" table [1] and the
>> "nested or crossed" section [2].  Something like this may be what you're
>> looking for:
>>
>> grade ~ Time + (Time | SubjectGroup / Subject) + (Time | ItemGroup / Item)
>>
>> Given that you've assigned groups randomly, I'm unsure if there will be
>> much benefit to modeling the groups this way (unless maybe "grade" for one
>> subject/item is somehow influenced by the other subjects or items in the
>> group?).  Anyway, the dataset is small enough that it will be easy to try
>> and see what happens.  Also note that if "Time" has only two values, it can
>> be treated as a factor (like "pre" and "post" treatment).
>>
>> [1]: https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.
>> html#model-specification
>> [2]: https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.
>> html#nested-or-crossed
>>
>> -- dan
>>
>> Daniel McCloy
>> http://dan.mccloy.info/
>> Postdoctoral Research Associate
>> Institute for Learning and Brain Sciences
>> University of Washington
>>
>>
> On Thu, Aug 4, 2016 at 2:22 AM, Meir Barneron <meir.barneron at gmail.com>
> wrote:
>
>> Hi everyone,
>>
>> I am relatively new in MEMs, and trying to tigure out what is the best
>> model fo my data. The data itself is relatively simple but the design more
>> complicated..
>>
>> To make it simpler, I am interested in investigating if there is a
>> difference between two measures made at two point in time (1 and 2), that
>> is all. My dependent variable is a grade. I do not enter into details in
>> order to keep it as simple as possible. My theory predicts that the grades
>> will be smaller at time 2 compared to time 1.
>>
>> Basically I have 30 subjects, and 100 Items and I want to make sure that
>> there is an effect after controlling for subjects and items. Here is the
>> design.
>> Before the experiment I randomly selected 30 subjects from a pool. I also
>> randomly selected 100 items from a pool. Next,  I randomly divided the 30
>> subjects into 5 groups of 6 subjects. I also randomly divided the 100
>> items into 5 groups of 20 items. The groups do not have any theoretical
>> relations and all was divided totally randomly.
>>
>> Then I assigned one group of 20 items to one group of 6 subjects. Within
>> each group, each 6 subjects saw each 20 items. For each Items, each
>> subject
>> gave me one grade at Time 1, and one at Time 2.
>>
>> My question is how to model this design. One possibility I have tried
>> if to ignore the group and took into account only the subjects and the
>> items.
>> This is my syntax:
>> model1 <- lmer(Grade ~ 1 + Time +
>>                  (1 + Time | Subject) +
>>                  (1 + Time | Item),
>>                REML=F, data = NITE1)
>>
>> Does anyone have an idea how to take the "group" into account?
>> Alternaltvely, do you think the model I built is sufficient?
>>
>> Thank you in advance
>>
>> Meir
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Aug 12 15:37:41 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Aug 2016 09:37:41 -0400
Subject: [R-sig-ME] searchable archives?
Message-ID: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>


  Can anyone point me to searchable archives of the list?  I usually use
Gmane, but it seems to be down.  Unless I'm mistaken, the official
archives <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> aren't
searchable.

 - although https://www.r-project.org/search.html says "This engine lets
you search help files, manuals, and mailing list archives",
http://finzi.psych.upenn.edu/search.html only says it indexes "R
functions, package vignettes, and task views"

 - I can't get the search bar at
http://r-sig-mixed-models.r-project.narkive.com to work ...

  - I can't figure out whether Nabble mirrors r-sig-mixed-models

  More specifically, I'm trying to remember a generic critique of AIC
weights someone posted to the list a while back ...

  cheers
    Ben Bolker


From bbolker at gmail.com  Fri Aug 12 16:09:05 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Aug 2016 10:09:05 -0400
Subject: [R-sig-ME] cross-validation
Message-ID: <2aadbac4-0098-5bd9-e58f-b086b622625b@math.mcmaster.ca>

There was a request for cross-validation code some time ago.  This is a
simple example of leave-one-out CV at the level of groups.

dd <- read.table(header=TRUE,
text="
ID TIME EVENT  x1       x2    x3      x4       x5
1   1   0   1.281   0.023   0.875   1.216   0.061
1   2   0   1.270   0.006   0.821   1.005   -0.014
1   3   0   1.053   -0.059  0.922   0.729   0.020
1   4   0   1.113   -0.015  0.859   0.810   0.076
1   5   1   1.220   -0.059  0.887   0.484   0.010
 2   1   0   1.062   0.107   0.815   0.836   0.200
 2   2   0   1.056   0.082   0.879   0.687   0.143
 2   3   0   0.971   0.076   0.907   0.810   0.166
 2   4   0   1.059   0.130   0.818   0.876   0.234
 2   5   0   1.125   0.148   0.759   1.080   0.276
 2   6   0   1.600   0.262   0.546   1.313   0.369
 2   7   0   1.576   0.262   0.564   1.156   0.349
 2   8   0   1.544   0.241   0.591   1.077   0.326
 2   9   0   1.722   0.215   0.552   0.841   0.293
 2   10  0   1.723   0.209   0.534   0.787   0.293
 2   11  0   1.631   0.186   0.548   0.728   0.274
 2   12  0   2.172   0.319   0.441   0.947   0.427
 3   1   0   0.874   -0.035  0.794   0.610   -0.003
 3   2   1   0.825   -0.142  0.952   0.573   -0.019")
require(lme4)
model1 <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=dd,
                family=binomial)

cvfun1 <- function(pred_id,pcut=0.5) {
    train <- subset(dd,!(ID %in% pred_id))
    mm <- suppressWarnings(update(model1, data=train))
    test <- subset(dd,ID %in% pred_id)
    prob <- predict(mm,type="response",newdata=test,re.form=~0)
    outcome <- as.numeric(prob>pcut)
    acc <- mean(outcome==test$EVENT)
    return(acc)
}

sapply(1:3,cvfun1)


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Aug 12 16:58:25 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 12 Aug 2016 14:58:25 +0000
Subject: [R-sig-ME] searchable archives?
In-Reply-To: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
References: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
Message-ID: <e14d715279934b519d58b64117ad561c@UM-MAIL3216.unimaas.nl>

Hi Ben,

How about just using google with:

site:https://stat.ethz.ch/pipermail/r-sig-mixed-models/

Of course, recent posts won't be found until google comes around again to crawl the site.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Friday, August 12, 2016 15:38
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] searchable archives?
> 
>   Can anyone point me to searchable archives of the list?  I usually use
> Gmane, but it seems to be down.  Unless I'm mistaken, the official
> archives <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> aren't
> searchable.
> 
>  - although https://www.r-project.org/search.html says "This engine lets
> you search help files, manuals, and mailing list archives",
> http://finzi.psych.upenn.edu/search.html only says it indexes "R
> functions, package vignettes, and task views"
> 
>  - I can't get the search bar at
> http://r-sig-mixed-models.r-project.narkive.com to work ...
> 
>   - I can't figure out whether Nabble mirrors r-sig-mixed-models
> 
>   More specifically, I'm trying to remember a generic critique of AIC
> weights someone posted to the list a while back ...
> 
>   cheers
>     Ben Bolker


From jake.a.westfall at gmail.com  Fri Aug 12 17:18:55 2016
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Fri, 12 Aug 2016 10:18:55 -0500
Subject: [R-sig-ME] searchable archives?
In-Reply-To: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
References: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
Message-ID: <CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>

The archives at stat.ethz.ch may not be searchable, but you can sort of
fake it using Google queries directed at the site/directory, e.g.,:

weights site:stat.ethz.ch/pipermail/r-sig-mixed-models/

Not sure if this will work for you, searching "IAC" didn't seem to turn up
any results, which isn't a good sign, although other queries seem to work
fine.

Jake

On Fri, Aug 12, 2016 at 8:37 AM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   Can anyone point me to searchable archives of the list?  I usually use
> Gmane, but it seems to be down.  Unless I'm mistaken, the official
> archives <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> aren't
> searchable.
>
>  - although https://www.r-project.org/search.html says "This engine lets
> you search help files, manuals, and mailing list archives",
> http://finzi.psych.upenn.edu/search.html only says it indexes "R
> functions, package vignettes, and task views"
>
>  - I can't get the search bar at
> http://r-sig-mixed-models.r-project.narkive.com to work ...
>
>   - I can't figure out whether Nabble mirrors r-sig-mixed-models
>
>   More specifically, I'm trying to remember a generic critique of AIC
> weights someone posted to the list a while back ...
>
>   cheers
>     Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Fri Aug 12 17:20:03 2016
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Fri, 12 Aug 2016 10:20:03 -0500
Subject: [R-sig-ME] searchable archives?
In-Reply-To: <CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>
References: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
	<CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>
Message-ID: <CAE9_Wg46k-KwDmi=sMa=ON-HxGi9reWf5fgMMKk1E5EjvhBG3Q@mail.gmail.com>

Oh, I guess Wolfgang beat me to it :p

Jake

On Fri, Aug 12, 2016 at 10:18 AM, Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> The archives at stat.ethz.ch may not be searchable, but you can sort of
> fake it using Google queries directed at the site/directory, e.g.,:
>
> weights site:stat.ethz.ch/pipermail/r-sig-mixed-models/
>
> Not sure if this will work for you, searching "IAC" didn't seem to turn up
> any results, which isn't a good sign, although other queries seem to work
> fine.
>
> Jake
>
> On Fri, Aug 12, 2016 at 8:37 AM, Ben Bolker <bbolker at gmail.com> wrote:
>
>>
>>   Can anyone point me to searchable archives of the list?  I usually use
>> Gmane, but it seems to be down.  Unless I'm mistaken, the official
>> archives <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> aren't
>> searchable.
>>
>>  - although https://www.r-project.org/search.html says "This engine lets
>> you search help files, manuals, and mailing list archives",
>> http://finzi.psych.upenn.edu/search.html only says it indexes "R
>> functions, package vignettes, and task views"
>>
>>  - I can't get the search bar at
>> http://r-sig-mixed-models.r-project.narkive.com to work ...
>>
>>   - I can't figure out whether Nabble mirrors r-sig-mixed-models
>>
>>   More specifically, I'm trying to remember a generic critique of AIC
>> weights someone posted to the list a while back ...
>>
>>   cheers
>>     Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Aug 13 09:52:55 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 13 Aug 2016 09:52:55 +0200
Subject: [R-sig-ME] searchable archives?
In-Reply-To: <CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>
References: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
	<CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>
Message-ID: <6DB868AC-522A-4B83-A464-F98EE1B082B9@gmail.com>


> On 12 Aug 2016, at 17:18 , Jake Westfall <jake.a.westfall at gmail.com> wrote:
> 
> weights site:stat.ethz.ch/pipermail/r-sig-mixed-models/
> 
> Not sure if this will work for you, searching "IAC" didn't seem to turn up
> any results, which isn't a good sign, although other queries seem to work
> fine.

Just a sign of bad spelling, I'd say.... 

http://www.acronymfinder.com/Science-and-Medicine/IAC.html 

;-)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From meir.barneron at gmail.com  Sun Aug 14 09:22:06 2016
From: meir.barneron at gmail.com (Meir Barneron)
Date: Sun, 14 Aug 2016 10:22:06 +0300
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAOE0pYk=sBG9j50GXH=4DUvSogG7D=db58Q2VqsKr9Usr4erqg@mail.gmail.com>
References: <CAGZ4N0JKXswb959mfr3g3Fs6ebmqV6vZgmqdn30DrVNQAAJrSw@mail.gmail.com>
	<CAOE0pYkN4fQRM70o=iDUVk9F4WZwvBPk8hqBqzGWffarQYDBYA@mail.gmail.com>
	<CAGZ4N0+Pk9t9AwhGb6RrU1_Jm6xpd40LA3V2hAyq9iQx4Fz96w@mail.gmail.com>
	<CAOE0pYk=sBG9j50GXH=4DUvSogG7D=db58Q2VqsKr9Usr4erqg@mail.gmail.com>
Message-ID: <CAGZ4N0JjHBOh8RmAuW8_yqQyh4T6wLM22a74znUkQZ6eXZRs0w@mail.gmail.com>

Great, thank you for your recommendations.

Meir

2016-08-11 19:48 GMT+03:00 Dan McCloy <drmccloy at uw.edu>:

> [please keep mailing list in cc]
>
> I don't know much about your study design details, and there are
> situations where it would matter to include such nested groupings.  For
> example, imagine that some of the "items" were problems with very similar
> solutions, and after solving one of them, it was easier to solve subsequent
> ones of the same type.  The random grouping of items might have led to one
> fairly homogeneous item group (that would be easier) and other item groups
> that were more heterogeneous (and harder).  In such a circumstance, the
> nested grouping would capture the extent to which the random groupings
> yielded non-balanced groups (with respect to some dimension that is
> desirable to balance, such as "difficulty" in this example).
>
> If you are worried about this possibility, then use the nested group
> syntax as previously suggested.  On the other hand, if you are confident in
> your assertion that "the groups do not have any theoretical relations and
> all was divided totally randomly" and thus believe that the groups are
> equivalent/balanced on all the dimensions that matter, then it is unlikely
> that modeling the nesting is going to yield different answers / better
> model fits / etc.  But as I said before, your dataset is small enough that
> you could just try it both ways and compare the two models...
>
>
>
On Thu, Aug 11, 2016 at 12:32 AM, Meir Barneron <meir.barneron at gmail.com>
wrote:

> Hey Dan,
>
> thank you very much for your answer.
> If I understood you, your advice is to run a model only with a random error
> on subjects and items because the group were created in a random manner?
>
> thanks again
>
> Meir
>
> 2016-08-08 21:12 GMT+03:00 Dan McCloy <drmccloy at uw.edu>:
>
>> The GLMM FAQ has some information about specifying nested random
>> effects.  See especially the "model specification" table [1] and the
>> "nested or crossed" section [2].  Something like this may be what you're
>> looking for:
>>
>> grade ~ Time + (Time | SubjectGroup / Subject) + (Time | ItemGroup / Item)
>>
>> Given that you've assigned groups randomly, I'm unsure if there will be
>> much benefit to modeling the groups this way (unless maybe "grade" for one
>> subject/item is somehow influenced by the other subjects or items in the
>> group?).  Anyway, the dataset is small enough that it will be easy to try
>> and see what happens.  Also note that if "Time" has only two values, it can
>> be treated as a factor (like "pre" and "post" treatment).
>>
>> [1]: https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.h
>> tml#model-specification
>> [2]: https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.h
>> tml#nested-or-crossed
>>
>> -- dan
>>
>> Daniel McCloy
>> http://dan.mccloy.info/
>> Postdoctoral Research Associate
>> Institute for Learning and Brain Sciences
>> University of Washington
>>
>>
> On Thu, Aug 4, 2016 at 2:22 AM, Meir Barneron <meir.barneron at gmail.com>
> wrote:
>
>> Hi everyone,
>>
>> I am relatively new in MEMs, and trying to tigure out what is the best
>> model fo my data. The data itself is relatively simple but the design more
>> complicated..
>>
>> To make it simpler, I am interested in investigating if there is a
>> difference between two measures made at two point in time (1 and 2), that
>> is all. My dependent variable is a grade. I do not enter into details in
>> order to keep it as simple as possible. My theory predicts that the grades
>> will be smaller at time 2 compared to time 1.
>>
>> Basically I have 30 subjects, and 100 Items and I want to make sure that
>> there is an effect after controlling for subjects and items. Here is the
>> design.
>> Before the experiment I randomly selected 30 subjects from a pool. I also
>> randomly selected 100 items from a pool. Next,  I randomly divided the 30
>> subjects into 5 groups of 6 subjects. I also randomly divided the 100
>> items into 5 groups of 20 items. The groups do not have any theoretical
>> relations and all was divided totally randomly.
>>
>> Then I assigned one group of 20 items to one group of 6 subjects. Within
>> each group, each 6 subjects saw each 20 items. For each Items, each
>> subject
>> gave me one grade at Time 1, and one at Time 2.
>>
>> My question is how to model this design. One possibility I have tried
>> if to ignore the group and took into account only the subjects and the
>> items.
>> This is my syntax:
>> model1 <- lmer(Grade ~ 1 + Time +
>>                  (1 + Time | Subject) +
>>                  (1 + Time | Item),
>>                REML=F, data = NITE1)
>>
>> Does anyone have an idea how to take the "group" into account?
>> Alternaltvely, do you think the model I built is sufficient?
>>
>> Thank you in advance
>>
>> Meir
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From sophia.kyriakou17 at gmail.com  Sun Aug 14 23:50:38 2016
From: sophia.kyriakou17 at gmail.com (Sophia Kyriakou)
Date: Mon, 15 Aug 2016 00:50:38 +0300
Subject: [R-sig-ME] glmmTMB: variance-covariance matrix parameterization
Message-ID: <CAO4gA+qgi=YADiQ=CiT7YYQud8rvZN2jQv84F4KyMvOKLX48jw@mail.gmail.com>

Hi all,

Does anyone know what is the parameterization that glmmTMB uses for the
variance-covariance matrix in the case of generelized linear mixed models?

I can tell that when fitting a generalized linear mixed model with a random
intercept, where the random effects are normally distributed with zero mean
and variance sigma^2, glmmTMB estimates theta = log(sigma) and then returns
sigma^2.

But what is the parameterization for example in the 2 x 2 random-slopes
case?
Let the 2 x 2 variance-covariance matrix have elements ( sigma^2_{1},
sigma_{12}, sigma_{12}, sigma^2_{2} ).
glmmTMB returns three theta parameters (theta_1, theta_2, theta_3), where
theta_1 = log(sigma_1)
theta_2 = log(sigma_2)
but I don't know what the relationship between theta_3 and sigma_{12} (or
the correlation rho) is.

I know that I can extract thetas using fitTMB$sdr$par.fixed and sigmas
using matrix(unlist(VarCorr(fitTMB)),2,2), where fitTMB is the model fitted
via glmmTMB, but I would like to understand the parameterization used.

Thank you in advance.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Aug 15 02:11:46 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 14 Aug 2016 20:11:46 -0400
Subject: [R-sig-ME] glmmTMB: variance-covariance matrix parameterization
In-Reply-To: <CAO4gA+qgi=YADiQ=CiT7YYQud8rvZN2jQv84F4KyMvOKLX48jw@mail.gmail.com>
References: <CAO4gA+qgi=YADiQ=CiT7YYQud8rvZN2jQv84F4KyMvOKLX48jw@mail.gmail.com>
Message-ID: <CABghstQSKOv+tX3ghmGOmbya4p2WRT3uJ+2+mqVg5xW_QJVdrA@mail.gmail.com>

Starting at

https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/src/glmmTMB.cpp#L151

for an nxn variance-covariance matrix, we have the first n parameters
as the logarithms of the standard deviation.  The remaining parameters
fill in the lower triangle (in column-major order) of the Cholesky
factor of the correlation matrix: information on this is at

http://kaskr.github.io/adcomp/classUNSTRUCTURED__CORR__t.html

So, for a 2x2 unstructured variance-covariance matrix, the first two
parameters are the log-sd, the third parameter is the correlation.

 I'm adding this to the documentation for ?VarCorr ...




On Sun, Aug 14, 2016 at 5:50 PM, Sophia Kyriakou
<sophia.kyriakou17 at gmail.com> wrote:
> Hi all,
>
> Does anyone know what is the parameterization that glmmTMB uses for the
> variance-covariance matrix in the case of generelized linear mixed models?
>
> I can tell that when fitting a generalized linear mixed model with a random
> intercept, where the random effects are normally distributed with zero mean
> and variance sigma^2, glmmTMB estimates theta = log(sigma) and then returns
> sigma^2.
>
> But what is the parameterization for example in the 2 x 2 random-slopes
> case?
> Let the 2 x 2 variance-covariance matrix have elements ( sigma^2_{1},
> sigma_{12}, sigma_{12}, sigma^2_{2} ).
> glmmTMB returns three theta parameters (theta_1, theta_2, theta_3), where
> theta_1 = log(sigma_1)
> theta_2 = log(sigma_2)
> but I don't know what the relationship between theta_3 and sigma_{12} (or
> the correlation rho) is.
>
> I know that I can extract thetas using fitTMB$sdr$par.fixed and sigmas
> using matrix(unlist(VarCorr(fitTMB)),2,2), where fitTMB is the model fitted
> via glmmTMB, but I would like to understand the parameterization used.
>
> Thank you in advance.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gaughra at tcd.ie  Mon Aug 15 11:06:53 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Mon, 15 Aug 2016 10:06:53 +0100
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
Message-ID: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>

Hello Mixed-Modellers,

I have getting the following error message when trying to standardize my
global glmmadmb model for dredging:

Error in (function (classes, fdef, mtable)  : unable to find an inherited
method for function ?standardize? for signature ?"glmmadmb"?

Is it not possible to standardise a glmmadmb model or is the problem with
the structure of the model itself?

globalmod    <- glmmadmb(field_count ~ habitat
#categorical - 7 levels
                     + season_wt
                                         #categorial - 3 levels
                     + sex
                                              #categorial - 2 levels
                     + ageclass
                                           #categorial - 3 levels
                     + slope
                                             #continuous, not scaled nor
centred
                     + NSEW
                                          #catagorical - 4 levels
                     + month_fix
                                          #continuous, not scaled nor
centred,
                     + num_fields
                  #continuous, not scaled nor centred
                     + habitat:ageclass
                     + habitat:sex
                     + offset(log(origarea))
                     + offset(log(PropAvlHab))
                     +(1|individual_id)
                                           #repeated obs from same
individual
                     +(1|field_id)
                                              #repeated obs in same field,
                     family="nbinom",
                     zeroInflation=TRUE,
                     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
                     debug=TRUE,
                     data = dframe1)

no of observations =9220

Many thanks,

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Aug 15 16:12:55 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 15 Aug 2016 10:12:55 -0400
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
Message-ID: <CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>

'standardize' is a function from the arm package.

I've just hacked glmmADMB a little bit so this should work:

library(devtools)
install_github("bbolker/glmmADMB")  ## install latest version
library(arm)
arm:::standardize.default(fitted_model$call)



On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> Hello Mixed-Modellers,
>
> I have getting the following error message when trying to standardize my
> global glmmadmb model for dredging:
>
> Error in (function (classes, fdef, mtable)  : unable to find an inherited
> method for function ?standardize? for signature ?"glmmadmb"?
>
> Is it not possible to standardise a glmmadmb model or is the problem with
> the structure of the model itself?
>
> globalmod    <- glmmadmb(field_count ~ habitat
> #categorical - 7 levels
>                      + season_wt
>                                          #categorial - 3 levels
>                      + sex
>                                               #categorial - 2 levels
>                      + ageclass
>                                            #categorial - 3 levels
>                      + slope
>                                              #continuous, not scaled nor
> centred
>                      + NSEW
>                                           #catagorical - 4 levels
>                      + month_fix
>                                           #continuous, not scaled nor
> centred,
>                      + num_fields
>                   #continuous, not scaled nor centred
>                      + habitat:ageclass
>                      + habitat:sex
>                      + offset(log(origarea))
>                      + offset(log(PropAvlHab))
>                      +(1|individual_id)
>                                            #repeated obs from same
> individual
>                      +(1|field_id)
>                                               #repeated obs in same field,
>                      family="nbinom",
>                      zeroInflation=TRUE,
>                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>                      debug=TRUE,
>                      data = dframe1)
>
> no of observations =9220
>
> Many thanks,
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gaughra at tcd.ie  Mon Aug 15 16:37:23 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Mon, 15 Aug 2016 15:37:23 +0100
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
Message-ID: <CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>

Thanks Ben, I ran the code and got the following error and warnings:-

Error in glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +  :
  rank of X = 16 < ncol(X) = 24In addition: Warning messages:1: In
log(z.PropAvlHab) : NaNs produced2: In glmmadmb(formula = field_count
~ habitat + season_wt + c.sex +  :
  NAs removed in constructing fixed-effect model frame: you should
probably remove them manually, e.g. with na.omit()


The original PropAvlHab summary is as follows:-

> summary(dframe1$PropAvlHab)     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000

Aoibheann


On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com> wrote:

> 'standardize' is a function from the arm package.
>
> I've just hacked glmmADMB a little bit so this should work:
>
> library(devtools)
> install_github("bbolker/glmmADMB")  ## install latest version
> library(arm)
> arm:::standardize.default(fitted_model$call)
>
>
>
> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> wrote:
> > Hello Mixed-Modellers,
> >
> > I have getting the following error message when trying to standardize my
> > global glmmadmb model for dredging:
> >
> > Error in (function (classes, fdef, mtable)  : unable to find an inherited
> > method for function ?standardize? for signature ?"glmmadmb"?
> >
> > Is it not possible to standardise a glmmadmb model or is the problem with
> > the structure of the model itself?
> >
> > globalmod    <- glmmadmb(field_count ~ habitat
> > #categorical - 7 levels
> >                      + season_wt
> >                                          #categorial - 3 levels
> >                      + sex
> >                                               #categorial - 2 levels
> >                      + ageclass
> >                                            #categorial - 3 levels
> >                      + slope
> >                                              #continuous, not scaled nor
> > centred
> >                      + NSEW
> >                                           #catagorical - 4 levels
> >                      + month_fix
> >                                           #continuous, not scaled nor
> > centred,
> >                      + num_fields
> >                   #continuous, not scaled nor centred
> >                      + habitat:ageclass
> >                      + habitat:sex
> >                      + offset(log(origarea))
> >                      + offset(log(PropAvlHab))
> >                      +(1|individual_id)
> >                                            #repeated obs from same
> > individual
> >                      +(1|field_id)
> >                                               #repeated obs in same
> field,
> >                      family="nbinom",
> >                      zeroInflation=TRUE,
> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
> >                      debug=TRUE,
> >                      data = dframe1)
> >
> > no of observations =9220
> >
> > Many thanks,
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From shebrahimi_3622 at yahoo.com  Mon Aug 15 16:47:05 2016
From: shebrahimi_3622 at yahoo.com (shahla ebrahimi)
Date: Mon, 15 Aug 2016 14:47:05 +0000 (UTC)
Subject: [R-sig-ME] cross-validation
In-Reply-To: <2aadbac4-0098-5bd9-e58f-b086b622625b@math.mcmaster.ca>
References: <2aadbac4-0098-5bd9-e58f-b086b622625b@math.mcmaster.ca>
Message-ID: <1419988319.16999482.1471272425821.JavaMail.yahoo@mail.yahoo.com>

Dear Dr. BolkerGreetings,
I thank you so much for your time, consideration and knowledge.
Best regards,

      From: Ben Bolker <bbolker at gmail.com>
 To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org> 
 Sent: Friday, August 12, 2016 6:39 PM
 Subject: [R-sig-ME] cross-validation
   
There was a request for cross-validation code some time ago.? This is a
simple example of leave-one-out CV at the level of groups.

dd <- read.table(header=TRUE,
text="
ID TIME EVENT? x1? ? ? x2? ? x3? ? ? x4? ? ? x5
1? 1? 0? 1.281? 0.023? 0.875? 1.216? 0.061
1? 2? 0? 1.270? 0.006? 0.821? 1.005? -0.014
1? 3? 0? 1.053? -0.059? 0.922? 0.729? 0.020
1? 4? 0? 1.113? -0.015? 0.859? 0.810? 0.076
1? 5? 1? 1.220? -0.059? 0.887? 0.484? 0.010
 2? 1? 0? 1.062? 0.107? 0.815? 0.836? 0.200
 2? 2? 0? 1.056? 0.082? 0.879? 0.687? 0.143
 2? 3? 0? 0.971? 0.076? 0.907? 0.810? 0.166
 2? 4? 0? 1.059? 0.130? 0.818? 0.876? 0.234
 2? 5? 0? 1.125? 0.148? 0.759? 1.080? 0.276
 2? 6? 0? 1.600? 0.262? 0.546? 1.313? 0.369
 2? 7? 0? 1.576? 0.262? 0.564? 1.156? 0.349
 2? 8? 0? 1.544? 0.241? 0.591? 1.077? 0.326
 2? 9? 0? 1.722? 0.215? 0.552? 0.841? 0.293
 2? 10? 0? 1.723? 0.209? 0.534? 0.787? 0.293
 2? 11? 0? 1.631? 0.186? 0.548? 0.728? 0.274
 2? 12? 0? 2.172? 0.319? 0.441? 0.947? 0.427
 3? 1? 0? 0.874? -0.035? 0.794? 0.610? -0.003
 3? 2? 1? 0.825? -0.142? 0.952? 0.573? -0.019")
require(lme4)
model1 <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=dd,
? ? ? ? ? ? ? ? family=binomial)

cvfun1 <- function(pred_id,pcut=0.5) {
? ? train <- subset(dd,!(ID %in% pred_id))
? ? mm <- suppressWarnings(update(model1, data=train))
? ? test <- subset(dd,ID %in% pred_id)
? ? prob <- predict(mm,type="response",newdata=test,re.form=~0)
? ? outcome <- as.numeric(prob>pcut)
? ? acc <- mean(outcome==test$EVENT)
? ? return(acc)
}

sapply(1:3,cvfun1)

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Aug 15 16:47:50 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 15 Aug 2016 10:47:50 -0400
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
Message-ID: <CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>

Hmm.  Surprising/hard to diagnose.

'standardize' doesn't do anything very fancy - it standardizes the
input variables as described by ?arm::standardize and *refits* the
model (I've always been a little disappointed that it doesn't
standardize by figuring out how to transform the *parameters*, which
is straightforward in principle although it can be tricky to figure
out how to deal with input variables that lead to multiple predictor
variables, e.g. polynomials).  I'd be curious to know what's going on,
but in your place I would

(1) try standardizing by hand, e.g.

std_data <- transform(data,
      z.season.wt = scale(season.wt),
     ...)

and refit yourself.

(2) see if it happens to work with glmmTMB (a simple example does).

  Ben Bolker




On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> Thanks Ben, I ran the code and got the following error and warnings:-
>
> Error in glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +  :
>   rank of X = 16 < ncol(X) = 24
> In addition: Warning messages:
> 1: In log(z.PropAvlHab) : NaNs produced
> 2: In glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +  :
>   NAs removed in constructing fixed-effect model frame: you should probably
> remove them manually, e.g. with na.omit()
>
>
> The original PropAvlHab summary is as follows:-
>
>> summary(dframe1$PropAvlHab)
>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
>
> Aoibheann
>
>
>
> On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> 'standardize' is a function from the arm package.
>>
>> I've just hacked glmmADMB a little bit so this should work:
>>
>> library(devtools)
>> install_github("bbolker/glmmADMB")  ## install latest version
>> library(arm)
>> arm:::standardize.default(fitted_model$call)
>>
>>
>>
>> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie>
>> wrote:
>> > Hello Mixed-Modellers,
>> >
>> > I have getting the following error message when trying to standardize my
>> > global glmmadmb model for dredging:
>> >
>> > Error in (function (classes, fdef, mtable)  : unable to find an
>> > inherited
>> > method for function ?standardize? for signature ?"glmmadmb"?
>> >
>> > Is it not possible to standardise a glmmadmb model or is the problem
>> > with
>> > the structure of the model itself?
>> >
>> > globalmod    <- glmmadmb(field_count ~ habitat
>> > #categorical - 7 levels
>> >                      + season_wt
>> >                                          #categorial - 3 levels
>> >                      + sex
>> >                                               #categorial - 2 levels
>> >                      + ageclass
>> >                                            #categorial - 3 levels
>> >                      + slope
>> >                                              #continuous, not scaled nor
>> > centred
>> >                      + NSEW
>> >                                           #catagorical - 4 levels
>> >                      + month_fix
>> >                                           #continuous, not scaled nor
>> > centred,
>> >                      + num_fields
>> >                   #continuous, not scaled nor centred
>> >                      + habitat:ageclass
>> >                      + habitat:sex
>> >                      + offset(log(origarea))
>> >                      + offset(log(PropAvlHab))
>> >                      +(1|individual_id)
>> >                                            #repeated obs from same
>> > individual
>> >                      +(1|field_id)
>> >                                               #repeated obs in same
>> > field,
>> >                      family="nbinom",
>> >                      zeroInflation=TRUE,
>> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>> >                      debug=TRUE,
>> >                      data = dframe1)
>> >
>> > no of observations =9220
>> >
>> > Many thanks,
>> >
>> > --
>> > Aoibheann Gaughran
>> >
>> > Behavioural and Evolutionary Ecology Research Group
>> > Zoology Building
>> > School of Natural Sciences
>> > Trinity College Dublin
>> > Dublin 2
>> > Ireland
>> > Phone: +353 (86) 3812615
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615


From daniel_rubi at ymail.com  Mon Aug 15 19:38:05 2016
From: daniel_rubi at ymail.com (Daniel Rubi)
Date: Mon, 15 Aug 2016 17:38:05 +0000 (UTC)
Subject: [R-sig-ME] Obtaining all effects in a multinomial regression where
 the grand mean is set as baseline
References: <1981606920.2663264.1471282685613.ref@mail.yahoo.com>
Message-ID: <1981606920.2663264.1471282685613@mail.yahoo.com>

I have data from these set of experiments:In each experiment I infect a neuron with a rabies virus. The virus climbs backwards across the axon of the infected neuron and jumps across the synapse to the input axons of that neuron. The rabies will then express a marker gene in the input neurons it jumped to thereby labeling the input neurons to the infected target neuron. The purpose of this is thus to trace the neurons that provide input to the neurons I'm infecting (target cells), thereby creating a connectivity map of this region in the brain.In each experiment I obtain counts of all the infected input neurons.?Here's a simulation of the data: (3 targets and 5 inputs):set.seed(1)
probs <- list(c(0.4,0.1,0.1,0.2,0.2),c(0.1,0.3,0.4,0.1,0.1),c(0.1,0.1,0.4,0.2,0.2))
mat <- matrix(unlist(lapply(probs,function(p) rmultinom(1, as.integer(runif(1,50,150)), p))),ncol=3)
inputs <- LETTERS[1:5]
targets <- letters[1:3]
df <- data.frame(input = c(unlist(apply(mat,2,function(x) rep(inputs ,x)))),target = rep(targets ,apply(mat,2,sum)))
What I'd like to estimate is the effect of each target neuron on these counts, relative to the grand mean. I was thinking that a?multinomial?regression model is appropriate in this case, where the contrasts are set to the?contr.sum?option:
library(foreign)
library(nnet)
library(reshape2)

df$input <- factor(df$input,levels=inputs)
df$target <- factor(df$target,levels=targets)
fit <- multinom(input ~ target, data = df,contrasts = list(target = "contr.sum"))
# weights:  20 (12 variable)
initial  value 505.363505 
iter  10 value 445.057386
final  value 441.645283 
convergedWhich gives me:
> summary(fit)$coefficients
  (Intercept)   target1   target2
B  0.08556288 -1.743854 1.6062660
C  0.55375003 -2.094266 1.2616939
D -0.17624590 -1.364270 0.6284231
E -0.04091248 -1.617374 0.6601274
So the effects for input?A?are not reported. In an?lm?they would be retrieved as:
-1*(apply(summary(fit)$coefficients,2,sum))
But I'm wondering whether it is the same for?multinom?using?contrasts = list(target = "contr.sum")?Also, it's not clear to me whether?target1?and?target2?refer to?targets?a?and?b.More generally, I would like to obtain both the effects of all?targets?on all?inputs?and the associated standard errors and p-values.Thanks,Dan
	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Tue Aug 16 11:36:53 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 16 Aug 2016 09:36:53 +0000
Subject: [R-sig-ME] searchable archives?
In-Reply-To: <CAE9_Wg46k-KwDmi=sMa=ON-HxGi9reWf5fgMMKk1E5EjvhBG3Q@mail.gmail.com>
References: <838d0ca7-e3bd-98fa-00bf-05098ff4fbaf@math.mcmaster.ca>
	<CAE9_Wg4WFQU-a10PW4Nn2NVq0Wk-0actwqx6tAtEL0NyWtpLeg@mail.gmail.com>
	<CAE9_Wg46k-KwDmi=sMa=ON-HxGi9reWf5fgMMKk1E5EjvhBG3Q@mail.gmail.com>
Message-ID: <1471340213.5449.8.camel@unisa.edu.au>

I'm a bit late to the game, but for those of you dependent on Gmane,
there's a rumour that it won't be around for much longer:

https://developers.slashdot.org/story/16/07/28/2059249/the-end-of-gmane

Phillip

On Fri, 2016-08-12 at 10:20 -0500, Jake Westfall wrote:
> Oh, I guess Wolfgang beat me to it :p
> 
> Jake
> 
> On Fri, Aug 12, 2016 at 10:18 AM, Jake Westfall <jake.a.westfall at gmai
> l.com>
> wrote:
> 
> > 
> > The archives at stat.ethz.ch may not be searchable, but you can
> > sort of
> > fake it using Google queries directed at the site/directory, e.g.,:
> > 
> > weights site:stat.ethz.ch/pipermail/r-sig-mixed-models/
> > 
> > Not sure if this will work for you, searching "IAC" didn't seem to
> > turn up
> > any results, which isn't a good sign, although other queries seem
> > to work
> > fine.
> > 
> > Jake
> > 
> > On Fri, Aug 12, 2016 at 8:37 AM, Ben Bolker <bbolker at gmail.com>
> > wrote:
> > 
> > > 
> > > 
> > > ? Can anyone point me to searchable archives of the list???I
> > > usually use
> > > Gmane, but it seems to be down.??Unless I'm mistaken, the
> > > official
> > > archives <https://stat.ethz.ch/pipermail/r-sig-mixed-models/>
> > > aren't
> > > searchable.
> > > 
> > > ?- although https://www.r-project.org/search.html says "This
> > > engine lets
> > > you search help files, manuals, and mailing list archives",
> > > http://finzi.psych.upenn.edu/search.html only says it indexes "R
> > > functions, package vignettes, and task views"
> > > 
> > > ?- I can't get the search bar at
> > > http://r-sig-mixed-models.r-project.narkive.com to work ...
> > > 
> > > ? - I can't figure out whether Nabble mirrors r-sig-mixed-models
> > > 
> > > ? More specifically, I'm trying to remember a generic critique of
> > > AIC
> > > weights someone posted to the list a while back ...
> > > 
> > > ? cheers
> > > ????Ben Bolker
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> > 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From gaughra at tcd.ie  Tue Aug 16 13:40:53 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Tue, 16 Aug 2016 12:40:53 +0100
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
Message-ID: <CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>

Hi Ben,

Im proceeding by standardizing by hand.  However, I need to include offsets
in my model for origarea and PropAvlHab i.e. offset(log(z.origarea)) but
logging the standardized varible produced NaNs due to the presence of
negative numbers, ditto with z.PropAvlHab. Is there a way around this? Do I
need to also standardize the offset terms or can I leave them in their
unstandardized form?

Many thanks,

Aoibheann

On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com> wrote:

> Hmm.  Surprising/hard to diagnose.
>
> 'standardize' doesn't do anything very fancy - it standardizes the
> input variables as described by ?arm::standardize and *refits* the
> model (I've always been a little disappointed that it doesn't
> standardize by figuring out how to transform the *parameters*, which
> is straightforward in principle although it can be tricky to figure
> out how to deal with input variables that lead to multiple predictor
> variables, e.g. polynomials).  I'd be curious to know what's going on,
> but in your place I would
>
> (1) try standardizing by hand, e.g.
>
> std_data <- transform(data,
>       z.season.wt = scale(season.wt),
>      ...)
>
> and refit yourself.
>
> (2) see if it happens to work with glmmTMB (a simple example does).
>
>   Ben Bolker
>
>
>
>
> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> wrote:
> > Thanks Ben, I ran the code and got the following error and warnings:-
> >
> > Error in glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +
> :
> >   rank of X = 16 < ncol(X) = 24
> > In addition: Warning messages:
> > 1: In log(z.PropAvlHab) : NaNs produced
> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +  :
> >   NAs removed in constructing fixed-effect model frame: you should
> probably
> > remove them manually, e.g. with na.omit()
> >
> >
> > The original PropAvlHab summary is as follows:-
> >
> >> summary(dframe1$PropAvlHab)
> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
> >
> > Aoibheann
> >
> >
> >
> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> 'standardize' is a function from the arm package.
> >>
> >> I've just hacked glmmADMB a little bit so this should work:
> >>
> >> library(devtools)
> >> install_github("bbolker/glmmADMB")  ## install latest version
> >> library(arm)
> >> arm:::standardize.default(fitted_model$call)
> >>
> >>
> >>
> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> >> wrote:
> >> > Hello Mixed-Modellers,
> >> >
> >> > I have getting the following error message when trying to standardize
> my
> >> > global glmmadmb model for dredging:
> >> >
> >> > Error in (function (classes, fdef, mtable)  : unable to find an
> >> > inherited
> >> > method for function ?standardize? for signature ?"glmmadmb"?
> >> >
> >> > Is it not possible to standardise a glmmadmb model or is the problem
> >> > with
> >> > the structure of the model itself?
> >> >
> >> > globalmod    <- glmmadmb(field_count ~ habitat
> >> > #categorical - 7 levels
> >> >                      + season_wt
> >> >                                          #categorial - 3 levels
> >> >                      + sex
> >> >                                               #categorial - 2 levels
> >> >                      + ageclass
> >> >                                            #categorial - 3 levels
> >> >                      + slope
> >> >                                              #continuous, not scaled
> nor
> >> > centred
> >> >                      + NSEW
> >> >                                           #catagorical - 4 levels
> >> >                      + month_fix
> >> >                                           #continuous, not scaled nor
> >> > centred,
> >> >                      + num_fields
> >> >                   #continuous, not scaled nor centred
> >> >                      + habitat:ageclass
> >> >                      + habitat:sex
> >> >                      + offset(log(origarea))
> >> >                      + offset(log(PropAvlHab))
> >> >                      +(1|individual_id)
> >> >                                            #repeated obs from same
> >> > individual
> >> >                      +(1|field_id)
> >> >                                               #repeated obs in same
> >> > field,
> >> >                      family="nbinom",
> >> >                      zeroInflation=TRUE,
> >> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
> >> >                      debug=TRUE,
> >> >                      data = dframe1)
> >> >
> >> > no of observations =9220
> >> >
> >> > Many thanks,
> >> >
> >> > --
> >> > Aoibheann Gaughran
> >> >
> >> > Behavioural and Evolutionary Ecology Research Group
> >> > Zoology Building
> >> > School of Natural Sciences
> >> > Trinity College Dublin
> >> > Dublin 2
> >> > Ireland
> >> > Phone: +353 (86) 3812615
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 16 13:55:36 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 16 Aug 2016 07:55:36 -0400
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
	<CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
Message-ID: <CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>

You can *scale* the offsets if you like, i.e. change them by a
multiplicative factor (thus changing the effective area unit for which
you were modeling counts), but *centering* them doesn't make sense --
as you've noticed.

On Tue, Aug 16, 2016 at 7:40 AM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> Hi Ben,
>
> Im proceeding by standardizing by hand.  However, I need to include offsets
> in my model for origarea and PropAvlHab i.e. offset(log(z.origarea)) but
> logging the standardized varible produced NaNs due to the presence of
> negative numbers, ditto with z.PropAvlHab. Is there a way around this? Do I
> need to also standardize the offset terms or can I leave them in their
> unstandardized form?
>
> Many thanks,
>
> Aoibheann
>
> On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> Hmm.  Surprising/hard to diagnose.
>>
>> 'standardize' doesn't do anything very fancy - it standardizes the
>> input variables as described by ?arm::standardize and *refits* the
>> model (I've always been a little disappointed that it doesn't
>> standardize by figuring out how to transform the *parameters*, which
>> is straightforward in principle although it can be tricky to figure
>> out how to deal with input variables that lead to multiple predictor
>> variables, e.g. polynomials).  I'd be curious to know what's going on,
>> but in your place I would
>>
>> (1) try standardizing by hand, e.g.
>>
>> std_data <- transform(data,
>>       z.season.wt = scale(season.wt),
>>      ...)
>>
>> and refit yourself.
>>
>> (2) see if it happens to work with glmmTMB (a simple example does).
>>
>>   Ben Bolker
>>
>>
>>
>>
>> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran <gaughra at tcd.ie>
>> wrote:
>> > Thanks Ben, I ran the code and got the following error and warnings:-
>> >
>> > Error in glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +
>> > :
>> >   rank of X = 16 < ncol(X) = 24
>> > In addition: Warning messages:
>> > 1: In log(z.PropAvlHab) : NaNs produced
>> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +  :
>> >   NAs removed in constructing fixed-effect model frame: you should
>> > probably
>> > remove them manually, e.g. with na.omit()
>> >
>> >
>> > The original PropAvlHab summary is as follows:-
>> >
>> >> summary(dframe1$PropAvlHab)
>> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
>> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
>> >
>> > Aoibheann
>> >
>> >
>> >
>> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >> 'standardize' is a function from the arm package.
>> >>
>> >> I've just hacked glmmADMB a little bit so this should work:
>> >>
>> >> library(devtools)
>> >> install_github("bbolker/glmmADMB")  ## install latest version
>> >> library(arm)
>> >> arm:::standardize.default(fitted_model$call)
>> >>
>> >>
>> >>
>> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie>
>> >> wrote:
>> >> > Hello Mixed-Modellers,
>> >> >
>> >> > I have getting the following error message when trying to standardize
>> >> > my
>> >> > global glmmadmb model for dredging:
>> >> >
>> >> > Error in (function (classes, fdef, mtable)  : unable to find an
>> >> > inherited
>> >> > method for function ?standardize? for signature ?"glmmadmb"?
>> >> >
>> >> > Is it not possible to standardise a glmmadmb model or is the problem
>> >> > with
>> >> > the structure of the model itself?
>> >> >
>> >> > globalmod    <- glmmadmb(field_count ~ habitat
>> >> > #categorical - 7 levels
>> >> >                      + season_wt
>> >> >                                          #categorial - 3 levels
>> >> >                      + sex
>> >> >                                               #categorial - 2 levels
>> >> >                      + ageclass
>> >> >                                            #categorial - 3 levels
>> >> >                      + slope
>> >> >                                              #continuous, not scaled
>> >> > nor
>> >> > centred
>> >> >                      + NSEW
>> >> >                                           #catagorical - 4 levels
>> >> >                      + month_fix
>> >> >                                           #continuous, not scaled nor
>> >> > centred,
>> >> >                      + num_fields
>> >> >                   #continuous, not scaled nor centred
>> >> >                      + habitat:ageclass
>> >> >                      + habitat:sex
>> >> >                      + offset(log(origarea))
>> >> >                      + offset(log(PropAvlHab))
>> >> >                      +(1|individual_id)
>> >> >                                            #repeated obs from same
>> >> > individual
>> >> >                      +(1|field_id)
>> >> >                                               #repeated obs in same
>> >> > field,
>> >> >                      family="nbinom",
>> >> >                      zeroInflation=TRUE,
>> >> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>> >> >                      debug=TRUE,
>> >> >                      data = dframe1)
>> >> >
>> >> > no of observations =9220
>> >> >
>> >> > Many thanks,
>> >> >
>> >> > --
>> >> > Aoibheann Gaughran
>> >> >
>> >> > Behavioural and Evolutionary Ecology Research Group
>> >> > Zoology Building
>> >> > School of Natural Sciences
>> >> > Trinity College Dublin
>> >> > Dublin 2
>> >> > Ireland
>> >> > Phone: +353 (86) 3812615
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-mixed-models at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> >
>> >
>> >
>> > --
>> > Aoibheann Gaughran
>> >
>> > Behavioural and Evolutionary Ecology Research Group
>> > Zoology Building
>> > School of Natural Sciences
>> > Trinity College Dublin
>> > Dublin 2
>> > Ireland
>> > Phone: +353 (86) 3812615
>
>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615


From russell-lenth at uiowa.edu  Wed Aug 17 03:15:04 2016
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Wed, 17 Aug 2016 01:15:04 +0000
Subject: [R-sig-ME] Obtaining all effects in a multinomial regression
Message-ID: <CO2PR04MB22142CEC5CEFA5AF032A3326F1140@CO2PR04MB2214.namprd04.prod.outlook.com>

I think maybe the lsmeans package can help with this...

> library("lsmeans")

> # Look at the reference grid that it uses by default for this model:

> ref.grid(fit)

'ref.grid' object with variables:
    target = a, b, c
    input = multivariate response levels: A, B, C, D, E

> # Note the multinomial response is treated like a factor 'input' with 5 levels


> # Here are the lsmeans - by default, they are on the probability scale:

> lsmeans(fit, ~ input | target)

target = a:
 input       prob         SE df    lower.CL  upper.CL
 A     0.55264789 0.09783283 12  0.33948846 0.7658073
 B     0.10525965 0.02727796 12  0.04582608 0.1646932
 C     0.11841616 0.02998773 12  0.05307850 0.1837538
 D     0.11841615 0.04028909 12  0.03063376 0.2061985
 E     0.10526015 0.03444923 12  0.03020173 0.1803186

target = b:
 input       prob         SE df    lower.CL  upper.CL
 A     0.06249061 0.01820814 12  0.02281847 0.1021627
 B     0.33928661 0.06201426 12  0.20416916 0.4744041
 C     0.38393000 0.04978587 12  0.27545592 0.4924041
 D     0.09821839 0.02201614 12  0.05024935 0.1461874
 E     0.11607438 0.02249977 12  0.06705159 0.1650972

target = c:
 input       prob         SE df    lower.CL  upper.CL
 A     0.09523627 0.07565354 12 -0.06959863 0.2600712
 B     0.11904618 0.13054235 12 -0.16538117 0.4034735
 C     0.38095561 0.27551283 12 -0.21933527 0.9812465
 D     0.16666102 0.16942976 12 -0.20249472 0.5358168
 E     0.23810092 0.22856258 12 -0.25989417 0.7360960

Confidence level used: 0.95 


> # But I think what you want are effects on the linear-predictor scale.
> # For that, specify mode = "latent" in the call (see ?models):

> fit.lsm <- lsmeans(fit, ~ input | target, mode = "latent")
> fit.lsm

target = a:
 input      lsmean        SE df   lower.CL      upper.CL
 A      1.27952178 0.3164462 12  0.5900446  1.9689989170
 B     -0.37876916 0.1737829 12 -0.7574095 -0.0001287816
 C     -0.26099411 0.1684176 12 -0.6279446  0.1059563636
 D     -0.26099417 0.2625914 12 -0.8331316  0.3111432930
 E     -0.37876434 0.2460970 12 -0.9149636  0.1574349505

target = b:
 input      lsmean        SE df   lower.CL      upper.CL
 A     -0.91573300 0.2450969 12 -1.4497534 -0.3817126475
 B      0.77609593 0.2237678 12  0.2885478  1.2636441045
 C      0.89971096 0.1502380 12  0.5723706  1.2270513543
 D     -0.46355580 0.1965806 12 -0.8918682 -0.0352433817
 E     -0.29651809 0.1734101 12 -0.6743463  0.0813101280

target = c:
 input      lsmean        SE df   lower.CL      upper.CL
 A     -0.61708150 0.6836341 12 -2.1065923  0.8724293349
 B     -0.39393084 0.9663707 12 -2.4994717  1.7116100068
 C      0.76924052 0.9107898 12 -1.2151999  2.7536809661
 D     -0.05748044 0.9413821 12 -2.1085759  1.9936149928
 E      0.29925226 0.9717157 12 -1.8179343  2.4164388165

Results are given on the log (not the response) scale. 
Confidence level used: 0.95 


> # To get the sum-to-zero effects, use contrasts of type "eff":

> contrast(fit.lsm, "eff")

target = a:
 contrast    estimate        SE df t.ratio p.value
 A effect  1.27952178 0.3164462 12   4.043  0.0081
 B effect -0.37876916 0.1737829 12  -2.180  0.1248
 C effect -0.26099411 0.1684176 12  -1.550  0.1872
 D effect -0.26099417 0.2625914 12  -0.994  0.3399
 E effect -0.37876434 0.2460970 12  -1.539  0.1872

target = b:
 contrast    estimate        SE df t.ratio p.value
 A effect -0.91573300 0.2450969 12  -3.736  0.0071
 B effect  0.77609593 0.2237678 12   3.468  0.0077
 C effect  0.89971096 0.1502380 12   5.989  0.0003
 D effect -0.46355580 0.1965806 12  -2.358  0.0452
 E effect -0.29651809 0.1734101 12  -1.710  0.1130

target = c:
 contrast    estimate        SE df t.ratio p.value
 A effect -0.61708150 0.6836341 12  -0.903  0.9523
 B effect -0.39393084 0.9663707 12  -0.408  0.9523
 C effect  0.76924052 0.9107898 12   0.845  0.9523
 D effect -0.05748044 0.9413821 12  -0.061  0.9523
 E effect  0.29925226 0.9717157 12   0.308  0.9523

P value adjustment: fdr method for 5 tests



I did this separately for each target (due to the formula '~ input | target' in the lsmeans call. But you can change that formula, and/or add a 'by' argument to the 'contrast' call. You can also use 'adjust' to specify a different p-value adjustment method (see ?contrast)

Hope this helps.

Russ

-----Original Message-----

Date: Mon, 15 Aug 2016 17:38:05 +0000 (UTC)
From: Daniel Rubi <daniel_rubi at ymail.com>
To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Obtaining all effects in a multinomial regression
	where the grand mean is set as baseline
Message-ID: <1981606920.2663264.1471282685613 at mail.yahoo.com>
Content-Type: text/plain; charset="UTF-8"

I have data from these set of experiments:In each experiment I infect a neuron with a rabies virus. The virus climbs backwards across the axon of the infected neuron and jumps across the synapse to the input axons of that neuron. The rabies will then express a marker gene in the input neurons it jumped to thereby labeling the input neurons to the infected target neuron. The purpose of this is thus to trace the neurons that provide input to the neurons I'm infecting (target cells), thereby creating a connectivity map of this region in the brain.In each experiment I obtain counts of all the infected input neurons.?Here's a simulation of the data: (3 targets and 5 inputs):set.seed(1) probs <- list(c(0.4,0.1,0.1,0.2,0.2),c(0.1,0.3,0.4,0.1,0.1),c(0.1,0.1,0.4,0.2,0.2))
mat <- matrix(unlist(lapply(probs,function(p) rmultinom(1, as.integer(runif(1,50,150)), p))),ncol=3) inputs <- LETTERS[1:5] targets <- letters[1:3] df <- data.frame(input = c(unlist(apply(mat,2,function(x) rep(inputs ,x)))),target = rep(targets ,apply(mat,2,sum))) What I'd like to estimate is the effect of each target neuron on these counts, relative to the grand mean. I was thinking that a?multinomial?regression model is appropriate in this case, where the contrasts are set to the?contr.sum?option:
library(foreign)
library(nnet)
library(reshape2)

df$input <- factor(df$input,levels=inputs) df$target <- factor(df$target,levels=targets) fit <- multinom(input ~ target, data = df,contrasts = list(target = "contr.sum")) # weights:  20 (12 variable) initial  value 505.363505 iter  10 value 445.057386 final  value 441.645283 convergedWhich gives me:
> summary(fit)$coefficients
  (Intercept)   target1   target2
B  0.08556288 -1.743854 1.6062660
C  0.55375003 -2.094266 1.2616939
D -0.17624590 -1.364270 0.6284231
E -0.04091248 -1.617374 0.6601274
So the effects for input?A?are not reported. In an?lm?they would be retrieved as:
-1*(apply(summary(fit)$coefficients,2,sum))
But I'm wondering whether it is the same for?multinom?using?contrasts = list(target = "contr.sum")?Also, it's not clear to me whether?target1?and?target2?refer to?targets?a?and?b.More generally, I would like to obtain both the effects of all?targets?on all?inputs?and the associated standard errors and p-values.Thanks,Dan
	[[alternative HTML version deleted]]


From gaughra at tcd.ie  Thu Aug 18 15:05:06 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Thu, 18 Aug 2016 14:05:06 +0100
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
	<CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
	<CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>
Message-ID: <CAN=0SEm+5cE=p9DYMP7MMWBXu_Hm+RQSRuhLHSceNyPMwysLjA@mail.gmail.com>

Hi Ben,

I've manually scaled and centered the continuous variables, and just scaled
the offset terms.  However, I now get the following error message when I
attempt to run the model, which appears to related to a subsetting issue?

Error in `[.data.frame`(cor_dat, start_pos + (1:x$npar), start_pos + 4 +  :
undefined columns selected

The revised global model is specified as follows:

stdmod12d <- glmmadmb(field_count ~ habitat #categorical
                     + season_wt #cat
                     + sex #cat
                     + ageclass #cat
                     + z.slope #continuous, scaled and centred
                     + NSEW #cat
                     + z.month_fix #continuous, scaled and centred
                     + z.num_fields #continuous, scaled and centred
                     + habitat:ageclass
                     + habitat:sex
                     + offset(log(z.origarea)) #scaled
                     + offset(log(z.PropAvlHab)) #scaled
                     +(1|animal) #repeated obs from same individual
                     +(1|field_id) #repeated obs in same field
                     ,
                     family="nbinom",
                     zeroInflation=TRUE,
                     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
                     debug=TRUE,
                     data = std_data)

On 16 August 2016 at 12:55, Ben Bolker <bbolker at gmail.com> wrote:

> You can *scale* the offsets if you like, i.e. change them by a
> multiplicative factor (thus changing the effective area unit for which
> you were modeling counts), but *centering* them doesn't make sense --
> as you've noticed.
>
> On Tue, Aug 16, 2016 at 7:40 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> wrote:
> > Hi Ben,
> >
> > Im proceeding by standardizing by hand.  However, I need to include
> offsets
> > in my model for origarea and PropAvlHab i.e. offset(log(z.origarea)) but
> > logging the standardized varible produced NaNs due to the presence of
> > negative numbers, ditto with z.PropAvlHab. Is there a way around this?
> Do I
> > need to also standardize the offset terms or can I leave them in their
> > unstandardized form?
> >
> > Many thanks,
> >
> > Aoibheann
> >
> > On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >> Hmm.  Surprising/hard to diagnose.
> >>
> >> 'standardize' doesn't do anything very fancy - it standardizes the
> >> input variables as described by ?arm::standardize and *refits* the
> >> model (I've always been a little disappointed that it doesn't
> >> standardize by figuring out how to transform the *parameters*, which
> >> is straightforward in principle although it can be tricky to figure
> >> out how to deal with input variables that lead to multiple predictor
> >> variables, e.g. polynomials).  I'd be curious to know what's going on,
> >> but in your place I would
> >>
> >> (1) try standardizing by hand, e.g.
> >>
> >> std_data <- transform(data,
> >>       z.season.wt = scale(season.wt),
> >>      ...)
> >>
> >> and refit yourself.
> >>
> >> (2) see if it happens to work with glmmTMB (a simple example does).
> >>
> >>   Ben Bolker
> >>
> >>
> >>
> >>
> >> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> >> wrote:
> >> > Thanks Ben, I ran the code and got the following error and warnings:-
> >> >
> >> > Error in glmmadmb(formula = field_count ~ habitat + season_wt + c.sex
> +
> >> > :
> >> >   rank of X = 16 < ncol(X) = 24
> >> > In addition: Warning messages:
> >> > 1: In log(z.PropAvlHab) : NaNs produced
> >> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt + c.sex +
> :
> >> >   NAs removed in constructing fixed-effect model frame: you should
> >> > probably
> >> > remove them manually, e.g. with na.omit()
> >> >
> >> >
> >> > The original PropAvlHab summary is as follows:-
> >> >
> >> >> summary(dframe1$PropAvlHab)
> >> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> >> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
> >> >
> >> > Aoibheann
> >> >
> >> >
> >> >
> >> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com> wrote:
> >> >>
> >> >> 'standardize' is a function from the arm package.
> >> >>
> >> >> I've just hacked glmmADMB a little bit so this should work:
> >> >>
> >> >> library(devtools)
> >> >> install_github("bbolker/glmmADMB")  ## install latest version
> >> >> library(arm)
> >> >> arm:::standardize.default(fitted_model$call)
> >> >>
> >> >>
> >> >>
> >> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran <gaughra at tcd.ie>
> >> >> wrote:
> >> >> > Hello Mixed-Modellers,
> >> >> >
> >> >> > I have getting the following error message when trying to
> standardize
> >> >> > my
> >> >> > global glmmadmb model for dredging:
> >> >> >
> >> >> > Error in (function (classes, fdef, mtable)  : unable to find an
> >> >> > inherited
> >> >> > method for function ?standardize? for signature ?"glmmadmb"?
> >> >> >
> >> >> > Is it not possible to standardise a glmmadmb model or is the
> problem
> >> >> > with
> >> >> > the structure of the model itself?
> >> >> >
> >> >> > globalmod    <- glmmadmb(field_count ~ habitat
> >> >> > #categorical - 7 levels
> >> >> >                      + season_wt
> >> >> >                                          #categorial - 3 levels
> >> >> >                      + sex
> >> >> >                                               #categorial - 2
> levels
> >> >> >                      + ageclass
> >> >> >                                            #categorial - 3 levels
> >> >> >                      + slope
> >> >> >                                              #continuous, not
> scaled
> >> >> > nor
> >> >> > centred
> >> >> >                      + NSEW
> >> >> >                                           #catagorical - 4 levels
> >> >> >                      + month_fix
> >> >> >                                           #continuous, not scaled
> nor
> >> >> > centred,
> >> >> >                      + num_fields
> >> >> >                   #continuous, not scaled nor centred
> >> >> >                      + habitat:ageclass
> >> >> >                      + habitat:sex
> >> >> >                      + offset(log(origarea))
> >> >> >                      + offset(log(PropAvlHab))
> >> >> >                      +(1|individual_id)
> >> >> >                                            #repeated obs from same
> >> >> > individual
> >> >> >                      +(1|field_id)
> >> >> >                                               #repeated obs in same
> >> >> > field,
> >> >> >                      family="nbinom",
> >> >> >                      zeroInflation=TRUE,
> >> >> >                      admb.opts=admbControl(shess=
> FALSE,noinit=FALSE),
> >> >> >                      debug=TRUE,
> >> >> >                      data = dframe1)
> >> >> >
> >> >> > no of observations =9220
> >> >> >
> >> >> > Many thanks,
> >> >> >
> >> >> > --
> >> >> > Aoibheann Gaughran
> >> >> >
> >> >> > Behavioural and Evolutionary Ecology Research Group
> >> >> > Zoology Building
> >> >> > School of Natural Sciences
> >> >> > Trinity College Dublin
> >> >> > Dublin 2
> >> >> > Ireland
> >> >> > Phone: +353 (86) 3812615
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > _______________________________________________
> >> >> > R-sig-mixed-models at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Aoibheann Gaughran
> >> >
> >> > Behavioural and Evolutionary Ecology Research Group
> >> > Zoology Building
> >> > School of Natural Sciences
> >> > Trinity College Dublin
> >> > Dublin 2
> >> > Ireland
> >> > Phone: +353 (86) 3812615
> >
> >
> >
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Aug 18 15:07:00 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Aug 2016 09:07:00 -0400
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CAN=0SEm+5cE=p9DYMP7MMWBXu_Hm+RQSRuhLHSceNyPMwysLjA@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
	<CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
	<CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>
	<CAN=0SEm+5cE=p9DYMP7MMWBXu_Hm+RQSRuhLHSceNyPMwysLjA@mail.gmail.com>
Message-ID: <b81d7705-99fe-0567-b9a8-5e332f28a07f@gmail.com>


  what's the results of names(std_data) ?

On 16-08-18 09:05 AM, Aoibheann Gaughran wrote:
> Hi Ben,
> 
> I've manually scaled and centered the continuous variables, and just
> scaled the offset terms.  However, I now get the following error message
> when I attempt to run the model, which appears to related to a
> subsetting issue?
> 
> Error in `[.data.frame`(cor_dat, start_pos + (1:x$npar), start_pos + 4 +  :
> undefined columns selected
> 
> The revised global model is specified as follows:
> 
> stdmod12d <- glmmadmb(field_count ~ habitat #categorical
>                      + season_wt #cat
>                      + sex #cat
>                      + ageclass #cat
>                      + z.slope #continuous, scaled and centred
>                      + NSEW #cat
>                      + z.month_fix #continuous, scaled and centred
>                      + z.num_fields #continuous, scaled and centred
>                      + habitat:ageclass
>                      + habitat:sex
>                      + offset(log(z.origarea)) #scaled
>                      + offset(log(z.PropAvlHab)) #scaled
>                      +(1|animal) #repeated obs from same individual
>                      +(1|field_id) #repeated obs in same field
>                      ,
>                      family="nbinom",
>                      zeroInflation=TRUE,
>                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>                      debug=TRUE,
>                      data = std_data)
> 
> On 16 August 2016 at 12:55, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     You can *scale* the offsets if you like, i.e. change them by a
>     multiplicative factor (thus changing the effective area unit for which
>     you were modeling counts), but *centering* them doesn't make sense --
>     as you've noticed.
> 
>     On Tue, Aug 16, 2016 at 7:40 AM, Aoibheann Gaughran <gaughra at tcd.ie
>     <mailto:gaughra at tcd.ie>> wrote:
>     > Hi Ben,
>     >
>     > Im proceeding by standardizing by hand.  However, I need to
>     include offsets
>     > in my model for origarea and PropAvlHab i.e.
>     offset(log(z.origarea)) but
>     > logging the standardized varible produced NaNs due to the presence of
>     > negative numbers, ditto with z.PropAvlHab. Is there a way around
>     this? Do I
>     > need to also standardize the offset terms or can I leave them in their
>     > unstandardized form?
>     >
>     > Many thanks,
>     >
>     > Aoibheann
>     >
>     > On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
>     >>
>     >> Hmm.  Surprising/hard to diagnose.
>     >>
>     >> 'standardize' doesn't do anything very fancy - it standardizes the
>     >> input variables as described by ?arm::standardize and *refits* the
>     >> model (I've always been a little disappointed that it doesn't
>     >> standardize by figuring out how to transform the *parameters*, which
>     >> is straightforward in principle although it can be tricky to figure
>     >> out how to deal with input variables that lead to multiple predictor
>     >> variables, e.g. polynomials).  I'd be curious to know what's
>     going on,
>     >> but in your place I would
>     >>
>     >> (1) try standardizing by hand, e.g.
>     >>
>     >> std_data <- transform(data,
>     >>       z.season.wt = scale(season.wt),
>     >>      ...)
>     >>
>     >> and refit yourself.
>     >>
>     >> (2) see if it happens to work with glmmTMB (a simple example does).
>     >>
>     >>   Ben Bolker
>     >>
>     >>
>     >>
>     >>
>     >> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran
>     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
>     >> wrote:
>     >> > Thanks Ben, I ran the code and got the following error and
>     warnings:-
>     >> >
>     >> > Error in glmmadmb(formula = field_count ~ habitat + season_wt +
>     c.sex +
>     >> > :
>     >> >   rank of X = 16 < ncol(X) = 24
>     >> > In addition: Warning messages:
>     >> > 1: In log(z.PropAvlHab) : NaNs produced
>     >> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt +
>     c.sex +  :
>     >> >   NAs removed in constructing fixed-effect model frame: you should
>     >> > probably
>     >> > remove them manually, e.g. with na.omit()
>     >> >
>     >> >
>     >> > The original PropAvlHab summary is as follows:-
>     >> >
>     >> >> summary(dframe1$PropAvlHab)
>     >> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
>     >> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
>     >> >
>     >> > Aoibheann
>     >> >
>     >> >
>     >> >
>     >> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
>     >> >>
>     >> >> 'standardize' is a function from the arm package.
>     >> >>
>     >> >> I've just hacked glmmADMB a little bit so this should work:
>     >> >>
>     >> >> library(devtools)
>     >> >> install_github("bbolker/glmmADMB")  ## install latest version
>     >> >> library(arm)
>     >> >> arm:::standardize.default(fitted_model$call)
>     >> >>
>     >> >>
>     >> >>
>     >> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran
>     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
>     >> >> wrote:
>     >> >> > Hello Mixed-Modellers,
>     >> >> >
>     >> >> > I have getting the following error message when trying to
>     standardize
>     >> >> > my
>     >> >> > global glmmadmb model for dredging:
>     >> >> >
>     >> >> > Error in (function (classes, fdef, mtable)  : unable to find an
>     >> >> > inherited
>     >> >> > method for function ?standardize? for signature ?"glmmadmb"?
>     >> >> >
>     >> >> > Is it not possible to standardise a glmmadmb model or is the
>     problem
>     >> >> > with
>     >> >> > the structure of the model itself?
>     >> >> >
>     >> >> > globalmod    <- glmmadmb(field_count ~ habitat
>     >> >> > #categorical - 7 levels
>     >> >> >                      + season_wt
>     >> >> >                                          #categorial - 3 levels
>     >> >> >                      + sex
>     >> >> >                                               #categorial -
>     2 levels
>     >> >> >                      + ageclass
>     >> >> >                                            #categorial - 3
>     levels
>     >> >> >                      + slope
>     >> >> >                                              #continuous,
>     not scaled
>     >> >> > nor
>     >> >> > centred
>     >> >> >                      + NSEW
>     >> >> >                                           #catagorical - 4
>     levels
>     >> >> >                      + month_fix
>     >> >> >                                           #continuous, not
>     scaled nor
>     >> >> > centred,
>     >> >> >                      + num_fields
>     >> >> >                   #continuous, not scaled nor centred
>     >> >> >                      + habitat:ageclass
>     >> >> >                      + habitat:sex
>     >> >> >                      + offset(log(origarea))
>     >> >> >                      + offset(log(PropAvlHab))
>     >> >> >                      +(1|individual_id)
>     >> >> >                                            #repeated obs
>     from same
>     >> >> > individual
>     >> >> >                      +(1|field_id)
>     >> >> >                                               #repeated obs
>     in same
>     >> >> > field,
>     >> >> >                      family="nbinom",
>     >> >> >                      zeroInflation=TRUE,
>     >> >> >                     
>     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>     >> >> >                      debug=TRUE,
>     >> >> >                      data = dframe1)
>     >> >> >
>     >> >> > no of observations =9220
>     >> >> >
>     >> >> > Many thanks,
>     >> >> >
>     >> >> > --
>     >> >> > Aoibheann Gaughran
>     >> >> >
>     >> >> > Behavioural and Evolutionary Ecology Research Group
>     >> >> > Zoology Building
>     >> >> > School of Natural Sciences
>     >> >> > Trinity College Dublin
>     >> >> > Dublin 2
>     >> >> > Ireland
>     >> >> > Phone: +353 (86) 3812615
>     >> >> >
>     >> >> >         [[alternative HTML version deleted]]
>     >> >> >
>     >> >> > _______________________________________________
>     >> >> > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >> >
>     >> >
>     >> >
>     >> >
>     >> > --
>     >> > Aoibheann Gaughran
>     >> >
>     >> > Behavioural and Evolutionary Ecology Research Group
>     >> > Zoology Building
>     >> > School of Natural Sciences
>     >> > Trinity College Dublin
>     >> > Dublin 2
>     >> > Ireland
>     >> > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
>     >
>     >
>     >
>     >
>     > --
>     > Aoibheann Gaughran
>     >
>     > Behavioural and Evolutionary Ecology Research Group
>     > Zoology Building
>     > School of Natural Sciences
>     > Trinity College Dublin
>     > Dublin 2
>     > Ireland
>     > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
> 
> 
> 
> 
> -- 
> Aoibheann Gaughran
> 
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615


From gaughra at tcd.ie  Thu Aug 18 15:11:43 2016
From: gaughra at tcd.ie (Aoibheann Gaughran)
Date: Thu, 18 Aug 2016 14:11:43 +0100
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <b81d7705-99fe-0567-b9a8-5e332f28a07f@gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
	<CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
	<CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>
	<CAN=0SEm+5cE=p9DYMP7MMWBXu_Hm+RQSRuhLHSceNyPMwysLjA@mail.gmail.com>
	<b81d7705-99fe-0567-b9a8-5e332f28a07f@gmail.com>
Message-ID: <CAN=0SE=XT4rKTt62dgUiTSEjC434aVWfX3gh7QwbrJ+soi6aaQ@mail.gmail.com>

> names(std_data) [1] "field_count"     "month_fix"       "num_fields"      "field_id"        "animal"          "soc_grp"         "habitat"
 [8] "habitat2"        "monyear"         "mon"             "season_wt"
      "season"          "month"           "year"
[15] "sex"             "age"             "ageclass"        "soil"
      "slope"           "elevation"       "aspect"
[22] "NSEW"            "origarea"        "newarea"         "HRNewArea"
      "HabNewArea"      "PropAvlHab"      "origperim"
[29] "newperim"        "propHRfield"     "percentHRfield"
"PropHabfield"    "percentHabfield" "field_use"       "slopescale"
[36] "aspectscale"     "z.month_fix"     "z.num_fields"    "z.slope"
      "z.origarea"      "z.PropAvlHab"


On 18 August 2016 at 14:07, Ben Bolker <bbolker at gmail.com> wrote:

>
>   what's the results of names(std_data) ?
>
> On 16-08-18 09:05 AM, Aoibheann Gaughran wrote:
> > Hi Ben,
> >
> > I've manually scaled and centered the continuous variables, and just
> > scaled the offset terms.  However, I now get the following error message
> > when I attempt to run the model, which appears to related to a
> > subsetting issue?
> >
> > Error in `[.data.frame`(cor_dat, start_pos + (1:x$npar), start_pos + 4
> +  :
> > undefined columns selected
> >
> > The revised global model is specified as follows:
> >
> > stdmod12d <- glmmadmb(field_count ~ habitat #categorical
> >                      + season_wt #cat
> >                      + sex #cat
> >                      + ageclass #cat
> >                      + z.slope #continuous, scaled and centred
> >                      + NSEW #cat
> >                      + z.month_fix #continuous, scaled and centred
> >                      + z.num_fields #continuous, scaled and centred
> >                      + habitat:ageclass
> >                      + habitat:sex
> >                      + offset(log(z.origarea)) #scaled
> >                      + offset(log(z.PropAvlHab)) #scaled
> >                      +(1|animal) #repeated obs from same individual
> >                      +(1|field_id) #repeated obs in same field
> >                      ,
> >                      family="nbinom",
> >                      zeroInflation=TRUE,
> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
> >                      debug=TRUE,
> >                      data = std_data)
> >
> > On 16 August 2016 at 12:55, Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >     You can *scale* the offsets if you like, i.e. change them by a
> >     multiplicative factor (thus changing the effective area unit for
> which
> >     you were modeling counts), but *centering* them doesn't make sense --
> >     as you've noticed.
> >
> >     On Tue, Aug 16, 2016 at 7:40 AM, Aoibheann Gaughran <gaughra at tcd.ie
> >     <mailto:gaughra at tcd.ie>> wrote:
> >     > Hi Ben,
> >     >
> >     > Im proceeding by standardizing by hand.  However, I need to
> >     include offsets
> >     > in my model for origarea and PropAvlHab i.e.
> >     offset(log(z.origarea)) but
> >     > logging the standardized varible produced NaNs due to the presence
> of
> >     > negative numbers, ditto with z.PropAvlHab. Is there a way around
> >     this? Do I
> >     > need to also standardize the offset terms or can I leave them in
> their
> >     > unstandardized form?
> >     >
> >     > Many thanks,
> >     >
> >     > Aoibheann
> >     >
> >     > On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>> wrote:
> >     >>
> >     >> Hmm.  Surprising/hard to diagnose.
> >     >>
> >     >> 'standardize' doesn't do anything very fancy - it standardizes the
> >     >> input variables as described by ?arm::standardize and *refits* the
> >     >> model (I've always been a little disappointed that it doesn't
> >     >> standardize by figuring out how to transform the *parameters*,
> which
> >     >> is straightforward in principle although it can be tricky to
> figure
> >     >> out how to deal with input variables that lead to multiple
> predictor
> >     >> variables, e.g. polynomials).  I'd be curious to know what's
> >     going on,
> >     >> but in your place I would
> >     >>
> >     >> (1) try standardizing by hand, e.g.
> >     >>
> >     >> std_data <- transform(data,
> >     >>       z.season.wt = scale(season.wt),
> >     >>      ...)
> >     >>
> >     >> and refit yourself.
> >     >>
> >     >> (2) see if it happens to work with glmmTMB (a simple example
> does).
> >     >>
> >     >>   Ben Bolker
> >     >>
> >     >>
> >     >>
> >     >>
> >     >> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran
> >     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
> >     >> wrote:
> >     >> > Thanks Ben, I ran the code and got the following error and
> >     warnings:-
> >     >> >
> >     >> > Error in glmmadmb(formula = field_count ~ habitat + season_wt +
> >     c.sex +
> >     >> > :
> >     >> >   rank of X = 16 < ncol(X) = 24
> >     >> > In addition: Warning messages:
> >     >> > 1: In log(z.PropAvlHab) : NaNs produced
> >     >> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt +
> >     c.sex +  :
> >     >> >   NAs removed in constructing fixed-effect model frame: you
> should
> >     >> > probably
> >     >> > remove them manually, e.g. with na.omit()
> >     >> >
> >     >> >
> >     >> > The original PropAvlHab summary is as follows:-
> >     >> >
> >     >> >> summary(dframe1$PropAvlHab)
> >     >> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> >     >> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
> >     >> >
> >     >> > Aoibheann
> >     >> >
> >     >> >
> >     >> >
> >     >> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com
> >     <mailto:bbolker at gmail.com>> wrote:
> >     >> >>
> >     >> >> 'standardize' is a function from the arm package.
> >     >> >>
> >     >> >> I've just hacked glmmADMB a little bit so this should work:
> >     >> >>
> >     >> >> library(devtools)
> >     >> >> install_github("bbolker/glmmADMB")  ## install latest version
> >     >> >> library(arm)
> >     >> >> arm:::standardize.default(fitted_model$call)
> >     >> >>
> >     >> >>
> >     >> >>
> >     >> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran
> >     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
> >     >> >> wrote:
> >     >> >> > Hello Mixed-Modellers,
> >     >> >> >
> >     >> >> > I have getting the following error message when trying to
> >     standardize
> >     >> >> > my
> >     >> >> > global glmmadmb model for dredging:
> >     >> >> >
> >     >> >> > Error in (function (classes, fdef, mtable)  : unable to find
> an
> >     >> >> > inherited
> >     >> >> > method for function ?standardize? for signature ?"glmmadmb"?
> >     >> >> >
> >     >> >> > Is it not possible to standardise a glmmadmb model or is the
> >     problem
> >     >> >> > with
> >     >> >> > the structure of the model itself?
> >     >> >> >
> >     >> >> > globalmod    <- glmmadmb(field_count ~ habitat
> >     >> >> > #categorical - 7 levels
> >     >> >> >                      + season_wt
> >     >> >> >                                          #categorial - 3
> levels
> >     >> >> >                      + sex
> >     >> >> >                                               #categorial -
> >     2 levels
> >     >> >> >                      + ageclass
> >     >> >> >                                            #categorial - 3
> >     levels
> >     >> >> >                      + slope
> >     >> >> >                                              #continuous,
> >     not scaled
> >     >> >> > nor
> >     >> >> > centred
> >     >> >> >                      + NSEW
> >     >> >> >                                           #catagorical - 4
> >     levels
> >     >> >> >                      + month_fix
> >     >> >> >                                           #continuous, not
> >     scaled nor
> >     >> >> > centred,
> >     >> >> >                      + num_fields
> >     >> >> >                   #continuous, not scaled nor centred
> >     >> >> >                      + habitat:ageclass
> >     >> >> >                      + habitat:sex
> >     >> >> >                      + offset(log(origarea))
> >     >> >> >                      + offset(log(PropAvlHab))
> >     >> >> >                      +(1|individual_id)
> >     >> >> >                                            #repeated obs
> >     from same
> >     >> >> > individual
> >     >> >> >                      +(1|field_id)
> >     >> >> >                                               #repeated obs
> >     in same
> >     >> >> > field,
> >     >> >> >                      family="nbinom",
> >     >> >> >                      zeroInflation=TRUE,
> >     >> >> >
> >     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
> >     >> >> >                      debug=TRUE,
> >     >> >> >                      data = dframe1)
> >     >> >> >
> >     >> >> > no of observations =9220
> >     >> >> >
> >     >> >> > Many thanks,
> >     >> >> >
> >     >> >> > --
> >     >> >> > Aoibheann Gaughran
> >     >> >> >
> >     >> >> > Behavioural and Evolutionary Ecology Research Group
> >     >> >> > Zoology Building
> >     >> >> > School of Natural Sciences
> >     >> >> > Trinity College Dublin
> >     >> >> > Dublin 2
> >     >> >> > Ireland
> >     >> >> > Phone: +353 (86) 3812615
> >     >> >> >
> >     >> >> >         [[alternative HTML version deleted]]
> >     >> >> >
> >     >> >> > _______________________________________________
> >     >> >> > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >> >
> >     >> >
> >     >> >
> >     >> >
> >     >> > --
> >     >> > Aoibheann Gaughran
> >     >> >
> >     >> > Behavioural and Evolutionary Ecology Research Group
> >     >> > Zoology Building
> >     >> > School of Natural Sciences
> >     >> > Trinity College Dublin
> >     >> > Dublin 2
> >     >> > Ireland
> >     >> > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
> >     >
> >     >
> >     >
> >     >
> >     > --
> >     > Aoibheann Gaughran
> >     >
> >     > Behavioural and Evolutionary Ecology Research Group
> >     > Zoology Building
> >     > School of Natural Sciences
> >     > Trinity College Dublin
> >     > Dublin 2
> >     > Ireland
> >     > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
> >
> >
> >
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
>



-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Aug 18 15:16:44 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Aug 2016 09:16:44 -0400
Subject: [R-sig-ME] Unable to standardize glmmADMB global model
In-Reply-To: <CAN=0SE=XT4rKTt62dgUiTSEjC434aVWfX3gh7QwbrJ+soi6aaQ@mail.gmail.com>
References: <CAN=0SEm0onRxS7o4h54pm_E8CQcyEJ3izf__CcpKHsxZbUUyhw@mail.gmail.com>
	<CABghstSEip58v9ZXGad3Gpt_c+379cj6XKiSitBChPqu28rsNA@mail.gmail.com>
	<CAN=0SEnZvSphvTcmazASBZyvoxF=kYb4FuWZ2a7omQa5dXdCUA@mail.gmail.com>
	<CABghstTV1zS3x5f+DY+CHT+dT5XYYhUSaDskJxrQkf=VQdoOzw@mail.gmail.com>
	<CAN=0SEkcvSx+tFbsZb43Wg_Tby7_ePx+GdSe+q2VuQu-_RAB_w@mail.gmail.com>
	<CABghstTO93jwnTLyG3hOk0uFSO7iPUYO4PG2C0BNGWgheNQjhA@mail.gmail.com>
	<CAN=0SEm+5cE=p9DYMP7MMWBXu_Hm+RQSRuhLHSceNyPMwysLjA@mail.gmail.com>
	<b81d7705-99fe-0567-b9a8-5e332f28a07f@gmail.com>
	<CAN=0SE=XT4rKTt62dgUiTSEjC434aVWfX3gh7QwbrJ+soi6aaQ@mail.gmail.com>
Message-ID: <CABghstTcFs1CZgBxVBXC+J7VduSwH7QfbGBG_yxoQKxhYMdxNw@mail.gmail.com>

Hmm.  Can you send me a reproducible example?

On Thu, Aug 18, 2016 at 9:11 AM, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>> names(std_data)
>  [1] "field_count"     "month_fix"       "num_fields"      "field_id"
> "animal"          "soc_grp"         "habitat"
>  [8] "habitat2"        "monyear"         "mon"             "season_wt"
> "season"          "month"           "year"
> [15] "sex"             "age"             "ageclass"        "soil"
> "slope"           "elevation"       "aspect"
> [22] "NSEW"            "origarea"        "newarea"         "HRNewArea"
> "HabNewArea"      "PropAvlHab"      "origperim"
> [29] "newperim"        "propHRfield"     "percentHRfield"  "PropHabfield"
> "percentHabfield" "field_use"       "slopescale"
> [36] "aspectscale"     "z.month_fix"     "z.num_fields"    "z.slope"
> "z.origarea"      "z.PropAvlHab"
>
>
> On 18 August 2016 at 14:07, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>   what's the results of names(std_data) ?
>>
>> On 16-08-18 09:05 AM, Aoibheann Gaughran wrote:
>> > Hi Ben,
>> >
>> > I've manually scaled and centered the continuous variables, and just
>> > scaled the offset terms.  However, I now get the following error message
>> > when I attempt to run the model, which appears to related to a
>> > subsetting issue?
>> >
>> > Error in `[.data.frame`(cor_dat, start_pos + (1:x$npar), start_pos + 4 +
>> > :
>> > undefined columns selected
>> >
>> > The revised global model is specified as follows:
>> >
>> > stdmod12d <- glmmadmb(field_count ~ habitat #categorical
>> >                      + season_wt #cat
>> >                      + sex #cat
>> >                      + ageclass #cat
>> >                      + z.slope #continuous, scaled and centred
>> >                      + NSEW #cat
>> >                      + z.month_fix #continuous, scaled and centred
>> >                      + z.num_fields #continuous, scaled and centred
>> >                      + habitat:ageclass
>> >                      + habitat:sex
>> >                      + offset(log(z.origarea)) #scaled
>> >                      + offset(log(z.PropAvlHab)) #scaled
>> >                      +(1|animal) #repeated obs from same individual
>> >                      +(1|field_id) #repeated obs in same field
>> >                      ,
>> >                      family="nbinom",
>> >                      zeroInflation=TRUE,
>> >                      admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>> >                      debug=TRUE,
>> >                      data = std_data)
>> >
>> > On 16 August 2016 at 12:55, Ben Bolker <bbolker at gmail.com
>> > <mailto:bbolker at gmail.com>> wrote:
>> >
>> >     You can *scale* the offsets if you like, i.e. change them by a
>> >     multiplicative factor (thus changing the effective area unit for
>> > which
>> >     you were modeling counts), but *centering* them doesn't make sense
>> > --
>> >     as you've noticed.
>> >
>> >     On Tue, Aug 16, 2016 at 7:40 AM, Aoibheann Gaughran <gaughra at tcd.ie
>> >     <mailto:gaughra at tcd.ie>> wrote:
>> >     > Hi Ben,
>> >     >
>> >     > Im proceeding by standardizing by hand.  However, I need to
>> >     include offsets
>> >     > in my model for origarea and PropAvlHab i.e.
>> >     offset(log(z.origarea)) but
>> >     > logging the standardized varible produced NaNs due to the presence
>> > of
>> >     > negative numbers, ditto with z.PropAvlHab. Is there a way around
>> >     this? Do I
>> >     > need to also standardize the offset terms or can I leave them in
>> > their
>> >     > unstandardized form?
>> >     >
>> >     > Many thanks,
>> >     >
>> >     > Aoibheann
>> >     >
>> >     > On 15 August 2016 at 15:47, Ben Bolker <bbolker at gmail.com
>> >     <mailto:bbolker at gmail.com>> wrote:
>> >     >>
>> >     >> Hmm.  Surprising/hard to diagnose.
>> >     >>
>> >     >> 'standardize' doesn't do anything very fancy - it standardizes
>> > the
>> >     >> input variables as described by ?arm::standardize and *refits*
>> > the
>> >     >> model (I've always been a little disappointed that it doesn't
>> >     >> standardize by figuring out how to transform the *parameters*,
>> > which
>> >     >> is straightforward in principle although it can be tricky to
>> > figure
>> >     >> out how to deal with input variables that lead to multiple
>> > predictor
>> >     >> variables, e.g. polynomials).  I'd be curious to know what's
>> >     going on,
>> >     >> but in your place I would
>> >     >>
>> >     >> (1) try standardizing by hand, e.g.
>> >     >>
>> >     >> std_data <- transform(data,
>> >     >>       z.season.wt = scale(season.wt),
>> >     >>      ...)
>> >     >>
>> >     >> and refit yourself.
>> >     >>
>> >     >> (2) see if it happens to work with glmmTMB (a simple example
>> > does).
>> >     >>
>> >     >>   Ben Bolker
>> >     >>
>> >     >>
>> >     >>
>> >     >>
>> >     >> On Mon, Aug 15, 2016 at 10:37 AM, Aoibheann Gaughran
>> >     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
>> >     >> wrote:
>> >     >> > Thanks Ben, I ran the code and got the following error and
>> >     warnings:-
>> >     >> >
>> >     >> > Error in glmmadmb(formula = field_count ~ habitat + season_wt +
>> >     c.sex +
>> >     >> > :
>> >     >> >   rank of X = 16 < ncol(X) = 24
>> >     >> > In addition: Warning messages:
>> >     >> > 1: In log(z.PropAvlHab) : NaNs produced
>> >     >> > 2: In glmmadmb(formula = field_count ~ habitat + season_wt +
>> >     c.sex +  :
>> >     >> >   NAs removed in constructing fixed-effect model frame: you
>> > should
>> >     >> > probably
>> >     >> > remove them manually, e.g. with na.omit()
>> >     >> >
>> >     >> >
>> >     >> > The original PropAvlHab summary is as follows:-
>> >     >> >
>> >     >> >> summary(dframe1$PropAvlHab)
>> >     >> >      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
>> >     >> > 0.0000123 0.1123000 0.4041000 0.4078000 0.6818000 1.0000000
>> >     >> >
>> >     >> > Aoibheann
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >> > On 15 August 2016 at 15:12, Ben Bolker <bbolker at gmail.com
>> >     <mailto:bbolker at gmail.com>> wrote:
>> >     >> >>
>> >     >> >> 'standardize' is a function from the arm package.
>> >     >> >>
>> >     >> >> I've just hacked glmmADMB a little bit so this should work:
>> >     >> >>
>> >     >> >> library(devtools)
>> >     >> >> install_github("bbolker/glmmADMB")  ## install latest version
>> >     >> >> library(arm)
>> >     >> >> arm:::standardize.default(fitted_model$call)
>> >     >> >>
>> >     >> >>
>> >     >> >>
>> >     >> >> On Mon, Aug 15, 2016 at 5:06 AM, Aoibheann Gaughran
>> >     <gaughra at tcd.ie <mailto:gaughra at tcd.ie>>
>> >     >> >> wrote:
>> >     >> >> > Hello Mixed-Modellers,
>> >     >> >> >
>> >     >> >> > I have getting the following error message when trying to
>> >     standardize
>> >     >> >> > my
>> >     >> >> > global glmmadmb model for dredging:
>> >     >> >> >
>> >     >> >> > Error in (function (classes, fdef, mtable)  : unable to find
>> > an
>> >     >> >> > inherited
>> >     >> >> > method for function ?standardize? for signature ?"glmmadmb"?
>> >     >> >> >
>> >     >> >> > Is it not possible to standardise a glmmadmb model or is the
>> >     problem
>> >     >> >> > with
>> >     >> >> > the structure of the model itself?
>> >     >> >> >
>> >     >> >> > globalmod    <- glmmadmb(field_count ~ habitat
>> >     >> >> > #categorical - 7 levels
>> >     >> >> >                      + season_wt
>> >     >> >> >                                          #categorial - 3
>> > levels
>> >     >> >> >                      + sex
>> >     >> >> >                                               #categorial -
>> >     2 levels
>> >     >> >> >                      + ageclass
>> >     >> >> >                                            #categorial - 3
>> >     levels
>> >     >> >> >                      + slope
>> >     >> >> >                                              #continuous,
>> >     not scaled
>> >     >> >> > nor
>> >     >> >> > centred
>> >     >> >> >                      + NSEW
>> >     >> >> >                                           #catagorical - 4
>> >     levels
>> >     >> >> >                      + month_fix
>> >     >> >> >                                           #continuous, not
>> >     scaled nor
>> >     >> >> > centred,
>> >     >> >> >                      + num_fields
>> >     >> >> >                   #continuous, not scaled nor centred
>> >     >> >> >                      + habitat:ageclass
>> >     >> >> >                      + habitat:sex
>> >     >> >> >                      + offset(log(origarea))
>> >     >> >> >                      + offset(log(PropAvlHab))
>> >     >> >> >                      +(1|individual_id)
>> >     >> >> >                                            #repeated obs
>> >     from same
>> >     >> >> > individual
>> >     >> >> >                      +(1|field_id)
>> >     >> >> >                                               #repeated obs
>> >     in same
>> >     >> >> > field,
>> >     >> >> >                      family="nbinom",
>> >     >> >> >                      zeroInflation=TRUE,
>> >     >> >> >
>> >     admb.opts=admbControl(shess=FALSE,noinit=FALSE),
>> >     >> >> >                      debug=TRUE,
>> >     >> >> >                      data = dframe1)
>> >     >> >> >
>> >     >> >> > no of observations =9220
>> >     >> >> >
>> >     >> >> > Many thanks,
>> >     >> >> >
>> >     >> >> > --
>> >     >> >> > Aoibheann Gaughran
>> >     >> >> >
>> >     >> >> > Behavioural and Evolutionary Ecology Research Group
>> >     >> >> > Zoology Building
>> >     >> >> > School of Natural Sciences
>> >     >> >> > Trinity College Dublin
>> >     >> >> > Dublin 2
>> >     >> >> > Ireland
>> >     >> >> > Phone: +353 (86) 3812615
>> >     >> >> >
>> >     >> >> >         [[alternative HTML version deleted]]
>> >     >> >> >
>> >     >> >> > _______________________________________________
>> >     >> >> > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >> >
>> >     >> > --
>> >     >> > Aoibheann Gaughran
>> >     >> >
>> >     >> > Behavioural and Evolutionary Ecology Research Group
>> >     >> > Zoology Building
>> >     >> > School of Natural Sciences
>> >     >> > Trinity College Dublin
>> >     >> > Dublin 2
>> >     >> > Ireland
>> >     >> > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
>> >     >
>> >     >
>> >     >
>> >     >
>> >     > --
>> >     > Aoibheann Gaughran
>> >     >
>> >     > Behavioural and Evolutionary Ecology Research Group
>> >     > Zoology Building
>> >     > School of Natural Sciences
>> >     > Trinity College Dublin
>> >     > Dublin 2
>> >     > Ireland
>> >     > Phone: +353 (86) 3812615 <tel:%2B353%20%2886%29%203812615>
>> >
>> >
>> >
>> >
>> > --
>> > Aoibheann Gaughran
>> >
>> > Behavioural and Evolutionary Ecology Research Group
>> > Zoology Building
>> > School of Natural Sciences
>> > Trinity College Dublin
>> > Dublin 2
>> > Ireland
>> > Phone: +353 (86) 3812615
>
>
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615


From pvdberg1 at gmail.com  Mon Aug 22 14:23:32 2016
From: pvdberg1 at gmail.com (Piet van den Berg)
Date: Mon, 22 Aug 2016 12:23:32 +0000
Subject: [R-sig-ME] Confidence intervals on predictions for a non-linear
	mixed model (nlme)
Message-ID: <CADRaQnCe9DWfNP9oOOys3+g_JgPT6hEw_O5cSWn9fq9E4RM8WA@mail.gmail.com>

Dear all,

I'm trying to get confidence intervals on my predictions for a non-linear
mixed model in nlme, using resampling of parameter values. I got a result,
but would like to know if I'm going in the right direction.

I posted my problem here:
http://stats.stackexchange.com/questions/231074/confidence-intervals-on-predictions-for-a-non-linear-mixed-model-nlme

Any help would be appreciated.

All best,
Piet.

	[[alternative HTML version deleted]]


From orzack at freshpond.org  Mon Aug 22 17:15:27 2016
From: orzack at freshpond.org (Steven Orzack)
Date: Mon, 22 Aug 2016 11:15:27 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
	invertible
Message-ID: <2d5d493d-d5b2-30d3-a0c7-494e582e8107@freshpond.org>

   I have updated the code and have implemented tryCatch in order to 
avoid the error (noninvertible matrix), which halts the simulation. 
Thanks again to Ben Bolker for the suggestion. FWIW, the manual page 
documentation and examples for tryCatch are, ahem....., a bit opaque but 
in the end it is straightforward to code.

On the possibility that this will help others, here is what I wrote:


try_AIC <- function(ind) {
     out <- tryCatch(
     {
           AIClist[ind] <- summary(gls(CV ~ 1, data = data_try, 
correlation = corARMA(p=ind), method="ML"))$AIC

     },
         error=function(e) {
            AIClist[ind] = 0
         },
         warning=function(w) {
              return(NULL)
         },
         finally={
         }
     )
     return(out)
}

This fits the gls model for a given order (ind) and stores an AIC value 
for that fit. if the matrix cannot be inverted and the gls model cannot 
be fit, the return is AIC = 0 (AIC values for models that are fitted are 
negative).

In the main simulation, the code where the fitting occurs is

#scan AR models (0 - 4)
AIClist <- c(rep(0,5))
  AIClist[1] <- summary(gls(CV ~ 1, data = data_try, correlation = NULL, 
method="ML"))$AIC
for (autor in 1:4) {
   index <- autor + 1
   AIClist[index] <- try_AIC(autor)
   }#CLOSE LOOP FOR AIC
#determine which AR model has smallest AIC
   arorder <- match(min(AIClist), AIClist) - 1

arorder returns the order of the AR model with the minimum AIC.

Now that I have solved this, I have a more strategic question about the 
overall structure of the analysis. Pleas see the next email!



  > I am analyzing time series of a statistic (coefficient of variation or
  > CV) generated by a Monte Carlo simulation of population dynamics. A
  > given simulation might generate thousands of such time series.
  >
  > For any given time series, the sequential estimates of CV are correlated
  > with one another (because they are based on partially overlapping sets
  > of the population numbers). Accordingly, I am using gls models with
  > autocorrelated errors to analyze each time series.
  >
  > Although the stochastic process generating all sample paths is the same,
  > any given sample path might consist of a time series of CV for which
  > AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced
  > by ar() (see below).
  >
  > In practice, I have seen time series for which AR(0), AR(1), AR(2)
  > generate the smallest AIC value and so always just using a specific
  > order (e.g., AR(1)) does not seem appropriate. This is especially so
  > because I am developing methods that would apply to time series for
  > which the generating dynamics are not known.
  >
  > For any given sample path y, the code is
  >
  > #assess order of AR model using ar. use order with smallest AIC
  > arorder <- ar(moving_statistics$CV, order.max = 5)$order
  >
  > #evaluate model with constant and time
  > if (arorder < 1) {
  > summary(int_model <- lm(CV ~ 1, data = moving_statistics))
  > summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))
  >
  > #extract statistics for sample path y
  > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
  > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
  > } else {
  > summary(int_model <- gls(CV ~ 1, data = moving_statistics, correlation =
  > corARMA(p=arorder), method="ML"))
  > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
  > correlation = corARMA(p=arorder), method="ML"))
  > #extract statistics for sample path y
  > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
  > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
  > }
  >
  >
  > When I run the simulation, there are some sample paths for which AR(2)
  > has the lowest AIC and so this is the model called, as in
  >
  > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
  > correlation = corARMA(p=2), method="ML"))
  >
  >
  > This call appears to always generate this error message
  >
  > Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
  >   Coefficient matrix not invertible
  >
  > Here are my questions:
  >
  > 1. how does ar generate an AIC value for p =2 even though the
  > coefficient matrix is not invertible and so the model fit fails?

    gls and ar are using different algorithms.  Furthermore, I think ar()
is assuming a constant mean whereas your gls() has a linear effect of
time, so they're actually trying to fit different models.


  > 2. Is there a way to actually fit such a model, say, by adjusting
  > tolerances?

    Don't know.  I would start by debugging my way through the gls code to
say where it is actually breaking.  I don't think I have much to say
other than what I already said in the SO thread you reference below.
  >
  > 3. a related thread
  > 
(http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)
  >
  >
  > indicates that there are too many parameters being estimated given the
  > length of the time series.
  >
  > Is there a numerical criterion that can be queried before the gls call
  > so that I can test for invertibility and fit, say, a lower order model
  > (e.g., AR(1)), so as to avoid an error?

    You could certainly wrap this attempt in a try() or tryCatch() clause
so that it wouldn't break your simulation run and you could then fall
back on AR(1) ...

  >
  > I cannot figure out from the code for gls what actually generates the
  > error message. A pointer to the specific numerical criterion that
  > generates this error would be very much appreciated.

    Unpacking the nlme source code and searching for the error message
finds it on line 557 of src/corStruct.c:

     F77_CALL(dqrdc2) (coef, &P, &P, &P,  &sqrt_eps, &i, qraux, pivot, w\
ork);
              if (i < P)
                  error(_("Coefficient matrix not invertible" ));


https://svn.r-project.org/R/trunk/src/appl/dqrdc2.f

says that dqrdc2 is a Householder transformation, but you'd really have
to figure this out for yourself ...

    the i parameter corresponds to a k argument inside the FORTRAN
function: "k contains the number of columns of x judged to be linearly
independent." so it looks like you end up with a rank-deficient matrix
at some point.
  >
  > In the stackoverflow thread, this is mentioned:
  >
  > The general rule of thumb is that you should have at least 10 times as
  > many data points as parameters, and that's for standard fixed
  > effect/regression parameters. (Generally variance structure parameters
  > such as AR parameters are even a bit harder/require a bit more data than
  > regression parameters to estimate.)
  >
  > Where in the literature is this rule discussed?

    I got it from Frank Harrell's _Regression Modeling Strategies_ book.

  > 4. If the only option is to fit a lower order model of error, say,
  > AR(1), instead of AR(2), what kind of bias does this generate in the
  > analysis?
  >

     Don't know.  Since you're running simulations, you could find out ...
  >
  >
  > Many thanks in advance,
  >
  > S.
  >

-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From orzack at freshpond.org  Mon Aug 22 18:31:57 2016
From: orzack at freshpond.org (Steven Orzack)
Date: Mon, 22 Aug 2016 12:31:57 -0400
Subject: [R-sig-ME] time series with autcorrelated errors - matrix not
	invertible
Message-ID: <fcbcbaf1-f1fe-cba1-d46a-b6412168fafc@freshpond.org>

   My original code involved use ar() to assess the appropriate AR model 
and then fit that model using gls(). This is not the general approach 
outlined in Fox and Weisberg's appendix chapter on Time-Series 
regression. They describe a proper approach (see below). The problematic 
nature of my original approach is hinted at by Ben Bolker noting that 
ar() and gls() are "using different algorithms".

Fox and Weisberg fit gls models for various orders and then choose among 
them. The proper point is that we need to compare models with different 
orders for the dependency of the errors. My approach incorrectly based 
the choice of order on the time series itself.

There is a wrinkle in the present context that is not addressed in Fox 
and Weisberg. In my analysis, I want to assess whether a constant

gls(CV ~ 1,....correlation = corARMA(p=?))

or time-dependent model


gls(CV ~ 1 + time,....correlation = corARMA(p=?))

has more support for a given time series.

So, which model is best to use (1 or 1 + time) as the model used to 
determine the value of p? Is there an a priori reason to choose one of 
them? The two models may suggest different values of p.

In addition, suppose one starts with, say,

gls(CV ~ 1.......correlation = corARMA(p=x))

and determines that p = x generates a (constant) model with the lowest 
AIC among those considered. it is easy to find time series (available 
upon request) for which for


gls(CV ~ 1 + time......correlation = corARMA(p=x))

canNOT be fit

or vice-versa.

does the simpler model have preference as a basis for choice of p? 
suppose it does and the time model cannot be fit for the same value of p.

What p value does one choose? One possible rule is to choose the order 
for which both models can be fit but there will likely be more than one 
value of p for which this occurs. How does one choose among them?

thoughts and suggestions will be much appreciated.

many thanks!


   > I am analyzing time series of a statistic (coefficient of variation or
   > CV) generated by a Monte Carlo simulation of population dynamics. A
   > given simulation might generate thousands of such time series.
   >
   > For any given time series, the sequential estimates of CV are 
correlated
   > with one another (because they are based on partially overlapping sets
   > of the population numbers). Accordingly, I am using gls models with
   > autocorrelated errors to analyze each time series.
   >
   > Although the stochastic process generating all sample paths is the 
same,
   > any given sample path might consist of a time series of CV for which
   > AR(0), AR(1), AR(2), etc. generates the smallest AIC value, as produced
   > by ar() (see below).
   >
   > In practice, I have seen time series for which AR(0), AR(1), AR(2)
   > generate the smallest AIC value and so always just using a specific
   > order (e.g., AR(1)) does not seem appropriate. This is especially so
   > because I am developing methods that would apply to time series for
   > which the generating dynamics are not known.
   >
   > For any given sample path y, the code is
   >
   > #assess order of AR model using ar. use order with smallest AIC
   > arorder <- ar(moving_statistics$CV, order.max = 5)$order
   >
   > #evaluate model with constant and time
   > if (arorder < 1) {
   > summary(int_model <- lm(CV ~ 1, data = moving_statistics))
   > summary(time_model <- lm(CV ~ 1 + time, data = moving_statistics))
   >
   > #extract statistics for sample path y
   > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$Pr
   > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
   > } else {
   > summary(int_model <- gls(CV ~ 1, data = moving_statistics, 
correlation =
   > corARMA(p=arorder), method="ML"))
   > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
   > correlation = corARMA(p=arorder), method="ML"))
   > #extract statistics for sample path y
   > pvalue_cv$pvalue[y] <- anova(int_model,time_model)$p[2]
   > pvalue_cv$slope_time[y] <- time_model$coefficients[2]
   > }
   >
   >
   > When I run the simulation, there are some sample paths for which AR(2)
   > has the lowest AIC and so this is the model called, as in
   >
   > summary(time_model <- gls(CV ~ 1 + time, data = moving_statistics,
   > correlation = corARMA(p=2), method="ML"))
   >
   >
   > This call appears to always generate this error message
   >
   > Error in `coef<-.corARMA`(`*tmp*`, value = value[parMap[, i]]) :
   >   Coefficient matrix not invertible
   >
   > Here are my questions:
   >
   > 1. how does ar generate an AIC value for p =2 even though the
   > coefficient matrix is not invertible and so the model fit fails?

     gls and ar are using different algorithms.  Furthermore, I think ar()
is assuming a constant mean whereas your gls() has a linear effect of
time, so they're actually trying to fit different models.


   > 2. Is there a way to actually fit such a model, say, by adjusting
   > tolerances?

     Don't know.  I would start by debugging my way through the gls code to
say where it is actually breaking.  I don't think I have much to say
other than what I already said in the SO thread you reference below.
   >
   > 3. a related thread
   > 
(http://stackoverflow.com/questions/6706143/error-with-gls-function-in-nlme-package-in-r)
   >
   >
   > indicates that there are too many parameters being estimated given the
   > length of the time series.
   >
   > Is there a numerical criterion that can be queried before the gls call
   > so that I can test for invertibility and fit, say, a lower order model
   > (e.g., AR(1)), so as to avoid an error?

     You could certainly wrap this attempt in a try() or tryCatch() clause
so that it wouldn't break your simulation run and you could then fall
back on AR(1) ...

   >
   > I cannot figure out from the code for gls what actually generates the
   > error message. A pointer to the specific numerical criterion that
   > generates this error would be very much appreciated.

     Unpacking the nlme source code and searching for the error message
finds it on line 557 of src/corStruct.c:

      F77_CALL(dqrdc2) (coef, &P, &P, &P,  &sqrt_eps, &i, qraux, pivot, w\
ork);
               if (i < P)
                   error(_("Coefficient matrix not invertible" ));


https://svn.r-project.org/R/trunk/src/appl/dqrdc2.f

says that dqrdc2 is a Householder transformation, but you'd really have
to figure this out for yourself ...

     the i parameter corresponds to a k argument inside the FORTRAN
function: "k contains the number of columns of x judged to be linearly
independent." so it looks like you end up with a rank-deficient matrix
at some point.
   >
   > In the stackoverflow thread, this is mentioned:
   >
   > The general rule of thumb is that you should have at least 10 times as
   > many data points as parameters, and that's for standard fixed
   > effect/regression parameters. (Generally variance structure parameters
   > such as AR parameters are even a bit harder/require a bit more data 
than
   > regression parameters to estimate.)
   >
   > Where in the literature is this rule discussed?

     I got it from Frank Harrell's _Regression Modeling Strategies_ book.

   > 4. If the only option is to fit a lower order model of error, say,
   > AR(1), instead of AR(2), what kind of bias does this generate in the
   > analysis?
   >

      Don't know.  Since you're running simulations, you could find out ...
   >
   >
   > Many thanks in advance,
   >
   > S.
   >

-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From paul.buerkner at gmail.com  Mon Aug 22 19:58:33 2016
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Mon, 22 Aug 2016 19:58:33 +0200
Subject: [R-sig-ME] Confidence intervals on predictions for a non-linear
 mixed model (nlme)
In-Reply-To: <CADRaQnCe9DWfNP9oOOys3+g_JgPT6hEw_O5cSWn9fq9E4RM8WA@mail.gmail.com>
References: <CADRaQnCe9DWfNP9oOOys3+g_JgPT6hEw_O5cSWn9fq9E4RM8WA@mail.gmail.com>
Message-ID: <CAGoSky-bmfSWThUf4impd5O2zgL=Wo1kYuq7Fm0OM3-+VP7aQA@mail.gmail.com>

Hi Piet,

as already pointed out on stackexchange, there is no direct way with nlme
to determine the distribution of the parameters so that we don't know if a
normal approximation is justified.

One solution to overcome this problem is to use Bayesian methods. With the
brms package, for instance, this looks as follows:

library(nlme)
library(brms)

# define some reasonable priors
prior = c(set_prior("normal(80, 20)", nlpar = "Asym"),
          set_prior("normal(0, 10)", nlpar = "R0"),
          set_prior("normal(0, 5)", nlpar = "lrc"))

# fit the model
fm2 <- brm(height ~ Asym+(R0-Asym)*exp(-exp(lrc)*age),
           data = Loblolly, prior = prior,
           nonlinear = list(Asym ~ 1 + (1|Seed), R0 ~ 1, lrc ~ 1))
summary(fm2)
plot(fm2)

# effect of age without RE variance
marginal_effects(fm2)
# effect of age with RE variance
marginal_effects(fm2, re_formula = NULL)


Using brms may be a bit cumbersome at start as you need a C++ compiler at
run time. That is you need Rtools on Windows or Xcode on Mac (see
https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#prerequisites)
for more details.

Hope this will help you in getting closer to answering your research
question.

- Paul

2016-08-22 14:23 GMT+02:00 Piet van den Berg <pvdberg1 at gmail.com>:

> Dear all,
>
> I'm trying to get confidence intervals on my predictions for a non-linear
> mixed model in nlme, using resampling of parameter values. I got a result,
> but would like to know if I'm going in the right direction.
>
> I posted my problem here:
> http://stats.stackexchange.com/questions/231074/confidence-intervals-on-
> predictions-for-a-non-linear-mixed-model-nlme
>
> Any help would be appreciated.
>
> All best,
> Piet.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Aug 25 11:06:03 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 25 Aug 2016 10:06:03 +0100
Subject: [R-sig-ME] Course: Introduction to Regression Models with Spatial
 and Temporal Correlation
Message-ID: <0fd5383b-c7f5-f18c-8967-5ba37b7c5ee4@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Regression Models with Spatial and Temporal 
Correlation
Where:  Lisbon, Portugal
When:   20-24 February 2017

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2017_02Lisbon_SpatTemp.pdf


Kind regards,

Alain Zuur






-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From mlw32 at uw.edu  Wed Aug 24 01:41:23 2016
From: mlw32 at uw.edu (Malcolm Wolff)
Date: Tue, 23 Aug 2016 16:41:23 -0700
Subject: [R-sig-ME] Question Regarding the BootMer function
Message-ID: <d2ddf012-ae93-45e2-daf3-56aace8247cc@uw.edu>

I am using the BootMer function for current research, and have a question regarding a specific warning message. When the message below appears, does BootMer recalculate the nonconvergent iteration, use an estimate from the nonconvergent iteration, or pass over the nonconvergent iteration?


Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues



Thank you for your time.


Regards,

Malcolm Wolff


From saah500 at york.ac.uk  Tue Aug 30 07:23:48 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 30 Aug 2016 08:23:48 +0300
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
Message-ID: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>

Good morning,


I have complex data of 7 variables (6 treatment + 1 control [?age? in the
model below]) plus 18 interactions in a dataset of 2448 observations which
have some missing values (NAs).  The maximal model which I have simplified
as per y hypothesis is as follows.



modelAAW<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
context +length + age + freq.+ Listgp:context+ Listgp:length+ Listgp:freq.+
Listgp:stimulus.presentation+ Listgp:age+ context:length+ context:freq.+
context:stimulus.presentation+ context:age+ length:freq.+
length:stimulus.presentation+ length:age+ freq.:stimulus.presentation+
freq.:age+ stimulus.presentation:age+  Listgp:stimulus.presentation +
Listgp:vowel.quality + stimulus.presentation:vowel.quality +
(Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data =
SBAAW, family = "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)),
nAGQ =1)



I ran a binomial logistic regression analysis on the data and did the
stepwise regression manually since the drop1(modelAAW, test = "Chisq")
command yielded no results in a span of more than 16 hours. The resulting
regression models are nested in the maximal model (modelAAW).



Then, I reached the model selection step where I have to interpret the
anova table below which has degrees of freedom of zero for some models.



         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)

AAWXI    49 2454.5 2738.8 -1178.2   2356.5

AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000

AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000

AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2     0.2375

AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0     1.0000

AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1     0.3320

AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16 ***

AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16 ***

AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2     0.1200

AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2     0.8076

AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0     1.0000

AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1     0.8835

AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3     0.5773

modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6     0.4721

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1





So many people that I have consulted tell me that I shouldn?t trust a model
of df=zero and advise that I should re-run the models using the drop1
command or simplify the maximal model but in my case I don?t know if I will
ever get results especially that it took more than 16 hours straight with
no luck and I simplified the maximal model to the best I could.



When I checked R documentation, I read that ?when given a sequence of
objects, anova tests the models against one another in the order specified?
based on the AIC value from the smallest to the largest.  However, there
is  a warning that ?the comparison between two or more models will only be
valid if they are fitted to the same dataset. This may be a problem if
there are missing values and R's default of na.action = na.omit is used?,
so I?m assuming this is the case with my models.



Now, should I select model AAWVIII since it has the least p-value (and the
least BIC value compared to AAWVII)?



The formulas of the two models in addition to AAWXI model are as follows.
The first two models are similar to each other except that in AAWVIII the
variable stimulus.presentation is deleted and in model AAWXI the variable
Listgp is deleted.


AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation + context
+ age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
context:freq.+ context:stimulus.presentation+length:stimulus.presentation+
length:age+ freq.:stimulus.presentation+ freq.:age+
stimulus.presentation:age+ + Listgp:stimulus.presentation +
Listgp:vowel.quality + stimulus.presentation:vowel.quality +
(Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data =
SBAAW, family = "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)),
nAGQ =1)



AAWVIII<-glmer(match~Listgp + vowel.quality + context + age + Listgp:freq.+
Listgp:stimulus.presentation+ context:length+ context:freq.+
context:stimulus.presentation+length:stimulus.presentation+ length:age+
freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
Listgp:stimulus.presentation + Listgp:vowel.quality +
stimulus.presentation:vowel.quality + (Listgp|stimulus) +
(stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
"binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)



AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+
Listgp:stimulus.presentation+ context:length+ context:freq.+
context:stimulus.presentation+length:stimulus.presentation+
freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
Listgp:stimulus.presentation + Listgp:vowel.quality +
stimulus.presentation:vowel.quality + (Listgp|stimulus) +
(stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
"binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)



I would appreciate your help with this.



-- 
Shadiya

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Aug 30 09:29:53 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 30 Aug 2016 09:29:53 +0200
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
Message-ID: <CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>

Dear Shadiya,

You need to do the model selection on a stable dataset. Therefore you
should create a subset which doesn't contain missing values in the
covariates. Use this subset for model selection. Then you can refit the
final model on the total dataset.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Good morning,
>
>
> I have complex data of 7 variables (6 treatment + 1 control [?age? in the
> model below]) plus 18 interactions in a dataset of 2448 observations which
> have some missing values (NAs).  The maximal model which I have simplified
> as per y hypothesis is as follows.
>
>
>
> modelAAW<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
> context +length + age + freq.+ Listgp:context+ Listgp:length+ Listgp:freq.+
> Listgp:stimulus.presentation+ Listgp:age+ context:length+ context:freq.+
> context:stimulus.presentation+ context:age+ length:freq.+
> length:stimulus.presentation+ length:age+ freq.:stimulus.presentation+
> freq.:age+ stimulus.presentation:age+  Listgp:stimulus.presentation +
> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data
> =
> SBAAW, family = "binomial", control=glmerControl(optCtrl=
> list(maxfun=2e5)),
> nAGQ =1)
>
>
>
> I ran a binomial logistic regression analysis on the data and did the
> stepwise regression manually since the drop1(modelAAW, test = "Chisq")
> command yielded no results in a span of more than 16 hours. The resulting
> regression models are nested in the maximal model (modelAAW).
>
>
>
> Then, I reached the model selection step where I have to interpret the
> anova table below which has degrees of freedom of zero for some models.
>
>
>
>          Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>
> AAWXI    49 2454.5 2738.8 -1178.2   2356.5
>
> AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>
> AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>
> AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2     0.2375
>
> AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0     1.0000
>
> AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1     0.3320
>
> AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16 ***
>
> AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16 ***
>
> AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2     0.1200
>
> AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2     0.8076
>
> AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0     1.0000
>
> AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1     0.8835
>
> AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3     0.5773
>
> modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6     0.4721
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
>
>
> So many people that I have consulted tell me that I shouldn?t trust a model
> of df=zero and advise that I should re-run the models using the drop1
> command or simplify the maximal model but in my case I don?t know if I will
> ever get results especially that it took more than 16 hours straight with
> no luck and I simplified the maximal model to the best I could.
>
>
>
> When I checked R documentation, I read that ?when given a sequence of
> objects, anova tests the models against one another in the order specified?
> based on the AIC value from the smallest to the largest.  However, there
> is  a warning that ?the comparison between two or more models will only be
> valid if they are fitted to the same dataset. This may be a problem if
> there are missing values and R's default of na.action = na.omit is used?,
> so I?m assuming this is the case with my models.
>
>
>
> Now, should I select model AAWVIII since it has the least p-value (and the
> least BIC value compared to AAWVII)?
>
>
>
> The formulas of the two models in addition to AAWXI model are as follows.
> The first two models are similar to each other except that in AAWVIII the
> variable stimulus.presentation is deleted and in model AAWXI the variable
> Listgp is deleted.
>
>
> AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation + context
> + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
> context:freq.+ context:stimulus.presentation+length:stimulus.presentation+
> length:age+ freq.:stimulus.presentation+ freq.:age+
> stimulus.presentation:age+ + Listgp:stimulus.presentation +
> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data
> =
> SBAAW, family = "binomial", control=glmerControl(optCtrl=
> list(maxfun=2e5)),
> nAGQ =1)
>
>
>
> AAWVIII<-glmer(match~Listgp + vowel.quality + context + age + Listgp:freq.+
> Listgp:stimulus.presentation+ context:length+ context:freq.+
> context:stimulus.presentation+length:stimulus.presentation+ length:age+
> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> Listgp:stimulus.presentation + Listgp:vowel.quality +
> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>
>
>
> AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+
> Listgp:stimulus.presentation+ context:length+ context:freq.+
> context:stimulus.presentation+length:stimulus.presentation+
> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> Listgp:stimulus.presentation + Listgp:vowel.quality +
> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>
>
>
> I would appreciate your help with this.
>
>
>
> --
> Shadiya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From saah500 at york.ac.uk  Tue Aug 30 10:03:10 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Tue, 30 Aug 2016 11:03:10 +0300
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
Message-ID: <CACrevpm2KbyL9Sgz1K=DgckTjTJHi3HkJh2KwHyt-CdOnj0c+A@mail.gmail.com>

Dear Thierry,

Thanks for the tip and for always being the first to respond to my
statistical dilemmas:)

I will try your suggestion now.

Best wishes,

Shadiya

On 30 August 2016 at 10:29, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Shadiya,
>
> You need to do the model selection on a stable dataset. Therefore you
> should create a subset which doesn't contain missing values in the
> covariates. Use this subset for model selection. Then you can refit the
> final model on the total dataset.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
>> Good morning,
>>
>>
>> I have complex data of 7 variables (6 treatment + 1 control [?age? in the
>> model below]) plus 18 interactions in a dataset of 2448 observations which
>> have some missing values (NAs).  The maximal model which I have simplified
>> as per y hypothesis is as follows.
>>
>>
>>
>> modelAAW<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
>> context +length + age + freq.+ Listgp:context+ Listgp:length+
>> Listgp:freq.+
>> Listgp:stimulus.presentation+ Listgp:age+ context:length+ context:freq.+
>> context:stimulus.presentation+ context:age+ length:freq.+
>> length:stimulus.presentation+ length:age+ freq.:stimulus.presentation+
>> freq.:age+ stimulus.presentation:age+  Listgp:stimulus.presentation +
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) ,
>> data =
>> SBAAW, family = "binomial", control=glmerControl(optCtrl=l
>> ist(maxfun=2e5)),
>> nAGQ =1)
>>
>>
>>
>> I ran a binomial logistic regression analysis on the data and did the
>> stepwise regression manually since the drop1(modelAAW, test = "Chisq")
>> command yielded no results in a span of more than 16 hours. The resulting
>> regression models are nested in the maximal model (modelAAW).
>>
>>
>>
>> Then, I reached the model selection step where I have to interpret the
>> anova table below which has degrees of freedom of zero for some models.
>>
>>
>>
>>          Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>>
>> AAWXI    49 2454.5 2738.8 -1178.2   2356.5
>>
>> AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>>
>> AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>>
>> AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2     0.2375
>>
>> AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0     1.0000
>>
>> AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1     0.3320
>>
>> AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16 ***
>>
>> AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16 ***
>>
>> AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2     0.1200
>>
>> AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2     0.8076
>>
>> AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0     1.0000
>>
>> AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1     0.8835
>>
>> AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3     0.5773
>>
>> modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6     0.4721
>>
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>>
>>
>> So many people that I have consulted tell me that I shouldn?t trust a
>> model
>> of df=zero and advise that I should re-run the models using the drop1
>> command or simplify the maximal model but in my case I don?t know if I
>> will
>> ever get results especially that it took more than 16 hours straight with
>> no luck and I simplified the maximal model to the best I could.
>>
>>
>>
>> When I checked R documentation, I read that ?when given a sequence of
>> objects, anova tests the models against one another in the order
>> specified?
>> based on the AIC value from the smallest to the largest.  However, there
>> is  a warning that ?the comparison between two or more models will only be
>> valid if they are fitted to the same dataset. This may be a problem if
>> there are missing values and R's default of na.action = na.omit is used?,
>> so I?m assuming this is the case with my models.
>>
>>
>>
>> Now, should I select model AAWVIII since it has the least p-value (and the
>> least BIC value compared to AAWVII)?
>>
>>
>>
>> The formulas of the two models in addition to AAWXI model are as follows.
>> The first two models are similar to each other except that in AAWVIII the
>> variable stimulus.presentation is deleted and in model AAWXI the variable
>> Listgp is deleted.
>>
>>
>> AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
>> context
>> + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
>> context:freq.+ context:stimulus.presentation+
>> length:stimulus.presentation+
>> length:age+ freq.:stimulus.presentation+ freq.:age+
>> stimulus.presentation:age+ + Listgp:stimulus.presentation +
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) ,
>> data =
>> SBAAW, family = "binomial", control=glmerControl(optCtrl=l
>> ist(maxfun=2e5)),
>> nAGQ =1)
>>
>>
>>
>> AAWVIII<-glmer(match~Listgp + vowel.quality + context + age +
>> Listgp:freq.+
>> Listgp:stimulus.presentation+ context:length+ context:freq.+
>> context:stimulus.presentation+length:stimulus.presentation+ length:age+
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
>> Listgp:stimulus.presentation + Listgp:vowel.quality +
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
>> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>>
>>
>>
>> AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+
>> Listgp:stimulus.presentation+ context:length+ context:freq.+
>> context:stimulus.presentation+length:stimulus.presentation+
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
>> Listgp:stimulus.presentation + Listgp:vowel.quality +
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
>> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>>
>>
>>
>> I would appreciate your help with this.
>>
>>
>>
>> --
>> Shadiya
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From pierces1 at msu.edu  Tue Aug 30 14:42:11 2016
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 30 Aug 2016 08:42:11 -0400
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
Message-ID: <000501d202bb$edb5f2f0$c921d8d0$@msu.edu>

I completely agree that analyzing a stable dataset is essential, but I'd argue that selecting a subset containing only cases with no missing data is actually changing the nature of the population to which your inferences can be generalized. In effect it tacks "and who have no missing data" onto the definition of the target population. That is unlikely to be the population you really want to study. It may also dramatically reduce your sample size, thereby reducing power and precision of the estimates.  

To preserve inference to the original intended population, solve the missing data problem with either some form of imputation or by using a full-information maximum likelihood estimation method that doesn?t throw out cases with missing data. 


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Tuesday, August 30, 2016 3:30 AM
To: Shadiya Al Hashmi <saah500 at york.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Anova II table, df, drop1 and very complex regression models!

Dear Shadiya,

You need to do the model selection on a stable dataset. Therefore you
should create a subset which doesn't contain missing values in the
covariates. Use this subset for model selection. Then you can refit the
final model on the total dataset.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:

> Good morning,
>
>
> I have complex data of 7 variables (6 treatment + 1 control [?age? in the
> model below]) plus 18 interactions in a dataset of 2448 observations which
> have some missing values (NAs).  The maximal model which I have simplified
> as per y hypothesis is as follows.
>
>
>
> modelAAW<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
> context +length + age + freq.+ Listgp:context+ Listgp:length+ Listgp:freq.+
> Listgp:stimulus.presentation+ Listgp:age+ context:length+ context:freq.+
> context:stimulus.presentation+ context:age+ length:freq.+
> length:stimulus.presentation+ length:age+ freq.:stimulus.presentation+
> freq.:age+ stimulus.presentation:age+  Listgp:stimulus.presentation +
> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data
> =
> SBAAW, family = "binomial", control=glmerControl(optCtrl=
> list(maxfun=2e5)),
> nAGQ =1)
>
>
>
> I ran a binomial logistic regression analysis on the data and did the
> stepwise regression manually since the drop1(modelAAW, test = "Chisq")
> command yielded no results in a span of more than 16 hours. The resulting
> regression models are nested in the maximal model (modelAAW).
>
>
>
> Then, I reached the model selection step where I have to interpret the
> anova table below which has degrees of freedom of zero for some models.
>
>
>
>          Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>
> AAWXI    49 2454.5 2738.8 -1178.2   2356.5
>
> AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>
> AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
>
> AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2     0.2375
>
> AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0     1.0000
>
> AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1     0.3320
>
> AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16 ***
>
> AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16 ***
>
> AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2     0.1200
>
> AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2     0.8076
>
> AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0     1.0000
>
> AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1     0.8835
>
> AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3     0.5773
>
> modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6     0.4721
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
>
>
> So many people that I have consulted tell me that I shouldn?t trust a model
> of df=zero and advise that I should re-run the models using the drop1
> command or simplify the maximal model but in my case I don?t know if I will
> ever get results especially that it took more than 16 hours straight with
> no luck and I simplified the maximal model to the best I could.
>
>
>
> When I checked R documentation, I read that ?when given a sequence of
> objects, anova tests the models against one another in the order specified?
> based on the AIC value from the smallest to the largest.  However, there
> is  a warning that ?the comparison between two or more models will only be
> valid if they are fitted to the same dataset. This may be a problem if
> there are missing values and R's default of na.action = na.omit is used?,
> so I?m assuming this is the case with my models.
>
>
>
> Now, should I select model AAWVIII since it has the least p-value (and the
> least BIC value compared to AAWVII)?
>
>
>
> The formulas of the two models in addition to AAWXI model are as follows.
> The first two models are similar to each other except that in AAWVIII the
> variable stimulus.presentation is deleted and in model AAWXI the variable
> Listgp is deleted.
>
>
> AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation + context
> + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
> context:freq.+ context:stimulus.presentation+length:stimulus.presentation+
> length:age+ freq.:stimulus.presentation+ freq.:age+
> stimulus.presentation:age+ + Listgp:stimulus.presentation +
> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) , data
> =
> SBAAW, family = "binomial", control=glmerControl(optCtrl=
> list(maxfun=2e5)),
> nAGQ =1)
>
>
>
> AAWVIII<-glmer(match~Listgp + vowel.quality + context + age + Listgp:freq.+
> Listgp:stimulus.presentation+ context:length+ context:freq.+
> context:stimulus.presentation+length:stimulus.presentation+ length:age+
> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> Listgp:stimulus.presentation + Listgp:vowel.quality +
> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>
>
>
> AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+
> Listgp:stimulus.presentation+ context:length+ context:freq.+
> context:stimulus.presentation+length:stimulus.presentation+
> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> Listgp:stimulus.presentation + Listgp:vowel.quality +
> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>
>
>
> I would appreciate your help with this.
>
>
>
> --
> Shadiya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 30 20:15:21 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 30 Aug 2016 14:15:21 -0400
Subject: [R-sig-ME] Anova II table, df,
 drop1 and very complex regression models!
In-Reply-To: <000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
	<000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
Message-ID: <15eacffd-cdf4-75b8-d3d9-7ffff5e0bd19@gmail.com>


  Can you recommend a convenient full-information ML estimation method
that handles a wide range of cases (hopefully nested+crossed, GLMM +
LMM, etc, hopefully implemented in R) ?

  Ben Bolker


On 16-08-30 08:42 AM, Steven J. Pierce wrote:
> I completely agree that analyzing a stable dataset is essential, but
> I'd argue that selecting a subset containing only cases with no
> missing data is actually changing the nature of the population to
> which your inferences can be generalized. In effect it tacks "and who
> have no missing data" onto the definition of the target population.
> That is unlikely to be the population you really want to study. It
> may also dramatically reduce your sample size, thereby reducing power
> and precision of the estimates.
> 
> To preserve inference to the original intended population, solve the
> missing data problem with either some form of imputation or by using
> a full-information maximum likelihood estimation method that doesn?t
> throw out cases with missing data.
> 
> 
> Steven J. Pierce, Ph.D. Associate Director Center for Statistical
> Training & Consulting (CSTAT) Michigan State University
> 
> -----Original Message----- From: Thierry Onkelinx
> [mailto:thierry.onkelinx at inbo.be] Sent: Tuesday, August 30, 2016 3:30
> AM To: Shadiya Al Hashmi <saah500 at york.ac.uk> Cc:
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Anova II
> table, df, drop1 and very complex regression models!
> 
> Dear Shadiya,
> 
> You need to do the model selection on a stable dataset. Therefore
> you should create a subset which doesn't contain missing values in
> the covariates. Use this subset for model selection. Then you can
> refit the final model on the total dataset.
> 
> Best regards,
> 
> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> Research Institute for Nature and Forest team Biometrie &
> Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> 25 1070 Anderlecht Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher 
> The plural of anecdote is not data. ~ Roger Brinner The combination
> of some data and an aching desire for an answer does not ensure that
> a reasonable answer can be extracted from a given body of data. ~
> John Tukey
> 
> 2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
> 
>> Good morning,
>> 
>> 
>> I have complex data of 7 variables (6 treatment + 1 control [?age?
>> in the model below]) plus 18 interactions in a dataset of 2448
>> observations which have some missing values (NAs).  The maximal
>> model which I have simplified as per y hypothesis is as follows.
>> 
>> 
>> 
>> modelAAW<-glmer(match~Listgp + vowel.quality +
>> stimulus.presentation + context +length + age + freq.+
>> Listgp:context+ Listgp:length+ Listgp:freq.+ 
>> Listgp:stimulus.presentation+ Listgp:age+ context:length+
>> context:freq.+ context:stimulus.presentation+ context:age+
>> length:freq.+ length:stimulus.presentation+ length:age+
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+
>> Listgp:stimulus.presentation + Listgp:vowel.quality +
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW,
>> family = "binomial", control=glmerControl(optCtrl= 
>> list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> I ran a binomial logistic regression analysis on the data and did
>> the stepwise regression manually since the drop1(modelAAW, test =
>> "Chisq") command yielded no results in a span of more than 16
>> hours. The resulting regression models are nested in the maximal
>> model (modelAAW).
>> 
>> 
>> 
>> Then, I reached the model selection step where I have to interpret
>> the anova table below which has degrees of freedom of zero for some
>> models.
>> 
>> 
>> 
>> Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> 
>> AAWXI    49 2454.5 2738.8 -1178.2   2356.5
>> 
>> AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0
>> 1.0000
>> 
>> AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0
>> 1.0000
>> 
>> AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2
>> 0.2375
>> 
>> AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0
>> 1.0000
>> 
>> AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1
>> 0.3320
>> 
>> AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16
>> ***
>> 
>> AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16
>> ***
>> 
>> AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2
>> 0.1200
>> 
>> AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2
>> 0.8076
>> 
>> AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0
>> 1.0000
>> 
>> AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1
>> 0.8835
>> 
>> AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3
>> 0.5773
>> 
>> modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6
>> 0.4721
>> 
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> 
>> 
>> 
>> 
>> So many people that I have consulted tell me that I shouldn?t trust
>> a model of df=zero and advise that I should re-run the models using
>> the drop1 command or simplify the maximal model but in my case I
>> don?t know if I will ever get results especially that it took more
>> than 16 hours straight with no luck and I simplified the maximal
>> model to the best I could.
>> 
>> 
>> 
>> When I checked R documentation, I read that ?when given a sequence
>> of objects, anova tests the models against one another in the order
>> specified? based on the AIC value from the smallest to the largest.
>> However, there is  a warning that ?the comparison between two or
>> more models will only be valid if they are fitted to the same
>> dataset. This may be a problem if there are missing values and R's
>> default of na.action = na.omit is used?, so I?m assuming this is
>> the case with my models.
>> 
>> 
>> 
>> Now, should I select model AAWVIII since it has the least p-value
>> (and the least BIC value compared to AAWVII)?
>> 
>> 
>> 
>> The formulas of the two models in addition to AAWXI model are as
>> follows. The first two models are similar to each other except that
>> in AAWVIII the variable stimulus.presentation is deleted and in
>> model AAWXI the variable Listgp is deleted.
>> 
>> 
>> AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
>> context + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+
>> context:length+ context:freq.+
>> context:stimulus.presentation+length:stimulus.presentation+ 
>> length:age+ freq.:stimulus.presentation+ freq.:age+ 
>> stimulus.presentation:age+ + Listgp:stimulus.presentation + 
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality + 
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener)
>> , data = SBAAW, family = "binomial", control=glmerControl(optCtrl= 
>> list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> AAWVIII<-glmer(match~Listgp + vowel.quality + context + age +
>> Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
>> context:freq.+ 
>> context:stimulus.presentation+length:stimulus.presentation+
>> length:age+ freq.:stimulus.presentation+ freq.:age+
>> stimulus.presentation:age+ + Listgp:stimulus.presentation +
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener)
>> , data = SBAAW, family = "binomial",
>> control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+ 
>> Listgp:stimulus.presentation+ context:length+ context:freq.+ 
>> context:stimulus.presentation+length:stimulus.presentation+ 
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+
>> + Listgp:stimulus.presentation + Listgp:vowel.quality + 
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) + 
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW,
>> family = "binomial",
>> control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> I would appreciate your help with this.
>> 
>> 
>> 
>> -- Shadiya
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From pierces1 at msu.edu  Wed Aug 31 14:53:14 2016
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 31 Aug 2016 08:53:14 -0400
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <15eacffd-cdf4-75b8-d3d9-7ffff5e0bd19@gmail.com>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>	<000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
	<15eacffd-cdf4-75b8-d3d9-7ffff5e0bd19@gmail.com>
Message-ID: <000201d20386$a3571560$ea054020$@msu.edu>

I'd probably use Mplus (www.statmodel.com) for that, because it implements a very flexible generalized latent variable modeling framework that handles random effects via latent variables. It supports FIML estimation, plus a number of other estimators, including Bayesian estimation via MCMC. While expensive and not open source, it's probably the leading software package for people who do structural equation modeling; it's heavily used in the social sciences and educational research. 

Fortunately, the lavaan package in R replicates some of what Mplus can do. It may be capable of handling the problem, but I haven?t been keeping up with recent development of lavaan to see how much of the more recent Mplus features it is now supporting. 

However, if one goes the imputation route instead, there are several R packages that offer sophisticated support for imputation (Amelia, mi, mice, mitools, mix, pan, VIM, and likely more that I haven't seen/tried yet). Then you don?t need FIML estimation, just whatever normal modeling tools you already use. 


Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Tuesday, August 30, 2016 2:15 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Anova II table, df, drop1 and very complex regression models!


  Can you recommend a convenient full-information ML estimation method
that handles a wide range of cases (hopefully nested+crossed, GLMM +
LMM, etc, hopefully implemented in R) ?

  Ben Bolker


On 16-08-30 08:42 AM, Steven J. Pierce wrote:
> I completely agree that analyzing a stable dataset is essential, but
> I'd argue that selecting a subset containing only cases with no
> missing data is actually changing the nature of the population to
> which your inferences can be generalized. In effect it tacks "and who
> have no missing data" onto the definition of the target population.
> That is unlikely to be the population you really want to study. It
> may also dramatically reduce your sample size, thereby reducing power
> and precision of the estimates.
> 
> To preserve inference to the original intended population, solve the
> missing data problem with either some form of imputation or by using
> a full-information maximum likelihood estimation method that doesn?t
> throw out cases with missing data.
> 
> 
> Steven J. Pierce, Ph.D. Associate Director Center for Statistical
> Training & Consulting (CSTAT) Michigan State University
> 
> -----Original Message----- From: Thierry Onkelinx
> [mailto:thierry.onkelinx at inbo.be] Sent: Tuesday, August 30, 2016 3:30
> AM To: Shadiya Al Hashmi <saah500 at york.ac.uk> Cc:
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Anova II
> table, df, drop1 and very complex regression models!
> 
> Dear Shadiya,
> 
> You need to do the model selection on a stable dataset. Therefore
> you should create a subset which doesn't contain missing values in
> the covariates. Use this subset for model selection. Then you can
> refit the final model on the total dataset.
> 
> Best regards,
> 
> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> Research Institute for Nature and Forest team Biometrie &
> Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> 25 1070 Anderlecht Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher 
> The plural of anecdote is not data. ~ Roger Brinner The combination
> of some data and an aching desire for an answer does not ensure that
> a reasonable answer can be extracted from a given body of data. ~
> John Tukey
> 
> 2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
> 
>> Good morning,
>> 
>> 
>> I have complex data of 7 variables (6 treatment + 1 control [?age?
>> in the model below]) plus 18 interactions in a dataset of 2448
>> observations which have some missing values (NAs).  The maximal
>> model which I have simplified as per y hypothesis is as follows.
>> 
>> 
>> 
>> modelAAW<-glmer(match~Listgp + vowel.quality +
>> stimulus.presentation + context +length + age + freq.+
>> Listgp:context+ Listgp:length+ Listgp:freq.+ 
>> Listgp:stimulus.presentation+ Listgp:age+ context:length+
>> context:freq.+ context:stimulus.presentation+ context:age+
>> length:freq.+ length:stimulus.presentation+ length:age+
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+
>> Listgp:stimulus.presentation + Listgp:vowel.quality +
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) +
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW,
>> family = "binomial", control=glmerControl(optCtrl= 
>> list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> I ran a binomial logistic regression analysis on the data and did
>> the stepwise regression manually since the drop1(modelAAW, test =
>> "Chisq") command yielded no results in a span of more than 16
>> hours. The resulting regression models are nested in the maximal
>> model (modelAAW).
>> 
>> 
>> 
>> Then, I reached the model selection step where I have to interpret
>> the anova table below which has degrees of freedom of zero for some
>> models.
>> 
>> 
>> 
>> Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
>> 
>> AAWXI    49 2454.5 2738.8 -1178.2   2356.5
>> 
>> AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0
>> 1.0000
>> 
>> AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0
>> 1.0000
>> 
>> AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2
>> 0.2375
>> 
>> AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0
>> 1.0000
>> 
>> AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1
>> 0.3320
>> 
>> AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16
>> ***
>> 
>> AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16
>> ***
>> 
>> AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2
>> 0.1200
>> 
>> AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2
>> 0.8076
>> 
>> AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0
>> 1.0000
>> 
>> AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1
>> 0.8835
>> 
>> AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3
>> 0.5773
>> 
>> modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6
>> 0.4721
>> 
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> 
>> 
>> 
>> 
>> So many people that I have consulted tell me that I shouldn?t trust
>> a model of df=zero and advise that I should re-run the models using
>> the drop1 command or simplify the maximal model but in my case I
>> don?t know if I will ever get results especially that it took more
>> than 16 hours straight with no luck and I simplified the maximal
>> model to the best I could.
>> 
>> 
>> 
>> When I checked R documentation, I read that ?when given a sequence
>> of objects, anova tests the models against one another in the order
>> specified? based on the AIC value from the smallest to the largest.
>> However, there is  a warning that ?the comparison between two or
>> more models will only be valid if they are fitted to the same
>> dataset. This may be a problem if there are missing values and R's
>> default of na.action = na.omit is used?, so I?m assuming this is
>> the case with my models.
>> 
>> 
>> 
>> Now, should I select model AAWVIII since it has the least p-value
>> (and the least BIC value compared to AAWVII)?
>> 
>> 
>> 
>> The formulas of the two models in addition to AAWXI model are as
>> follows. The first two models are similar to each other except that
>> in AAWVIII the variable stimulus.presentation is deleted and in
>> model AAWXI the variable Listgp is deleted.
>> 
>> 
>> AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
>> context + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+
>> context:length+ context:freq.+
>> context:stimulus.presentation+length:stimulus.presentation+ 
>> length:age+ freq.:stimulus.presentation+ freq.:age+ 
>> stimulus.presentation:age+ + Listgp:stimulus.presentation + 
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality + 
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener)
>> , data = SBAAW, family = "binomial", control=glmerControl(optCtrl= 
>> list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> AAWVIII<-glmer(match~Listgp + vowel.quality + context + age +
>> Listgp:freq.+ Listgp:stimulus.presentation+ context:length+
>> context:freq.+ 
>> context:stimulus.presentation+length:stimulus.presentation+
>> length:age+ freq.:stimulus.presentation+ freq.:age+
>> stimulus.presentation:age+ + Listgp:stimulus.presentation +
>> Listgp:vowel.quality + stimulus.presentation:vowel.quality +
>> (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener)
>> , data = SBAAW, family = "binomial",
>> control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+ 
>> Listgp:stimulus.presentation+ context:length+ context:freq.+ 
>> context:stimulus.presentation+length:stimulus.presentation+ 
>> freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+
>> + Listgp:stimulus.presentation + Listgp:vowel.quality + 
>> stimulus.presentation:vowel.quality + (Listgp|stimulus) + 
>> (stimulus.presentation+vowel.quality|listener) , data = SBAAW,
>> family = "binomial",
>> control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
>> 
>> 
>> 
>> I would appreciate your help with this.
>> 
>> 
>> 
>> -- Shadiya
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From David.Duffy at qimrberghofer.edu.au  Thu Sep  1 05:45:23 2016
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Thu, 1 Sep 2016 03:45:23 +0000
Subject: [R-sig-ME] Anova II table, df,
 drop1 and very complex regression models!
In-Reply-To: <000201d20386$a3571560$ea054020$@msu.edu>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
	<000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
	<15eacffd-cdf4-75b8-d3d9-7ffff5e0bd19@gmail.com>,
	<000201d20386$a3571560$ea054020$@msu.edu>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D48A64A48B@EXCH06S.adqimr.ad.lan>

 Steven J. Pierce [pierces1 at msu.edu] wrote:

> I'd probably use Mplus (www.statmodel.com) for that, [...]
[snip]
> Fortunately, the lavaan package in R replicates some of what Mplus can do. 

Every couple of years, I mention OpenMx on this list:

http://openmx.psyc.virginia.edu/
https://cran.r-project.org/web/packages/OpenMx/index.html

I don't know exactly how much of Mplus's functionality it provides, but suspect it would be close to 100%.

As to the OP's question, we don't know how much data is actually missing, or what pattern that takes. We also don't know why some of the fitted models differ by 0 d.f.  If we did impute the data 5 times, wouldn't that give us an 80 h run-time?

Cheers, David.





From pierces1 at msu.edu  Thu Sep  1 14:41:31 2016
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 1 Sep 2016 08:41:31 -0400
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D48A64A48B@EXCH06S.adqimr.ad.lan>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>	<000501d202bb$edb5f2f0$c921d8d0$@msu.edu>	<15eacffd-cdf4-75b8-d3d9-7ffff5e0bd19@gmail.com>,
	<000201d20386$a3571560$ea054020$@msu.edu>
	<4737E17E7C8C3C4A8B5C1CE5346371D48A64A48B@EXCH06S.adqimr.ad.lan>
Message-ID: <000001d2044e$2a8eaf80$7fac0e80$@msu.edu>

True, we don't know how much missing data there is in this particular case,
and of course analyzing multiple imputed datasets will take more
computational time than analyzing a single dataset (either complete or
incomplete). My point was only that using listwise deletion to reduce an
incomplete dataset to a complete one by discarding observations with missing
data on the variables involved in the analyses could be changing the nature
of the population to which one can legitimately generalize the results. 

If there is a trivial amount of missing data, that may not matter much
because it won't change the answer much (negligible bias). But with larger
amounts of missing data that difference may well be very important because
now you're likely working from a more biased sample (or we can describe it
as a sample that represents a different, more narrowly defined population).
Drawing conclusions about the original target population from a biased
sample is poor statistical and scientific practice. The number of people who
regularly do so despite the fact that solutions to such a problem exist
concerns me. 

I just wanted the original poster to consider the issues involved and assess
the amount of missing data before blindly using listwise deletion. 

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: David Duffy [mailto:David.Duffy at qimrberghofer.edu.au] 
Sent: Wednesday, August 31, 2016 11:45 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Anova II table, df, drop1 and very complex
regression models!

 Steven J. Pierce [pierces1 at msu.edu] wrote:

> I'd probably use Mplus (www.statmodel.com) for that, [...]
[snip]
> Fortunately, the lavaan package in R replicates some of what Mplus can do.


Every couple of years, I mention OpenMx on this list:

http://openmx.psyc.virginia.edu/
https://cran.r-project.org/web/packages/OpenMx/index.html

I don't know exactly how much of Mplus's functionality it provides, but
suspect it would be close to 100%.

As to the OP's question, we don't know how much data is actually missing, or
what pattern that takes. We also don't know why some of the fitted models
differ by 0 d.f.  If we did impute the data 5 times, wouldn't that give us
an 80 h run-time?

Cheers, David.


From saah500 at york.ac.uk  Fri Sep  2 18:58:07 2016
From: saah500 at york.ac.uk (Shadiya Al Hashmi)
Date: Fri, 2 Sep 2016 19:58:07 +0300
Subject: [R-sig-ME] Anova II table, df,
	drop1 and very complex regression models!
In-Reply-To: <000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
References: <CACrevp=B0uderKhKr00ndF7dAcFAdbRRNvL9OAG=N_oji=-Grg@mail.gmail.com>
	<CAJuCY5ycQVzXzZa8R8OZgHvNFbUQd-tZd_2FyxEjWaaimK=SOQ@mail.gmail.com>
	<000501d202bb$edb5f2f0$c921d8d0$@msu.edu>
Message-ID: <CACrevpmRgRKf2aO_YwL_qq1OUo4BrZEp0sp1ZFuQ19LG-rW8hQ@mail.gmail.com>

Thanks Steven for pointing that out.  If I read Thierry correctly, he
suggested that after selecting the model using the subset with no NA
values, then to refit the final model on the original dataset with NAs
(Thierry, kindly correct if I got you wrong).

So, I actually ran two parallel R sessions, one with the NAs and one
without and the results were the same. However, this is probably the case
here since I have only one cell with an NA value, so this wouldn't affect
the results anyway.

I also found out that the dropterm command in the MASS package worked well
with my data, so I used it in selecting my stepwise models.

Thanks again Steven and thanks to you too Thierry!

Best wishes,

Shadiya


On 30 August 2016 at 15:42, Steven J. Pierce <pierces1 at msu.edu> wrote:

> I completely agree that analyzing a stable dataset is essential, but I'd
> argue that selecting a subset containing only cases with no missing data is
> actually changing the nature of the population to which your inferences can
> be generalized. In effect it tacks "and who have no missing data" onto the
> definition of the target population. That is unlikely to be the population
> you really want to study. It may also dramatically reduce your sample size,
> thereby reducing power and precision of the estimates.
>
> To preserve inference to the original intended population, solve the
> missing data problem with either some form of imputation or by using a
> full-information maximum likelihood estimation method that doesn?t throw
> out cases with missing data.
>
>
> Steven J. Pierce, Ph.D.
> Associate Director
> Center for Statistical Training & Consulting (CSTAT)
> Michigan State University
>
> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Tuesday, August 30, 2016 3:30 AM
> To: Shadiya Al Hashmi <saah500 at york.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Anova II table, df, drop1 and very complex
> regression models!
>
> Dear Shadiya,
>
> You need to do the model selection on a stable dataset. Therefore you
> should create a subset which doesn't contain missing values in the
> covariates. Use this subset for model selection. Then you can refit the
> final model on the total dataset.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-08-30 7:23 GMT+02:00 Shadiya Al Hashmi <saah500 at york.ac.uk>:
>
> > Good morning,
> >
> >
> > I have complex data of 7 variables (6 treatment + 1 control [?age? in the
> > model below]) plus 18 interactions in a dataset of 2448 observations
> which
> > have some missing values (NAs).  The maximal model which I have
> simplified
> > as per y hypothesis is as follows.
> >
> >
> >
> > modelAAW<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
> > context +length + age + freq.+ Listgp:context+ Listgp:length+
> Listgp:freq.+
> > Listgp:stimulus.presentation+ Listgp:age+ context:length+ context:freq.+
> > context:stimulus.presentation+ context:age+ length:freq.+
> > length:stimulus.presentation+ length:age+ freq.:stimulus.presentation+
> > freq.:age+ stimulus.presentation:age+  Listgp:stimulus.presentation +
> > Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> > (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) ,
> data
> > =
> > SBAAW, family = "binomial", control=glmerControl(optCtrl=
> > list(maxfun=2e5)),
> > nAGQ =1)
> >
> >
> >
> > I ran a binomial logistic regression analysis on the data and did the
> > stepwise regression manually since the drop1(modelAAW, test = "Chisq")
> > command yielded no results in a span of more than 16 hours. The resulting
> > regression models are nested in the maximal model (modelAAW).
> >
> >
> >
> > Then, I reached the model selection step where I have to interpret the
> > anova table below which has degrees of freedom of zero for some models.
> >
> >
> >
> >          Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> >
> > AAWXI    49 2454.5 2738.8 -1178.2   2356.5
> >
> > AAWXII   49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
> >
> > AAWXIII  49 2456.4 2740.8 -1179.2   2358.4 0.0000      0     1.0000
> >
> > AAWIX    51 2457.6 2753.5 -1177.8   2355.6 2.8749      2     0.2375
> >
> > AAWX     51 2457.6 2753.5 -1177.8   2355.6 0.0000      0     1.0000
> >
> > AAWVI    52 2458.6 2760.4 -1177.3   2354.6 0.9410      1     0.3320
> >
> > AAWVII   52 2458.6 2760.4 -1177.3   2354.6 0.0075      0     <2e-16 ***
> >
> > AAWVIII  52 2458.6 2760.3 -1177.3   2354.6 0.0094      0     <2e-16 ***
> >
> > AAWV     54 2458.4 2771.7 -1175.2   2350.4 4.2412      2     0.1200
> >
> > AAWIII   56 2461.9 2786.9 -1175.0   2349.9 0.4275      2     0.8076
> >
> > AAWIV    56 2461.9 2786.9 -1175.0   2349.9 0.0000      0     1.0000
> >
> > AAWII    57 2463.9 2794.7 -1175.0   2349.9 0.0215      1     0.8835
> >
> > AAWI     60 2467.9 2816.1 -1174.0   2347.9 1.9763      3     0.5773
> >
> > modelAAW 66 2474.4 2857.3 -1171.2   2342.4 5.5778      6     0.4721
> >
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> >
> >
> >
> > So many people that I have consulted tell me that I shouldn?t trust a
> model
> > of df=zero and advise that I should re-run the models using the drop1
> > command or simplify the maximal model but in my case I don?t know if I
> will
> > ever get results especially that it took more than 16 hours straight with
> > no luck and I simplified the maximal model to the best I could.
> >
> >
> >
> > When I checked R documentation, I read that ?when given a sequence of
> > objects, anova tests the models against one another in the order
> specified?
> > based on the AIC value from the smallest to the largest.  However, there
> > is  a warning that ?the comparison between two or more models will only
> be
> > valid if they are fitted to the same dataset. This may be a problem if
> > there are missing values and R's default of na.action = na.omit is used?,
> > so I?m assuming this is the case with my models.
> >
> >
> >
> > Now, should I select model AAWVIII since it has the least p-value (and
> the
> > least BIC value compared to AAWVII)?
> >
> >
> >
> > The formulas of the two models in addition to AAWXI model are as follows.
> > The first two models are similar to each other except that in AAWVIII the
> > variable stimulus.presentation is deleted and in model AAWXI the variable
> > Listgp is deleted.
> >
> >
> > AAWVI<-glmer(match~Listgp + vowel.quality + stimulus.presentation +
> context
> > + age + freq.+ Listgp:freq.+ Listgp:stimulus.presentation+
> context:length+
> > context:freq.+ context:stimulus.presentation+
> length:stimulus.presentation+
> > length:age+ freq.:stimulus.presentation+ freq.:age+
> > stimulus.presentation:age+ + Listgp:stimulus.presentation +
> > Listgp:vowel.quality + stimulus.presentation:vowel.quality +
> > (Listgp|stimulus) + (stimulus.presentation+vowel.quality|listener) ,
> data
> > =
> > SBAAW, family = "binomial", control=glmerControl(optCtrl=
> > list(maxfun=2e5)),
> > nAGQ =1)
> >
> >
> >
> > AAWVIII<-glmer(match~Listgp + vowel.quality + context + age +
> Listgp:freq.+
> > Listgp:stimulus.presentation+ context:length+ context:freq.+
> > context:stimulus.presentation+length:stimulus.presentation+ length:age+
> > freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> > Listgp:stimulus.presentation + Listgp:vowel.quality +
> > stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> > (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> > "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
> >
> >
> >
> > AAWXI<-glmer(match~vowel.quality + context + age + Listgp:freq.+
> > Listgp:stimulus.presentation+ context:length+ context:freq.+
> > context:stimulus.presentation+length:stimulus.presentation+
> > freq.:stimulus.presentation+ freq.:age+ stimulus.presentation:age+ +
> > Listgp:stimulus.presentation + Listgp:vowel.quality +
> > stimulus.presentation:vowel.quality + (Listgp|stimulus) +
> > (stimulus.presentation+vowel.quality|listener) , data = SBAAW, family =
> > "binomial", control=glmerControl(optCtrl=list(maxfun=2e5)), nAGQ =1)
> >
> >
> >
> > I would appreciate your help with this.
> >
> >
> >
> > --
> > Shadiya
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
>
>

	[[alternative HTML version deleted]]


From longy213 at 163.com  Fri Sep  2 20:18:15 2016
From: longy213 at 163.com (Gu Hao)
Date: Sat, 3 Sep 2016 02:18:15 +0800 (CST)
Subject: [R-sig-ME] a question of conducting contrast in lme4 (not pairwise
	contrast)
Message-ID: <56e07c0d.12d.156ec1f63d9.Coremail.longy213@163.com>

Hello,

I am trying to do some contrasts using a mixed model, but don?t know how to use it in lme4. I've done the multiple contrast, but I believe the power of this method is lower than ideal. I think contrast in lme4 would be a better option. I searched the question on stackoverflow and found one post. However, the question asked wasn't our situation. 

In our case, there are five treatments. Let?s call them AA, BB, CC, DD, and EE.

I have the following hypotheses:

the response to AA will be higher than the average of BB, CC and DD.
the response to AA will be higher than EE
the average response to BB, CC and DD will be higher than EE.

The model is being run in lme4 as a mixed model:

response (binomial, 0 or 1) ~ treatment (the 5 levels above) + (1|tape) + (1|round) + (1|location).
Do anybody know how to code this?
Please kindly find the data in the attachment.

With thanks and best wishes,

Hao

--

??(GU HAO),
????, ???????????????????????,????????100????????519?? ???530005.

Research Associate, Behavioral and Community Ecology, Conservation Biology, Office 519, College of Forestry, Guangxi University,No. 100 Daxue Road, Nanning, Guangxi 530005, People?s Republic of China 

E-mail: longy213 at 163.com or guhao at xtbg.org.cn ; Cell phone: (+86) 18288055414; Lab Web: www.animal-ecology-guangxi.com; My Page:https://cn.linkedin.com/pub/hao-gu/80/95/9a3

From bbolker at gmail.com  Fri Sep  2 20:47:50 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Sep 2016 14:47:50 -0400
Subject: [R-sig-ME] a question of conducting contrast in lme4 (not
 pairwise contrast)
In-Reply-To: <56e07c0d.12d.156ec1f63d9.Coremail.longy213@163.com>
References: <56e07c0d.12d.156ec1f63d9.Coremail.longy213@163.com>
Message-ID: <49625e27-509d-dfde-2d80-6f78926ab3de@gmail.com>



On 16-09-02 02:18 PM, Gu Hao wrote:
> Hello,
> 
> I am trying to do some contrasts using a mixed model, but don?t know
> how to use it in lme4. I've done the multiple contrast, but I believe
> the power of this method is lower than ideal. I think contrast in
> lme4 would be a better option. I searched the question on
> stackoverflow and found one post. However, the question asked wasn't
> our situation.
> 
> In our case, there are five treatments. Let?s call them AA, BB, CC,
> DD, and EE.
> 
> I have the following hypotheses:
> 
> the response to AA will be higher than the average of BB, CC and DD. 
> the response to AA will be higher than EE the average response to BB,
> CC and DD will be higher than EE.

Some notes on linear contrasts:

http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.Rnw
http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf

The three contrasts you've set up are collinear: let's code them as

   c1 = c(1, -1/3, -1/3, -1/3,  0)  ## AA vs (BB,CC,DD)
   c2 = c(1,      0,      0,      0, -1) ## AA vs EE
   c3 = c(0,  1/3,   1/3,  1/3, -1) ## (BB,CC,DD) vs EE

then you can see that c1 + c3 is equal to c2.  Therefore, you can't use
these three contrasts as part of a full set of 5 contrasts that span the
space of possibilities.

  Before I saw that you said you've already tried multcomp I wrote the
following down; it might be useful to someone else.
  Adapted from the examples in ?multcomp::glht


 z <- gl(5,10,labels=LETTERS[1:5])
y <- rnorm(50)
library(multcomp)

K <- rbind("A - BCD" = c( 1, -1/3, -1/3, -1/3,  0),
           "A - E" =   c( 1,    0,    0,    0, -1),
           "BCD-E" =   c( 0,  1/3,  1/3,  1/3, -1))

m <- lm(y~z)
mc <- glht(m,
           linfct = mcp(z = K),
           alternative = "less")
summary(mc)

If you want to live dangerously I think

summary(mc,test=univariate())

will give you the unadjusted p-values ...



> 
> The model is being run in lme4 as a mixed model:
> 
> response (binomial, 0 or 1) ~ treatment (the 5 levels above) +
> (1|tape) + (1|round) + (1|location). Do anybody know how to code
> this? Please kindly find the data in the attachment.
> 
> With thanks and best wishes,
> 
> Hao
>


From ep311508 at ohio.edu  Fri Sep  2 21:15:57 2016
From: ep311508 at ohio.edu (Price, Emily)
Date: Fri, 2 Sep 2016 19:15:57 +0000
Subject: [R-sig-ME] a question of conducting contrast in lme4 (not
 pairwise contrast)
In-Reply-To: <49625e27-509d-dfde-2d80-6f78926ab3de@gmail.com>
References: <56e07c0d.12d.156ec1f63d9.Coremail.longy213@163.com>,
	<49625e27-509d-dfde-2d80-6f78926ab3de@gmail.com>
Message-ID: <BY1PR01MB12753DD5DAB2E7AA987EEA0FBAE50@BY1PR01MB1275.prod.exchangelabs.com>

Hi Dr. Bolker,


I am also working on a project with contrast codes.


In my project I would like to investigate all the pairwise comparisons between a categorical variable with four levels.  In the second handout (http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf)  you mention discussing all pairwise comparisons later.  Would you be willing to share the link for the handout with the pairwise comparisons?


Thank you!

Emily

STAT 4/6C03: notes, week 2, part 2 - McMaster University<http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf>
ms.mcmaster.ca
stat 4/6c03: notes, week 2, part 2 2 sensible not always completely compatible, ways, across add-on packages ?The bar (|) is used as a grouping variable in various ...


Emily A. Price, PhD

Educational Research and Evaluation
Patton College of Education
Ohio University
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Friday, September 2, 2016 1:47:50 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] a question of conducting contrast in lme4 (not pairwise contrast)



On 16-09-02 02:18 PM, Gu Hao wrote:
> Hello,
>
> I am trying to do some contrasts using a mixed model, but don?t know
> how to use it in lme4. I've done the multiple contrast, but I believe
> the power of this method is lower than ideal. I think contrast in
> lme4 would be a better option. I searched the question on
> stackoverflow and found one post. However, the question asked wasn't
> our situation.
>
> In our case, there are five treatments. Let?s call them AA, BB, CC,
> DD, and EE.
>
> I have the following hypotheses:
>
> the response to AA will be higher than the average of BB, CC and DD.
> the response to AA will be higher than EE the average response to BB,
> CC and DD will be higher than EE.

Some notes on linear contrasts:

http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.Rnw
http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf

The three contrasts you've set up are collinear: let's code them as

   c1 = c(1, -1/3, -1/3, -1/3,  0)  ## AA vs (BB,CC,DD)
   c2 = c(1,      0,      0,      0, -1) ## AA vs EE
   c3 = c(0,  1/3,   1/3,  1/3, -1) ## (BB,CC,DD) vs EE

then you can see that c1 + c3 is equal to c2.  Therefore, you can't use
these three contrasts as part of a full set of 5 contrasts that span the
space of possibilities.

  Before I saw that you said you've already tried multcomp I wrote the
following down; it might be useful to someone else.
  Adapted from the examples in ?multcomp::glht


 z <- gl(5,10,labels=LETTERS[1:5])
y <- rnorm(50)
library(multcomp)

K <- rbind("A - BCD" = c( 1, -1/3, -1/3, -1/3,  0),
           "A - E" =   c( 1,    0,    0,    0, -1),
           "BCD-E" =   c( 0,  1/3,  1/3,  1/3, -1))

m <- lm(y~z)
mc <- glht(m,
           linfct = mcp(z = K),
           alternative = "less")
summary(mc)

If you want to live dangerously I think

summary(mc,test=univariate())

will give you the unadjusted p-values ...



>
> The model is being run in lme4 as a mixed model:
>
> response (binomial, 0 or 1) ~ treatment (the 5 levels above) +
> (1|tape) + (1|round) + (1|location). Do anybody know how to code
> this? Please kindly find the data in the attachment.
>
> With thanks and best wishes,
>
> Hao
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep  2 22:35:49 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 2 Sep 2016 16:35:49 -0400
Subject: [R-sig-ME] a question of conducting contrast in lme4 (not
 pairwise contrast)
In-Reply-To: <BY1PR01MB12753DD5DAB2E7AA987EEA0FBAE50@BY1PR01MB1275.prod.exchangelabs.com>
References: <56e07c0d.12d.156ec1f63d9.Coremail.longy213@163.com>
	<49625e27-509d-dfde-2d80-6f78926ab3de@gmail.com>
	<BY1PR01MB12753DD5DAB2E7AA987EEA0FBAE50@BY1PR01MB1275.prod.exchangelabs.com>
Message-ID: <CABghstQgRCPgkiXsqa+YwMDda7g6+zkpEseY7WPo6wbffjz9Ow@mail.gmail.com>

I may never have gotten around to covering that stuff in the class, but the
recipe is pretty simple: just google "multcomp glht tukey".  The
stats.stackexchange postings that you'll find deal with slightly more
complicated situations: if you just want to do pairwise tests on a
fixed-effect categorical predictor at the population level you can just
follow the recipes in the multcomp documentation.

CrossValidated:

http://stats.stackexchange.com/questions/145765/post-hoc-testing-in-multcompglht-for-mixed-effects-models-lme4-with-interact

http://stats.stackexchange.com/questions/5250/multiple-comparisons-on-a-mixed-effects-model



On Fri, Sep 2, 2016 at 3:15 PM, Price, Emily <ep311508 at ohio.edu> wrote:

> Hi Dr. Bolker,
>
>
> I am also working on a project with contrast codes.
>
>
> In my project I would like to investigate all the pairwise comparisons
> between a categorical variable with four levels.  In the second handout (
> http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf)  you
> mention discussing all pairwise comparisons later.  Would you be willing to
> share the link for the handout with the pairwise comparisons?
>
>
> Thank you!
>
> Emily
> STAT 4/6C03: notes, week 2, part 2 - McMaster University
> <http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf>
> ms.mcmaster.ca
> stat 4/6c03: notes, week 2, part 2 2 sensible not always completely
> compatible, ways, across add-on packages ?The bar (|) is used as a grouping
> variable in various ...
>
> Emily A. Price, PhD
> Educational Research and Evaluation
> Patton College of Education
> Ohio University
> ------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Friday, September 2, 2016 1:47:50 PM
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] a question of conducting contrast in lme4 (not
> pairwise contrast)
>
>
>
> On 16-09-02 02:18 PM, Gu Hao wrote:
> > Hello,
> >
> > I am trying to do some contrasts using a mixed model, but don?t know
> > how to use it in lme4. I've done the multiple contrast, but I believe
> > the power of this method is lower than ideal. I think contrast in
> > lme4 would be a better option. I searched the question on
> > stackoverflow and found one post. However, the question asked wasn't
> > our situation.
> >
> > In our case, there are five treatments. Let?s call them AA, BB, CC,
> > DD, and EE.
> >
> > I have the following hypotheses:
> >
> > the response to AA will be higher than the average of BB, CC and DD.
> > the response to AA will be higher than EE the average response to BB,
> > CC and DD will be higher than EE.
>
> Some notes on linear contrasts:
>
> http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.Rnw
> http://ms.mcmaster.ca/~bolker/classes/s4c03/notes/week2B.pdf
>
> The three contrasts you've set up are collinear: let's code them as
>
>    c1 = c(1, -1/3, -1/3, -1/3,  0)  ## AA vs (BB,CC,DD)
>    c2 = c(1,      0,      0,      0, -1) ## AA vs EE
>    c3 = c(0,  1/3,   1/3,  1/3, -1) ## (BB,CC,DD) vs EE
>
> then you can see that c1 + c3 is equal to c2.  Therefore, you can't use
> these three contrasts as part of a full set of 5 contrasts that span the
> space of possibilities.
>
>   Before I saw that you said you've already tried multcomp I wrote the
> following down; it might be useful to someone else.
>   Adapted from the examples in ?multcomp::glht
>
>
>  z <- gl(5,10,labels=LETTERS[1:5])
> y <- rnorm(50)
> library(multcomp)
>
> K <- rbind("A - BCD" = c( 1, -1/3, -1/3, -1/3,  0),
>            "A - E" =   c( 1,    0,    0,    0, -1),
>            "BCD-E" =   c( 0,  1/3,  1/3,  1/3, -1))
>
> m <- lm(y~z)
> mc <- glht(m,
>            linfct = mcp(z = K),
>            alternative = "less")
> summary(mc)
>
> If you want to live dangerously I think
>
> summary(mc,test=univariate())
>
> will give you the unadjusted p-values ...
>
>
>
> >
> > The model is being run in lme4 as a mixed model:
> >
> > response (binomial, 0 or 1) ~ treatment (the 5 levels above) +
> > (1|tape) + (1|round) + (1|location). Do anybody know how to code
> > this? Please kindly find the data in the attachment.
> >
> > With thanks and best wishes,
> >
> > Hao
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From chun.chen at wur.nl  Mon Sep  5 10:08:40 2016
From: chun.chen at wur.nl (Chen, Chun)
Date: Mon, 5 Sep 2016 08:08:40 +0000
Subject: [R-sig-ME] =?windows-1252?q?_Does_the_=93non-independent=22_data_?=
 =?windows-1252?q?structure_defined_in_mixed_models_follow_the_=93independ?=
 =?windows-1252?q?ency=94_defined_by_probability_theory=3F?=
Message-ID: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>

Dear all,

I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.

>From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.

My questions are:

What?s the definition of the ?non-independent data? that is often referred in mixed modeling? Is it the same concept as ?independency? defined by probability theory, which is relevant by how the observations are selected, rather than how the observations look alike in the final sample

Thanks

Regards,
Chun

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Sep  5 20:51:13 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 5 Sep 2016 14:51:13 -0400
Subject: [R-sig-ME]
	=?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
	=?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cinde?=
	=?utf-8?q?pendency=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
Message-ID: <CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>

On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
> Dear all,
>
> I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.
>
> >From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
>
> My questions are:
>
> What?s the definition of the ?non-independent data? that is often referred in mixed modeling? Is it the same concept as ?independency? defined by probability theory, which is relevant by how the observations are selected, rather than how the observations look alike in the final sample

   (You say "questions" here, but there really seems to be only one
question here.)

  Yes, mixed modeling defines grouping variables based on
experimental/observational design.  That is, grouping variables are
identifiers that are believed *a priori* to be associated with
non-independence of observations with the same identifier values.

  Ben Bolker


From joaquin.aldabe at gmail.com  Mon Sep  5 21:53:55 2016
From: joaquin.aldabe at gmail.com (joaquin.aldabe at gmail.com)
Date: Mon, 5 Sep 2016 16:53:55 -0300
Subject: [R-sig-ME]
 =?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
 =?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cindependenc?=
 =?utf-8?q?y=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
Message-ID: <1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>

I have a related doubt. Do levels of a grouping variable have to be independent? Eg. Sites from where i take non independient samples?
Thanks in advanced
Joaqu?n

Enviado desde mi iPad

> El 5 set. 2016, a las 3:51 p.m., Ben Bolker <bbolker at gmail.com> escribi?:
> 
>> On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
>> Dear all,
>> 
>> I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.
>> 
>>> From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
>> 
>> My questions are:
>> 
>> What?s the definition of the ?non-independent data? that is often referred in mixed modeling? Is it the same concept as ?independency? defined by probability theory, which is relevant by how the observations are selected, rather than how the observations look alike in the final sample
> 
>   (You say "questions" here, but there really seems to be only one
> question here.)
> 
>  Yes, mixed modeling defines grouping variables based on
> experimental/observational design.  That is, grouping variables are
> identifiers that are believed *a priori* to be associated with
> non-independence of observations with the same identifier values.
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jdpo223 at g.uky.edu  Mon Sep  5 22:09:30 2016
From: jdpo223 at g.uky.edu (Poe, John)
Date: Mon, 5 Sep 2016 16:09:30 -0400
Subject: [R-sig-ME]
	=?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
	=?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cinde?=
	=?utf-8?q?pendency=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
	<1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>
Message-ID: <CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>

They are assumed to be independent across levels but you can deal with the
assumption by specifying the dependence as part of the model. You can add
in fixed effects or additional random effects for starters.

In practice having correlation across groups seems to distort the
distribution of the random effect causing some groups to be clustered. In
extreme cases the random effect can become multimodal. This doesn't seem to
matter much for linear models but it can badly damage generalized linear
models depending on how you approximate random effects.

On Sep 5, 2016 3:54 PM, <joaquin.aldabe at gmail.com> wrote:

> I have a related doubt. Do levels of a grouping variable have to be
> independent? Eg. Sites from where i take non independient samples?
> Thanks in advanced
> Joaqu?n
>
> Enviado desde mi iPad
>
> > El 5 set. 2016, a las 3:51 p.m., Ben Bolker <bbolker at gmail.com>
> escribi?:
> >
> >> On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
> >> Dear all,
> >>
> >> I am bit puzzled by definition of the ?nested data? or ?non-independent
> data? structure in the mixed model.
> >>
> >>> From the statistical point of view, independency is defined as the
> probabilities of selecting two observations are not influencing each other.
> In this case, if I design an experiment where I on purposely select two
> observations from the same group (or strata), then later on we can say
> these two observations are dependent. However, if I am doing a sampling
> with replacement and by coincidence I selected one observations twice (e.g.
> throw a dice twice and by coincidence we get both a ?6? each time). The
> probability of selecting these two observations are indeed not influencing
> each other and they are independent.
> >>
> >> My questions are:
> >>
> >> What?s the definition of the ?non-independent data? that is often
> referred in mixed modeling? Is it the same concept as ?independency?
> defined by probability theory, which is relevant by how the observations
> are selected, rather than how the observations look alike in the final
> sample
> >
> >   (You say "questions" here, but there really seems to be only one
> > question here.)
> >
> >  Yes, mixed modeling defines grouping variables based on
> > experimental/observational design.  That is, grouping variables are
> > identifiers that are believed *a priori* to be associated with
> > non-independence of observations with the same identifier values.
> >
> >  Ben Bolker
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Mon Sep  5 22:19:13 2016
From: joaquin.aldabe at gmail.com (joaquin.aldabe at gmail.com)
Date: Mon, 5 Sep 2016 17:19:13 -0300
Subject: [R-sig-ME]
 =?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
 =?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cindependenc?=
 =?utf-8?q?y=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
	<1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>
	<CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>
Message-ID: <42851F85-E547-438C-8AB3-57AEE17AC296@gmail.com>

Thankyou very much

Enviado desde mi iPad

> El 5 set. 2016, a las 5:09 p.m., Poe, John <jdpo223 at g.uky.edu> escribi?:
> 
> They are assumed to be independent across levels but you can deal with the assumption by specifying the dependence as part of the model. You can add in fixed effects or additional random effects for starters.
> 
> In practice having correlation across groups seems to distort the distribution of the random effect causing some groups to be clustered. In extreme cases the random effect can become multimodal. This doesn't seem to matter much for linear models but it can badly damage generalized linear models depending on how you approximate random effects.
> 
> 
>> On Sep 5, 2016 3:54 PM, <joaquin.aldabe at gmail.com> wrote:
>> I have a related doubt. Do levels of a grouping variable have to be independent? Eg. Sites from where i take non independient samples?
>> Thanks in advanced
>> Joaqu?n
>> 
>> Enviado desde mi iPad
>> 
>> > El 5 set. 2016, a las 3:51 p.m., Ben Bolker <bbolker at gmail.com> escribi?:
>> >
>> >> On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
>> >> Dear all,
>> >>
>> >> I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.
>> >>
>> >>> From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
>> >>
>> >> My questions are:
>> >>
>> >> What?s the definition of the ?non-independent data? that is often referred in mixed modeling? Is it the same concept as ?independency? defined by probability theory, which is relevant by how the observations are selected, rather than how the observations look alike in the final sample
>> >
>> >   (You say "questions" here, but there really seems to be only one
>> > question here.)
>> >
>> >  Yes, mixed modeling defines grouping variables based on
>> > experimental/observational design.  That is, grouping variables are
>> > identifiers that are believed *a priori* to be associated with
>> > non-independence of observations with the same identifier values.
>> >
>> >  Ben Bolker
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From David.Duffy at qimrberghofer.edu.au  Tue Sep  6 02:10:02 2016
From: David.Duffy at qimrberghofer.edu.au (David Duffy)
Date: Tue, 6 Sep 2016 00:10:02 +0000
Subject: [R-sig-ME]
 =?windows-1252?q?Does_the_=93non-independent=22_data_s?=
 =?windows-1252?q?tructure_defined_in_mixed_models_follow_the_=93independe?=
 =?windows-1252?q?ncy=94_defined_by_probability_theory=3F?=
In-Reply-To: <CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
	<1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>,
	<CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D48A64A90A@EXCH06S.adqimr.ad.lan>

> In practice having correlation across groups seems to distort the
> distribution of the random effect causing some groups to be clustered. In
> extreme cases the random effect can become multimodal.

Further to this, there are nonparametric maximum likelihood (and Bayesian) mixed models that might be useful for this kind of situation -  the distribution of the random effects is modelled as a finite mixture (of eg normals) to be estimated. The npmlreg package implements Murray Aitkin's approach.

From joaquin.aldabe at gmail.com  Tue Sep  6 03:28:58 2016
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 5 Sep 2016 22:28:58 -0300
Subject: [R-sig-ME]
	=?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
	=?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cinde?=
	=?utf-8?q?pendency=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D48A64A90A@EXCH06S.adqimr.ad.lan>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<CABghstRaQ4iVxdCf0aPHSK9C4y_sQUKm-snEvJQS83xFYaLAbQ@mail.gmail.com>
	<1A5E8735-83C1-4AAF-9B96-EE9143F4D307@gmail.com>
	<CAFW8ByqR9WrjeDv6RuxiV2jWNP=PK4GZ3kzve3=mzePFu2zCXg@mail.gmail.com>
	<4737E17E7C8C3C4A8B5C1CE5346371D48A64A90A@EXCH06S.adqimr.ad.lan>
Message-ID: <CAMM93=JSpW1zO-Ss_Ocd=ivBY5zT8Qdv7LVAmvvC3o=9gScARQ@mail.gmail.com>

Thankyou very much David!

2016-09-05 21:10 GMT-03:00 David Duffy <David.Duffy at qimrberghofer.edu.au>:

> > In practice having correlation across groups seems to distort the
> > distribution of the random effect causing some groups to be clustered. In
> > extreme cases the random effect can become multimodal.
>
> Further to this, there are nonparametric maximum likelihood (and Bayesian)
> mixed models that might be useful for this kind of situation -  the
> distribution of the random effects is modelled as a finite mixture (of eg
> normals) to be estimated. The npmlreg package implements Murray Aitkin's
> approach.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From chun.chen at wur.nl  Tue Sep  6 09:41:56 2016
From: chun.chen at wur.nl (Chen, Chun)
Date: Tue, 6 Sep 2016 07:41:56 +0000
Subject: [R-sig-ME]
 =?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
 =?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cindependenc?=
 =?utf-8?q?y=E2=80=9D_defined_by_probability_theory=3F?=
Message-ID: <86b795a5dfa241da9956ac2996e5ccdd@scomp5296.wurnet.nl>

Thank you Ben for the answer. Now I am wondering:

1) If I happened to have a grouping variable that is not by design, for instance my randomly selected observations turned out to show some site related characteristics, is it sound to apply a mixed model including site as random intercept? In practice, it is pretty common to use site as a fixed effect in the regression analysis (i.e. to detect the main effect after adjusting site effect), even site is not a factor in the experimental/observational design.

2) If site can be used as a random intercept, what is the exact criteria for non-independence (i.e. nested structure ) in the context of applying a mixed model? Not the same as what you defined below?

3) In case site can not be used as random intercept, but can be used as a fixed factor: I assume that if a categorical variable can be modeled as a fixed effect, it can also be modeled as random effect (both are trying to estimate an  effect, but using different ways). Additionally, there is no limitation about on what condition we can  use a variable as fixed factor during regression (you can apply any variable as an fixed effect if you hypothesie the effect, no non-independence requirements). Why do we need non-independence condition for the random factors?

Thanks

Regards,
Chun

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: maandag, september 05, 2016 20:51
To: Chen, Chun
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Does the ?non-independent" data structure defined in mixed models follow the ?independency? defined by probability theory?

On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
> Dear all,
>
> I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.
>
> >From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
>
> My questions are:
>
> What?s the definition of the ?non-independent data? that is often 
> referred in mixed modeling? Is it the same concept as ?independency? 
> defined by probability theory, which is relevant by how the 
> observations are selected, rather than how the observations look alike 
> in the final sample

   (You say "questions" here, but there really seems to be only one question here.)

  Yes, mixed modeling defines grouping variables based on experimental/observational design.  That is, grouping variables are identifiers that are believed *a priori* to be associated with non-independence of observations with the same identifier values.

  Ben Bolker

From francois.rousset at umontpellier.fr  Wed Sep  7 14:27:31 2016
From: francois.rousset at umontpellier.fr (=?UTF-8?Q?Fran=c3=a7ois_Rousset?=)
Date: Wed, 7 Sep 2016 14:27:31 +0200
Subject: [R-sig-ME]
 =?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
 =?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cindependenc?=
 =?utf-8?q?y=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
Message-ID: <d951d08d-14f5-0e65-aa06-b2488dff7efc@umontpellier.fr>

Dear all,

I am a bit surprized by the previous follow-up to this question:

Le 05/09/2016 ? 10:08, Chen, Chun a ?crit :
> Dear all,
>
> I am bit puzzled by definition of the ?nested data? or ?non-independent data? structure in the mixed model.
>
> >From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a ?6? each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
the assumptions are those of the model being fitted. Thus is a mixed 
model one typically assumes that the _residual errors_ for each 
observation are independent.
The "observations" are not independent, but the model does not assume 
that the "observations" are independent in any elevant stochastic sense, 
only that the residuals are.

I don't see independence in probability as being defined as "not 
influencing each other". In practice independence also means "not 
affected by a common factor". A formal definition of independence of 
several events  is that the joint probability of these events is the 
product of probabilities of each event : see e.g. Feller 1950, p.125. In 
the above example of sampling with replacement, a single draw of a 
residual error affects two response values, so according to the formal 
definition, the two residuals are not independent. So sampling with 
replacement violates the assumptions of independence of residuals.

F.R.
>
> My questions are:
>
> What?s the definition of the ?non-independent data? that is often referred in mixed modeling? Is it the same concept as ?independency? defined by probability theory, which is relevant by how the observations are selected, rather than how the observations look alike in the final sample
>
> Thanks
>
> Regards,
> Chun
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bates at stat.wisc.edu  Fri Sep  9 15:50:13 2016
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 09 Sep 2016 13:50:13 +0000
Subject: [R-sig-ME] Experience with PyMC3 Bambi package?
Message-ID: <CAO7JsnRmz0aaEZVwi3wD2tvaurwanpGCDh+3AO1fuh1gWOuHtw@mail.gmail.com>

Has anyone tried https://github.com/bambinos/bambi for Bayesian analysis of
mixed-effects models?  It looks quite interesting.

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Fri Sep  9 17:22:42 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Fri, 9 Sep 2016 15:22:42 +0000
Subject: [R-sig-ME] Experience with PyMC3 Bambi package?
In-Reply-To: <CAO7JsnRmz0aaEZVwi3wD2tvaurwanpGCDh+3AO1fuh1gWOuHtw@mail.gmail.com>
References: <CAO7JsnRmz0aaEZVwi3wD2tvaurwanpGCDh+3AO1fuh1gWOuHtw@mail.gmail.com>
Message-ID: <1473434560.20792.8.camel@unisa.edu.au>

I haven't tried Bambi just yet, but the PyMC3 package upon which it is
built has been really quite nice in my experience. The only reason why
I wasn't using PyMC3 more extensively is that it was a pain to
construct the model for complicated GLM(M)s and they only had
convenience functions for constructing non-mixed GLMs.

I will be taking a look soon and will report back!

Best,
Phillip?

On Fri, 2016-09-09 at 13:50 +0000, Douglas Bates wrote:
> Has anyone tried https://github.com/bambinos/bambi for Bayesian
> analysis of
> mixed-effects models???It looks quite interesting.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From jake.a.westfall at gmail.com  Fri Sep  9 17:46:44 2016
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Fri, 9 Sep 2016 10:46:44 -0500
Subject: [R-sig-ME] Experience with PyMC3 Bambi package?
In-Reply-To: <1473434560.20792.8.camel@unisa.edu.au>
References: <CAO7JsnRmz0aaEZVwi3wD2tvaurwanpGCDh+3AO1fuh1gWOuHtw@mail.gmail.com>
	<1473434560.20792.8.camel@unisa.edu.au>
Message-ID: <CAE9_Wg5ThvyHtGYGGVrgwwo_h=-=zgzTDKTdBWL9bzHhRUcN_w@mail.gmail.com>

Tal and I would love to hear thoughts and reactions from anyone and
everyone!

Jake

On Fri, Sep 9, 2016 at 10:22 AM, Phillip Alday <Phillip.Alday at unisa.edu.au>
wrote:

> I haven't tried Bambi just yet, but the PyMC3 package upon which it is
> built has been really quite nice in my experience. The only reason why
> I wasn't using PyMC3 more extensively is that it was a pain to
> construct the model for complicated GLM(M)s and they only had
> convenience functions for constructing non-mixed GLMs.
>
> I will be taking a look soon and will report back!
>
> Best,
> Phillip
>
> On Fri, 2016-09-09 at 13:50 +0000, Douglas Bates wrote:
> > Has anyone tried https://github.com/bambinos/bambi for Bayesian
> > analysis of
> > mixed-effects models?  It looks quite interesting.
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jasnie111 at gmail.com  Fri Sep  9 18:47:22 2016
From: jasnie111 at gmail.com (jas ni)
Date: Fri, 9 Sep 2016 17:47:22 +0100
Subject: [R-sig-ME] Handling missing data through Gaussian mixture model
Message-ID: <CACEyfM8fhsVDdHg7miAMQ8-X126+4M5Oaii0HBLAN8d+hEUFBA@mail.gmail.com>

Dear all,

I'm currently trying to write the missing data imputation code through
Gaussian mixture model. My current reference as provided in the attachment
or you can reach at this url:
http://www.sciencedirect.com/science/article/pii/S0167947306003707

This is the code for e-step and m-step through the Gaussian mixture model:

data(faithful);
library(mvtnorm); # using multivariate normal package (need to install this
but easy .... )
N = dim(faithful)[1]; # number of sample points
X = faithful[,1:2]; # the data matrix
alpha1 = alpha2 = .5; # these are our initial class probability
m1 = c(2,90);   # initial means, chosen to be bad
m2 = c(4,50);
Sigma1 = Sigma2 = diag(c(var(X[,1]),var(X[,2])));   # initial covariance
matrices computed from entire data

e_step<-function(x,m1,m2,Sigma1,Sigma2,alpha){

  x_missing<-x
  x_missing$eruptions[1:10] <- NA
  x_missing$waiting[10:20] <- NA
  x_missing$eruptions[is.na(x_missing$eruptions)] =
mean(x_missing$eruptions, na.rm=TRUE)
  x_missing$waiting[is.na(x_missing$waiting)] = mean(x_missing$waiting,
na.rm=TRUE)
  x<-x_missing

  comp1.prod <- dmvnorm(x, m1, Sigma1) * alpha[1]
  comp2.prod <- dmvnorm(x, m2, Sigma2) * alpha[2]
  sum.of.comps <- comp1.prod + comp2.prod
  comp1.post <- comp1.prod / sum.of.comps
  comp2.post <- comp2.prod / sum.of.comps
  ll = sum(log(sum.of.comps))

  list("ll" = ll,
       "posterior.df" = cbind(comp1.post, comp2.post))
}

m_step<-function(x,posterior.df){
  comp1.n <- sum(posterior.df[, 1])
  comp2.n <- sum(posterior.df[, 2])

  comp1.alpha <- comp1.n / length(x)
  comp2.alpha <- comp2.n / length(x)

  comp1.mu <- colSums(posterior.df[, 1]*X)/comp1.n
  comp2.mu <- colSums(posterior.df[, 2]*X)/comp2.n

  resp1=posterior.df[, 1]
  resp2=posterior.df[, 2]
  acc1 = acc2 = matrix(0,nrow=2,ncol=2);
  Y = as.matrix(x);
  for (n in 1:N) {
    acc1 = acc1 +  resp1[n] * ((Y[n,] - m1)  %*% t(Y[n,]-m1));
    acc2 = acc2 + resp2[n] * ((Y[n,] - m2)  %*% t(Y[n,]-m2));
  }
  Sigma1 = acc1/sum(resp1); Sigma2 = acc2/sum(resp1);

  list("m1" = comp1.mu,
       "m2"   = comp2.mu,
       "Sigma1" = Sigma1,
       "Sigma2" = Sigma2,
       "alpha" = c(comp1.alpha, comp2.alpha))
}

I have noticed that mean imputation part in the e-step is not in right way.
Therefore i want to apply the random draw imputation as mentioned in the
paper at page number 5308.

Can anybody here guide me on how to write the random draw imputation in R?
Thank you in advance
-Jas

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Fri Sep  9 20:34:07 2016
From: jdpo223 at g.uky.edu (Poe, John)
Date: Fri, 9 Sep 2016 14:34:07 -0400
Subject: [R-sig-ME]
	=?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
	=?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cinde?=
	=?utf-8?q?pendency=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <86b795a5dfa241da9956ac2996e5ccdd@scomp5296.wurnet.nl>
References: <86b795a5dfa241da9956ac2996e5ccdd@scomp5296.wurnet.nl>
Message-ID: <CAFW8Byp_JeYYrwz5BNWump9UMCizZhbm6W=NsSZq69tENnywbQ@mail.gmail.com>

On point 1, depending on the number of sites yes you can use a random
effect instead of a fixed effect to account for omitted variables like the
site selection mechanism.


If you are doing this to control for site effects that are essentially
contamination and of no theoretical interest, then using fixed effects for
site is the easiest approach for a linear model. In most generalized linear
models you can?t effectively difference the fixed effects out of the data
in the same way and including them in the model will result in incidental
parameters bias with as few as ten dummy variables.


If you are interested in understanding how the site related latent variable
might work, then you should use a mixed effects model and be sure to
include group averages for your lower level variables so that you can
interpret the within group and between group effects separately.  You may
also need to model random coefficients because decomposing the variables
doesn?t always completely orthogonalize the within group versions of the
variables and the random effect.


With any random effect you are assuming that it is uncorrelated with fixed
components in the model which means you are modeling the relationship
between the random effect and all of your independent variables regardless
of what you do. You can either take the fixed effects/group indicator
variables approach or the mixed effects modeling approach but in both cases
doing it properly means you have accounted for lack of independence across
variables and within sites.

On Tue, Sep 6, 2016 at 3:41 AM, Chen, Chun <chun.chen at wur.nl> wrote:

> Thank you Ben for the answer. Now I am wondering:
>
> 1) If I happened to have a grouping variable that is not by design, for
> instance my randomly selected observations turned out to show some site
> related characteristics, is it sound to apply a mixed model including site
> as random intercept? In practice, it is pretty common to use site as a
> fixed effect in the regression analysis (i.e. to detect the main effect
> after adjusting site effect), even site is not a factor in the
> experimental/observational design.
>
> 2) If site can be used as a random intercept, what is the exact criteria
> for non-independence (i.e. nested structure ) in the context of applying a
> mixed model? Not the same as what you defined below?
>
> 3) In case site can not be used as random intercept, but can be used as a
> fixed factor: I assume that if a categorical variable can be modeled as a
> fixed effect, it can also be modeled as random effect (both are trying to
> estimate an  effect, but using different ways). Additionally, there is no
> limitation about on what condition we can  use a variable as fixed factor
> during regression (you can apply any variable as an fixed effect if you
> hypothesie the effect, no non-independence requirements). Why do we need
> non-independence condition for the random factors?
>
> Thanks
>
> Regards,
> Chun
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: maandag, september 05, 2016 20:51
> To: Chen, Chun
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Does the ?non-independent" data structure defined
> in mixed models follow the ?independency? defined by probability theory?
>
> On Mon, Sep 5, 2016 at 4:08 AM, Chen, Chun <chun.chen at wur.nl> wrote:
> > Dear all,
> >
> > I am bit puzzled by definition of the ?nested data? or ?non-independent
> data? structure in the mixed model.
> >
> > >From the statistical point of view, independency is defined as the
> probabilities of selecting two observations are not influencing each other.
> In this case, if I design an experiment where I on purposely select two
> observations from the same group (or strata), then later on we can say
> these two observations are dependent. However, if I am doing a sampling
> with replacement and by coincidence I selected one observations twice (e.g.
> throw a dice twice and by coincidence we get both a ?6? each time). The
> probability of selecting these two observations are indeed not influencing
> each other and they are independent.
> >
> > My questions are:
> >
> > What?s the definition of the ?non-independent data? that is often
> > referred in mixed modeling? Is it the same concept as ?independency?
> > defined by probability theory, which is relevant by how the
> > observations are selected, rather than how the observations look alike
> > in the final sample
>
>    (You say "questions" here, but there really seems to be only one
> question here.)
>
>   Yes, mixed modeling defines grouping variables based on
> experimental/observational design.  That is, grouping variables are
> identifiers that are believed *a priori* to be associated with
> non-independence of observations with the same identifier values.
>
>   Ben Bolker
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 




Thanks,
John


John Poe
Doctoral Candidate
Department of Political Science
Research Methodologist
UK Center for Public Health Services & Systems Research
University of Kentucky
111 Washington Avenue, Room 203a
Lexington, KY 40536
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From kerry.samerotte at gmail.com  Sun Sep 11 05:00:32 2016
From: kerry.samerotte at gmail.com (Kerry Samerotte)
Date: Sun, 11 Sep 2016 03:00:32 +0000
Subject: [R-sig-ME] MCMCglmm predict fails on MCMCglmm output generated
	11/15/15
Message-ID: <CAPD5L3B2v1x5i+CVyMtoKCLaeSz_=VFXm_BEQjZqhLbZYjUXsQ@mail.gmail.com>

Hi mixed modelers,

I could really use some help with the MCMCglmm predict function. It works
for me on MCMCglmm output that I generated recently, but fails on MCMCglmm
output that I generated in November of 2015. In the past, the predict
function worked just fine on the 11/15 data, but now it fails with the
following error:

Error in if (!grepl("hu|zi|za|multinomial", object$Residual$family[i])) { :
argument is of length zero

Here is the model I run in MCMCglmm:
model = MCMCglmm(phen ~ condition, random = ~us(condition):strain,
rcov=~idh(condition):units, data=data, prior = prior_PE, thin = 15, nitt =
30000, burnin = 6000, verbose = FALSE, pr = TRUE)

Then I simply run:
predictions <- predict(model, marginal = NULL)

And it fails with the above error. This also fails with the same error:
predictions <- predict(model)

Help is appreciated!
Thank you
Kerry

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Sep 12 18:08:21 2016
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 12 Sep 2016 17:08:21 +0100
Subject: [R-sig-ME] MCMCglmm predict fails on MCMCglmm output generated
 11/15/15
In-Reply-To: <CAPD5L3B2v1x5i+CVyMtoKCLaeSz_=VFXm_BEQjZqhLbZYjUXsQ@mail.gmail.com>
References: <CAPD5L3B2v1x5i+CVyMtoKCLaeSz_=VFXm_BEQjZqhLbZYjUXsQ@mail.gmail.com>
Message-ID: <17a5babf-0fd4-5cb0-b6cd-b29e4e1031bb@ed.ac.uk>

Hi,

I had to change how the predict function works in order to accommodate multivariate responses coming from different distributions. If you use:

model$Residual$family<-rep("gaussian", nrow(model$X))

it should run I think (if your response is gaussian).

Cheers,

Jarrod


On 11/09/2016 04:00, Kerry Samerotte wrote:
> Hi mixed modelers,
>
> I could really use some help with the MCMCglmm predict function. It works
> for me on MCMCglmm output that I generated recently, but fails on MCMCglmm
> output that I generated in November of 2015. In the past, the predict
> function worked just fine on the 11/15 data, but now it fails with the
> following error:
>
> Error in if (!grepl("hu|zi|za|multinomial", object$Residual$family[i])) { :
> argument is of length zero
>
> Here is the model I run in MCMCglmm:
> model = MCMCglmm(phen ~ condition, random = ~us(condition):strain,
> rcov=~idh(condition):units, data=data, prior = prior_PE, thin = 15, nitt =
> 30000, burnin = 6000, verbose = FALSE, pr = TRUE)
>
> Then I simply run:
> predictions <- predict(model, marginal = NULL)
>
> And it fails with the above error. This also fails with the same error:
> predictions <- predict(model)
>
> Help is appreciated!
> Thank you
> Kerry
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From diego.pavonjordan at gmail.com  Tue Sep 13 08:18:08 2016
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Tue, 13 Sep 2016 09:18:08 +0300
Subject: [R-sig-ME] error: 'Calloc' could not allocate memory
Message-ID: <CAD93_FojnheoWtwvBsvgiATb8vPZZYMxbJ3QiOPha=fqmbTcsw@mail.gmail.com>

Dear colleagues

I am handling a (relatively large) data set on ring recoveries and I want
to fit a random effects model to the data using the package lme. When I run
the RANDOM INTERCEPT ONLY model it runs nicely, but when I try to include
also RANDOM SLOPE then I get an error message:

Error in logLik.lmeStructInt(lmeSt, lmePars) :
  'Calloc' could not allocate memory (2036500788 of 8 bytes)


My memory is right now:
> memory.size()
[1] 375.64
> memory.limit()
[1] 3e+11


I have tried to run it only with R running in the computer (plus the basic
stuff that may use RAM) but still can't get the results. Any ideas how to
deal with this issue?

THANK YOU VERY MUCH!

Di



-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*



*0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
<https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile
<http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
<https://helsinki.academia.edu/DiegoPavon>*

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Sep 13 09:36:49 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Sep 2016 09:36:49 +0200
Subject: [R-sig-ME] error: 'Calloc' could not allocate memory
In-Reply-To: <CAD93_FojnheoWtwvBsvgiATb8vPZZYMxbJ3QiOPha=fqmbTcsw@mail.gmail.com>
References: <CAD93_FojnheoWtwvBsvgiATb8vPZZYMxbJ3QiOPha=fqmbTcsw@mail.gmail.com>
Message-ID: <CAJuCY5zR7p8JgRJPshxvhr7L+Le+Uj5YSHRSBgOR3ZuDZRTNUQ@mail.gmail.com>

Dear Diego,

Please don't post in HTML.

Can you provide more information on the model and the data? What is the
formula of the model (fixed and random). Type of the variables. In case of
factors: the number of levels. How many observations/groups do you have?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-13 8:18 GMT+02:00 Diego Pavon <diego.pavonjordan at gmail.com>:

> Dear colleagues
>
> I am handling a (relatively large) data set on ring recoveries and I want
> to fit a random effects model to the data using the package lme. When I run
> the RANDOM INTERCEPT ONLY model it runs nicely, but when I try to include
> also RANDOM SLOPE then I get an error message:
>
> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>   'Calloc' could not allocate memory (2036500788 of 8 bytes)
>
>
> My memory is right now:
> > memory.size()
> [1] 375.64
> > memory.limit()
> [1] 3e+11
>
>
> I have tried to run it only with R running in the computer (plus the basic
> stuff that may use RAM) but still can't get the results. Any ideas how to
> deal with this issue?
>
> THANK YOU VERY MUCH!
>
> Di
>
>
>
> --
> *Diego Pav?n Jord?n*
>
> *Finnish Museum of Natural History*
> *PO BOX 17 *
>
> *Helsinki. Finland*
>
>
>
> *0445061210https://tuhat.halvi.helsinki.fi/portal/en/
> persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
> <https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-
> pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>
> http://www.linkedin.com/profile/view?id=170617924&trk=
> nav_responsive_tab_profile
> <http://www.linkedin.com/profile/view?id=170617924&trk=
> nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
> <https://helsinki.academia.edu/DiegoPavon>*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Sep 13 10:21:09 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Sep 2016 10:21:09 +0200
Subject: [R-sig-ME] error: 'Calloc' could not allocate memory
In-Reply-To: <CAD93_Fr4O5=L6+7V7uzF_bmzRzwoGeSjUnznHZrjbHt4KaagVw@mail.gmail.com>
References: <CAD93_FojnheoWtwvBsvgiATb8vPZZYMxbJ3QiOPha=fqmbTcsw@mail.gmail.com>
	<CAJuCY5zR7p8JgRJPshxvhr7L+Le+Uj5YSHRSBgOR3ZuDZRTNUQ@mail.gmail.com>
	<CAD93_Fr4O5=L6+7V7uzF_bmzRzwoGeSjUnznHZrjbHt4KaagVw@mail.gmail.com>
Message-ID: <CAJuCY5wE=XTH3c0cL72kMWkj8F2Fawr8zr=hhtZHNH8cMfQG8Q@mail.gmail.com>

Dear Diego,

Please keep the mailing list in cc.

You can turn off HTML posting in the settings of your mail editor.

The problem with your model is that the random slope with a factor requires
a variance-covariance matrix with the same dimension as the number of
levels of the factor. In your case this requires 3079 parameters, just for
the random effects. You would need observations for most of the species -
year combination which you clearly don't have.

So you model is too complex given the data.

Here a a few solutions.
1) use a nested random effect of species within year: ~1|YearFound/Species
2) use a nested random effect of year within species: ~1|Species/YearFound
3) use crossed random effects using lme4
lmer(Lat ~ Killed + (1 | Species) + (1| YearFound))

Another option would be to model the probability of getting killed by
latitude.

glmer(Killed ~ Lat + (1 | Species) + (1| YearFound), family = binomial)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-13 10:08 GMT+02:00 Diego Pavon <diego.pavonjordan at gmail.com>:

>  Hello
>
> Thanks for the reply. First, I did not know I was posting in HTML... How
> can I do it otherwise (plain text like now)?
>
>
> So, I want to asses whether the Latitude of ring recovery is related to
> whether the bird was shot (killed) or not. I have recoveries from 1914 to
> 2014. Then I thought to use 'Year' (i.e. when the ring was recovered) as a
> random intercept and, since I am using multiple species, use 'species' as a
> random slope. The code looks like this:
>
> model1 <- lme(Lat ~ Killed, random =~ 1 + Species | YearFound, #Year =
> random intercept, Species = random slope
>               method = "REML",
>               data = Rings2)
>
> Killed has two levels (killed or not killed),
> Year has 100 levels (1913-2013) and
> species has 56 levels (56 different species included). We have selected
> species with >= 10 observations (recoveries).
>
> Or can I even do this? Would I need observations in all years?
>
> By the way, I am using RStudio Version 0.99.903 and R-64 3.2.2 on Windows
> 7 (RAM 8GB).
>
> Thanks!
>
> Diego
>
> 2016-09-13 10:36 GMT+03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Diego,
>>
>> Please don't post in HTML.
>>
>> Can you provide more information on the model and the data? What is the
>> formula of the model (fixed and random). Type of the variables. In case of
>> factors: the number of levels. How many observations/groups do you have?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-09-13 8:18 GMT+02:00 Diego Pavon <diego.pavonjordan at gmail.com>:
>>
>>> Dear colleagues
>>>
>>> I am handling a (relatively large) data set on ring recoveries and I want
>>> to fit a random effects model to the data using the package lme. When I
>>> run
>>> the RANDOM INTERCEPT ONLY model it runs nicely, but when I try to include
>>> also RANDOM SLOPE then I get an error message:
>>>
>>> Error in logLik.lmeStructInt(lmeSt, lmePars) :
>>>   'Calloc' could not allocate memory (2036500788 of 8 bytes)
>>>
>>>
>>> My memory is right now:
>>> > memory.size()
>>> [1] 375.64
>>> > memory.limit()
>>> [1] 3e+11
>>>
>>>
>>> I have tried to run it only with R running in the computer (plus the
>>> basic
>>> stuff that may use RAM) but still can't get the results. Any ideas how to
>>> deal with this issue?
>>>
>>> THANK YOU VERY MUCH!
>>>
>>> Di
>>>
>>>
>>>
>>> --
>>> *Diego Pav?n Jord?n*
>>>
>>> *Finnish Museum of Natural History*
>>> *PO BOX 17 *
>>>
>>> *Helsinki. Finland*
>>>
>>>
>>>
>>> *0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons
>>> /diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
>>> <https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pav
>>> on-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>htt
>>> p://www.linkedin.com/profile/view?id=170617924&trk=nav_respo
>>> nsive_tab_profile
>>> <http://www.linkedin.com/profile/view?id=170617924&trk=nav_r
>>> esponsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
>>> <https://helsinki.academia.edu/DiegoPavon>*
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
>
> --
> *Diego Pav?n Jord?n*
>
> *Finnish Museum of Natural History*
> *PO BOX 17 *
>
> *Helsinki. Finland*
>
>
>
> *0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
> <https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile
> <http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
> <https://helsinki.academia.edu/DiegoPavon>*
>

	[[alternative HTML version deleted]]


From quentin.schorpp at thuenen.de  Mon Sep 12 15:22:45 2016
From: quentin.schorpp at thuenen.de (Quentin Schorpp)
Date: Mon, 12 Sep 2016 15:22:45 +0200 (CEST)
Subject: [R-sig-ME] A sledgehammer to crack a nut?
Message-ID: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>

Hello,

I have trouble with the term "repeated measurements" since I started to
use statistics. During my time as a scientist I never saw an experiment
where time-repeated measurements are NOT involved. Normally there are
either before/after measurements, time-rows to investigate a development
of a measurement variable or the repetition of a certain investigation in
consecutive years. Therefore I'm already wondering why most people start
learning basic statistics and repeated measurement is always declared as
the "hard stuff" for self training in the future.

Now I?ve got data from an experiment repeatedly conducted in 2 consecutive
years.

The measurements are from trees, there are five trees exposed/not exposed
at each habitat (5x3x3) = 30 trees. From each tree three samples were
taken (i.e. n=3 pseudoreplicates). Considering the repetition in the two
years there are n=6 pseudoreplicates, right? And total n = 6 x 30 = 180
Summary: 10 Trees at three habitats either exposed or not exposed to blue
tits. Each tree was measured three times. The whole experiment was
repeated two times. Balanced sample design.

The response variable is count data (of larvae and pupae of a moth)
The explanatory variables are: E1) exposition to blue tits (factor,
yes/no); E2) the type of habitat (wood, farmland, urban) and E3) the year
of conduction.

The random variables are R1) the Tree (factor, ID 1-30)  [and R2) the year
of conduction]

In my opinion, a quite simple study design. Now, I am interested in (all
the possible ways of) analysis of the following Hypotheses:
H1 = blue tits reduce the number of larvae on the trees
H0 = There are no differences in the number of pupae/larvae either exposed
to blue tits or not
Additionally I am interested in the influence of Habitat type on H1 and H0

I learned that the best way to solve problems with repeated measurements
is to use mixed effects models.

My model:
lmer(response ~ E1 * E2 + (1|E3) + (1|R1), data)
and if I?m interested in differences according to the years:
lmer(response ~ E1 * E2 * E3 + (1|R1), data)

Questions:
is that right or do i use a sledgehammer to crack a nut?
is it better to use two ANOVAs for each consecutive year and the means for
the trees, just because everybody can understand it?
What would be the analysis of choice if the residuals are not normally
distributed or heteroscedastic? Or: do non-parameteric tests do not need
to consider random effects?

Kind regards,
Quentin


From chun.chen at wur.nl  Tue Sep 13 14:28:00 2016
From: chun.chen at wur.nl (Chen, Chun)
Date: Tue, 13 Sep 2016 12:28:00 +0000
Subject: [R-sig-ME]
 =?utf-8?q?Does_the_=E2=80=9Cnon-independent=22_data_st?=
 =?utf-8?q?ructure_defined_in_mixed_models_follow_the_=E2=80=9Cindependenc?=
 =?utf-8?q?y=E2=80=9D_defined_by_probability_theory=3F?=
In-Reply-To: <d951d08d-14f5-0e65-aa06-b2488dff7efc@umontpellier.fr>
References: <90a4790272c04249a8dcbc2e9cada269@scomp5296.wurnet.nl>
	<d951d08d-14f5-0e65-aa06-b2488dff7efc@umontpellier.fr>
Message-ID: <eb3b6c514c6946b58c5a27f748409b9c@scomp5296.wurnet.nl>

Thank you Fran?ois, it is much clear for me now.

-----Original Message-----
From: Fran?ois Rousset [mailto:francois.rousset at umontpellier.fr] 
Sent: woensdag, september 07, 2016 14:28
To: Chen, Chun; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Does the ?non-independent" data structure defined in mixed models follow the ?independency? defined by probability theory?

Dear all,

I am a bit surprized by the previous follow-up to this question:

Le 05/09/2016 ? 10:08, Chen, Chun a ?crit :
> Dear all,
>
> I am bit puzzled by definition of the  nested data  or  non-independent data  structure in the mixed model.
>
> >From the statistical point of view, independency is defined as the probabilities of selecting two observations are not influencing each other. In this case, if I design an experiment where I on purposely select two observations from the same group (or strata), then later on we can say these two observations are dependent. However, if I am doing a sampling with replacement and by coincidence I selected one observations twice (e.g. throw a dice twice and by coincidence we get both a  6  each time). The probability of selecting these two observations are indeed not influencing each other and they are independent.
the assumptions are those of the model being fitted. Thus is a mixed model one typically assumes that the _residual errors_ for each observation are independent.
The "observations" are not independent, but the model does not assume that the "observations" are independent in any elevant stochastic sense, only that the residuals are.

I don't see independence in probability as being defined as "not influencing each other". In practice independence also means "not affected by a common factor". A formal definition of independence of several events  is that the joint probability of these events is the product of probabilities of each event : see e.g. Feller 1950, p.125. In the above example of sampling with replacement, a single draw of a residual error affects two response values, so according to the formal definition, the two residuals are not independent. So sampling with replacement violates the assumptions of independence of residuals.

F.R.
>
> My questions are:
>
> What s the definition of the  non-independent data  that is often 
> referred in mixed modeling? Is it the same concept as  independency  
> defined by probability theory, which is relevant by how the 
> observations are selected, rather than how the observations look alike 
> in the final sample
>
> Thanks
>
> Regards,
> Chun
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jsorkin at grecc.umaryland.edu  Tue Sep 13 16:00:48 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 13 Sep 2016 10:00:48 -0400
Subject: [R-sig-ME] A sledgehammer to crack a nut?
In-Reply-To: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>
References: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>
Message-ID: <57D7CE50020000CB001606EA@smtp.medicine.umaryland.edu>

Quentin,
 
A general comment.
 
Accounting for repeated measures taken from the same observational unit
is needed only when three or more measurements
have been obtained. When there are only two measurements one can either
model change (i.e. post-pre) or post alone without
any use of repeated measures theory or software. In fact, if one uses
repeated measures ANOVA when only two measurements, 
the analysis "devolves" into a non-repeated measures analysis. When we
wish to model two measurements the model can be  
specified in many ways including:
change (post-pre) = group
change =group + pre
post = group (this should be used we care as it assumes that the pre
value is the same in all experimental groups)
post = group + pre 
 
You will note that all the models listed above have at most single value
of the outcome of interest on the right side 
of the equals sign, further there is no indication of time the
observation was obtained on the right side of the equals
sign. If you need to have two or more values of the outcome of interest
on the right side of the equals sign, and thus
need a variable to indicate the time at which the observation was
obtained, you need to use repeated measures techniques
and repeated measures analyses. For example if there are three
measurements obtained from each observational unit,
you would need a model something like the following:
value = group + time, where time might equal 0,  1, and 2.
 
John 


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> "Quentin Schorpp" <quentin.schorpp at thuenen.de> 09/13/16 9:18 AM >>>
Hello,

I have trouble with the term "repeated measurements" since I started to
use statistics. During my time as a scientist I never saw an experiment
where time-repeated measurements are NOT involved. Normally there are
either before/after measurements, time-rows to investigate a development
of a measurement variable or the repetition of a certain investigation
in
consecutive years. Therefore I'm already wondering why most people start
learning basic statistics and repeated measurement is always declared as
the "hard stuff" for self training in the future.

Now I?ve got data from an experiment repeatedly conducted in 2
consecutive
years.

The measurements are from trees, there are five trees exposed/not
exposed
at each habitat (5x3x3) = 30 trees. From each tree three samples were
taken (i.e. n=3 pseudoreplicates). Considering the repetition in the two
years there are n=6 pseudoreplicates, right? And total n = 6 x 30 = 180
Summary: 10 Trees at three habitats either exposed or not exposed to
blue
tits. Each tree was measured three times. The whole experiment was
repeated two times. Balanced sample design.

The response variable is count data (of larvae and pupae of a moth)
The explanatory variables are: E1) exposition to blue tits (factor,
yes/no); E2) the type of habitat (wood, farmland, urban) and E3) the
year
of conduction.

The random variables are R1) the Tree (factor, ID 1-30) [and R2) the
year
of conduction]

In my opinion, a quite simple study design. Now, I am interested in (all
the possible ways of) analysis of the following Hypotheses:
H1 = blue tits reduce the number of larvae on the trees
H0 = There are no differences in the number of pupae/larvae either
exposed
to blue tits or not
Additionally I am interested in the influence of Habitat type on H1 and
H0

I learned that the best way to solve problems with repeated measurements
is to use mixed effects models.

My model:
lmer(response ~ E1 * E2 + (1|E3) + (1|R1), data)
and if I?m interested in differences according to the years:
lmer(response ~ E1 * E2 * E3 + (1|R1), data)

Questions:
is that right or do i is it better to use two ANOVAs for each consecutive year and the means
for
the trees, just because everybody can understand it?
What would be the analysis of choice if the residuals are not normally
distributed or heteroscedastic? Or: do non-parameteric tests do not need
to consider random effects?

Kind regards,
Quentin

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From thierry.onkelinx at inbo.be  Tue Sep 13 17:00:34 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Sep 2016 17:00:34 +0200
Subject: [R-sig-ME] A sledgehammer to crack a nut?
In-Reply-To: <57D7CE50020000CB001606EA@smtp.medicine.umaryland.edu>
References: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>
	<57D7CE50020000CB001606EA@smtp.medicine.umaryland.edu>
Message-ID: <CAJuCY5zdh38RY0PM_D+QdsfZrZGxhCqdYZbm7yuC6UdCdDXbyw@mail.gmail.com>

Dear Quentin,

Since your response variable contains counts, you can't use ANOVA which
assumes residuals with a Gaussian distribution.

Year is conceptually a random effect. But with only two levels you get into
numerical problem. Hence it is better to add it to the fixed effects.

So I'd go for

glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
glmer.nb(response ~ E1 * E2 + E3 + (1|R1), data)

Note that  E1 * E2 * E3 if much more complex than  E1 * E2 + (1|E3) in
terms of model fit.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-13 16:00 GMT+02:00 John Sorkin <jsorkin at grecc.umaryland.edu>:

> Quentin,
>
> A general comment.
>
> Accounting for repeated measures taken from the same observational unit
> is needed only when three or more measurements
> have been obtained. When there are only two measurements one can either
> model change (i.e. post-pre) or post alone without
> any use of repeated measures theory or software. In fact, if one uses
> repeated measures ANOVA when only two measurements,
> the analysis "devolves" into a non-repeated measures analysis. When we
> wish to model two measurements the model can be
> specified in many ways including:
> change (post-pre) = group
> change =group + pre
> post = group (this should be used we care as it assumes that the pre
> value is the same in all experimental groups)
> post = group + pre
>
> You will note that all the models listed above have at most single value
> of the outcome of interest on the right side
> of the equals sign, further there is no indication of time the
> observation was obtained on the right side of the equals
> sign. If you need to have two or more values of the outcome of interest
> on the right side of the equals sign, and thus
> need a variable to indicate the time at which the observation was
> obtained, you need to use repeated measures techniques
> and repeated measures analyses. For example if there are three
> measurements obtained from each observational unit,
> you would need a model something like the following:
> value = group + time, where time might equal 0,  1, and 2.
>
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>> "Quentin Schorpp" <quentin.schorpp at thuenen.de> 09/13/16 9:18 AM >>>
> Hello,
>
> I have trouble with the term "repeated measurements" since I started to
> use statistics. During my time as a scientist I never saw an experiment
> where time-repeated measurements are NOT involved. Normally there are
> either before/after measurements, time-rows to investigate a development
> of a measurement variable or the repetition of a certain investigation
> in
> consecutive years. Therefore I'm already wondering why most people start
> learning basic statistics and repeated measurement is always declared as
> the "hard stuff" for self training in the future.
>
> Now I?ve got data from an experiment repeatedly conducted in 2
> consecutive
> years.
>
> The measurements are from trees, there are five trees exposed/not
> exposed
> at each habitat (5x3x3) = 30 trees. From each tree three samples were
> taken (i.e. n=3 pseudoreplicates). Considering the repetition in the two
> years there are n=6 pseudoreplicates, right? And total n = 6 x 30 = 180
> Summary: 10 Trees at three habitats either exposed or not exposed to
> blue
> tits. Each tree was measured three times. The whole experiment was
> repeated two times. Balanced sample design.
>
> The response variable is count data (of larvae and pupae of a moth)
> The explanatory variables are: E1) exposition to blue tits (factor,
> yes/no); E2) the type of habitat (wood, farmland, urban) and E3) the
> year
> of conduction.
>
> The random variables are R1) the Tree (factor, ID 1-30) [and R2) the
> year
> of conduction]
>
> In my opinion, a quite simple study design. Now, I am interested in (all
> the possible ways of) analysis of the following Hypotheses:
> H1 = blue tits reduce the number of larvae on the trees
> H0 = There are no differences in the number of pupae/larvae either
> exposed
> to blue tits or not
> Additionally I am interested in the influence of Habitat type on H1 and
> H0
>
> I learned that the best way to solve problems with repeated measurements
> is to use mixed effects models.
>
> My model:
> lmer(response ~ E1 * E2 + (1|E3) + (1|R1), data)
> and if I?m interested in differences according to the years:
> lmer(response ~ E1 * E2 * E3 + (1|R1), data)
>
> Questions:
> is that right or do i is it better to use two ANOVAs for each consecutive
> year and the means
> for
> the trees, just because everybody can understand it?
> What would be the analysis of choice if the residuals are not normally
> distributed or heteroscedastic? Or: do non-parameteric tests do not need
> to consider random effects?
>
> Kind regards,
> Quentin
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:13}}


From highstat at highstat.com  Wed Sep 14 10:56:47 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 14 Sep 2016 09:56:47 +0100
Subject: [R-sig-ME] Course: Data exploration, regression,
 GLM & GAM with introduction to R
Message-ID: <925d79ee-6ec6-0568-e23f-014b4f4d0587@highstat.com>


We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with introduction to R

Where:  Lisbon, Portugal

When:   13-17 February 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: http://highstat.com/Courses/Flyers/Flyer2017_02Lisbon_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

9-13 January 2017: Data exploration, regression, GLM & GAM

20-24 February 2017: Introduction to Regression Models with Spatial and 
Temporal Correlatio

9-13 October 2017: Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From selebatsom at yahoo.co.uk  Wed Sep 14 12:50:47 2016
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Wed, 14 Sep 2016 10:50:47 +0000 (UTC)
Subject: [R-sig-ME] Reporting means and standard deviation from lme
References: <1143810636.1562263.1473850247968.ref@mail.yahoo.com>
Message-ID: <1143810636.1562263.1473850247968@mail.yahoo.com>

?Good dayCan someone guide me how I can extract means and SD from lm models? I am interested in reporting means associated with my fixed effects.
Moses 
	[[alternative HTML version deleted]]


From quentin.schorpp at thuenen.de  Wed Sep 14 14:21:26 2016
From: quentin.schorpp at thuenen.de (Quentin Schorpp)
Date: Wed, 14 Sep 2016 14:21:26 +0200 (CEST)
Subject: [R-sig-ME] A sledgehammer to crack a nut?
In-Reply-To: <CAJuCY5zdh38RY0PM_D+QdsfZrZGxhCqdYZbm7yuC6UdCdDXbyw@mail.gmail.com>
References: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>
	<57D7CE50020000CB001606EA@smtp.medicine.umaryland.edu>
	<CAJuCY5zdh38RY0PM_D+QdsfZrZGxhCqdYZbm7yuC6UdCdDXbyw@mail.gmail.com>
Message-ID: <c36e8efce0a397e49a9c18b3e8bb97a5.squirrel@webmail.thuenen.de>

Hello,
thank you very much for your answers,

@ Thierry,

In the Model
glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)

can I say "I analyze E3 as a main effect"?.

Let's assume the following effect: For habitat "wood" the numbers of pupae
were significantly decreased when exposed to blue tits, but when i look at
the data i see, that the effect was very strong in the first year, but not
visible at all in the second year. Could i be deceived by the analysis
above, in the way that it says: There was a strong difference between
exposed/not exposed for wood and overall the numbers of pupae where
similar in both years?
Or is it simply not necessary that the analysis tells me about that, the
assumed "strong" effect would be predicted as "moderate" and it is up to
me to lay it on the line and present figures to tell the audience that
there is a also 50/50 chance to have an effect at all?

Wuuld that be the right way to perform a Likelihood ratio test for the
above analysis?

glmm1 <- glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
glmm2 <- glmer(response ~ E1 + E2 + E3 + (1|R1), data, family = poisson)
glmm3 <- glmer(response ~ E1 + E2 + (1|R1), data, family = poisson)
glmm4 <- glmer(response ~ E2 + E3 + (1|R1), data, family = poisson)
glmm5 <- glmer(response ~ E1 + E3 + (1|R1), data, family = poisson)
glmm0 <- glmer(response ~ 1 + (1|R1), data, family = poisson)

anova(glmm1, glmm2, glmm3, glmm4, glmm5, glmm0) ?

I don't find a tutorial on "how to perfom a likelihood ratio test by hand"
and the afex package does not work on my computer.

@John
That was very interesting, repeated measures ANOVA with only two rep.
measurements "devolves" into a non-repeated measures analysis.
And combining the values of both measurements followed by non-repmes ANOVA
could solve the problem.
The first part of your answer focuses experiments with only two repeated
measures, when these measures where taken within the same experimental
unit, right?. Then you explain methods how to reduce both measurements to
get a single value as outcome variable. Would taking the average of both
repeated measurements be an option, too?
I did not understand the difference between
b) change = group + pre
and
d) post = group + pre

since when group is defined as a) change (post-pre) = group, then group +
pre = post - pre + pre = post  (= change in b) )

Next, addition of 0,1,2 to the measurement value in value = group + time,
wouldn't that mean to add two values of different units, i.e. counts and
hours? Or is 0,1,2 without a unit?

Thank you very much

Kind regards,
Quentin

> Dear Quentin,
>
> Since your response variable contains counts, you can't use ANOVA which
> assumes residuals with a Gaussian distribution.
>
> Year is conceptually a random effect. But with only two levels you get
> into
> numerical problem. Hence it is better to add it to the fixed effects.
>
> So I'd go for
>
> glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
> glmer.nb(response ~ E1 * E2 + E3 + (1|R1), data)
>
> Note that  E1 * E2 * E3 if much more complex than  E1 * E2 + (1|E3) in
> terms of model fit.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> 2016-09-13 16:00 GMT+02:00 John Sorkin <jsorkin at grecc.umaryland.edu>:
>
>> Quentin,
>>
>> A general comment.
>>
>> Accounting for repeated measures taken from the same observational unit
>> is needed only when three or more measurements
>> have been obtained. When there are only two measurements one can either
>> model change (i.e. post-pre) or post alone without
>> any use of repeated measures theory or software. In fact, if one uses
>> repeated measures ANOVA when only two measurements,
>> the analysis "devolves" into a non-repeated measures analysis. When we
>> wish to model two measurements the model can be
>> specified in many ways including:
>> change (post-pre) = group
>> change =group + pre
>> post = group (this should be used we care as it assumes that the pre
>> value is the same in all experimental groups)
>> post = group + pre
>>
>> You will note that all the models listed above have at most single value
>> of the outcome of interest on the right side
>> of the equals sign, further there is no indication of time the
>> observation was obtained on the right side of the equals
>> sign. If you need to have two or more values of the outcome of interest
>> on the right side of the equals sign, and thus
>> need a variable to indicate the time at which the observation was
>> obtained, you need to use repeated measures techniques
>> and repeated measures analyses. For example if there are three
>> measurements obtained from each observational unit,
>> you would need a model something like the following:
>> value = group + time, where time might equal 0,  1, and 2.
>>
>> John
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>> "Quentin Schorpp" <quentin.schorpp at thuenen.de> 09/13/16 9:18 AM >>>
>> Hello,
>>
>> I have trouble with the term "repeated measurements" since I started to
>> use statistics. During my time as a scientist I never saw an experiment
>> where time-repeated measurements are NOT involved. Normally there are
>> either before/after measurements, time-rows to investigate a development
>> of a measurement variable or the repetition of a certain investigation
>> in
>> consecutive years. Therefore I'm already wondering why most people start
>> learning basic statistics and repeated measurement is always declared as
>> the "hard stuff" for self training in the future.
>>
>> Now I?ve got data from an experiment repeatedly conducted in 2
>> consecutive
>> years.
>>
>> The measurements are from trees, there are five trees exposed/not
>> exposed
>> at each habitat (5x3x3) = 30 trees. From each tree three samples were
>> taken (i.e. n=3 pseudoreplicates). Considering the repetition in the two
>> years there are n=6 pseudoreplicates, right? And total n = 6 x 30 = 180
>> Summary: 10 Trees at three habitats either exposed or not exposed to
>> blue
>> tits. Each tree was measured three times. The whole experiment was
>> repeated two times. Balanced sample design.
>>
>> The response variable is count data (of larvae and pupae of a moth)
>> The explanatory variables are: E1) exposition to blue tits (factor,
>> yes/no); E2) the type of habitat (wood, farmland, urban) and E3) the
>> year
>> of conduction.
>>
>> The random variables are R1) the Tree (factor, ID 1-30) [and R2) the
>> year
>> of conduction]
>>
>> In my opinion, a quite simple study design. Now, I am interested in (all
>> the possible ways of) analysis of the following Hypotheses:
>> H1 = blue tits reduce the number of larvae on the trees
>> H0 = There are no differences in the number of pupae/larvae either
>> exposed
>> to blue tits or not
>> Additionally I am interested in the influence of Habitat type on H1 and
>> H0
>>
>> I learned that the best way to solve problems with repeated measurements
>> is to use mixed effects models.
>>
>> My model:
>> lmer(response ~ E1 * E2 + (1|E3) + (1|R1), data)
>> and if I?m interested in differences according to the years:
>> lmer(response ~ E1 * E2 * E3 + (1|R1), data)
>>
>> Questions:
>> is that right or do i is it better to use two ANOVAs for each
>> consecutive
>> year and the means
>> for
>> the trees, just because everybody can understand it?
>> What would be the analysis of choice if the residuals are not normally
>> distributed or heteroscedastic? Or: do non-parameteric tests do not need
>> to consider random effects?
>>
>> Kind regards,
>> Quentin
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of
>> the intended recipient(s) and may contain confidential and privileged
>> information. Any unauthorized use, disclosure or distribution is
>> prohibited. If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From Margaret.MacDougall at ed.ac.uk  Wed Sep 14 18:14:41 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Wed, 14 Sep 2016 16:14:41 +0000
Subject: [R-sig-ME] Cross-classified multilevel binary logistic regression
 model with random effects at level 2
Message-ID: <VI1PR0502MB302163F2EBD4C14D3654C9F0C5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Hello



I am not a seasoned R user and am therefore keen to identify a book chapter that provides structured advice on using R to set up the type of model I am interested in. I would like to run a cross-classified multilevel binary logistic regression model. The model contains two level 2 random effects variables. These variables are crossed to form a cross-classified design. The model has subjects at level one and these subjects are nested within each of the two level 2 variables. I understand that the R package lme4 may be suitable for running my model and that there are several published books on running mixed models in R. If a list member is able to kindly recommend whether one of these books is particularly helpful in enabling less experienced R users to fully understand how to use this (or an alternative) program specifically for the model I have outlined above, I would be most grateful for recommendations.

Best wishes



Margaret


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr Margaret MacDougall
Medical Statistician and Researcher in Education
Centre for Population Health Sciences
College of Medicine and Veterinary Medicine
Teviot Place
University of Edinburgh
Edinburgh EH8 9AG

Email: Margaret.MacDougall at ed.ac.uk<mailto:Margaret.MacDougall at ed.ac.uk>
Tel: +44(0)131 650 3211
Fax: +44(0)131 650 6909
Personal profile: http://www.ed.ac.uk/profile/margaret-macdougall

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20160914/572ee786/attachment.pl>

From HDoran at air.org  Wed Sep 14 20:21:58 2016
From: HDoran at air.org (Doran, Harold)
Date: Wed, 14 Sep 2016 18:21:58 +0000
Subject: [R-sig-ME] Cross-classified multilevel binary logistic
 regression model with random effects at level 2
In-Reply-To: <VI1PR0502MB302163F2EBD4C14D3654C9F0C5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB302163F2EBD4C14D3654C9F0C5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <D3FF0D53.3F3D8%hdoran@air.org>

Our paper below does exactly this

https://www.jstatsoft.org/article/view/v020i02

On 9/14/16, 12:14 PM, "MACDOUGALL Margaret" <Margaret.MacDougall at ed.ac.uk>
wrote:

>Hello
>
>
>
>I am not a seasoned R user and am therefore keen to identify a book
>chapter that provides structured advice on using R to set up the type of
>model I am interested in. I would like to run a cross-classified
>multilevel binary logistic regression model. The model contains two level
>2 random effects variables. These variables are crossed to form a
>cross-classified design. The model has subjects at level one and these
>subjects are nested within each of the two level 2 variables. I
>understand that the R package lme4 may be suitable for running my model
>and that there are several published books on running mixed models in R.
>If a list member is able to kindly recommend whether one of these books
>is particularly helpful in enabling less experienced R users to fully
>understand how to use this (or an alternative) program specifically for
>the model I have outlined above, I would be most grateful for
>recommendations.
>
>Best wishes
>
>
>
>Margaret
>
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Dr Margaret MacDougall
>Medical Statistician and Researcher in Education
>Centre for Population Health Sciences
>College of Medicine and Veterinary Medicine
>Teviot Place
>University of Edinburgh
>Edinburgh EH8 9AG
>
>Email: Margaret.MacDougall at ed.ac.uk<mailto:Margaret.MacDougall at ed.ac.uk>
>Tel: +44(0)131 650 3211
>Fax: +44(0)131 650 6909
>Personal profile: http://www.ed.ac.uk/profile/margaret-macdougall
>


From thierry.onkelinx at inbo.be  Thu Sep 15 11:02:52 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 15 Sep 2016 11:02:52 +0200
Subject: [R-sig-ME] A sledgehammer to crack a nut?
In-Reply-To: <c36e8efce0a397e49a9c18b3e8bb97a5.squirrel@webmail.thuenen.de>
References: <71e2113788bc3d7e6dfab0993eb90863.squirrel@webmail.thuenen.de>
	<57D7CE50020000CB001606EA@smtp.medicine.umaryland.edu>
	<CAJuCY5zdh38RY0PM_D+QdsfZrZGxhCqdYZbm7yuC6UdCdDXbyw@mail.gmail.com>
	<c36e8efce0a397e49a9c18b3e8bb97a5.squirrel@webmail.thuenen.de>
Message-ID: <CAJuCY5zjJYRewbRiPoi6gbEwnwcT2=CrEJd9BSn=Stf6VfVCyw@mail.gmail.com>

Dear Quentin,

I suggested to use E1 * E2 + E3 + (1|R1) because that allows the same model
fit as E1 * E2 + (1|E3) + (1|R1). If interaction between E3 and E1 or E2
make sense then you should add them.

Use LRT as

anova(glmm1, glmm2)
anova(glmm2, glmm3)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-09-14 14:21 GMT+02:00 Quentin Schorpp <quentin.schorpp at thuenen.de>:

> Hello,
> thank you very much for your answers,
>
> @ Thierry,
>
> In the Model
> glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
>
> can I say "I analyze E3 as a main effect"?.
>
> Let's assume the following effect: For habitat "wood" the numbers of pupae
> were significantly decreased when exposed to blue tits, but when i look at
> the data i see, that the effect was very strong in the first year, but not
> visible at all in the second year. Could i be deceived by the analysis
> above, in the way that it says: There was a strong difference between
> exposed/not exposed for wood and overall the numbers of pupae where
> similar in both years?
> Or is it simply not necessary that the analysis tells me about that, the
> assumed "strong" effect would be predicted as "moderate" and it is up to
> me to lay it on the line and present figures to tell the audience that
> there is a also 50/50 chance to have an effect at all?
>
> Wuuld that be the right way to perform a Likelihood ratio test for the
> above analysis?
>
> glmm1 <- glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
> glmm2 <- glmer(response ~ E1 + E2 + E3 + (1|R1), data, family = poisson)
> glmm3 <- glmer(response ~ E1 + E2 + (1|R1), data, family = poisson)
> glmm4 <- glmer(response ~ E2 + E3 + (1|R1), data, family = poisson)
> glmm5 <- glmer(response ~ E1 + E3 + (1|R1), data, family = poisson)
> glmm0 <- glmer(response ~ 1 + (1|R1), data, family = poisson)
>
> anova(glmm1, glmm2, glmm3, glmm4, glmm5, glmm0) ?
>
> I don't find a tutorial on "how to perfom a likelihood ratio test by hand"
> and the afex package does not work on my computer.
>
> @John
> That was very interesting, repeated measures ANOVA with only two rep.
> measurements "devolves" into a non-repeated measures analysis.
> And combining the values of both measurements followed by non-repmes ANOVA
> could solve the problem.
> The first part of your answer focuses experiments with only two repeated
> measures, when these measures where taken within the same experimental
> unit, right?. Then you explain methods how to reduce both measurements to
> get a single value as outcome variable. Would taking the average of both
> repeated measurements be an option, too?
> I did not understand the difference between
> b) change = group + pre
> and
> d) post = group + pre
>
> since when group is defined as a) change (post-pre) = group, then group +
> pre = post - pre + pre = post  (= change in b) )
>
> Next, addition of 0,1,2 to the measurement value in value = group + time,
> wouldn't that mean to add two values of different units, i.e. counts and
> hours? Or is 0,1,2 without a unit?
>
> Thank you very much
>
> Kind regards,
> Quentin
>
> > Dear Quentin,
> >
> > Since your response variable contains counts, you can't use ANOVA which
> > assumes residuals with a Gaussian distribution.
> >
> > Year is conceptually a random effect. But with only two levels you get
> > into
> > numerical problem. Hence it is better to add it to the fixed effects.
> >
> > So I'd go for
> >
> > glmer(response ~ E1 * E2 + E3 + (1|R1), data, family = poisson)
> > glmer.nb(response ~ E1 * E2 + E3 + (1|R1), data)
> >
> > Note that  E1 * E2 * E3 if much more complex than  E1 * E2 + (1|E3) in
> > terms of model fit.
> >
> > Best regards,
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > ~ John Tukey
> >
> > 2016-09-13 16:00 GMT+02:00 John Sorkin <jsorkin at grecc.umaryland.edu>:
> >
> >> Quentin,
> >>
> >> A general comment.
> >>
> >> Accounting for repeated measures taken from the same observational unit
> >> is needed only when three or more measurements
> >> have been obtained. When there are only two measurements one can either
> >> model change (i.e. post-pre) or post alone without
> >> any use of repeated measures theory or software. In fact, if one uses
> >> repeated measures ANOVA when only two measurements,
> >> the analysis "devolves" into a non-repeated measures analysis. When we
> >> wish to model two measurements the model can be
> >> specified in many ways including:
> >> change (post-pre) = group
> >> change =group + pre
> >> post = group (this should be used we care as it assumes that the pre
> >> value is the same in all experimental groups)
> >> post = group + pre
> >>
> >> You will note that all the models listed above have at most single value
> >> of the outcome of interest on the right side
> >> of the equals sign, further there is no indication of time the
> >> observation was obtained on the right side of the equals
> >> sign. If you need to have two or more values of the outcome of interest
> >> on the right side of the equals sign, and thus
> >> need a variable to indicate the time at which the observation was
> >> obtained, you need to use repeated measures techniques
> >> and repeated measures analyses. For example if there are three
> >> measurements obtained from each observational unit,
> >> you would need a model something like the following:
> >> value = group + time, where time might equal 0,  1, and 2.
> >>
> >> John
> >>
> >>
> >> John David Sorkin M.D., Ph.D.
> >> Professor of Medicine
> >> Chief, Biostatistics and Informatics
> >> University of Maryland School of Medicine Division of Gerontology and
> >> Geriatric Medicine
> >> Baltimore VA Medical Center
> >> 10 North Greene Street
> >> GRECC (BT/18/GR)
> >> Baltimore, MD 21201-1524
> >> (Phone) 410-605-7119
> >> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >> >>> "Quentin Schorpp" <quentin.schorpp at thuenen.de> 09/13/16 9:18 AM >>>
> >> Hello,
> >>
> >> I have trouble with the term "repeated measurements" since I started to
> >> use statistics. During my time as a scientist I never saw an experiment
> >> where time-repeated measurements are NOT involved. Normally there are
> >> either before/after measurements, time-rows to investigate a development
> >> of a measurement variable or the repetition of a certain investigation
> >> in
> >> consecutive years. Therefore I'm already wondering why most people start
> >> learning basic statistics and repeated measurement is always declared as
> >> the "hard stuff" for self training in the future.
> >>
> >> Now I?ve got data from an experiment repeatedly conducted in 2
> >> consecutive
> >> years.
> >>
> >> The measurements are from trees, there are five trees exposed/not
> >> exposed
> >> at each habitat (5x3x3) = 30 trees. From each tree three samples were
> >> taken (i.e. n=3 pseudoreplicates). Considering the repetition in the two
> >> years there are n=6 pseudoreplicates, right? And total n = 6 x 30 = 180
> >> Summary: 10 Trees at three habitats either exposed or not exposed to
> >> blue
> >> tits. Each tree was measured three times. The whole experiment was
> >> repeated two times. Balanced sample design.
> >>
> >> The response variable is count data (of larvae and pupae of a moth)
> >> The explanatory variables are: E1) exposition to blue tits (factor,
> >> yes/no); E2) the type of habitat (wood, farmland, urban) and E3) the
> >> year
> >> of conduction.
> >>
> >> The random variables are R1) the Tree (factor, ID 1-30) [and R2) the
> >> year
> >> of conduction]
> >>
> >> In my opinion, a quite simple study design. Now, I am interested in (all
> >> the possible ways of) analysis of the following Hypotheses:
> >> H1 = blue tits reduce the number of larvae on the trees
> >> H0 = There are no differences in the number of pupae/larvae either
> >> exposed
> >> to blue tits or not
> >> Additionally I am interested in the influence of Habitat type on H1 and
> >> H0
> >>
> >> I learned that the best way to solve problems with repeated measurements
> >> is to use mixed effects models.
> >>
> >> My model:
> >> lmer(response ~ E1 * E2 + (1|E3) + (1|R1), data)
> >> and if I?m interested in differences according to the years:
> >> lmer(response ~ E1 * E2 * E3 + (1|R1), data)
> >>
> >> Questions:
> >> is that right or do i is it better to use two ANOVAs for each
> >> consecutive
> >> year and the means
> >> for
> >> the trees, just because everybody can understand it?
> >> What would be the analysis of choice if the residuals are not normally
> >> distributed or heteroscedastic? Or: do non-parameteric tests do not need
> >> to consider random effects?
> >>
> >> Kind regards,
> >> Quentin
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> Confidentiality Statement:
> >> This email message, including any attachments, is for the sole use of
> >> the intended recipient(s) and may contain confidential and privileged
> >> information. Any unauthorized use, disclosure or distribution is
> >> prohibited. If you are not the intended recipient, please contact the
> >> sender by reply email and destroy all copies of the original message.
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
>
>
>

	[[alternative HTML version deleted]]


From Margaret.MacDougall at ed.ac.uk  Fri Sep 16 18:45:20 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Fri, 16 Sep 2016 16:45:20 +0000
Subject: [R-sig-ME] Cross-classified multilevel binary logistic
 regression model with random effects at level 2
In-Reply-To: <D3FF0D53.3F3D8%hdoran@air.org>
References: <VI1PR0502MB302163F2EBD4C14D3654C9F0C5F10@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<D3FF0D53.3F3D8%hdoran@air.org>
Message-ID: <VI1PR0502MB30219C15CB38F36D84F5F4D4C5F30@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Thank you for this valued suggestion, Harold. I look forward to reading this paper and getting back to you directly with any comments.

Best wishes

Margaret



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


-----Original Message-----
From: Doran, Harold [mailto:HDoran at air.org] 
Sent: 14 September 2016 19:22
To: MACDOUGALL Margaret <Margaret.MacDougall at ed.ac.uk>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Cross-classified multilevel binary logistic regression model with random effects at level 2

Our paper below does exactly this

https://www.jstatsoft.org/article/view/v020i02

On 9/14/16, 12:14 PM, "MACDOUGALL Margaret" <Margaret.MacDougall at ed.ac.uk>
wrote:

>Hello
>
>
>
>I am not a seasoned R user and am therefore keen to identify a book 
>chapter that provides structured advice on using R to set up the type 
>of model I am interested in. I would like to run a cross-classified 
>multilevel binary logistic regression model. The model contains two 
>level
>2 random effects variables. These variables are crossed to form a 
>cross-classified design. The model has subjects at level one and these 
>subjects are nested within each of the two level 2 variables. I 
>understand that the R package lme4 may be suitable for running my model 
>and that there are several published books on running mixed models in R.
>If a list member is able to kindly recommend whether one of these books 
>is particularly helpful in enabling less experienced R users to fully 
>understand how to use this (or an alternative) program specifically for 
>the model I have outlined above, I would be most grateful for 
>recommendations.
>
>Best wishes
>
>
>
>Margaret
>
>
>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>Dr Margaret MacDougall
>Medical Statistician and Researcher in Education Centre for Population 
>Health Sciences College of Medicine and Veterinary Medicine Teviot 
>Place University of Edinburgh Edinburgh EH8 9AG
>
>Email: 
>Margaret.MacDougall at ed.ac.uk<mailto:Margaret.MacDougall at ed.ac.uk>
>Tel: +44(0)131 650 3211
>Fax: +44(0)131 650 6909
>Personal profile: http://www.ed.ac.uk/profile/margaret-macdougall
>


From lee.wurm at wayne.edu  Mon Sep 19 14:50:40 2016
From: lee.wurm at wayne.edu (Lee Wurm)
Date: Mon, 19 Sep 2016 08:50:40 -0400
Subject: [R-sig-ME] repeated-measures correlation coefficient?
Message-ID: <CAPUqT-Y=FeMFooKQucXxg18MPtK0y2eD-xp0CywH10X8CaCyMA@mail.gmail.com>

I've seen linear mixed-effects models described as "repeated-measures
regression analyses" and I'm wondering whether there exists something like
a "repeated-measures" version of the Pearson correlation coefficient. For
my dataset the linguistic content of interviews has been coded on several
dozen dimensions (like proportion of words that are pronouns, proportion of
words that involve positive emotion, overall number of words, etc.), and
I've been asked to show the correlations between lots and lots of these
dimensions. The problem is that the data come from perhaps 35 different
interviewees, who are represented in the data different numbers of times
(from 1 to 90 interviews). My searches on this topic all point to the
intrac-class correlation, but when I read the details it seems obvious to
me that this is not what I want.

--Lee

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Tue Sep 20 00:47:41 2016
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Mon, 19 Sep 2016 22:47:41 +0000
Subject: [R-sig-ME] repeated-measures correlation coefficient?
In-Reply-To: <CAPUqT-Y=FeMFooKQucXxg18MPtK0y2eD-xp0CywH10X8CaCyMA@mail.gmail.com>
References: <CAPUqT-Y=FeMFooKQucXxg18MPtK0y2eD-xp0CywH10X8CaCyMA@mail.gmail.com>
Message-ID: <1474325267.24960.142.camel@loki>

The answer is "sort of". If you've already looked at measures like
intra-class correlation, then you might start to see some of the
problems. A parallel issue on the difficulties with R^2 and the trouble
defining it for the (G)LMM case is discussed on the FAQ:

https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms

including a link back to one of Doug Bates' enlightening "half-rants".
(No sarcasm there -- DB doesn't speak up too often on the list, but I
always learn a lot when he does!)

There are two intuitive problems. One is a direct carryover from
multiple regression -- measuring correlation between x1 and y is always
tricky if you want it conditional on x2 or the interaction x1 and x2.
The other is that it's not entirely clear what a good regression measure
is with a multilevel model because of things like Simpson's Paradox --
it's quite possible for the correlation within each level (e.g. within
each participant) to be in one direction, but the correlation across
participants to go in the other direction. Which one is the "correct"
correlation? The obvious measures of "correlation across trials,
ignoring grouping levels", "average of correlations computed within
groups" and "correlation across within-group averages" would/could all
individually fail to capture the complex relationship between x and y
and may be misleading in certain circumstances, but might suffice for
what you're doing. It really depends on what question you're trying to
answer. When you have multiple grouping factors (e.g. participants and
items), things only get more complicated.

Maybe somebody else has heard of a new measure that addresses these
issues?

Phillip

On Mon, 2016-09-19 at 08:50 -0400, Lee Wurm wrote:
> I've seen linear mixed-effects models described as "repeated-measures
> regression analyses" and I'm wondering whether there exists something like
> a "repeated-measures" version of the Pearson correlation coefficient. For
> my dataset the linguistic content of interviews has been coded on several
> dozen dimensions (like proportion of words that are pronouns, proportion of
> words that involve positive emotion, overall number of words, etc.), and
> I've been asked to show the correlations between lots and lots of these
> dimensions. The problem is that the data come from perhaps 35 different
> interviewees, who are represented in the data different numbers of times
> (from 1 to 90 interviews). My searches on this topic all point to the
> intrac-class correlation, but when I read the details it seems obvious to
> me that this is not what I want.
> 
> --Lee
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From osoong+r at gmail.com  Wed Sep 21 01:13:52 2016
From: osoong+r at gmail.com (Oliver Soong)
Date: Tue, 20 Sep 2016 16:13:52 -0700
Subject: [R-sig-ME] mcmcsamp
Message-ID: <CAPQ=hV+L5V4i8_xV2xTfP7=Ub-4J7OkiJ-KQT5nrGw=5ML+m-g@mail.gmail.com>

I know mcmcsamp is no longer released as part of lme4, but I was
looking the code to see if I could understand what it used to do.
Mostly, I was hoping to figure out what sort of MCMC sampler it was
using.  I seem to have failed.  I'm only familiar with some of the
most common samplers, but all of them involve some sort of
accept/reject step, and I couldn't figure out where that occurred in
mcmcsamp.  An RNG only seems to be invoked in MCMC_beta_u.  My best
guess is it's actually directly sampling the posterior distribution
used the fitted/estimated parameters.  Can somebody give me a few
hints as to what's going on here?

Oliver


From Olga.Viedma at uclm.es  Thu Sep 22 13:13:06 2016
From: Olga.Viedma at uclm.es (MARIA OLGA VIEDMA SILLERO)
Date: Thu, 22 Sep 2016 11:13:06 +0000
Subject: [R-sig-ME] multilevel ZINB mixture model (interpreting interactions
	with time)
Message-ID: <DB5PR0101MB1624EF1FE3B086D2C89F0301ECC90@DB5PR0101MB1624.eurprd01.prod.exchangelabs.com>

Dear all:

I am working with a multilevel Zero-inflated mixture model for longitudinal data. Concretely, I am predicting fire frequency and excess of zeros over 445 spatial units across 35 years. I am running the models using MCMCglmm package in R.

I used the ID of the units and Time (as categorical variable) as random factors, and time (in continuous) and other explanatory variables as fixed effects. Moreover, I tested the interaction between time (continuous: 0-34 years) and other explanatory covariates (both, time-no variant and time-varying) in both parts of the model (the count part: negative binomial and the zero-part: logistic).

My problem resides on how interpret the interactions with time. If I understood well, the coefficient of the fixed effect in longitudinal models is the averaged effect of any co-variable on the outcome across time, and the interaction of any co-variable with time indicates the change of that averaged effect at each time step.

However, I observed that in almost all co-variables when the fixed effect was negative, the interaction with time resulted positive, while the opposite was observed when the mean fixed effect was positive. Actually, I don?t know how interpret this results. Will it be that the averaged effect (for example negative) is stronger (more negative) at each time step if the sign of the interaction is positive? Or that the averaged negative effect is turning more positive across time?

Thanks in advance,

Olga Viedma

D?. Olga Viedma Sillero
Profesora Ordenaci?n del Territorio
Facultad de Ciencias del Medio Ambiente y Bioqu?mica
Universidad de Castilla-La Mancha
Avd/ Carlos III, s/n. 45071 Toledo
Tel: 925 268800 (ext. 5780)
Email: olga.viedma at uclm.es
http://blog.uclm.es/grupofuego


	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Thu Sep 22 22:34:07 2016
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 22 Sep 2016 15:34:07 -0500
Subject: [R-sig-ME] Replicating analysis in asreml in lme4
In-Reply-To: <a9e6fc12-c3c0-f381-ca8e-aff6b08a0a3d@gmail.com>
References: <CA+0rMg=bpxedA1m3wMm0rcSketuf+KY=4CY=R25evm=G10f5Qw@mail.gmail.com>
	<a9e6fc12-c3c0-f381-ca8e-aff6b08a0a3d@gmail.com>
Message-ID: <CAKFxdiTh28hBGgoBS-_-pOft2N7vCudESDaBy8P9UXoySjYCyA@mail.gmail.com>

This is very late, but I'm posting it for completeness.

Thanks to Aravind for the question and to Ben for the tip.  Here's how you
would use lme4/lsmeans:

   require(lme4)

  cov2sed <- function(x){
  # Convert var-cov matrix to SED matrix
  # sed[i,j] = sqrt( x[i,i] + x[j,j]- 2*x[i,j] )
  n <- nrow(x)
  vars <- diag(x)
  sed <- sqrt( matrix(vars, n, n, byrow=TRUE) +
                 matrix(vars, n, n, byrow=FALSE) - 2*x )
  diag(sed) <- 0
  return(sed)
  }

  # Same as asreml model m4
  m5 <- lmer(yield ~ 0 + gen + rep + (1|rep:block), dat)

  require(lsmeans)
  ls5 <- lsmeans(m5, "gen")
  con <- ls5 at linfct # contrast matrix
  sed5 <- cov2sed(con %*% vcov(m5) %*% t(con)) # SED between genotypes
  # Average variance of difference between genotypes
  mean(sed5[upper.tri(sed5)]^2) # .07010875 matches 'vblue' from asreml



On Sun, Jul 31, 2016 at 8:50 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>  Try the lsmeans package ...
>
> On 16-07-30 01:41 AM, Aravind J. wrote:
> > Dear members,
> >
> > I am trying to reproduce analyse an alpha lattice design (an unbalanced
> > design) in  `lme4`.
> >
> > https://cran.r-project.org/web/packages/agridat/agridat.pdf#page.184
> >
> > library(agridat)
> > library(lme4)
> >
> > The model can be fitted in lme4
> >
> > # genotypes - fixed
> > model <- lmer(yield ~ 0 + gen + rep + (1|rep:block), dat)
> > # genotypes - random
> > model <- lmer(yield ~ 0 + (1|gen) + rep + (1|rep:block), dat)
> >
> > However further calculations seem to required `asreml`.
> >
> > library(asreml)
> >
> > m3 <- asreml(yield ~ 1 + rep, data=dat, random=~ gen + rep:block)
> > sg2 <- summary(m3)$varcomp[1,'component']
> > vblup <- predict(m3, classify="gen")$pred$avsed ^ 2
> >
> > m3 <- asreml(yield ~ 1 + gen + rep, data=dat, random = ~ rep:block)
> > vblue <- predict(m3, classify="gen")$pred$avsed ^ 2
> > sg2 / (sg2 + vblue/2)
> > 1-(vblup / 2 / sg2)
> >
> > Here `avsed` is the "mean variance of difference of adjusted means" (BLUP
> > or BLUE). Is it possible to replicate the last part also in `lme4`?
> >
> > `avsed` can be computed from the "variance-covariance matrix of adjusted
> > means" for genotypes. (
> > https://static-content.springer.com/esm/art%3A10.
> 1186%2F1471-2164-14-860/MediaObjects/12864_2013_5591_MOESM1_ESM.doc).
> > How to get that matrix from lme4?
> >
> >
> > Warm Regards,
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From tibor at linguistics.rub.de  Fri Sep 23 07:03:36 2016
From: tibor at linguistics.rub.de (Tibor Kiss)
Date: Fri, 23 Sep 2016 07:03:36 +0200
Subject: [R-sig-ME] mhglm as a substitute for glmer in case of
	quasi-complete separation
Message-ID: <1A42F5FB-0310-421F-A810-EDC49E278287@linguistics.rub.de>

Hello,

I have a question emerging from a case of quasi-complete separation (as I understand it): I am working on a random-intercept GLMM, where one of my predictors has eight levels, one of which seems to lead to quasi-complete separation, as the dependent variable has a (0/260) distribution for this level. In any case, the standard error for this level is about 20 times as high as its coefficient, and consequently, the the Pr(z) is greater 0.95.

I understand that Firth's penalized likelihood method is the method of choice, and hence used mhglm (from mbest), which allows for glmms with one random factor. The problem with the aforementioned level disappears but the coefficients are differ largely from the one provided by glmer. mhglm deals with the offending level, but also turns other factors that have always received Pr(z) < 0.05 with values above 0.05. 

Here are my questions: Does anybody on this list have experience with mbest and mhglm in particular, or is there another alternative for mixed models? Is there another way to tweak glmer so that Firth's logistic regression can be included into glmer?

Thanks

T.
   

   	 	
Prof. Dr. Tibor Kiss, Sprachwissenschaftliches Institut
Ruhr-Universit?t Bochum D-44780 Bochum
Office: +49-234-322-5114

 


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 23 13:11:57 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 23 Sep 2016 07:11:57 -0400
Subject: [R-sig-ME] mhglm as a substitute for glmer in case of
 quasi-complete separation
In-Reply-To: <1A42F5FB-0310-421F-A810-EDC49E278287@linguistics.rub.de>
References: <1A42F5FB-0310-421F-A810-EDC49E278287@linguistics.rub.de>
Message-ID: <068a7bcb-e36f-c1f6-ab0d-3b64156557ff@gmail.com>



On 16-09-23 01:03 AM, Tibor Kiss wrote:
> Hello,
> 
> I have a question emerging from a case of quasi-complete separation
> (as I understand it): I am working on a random-intercept GLMM, where
> one of my predictors has eight levels, one of which seems to lead to
> quasi-complete separation, as the dependent variable has a (0/260)
> distribution for this level. In any case, the standard error for this
> level is about 20 times as high as its coefficient, and consequently,
> the the Pr(z) is greater 0.95.
> 
> I understand that Firth's penalized likelihood method is the method
> of choice, and hence used mhglm (from mbest), which allows for glmms
> with one random factor. The problem with the aforementioned level
> disappears but the coefficients are differ largely from the one
> provided by glmer. mhglm deals with the offending level, but also
> turns other factors that have always received Pr(z) < 0.05 with
> values above 0.05.
> 
> Here are my questions: Does anybody on this list have experience with
> mbest and mhglm in particular, or is there another alternative for
> mixed models? Is there another way to tweak glmer so that Firth's
> logistic regression can be included into glmer?
> 
> Thanks
> 
> T.
> 
> 
>  Prof. Dr. Tibor Kiss, Sprachwissenschaftliches Institut 
> Ruhr-Universit?t Bochum D-44780 Bochum Office: +49-234-322-5114
> 

  Other solutions I have tried in the past:

  - Imposing a weakly informative prior on the fixed effects via either
MCMCglmm or blmer
  - Doing likelihood ratio tests (i.e.
anova(full_model,reduced_model_without_focal_term), which unlike the
Wald Z/p values in summary(), aren't strongly affected by complete
separation

http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#digression-complete-separation

 has an example of the former.


From tim.cole at ucl.ac.uk  Fri Sep 23 15:50:55 2016
From: tim.cole at ucl.ac.uk (Cole, Tim)
Date: Fri, 23 Sep 2016 13:50:55 +0000
Subject: [R-sig-ME] varIdent warnings in nlme
Message-ID: <D40AE12E.4E665%tim.cole@ucl.ac.uk>

I'm getting lots of warnings:

In conLin$Xy * varWeights(object) :
longer object length is not a multiple of shorter object length

when using varIdent for weights in nlme. I see that the problem has been flagged several times since 2004, but I'm an optimist and I wondered if there was a workaround or fix. Despite the warnings, the results seem to be correct.

If anyone has any experience of this I'd be interested to hear.

Here are some examples from my CRAN R sitar growth curves package, with data from the heights database. I've unpacked the sitar call to show the nlme call. I'm not too bothered about the singularities, which look to be data-driven, just the warnings.

  if (!require(sitar)) install.packages('sitar')
  library(sitar)
  data(heights)

  names(heights)[2:3] <- c('x', 'y')
  heights$x <- scale(heights$x, scale=FALSE)
  df <- 6
  knots <- with(heights, quantile(x, (1:(df-1))/df))
  bounds <- with(heights, range(x) + abs(0.04) * c(-1,1) * diff(range(x)))
  start <- with(heights, lm(y ~ ns(x, knots=knots, Bound=bounds)))$coef
  start <- c(start[c(2:(df+1), 1)], 0, 0)

  fitnlme <- function(x,s1,s2,s3,s4,s5,s6,a,b,c) {
    as.vector(a +
      (as.matrix(cbind(s1,s2,s3,s4,s5,s6)) * as.matrix(ns((x-b) * exp(c),
        knots=knots, Bound=bounds))) %*% matrix(rep(1,df), ncol=1))
  }

  test <- function(...) {
# NLME CALL HERE
    invisible(nlme(y ~ fitnlme(x,s1,s2,s3,s4,s5,s6,a,b,c), data = heights,
             fixed = s1+s2+s3+s4+s5+s6+a+b+c ~ 1,
             random = a+b+c ~ 1 | id, start = start, ...))
  }

  test() # THE MODEL WITHOUT weights WORKS FINE

  heights$wt1 <- factor(as.numeric(heights$id) > 6) # split 63:61 GROUPING FACTOR FOR varIdent
  heights$wt2 <- factor(heights$id == 12) # split 120:4 ALTERNATIVE GROUPING FACTOR

  ratio <- 1e3 # c(0.5, 1:5, 10^(1:6)) # DIFFERENT RATIOS FOR value AND fixed IN varIdent
  var <- c(`TRUE`=ratio)

# RESULTS HERE FOR DIFFERENT FORMS OF varIdent AND DIFFERENT VALUES OF ratio

  test(weights=Initialize(varIdent(form=~1|wt1), heights)) # ok
  test(weights=Initialize(varIdent(form=~1|wt2), heights)) # Singularity
  test(weights=Initialize(varIdent(var, form=~1|wt1), heights)) # ok
  test(weights=Initialize(varIdent(var, form=~1|wt2), heights)) # Singularity, all ratios
  test(weights=Initialize(varIdent(form=~1|wt1, fixed=var), heights)) # warnings / Singularity depending on ratio
  test(weights=Initialize(varIdent(form=~1|wt2, fixed=var), heights)) # warnings

Thanks if you've read this far.

Best wishes,
Tim Cole
---
Tim.cole at ucl.ac.uk<mailto:Tim.cole at ucl.ac.uk> Phone +44(0)20 7905 2666 Fax +44(0)20 7905 2381
Population, Policy and Practice Programme
UCL Great Ormond Street Institute of Child Health, London WC1N 1EH, UK


	[[alternative HTML version deleted]]


From quentin.schorpp at thuenen.de  Tue Sep 27 21:02:53 2016
From: quentin.schorpp at thuenen.de (Quentin Schorpp)
Date: Tue, 27 Sep 2016 21:02:53 +0200 (CEST)
Subject: [R-sig-ME] The role of the Null Model
Message-ID: <50f40bc0bc89652e22936a6133ae397f.squirrel@webmail.thuenen.de>


Hello,

This is probably the wrong forum for such a question, but at the moment i
don't know who to ask instead.

When analysing data with glmm, at one point it comes to the question of
model selection.
I wrote a paper and got it back with major revisions. For the analysis in
this paper I used Multimodel-Averaging to determine the "best" model as
well as the Average Model of the best model subset within delta 4 AIC
points difference to the "best" model.

Anywhere I read that, if the Null model (fit with intercept only) defined
as, i.e. lmer(response ~ 1 + (1|ranef), data) is incuded within the top
model subset, it means that the data were insufficient for unveiling an
effect of any of the chosen explanatory variables. Hence I wrote it in my
paper. Now the reviewer wants an explanation on the reasons for that and
asks if we made too less sampling efforts in our investigation.

Can someone tell me if I was rigth with my statement, and probably provide
literature for citation?

Thank you very much and kind regards,
Quentin


From domprinsloo at gmail.com  Tue Sep 27 21:27:20 2016
From: domprinsloo at gmail.com (Dominique Prinsloo)
Date: Tue, 27 Sep 2016 21:27:20 +0200
Subject: [R-sig-ME] Attention Ben Bolker: Issues with glmer.nb() in R
Message-ID: <CANb4-6Sy8umSbGTM0FxkCy_yggcMXMETfpxh+_Lkfm+Z76aLzA@mail.gmail.com>

Hi Ben

I hope you are well. I have some issues regarding the structure of a GLMM
in R using the glmer.nb().

I have posted this question on Cross Validated at this link:
http://stats.stackexchange.com/questions/237216/how-do-you-structure-a-glmm-using-a-glmer-nb-in-r

Here is the question and attached is a csv. file with a sample dataset.

I want to find out what variable affects the number of fish counts.
FishCounts is my response variable and it needs to be offset by the
InitialNumberPerQuadrat. I have three fixed effects that I want to test:
DaysSinceRelease, SizeRanking and SeededDensity or the interactions between
them. There are 18 sites and each Site was sampled up to 3 times (
SampleRound 1, 2 or 3) in the period of 600 days, therefore my random
variables need to take into account the repeated measures. The most
appropriate distribution for my response variable was the Negative Binomial
distribution as it had the lowest AIC value.

Firstly, should i use glmer() and then stipulate family=negative.binomial?
Or should I use glmer.nb()?

I have tried both ways but the glmer.nb() allows me to offset my variable
which is what I need to do. So have I structured the code correctly? Are
the random variables correct and do they account for the repeated measures?

model1 <- glmer.nb(FishCounts ~ DaysSinceRelease * SizeRanking *
SeededDensity + (1|Site)+(1|SampleRound),
offset(InitialNumberPerQuadrat),data = x))

When I run this code, I keep getting the following error: 'control' is not
a list; use glmerControl()?
Please help me as i'm getting desperate to figure this out.

Thanks
Dominique

From mbrooks at ufl.edu  Tue Sep 27 22:35:53 2016
From: mbrooks at ufl.edu (Mollie Brooks)
Date: Tue, 27 Sep 2016 22:35:53 +0200
Subject: [R-sig-ME] Attention Ben Bolker: Issues with glmer.nb() in R
In-Reply-To: <CANb4-6Sy8umSbGTM0FxkCy_yggcMXMETfpxh+_Lkfm+Z76aLzA@mail.gmail.com>
References: <CANb4-6Sy8umSbGTM0FxkCy_yggcMXMETfpxh+_Lkfm+Z76aLzA@mail.gmail.com>
Message-ID: <E966E123-8D1A-4BE4-9E0E-1A7C4F772FFA@ufl.edu>

Hi Dominique,

It looks like you specified the offset in model1 in the wrong way and that is causing the error.
Try
model1 <- glmer.nb(FishCounts ~ DaysSinceRelease * SizeRanking *
SeededDensity + (1|Site)+(1|SampleRound) +
offset(InitialNumberPerQuadrat),data = x))

Because of the log-link, you probably actually want
offset(log(InitialNumberPerQuadrat))

Your csv file was removed by the mail server. So I haven?t looked at your data.

You can?t use AIC to choose the best distribution until you?ve fitted models with the various distributions. Use AIC on the fitted models.

Mollie

> On 27Sep 2016, at 21:27, Dominique Prinsloo <domprinsloo at gmail.com> wrote:
> 
> Hi Ben
> 
> I hope you are well. I have some issues regarding the structure of a GLMM
> in R using the glmer.nb().
> 

> I have posted this question on Cross Validated at this link:
> http://stats.stackexchange.com/questions/237216/how-do-you-structure-a-glmm-using-a-glmer-nb-in-r
> 
> Here is the question and attached is a csv. file with a sample dataset.
> 
> I want to find out what variable affects the number of fish counts.
> FishCounts is my response variable and it needs to be offset by the
> InitialNumberPerQuadrat. I have three fixed effects that I want to test:
> DaysSinceRelease, SizeRanking and SeededDensity or the interactions between
> them. There are 18 sites and each Site was sampled up to 3 times (
> SampleRound 1, 2 or 3) in the period of 600 days, therefore my random
> variables need to take into account the repeated measures. The most
> appropriate distribution for my response variable was the Negative Binomial
> distribution as it had the lowest AIC value.
> 
> Firstly, should i use glmer() and then stipulate family=negative.binomial?
> Or should I use glmer.nb()?
> 
> I have tried both ways but the glmer.nb() allows me to offset my variable
> which is what I need to do. So have I structured the code correctly? Are
> the random variables correct and do they account for the repeated measures?
> 
> model1 <- glmer.nb(FishCounts ~ DaysSinceRelease * SizeRanking *
> SeededDensity + (1|Site)+(1|SampleRound),
> offset(InitialNumberPerQuadrat),data = x))
> 
> When I run this code, I keep getting the following error: 'control' is not
> a list; use glmerControl()?
> Please help me as i'm getting desperate to figure this out.
> 
> Thanks
> Dominique
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From kamokoi55 at gmail.com  Thu Sep 29 19:36:42 2016
From: kamokoi55 at gmail.com (Mark Albins)
Date: Thu, 29 Sep 2016 12:36:42 -0500
Subject: [R-sig-ME] Error in glmmADMB: no PSV file found -- link to known
	fix is broken
Message-ID: <CA+DkWK+ybzPsFNyUNFcR5wonCFM4MNwSen9FLx75CnbCfmb5Tw@mail.gmail.com>

Hi r-sig-ME-ers,

I'm running a glmmADMB model with a single random effect, zero inflation,
and a negative binomial distribution (session info below).  The model seems
to run fine on its own (i.e. no error message, sensible outcome, etc.), but
throws a "no PSV file found" error when I try to run it with mcmc = TRUE.

I found the following solution to a similar problem posted here on the
r-sig-ME list:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024490.html

Unfortunately, when I tried to follow the instructions at:

http://glmmadmb.r-forge.r-project.org/

..I found the link to the "Buildbot page" was broken...

http://www.admb-project.org/buildbot/glmmadmb/

A google search for "glmmADMB buildbot page" did not uncover any obvious
alternate locations for the various OS compatible binaries.

I don't know how to build the binary from its TPL on my system.

Any suggestions?

Thanks!

Mark Albins

R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] glmmADMB_0.8.3.3 MASS_7.3-45      ggplot2_2.1.0    lattice_0.20-33
[5] nlme_3.1-128

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.6      digest_0.6.10    grid_3.3.1       plyr_1.8.4
 [5] gtable_0.2.0     magrittr_1.5     coda_0.18-1      scales_0.4.0
 [9] stringi_1.1.1    Matrix_1.2-6     labeling_0.3     tools_3.3.1
[13] stringr_1.1.0    munsell_0.4.3    colorspace_1.2-6 R2admb_0.7.13

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Sep 29 21:02:20 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Sep 2016 15:02:20 -0400
Subject: [R-sig-ME] Error in glmmADMB: no PSV file found -- link to
 known fix is broken
In-Reply-To: <CA+DkWK+ybzPsFNyUNFcR5wonCFM4MNwSen9FLx75CnbCfmb5Tw@mail.gmail.com>
References: <CA+DkWK+ybzPsFNyUNFcR5wonCFM4MNwSen9FLx75CnbCfmb5Tw@mail.gmail.com>
Message-ID: <370c94fd-c256-8a12-4c8b-f247c7b855e7@gmail.com>


  The ADMB web site migrated in the recent past, apparently breaking
this link.  I have an e-mail in to the site maintainer to ask if there's
a way to restore this link ...

  cheers
    Ben Bolker

On 16-09-29 01:36 PM, Mark Albins wrote:
> Hi r-sig-ME-ers,
> 
> I'm running a glmmADMB model with a single random effect, zero inflation,
> and a negative binomial distribution (session info below).  The model seems
> to run fine on its own (i.e. no error message, sensible outcome, etc.), but
> throws a "no PSV file found" error when I try to run it with mcmc = TRUE.
> 
> I found the following solution to a similar problem posted here on the
> r-sig-ME list:
> 
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024490.html
> 
> Unfortunately, when I tried to follow the instructions at:
> 
> http://glmmadmb.r-forge.r-project.org/
> 
> ..I found the link to the "Buildbot page" was broken...
> 
> http://www.admb-project.org/buildbot/glmmadmb/
> 
> A google search for "glmmADMB buildbot page" did not uncover any obvious
> alternate locations for the various OS compatible binaries.
> 
> I don't know how to build the binary from its TPL on my system.
> 
> Any suggestions?
> 
> Thanks!
> 
> Mark Albins
> 
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.8.3.3 MASS_7.3-45      ggplot2_2.1.0    lattice_0.20-33
> [5] nlme_3.1-128
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.6      digest_0.6.10    grid_3.3.1       plyr_1.8.4
>  [5] gtable_0.2.0     magrittr_1.5     coda_0.18-1      scales_0.4.0
>  [9] stringi_1.1.1    Matrix_1.2-6     labeling_0.3     tools_3.3.1
> [13] stringr_1.1.0    munsell_0.4.3    colorspace_1.2-6 R2admb_0.7.13
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Thu Sep 29 21:59:27 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 29 Sep 2016 15:59:27 -0400
Subject: [R-sig-ME] Error in glmmADMB: no PSV file found -- link to
 known fix is broken
In-Reply-To: <CAJMx2XW-1tVuQDhAwZCN3iwWLJM08jvBQ4F+x0495Y6BPy49Eg@mail.gmail.com>
References: <CAJMx2XW-1tVuQDhAwZCN3iwWLJM08jvBQ4F+x0495Y6BPy49Eg@mail.gmail.com>
Message-ID: <468aba9b-c9c3-8fe7-1291-58aea7535355@gmail.com>



The maintainer has let me know the new URL is
http://buildbot.admb-project.org/glmmadmb/ . I'll update the
documentation/web page

    -------- Forwarded Message --------
    Subject: [R-sig-ME] Error in glmmADMB: no PSV file found -- link to
    known fix is broken
    Date: Thu, 29 Sep 2016 12:36:42 -0500
    From: Mark Albins <kamokoi55 at gmail.com <mailto:kamokoi55 at gmail.com>>
    To: r-sig-mixed-models at r-project.org
    <mailto:r-sig-mixed-models at r-project.org>

    Hi r-sig-ME-ers,

    I'm running a glmmADMB model with a single random effect, zero
    inflation,
    and a negative binomial distribution (session info below).  The
    model seems
    to run fine on its own (i.e. no error message, sensible outcome,
    etc.), but
    throws a "no PSV file found" error when I try to run it with mcmc =
    TRUE.

    I found the following solution to a similar problem posted here on the
    r-sig-ME list:

    https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024490.html
    <https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q1/024490.html>

    Unfortunately, when I tried to follow the instructions at:

    http://glmmadmb.r-forge.r-project.org/
    <http://glmmadmb.r-forge.r-project.org/>

    ..I found the link to the "Buildbot page" was broken...

    http://www.admb-project.org/buildbot/glmmadmb/
    <http://www.admb-project.org/buildbot/glmmadmb/>

    A google search for "glmmADMB buildbot page" did not uncover any obvious
    alternate locations for the various OS compatible binaries.

    I don't know how to build the binary from its TPL on my system.

    Any suggestions?

    Thanks!

    Mark Albins

    R version 3.3.1 (2016-06-21)
    Platform: x86_64-w64-mingw32/x64 (64-bit)
    Running under: Windows 7 x64 (build 7601) Service Pack 1

    locale:
    [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
    States.1252
    [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
    [5] LC_TIME=English_United States.1252

    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods   base

    other attached packages:
    [1] glmmADMB_0.8.3.3 MASS_7.3-45      ggplot2_2.1.0    lattice_0.20-33
    [5] nlme_3.1-128

    loaded via a namespace (and not attached):
     [1] Rcpp_0.12.6      digest_0.6.10    grid_3.3.1       plyr_1.8.4
     [5] gtable_0.2.0     magrittr_1.5     coda_0.18-1      scales_0.4.0
     [9] stringi_1.1.1    Matrix_1.2-6     labeling_0.3     tools_3.3.1
    [13] stringr_1.1.0    munsell_0.4.3    colorspace_1.2-6 R2admb_0.7.13

            [[alternative HTML version deleted]]

    _______________________________________________
    R-sig-mixed-models at r-project.org
    <mailto:R-sig-mixed-models at r-project.org> mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


From carbrae at gmail.com  Thu Sep 29 22:16:31 2016
From: carbrae at gmail.com (Bradley Carlson)
Date: Thu, 29 Sep 2016 16:16:31 -0400
Subject: [R-sig-ME] Using bootMer for random and fixed effects
Message-ID: <CAF37_NcxkO3o4+R2G3ZPaCC_k1WnWAynQHZH9MqN5dJqYt-dGQ@mail.gmail.com>

Hello,

I'm trying to establish 95% CIs for both the variance for a random
intercept and for the slopes of each fixed effect in lmer models. The
random intercept represents about 30 individual animals, and fixed effects
represent covariates that may be associated with behavior. There are 8
observations per individual animal. The fixed effects in some models are
all constant for an individual (e.g., sex); the fixed effects in other
models vary within individuals (e.g., body temperature at testing).

My approach has been bootstrapping with the bootMer and boot.ci functions
in the "boot" package. I started off using the arguments type =
"semiparametric" and use.u =TRUE to bootstrap the random intercept
variance; this was on the basis of my interpretation of Ben Bolker's
suggestion elsewhere
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q2/018686.html> to
resample the random effects (maybe I understood wrong). The random
intercept 95% CI seemed reasonable.

When I use the same arguments for bootstrapping the fixed effects, I get
95% CIs that seem far too narrow in cases in which the fixed effect is
constant within individuals. Example: for the fixed effect of sex, the lmer
model summary provides an estimated beta of 0.64 (males), SE of 1.10, and t
of 0.58 - which is far from looking significant - then produces a bootstrap
95% CI of (0.21, 1.04) - which I interpret as significant (not containing
0). This tells me I'm doing something wrong.

My questions are:
1) Have I made reasonable choices about the "type=" and "use.u=" arguments,
for either random intercept variance or fixed effects? If no, how should I
approach this? If yes, why do coefficients/SE/t value disagree with
bootstrapped 95% CIs?

2) Does the decision about those arguments matter when applying them to
fixed effects that vary within individuals vs. fixed effects that are
constant within individuals?

Thank you very much for considering my question,

Brad

--
Bradley E. Carlson

Assistant Professor of Biology
Wabash College
Crawfordsville, IN 47933
Website: carlsonecolab.weebly.com

	[[alternative HTML version deleted]]


From brenden at anr.msu.edu  Fri Sep 30 16:53:27 2016
From: brenden at anr.msu.edu (Brenden, Travis)
Date: Fri, 30 Sep 2016 14:53:27 +0000
Subject: [R-sig-ME] Random effect distributions varying by factor level in
 an nlme() repeated measures model
Message-ID: <a5301b159e634536b53ce4c65e435de3@EXCHATS14001.collegemail.msu.edu>

I've checked the archives for similar posts to my question below and found similar questions but never a satisfying answer.  Links to these previous questions are here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020655.html

I'm trying to fit a nonlinear mixed-effects growth model using nlme() to some length and age data for a fish population.  The data are repeated measures from nearly 400 individuals of both male and female fish.  It is easy enough to fit a nonlinear model incorporating sex as a fixed effect for each of the model parameters and then include a random effect for individuals for each of the parameters.
> library(FSAdata)
> library(nlme)
>
> #load the data and subset to the year that will be analyzed
> data(WalleyeML)
> wml.01 <- filterD(WalleyeML,Year==2001)
>
> #Define the nonlinear growth function to be estimated
> gomplog <- function(T,logLinf,tstar,gstar) {
+   exp(logLinf)*exp(-exp(-gstar*(T-tstar)))
+ }
>
> #Fit a model with sex-specific population average parameter estimates
> #and individual-specific deviations assuming a constant distribution
> #across sexes for the deviations
> fit.01 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~Sex,
+                  random=logLinf+tstar+gstar~1|ID,
+                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
+                  weights=varPower(form=~BC.Age))
> fixef(fit.01)
logLinf.(Intercept)        logLinf.SexM   tstar.(Intercept)          tstar.SexM   gstar.(Intercept)
         6.36279069         -0.14087373          1.92551175         -0.23136899          0.54801947
         gstar.SexM
         0.05194933 head(ranef(fit.01))
> head(ranef(fit.01))
            logLinf.(Intercept) tstar.(Intercept) gstar.(Intercept)
2001.2392.F         0.015789108       -0.05055326      -0.036448467
2001.2470.M         0.114106528        0.10101465      -0.110922370
2001.2889.F         0.024976125       -0.17716804      -0.036499377
2001.3138.F         0.040140160       -0.06361609       0.048073911
2001.3139.M        -0.006431748        0.31297354      -0.009468046
2001.3147.M         0.039636492        0.48169423      -0.256690199
(the first column above is the identifier for an individual fish where the last letter indicates if that individual is male (M) or female (F).


However, I'm interested in having the underlying probability distributions for the random effects be different for males and females.  In other words, I would like to have the random effects for males generated from a MVN(0,Sigma) distribution and the random effects for females  generated from a MVN(0,Sigma1) distribution where Sigma and Sigma1 are different.  Males and females can have very different growth patterns, with female fish often getting quite a bit larger than males.  Therefore it seems reasonable that there perhaps would be greater variability in random effects for females than for males.  I can't say this for sure but would like to at least see.  I originally thought the following nlme() call would work.

> fit.02 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~Sex,
+                  random=logLinf+tstar+gstar~Sex|ID,
+                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
+                  weights=varPower(form=~BC.Age))

But if you look at the random effect estimates from this fitted model, it appears that 2 sets of random effects are generated for each parameter and that they apply to every individual regardless of their sex, which is not what I am looking for although perhaps I am mis-interpreting this output.  If I had coded this correctly, I would expect to see the .(Intercept) random effects functionally be 0 for males and the .SexM random effects functionally be 0 for females.
> head(ranef(fit.02))
            logLinf.(Intercept)  logLinf.SexM tstar.(Intercept)  tstar.SexM gstar.(Intercept)
2001.2392.F          0.01492824 -0.0021143909       -0.05017410  0.03296103      -0.033336005
2001.2470.M          0.13741234 -0.0251483452        0.19731797 -0.10774971      -0.113328192
2001.2889.F          0.02000375 -0.0025014450       -0.19655379  0.08813044      -0.026224542
2001.3138.F          0.04430510 -0.0112679068       -0.05814585 -0.01257797       0.042181315
2001.3139.M         -0.01154091 -0.0001006231        0.18061890  0.12099219      -0.003301668
2001.3147.M          0.05160132 -0.0134577925        0.40190910  0.06730332      -0.205363908
               gstar.SexM
2001.2392.F -3.205562e-03
2001.2470.M  8.861980e-05
2001.2889.F -9.362266e-05
2001.3138.F  1.386004e-02
2001.3139.M -4.230159e-03
2001.3147.M -5.382077e-02

It doesn't make sense to treat Sex as a random effect because there are only two levels.  If I could treat Sex as a random effect then the following model call would work with the random effect of ID nested within the random effect of Sex.  But I'm rather interested in having the random effect of ID nested within the fixed effect of Sex.   There shouldn't be any issue of sample size as the dataset are there are about 188 individual males (1010 total observations) and 199 individual females (1138 total observations) in the dataset.

> fit.03 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~1,
+                  random=list(Sex=logLinf+tstar+gstar~1,ID=logLinf+tstar+gstar~1
+                  start=list(fixed=c(6.0,2.0,0.5)),
+                  weights=varPower(form=~BC.Age))

I've tried other model calls but with no success. Again, I realize questions similar to this have posted but I have not seen an answer as to how this could be implement in nlme() if at all.  Any suggestions would be appreciated.  Thank you.

Travis Brenden
Department of Fisheries and Wildlife
Michigan State University


	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Fri Sep 30 21:28:06 2016
From: jdpo223 at g.uky.edu (Poe, John)
Date: Fri, 30 Sep 2016 15:28:06 -0400
Subject: [R-sig-ME] Random effect distributions varying by factor level
 in an nlme() repeated measures model
In-Reply-To: <a5301b159e634536b53ce4c65e435de3@EXCHATS14001.collegemail.msu.edu>
References: <a5301b159e634536b53ce4c65e435de3@EXCHATS14001.collegemail.msu.edu>
Message-ID: <CAFW8ByqhMftxObyFabFGjHDFzkF484NGPQ9g7MU3jjrf2bJwCg@mail.gmail.com>

If it's only two groups and sample size isn't an issue then why not just
estimate a model for males and one for females then predict their random
effects distributions and compare them?

On Fri, Sep 30, 2016 at 10:53 AM, Brenden, Travis <brenden at anr.msu.edu>
wrote:

> I've checked the archives for similar posts to my question below and found
> similar questions but never a satisfying answer.  Links to these previous
> questions are here https://stat.ethz.ch/pipermail/r-sig-mixed-models/
> 2013q3/020655.html
>
> I'm trying to fit a nonlinear mixed-effects growth model using nlme() to
> some length and age data for a fish population.  The data are repeated
> measures from nearly 400 individuals of both male and female fish.  It is
> easy enough to fit a nonlinear model incorporating sex as a fixed effect
> for each of the model parameters and then include a random effect for
> individuals for each of the parameters.
> > library(FSAdata)
> > library(nlme)
> >
> > #load the data and subset to the year that will be analyzed
> > data(WalleyeML)
> > wml.01 <- filterD(WalleyeML,Year==2001)
> >
> > #Define the nonlinear growth function to be estimated
> > gomplog <- function(T,logLinf,tstar,gstar) {
> +   exp(logLinf)*exp(-exp(-gstar*(T-tstar)))
> + }
> >
> > #Fit a model with sex-specific population average parameter estimates
> > #and individual-specific deviations assuming a constant distribution
> > #across sexes for the deviations
> > fit.01 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~Sex,
> +                  random=logLinf+tstar+gstar~1|ID,
> +                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
> +                  weights=varPower(form=~BC.Age))
> > fixef(fit.01)
> logLinf.(Intercept)        logLinf.SexM   tstar.(Intercept)
> tstar.SexM   gstar.(Intercept)
>          6.36279069         -0.14087373          1.92551175
>  -0.23136899          0.54801947
>          gstar.SexM
>          0.05194933 head(ranef(fit.01))
> > head(ranef(fit.01))
>             logLinf.(Intercept) tstar.(Intercept) gstar.(Intercept)
> 2001.2392.F         0.015789108       -0.05055326      -0.036448467
> 2001.2470.M         0.114106528        0.10101465      -0.110922370
> 2001.2889.F         0.024976125       -0.17716804      -0.036499377
> 2001.3138.F         0.040140160       -0.06361609       0.048073911
> 2001.3139.M        -0.006431748        0.31297354      -0.009468046
> 2001.3147.M         0.039636492        0.48169423      -0.256690199
> (the first column above is the identifier for an individual fish where the
> last letter indicates if that individual is male (M) or female (F).
>
>
> However, I'm interested in having the underlying probability distributions
> for the random effects be different for males and females.  In other words,
> I would like to have the random effects for males generated from a
> MVN(0,Sigma) distribution and the random effects for females  generated
> from a MVN(0,Sigma1) distribution where Sigma and Sigma1 are different.
> Males and females can have very different growth patterns, with female fish
> often getting quite a bit larger than males.  Therefore it seems reasonable
> that there perhaps would be greater variability in random effects for
> females than for males.  I can't say this for sure but would like to at
> least see.  I originally thought the following nlme() call would work.
>
> > fit.02 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~Sex,
> +                  random=logLinf+tstar+gstar~Sex|ID,
> +                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
> +                  weights=varPower(form=~BC.Age))
>
> But if you look at the random effect estimates from this fitted model, it
> appears that 2 sets of random effects are generated for each parameter and
> that they apply to every individual regardless of their sex, which is not
> what I am looking for although perhaps I am mis-interpreting this output.
> If I had coded this correctly, I would expect to see the .(Intercept)
> random effects functionally be 0 for males and the .SexM random effects
> functionally be 0 for females.
> > head(ranef(fit.02))
>             logLinf.(Intercept)  logLinf.SexM tstar.(Intercept)
> tstar.SexM gstar.(Intercept)
> 2001.2392.F          0.01492824 -0.0021143909       -0.05017410
> 0.03296103      -0.033336005
> 2001.2470.M          0.13741234 -0.0251483452        0.19731797
> -0.10774971      -0.113328192
> 2001.2889.F          0.02000375 -0.0025014450       -0.19655379
> 0.08813044      -0.026224542
> 2001.3138.F          0.04430510 -0.0112679068       -0.05814585
> -0.01257797       0.042181315
> 2001.3139.M         -0.01154091 -0.0001006231        0.18061890
> 0.12099219      -0.003301668
> 2001.3147.M          0.05160132 -0.0134577925        0.40190910
> 0.06730332      -0.205363908
>                gstar.SexM
> 2001.2392.F -3.205562e-03
> 2001.2470.M  8.861980e-05
> 2001.2889.F -9.362266e-05
> 2001.3138.F  1.386004e-02
> 2001.3139.M -4.230159e-03
> 2001.3147.M -5.382077e-02
>
> It doesn't make sense to treat Sex as a random effect because there are
> only two levels.  If I could treat Sex as a random effect then the
> following model call would work with the random effect of ID nested within
> the random effect of Sex.  But I'm rather interested in having the random
> effect of ID nested within the fixed effect of Sex.   There shouldn't be
> any issue of sample size as the dataset are there are about 188 individual
> males (1010 total observations) and 199 individual females (1138 total
> observations) in the dataset.
>
> > fit.03 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~1,
> +                  random=list(Sex=logLinf+tstar+gstar~1,ID=logLinf+tstar+
> gstar~1
> +                  start=list(fixed=c(6.0,2.0,0.5)),
> +                  weights=varPower(form=~BC.Age))
>
> I've tried other model calls but with no success. Again, I realize
> questions similar to this have posted but I have not seen an answer as to
> how this could be implement in nlme() if at all.  Any suggestions would be
> appreciated.  Thank you.
>
> Travis Brenden
> Department of Fisheries and Wildlife
> Michigan State University
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 




Thanks,
John


John Poe
Doctoral Candidate
Department of Political Science
Research Methodologist
UK Center for Public Health Services & Systems Research
University of Kentucky
111 Washington Avenue, Room 203a
Lexington, KY 40536
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Fri Sep 30 22:15:52 2016
From: jdpo223 at g.uky.edu (Poe, John)
Date: Fri, 30 Sep 2016 16:15:52 -0400
Subject: [R-sig-ME] Random effect distributions varying by factor level
 in an nlme() repeated measures model
In-Reply-To: <45f03ad1fc634af48ddefc558708aa79@EXCHATS14001.collegemail.msu.edu>
References: <a5301b159e634536b53ce4c65e435de3@EXCHATS14001.collegemail.msu.edu>
	<CAFW8ByqhMftxObyFabFGjHDFzkF484NGPQ9g7MU3jjrf2bJwCg@mail.gmail.com>
	<45f03ad1fc634af48ddefc558708aa79@EXCHATS14001.collegemail.msu.edu>
Message-ID: <CAFW8Byrq4PpBUWcLmQqryH2xn8bfBpwEQF9gnzvH2jB_1P_+Gw@mail.gmail.com>

Using a bayesian framework instead of a standard likelihood based
estimation of random effects should make it much easier to calculate
different random effects by sex. Alternatively, you could *probably* figure
it out in a structural equation modeling framework if you were bound and
determined to stay with MLE. I don't think there's a way to do this
properly in nlme short of just splitting the data.

I think you are right that it's probably not detrimental to your particular
case since you know sex is the major driver of differences in the variance
for the random effect and you are removing the distortion by adding it as a
fixed effect.

On Fri, Sep 30, 2016 at 4:00 PM, Brenden, Travis <brenden at anr.msu.edu>
wrote:

> John, Thank you for the response.  That is certainly a fall-back option in
> this particular case.  I guess I?m trying to think about this more broadly
> as to whether/how this type of model could be implemented in nlme().  It is
> straightforward to implement in something like jags, but perhaps its
> structure isn?t amenable to nlme() format?  I would be fine with this and
> could then just move on. I just didn?t want to conclude that without
> checking with others as to whether there is a solution to this that I am
> just missing.  Alternatively, perhaps there isn?t really a ?cost?
> associated with a common variance-covariance for the random effects for all
> individuals even if one of the factor levels (in this case female sex) is
> thought to be more variable as it would ?subsume? the variability in the
> other factor level (male sex).
>
>
>
> Travis
>
>
>
> *From:* Poe, John [mailto:jdpo223 at g.uky.edu]
> *Sent:* Friday, September 30, 2016 3:28 PM
> *To:* Brenden, Travis <brenden at anr.msu.edu>
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Random effect distributions varying by factor
> level in an nlme() repeated measures model
>
>
>
> If it's only two groups and sample size isn't an issue then why not just
> estimate a model for males and one for females then predict their random
> effects distributions and compare them?
>
>
>
> On Fri, Sep 30, 2016 at 10:53 AM, Brenden, Travis <brenden at anr.msu.edu>
> wrote:
>
> I've checked the archives for similar posts to my question below and found
> similar questions but never a satisfying answer.  Links to these previous
> questions are here https://stat.ethz.ch/pipermail/r-sig-mixed-models/
> 2013q3/020655.html
>
> I'm trying to fit a nonlinear mixed-effects growth model using nlme() to
> some length and age data for a fish population.  The data are repeated
> measures from nearly 400 individuals of both male and female fish.  It is
> easy enough to fit a nonlinear model incorporating sex as a fixed effect
> for each of the model parameters and then include a random effect for
> individuals for each of the parameters.
> > library(FSAdata)
> > library(nlme)
> >
> > #load the data and subset to the year that will be analyzed
> > data(WalleyeML)
> > wml.01 <- filterD(WalleyeML,Year==2001)
> >
> > #Define the nonlinear growth function to be estimated
> > gomplog <- function(T,logLinf,tstar,gstar) {
> +   exp(logLinf)*exp(-exp(-gstar*(T-tstar)))
> + }
> >
> > #Fit a model with sex-specific population average parameter estimates
> > #and individual-specific deviations assuming a constant distribution
> > #across sexes for the deviations
> > fit.01 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~Sex,
> +                  random=logLinf+tstar+gstar~1|ID,
> +                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
> +                  weights=varPower(form=~BC.Age))
> > fixef(fit.01)
> logLinf.(Intercept)        logLinf.SexM   tstar.(Intercept)
> tstar.SexM   gstar.(Intercept)
>          6.36279069         -0.14087373          1.92551175
>  -0.23136899          0.54801947
>          gstar.SexM
>          0.05194933 head(ranef(fit.01))
> > head(ranef(fit.01))
>             logLinf.(Intercept) tstar.(Intercept) gstar.(Intercept)
> 2001.2392.F         0.015789108       -0.05055326      -0.036448467
> 2001.2470.M         0.114106528        0.10101465      -0.110922370
> 2001.2889.F         0.024976125       -0.17716804      -0.036499377
> 2001.3138.F         0.040140160       -0.06361609       0.048073911
> 2001.3139.M        -0.006431748        0.31297354      -0.009468046
> 2001.3147.M         0.039636492        0.48169423      -0.256690199
> (the first column above is the identifier for an individual fish where the
> last letter indicates if that individual is male (M) or female (F).
>
>
> However, I'm interested in having the underlying probability distributions
> for the random effects be different for males and females.  In other words,
> I would like to have the random effects for males generated from a
> MVN(0,Sigma) distribution and the random effects for females  generated
> from a MVN(0,Sigma1) distribution where Sigma and Sigma1 are different.
> Males and females can have very different growth patterns, with female fish
> often getting quite a bit larger than males.  Therefore it seems reasonable
> that there perhaps would be greater variability in random effects for
> females than for males.  I can't say this for sure but would like to at
> least see.  I originally thought the following nlme() call would work.
>
> > fit.02 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~Sex,
> +                  random=logLinf+tstar+gstar~Sex|ID,
> +                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
> +                  weights=varPower(form=~BC.Age))
>
> But if you look at the random effect estimates from this fitted model, it
> appears that 2 sets of random effects are generated for each parameter and
> that they apply to every individual regardless of their sex, which is not
> what I am looking for although perhaps I am mis-interpreting this output.
> If I had coded this correctly, I would expect to see the .(Intercept)
> random effects functionally be 0 for males and the .SexM random effects
> functionally be 0 for females.
> > head(ranef(fit.02))
>             logLinf.(Intercept)  logLinf.SexM tstar.(Intercept)
> tstar.SexM gstar.(Intercept)
> 2001.2392.F          0.01492824 -0.0021143909       -0.05017410
> 0.03296103      -0.033336005
> 2001.2470.M          0.13741234 -0.0251483452        0.19731797
> -0.10774971      -0.113328192
> 2001.2889.F          0.02000375 -0.0025014450       -0.19655379
> 0.08813044      -0.026224542
> 2001.3138.F          0.04430510 -0.0112679068       -0.05814585
> -0.01257797       0.042181315
> 2001.3139.M         -0.01154091 -0.0001006231        0.18061890
> 0.12099219      -0.003301668
> 2001.3147.M          0.05160132 -0.0134577925        0.40190910
> 0.06730332      -0.205363908
>                gstar.SexM
> 2001.2392.F -3.205562e-03
> 2001.2470.M  8.861980e-05
> 2001.2889.F -9.362266e-05
> 2001.3138.F  1.386004e-02
> 2001.3139.M -4.230159e-03
> 2001.3147.M -5.382077e-02
>
> It doesn't make sense to treat Sex as a random effect because there are
> only two levels.  If I could treat Sex as a random effect then the
> following model call would work with the random effect of ID nested within
> the random effect of Sex.  But I'm rather interested in having the random
> effect of ID nested within the fixed effect of Sex.   There shouldn't be
> any issue of sample size as the dataset are there are about 188 individual
> males (1010 total observations) and 199 individual females (1138 total
> observations) in the dataset.
>
> > fit.03 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
> +                  fixed=logLinf+tstar+gstar~1,
> +                  random=list(Sex=logLinf+tstar+gstar~1,ID=logLinf+tstar+
> gstar~1
> +                  start=list(fixed=c(6.0,2.0,0.5)),
> +                  weights=varPower(form=~BC.Age))
>
> I've tried other model calls but with no success. Again, I realize
> questions similar to this have posted but I have not seen an answer as to
> how this could be implement in nlme() if at all.  Any suggestions would be
> appreciated.  Thank you.
>
> Travis Brenden
> Department of Fisheries and Wildlife
> Michigan State University
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> --
>
>
>
>
>
>
>
>
> Thanks,
>
> John
>
>
>
>
>
> John Poe
>
> Doctoral Candidate
>
> Department of Political Science
>
> Research Methodologist
>
> UK Center for Public Health Services & Systems Research
>
> University of Kentucky
>
> 111 Washington Avenue, Room 203a
>
> Lexington, KY 40536
>
> www.johndavidpoe.com
>



-- 




Thanks,
John


John Poe
Doctoral Candidate
Department of Political Science
Research Methodologist
UK Center for Public Health Services & Systems Research
University of Kentucky
111 Washington Avenue, Room 203a
Lexington, KY 40536
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From brenden at anr.msu.edu  Fri Sep 30 22:00:06 2016
From: brenden at anr.msu.edu (Brenden, Travis)
Date: Fri, 30 Sep 2016 20:00:06 +0000
Subject: [R-sig-ME] Random effect distributions varying by factor level
 in an nlme() repeated measures model
In-Reply-To: <CAFW8ByqhMftxObyFabFGjHDFzkF484NGPQ9g7MU3jjrf2bJwCg@mail.gmail.com>
References: <a5301b159e634536b53ce4c65e435de3@EXCHATS14001.collegemail.msu.edu>
	<CAFW8ByqhMftxObyFabFGjHDFzkF484NGPQ9g7MU3jjrf2bJwCg@mail.gmail.com>
Message-ID: <45f03ad1fc634af48ddefc558708aa79@EXCHATS14001.collegemail.msu.edu>

John, Thank you for the response.  That is certainly a fall-back option in this particular case.  I guess I?m trying to think about this more broadly as to whether/how this type of model could be implemented in nlme().  It is straightforward to implement in something like jags, but perhaps its structure isn?t amenable to nlme() format?  I would be fine with this and could then just move on. I just didn?t want to conclude that without checking with others as to whether there is a solution to this that I am just missing.  Alternatively, perhaps there isn?t really a ?cost? associated with a common variance-covariance for the random effects for all individuals even if one of the factor levels (in this case female sex) is thought to be more variable as it would ?subsume? the variability in the other factor level (male sex).

Travis

From: Poe, John [mailto:jdpo223 at g.uky.edu]
Sent: Friday, September 30, 2016 3:28 PM
To: Brenden, Travis <brenden at anr.msu.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Random effect distributions varying by factor level in an nlme() repeated measures model

If it's only two groups and sample size isn't an issue then why not just estimate a model for males and one for females then predict their random effects distributions and compare them?

On Fri, Sep 30, 2016 at 10:53 AM, Brenden, Travis <brenden at anr.msu.edu<mailto:brenden at anr.msu.edu>> wrote:
I've checked the archives for similar posts to my question below and found similar questions but never a satisfying answer.  Links to these previous questions are here https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020655.html

I'm trying to fit a nonlinear mixed-effects growth model using nlme() to some length and age data for a fish population.  The data are repeated measures from nearly 400 individuals of both male and female fish.  It is easy enough to fit a nonlinear model incorporating sex as a fixed effect for each of the model parameters and then include a random effect for individuals for each of the parameters.
> library(FSAdata)
> library(nlme)
>
> #load the data and subset to the year that will be analyzed
> data(WalleyeML)
> wml.01 <- filterD(WalleyeML,Year==2001)
>
> #Define the nonlinear growth function to be estimated
> gomplog <- function(T,logLinf,tstar,gstar) {
+   exp(logLinf)*exp(-exp(-gstar*(T-tstar)))
+ }
>
> #Fit a model with sex-specific population average parameter estimates
> #and individual-specific deviations assuming a constant distribution
> #across sexes for the deviations
> fit.01 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~Sex,
+                  random=logLinf+tstar+gstar~1|ID,
+                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
+                  weights=varPower(form=~BC.Age))
> fixef(fit.01)
logLinf.(Intercept)        logLinf.SexM   tstar.(Intercept)          tstar.SexM   gstar.(Intercept)
         6.36279069         -0.14087373          1.92551175         -0.23136899          0.54801947
         gstar.SexM
         0.05194933 head(ranef(fit.01))
> head(ranef(fit.01))
            logLinf.(Intercept) tstar.(Intercept) gstar.(Intercept)
2001.2392.F         0.015789108       -0.05055326      -0.036448467
2001.2470.M         0.114106528        0.10101465      -0.110922370
2001.2889.F         0.024976125       -0.17716804      -0.036499377
2001.3138.F         0.040140160       -0.06361609       0.048073911
2001.3139.M        -0.006431748        0.31297354      -0.009468046
2001.3147.M         0.039636492        0.48169423      -0.256690199
(the first column above is the identifier for an individual fish where the last letter indicates if that individual is male (M) or female (F).


However, I'm interested in having the underlying probability distributions for the random effects be different for males and females.  In other words, I would like to have the random effects for males generated from a MVN(0,Sigma) distribution and the random effects for females  generated from a MVN(0,Sigma1) distribution where Sigma and Sigma1 are different.  Males and females can have very different growth patterns, with female fish often getting quite a bit larger than males.  Therefore it seems reasonable that there perhaps would be greater variability in random effects for females than for males.  I can't say this for sure but would like to at least see.  I originally thought the following nlme() call would work.

> fit.02 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~Sex,
+                  random=logLinf+tstar+gstar~Sex|ID,
+                  start=list(fixed=c(6.0,0.0,2.0,0.0,0.5,0.0)),
+                  weights=varPower(form=~BC.Age))

But if you look at the random effect estimates from this fitted model, it appears that 2 sets of random effects are generated for each parameter and that they apply to every individual regardless of their sex, which is not what I am looking for although perhaps I am mis-interpreting this output.  If I had coded this correctly, I would expect to see the .(Intercept) random effects functionally be 0 for males and the .SexM random effects functionally be 0 for females.
> head(ranef(fit.02))
            logLinf.(Intercept)  logLinf.SexM tstar.(Intercept)  tstar.SexM gstar.(Intercept)
2001.2392.F          0.01492824 -0.0021143909       -0.05017410  0.03296103      -0.033336005
2001.2470.M          0.13741234 -0.0251483452        0.19731797 -0.10774971      -0.113328192
2001.2889.F          0.02000375 -0.0025014450       -0.19655379  0.08813044      -0.026224542
2001.3138.F          0.04430510 -0.0112679068       -0.05814585 -0.01257797       0.042181315
2001.3139.M         -0.01154091 -0.0001006231        0.18061890  0.12099219      -0.003301668
2001.3147.M          0.05160132 -0.0134577925        0.40190910  0.06730332      -0.205363908
               gstar.SexM
2001.2392.F -3.205562e-03
2001.2470.M  8.861980e-05
2001.2889.F -9.362266e-05
2001.3138.F  1.386004e-02
2001.3139.M -4.230159e-03
2001.3147.M -5.382077e-02

It doesn't make sense to treat Sex as a random effect because there are only two levels.  If I could treat Sex as a random effect then the following model call would work with the random effect of ID nested within the random effect of Sex.  But I'm rather interested in having the random effect of ID nested within the fixed effect of Sex.   There shouldn't be any issue of sample size as the dataset are there are about 188 individual males (1010 total observations) and 199 individual females (1138 total observations) in the dataset.

> fit.03 <- nlme(BC.Len~gomplog(BC.Age,logLinf,tstar,gstar),data=wml.01,
+                  fixed=logLinf+tstar+gstar~1,
+                  random=list(Sex=logLinf+tstar+gstar~1,ID=logLinf+tstar+gstar~1
+                  start=list(fixed=c(6.0,2.0,0.5)),
+                  weights=varPower(form=~BC.Age))

I've tried other model calls but with no success. Again, I realize questions similar to this have posted but I have not seen an answer as to how this could be implement in nlme() if at all.  Any suggestions would be appreciated.  Thank you.

Travis Brenden
Department of Fisheries and Wildlife
Michigan State University


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--




Thanks,
John


John Poe
Doctoral Candidate
Department of Political Science
Research Methodologist
UK Center for Public Health Services & Systems Research
University of Kentucky
111 Washington Avenue, Room 203a
Lexington, KY 40536
www.johndavidpoe.com<http://www.johndavidpoe.com>

	[[alternative HTML version deleted]]


From gangchen at mail.nih.gov  Fri Sep 30 23:05:14 2016
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Fri, 30 Sep 2016 21:05:14 +0000
Subject: [R-sig-ME] Incomplete two-way ANOVA
Message-ID: <B9A765D8-C71A-43A9-8622-4D3AF58C326F@mail.nih.gov>

Suppose that there are two experimental factors A and B, each of which has two levels, leading to 2 x 2 = 4 combinations: A1B1, 2A2B1, A1B2, and A2B2. Typically this would be analyzed with a two-way within-subject (or repeated-measures) ANOVA.

However, data has been only collected with A1B1 and A2B2 from one group with n1 subjects, and with A2B1 and A1B2 from the other group with n2 subjects. A two-way between-subjects ANOVA might be adopted, but that requires an independence assumption among the four combinations, which does not hold. On the other hand, how about a linear mixed-effects model like the
following?

dat <- read.table(text = "
  Subj  A  B            y
 S1 A1 B1 -0.214137949
 S1 A2 B2 -1.714628408
 S2 A1 B1 -1.229578334
 S2 A2 B2 -1.664862753
 S3 A1 B1  0.838064385
 S3 A2 B2 -0.368188970
 S4 A1 B1  0.002022487
 S4 A2 B2  1.399422383
 S5 A2 B1  0.995036719
 S5 A1 B2  0.752182526
 S6 A2 B1 -0.426498651
 S6 A1 B2  0.771060004
 S7 A2 B1 -1.274627158
 S7 A1 B2 -0.256490231
 S8 A2 B1 -0.175888411
 S8 A1 B2  0.389261459
 S9 A2 B1  0.629649580
 S9 A1 B2 -0.885086803", header = TRUE)

xtabs(~A+B, data=dat)

   B
A    B1 B2
 A1  4  5
 A2  5  4

fm <- lme(y ~ A*B, data=dat, random=~1|Subj)

anova(fm)
           numDF denDF   F-value p-value
(Intercept)     1     8 0.2605135  0.6235
A               1     6 0.5945658  0.4699
B               1     6 0.0831877  0.7827
A:B             1     6 0.6234177  0.4598

Would the above LME approach be valid in this case with total missing data in two cells from each of the two groups? It seems this would violate the missing-at-random assumption. Nothing can be done other than collecting more data?

Thanks,
Gang

