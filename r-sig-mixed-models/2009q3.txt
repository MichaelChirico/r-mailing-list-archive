From bolker at ufl.edu  Wed Jul  1 03:03:41 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 30 Jun 2009 21:03:41 -0400
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4836bc6a0906300924n259509bfu7b2fc7f97938dfa2@mail.gmail.com>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>	
	<4A45119E.9030503@ufl.edu>	
	<87E6B088-2A58-4E32-B079-8A5388D2B541@kjbeath.com.au>
	<4836bc6a0906300924n259509bfu7b2fc7f97938dfa2@mail.gmail.com>
Message-ID: <4A4AB5ED.1040208@ufl.edu>

Fabian Scheipl wrote:
> On Tue, Jun 30, 2009 at 9:16 AM, Ken Beath<ken at kjbeath.com.au> wrote:
>> It appears that PQL with moderate random effect variance introduces a small
>> bias in a direction that reduces the MSE, at least in the simulations
>> chosen. For large variances the bias is probably excessive and the MSE will
>> increase using PQL.

  Hmmm.  How can bias, in any direction, reduce MSE?  (I can see that
there could be a tradeoff between bias and variance, but MSE
incorporates bias^2, right?  How about bias-corrected variants of
PQL (a la Raudenbush et al) -- mights those provide the best
of both worlds, or does the additional complexity inevitably
increase variance -> MSE?  (I don't know if those bias-corrected
variants are implemented anywhere other than MLWiN/HLM ... ?)

> Results from simulations with sd(RandomIntercept)=3 instead of 1
> (results attached) confirm your remark - with the possible exception
> of very small data sets the performance (in rmse & bias) for Laplace
> and AGQ is much much better than PQL.
> I'm sorry for getting Ben Bolker and others all riled up with my earlier post.

  On the contrary, I think this is fascinating and worthwhile.
It amazes me that we still don't know these very basic things.

> One more thing to consider though:
>  A random intercept variance of 1 in a logistic model means that the
> medium  50% of subjects/groups are expected to have between about half
> and about double the odds of a subject/group with random intercept=0,
> which is already fairly large effect in my book.
> ##
>> qlnorm(c(.1, .25, .75, .9))
> [1] 0.28 0.51 1.96 3.60
> ##
> 
> For a random intercept sd of 3, the multiplicative effect on the
> baseline odds for the middle 50% is between  0.13 and  7.6,
> ##
>> qlnorm(c(.1, .25,  .75, .9), sdlog = 3)
> [1]  0.021  0.132  7.565 46.743
> ##
> which means really large inter-group/subject heterogeneity and might
> not be encountered that frequently in real data (?) (or at least
> suggest a mis-specified model that misses important
> subject/group-level predictors...).
> 
> (Similar remarks concerning "effect size" of the random effect apply
> to Poisson regression with log-link.)
> 
> So, what's the lesson --
> Should we still prefer PQL if we expect to see small to intermediate
> inter-group/subject heterogeneity?
> 
> Fabian

  good question.


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From hypergeometric at mensakorea.org  Wed Jul  1 03:38:52 2009
From: hypergeometric at mensakorea.org (Hypergeometric)
Date: Wed, 01 Jul 2009 10:38:52 +0900
Subject: [R-sig-ME] The issue of increasing maximum number of iterations
Message-ID: <1246412332.5260.24.camel@cray>

Dear colleagues,

I am trying to reset the maximum number of iterations in lmer function
by inserting "control=list(maxIter=1000)." Unfortunately, I found it's
not working. Interestingly, this issue has been raised by two posts in
this list, but remains unsolved. 

I am using the latest lme4 package on R version 2.9.0 (2009-04-17) on
the platform of Ubuntu 9.04 Jaunty 64-bit. I also tried this on the
platform of Windows XP 32-bit and found the same result. 

My model is as follows:

R22<-lmer(ldv2_1~tstatus+...+it1+it2+(1|a1idf)+(1|a2idf)+(1|a12idf)+(1|
tidf),sample,family=binomial(link="logit"), verbose =
TRUE,control=list(maxIter=1000))

Any suggestion or help will be appreciated.

Thanks in advance!

Kyuho



From ken at kjbeath.com.au  Wed Jul  1 10:37:41 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 1 Jul 2009 18:37:41 +1000
Subject: [R-sig-ME] lmer vs glmmPQL
In-Reply-To: <4A4AB5ED.1040208@ufl.edu>
References: <4836bc6a0906250133x48fe4323ue2ed0917cdea9678@mail.gmail.com>	
	<4A45119E.9030503@ufl.edu>	
	<87E6B088-2A58-4E32-B079-8A5388D2B541@kjbeath.com.au>
	<4836bc6a0906300924n259509bfu7b2fc7f97938dfa2@mail.gmail.com>
	<4A4AB5ED.1040208@ufl.edu>
Message-ID: <9AD621F9-6C62-4F0F-ABF5-9DB79664CD72@kjbeath.com.au>

On 01/07/2009, at 11:03 AM, Ben Bolker wrote:

> Fabian Scheipl wrote:
>> On Tue, Jun 30, 2009 at 9:16 AM, Ken Beath<ken at kjbeath.com.au> wrote:
>>> It appears that PQL with moderate random effect variance  
>>> introduces a small
>>> bias in a direction that reduces the MSE, at least in the  
>>> simulations
>>> chosen. For large variances the bias is probably excessive and the  
>>> MSE will
>>> increase using PQL.
>
>  Hmmm.  How can bias, in any direction, reduce MSE?  (I can see that
> there could be a tradeoff between bias and variance, but MSE
> incorporates bias^2, right?  How about bias-corrected variants of
> PQL (a la Raudenbush et al) -- mights those provide the best
> of both worlds, or does the additional complexity inevitably
> increase variance -> MSE?  (I don't know if those bias-corrected
> variants are implemented anywhere other than MLWiN/HLM ... ?)
>

By bias for PQL, I mean the difference from the "correct" maximum  
likelihood estimates rather than from the true values.


>> Results from simulations with sd(RandomIntercept)=3 instead of 1
>> (results attached) confirm your remark - with the possible exception
>> of very small data sets the performance (in rmse & bias) for Laplace
>> and AGQ is much much better than PQL.
>> I'm sorry for getting Ben Bolker and others all riled up with my  
>> earlier post.
>
>  On the contrary, I think this is fascinating and worthwhile.
> It amazes me that we still don't know these very basic things.
>

The nice thing is that most of the time it doesn't make much  
difference what approximation is used. Fixed effect estimates which is  
usually what we are interested in are usually less biased than random  
effect variance estimates.

>> One more thing to consider though:
>> A random intercept variance of 1 in a logistic model means that the
>> medium  50% of subjects/groups are expected to have between about  
>> half
>> and about double the odds of a subject/group with random intercept=0,
>> which is already fairly large effect in my book.
>> ##
>>> qlnorm(c(.1, .25, .75, .9))
>> [1] 0.28 0.51 1.96 3.60
>> ##
>>
>> For a random intercept sd of 3, the multiplicative effect on the
>> baseline odds for the middle 50% is between  0.13 and  7.6,
>> ##
>>> qlnorm(c(.1, .25,  .75, .9), sdlog = 3)
>> [1]  0.021  0.132  7.565 46.743
>> ##
>> which means really large inter-group/subject heterogeneity and might
>> not be encountered that frequently in real data (?) (or at least
>> suggest a mis-specified model that misses important
>> subject/group-level predictors...).
>>
>> (Similar remarks concerning "effect size" of the random effect apply
>> to Poisson regression with log-link.)
>>
>> So, what's the lesson --
>> Should we still prefer PQL if we expect to see small to intermediate
>> inter-group/subject heterogeneity?
>>
>> Fabian
>
>  good question.
>

Provided the bias with either method is small then it isn't a problem  
because there will always be other errors because of assumptions about  
random effects distributions. There are a reasonable number of data  
sets with small cluster size and high within cluster correlation where  
we don't know the reasons for the correlation, simply because we don't  
know the full causes. An example is many eye diseases.

Why I like the Laplace/AGQ methodology where you increase the  
quadrature points until the fit isn't improved is that it removes one  
possible problem.

Ken


>
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Kate.Pressland at bristol.ac.uk  Wed Jul  1 16:39:38 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Wed, 01 Jul 2009 15:39:38 +0100
Subject: [R-sig-ME] Help needed with error "matrix not symmetrical"
Message-ID: <559421209D3D254A8034E4D9@bio-mammal03.bio.bris.ac.uk>

Dear R users,

I have a model problem and don't understand the error being given to me. 
Essentially I have unbalanced data with many blocks/replicates (ID, n=34), 
sampled regularly (Sample, n varies with year) over years (Year, n varies 
with ID) and each block has an associated treatment (Treatment, n=3) and 
various habitats (Habitat). I am interested in seeing how treatment and 
habitat interact within the sampling structure of the data collected. I 
have attached a text file of simulated data. All effects are factors and y 
is continuous data, poisson but normalises okay(ish) when log(y) is used.

When I do a super simple model such as below:

	> model<-lmer(log(y)~Treatment*Habitat+(1|ID)+(1|Year)+(1|Sample), 
dataset=data)

I get this error message:

	Error in mer_finalize(ans) : Downdated X'X is not positive definite, 26.

I've had this before when there wasn't enough data in all the groups so 
found that habitat 12 has a very low frequency when I plotted y~Habitat. 
When I remove habitat 12 the model gives me the same error.

If I subset treatment and run 3 separate models as such:

	> model<-lmer(log(y)~Habitat+(1|ID)+(1|Year)+(1|Sample), dataset=data, 
subset=Treatment=="0")

the model runs without error but when I then run:

	>summary(model)

This error appears:

	Error in asMethod(object) : matrix is not symmetric [1,2]

This does not happen for the other 2 treatments which, oddly, have fewer 
blocks(ID) than 0 and therefore fewer data points - these run without 
problem and have good residuals. I've spotted that 2 IDs have a small 
number of records compared to others so I've tried removing them and I 
still get the error. Why would this happen? I can't see any major reason 
for treatment 0 to be tripping out the model. I've search the forum and 
found that this second error can occur (i) with old/new R version types, 
but I've recently updated lme4 and running 2.9.0 only, (ii)if you run nlme 
at the same time as lme4, which I never do. I cannot find any other 
explanation for this error on the forum. I've tried lots of different 
random structures and it makes no difference. Can anyone shed any light on 
this?

Any help is, as always, really appreciated.

Thanks,

Kate
-------------- next part --------------
ID	Year	Sample	Habitat	y	Treatment
4	2000	1	17	0.03	1
4	2000	2	17	0.03	1
4	2000	3	17	0.12	1
4	2000	3	19	6.89655172413793E-03	1
4	2000	3	32	0.005	1
4	2000	4	17	0.02	1
4	2000	4	19	0.02	1
4	2000	4	32	0.01	1
4	2000	6	17	0.06	1
4	2000	6	19	0.03	1
4	2000	6	32	0.01	1
4	2000	7	17	0.03	1
4	2000	7	19	0.04	1
4	2000	7	32	0.01	1
4	2000	8	17	0.04	1
4	2000	8	19	0.02	1
4	2000	9	17	0.02	1
4	2000	9	19	0.03	1
4	2000	9	26	0.00625	1
4	2000	9	32	0.005	1
4	2000	10	17	0.04	1
4	2000	10	19	0.01	1
4	2000	10	26	0.00625	1
4	2000	11	17	0.07	1
4	2000	11	19	0.03	1
4	2000	11	26	0.00625	1
4	2000	11	32	0.02	1
4	2000	12	17	0.13	1
4	2000	12	19	0.01	1
4	2000	12	26	0.01	1
4	2000	12	32	0.02	1
4	2000	13	17	0.58	1
4	2000	13	19	0.03	1
4	2000	13	32	0.005	1
4	2000	14	17	1.02	1
4	2000	14	19	0.15	1
4	2000	14	32	0.01	1
4	2000	15	17	1.14	1
4	2000	15	19	0.2	1
4	2000	15	32	0.01	1
4	2000	16	17	1.25	1
4	2000	16	19	0.23	1
4	2000	16	26	0.03	1
4	2000	16	32	0.06	1
4	2000	17	17	1.14	1
4	2000	17	19	0.2	1
4	2000	17	32	0.02	1
4	2000	18	17	0.91	1
4	2000	18	19	0.19	1
4	2000	18	32	0.06	1
4	2000	19	17	0.42	1
4	2000	19	19	0.2	1
4	2000	19	32	0.01	1
4	2000	20	17	0.7	1
4	2000	20	19	0.32	1
4	2000	20	32	0.01	1
4	2000	21	17	0.23	1
4	2000	21	19	0.06	1
4	2000	21	26	0.00625	1
4	2000	21	32	0.02	1
4	2000	22	17	0.11	1
4	2000	22	19	0.04	1
4	2000	22	26	0.00625	1
4	2000	22	32	0.005	1
4	2000	23	17	0.12	1
4	2000	23	19	0.01	1
4	2000	23	26	0.00625	1
4	2000	23	32	0.005	1
4	2000	24	17	0.05	1
4	2000	24	19	0.01	1
4	2000	24	26	0.00625	1
4	2000	25	17	0.03	1
4	2000	25	32	0.005	1
4	2000	26	17	0.01	1
4	2001	5	17	0.07	1
4	2001	5	19	6.89655172413793E-03	1
4	2001	6	17	0.03	1
4	2001	6	19	0.005	1
4	2001	6	26	0.00625	1
4	2001	6	32	0.01	1
4	2001	8	17	0.04	1
4	2001	8	19	0.01	1
4	2001	8	26	0.00625	1
4	2001	8	32	0.005	1
4	2001	9	17	0.01	1
4	2001	9	19	0.02	1
4	2001	9	26	0.00625	1
4	2001	10	17	0.01	1
4	2001	10	19	0.04	1
4	2001	10	26	0.00625	1
4	2001	10	32	0.005	1
4	2001	11	17	0.04	1
4	2001	11	26	0.01	1
4	2001	12	17	0.09	1
4	2001	12	19	0.02	1
4	2001	13	17	0.08	1
4	2001	13	19	0.05	1
4	2001	13	26	0.00625	1
4	2001	13	32	0.005	1
4	2001	14	17	0.31	1
4	2001	14	19	0.05	1
4	2001	14	26	0.00625	1
4	2001	14	32	0.01	1
4	2001	15	17	2.16	1
4	2001	15	19	0.11	1
4	2001	15	32	0.12	1
4	2001	16	17	1.03	1
4	2001	16	19	0.11	1
4	2001	16	32	0.04	1
4	2001	17	17	0.79	1
4	2001	17	19	0.1	1
4	2001	17	26	0.01	1
4	2001	17	32	0.02	1
4	2001	18	17	0.56	1
4	2001	18	19	0.08	1
4	2001	18	26	0.01	1
4	2001	18	32	0.01	1
4	2001	19	17	0.46	1
4	2001	19	19	0.03	1
4	2001	19	32	0.02	1
4	2001	20	17	0.33	1
4	2001	20	19	0.02	1
4	2001	20	26	0.00625	1
4	2001	20	32	0.01	1
4	2001	21	17	0.11	1
4	2001	21	19	0.03	1
4	2001	21	26	0.01	1
4	2001	21	32	0.01	1
4	2001	22	17	0.13	1
4	2001	22	19	0.01	1
4	2001	22	26	0.01	1
4	2001	23	17	0.18	1
4	2001	23	19	0.03	1
4	2001	24	17	0.01	1
4	2001	24	19	0.005	1
4	2001	25	17	6.78685047720042E-03	1
4	2001	25	19	6.89655172413793E-03	1
4	2001	26	19	0.005	1
4	2002	1	17	0.05	1
4	2002	1	19	0.02	1
4	2002	1	32	0.01	1
4	2002	2	17	0.02	1
4	2002	2	19	0.01	1
4	2002	2	26	0.00625	1
4	2002	2	32	0.01	1
4	2002	3	17	0.19	1
4	2002	3	19	0.08	1
4	2002	3	32	0.02	1
4	2002	4	17	0.09	1
4	2002	4	19	0.03	1
4	2002	4	32	0.01	1
4	2002	6	17	0.04	1
4	2002	6	19	0.01	1
4	2002	6	26	0.01	1
4	2002	6	32	0.005	1
4	2002	7	17	0.08	1
4	2002	7	19	0.03	1
4	2002	7	26	0.01	1
4	2002	8	17	0.07	1
4	2002	8	19	0.02	1
4	2002	8	32	0.01	1
4	2002	9	17	0.03	1
4	2002	9	19	0.005	1
4	2002	9	32	0.01	1
4	2002	10	17	0.02	1
4	2002	10	19	0.03	1
4	2002	10	32	0.005	1
4	2002	11	17	0.25	1
4	2002	11	19	0.02	1
4	2002	11	32	0.005	1
4	2002	12	17	0.58	1
4	2002	12	19	0.02	1
4	2002	12	32	0.01	1
4	2002	13	17	0.44	1
4	2002	13	19	0.02	1
4	2002	13	32	0.01	1
4	2002	14	17	1.22	1
4	2002	14	19	0.08	1
4	2002	14	26	0.00625	1
4	2002	14	32	0.05	1
4	2002	15	17	1.37	1
4	2002	15	19	0.26	1
4	2002	15	32	0.05	1
4	2002	16	17	1.29	1
4	2002	16	19	0.16	1
4	2002	16	26	0.1	1
4	2002	16	32	0.04	1
4	2002	17	17	2.44	1
4	2002	17	19	0.49	1
4	2002	17	26	0.04	1
4	2002	17	32	0.12	1
4	2002	18	17	0.99	1
4	2002	18	19	0.31	1
4	2002	18	26	0.00625	1
4	2002	18	32	0.04	1
4	2002	19	17	0.69	1
4	2002	19	19	0.1	1
4	2002	19	32	0.01	1
4	2002	20	17	0.29	1
4	2002	20	19	0.08	1
4	2002	20	26	0.00625	1
4	2002	20	32	0.01	1
4	2002	21	17	0.18	1
4	2002	21	19	0.03	1
4	2002	21	26	0.01	1
4	2002	21	32	0.02	1
4	2002	22	17	0.19	1
4	2002	22	19	0.04	1
4	2002	22	26	0.00625	1
4	2002	22	32	0.04	1
4	2002	23	17	0.15	1
4	2002	23	19	0.01	1
4	2002	23	32	0.01	1
4	2002	24	17	0.03	1
4	2002	24	32	0.005	1
4	2002	25	17	0.02	1
4	2002	25	19	0.01	1
4	2002	26	17	5.55555555555556E-03	1
4	2003	1	17	0.03	1
4	2003	1	32	0.01	1
4	2003	2	17	0.03	1
4	2003	2	19	6.89655172413793E-03	1
4	2003	2	32	0.005	1
4	2003	3	17	0.1	1
4	2003	3	19	0.04	1
4	2003	3	32	0.005	1
4	2003	4	17	0.06	1
4	2003	4	19	0.02	1
4	2003	5	17	0.02	1
4	2003	5	19	0.02	1
4	2003	5	26	0.00625	1
4	2003	5	32	0.005	1
4	2003	6	17	0.06	1
4	2003	6	19	0.02	1
4	2003	6	26	0.00625	1
4	2003	6	32	0.01	1
4	2003	7	17	0.02	1
4	2003	8	17	0.03	1
4	2003	8	19	0.01	1
4	2003	8	32	0.01	1
4	2003	9	17	0.03	1
4	2003	9	17	0.08	1
4	2003	9	19	0.02	1
4	2003	9	19	0.03	1
4	2003	9	26	0.01	1
4	2003	10	17	0.08	1
4	2003	10	19	0.03	1
4	2003	11	17	0.26	1
4	2003	11	19	0.07	1
4	2003	11	26	0.02	1
4	2003	11	32	0.005	1
4	2003	12	17	0.21	1
4	2003	12	19	0.04	1
4	2003	12	26	0.02	1
4	2003	13	17	0.89	1
4	2003	13	19	0.13	1
4	2003	13	32	0.05	1
4	2003	14	17	1.56	1
4	2003	14	19	0.14	1
4	2003	14	26	0.00625	1
4	2003	14	32	0.05	1
4	2003	15	17	2.58	1
4	2003	15	19	0.71	1
4	2003	15	26	0.08	1
4	2003	15	32	0.09	1
4	2003	16	17	3.5	1
4	2003	16	19	0.68	1
4	2003	16	26	0.08	1
4	2003	16	32	0.14	1
4	2003	17	17	2.13	1
4	2003	17	19	0.35	1
4	2003	17	26	0.03	1
4	2003	17	32	0.1	1
4	2003	18	17	0.66	1
4	2003	18	17	1.5	1
4	2003	18	19	0.06	1
4	2003	18	19	0.21	1
4	2003	18	26	0.00625	1
4	2003	18	26	0.01	1
4	2003	18	32	0.02	1
4	2003	18	32	0.07	1
4	2003	19	17	0.66	1
4	2003	19	19	0.06	1
4	2003	19	26	0.01	1
4	2003	19	32	0.02	1
4	2003	20	17	0.43	1
4	2003	20	19	0.09	1
4	2003	20	26	0.02	1
4	2003	20	32	0.03	1
4	2003	21	17	0.52	1
4	2003	21	19	0.16	1
4	2003	21	26	0.00625	1
4	2003	21	32	0.05	1
4	2003	22	17	0.23	1
4	2003	22	19	0.08	1
4	2003	22	26	0.00625	1
4	2003	22	32	0.02	1
4	2003	23	17	0.4	1
4	2003	23	19	0.1	1
4	2003	23	26	0.01	1
4	2003	23	32	0.02	1
4	2003	24	17	0.24	1
4	2003	24	19	0.04	1
4	2003	24	26	0.01	1
4	2003	24	32	0.005	1
4	2003	25	17	0.05	1
4	2003	25	19	0.005	1
4	2003	25	26	0.00625	1
4	2003	26	17	0.06	1
4	2003	26	19	0.01	1
4	2004	2	17	0.07	1
4	2004	2	19	0.02	1
4	2004	2	32	0.005	1
4	2004	3	17	0.11	1
4	2004	3	19	0.02	1
4	2004	3	32	0.02	1
4	2004	4	17	0.08	1
4	2004	4	19	0.05	1
4	2004	4	32	0.005	1
4	2004	7	17	0.14	1
4	2004	7	19	0.02	1
4	2004	7	26	0.01	1
4	2004	7	32	0.01	1
4	2004	8	17	8.50123718628491E-03	1
4	2004	8	19	0.02	1
4	2004	8	32	0.01	1
4	2004	9	17	0.02	1
4	2004	9	19	0.05	1
4	2004	10	17	0.07	1
4	2004	10	19	0.06	1
4	2004	10	26	0.01	1
4	2004	10	32	0.01	1
4	2004	11	17	0.21	1
4	2004	11	19	0.01	1
4	2004	11	26	0.01	1
4	2004	11	32	0.01	1
4	2004	12	17	0.31	1
4	2004	12	19	0.09	1
4	2004	12	32	0.005	1
4	2004	13	17	1.33	1
4	2004	13	19	0.1	1
4	2004	13	32	0.09	1
4	2004	14	17	1.59	1
4	2004	14	19	0.31	1
4	2004	14	26	0.07	1
4	2004	14	32	0.16	1
4	2004	15	17	0.89	1
4	2004	15	19	0.12	1
4	2004	15	26	0.01	1
4	2004	15	32	0.09	1
4	2004	16	17	1	1
4	2004	16	19	0.1	1
4	2004	16	32	0.08	1
4	2004	17	17	1.38	1
4	2004	17	19	0.18	1
4	2004	17	26	0.00625	1
4	2004	17	32	0.06	1
4	2004	18	17	0.87	1
4	2004	18	19	0.15	1
4	2004	18	26	0.01	1
4	2004	18	32	0.03	1
4	2004	19	17	0.51	1
4	2004	19	19	0.07	1
4	2004	19	26	0.01	1
4	2004	19	32	0.01	1
4	2004	20	17	0.9	1
4	2004	20	19	0.13	1
4	2004	20	26	0.02	1
4	2004	20	32	0.04	1
4	2004	22	17	0.22	1
4	2004	22	19	0.03	1
4	2004	22	26	0.00625	1
4	2004	22	32	0.03	1
4	2004	23	17	0.5	1
4	2004	23	19	0.15	1
4	2004	23	32	0.04	1
4	2004	24	17	0.03	1
4	2004	24	19	6.89655172413793E-03	1
4	2004	25	17	0.03	1
4	2004	25	19	6.89655172413793E-03	1
4	2004	26	17	9.17874396135266E-03	1
4	2005	3	17	0.12	1
4	2005	3	19	0.06	1
4	2005	3	32	0.02	1
4	2005	4	17	0.12	1
4	2005	4	19	0.06	1
4	2005	4	26	0.01	1
4	2005	4	32	0.02	1
4	2005	5	17	0.06	1
4	2005	5	17	0.08	1
4	2005	5	19	6.89655172413793E-03	1
4	2005	5	19	0.02	1
4	2005	5	26	0.00625	1
4	2005	5	26	0.01	1
4	2005	5	32	0.005	1
4	2005	5	32	0.01	1
4	2005	6	17	0.06	1
4	2005	6	19	6.89655172413793E-03	1
4	2005	6	26	0.00625	1
4	2005	6	32	0.005	1
4	2005	7	17	0.03	1
4	2005	7	19	0.05	1
4	2005	8	17	0.06	1
4	2005	8	19	0.03	1
4	2005	9	17	0.03	1
4	2005	9	17	0.08	1
4	2005	9	19	0.02	1
4	2005	9	32	0.02	1
4	2005	10	17	0.08	1
4	2005	10	19	0.02	1
4	2005	10	32	0.02	1
4	2005	11	17	0.19	1
4	2005	11	19	0.01	1
4	2005	11	32	0.01	1
4	2005	12	17	0.1	1
4	2005	12	19	0.01	1
4	2005	12	32	0.01	1
4	2005	13	17	0.87	1
4	2005	13	19	0.08	1
4	2005	13	26	0.03	1
4	2005	13	32	0.05	1
4	2005	14	17	1	1
4	2005	14	19	0.12	1
4	2005	14	32	0.06	1
4	2005	15	17	3.67	1
4	2005	15	19	0.47	1
4	2005	15	26	0.08	1
4	2005	15	32	0.24	1
4	2005	16	17	2.21	1
4	2005	16	19	0.25	1
4	2005	16	26	0.01	1
4	2005	16	32	0.09	1
4	2005	17	17	1.36	1
4	2005	17	19	0.14	1
4	2005	17	26	0.01	1
4	2005	17	32	0.02	1
4	2005	18	17	0.64	1
4	2005	18	19	0.02	1
4	2005	18	26	0.01	1
4	2005	18	32	0.03	1
4	2005	19	17	0.38	1
4	2005	19	19	0.05	1
4	2005	19	26	0.00625	1
4	2005	19	32	0.01	1
4	2005	20	17	0.3	1
4	2005	20	19	0.04	1
4	2005	20	32	0.03	1
4	2005	21	17	0.13	1
4	2005	21	19	0.005	1
4	2005	21	32	0.01	1
4	2005	22	17	0.16	1
4	2005	22	19	0.03	1
4	2005	22	26	0.00625	1
4	2005	22	32	0.02	1
4	2005	23	17	0.28	1
4	2005	23	19	0.04	1
4	2005	23	26	0.02	1
4	2005	23	32	0.02	1
4	2005	24	17	0.13	1
4	2005	24	19	0.03	1
4	2005	24	26	0.02	1
4	2005	24	32	0.02	1
4	2005	25	17	0.02	1
4	2005	26	17	7.47282608695652E-03	1
4	2005	26	32	0.005	1
4	2006	1	17	0.01	1
4	2006	1	19	0.005	1
4	2006	2	17	0.05	1
4	2006	2	32	0.005	1
4	2006	3	17	0.03	1
4	2006	3	32	0.01	1
4	2006	4	17	0.05	1
4	2006	5	17	0.05	1
4	2006	5	32	0.005	1
4	2006	6	17	0.05	1
4	2006	6	19	0.02	1
4	2006	8	17	0.02	1
4	2006	8	19	0.02	1
4	2006	9	17	6.7481884057971E-03	1
4	2006	9	19	6.89655172413793E-03	1
4	2006	10	17	0.06	1
4	2006	10	19	0.02	1
4	2006	10	32	0.01	1
4	2006	11	17	0.14	1
4	2006	11	19	0.04	1
4	2006	11	26	0.00625	1
4	2006	11	32	0.01	1
4	2006	12	17	0.23	1
4	2006	12	19	0.005	1
4	2006	12	32	0.01	1
4	2006	13	17	0.64	1
4	2006	13	19	0.02	1
4	2006	13	32	0.04	1
4	2006	14	17	0.71	1
4	2006	14	19	0.16	1
4	2006	14	26	0.01	1
4	2006	14	32	0.03	1
4	2006	15	17	1.24	1
4	2006	15	19	0.16	1
4	2006	15	26	0.01	1
4	2006	15	32	0.07	1
4	2006	16	17	1.2	1
4	2006	16	19	0.14	1
4	2006	16	26	0.03	1
4	2006	16	32	0.08	1
4	2006	17	17	0.68	1
4	2006	17	19	0.1	1
4	2006	17	26	0.00625	1
4	2006	17	32	0.05	1
4	2006	18	17	0.5	1
4	2006	18	19	0.03	1
4	2006	18	32	0.01	1
4	2006	19	17	0.5	1
4	2006	19	19	0.08	1
4	2006	19	26	0.00625	1
4	2006	19	32	0.05	1
4	2006	20	17	0.64	1
4	2006	20	19	0.07	1
4	2006	20	32	0.02	1
4	2006	21	17	0.19	1
4	2006	21	19	0.03	1
4	2006	21	32	0.01	1
4	2006	22	17	0.1	1
4	2006	22	19	0.01	1
4	2006	22	32	0.01	1
4	2006	23	17	0.11	1
4	2006	23	19	0.01	1
4	2006	24	17	0.03	1
4	2006	24	19	0.01	1
4	2006	24	26	0.01	1
4	2006	25	17	0.01	1
4	2006	26	19	0.005	1
4	2007	1	17	0.06	1
4	2007	2	17	0.14	1
4	2007	2	19	0.005	1
4	2007	3	17	0.01	1
4	2007	3	19	0.005	1
4	2007	3	32	0.005	1
4	2007	4	17	0.09	1
4	2007	4	19	0.02	1
4	2007	4	32	0.005	1
4	2007	5	17	0.07	1
4	2007	5	19	0.01	1
4	2007	5	32	0.01	1
4	2007	7	17	0.04	1
4	2007	7	19	6.89655172413793E-03	1
4	2007	8	17	0.03	1
4	2007	8	19	6.89655172413793E-03	1
4	2007	9	17	0.03	1
4	2007	9	17	0.04	1
4	2007	9	19	6.89655172413793E-03	1
4	2007	9	19	0.01	1
4	2007	9	32	0.005	1
4	2007	10	17	0.03	1
4	2007	10	19	0.02	1
4	2007	10	26	0.01	1
4	2007	11	17	0.09	1
4	2007	11	19	0.01	1
4	2007	11	32	0.01	1
4	2007	12	17	0.16	1
4	2007	12	19	0.02	1
4	2007	12	32	0.01	1
4	2007	13	17	0.52	1
4	2007	13	19	0.02	1
4	2007	13	32	0.03	1
4	2007	14	17	2	1
4	2007	14	19	0.21	1
4	2007	14	26	0.00625	1
4	2007	14	32	0.08	1
4	2007	15	17	2.17	1
4	2007	15	19	0.3	1
4	2007	15	26	0.02	1
4	2007	15	32	0.25	1
4	2007	16	17	1.26	1
4	2007	16	19	0.22	1
4	2007	16	32	0.09	1
4	2007	18	17	0.63	1
4	2007	18	19	0.09	1
4	2007	18	26	0.00625	1
4	2007	18	32	0.02	1
4	2007	19	17	0.37	1
4	2007	19	19	0.04	1
4	2007	19	26	0.00625	1
4	2007	19	32	0.01	1
4	2007	20	17	0.13	1
4	2007	20	19	0.005	1
4	2007	20	32	0.02	1
4	2007	21	17	0.05	1
4	2007	21	19	0.01	1
4	2007	22	17	0.06	1
4	2007	22	19	0.04	1
4	2007	23	17	0.06	1
4	2007	23	19	0.01	1
4	2007	23	32	0.005	1
4	2007	24	17	0.04	1
4	2007	24	19	0.005	1
4	2007	24	26	0.00625	1
4	2007	24	32	0.005	1
4	2007	25	17	0.00625	1
23	2000	1	15	6.73496076721883E-03	0
23	2000	1	26	0.04	0
23	2000	2	15	8.7510897994769E-03	0
23	2000	2	26	0.07	0
23	2000	4	15	0.02	0
23	2000	4	26	0.04	0
23	2000	5	15	0.02	0
23	2000	5	15	0.04	0
23	2000	5	26	0.04	0
23	2000	5	26	0.08	0
23	2000	6	15	0.06	0
23	2000	6	26	0.1	0
23	2000	7	15	0.07	0
23	2000	7	26	0.07	0
23	2000	8	15	0.07	0
23	2000	8	26	0.05	0
23	2000	9	15	0.01	0
23	2000	9	15	0.06	0
23	2000	9	26	0.02	0
23	2000	9	26	0.04	0
23	2000	10	15	0.06	0
23	2000	10	26	0.06	0
23	2000	11	15	0.06	0
23	2000	11	26	0.07	0
23	2000	12	15	0.18	0
23	2000	12	26	0.09	0
23	2000	13	15	0.35	0
23	2000	13	26	0.05	0
23	2000	14	15	0.41	0
23	2000	14	26	0.16	0
23	2000	15	15	0.56	0
23	2000	15	26	0.31	0
23	2000	16	15	0.6	0
23	2000	16	26	0.35	0
23	2000	17	15	0.54	0
23	2000	17	26	0.21	0
23	2000	18	15	0.09	0
23	2000	18	15	0.16	0
23	2000	18	26	0.07	0
23	2000	18	26	0.09	0
23	2000	19	15	0.29	0
23	2000	19	26	0.15	0
23	2000	20	15	0.21	0
23	2000	20	26	0.1	0
23	2000	21	15	0.08	0
23	2000	21	26	0.04	0
23	2000	22	15	0.05	0
23	2000	22	26	0.04	0
23	2000	23	15	0.01	0
23	2000	23	26	8.87573964497041E-03	0
23	2000	24	15	0.03	0
23	2000	24	26	0.04	0
23	2000	25	15	0.04	0
23	2000	25	26	0.04	0
23	2000	26	15	0.05	0
23	2000	26	26	0.02	0
23	2001	3	15	2.01612903225806E-03	0
23	2001	3	26	0.01	0
23	2001	4	26	0.01	0
23	2001	5	15	5.40540540540541E-03	0
23	2001	5	26	0.02	0
23	2001	6	15	5.40540540540541E-03	0
23	2001	6	26	0.04	0
23	2001	7	15	0.01	0
23	2001	7	26	0.03	0
23	2001	8	15	0.01	0
23	2001	8	26	0.03	0
23	2001	10	26	6.47249190938511E-03	0
23	2001	12	15	0.01	0
23	2001	12	26	0.02	0
23	2001	13	15	0.02	0
23	2001	13	26	0.03	0
23	2001	14	15	0.15	0
23	2001	14	26	0.06	0
23	2001	15	15	0.18	0
23	2001	15	26	0.17	0
23	2001	16	15	0.13	0
23	2001	16	26	0.12	0
23	2001	17	15	0.09	0
23	2001	17	26	0.08	0
23	2001	19	15	0.08	0
23	2001	19	26	0.03	0
23	2001	20	15	0.06	0
23	2001	20	26	0.04	0
23	2001	21	15	0.03	0
23	2001	21	26	9.40509870954358E-03	0
23	2001	22	15	0.02	0
23	2001	22	26	0.01	0
23	2001	25	15	8.7510897994769E-03	0
23	2001	25	26	1.60513643659711E-03	0
23	2001	26	15	8.06451612903226E-03	0
23	2001	26	26	0.02	0
23	2002	1	15	0.01	0
23	2002	1	26	0.03	0
23	2002	2	15	0.01	0
23	2002	2	26	0.02	0
23	2002	3	15	4.71883173496077E-03	0
23	2002	3	26	0.01	0
23	2002	5	15	0.02	0
23	2002	5	26	0.06	0
23	2002	6	15	0.05	0
23	2002	6	26	0.06	0
23	2002	7	15	0.02	0
23	2002	7	26	0.06	0
23	2002	8	15	0.05	0
23	2002	8	26	0.01	0
23	2002	9	15	0.05	0
23	2002	9	26	0.01	0
23	2002	12	15	0.03	0
23	2002	12	26	0.03	0
23	2002	13	15	0.02	0
23	2002	13	26	0.02	0
23	2002	15	15	0.14	0
23	2002	15	26	0.13	0
23	2002	16	15	0.07	0
23	2002	16	26	0.06	0
23	2002	17	15	0.15	0
23	2002	17	26	0.09	0
23	2002	18	15	0.07	0
23	2002	18	26	0.05	0
23	2002	19	15	0.19	0
23	2002	19	26	0.06	0
23	2002	20	15	0.09	0
23	2002	20	26	9.37912562804525E-03	0
23	2002	21	15	0.07	0
23	2002	21	26	0.03	0
23	2002	22	15	0.06	0
23	2002	22	26	2.9585798816568E-03	0
23	2002	23	15	0.01	0
23	2002	23	26	2.9585798816568E-03	0
23	2002	24	15	0.02	0
23	2002	24	26	0.01	0
23	2002	25	15	6.04838709677419E-03	0
23	2002	25	26	0.01	0
23	2002	26	15	0.01	0
23	2002	26	26	3.21027287319422E-03	0
23	2003	1	15	2.7027027027027E-03	0
23	2003	1	26	0.01	0
23	2003	3	15	0.01	0
23	2003	3	26	0.07	0
23	2003	4	15	0.01	0
23	2003	4	26	0.03	0
23	2003	5	15	0.02	0
23	2003	5	26	0.04	0
23	2003	6	15	0.03	0
23	2003	6	26	0.04	0
23	2003	7	15	0.04	0
23	2003	7	26	0.11	0
23	2003	8	15	7.42153443766347E-03	0
23	2003	8	26	0.02	0
23	2003	9	15	0.01	0
23	2003	9	26	7.77398919144814E-03	0
23	2003	10	15	0.01	0
23	2003	10	26	0.02	0
23	2003	11	15	0.04	0
23	2003	11	26	0.04	0
23	2003	12	15	0.12	0
23	2003	12	26	0.1	0
23	2003	13	15	0.09	0
23	2003	13	26	0.07	0
23	2003	14	15	0.16	0
23	2003	14	26	0.14	0
23	2003	15	15	0.21	0
23	2003	15	26	0.18	0
23	2003	17	15	0.17	0
23	2003	17	26	0.12	0
23	2003	18	15	0.17	0
23	2003	18	26	0.04	0
23	2003	19	15	0.15	0
23	2003	19	26	0.08	0
23	2003	20	15	0.11	0
23	2003	20	26	0.05	0
23	2003	21	15	0.04	0
23	2003	21	26	0.03	0
23	2003	22	15	0.03	0
23	2003	22	15	0.04	0
23	2003	22	26	3.21027287319422E-03	0
23	2003	22	26	0.01	0
23	2003	23	15	0.04	0
23	2003	23	26	0.01	0
23	2003	24	15	0.02	0
23	2003	24	26	0.02	0
23	2003	25	15	0.02	0
23	2003	25	26	0.02	0
23	2004	2	15	0.01	0
23	2004	2	26	0.01	0
23	2004	4	15	0.02	0
23	2004	4	26	0.05	0
23	2004	5	15	4.71883173496077E-03	0
23	2004	5	26	0.02	0
23	2004	7	15	0.02	0
23	2004	7	26	0.02	0
23	2004	8	15	7.42153443766347E-03	0
23	2004	8	26	0.02	0
23	2004	9	15	0.02	0
23	2004	9	26	0.02	0
23	2004	10	15	0.02	0
23	2004	10	26	0.05	0
23	2004	11	15	0.05	0
23	2004	11	26	0.03	0
23	2004	13	15	0.08	0
23	2004	13	26	0.03	0
23	2004	14	15	0.05	0
23	2004	14	26	0.04	0
23	2004	16	15	0.09	0
23	2004	16	26	0.06	0
23	2004	17	15	0.1	0
23	2004	17	26	0.09	0
23	2004	18	15	0.11	0
23	2004	18	26	0.07	0
23	2004	19	15	0.22	0
23	2004	19	26	0.1	0
23	2004	22	15	0.02	0
23	2004	22	26	0.01	0
23	2004	23	15	9.43766346992153E-03	0
23	2004	23	26	0.02	0
23	2004	24	15	0.01	0
23	2004	24	26	2.9585798816568E-03	0
23	2004	25	15	0.01	0
23	2004	25	26	2.9585798816568E-03	0
23	2004	26	15	0.01	0
23	2004	26	26	7.77398919144814E-03	0
23	2005	1	15	4.71883173496077E-03	0
23	2005	1	26	0.02	0
23	2006	1	15	2.7027027027027E-03	0
23	2006	1	26	9.43107179104192E-03	0
23	2006	4	15	0.01	0
23	2006	4	26	0.05	0
23	2006	5	15	0.01	0
23	2006	5	26	0.03	0
23	2006	6	15	0.02	0
23	2006	6	26	0.04	0
23	2006	9	15	0.02	0
23	2006	9	26	0.02	0
23	2006	10	15	2.01612903225806E-03	0
23	2006	10	26	6.47249190938511E-03	0
23	2006	11	15	6.73496076721883E-03	0
23	2006	11	26	0.01	0
23	2006	13	15	0.06	0
23	2006	13	26	0.05	0
23	2006	14	15	0.08	0
23	2006	14	26	0.07	0
23	2006	15	15	0.21	0
23	2006	15	26	0.16	0
23	2006	16	15	0.11	0
23	2006	16	26	0.11	0
23	2006	17	15	0.07	0
23	2006	17	26	0.14	0
23	2006	18	15	0.11	0
23	2006	18	26	0.04	0
23	2006	19	15	0.08	0
23	2006	19	26	0.03	0
23	2006	21	15	0.03	0
23	2006	21	26	0.01	0
23	2006	22	15	0.01	0
23	2006	22	26	0.01	0
23	2006	23	15	0.04	0
23	2006	23	26	0.02	0
23	2006	24	15	0.01	0
23	2006	24	26	5.91715976331361E-03	0
23	2006	25	15	8.7510897994769E-03	0
23	2006	25	26	4.84138239128967E-03	0
23	2006	26	15	0.01	0
23	2006	26	26	0.01	0
23	2007	1	15	0.01	0
23	2007	1	26	0.05	0
23	2007	2	15	0.01	0
23	2007	2	26	0.02	0
23	2007	3	15	0.02	0
23	2007	3	26	0.05	0
23	2007	4	15	0.03	0
23	2007	4	26	0.03	0
23	2007	5	15	7.42153443766347E-03	0
23	2007	5	26	0.04	0
23	2007	7	15	0.01	0
23	2007	7	26	0.01	0
23	2007	8	15	0.01	0
23	2007	8	26	0.03	0
23	2007	9	15	2.01612903225806E-03	0
23	2007	10	15	0.01	0
23	2007	10	26	0.01	0
23	2007	13	15	0.05	0
23	2007	13	26	0.05	0
23	2007	14	15	0.05	0
23	2007	14	26	0.08	0
23	2007	15	15	0.08	0
23	2007	15	26	0.11	0
23	2007	16	15	0.1	0
23	2007	16	26	0.05	0
23	2007	18	15	0.09	0
23	2007	18	26	0.03	0
23	2007	19	15	0.08	0
23	2007	19	26	0.06	0
23	2007	20	15	0.06	0
23	2007	20	26	9.12743263650783E-03	0
23	2007	21	15	0.03	0
23	2007	21	26	9.40509870954358E-03	0
23	2007	22	15	0.03	0
23	2007	22	26	0.01	0
23	2007	23	15	0.01	0
23	2007	23	26	0.03	0
23	2007	24	15	8.06451612903226E-03	0
23	2007	24	26	6.19482583634936E-03	0
34	2000	2	26	0.03	0
34	2000	2	28	0.02	0
34	2000	3	26	0.02	0
34	2000	3	28	0.03	0
34	2000	4	26	0.06	0
34	2000	4	28	0.04	0
34	2000	5	26	0.06	0
34	2000	5	28	0.05	0
34	2000	6	26	9.61098398169336E-03	0
34	2000	6	28	0.02	0
34	2000	7	26	0.04	0
34	2000	7	28	0.05	0
34	2000	8	26	0.02	0
34	2000	8	28	0.04	0
34	2000	9	26	0.01	0
34	2000	9	28	0.02	0
34	2000	10	26	0.03	0
34	2000	10	28	0.02	0
34	2000	11	26	0.01	0
34	2000	11	28	0.02	0
34	2000	12	26	0.03	0
34	2000	12	28	0.01	0
34	2000	13	26	0.04	0
34	2000	13	28	0.03	0
34	2000	14	26	0.1	0
34	2000	14	28	0.11	0
34	2000	15	26	0.09	0
34	2000	15	28	0.09	0
34	2000	16	26	0.14	0
34	2000	16	28	0.07	0
34	2000	17	26	0.29	0
34	2000	17	28	0.12	0
34	2000	18	26	0.2	0
34	2000	18	28	0.15	0
34	2000	19	26	0.34	0
34	2000	19	28	0.29	0
34	2000	20	26	0.31	0
34	2000	20	28	0.31	0
34	2000	21	26	0.08	0
34	2000	21	28	0.07	0
34	2000	22	26	0.04	0
34	2000	22	28	0.02	0
34	2000	23	26	0.09	0
34	2000	23	28	0.04	0
34	2000	25	26	0.03	0
34	2000	25	28	0.03	0
34	2000	26	26	7.13107338619552E-03	0
34	2000	26	28	7.67676767676768E-03	0
34	2001	2	26	9.22213311948677E-03	0
34	2001	2	28	3.63636363636364E-03	0
34	2001	4	26	0.02	0
34	2001	4	28	0.01	0
34	2001	5	26	0.02	0
34	2001	5	28	0.01	0
34	2001	6	26	0.02	0
34	2001	6	28	0.01	0
34	2001	7	26	0.04	0
34	2001	7	28	0.02	0
34	2001	8	26	0.03	0
34	2001	8	28	0.02	0
34	2001	9	26	0.02	0
34	2001	9	28	0.02	0
34	2001	10	26	0.02	0
34	2001	10	28	0.02	0
34	2001	11	26	7.4370709382151E-03	0
34	2001	11	28	0.01	0
34	2001	12	26	0.02	0
34	2001	12	28	0.03	0
34	2001	13	26	0.01	0
34	2001	13	28	0.02	0
34	2001	14	26	0.1	0
34	2001	14	28	0.05	0
34	2001	15	26	0.43	0
34	2001	15	28	0.46	0
34	2001	16	26	0.2	0
34	2001	16	28	0.25	0
34	2001	17	26	0.48	0
34	2001	17	28	0.55	0
34	2001	18	26	0.24	0
34	2001	18	28	0.32	0
34	2001	20	26	0.33	0
34	2001	20	28	0.26	0
34	2001	21	26	0.1	0
34	2001	21	28	0.09	0
34	2001	22	26	0.07	0
34	2001	22	28	0.08	0
34	2001	23	26	0.11	0
34	2001	23	28	0.1	0
34	2001	24	26	0.06	0
34	2001	24	28	0.03	0
34	2001	25	26	0.02	0
34	2001	25	28	0.01	0
34	2001	26	26	0.02	0
34	2001	26	28	0.01	0
34	2002	1	26	0.02	0
34	2002	1	28	0.02	0
34	2002	3	26	0.02	0
34	2002	3	28	0.02	0
34	2002	4	26	0.04	0
34	2002	4	28	0.07	0
34	2002	5	26	0.03	0
34	2002	5	28	0.04	0
34	2002	6	26	0.04	0
34	2002	6	28	0.03	0
34	2002	7	26	0.04	0
34	2002	7	28	0.03	0
34	2002	8	26	0.03	0
34	2002	8	28	0.01	0
34	2002	9	26	0.02	0
34	2002	9	28	0.04	0
34	2002	10	26	0.03	0
34	2002	10	28	0.03	0
34	2002	11	26	0.03	0
34	2002	11	28	0.02	0
34	2002	12	26	0.02	0
34	2002	12	28	0.03	0
34	2002	13	26	0.05	0
34	2002	13	28	0.02	0
34	2002	14	26	0.15	0
34	2002	14	28	0.09	0
34	2002	15	26	0.54	0
34	2002	15	28	0.36	0
34	2002	16	26	0.24	0
34	2002	16	28	0.19	0
34	2002	17	26	0.29	0
34	2002	17	28	0.23	0
34	2002	18	26	0.29	0
34	2002	18	28	0.3	0
34	2002	19	26	0.38	0
34	2002	19	28	0.31	0
34	2002	20	26	0.22	0
34	2002	20	28	0.1	0
34	2002	21	26	0.09	0
34	2002	21	28	0.06	0
34	2002	22	26	0.07	0
34	2002	22	28	0.06	0
34	2002	23	26	0.06	0
34	2002	23	28	0.04	0
34	2002	24	26	0.03	0
34	2002	24	28	0.01	0
34	2002	25	26	0.01	0
34	2002	25	28	4.44444444444444E-03	0
34	2002	26	26	0.01	0
34	2002	26	28	1.81818181818182E-03	0
34	2003	1	26	6.97674418604651E-03	0
34	2003	1	28	0.02	0
34	2003	2	26	0.01	0
34	2003	2	28	0.01	0
34	2003	3	26	0.02	0
34	2003	3	28	0.01	0
34	2003	4	26	0.02	0
34	2003	4	28	0.02	0
34	2003	5	26	0.04	0
34	2003	5	28	0.01	0
34	2003	7	26	0.01	0
34	2003	7	28	0.01	0
34	2003	8	26	0.02	0
34	2003	8	28	0.01	0
34	2003	9	26	0.02	0
34	2003	9	28	0.01	0
34	2003	10	26	0.03	0
34	2003	10	28	0.02	0
34	2003	11	26	0.08	0
34	2003	11	28	0.05	0
34	2003	12	26	0.05	0
34	2003	12	28	0.02	0
34	2003	13	26	0.19	0
34	2003	13	28	0.14	0
34	2003	14	26	0.21	0
34	2003	14	28	0.22	0
34	2003	15	26	0.25	0
34	2003	15	28	0.2	0
34	2003	16	26	0.21	0
34	2003	16	28	0.28	0
34	2003	17	26	0.22	0
34	2003	17	28	0.25	0
34	2003	18	26	0.37	0
34	2003	18	28	0.38	0
34	2003	19	26	0.21	0
34	2003	19	28	0.15	0
34	2003	20	26	0.12	0
34	2003	20	28	0.14	0
34	2003	21	26	0.22	0
34	2003	21	28	0.13	0
34	2003	22	26	0.24	0
34	2003	22	28	0.08	0
34	2003	23	26	0.13	0
34	2003	23	28	0.05	0
34	2003	24	26	0.11	0
34	2003	24	28	0.01	0
34	2003	25	26	0.08	0
34	2003	25	28	0.01	0
34	2003	26	26	0.01	0
34	2003	26	28	9.09090909090909E-03	0
34	2004	1	26	0.04	0
34	2004	1	28	0.02	0
34	2004	2	26	0.03	0
34	2004	2	28	0.02	0
34	2004	4	26	6.65207559695455E-03	0
34	2004	4	28	0.02	0
34	2004	7	26	0.01	0
34	2004	7	28	0.01	0
34	2004	8	26	9.76265233356394E-03	0
34	2004	8	28	0.02	0
34	2004	9	26	8.84732052578362E-03	0
34	2004	9	28	0.01	0
34	2004	10	26	0.01	0
34	2004	10	28	0.02	0
34	2004	11	26	0.03	0
34	2004	11	28	0.01	0
34	2004	12	26	0.03	0
34	2004	12	28	0.02	0
34	2004	13	26	0.07	0
34	2004	13	28	0.03	0
34	2004	14	26	0.09	0
34	2004	14	28	0.12	0
34	2004	15	26	0.12	0
34	2004	15	28	0.1	0
34	2004	16	26	0.18	0
34	2004	16	28	0.12	0
34	2004	17	26	0.3	0
34	2004	17	28	0.18	0
34	2004	18	26	0.29	0
34	2004	18	28	0.11	0
34	2004	19	26	0.23	0
34	2004	19	28	0.24	0
34	2004	20	26	0.38	0
34	2004	20	28	0.39	0
34	2004	22	26	0.38	0
34	2004	22	28	0.26	0
34	2004	23	26	0.11	0
34	2004	23	28	0.05	0
34	2004	24	26	0.1	0
34	2004	24	28	0.08	0
34	2004	25	26	0.06	0
34	2004	25	28	0.02	0
34	2005	1	26	0.06	0
34	2005	1	28	0.02	0
34	2005	2	26	0.03	0
34	2005	2	28	0.01	0
34	2005	3	26	0.07	0
34	2005	3	28	0.03	0
34	2005	4	26	0.04	0
34	2005	4	28	0.01	0
34	2005	5	26	0.06	0
34	2005	5	28	0.02	0
34	2005	6	26	0.03	0
34	2005	6	28	0.02	0
34	2005	7	26	0.02	0
34	2005	7	28	0.02	0
34	2005	9	26	0.01	0
34	2005	9	28	0.01	0
34	2005	9	28	0.02	0
34	2005	10	26	0.01	0
34	2005	10	28	0.02	0
34	2005	11	26	0.02	0
34	2005	11	28	0.01	0
34	2005	12	26	0.02	0
34	2005	12	28	0.01	0
34	2005	13	26	0.09	0
34	2005	13	28	0.05	0
34	2005	14	26	0.07	0
34	2005	14	28	0.18	0
34	2005	15	26	0.28	0
34	2005	15	28	0.29	0
34	2005	16	26	0.49	0
34	2005	16	28	0.45	0
34	2005	17	26	0.42	0
34	2005	17	28	0.39	0
34	2005	18	26	0.64	0
34	2005	18	28	0.35	0
34	2005	19	26	0.38	0
34	2005	19	28	0.25	0
34	2005	20	26	0.2	0
34	2005	20	28	0.12	0
34	2005	21	26	0.11	0
34	2005	21	28	0.07	0
34	2005	22	26	0.03	0
34	2005	22	28	0.02	0
34	2005	23	26	0.03	0
34	2005	23	28	0.05	0
34	2005	25	26	0.01	0
34	2005	25	28	1.81818181818182E-03	0
34	2005	26	26	0.01	0
34	2005	26	28	8.48484848484849E-03	0
34	2006	1	26	0.01	0
34	2006	1	28	0.01	0
34	2006	2	26	0.01	0
34	2006	2	28	0.02	0
34	2006	3	26	0.08	0
34	2006	3	28	0.02	0
34	2006	4	26	0.04	0
34	2006	4	28	0.01	0
34	2006	5	26	0.02	0
34	2006	5	28	0.02	0
34	2006	6	26	0.05	0
34	2006	6	28	0.02	0
34	2006	7	26	0.06	0
34	2006	7	28	0.01	0
34	2006	9	26	0.02	0
34	2006	9	28	0.01	0
34	2006	10	26	0.04	0
34	2006	10	28	0.04	0
34	2006	11	26	0.02	0
34	2006	11	28	0.02	0
34	2006	12	26	0.01	0
34	2006	12	28	0.01	0
34	2006	13	26	0.29	0
34	2006	13	28	0.22	0
34	2006	14	26	0.6	0
34	2006	14	28	0.45	0
34	2006	15	26	0.43	0
34	2006	15	28	0.3	0
34	2006	16	26	0.49	0
34	2006	16	28	0.31	0
34	2006	17	26	0.53	0
34	2006	17	28	0.53	0
34	2006	18	26	0.34	0
34	2006	18	28	0.36	0
34	2006	19	26	0.25	0
34	2006	19	28	0.35	0
34	2006	20	26	0.09	0
34	2006	20	28	0.13	0
34	2006	21	26	0.05	0
34	2006	21	28	0.08	0
34	2006	22	26	0.04	0
34	2006	22	28	0.04	0
34	2006	23	26	0.11	0
34	2006	23	28	0.1	0
34	2006	24	26	0.07	0
34	2006	24	28	0.04	0
34	2006	25	26	0.01	0
34	2006	25	28	0.01	0
34	2006	26	26	7.28274173806609E-03	0
34	2006	26	28	0.01	0
34	2007	1	26	0.11	0
34	2007	1	28	0.02	0
34	2007	2	26	0.08	0
34	2007	2	28	0.03	0
34	2007	3	26	0.08	0
34	2007	3	28	0.04	0
34	2007	4	26	0.09	0
34	2007	4	28	0.06	0
34	2007	5	26	0.05	0
34	2007	5	28	0.02	0
34	2007	7	26	9.07046476761619E-03	0
34	2007	7	28	7.67676767676768E-03	0
34	2007	8	26	8.40543620478622E-03	0
34	2007	8	28	9.09090909090909E-03	0
34	2007	9	26	0.02	0
34	2007	9	28	0.01	0
34	2007	10	26	0.03	0
34	2007	10	28	0.01	0
34	2007	11	26	0.02	0
34	2007	11	28	0.06	0
34	2007	12	26	0.01	0
34	2007	12	28	0.04	0
34	2007	13	26	0.17	0
34	2007	13	28	0.2	0
34	2007	14	26	0.54	0
34	2007	14	28	0.49	0
34	2007	15	26	0.82	0
34	2007	15	28	0.66	0
34	2007	16	26	0.78	0
34	2007	16	28	0.57	0
34	2007	17	26	0.61	0
34	2007	17	28	0.33	0
34	2007	18	26	0.17	0
34	2007	18	26	0.29	0
34	2007	18	28	0.08	0
34	2007	18	28	0.14	0
34	2007	19	26	0.28	0
34	2007	19	28	0.14	0
34	2007	20	26	0.11	0
34	2007	20	28	0.05	0
34	2007	21	26	0.1	0
34	2007	21	28	0.07	0
34	2007	22	26	0.1	0
34	2007	22	28	0.07	0
34	2007	23	26	0.07	0
34	2007	23	28	0.04	0
34	2007	24	26	0.08	0
34	2007	24	28	0.08	0
34	2007	25	26	0.06	0
34	2007	25	28	0.04	0
34	2007	26	26	0.02	0
34	2007	26	28	0.01	0
61	2000	5	26	5.26315789473684E-03	1
61	2000	9	12	3.7037037037037E-03	1
61	2000	9	16	4.16666666666667E-03	1
61	2000	9	19	9.09090909090909E-03	1
61	2000	9	24	0.01	1
61	2000	9	26	0.002	1
61	2000	9	32	2.77777777777778E-03	1
61	2000	10	12	3.7037037037037E-03	1
61	2000	10	16	4.16666666666667E-03	1
61	2000	10	19	9.09090909090909E-03	1
61	2000	10	24	0.01	1
61	2000	10	26	0.002	1
61	2000	10	32	2.77777777777778E-03	1
61	2000	16	16	0.02	1
61	2000	16	19	9.09090909090909E-03	1
61	2000	16	24	2.63157894736842E-03	1
61	2000	16	26	0.02	1
61	2000	17	16	0.1	1
61	2000	17	18	0.01	1
61	2000	17	19	0.07	1
61	2000	17	24	5.26315789473684E-03	1
61	2000	17	26	0.12	1
61	2000	17	32	7.69230769230769E-03	1
61	2000	19	12	7.40740740740741E-03	1
61	2000	19	16	0.89	1
61	2000	19	18	0.01	1
61	2000	19	19	0.95	1
61	2000	19	24	0.01	1
61	2000	19	26	0.32	1
61	2000	21	16	0.06	1
61	2000	21	18	0.01	1
61	2000	21	19	0.17	1
61	2000	21	24	0.01	1
61	2000	21	26	0.22	1
61	2000	21	32	5.34188034188034E-03	1
61	2001	6	19	9.09090909090909E-03	1
61	2001	6	32	2.56410256410256E-03	1
61	2001	8	12	7.40740740740741E-03	1
61	2001	8	16	0.04	1
61	2001	8	18	0.01	1
61	2001	8	19	0.06	1
61	2001	8	24	0.01	1
61	2001	8	26	0.01	1
61	2001	8	32	8.33333333333333E-03	1
61	2001	12	16	0.03	1
61	2001	12	19	0.02	1
61	2001	12	24	5.26315789473684E-03	1
61	2001	12	26	0.01	1
61	2001	17	16	0.06	1
61	2001	17	19	0.04	1
61	2001	17	24	2.63157894736842E-03	1
61	2001	17	26	0.05	1
61	2001	18	16	0.58	1
61	2001	18	19	0.5	1
61	2001	18	24	0.02	1
61	2001	18	26	0.6	1
61	2001	19	16	0.5	1
61	2001	19	18	0.01	1
61	2001	19	19	0.37	1
61	2001	19	24	7.89473684210526E-03	1
61	2001	19	26	0.33	1
61	2001	19	32	0.02	1
61	2001	21	12	7.40740740740741E-03	1
61	2001	21	16	0.41	1
61	2001	21	19	0.15	1
61	2001	21	24	0.02	1
61	2001	21	26	0.16	1
61	2001	21	32	0.01	1
61	2002	4	32	2.77777777777778E-03	1
61	2002	8	12	7.40740740740741E-03	1
61	2002	8	16	0.13	1
61	2002	8	18	5.55555555555556E-03	1
61	2002	8	19	0.05	1
61	2002	8	24	0.02	1
61	2002	8	26	0.02	1
61	2002	8	32	2.77777777777778E-03	1
61	2002	10	12	3.7037037037037E-03	1
61	2002	10	16	0.09	1
61	2002	10	18	0.01	1
61	2002	10	19	0.04	1
61	2002	10	24	0.01	1
61	2002	10	26	0.02	1
61	2002	12	16	0.05	1
61	2002	12	19	0.09	1
61	2002	12	24	2.63157894736842E-03	1
61	2002	12	26	0.01	1
61	2002	12	32	2.77777777777778E-03	1
61	2002	14	16	0.02	1
61	2002	14	19	0.04	1
61	2002	14	24	7.89473684210526E-03	1
61	2002	14	26	0.1	1
61	2002	14	32	2.56410256410256E-03	1
61	2002	15	26	0.06	1
61	2002	18	16	1.05	1
61	2002	18	18	5.55555555555556E-03	1
61	2002	18	19	0.58	1
61	2002	18	26	0.51	1
61	2002	18	32	0.02	1
61	2002	20	16	1.01	1
61	2002	20	18	0.01	1
61	2002	20	19	0.47	1
61	2002	20	24	2.63157894736842E-03	1
61	2002	20	26	0.78	1
61	2002	20	32	0.02	1
61	2002	21	16	0.17	1
61	2002	21	18	5.55555555555556E-03	1
61	2002	21	19	0.1	1
61	2002	21	24	5.26315789473684E-03	1
61	2002	21	26	0.25	1
61	2003	2	16	4.16666666666667E-03	1
61	2003	3	16	4.16666666666667E-03	1
61	2003	4	18	5.55555555555556E-03	1
61	2003	4	24	7.89473684210526E-03	1
61	2003	4	26	0.004	1
61	2003	7	16	0.02	1
61	2003	7	19	9.09090909090909E-03	1
61	2003	7	24	2.63157894736842E-03	1
61	2003	8	12	3.7037037037037E-03	1
61	2003	8	16	0.05	1
61	2003	8	18	5.55555555555556E-03	1
61	2003	8	19	0.01	1
61	2003	8	24	0.01	1
61	2003	9	12	3.7037037037037E-03	1
61	2003	9	16	0.03	1
61	2003	9	18	5.55555555555556E-03	1
61	2003	9	19	9.09090909090909E-03	1
61	2003	9	24	0.01	1
61	2003	10	16	4.16666666666667E-03	1
61	2003	10	19	0.04	1
61	2003	10	24	5.26315789473684E-03	1
61	2003	11	12	3.7037037037037E-03	1
61	2003	11	19	0.06	1
61	2003	13	12	3.7037037037037E-03	1
61	2003	13	16	0.03	1
61	2003	13	19	0.1	1
61	2003	13	24	5.26315789473684E-03	1
61	2003	13	26	0.03	1
61	2003	14	19	9.09090909090909E-03	1
61	2003	14	26	0.03	1
61	2003	15	16	0.04	1
61	2003	15	19	0.06	1
61	2003	15	24	7.89473684210526E-03	1
61	2003	15	26	0.03	1
61	2003	16	16	0.29	1
61	2003	16	18	0.01	1
61	2003	16	19	0.25	1
61	2003	16	24	0.01	1
61	2003	16	26	0.16	1
61	2003	17	16	0.24	1
61	2003	17	18	0.01	1
61	2003	17	19	0.2	1
61	2003	17	24	5.26315789473684E-03	1
61	2003	17	26	0.14	1
61	2003	18	12	3.7037037037037E-03	1
61	2003	18	16	1.35	1
61	2003	18	18	5.55555555555556E-03	1
61	2003	18	19	0.32	1
61	2003	18	24	7.89473684210526E-03	1
61	2003	18	26	0.44	1
61	2003	18	32	0.01	1
61	2003	19	12	3.7037037037037E-03	1
61	2003	19	16	0.74	1
61	2003	19	18	5.55555555555556E-03	1
61	2003	19	19	0.5	1
61	2003	19	24	0.03	1
61	2003	19	26	0.19	1
61	2003	19	32	0.01	1
61	2004	6	12	3.7037037037037E-03	1
61	2004	6	24	2.63157894736842E-03	1
61	2004	6	26	0.01	1
61	2004	8	12	3.7037037037037E-03	1
61	2004	8	16	0.04	1
61	2004	8	18	5.55555555555556E-03	1
61	2004	8	19	0.01	1
61	2004	8	24	0.01	1
61	2004	8	26	9.26315789473684E-03	1
61	2004	8	32	7.69230769230769E-03	1
61	2004	11	16	0.06	1
61	2004	11	19	0.09	1
61	2004	11	24	7.89473684210526E-03	1
61	2004	11	26	0.02	1
61	2004	12	16	0.21	1
61	2004	12	19	0.19	1
61	2004	12	24	0.01	1
61	2004	12	26	0.29	1
61	2004	12	32	2.56410256410256E-03	1
61	2005	5	16	4.16666666666667E-03	1
61	2005	5	26	0.002	1
61	2005	6	16	0.01	1
61	2005	6	18	5.55555555555556E-03	1
61	2005	6	19	0.03	1
61	2005	6	24	2.63157894736842E-03	1
61	2005	6	26	0.004	1
61	2005	7	16	4.16666666666667E-03	1
61	2005	7	19	9.09090909090909E-03	1
61	2005	9	16	0.06	1
61	2005	9	19	0.01	1
61	2005	9	24	5.26315789473684E-03	1
61	2005	9	26	0.002	1
61	2005	10	16	0.02	1
61	2005	10	18	5.55555555555556E-03	1
61	2005	10	19	9.09090909090909E-03	1
61	2005	10	24	7.89473684210526E-03	1
61	2005	11	12	3.7037037037037E-03	1
61	2005	11	16	0.05	1
61	2005	11	18	5.55555555555556E-03	1
61	2005	11	19	0.04	1
61	2005	11	24	0.01	1
61	2005	11	26	0.03	1
61	2005	12	12	3.7037037037037E-03	1
61	2005	12	16	0.04	1
61	2005	12	19	0.03	1
61	2005	12	24	5.26315789473684E-03	1
61	2005	12	26	0.03	1
61	2005	13	16	0.09	1
61	2005	13	18	0.01	1
61	2005	13	19	9.09090909090909E-03	1
61	2005	13	24	7.89473684210526E-03	1
61	2005	13	26	0.49	1
61	2005	14	16	0.25	1
61	2005	14	19	0.07	1
61	2005	14	26	0.14	1
61	2005	17	12	3.7037037037037E-03	1
61	2005	17	16	0.06	1
61	2005	17	19	0.03	1
61	2005	17	24	5.26315789473684E-03	1
61	2005	17	26	0.03	1
61	2005	17	32	2.56410256410256E-03	1
61	2005	20	16	0.35	1
61	2005	20	18	0.01	1
61	2005	20	19	0.09	1
61	2005	20	24	0.03	1
61	2005	20	26	0.36	1
61	2005	20	32	7.69230769230769E-03	1
61	2005	21	12	7.40740740740741E-03	1
61	2005	21	16	0.07	1
61	2005	21	18	0.01	1
61	2005	21	19	0.14	1
61	2005	21	26	0.07	1
61	2005	23	19	9.09090909090909E-03	1
61	2005	23	26	0.11	1
61	2005	24	16	0.01	1
61	2005	24	18	5.55555555555556E-03	1
61	2005	24	24	2.63157894736842E-03	1
61	2005	24	26	0.01	1
61	2006	5	16	2.7027027027027E-03	1
61	2006	5	24	2.63157894736842E-03	1
61	2006	6	16	4.16666666666667E-03	1
61	2006	6	18	0.02	1
61	2006	6	19	0.03	1
61	2006	6	24	0.01	1
61	2006	6	26	9.26315789473684E-03	1
61	2006	6	32	2.77777777777778E-03	1
61	2006	9	19	9.09090909090909E-03	1
61	2006	10	19	9.09090909090909E-03	1
61	2006	11	16	0.01	1
61	2006	11	18	5.55555555555556E-03	1
61	2006	11	19	0.05	1
61	2006	11	24	0.02	1
61	2006	11	26	0.02	1
61	2006	11	32	5.34188034188034E-03	1
61	2006	12	16	0.01	1
61	2006	12	18	0.01	1
61	2006	12	19	0.04	1
61	2006	12	26	0.05	1
61	2006	13	16	0.01	1
61	2006	13	18	0.01	1
61	2006	13	19	0.04	1
61	2006	13	26	0.05	1
61	2006	14	16	0.22	1
61	2006	14	19	0.03	1
61	2006	14	24	2.63157894736842E-03	1
61	2006	14	26	0.04	1
61	2006	15	16	0.21	1
61	2006	15	19	0.01	1
61	2006	15	24	5.26315789473684E-03	1
61	2006	15	26	0.06	1
61	2006	16	16	0.1	1
61	2006	16	18	0.02	1
61	2006	16	19	0.15	1
61	2006	16	24	2.63157894736842E-03	1
61	2006	16	26	0.08	1
61	2006	16	32	8.11965811965812E-03	1
61	2006	17	16	0.55	1
61	2006	17	18	0.04	1
61	2006	17	19	0.41	1
61	2006	17	24	0.05	1
61	2006	17	26	0.57	1
61	2006	17	32	0.01	1
61	2006	18	16	0.35	1
61	2006	18	18	0.03	1
61	2006	18	19	0.31	1
61	2006	18	24	0.03	1
61	2006	18	26	0.44	1
61	2006	18	32	0.01	1
61	2006	21	16	0.04	1
61	2006	21	19	0.05	1
61	2006	21	24	2.63157894736842E-03	1
61	2006	21	26	0.05	1
61	2006	23	16	0.1	1
61	2006	23	19	0.06	1
61	2006	23	26	0.06	1
61	2006	24	16	0.04	1
61	2006	24	19	0.02	1
61	2006	24	26	9.09090909090909E-03	1
61	2007	1	26	9.09090909090909E-03	1
61	2007	2	16	8.33333333333333E-03	1
61	2007	2	18	5.55555555555556E-03	1
61	2007	2	24	2.63157894736842E-03	1
61	2007	2	32	5.55555555555556E-03	1
61	2007	4	16	0.05	1
61	2007	4	19	0.01	1
61	2007	4	24	0.01	1
61	2007	4	26	0.008	1
61	2007	5	16	0.05	1
61	2007	5	18	0.01	1
61	2007	5	19	0.01	1
61	2007	5	24	0.02	1
61	2007	5	26	0.02	1
61	2007	7	16	8.33333333333333E-03	1
61	2007	7	18	5.55555555555556E-03	1
61	2007	7	24	5.26315789473684E-03	1
61	2007	7	26	0.002	1
61	2007	8	16	0.17	1
61	2007	8	18	0.03	1
61	2007	8	19	0.1	1
61	2007	8	24	0.01	1
61	2007	8	26	0.03	1
61	2007	9	16	0.07	1
61	2007	9	24	5.26315789473684E-03	1
61	2007	9	26	0.002	1
61	2007	10	16	0.03	1
61	2007	10	19	0.03	1
61	2007	10	24	2.63157894736842E-03	1
61	2007	10	26	0.02	1
61	2007	11	16	0.12	1
61	2007	11	19	0.1	1
61	2007	11	24	2.63157894736842E-03	1
61	2007	11	26	0.06	1
61	2007	11	32	0.01	1
61	2007	12	16	0.11	1
61	2007	12	18	5.55555555555556E-03	1
61	2007	12	19	0.1	1
61	2007	12	24	5.26315789473684E-03	1
61	2007	12	26	0.08	1
61	2007	13	19	0.01	1
61	2007	13	24	2.63157894736842E-03	1
61	2007	13	26	9.09090909090909E-03	1
61	2007	16	16	0.16	1
61	2007	16	19	0.3	1
61	2007	16	24	5.26315789473684E-03	1
61	2007	16	26	0.11	1
61	2007	16	32	0.01	1
61	2007	18	16	0.45	1
61	2007	18	19	0.2	1
61	2007	18	26	0.12	1
61	2007	19	12	3.7037037037037E-03	1
61	2007	19	16	0.43	1
61	2007	19	18	5.55555555555556E-03	1
61	2007	19	19	0.39	1
61	2007	19	24	0.01	1
61	2007	19	26	0.34	1
61	2007	19	32	7.69230769230769E-03	1
61	2007	21	16	0.46	1
61	2007	21	19	0.22	1
61	2007	21	26	0.32	1
61	2007	21	32	8.11965811965812E-03	1
61	2007	23	16	0.01	1
61	2007	23	19	0.07	1
61	2007	23	26	0.12	1
61	2007	23	32	2.56410256410256E-03	1
72	2000	1	31	0.06	2
72	2000	2	31	0.03	2
72	2000	4	31	0.04	2
72	2000	5	31	0.22	2
72	2000	6	31	0.18	2
72	2000	7	31	0.42	2
72	2000	8	31	0.23	2
72	2000	9	31	0.12	2
72	2000	10	31	0.09	2
72	2000	11	31	0.21	2
72	2000	12	31	0.27	2
72	2000	13	31	0.44	2
72	2000	14	31	0.49	2
72	2000	15	31	1.17	2
72	2000	16	31	0.51	2
72	2000	17	31	0.18	2
72	2000	18	31	0.1	2
72	2000	19	31	0.17	2
72	2000	20	31	0.09	2
72	2000	21	31	0.36	2
72	2000	22	31	0.27	2
72	2000	23	31	0.05	2
72	2000	24	31	0.16	2
72	2000	25	31	0.19	2
72	2000	26	31	0.45	2
72	2001	5	31	0.1	2
72	2001	6	31	0.36	2
72	2001	7	31	0.23	2
72	2001	8	31	0.32	2
72	2001	10	31	0.22	2
72	2001	11	31	0.11	2
72	2001	12	31	0.13	2
72	2001	13	31	0.2	2
72	2001	14	31	0.65	2
72	2001	15	31	0.56	2
72	2001	16	31	0.58	2
72	2001	17	31	0.6	2
72	2001	18	31	0.64	2
72	2001	19	31	0.59	2
72	2001	20	31	0.2	2
72	2001	21	31	0.2	2
72	2001	22	31	0.09	2
72	2001	23	31	0.05	2
72	2001	24	31	0.07	2
72	2001	25	31	0.07	2
72	2001	26	31	0.13	2
72	2002	1	31	0.04	2
72	2002	2	31	0.11	2
72	2002	3	31	0.03	2
72	2002	4	31	0.05	2
72	2002	5	31	0.21	2
72	2002	6	31	0.35	2
72	2002	7	31	0.39	2
72	2002	8	31	0.2	2
72	2002	9	31	0.19	2
72	2002	10	31	0.23	2
72	2002	11	31	0.17	2
72	2002	12	31	0.25	2
72	2002	14	31	0.21	2
72	2002	15	31	0.23	2
72	2002	16	31	0.15	2
72	2002	17	31	0.28	2
72	2002	18	31	0.37	2
72	2002	19	31	0.22	2
72	2002	20	31	0.33	2
72	2002	21	31	0.2	2
72	2002	22	31	0.17	2
72	2002	23	31	0.23	2
72	2002	24	31	0.32	2
72	2002	25	31	0.33	2
72	2002	26	31	0.34	2
72	2003	1	31	0.02	2
72	2003	2	31	0.13	2
72	2003	3	31	0.1	2
72	2003	4	31	0.06	2
72	2003	5	31	0.21	2
72	2003	6	31	0.39	2
72	2003	7	31	0.2	2
72	2003	9	31	0.12	2
72	2003	10	31	0.08	2
72	2003	11	31	0.13	2
72	2003	12	31	0.3	2
72	2003	13	31	0.53	2
72	2003	15	31	1.18	2
72	2003	16	31	0.59	2
72	2003	17	31	0.55	2
72	2003	18	31	0.24	2
72	2003	19	31	0.24	2
72	2003	20	31	0.08	2
72	2003	21	31	0.13	2
72	2003	22	31	0.24	2
72	2003	23	31	0.46	2
72	2003	24	31	0.58	2
72	2003	25	31	0.26	2
72	2003	26	31	0.26	2
72	2004	1	31	0.04	2
72	2004	2	31	0.07	2
72	2004	3	31	0.06	2
72	2004	5	31	0.22	2
72	2004	6	31	0.11	2
72	2004	7	31	0.37	2
72	2004	8	31	0.29	2
72	2004	9	31	0.3	2
72	2004	11	31	0.24	2
72	2004	12	31	0.29	2
72	2004	13	31	0.34	2
72	2004	14	31	0.42	2
72	2004	16	31	0.46	2
72	2004	17	31	0.82	2
72	2004	18	31	0.31	2
72	2004	19	31	0.48	2
72	2004	20	31	0.18	2
72	2004	21	31	0.2	2
72	2004	22	31	0.23	2
72	2004	23	31	0.3	2
72	2004	24	31	0.1	2
72	2004	25	31	0.08	2
72	2004	26	31	0.09	2
72	2005	1	31	0.08	2
72	2005	3	31	0.03	2
72	2005	4	31	0.13	2
72	2005	5	31	0.06	2
72	2005	6	31	0.16	2
72	2005	7	31	0.09	2
72	2005	8	31	0.19	2
72	2005	9	31	0.14	2
72	2005	10	31	0.13	2
72	2005	12	31	0.12	2
72	2005	13	31	0.54	2
72	2005	14	31	0.34	2
72	2005	15	31	0.35	2
72	2005	16	31	0.55	2
72	2005	18	31	0.62	2
72	2005	19	31	0.52	2
72	2005	20	31	0.29	2
72	2005	21	31	0.19	2
72	2005	22	31	0.19	2
72	2005	23	31	0.19	2
72	2005	24	31	0.4	2
72	2005	25	31	0.27	2
72	2005	26	31	0.14	2
72	2006	2	31	0.00625	2
72	2006	3	31	0.06	2
72	2006	4	31	0.1	2
72	2006	5	31	0.03	2
72	2006	6	31	0.35	2
72	2006	8	31	0.03	2
72	2006	9	31	0.03	2
72	2006	10	31	0.09	2
72	2006	11	31	0.2	2
72	2006	12	31	0.14	2
72	2006	13	31	0.21	2
72	2006	14	31	0.37	2
72	2006	15	31	0.53	2
72	2006	16	31	0.71	2
72	2006	17	31	0.38	2
72	2006	18	31	0.34	2
72	2006	19	31	0.22	2
72	2006	20	31	0.22	2
72	2006	21	31	0.12	2
72	2006	23	31	0.08	2
72	2006	25	31	0.56	2
72	2006	26	31	0.3	2
72	2007	1	31	0.03	2
72	2007	2	31	0.1	2
72	2007	4	31	0.27	2
72	2007	5	31	0.18	2
72	2007	7	31	0.06	2
72	2007	9	31	0.06	2
72	2007	10	31	0.14	2
72	2007	11	31	0.05	2
72	2007	12	31	0.09	2
72	2007	13	31	0.08	2
72	2007	15	31	0.27	2
72	2007	16	31	0.42	2
72	2007	18	31	0.54	2
72	2007	19	31	0.55	2
72	2007	21	31	0.32	2
72	2007	22	31	0.03	2
72	2007	23	31	0.22	2
72	2007	24	31	0.14	2
72	2007	26	31	0.05	2
84	2000	1	27	0.04	0
84	2000	1	32	0.11	0
84	2000	2	27	0.08	0
84	2000	2	32	0.17	0
84	2000	3	27	0.01	0
84	2000	3	32	0.07	0
84	2000	4	27	0.01	0
84	2000	4	32	0.05	0
84	2000	5	32	0.08	0
84	2000	6	32	0.09	0
84	2000	7	27	0.01	0
84	2000	7	32	0.11	0
84	2000	9	27	0.01	0
84	2000	9	32	0.03	0
84	2000	10	27	0.02	0
84	2000	10	32	0.04	0
84	2000	11	27	5.26315789473684E-03	0
84	2000	11	32	0.03	0
84	2000	12	27	0.01	0
84	2000	12	32	0.08	0
84	2000	13	27	0.02	0
84	2000	13	32	0.07	0
84	2000	14	27	0.02	0
84	2000	14	32	0.27	0
84	2000	16	32	0.43	0
84	2000	17	27	0.01	0
84	2000	17	32	0.32	0
84	2000	18	27	0.02	0
84	2000	18	32	0.31	0
84	2000	19	27	0.01	0
84	2000	19	32	0.46	0
84	2000	20	27	0.03	0
84	2000	20	32	0.27	0
84	2000	21	27	0.02	0
84	2000	21	32	0.21	0
84	2000	22	27	0.01	0
84	2000	22	32	0.09	0
84	2000	23	27	0.01	0
84	2000	23	32	0.11	0
84	2000	24	32	0.06	0
84	2000	25	32	0.01	0
84	2000	26	32	0.02	0
84	2001	8	27	0.01	0
84	2001	8	32	0.08	0
84	2001	9	27	0.01	0
84	2001	9	32	0.05	0
84	2001	10	27	5.26315789473684E-03	0
84	2001	10	32	0.04	0
84	2001	11	27	0.03	0
84	2001	11	32	0.01	0
84	2001	12	27	0.01	0
84	2001	12	32	0.02	0
84	2001	13	27	5.26315789473684E-03	0
84	2001	13	32	0.05	0
84	2001	14	32	0.19	0
84	2001	16	32	0.43	0
84	2001	17	32	0.19	0
84	2001	18	27	5.26315789473684E-03	0
84	2001	18	32	0.24	0
84	2001	19	32	0.14	0
84	2001	20	27	5.26315789473684E-03	0
84	2001	20	32	0.23	0
84	2001	21	27	0.01	0
84	2001	21	32	0.04	0
84	2001	22	27	5.26315789473684E-03	0
84	2001	22	32	0.05	0
84	2001	23	32	0.02	0
84	2001	24	32	0.04	0
84	2001	25	32	0.01	0
84	2001	26	32	0.01	0
84	2002	1	27	0.02	0
84	2002	1	32	0.14	0
84	2002	2	27	0.01	0
84	2002	2	32	0.01	0
84	2002	3	27	0.03	0
84	2002	3	32	0.22	0
84	2002	4	27	5.26315789473684E-03	0
84	2002	4	32	0.16	0
84	2002	6	27	0.02	0
84	2002	6	32	0.13	0
84	2002	7	27	5.26315789473684E-03	0
84	2002	7	32	0.15	0
84	2002	9	27	0.03	0
84	2002	9	32	0.12	0
84	2002	12	27	0.02	0
84	2002	12	32	0.07	0
84	2002	13	27	0.01	0
84	2002	13	32	0.01	0
84	2002	15	27	0.01	0
84	2002	15	32	0.17	0
84	2002	16	32	0.07	0
84	2002	17	27	0.03	0
84	2002	17	32	0.27	0
84	2002	18	27	5.26315789473684E-03	0
84	2002	18	27	0.03	0
84	2002	18	32	0.04	0
84	2002	18	32	0.13	0
84	2002	19	27	5.26315789473684E-03	0
84	2002	19	32	0.04	0
84	2002	20	27	0.01	0
84	2002	20	32	0.1	0
84	2002	21	27	0.03	0
84	2002	21	32	0.05	0
84	2002	22	27	0.04	0
84	2002	22	32	0.08	0
84	2002	22	32	0.09	0
84	2002	23	32	0.09	0
84	2002	24	32	0.04	0
84	2002	25	32	0.01	0
84	2002	26	32	0.01	0
84	2003	1	27	0.01	0
84	2003	1	32	0.08	0
84	2003	2	27	0.01	0
84	2003	2	32	0.11	0
84	2003	3	27	0.01	0
84	2003	3	32	0.11	0
84	2003	4	27	0.03	0
84	2003	4	32	0.15	0
84	2003	5	27	0.02	0
84	2003	5	32	0.18	0
84	2003	6	27	0.02	0
84	2003	6	32	0.09	0
84	2003	7	27	0.01	0
84	2003	7	32	0.12	0
84	2003	8	27	0.01	0
84	2003	8	32	0.08	0
84	2003	9	27	0.03	0
84	2003	9	32	0.02	0
84	2003	10	32	0.06	0
84	2003	11	27	0.03	0
84	2003	11	32	0.1	0
84	2003	12	27	0.03	0
84	2003	12	32	0.16	0
84	2003	13	27	0.01	0
84	2003	13	32	0.07	0
84	2003	15	27	0.02	0
84	2003	15	32	0.31	0
84	2003	16	27	0.01	0
84	2003	16	32	0.07	0
84	2003	17	32	0.19	0
84	2003	18	27	0.03	0
84	2003	18	32	0.21	0
84	2003	19	32	0.21	0
84	2003	20	27	5.26315789473684E-03	0
84	2003	20	32	0.34	0
84	2003	21	27	0.05	0
84	2003	21	32	0.54	0
84	2003	22	27	0.03	0
84	2003	22	32	0.31	0
84	2003	23	27	0.01	0
84	2003	23	32	0.22	0
84	2003	24	27	0.01	0
84	2003	24	32	0.23	0
84	2003	25	27	0.01	0
84	2003	25	32	0.08	0
84	2003	26	27	5.26315789473684E-03	0
84	2003	26	32	0.07	0
84	2004	1	27	0.04	0
84	2004	1	32	0.12	0
84	2004	2	27	0.02	0
84	2004	2	32	0.19	0
84	2004	3	27	0.03	0
84	2004	3	32	0.08	0
84	2004	4	27	0.02	0
84	2004	4	32	0.04	0
84	2004	5	32	0.08	0
84	2004	6	27	0.01	0
84	2004	6	32	0.07	0
84	2004	7	27	0.02	0
84	2004	7	32	0.05	0
84	2004	8	27	0.01	0
84	2004	8	32	0.09	0
84	2004	9	32	0.07	0
84	2004	10	27	0.03	0
84	2004	10	32	0.08	0
84	2004	11	27	0.02	0
84	2004	11	32	0.04	0
84	2004	12	27	5.26315789473684E-03	0
84	2004	12	32	0.08	0
84	2004	13	27	0.02	0
84	2004	13	32	0.17	0
84	2004	14	27	0.02	0
84	2004	14	32	0.24	0
84	2004	15	27	0.02	0
84	2004	15	32	0.18	0
84	2004	16	27	0.04	0
84	2004	16	32	0.29	0
84	2004	17	27	0.06	0
84	2004	17	32	0.24	0
84	2004	18	27	0.05	0
84	2004	18	32	0.21	0
84	2004	19	27	0.04	0
84	2004	19	32	0.18	0
84	2004	20	27	0.03	0
84	2004	20	32	0.1	0
84	2004	21	27	0.02	0
84	2004	21	32	0.11	0
84	2004	22	27	0.04	0
84	2004	22	32	0.07	0
84	2004	23	27	0.08	0
84	2004	23	32	0.03	0
84	2004	24	27	0.01	0
84	2004	24	32	0.03	0
84	2004	25	27	5.26315789473684E-03	0
84	2004	25	32	0.04	0
84	2005	1	27	0.03	0
84	2005	1	32	0.15	0
84	2005	3	27	0.02	0
84	2005	3	32	0.09	0
84	2005	5	27	0.01	0
84	2005	5	32	0.16	0
84	2005	6	27	0.05	0
84	2005	6	32	0.09	0
84	2005	7	27	0.06	0
84	2005	7	32	0.17	0
84	2005	8	27	0.09	0
84	2005	8	32	0.09	0
84	2005	9	27	0.05	0
84	2005	9	32	0.05	0
84	2005	10	27	0.05	0
84	2005	10	32	0.09	0
84	2005	11	27	0.05	0
84	2005	11	32	0.09	0
84	2005	12	27	0.04	0
84	2005	12	32	0.02	0
84	2005	13	27	0.08	0
84	2005	13	32	0.26	0
84	2005	15	27	0.09	0
84	2005	15	32	0.22	0
84	2005	16	27	0.1	0
84	2005	16	32	0.6	0
84	2005	17	27	0.02	0
84	2005	17	32	0.34	0
84	2005	18	27	0.02	0
84	2005	18	32	0.33	0
84	2005	19	27	0.05	0
84	2005	19	32	0.23	0
84	2005	20	27	0.07	0
84	2005	20	32	0.15	0
84	2005	21	27	0.09	0
84	2005	21	32	0.04	0
84	2005	22	27	0.01	0
84	2005	22	32	0.05	0
84	2005	23	27	0.07	0
84	2005	23	32	0.08	0
84	2005	24	32	0.05	0
84	2005	25	27	0.01	0
84	2005	25	32	9.9537037037037E-03	0
84	2005	26	32	0.01	0
84	2006	1	27	0.09	0
84	2006	1	32	0.25	0
84	2006	3	27	0.06	0
84	2006	3	32	0.24	0
84	2006	4	27	0.01	0
84	2006	4	32	0.11	0
84	2006	5	27	0.02	0
84	2006	5	32	0.04	0
84	2006	6	27	0.03	0
84	2006	6	32	0.2	0
84	2006	7	27	0.02	0
84	2006	7	32	0.06	0
84	2006	9	27	0.07	0
84	2006	9	32	0.21	0
84	2006	10	27	0.02	0
84	2006	10	32	0.06	0
84	2006	11	27	0.02	0
84	2006	11	32	0.15	0
84	2006	12	27	0.03	0
84	2006	12	32	0.11	0
84	2006	13	27	0.04	0
84	2006	13	32	0.37	0
84	2006	14	27	0.14	0
84	2006	14	32	1.34	0
84	2006	15	27	0.07	0
84	2006	15	32	0.82	0
84	2006	17	27	0.17	0
84	2006	17	32	0.53	0
84	2006	18	27	0.08	0
84	2006	18	32	0.25	0
84	2006	19	27	0.15	0
84	2006	19	32	0.22	0
84	2006	21	27	0.14	0
84	2006	21	32	0.1	0
84	2006	22	27	0.03	0
84	2006	22	32	0.06	0
84	2006	23	27	0.04	0
84	2006	23	32	0.09	0
84	2006	25	27	0.01	0
84	2006	25	32	0.02	0
84	2006	26	27	0.01	0
84	2006	26	32	0.02	0
84	2007	1	27	0.05	0
84	2007	1	32	0.27	0
84	2007	2	27	0.01	0
84	2007	2	32	0.11	0
84	2007	3	27	0.08	0
84	2007	3	32	0.28	0
84	2007	4	32	0.16	0
84	2007	5	27	0.05	0
84	2007	5	32	0.21	0
84	2007	8	27	0.06	0
84	2007	8	32	0.09	0
84	2007	9	32	0.01	0
84	2007	10	27	0.01	0
84	2007	10	32	0.06	0
84	2007	11	27	0.01	0
84	2007	11	32	0.03	0
84	2007	12	27	5.26315789473684E-03	0
84	2007	12	32	0.33	0
84	2007	14	27	0.14	0
84	2007	14	32	1.47	0
84	2007	15	27	0.03	0
84	2007	15	32	0.67	0
84	2007	16	27	0.05	0
84	2007	16	32	0.45	0
84	2007	17	27	0.09	0
84	2007	17	32	0.42	0
84	2007	18	27	0.02	0
84	2007	18	32	0.19	0
84	2007	19	32	0.06	0
84	2007	20	27	0.06	0
84	2007	20	32	0.08	0
84	2007	21	27	0.03	0
84	2007	21	32	0.05	0
84	2007	22	27	0.01	0
84	2007	22	32	0.07	0
84	2007	23	27	5.26315789473684E-03	0
84	2007	23	32	0.02	0
84	2007	24	27	0.01	0
84	2007	24	32	0.02	0
84	2007	25	32	7.40740740740741E-03	0
95	2000	1	16	0.01	0
95	2000	1	20	0.01	0
95	2000	1	26	0.01	0
95	2000	2	16	0.04	0
95	2000	2	17	0.01	0
95	2000	2	20	0.01	0
95	2000	2	26	0.02	0
95	2000	3	16	0.04	0
95	2000	3	17	0.01	0
95	2000	4	16	0.03	0
95	2000	4	20	0.01	0
95	2000	4	26	0.02	0
95	2000	5	16	0.06	0
95	2000	5	20	0.04	0
95	2000	5	25	0.03	0
95	2000	5	26	0.04	0
95	2000	6	16	0.07	0
95	2000	6	20	0.01	0
95	2000	6	25	0.03	0
95	2000	6	26	0.02	0
95	2000	7	16	0.11	0
95	2000	7	20	0.01	0
95	2000	7	25	0.03	0
95	2000	7	26	0.02	0
95	2000	7	40	0.005	0
95	2000	8	16	0.09	0
95	2000	8	20	0.02	0
95	2000	8	26	0.01	0
95	2000	9	16	0.05	0
95	2000	10	16	0.05	0
95	2000	11	16	0.11	0
95	2000	11	17	0.01	0
95	2000	11	20	5.88235294117647E-03	0
95	2000	11	26	7.69230769230769E-03	0
95	2000	12	16	0.05	0
95	2000	12	26	0.01	0
95	2000	12	40	0.01	0
95	2000	14	16	0.55	0
95	2000	14	17	0.16	0
95	2000	14	20	0.1	0
95	2000	14	25	0.05	0
95	2000	14	26	0.08	0
95	2000	14	27	0.01	0
95	2000	14	40	0.01	0
95	2000	15	16	0.56	0
95	2000	15	17	0.07	0
95	2000	15	20	0.08	0
95	2000	15	26	0.04	0
95	2000	16	16	0.81	0
95	2000	16	17	0.17	0
95	2000	16	20	0.11	0
95	2000	16	25	0.08	0
95	2000	16	26	0.11	0
95	2000	16	40	0.01	0
95	2000	17	16	0.66	0
95	2000	17	17	0.13	0
95	2000	17	20	0.1	0
95	2000	17	25	0.08	0
95	2000	17	26	0.07	0
95	2000	17	40	0.02	0
95	2000	18	16	0.71	0
95	2000	18	17	0.3	0
95	2000	18	20	0.1	0
95	2000	18	25	0.06	0
95	2000	18	26	0.11	0
95	2000	18	40	5.26315789473684E-03	0
95	2000	19	16	0.54	0
95	2000	19	17	0.16	0
95	2000	19	20	0.1	0
95	2000	19	25	0.03	0
95	2000	19	26	0.19	0
95	2000	20	16	1.02	0
95	2000	20	17	0.5	0
95	2000	20	20	0.18	0
95	2000	20	25	0.05	0
95	2000	20	26	0.37	0
95	2000	20	40	5.26315789473684E-03	0
95	2000	21	16	0.22	0
95	2000	21	17	0.1	0
95	2000	21	20	0.03	0
95	2000	21	26	0.07	0
95	2000	22	16	0.13	0
95	2000	22	17	0.22	0
95	2000	22	26	0.05	0
95	2000	23	16	0.09	0
95	2000	23	17	0.1	0
95	2000	23	26	0.01	0
95	2000	24	16	0.13	0
95	2000	24	17	0.03	0
95	2000	24	26	0.01	0
95	2000	25	16	0.03	0
95	2000	25	17	0.01	0
95	2000	25	20	5.88235294117647E-03	0
95	2000	25	25	0.03	0
95	2000	25	26	0.02	0
95	2000	26	16	0.03	0
95	2000	26	17	0.02	0
95	2000	26	20	0.02	0
95	2000	26	26	0.01	0
95	2001	10	16	0.15	0
95	2001	10	20	5.88235294117647E-03	0
95	2001	10	26	0.03	0
95	2001	11	16	0.03	0
95	2001	13	16	0.01	0
95	2001	13	26	0.01	0
95	2001	14	16	0.19	0
95	2001	14	17	0.01	0
95	2001	14	26	0.05	0
95	2001	14	40	0.005	0
95	2001	15	16	0.28	0
95	2001	15	17	0.02	0
95	2001	15	20	0.06	0
95	2001	15	26	0.08	0
95	2001	15	40	0.005	0
95	2001	16	16	0.31	0
95	2001	16	17	0.06	0
95	2001	16	20	0.08	0
95	2001	16	26	0.11	0
95	2001	16	40	0.005	0
95	2001	17	16	0.3	0
95	2001	17	17	0.03	0
95	2001	17	20	0.04	0
95	2001	17	25	0.05	0
95	2001	17	26	0.1	0
95	2001	17	27	0.01	0
95	2001	17	40	0.02	0
95	2001	18	16	0.36	0
95	2001	18	17	0.01	0
95	2001	18	20	0.01	0
95	2001	18	26	0.07	0
95	2001	18	40	0.03	0
95	2001	19	16	0.21	0
95	2001	19	17	0.02	0
95	2001	19	20	0.03	0
95	2001	19	26	0.04	0
95	2001	20	16	0.24	0
95	2001	20	17	0.08	0
95	2001	20	20	0.03	0
95	2001	20	26	0.09	0
95	2001	20	40	0.01	0
95	2001	21	16	0.11	0
95	2001	21	17	0.15	0
95	2001	21	20	0.01	0
95	2001	21	26	0.03	0
95	2001	22	16	0.09	0
95	2001	22	17	0.1	0
95	2001	22	26	0.02	0
95	2001	23	16	0.01	0
95	2001	23	17	0.03	0
95	2001	24	16	0.05	0
95	2001	24	20	5.88235294117647E-03	0
95	2001	24	26	6.45161290322581E-03	0
95	2001	26	16	0.01	0
95	2001	26	17	0.02	0
95	2001	26	25	0.01	0
95	2001	26	26	9.67741935483871E-03	0
95	2002	1	16	0.04	0
95	2002	1	20	0.04	0
95	2002	1	26	0.01	0
95	2002	1	40	0.005	0
95	2002	2	16	0.04	0
95	2002	2	20	0.02	0
95	2002	2	26	0.03	0
95	2002	2	40	0.005	0
95	2002	3	16	0.03	0
95	2002	3	20	0.01	0
95	2002	3	26	0.02	0
95	2002	4	16	0.11	0
95	2002	4	17	0.02	0
95	2002	4	20	0.02	0
95	2002	4	26	0.03	0
95	2002	4	40	0.005	0
95	2002	5	26	3.2258064516129E-03	0
95	2002	6	16	0.1	0
95	2002	6	20	5.88235294117647E-03	0
95	2002	6	26	0.05	0
95	2002	7	16	0.14	0
95	2002	7	20	0.01	0
95	2002	7	26	0.02	0
95	2002	7	40	5.26315789473684E-03	0
95	2002	8	16	0.08	0
95	2002	8	26	0.01	0
95	2002	9	16	0.05	0
95	2002	9	20	0.01	0
95	2002	9	26	0.01	0
95	2002	9	40	0.005	0
95	2002	10	16	0.06	0
95	2002	10	20	0.03	0
95	2002	10	26	3.2258064516129E-03	0
95	2002	11	16	0.03	0
95	2002	11	26	3.2258064516129E-03	0
95	2002	12	16	0.15	0
95	2002	12	17	0.01	0
95	2002	12	20	5.88235294117647E-03	0
95	2002	12	25	0.01	0
95	2002	12	26	0.02	0
95	2002	12	40	5.26315789473684E-03	0
95	2002	13	16	0.07	0
95	2002	13	17	0.01	0
95	2002	13	20	5.88235294117647E-03	0
95	2002	13	25	0.01	0
95	2002	13	26	0.01	0
95	2002	13	40	5.26315789473684E-03	0
95	2002	14	16	0.35	0
95	2002	14	20	0.01	0
95	2002	14	25	0.03	0
95	2002	14	26	0.07	0
95	2002	14	40	0.02	0
95	2002	15	16	0.41	0
95	2002	15	17	0.01	0
95	2002	15	20	0.03	0
95	2002	15	25	0.03	0
95	2002	15	26	0.11	0
95	2002	15	40	0.04	0
95	2002	16	16	0.24	0
95	2002	16	17	0.01	0
95	2002	16	20	0.01	0
95	2002	16	25	0.03	0
95	2002	16	26	0.09	0
95	2002	16	40	0.02	0
95	2002	19	16	0.34	0
95	2002	19	17	0.15	0
95	2002	19	20	0.1	0
95	2002	19	25	0.01	0
95	2002	19	26	0.04	0
95	2002	19	40	0.03	0
95	2002	20	16	0.15	0
95	2002	20	17	0.06	0
95	2002	20	20	0.05	0
95	2002	20	25	0.05	0
95	2002	20	26	0.07	0
95	2002	20	40	5.26315789473684E-03	0
95	2002	21	16	0.1	0
95	2002	21	17	0.17	0
95	2002	21	20	0.04	0
95	2002	21	25	0.01	0
95	2002	21	26	0.05	0
95	2002	21	40	5.26315789473684E-03	0
95	2002	22	16	0.11	0
95	2002	22	16	0.13	0
95	2002	22	17	0.06	0
95	2002	22	17	0.15	0
95	2002	22	20	0.01	0
95	2002	22	20	0.02	0
95	2002	22	25	0.05	0
95	2002	22	26	0.03	0
95	2002	22	26	0.04	0
95	2002	22	40	0.01	0
95	2002	23	16	0.11	0
95	2002	23	17	0.06	0
95	2002	23	20	0.01	0
95	2002	23	26	0.03	0
95	2002	23	40	0.01	0
95	2002	24	16	0.06	0
95	2002	24	17	0.07	0
95	2002	24	25	0.01	0
95	2002	24	26	0.02	0
95	2002	25	16	4.34782608695652E-03	0
95	2002	25	17	0.01	0
95	2002	25	20	5.88235294117647E-03	0
95	2002	25	26	0.03	0
95	2002	26	20	0.01	0
95	2002	26	26	0.04	0
95	2003	1	16	4.34782608695652E-03	0
95	2003	1	20	0.01	0
95	2003	1	26	0.01	0
95	2003	2	16	0.04	0
95	2003	2	20	0.04	0
95	2003	2	26	0.04	0
95	2003	3	16	0.06	0
95	2003	3	20	0.03	0
95	2003	3	26	0.04	0
95	2003	4	16	0.02	0
95	2003	4	26	9.30232558139535E-03	0
95	2003	5	16	0.03	0
95	2003	5	16	0.06	0
95	2003	5	20	0.03	0
95	2003	5	25	0.01	0
95	2003	5	26	7.69230769230769E-03	0
95	2003	5	26	0.04	0
95	2003	5	40	5.26315789473684E-03	0
95	2003	6	16	0.06	0
95	2003	6	25	0.01	0
95	2003	6	26	0.04	0
95	2003	7	16	0.01	0
95	2003	7	20	5.88235294117647E-03	0
95	2003	7	25	0.01	0
95	2003	7	26	7.69230769230769E-03	0
95	2003	8	16	0.03	0
95	2003	9	16	0.07	0
95	2003	9	26	0.01	0
95	2003	9	40	0.01	0
95	2003	10	16	0.05	0
95	2003	11	16	0.05	0
95	2003	11	26	0.01	0
95	2003	11	40	5.26315789473684E-03	0
95	2003	12	16	0.16	0
95	2003	12	20	5.88235294117647E-03	0
95	2003	12	26	0.02	0
95	2003	12	40	5.26315789473684E-03	0
95	2003	13	16	0.08	0
95	2003	13	26	0.02	0
95	2003	13	40	5.26315789473684E-03	0
95	2003	14	16	0.16	0
95	2003	14	17	0.01	0
95	2003	14	20	0.04	0
95	2003	14	25	0.03	0
95	2003	14	26	0.05	0
95	2003	14	40	5.26315789473684E-03	0
95	2003	15	16	0.87	0
95	2003	15	17	0.16	0
95	2003	15	20	0.17	0
95	2003	15	25	0.03	0
95	2003	15	26	0.19	0
95	2003	15	40	0.13	0
95	2003	16	16	0.5	0
95	2003	16	17	0.06	0
95	2003	16	20	0.08	0
95	2003	16	26	0.09	0
95	2003	16	40	0.07	0
95	2003	17	16	0.26	0
95	2003	17	17	0.01	0
95	2003	17	20	0.05	0
95	2003	17	25	0.01	0
95	2003	17	26	0.06	0
95	2003	17	27	0.01	0
95	2003	18	16	0.86	0
95	2003	18	17	0.25	0
95	2003	18	20	0.01	0
95	2003	18	25	0.01	0
95	2003	18	26	0.1	0
95	2003	18	40	0.04	0
95	2003	19	16	0.7	0
95	2003	19	17	0.03	0
95	2003	19	20	0.01	0
95	2003	19	26	0.05	0
95	2003	19	40	0.04	0
95	2003	20	16	0.47	0
95	2003	20	20	0.01	0
95	2003	20	26	0.02	0
95	2003	20	40	0.03	0
95	2003	21	16	0.19	0
95	2003	21	17	0.02	0
95	2003	21	20	0.01	0
95	2003	21	26	0.03	0
95	2003	21	40	0.01	0
95	2003	22	16	0.12	0
95	2003	22	16	0.18	0
95	2003	22	17	0.03	0
95	2003	22	17	0.05	0
95	2003	22	20	5.88235294117647E-03	0
95	2003	22	20	0.01	0
95	2003	22	26	0.01	0
95	2003	22	26	0.03	0
95	2003	22	40	0.005	0
95	2003	22	40	5.26315789473684E-03	0
95	2003	23	16	0.2	0
95	2003	23	17	0.06	0
95	2003	23	20	5.88235294117647E-03	0
95	2003	23	26	0.06	0
95	2003	23	40	0.005	0
95	2003	24	16	0.08	0
95	2003	24	17	0.03	0
95	2003	24	26	0.04	0
95	2003	25	16	8.89328063241107E-03	0
95	2003	25	17	0.01	0
95	2003	25	26	2.32558139534884E-03	0
95	2003	26	16	0.02	0
95	2003	26	26	6.45161290322581E-03	0
95	2003	26	40	5.26315789473684E-03	0
95	2004	1	16	0.05	0
95	2004	1	20	0.02	0
95	2004	1	26	0.01	0
95	2004	2	16	0.07	0
95	2004	2	17	0.01	0
95	2004	2	20	0.01	0
95	2004	2	26	0.02	0
95	2004	2	40	0.005	0
95	2004	3	16	0.06	0
95	2004	3	20	0.02	0
95	2004	3	25	0.01	0
95	2004	3	26	0.01	0
95	2004	3	40	0.005	0
95	2004	4	16	0.08	0
95	2004	4	20	0.01	0
95	2004	4	25	0.01	0
95	2004	4	26	0.04	0
95	2004	4	40	0.005	0
95	2004	5	16	0.06	0
95	2004	5	17	0.03	0
95	2004	5	20	5.88235294117647E-03	0
95	2004	5	25	0.01	0
95	2004	5	26	0.01	0
95	2004	6	16	0.07	0
95	2004	6	17	0.01	0
95	2004	6	20	0.02	0
95	2004	6	26	0.06	0
95	2004	6	40	0.01	0
95	2004	7	16	0.1	0
95	2004	7	17	0.02	0
95	2004	7	20	0.02	0
95	2004	7	26	0.01	0
95	2004	7	40	0.005	0
95	2004	8	16	0.08	0
95	2004	8	17	0.01	0
95	2004	8	20	5.88235294117647E-03	0
95	2004	8	26	3.2258064516129E-03	0
95	2004	9	16	0.04	0
95	2004	9	25	0.01	0
95	2004	9	26	0.03	0
95	2004	10	16	0.07	0
95	2004	10	20	0.02	0
95	2004	10	26	0.01	0
95	2004	11	16	0.08	0
95	2004	11	26	0.01	0
95	2004	11	40	0.01	0
95	2004	12	16	0.04	0
95	2004	12	17	0.02	0
95	2004	12	20	5.88235294117647E-03	0
95	2004	12	26	0.01	0
95	2004	12	40	5.26315789473684E-03	0
95	2004	13	16	0.09	0
95	2004	13	20	5.88235294117647E-03	0
95	2004	13	26	0.01	0
95	2004	13	40	5.26315789473684E-03	0
95	2004	14	16	0.24	0
95	2004	14	20	0.06	0
95	2004	14	26	3.2258064516129E-03	0
95	2004	15	16	0.28	0
95	2004	15	17	0.03	0
95	2004	15	20	0.01	0
95	2004	15	26	6.45161290322581E-03	0
95	2004	16	16	0.39	0
95	2004	16	17	0.03	0
95	2004	16	20	0.09	0
95	2004	16	26	0.04	0
95	2004	16	40	0.02	0
95	2004	17	16	0.52	0
95	2004	17	17	0.08	0
95	2004	17	20	0.04	0
95	2004	17	25	0.01	0
95	2004	17	26	0.1	0
95	2004	17	40	0.04	0
95	2004	18	16	0.8	0
95	2004	18	17	0.05	0
95	2004	18	20	0.1	0
95	2004	18	25	0.01	0
95	2004	18	26	0.15	0
95	2004	18	40	0.06	0
95	2004	19	16	0.72	0
95	2004	19	17	0.2	0
95	2004	19	20	0.07	0
95	2004	19	25	0.01	0
95	2004	19	26	0.09	0
95	2004	19	27	0.01	0
95	2004	19	40	0.09	0
95	2004	20	16	0.41	0
95	2004	20	17	0.26	0
95	2004	20	20	0.05	0
95	2004	20	25	0.01	0
95	2004	20	26	0.04	0
95	2004	22	16	0.17	0
95	2004	22	17	0.07	0
95	2004	22	20	0.01	0
95	2004	22	26	3.2258064516129E-03	0
95	2004	22	40	0.005	0
95	2004	23	16	0.17	0
95	2004	23	17	0.06	0
95	2004	23	26	0.02	0
95	2004	24	16	0.06	0
95	2004	24	17	0.03	0
95	2004	24	26	6.45161290322581E-03	0
95	2004	25	16	0.04	0
95	2004	25	17	0.01	0
95	2004	25	20	0.01	0
95	2004	26	16	4.34782608695652E-03	0
95	2004	26	26	3.2258064516129E-03	0
95	2005	1	16	0.04	0
95	2005	1	26	0.02	0
95	2005	2	16	0.02	0
95	2005	3	16	0.01	0
95	2005	3	26	3.2258064516129E-03	0
95	2005	4	16	0.01	0
95	2005	5	16	0.05	0
95	2005	5	17	0.01	0
95	2005	5	26	0.02	0
95	2005	6	16	0.03	0
95	2005	6	20	0.01	0
95	2005	6	26	0.005	0
95	2005	7	16	0.09	0
95	2005	7	20	0.02	0
95	2005	7	26	0.02	0
95	2005	7	40	5.26315789473684E-03	0
95	2005	8	16	0.08	0
95	2005	8	25	0.03	0
95	2005	8	26	9.67741935483871E-03	0
95	2005	9	16	0.05	0
95	2005	9	16	0.06	0
95	2005	9	26	6.45161290322581E-03	0
95	2005	9	40	0.005	0
95	2005	10	16	0.06	0
95	2005	10	26	6.45161290322581E-03	0
95	2005	10	40	0.005	0
95	2005	11	16	0.07	0
95	2005	11	25	0.01	0
95	2005	11	26	3.2258064516129E-03	0
95	2005	12	16	0.03	0
95	2005	13	16	0.11	0
95	2005	13	17	0.01	0
95	2005	13	20	5.88235294117647E-03	0
95	2005	13	26	0.03	0
95	2005	14	16	0.32	0
95	2005	14	17	0.06	0
95	2005	14	20	0.01	0
95	2005	14	25	0.03	0
95	2005	14	26	0.05	0
95	2005	14	40	0.02	0
95	2005	15	16	0.2	0
95	2005	15	17	0.03	0
95	2005	15	20	0.01	0
95	2005	15	25	0.03	0
95	2005	15	26	0.04	0
95	2005	15	40	0.02	0
95	2005	16	16	0.49	0
95	2005	16	17	0.02	0
95	2005	16	20	0.04	0
95	2005	16	25	0.01	0
95	2005	16	26	0.05	0
95	2005	16	40	0.02	0
95	2005	17	16	0.22	0
95	2005	17	17	0.17	0
95	2005	17	20	0.05	0
95	2005	17	26	0.05	0
95	2005	18	16	0.7	0
95	2005	18	17	0.16	0
95	2005	18	20	0.14	0
95	2005	18	26	0.02	0
95	2005	18	40	0.02	0
95	2005	19	16	0.8	0
95	2005	19	17	0.05	0
95	2005	19	20	0.07	0
95	2005	19	25	0.05	0
95	2005	19	26	0.08	0
95	2005	19	40	0.03	0
95	2005	20	16	0.34	0
95	2005	20	17	0.07	0
95	2005	20	20	0.01	0
95	2005	20	26	0.03	0
95	2005	20	40	0.01	0
95	2005	21	16	0.23	0
95	2005	21	17	0.05	0
95	2005	21	20	0.01	0
95	2005	21	26	0.03	0
95	2005	21	40	0.005	0
95	2005	22	16	0.16	0
95	2005	22	17	0.06	0
95	2005	22	25	0.01	0
95	2005	22	26	0.01	0
95	2005	22	40	0.01	0
95	2005	23	16	0.01	0
95	2005	23	20	0.01	0
95	2005	23	26	0.01	0
95	2005	23	40	0.01	0
95	2005	24	16	0.01	0
95	2005	24	26	0.01	0
95	2005	24	40	0.005	0
95	2005	25	16	4.34782608695652E-03	0
95	2005	25	26	0.02	0
95	2005	26	26	9.67741935483871E-03	0
95	2006	1	16	4.34782608695652E-03	0
95	2006	1	26	0.02	0
95	2006	2	16	4.34782608695652E-03	0
95	2006	2	26	5.55138784696174E-03	0
95	2006	4	16	0.01	0
95	2006	4	20	5.88235294117647E-03	0
95	2006	4	26	0.04	0
95	2006	4	40	0.005	0
95	2006	5	16	0.06	0
95	2006	5	20	0.02	0
95	2006	5	25	0.03	0
95	2006	5	26	0.01	0
95	2006	5	40	0.005	0
95	2006	6	16	0.03	0
95	2006	6	20	5.88235294117647E-03	0
95	2006	6	26	0.02	0
95	2006	6	40	5.26315789473684E-03	0
95	2006	7	16	0.02	0
95	2006	7	20	0.01	0
95	2006	7	26	7.69230769230769E-03	0
95	2006	8	16	8.69565217391304E-03	0
95	2006	8	20	5.88235294117647E-03	0
95	2006	9	16	0.03	0
95	2006	9	16	0.04	0
95	2006	9	26	0.01	0
95	2006	9	40	0.02	0
95	2006	10	16	0.03	0
95	2006	10	26	0.01	0
95	2006	10	40	0.02	0
95	2006	11	16	0.02	0
95	2006	11	26	0.01	0
95	2006	11	40	0.005	0
95	2006	12	16	0.04	0
95	2006	12	17	0.01	0
95	2006	12	26	0.01	0
95	2006	12	40	5.26315789473684E-03	0
95	2006	13	16	0.24	0
95	2006	13	17	0.06	0
95	2006	13	20	0.03	0
95	2006	13	25	0.01	0
95	2006	13	26	0.06	0
95	2006	13	40	0.02	0
95	2006	14	16	0.18	0
95	2006	14	17	0.06	0
95	2006	14	20	0.02	0
95	2006	14	25	0.01	0
95	2006	14	26	0.02	0
95	2006	14	40	0.02	0
95	2006	15	16	0.43	0
95	2006	15	17	0.08	0
95	2006	15	20	0.05	0
95	2006	15	25	0.03	0
95	2006	15	26	0.05	0
95	2006	15	40	0.09	0
95	2006	16	16	0.65	0
95	2006	16	17	0.05	0
95	2006	16	20	0.06	0
95	2006	16	26	0.07	0
95	2006	16	40	0.09	0
95	2006	17	16	0.85	0
95	2006	17	17	0.11	0
95	2006	17	20	0.02	0
95	2006	17	26	0.11	0
95	2006	17	27	0.02	0
95	2006	17	40	0.12	0
95	2006	18	16	0.35	0
95	2006	18	20	0.02	0
95	2006	18	25	0.01	0
95	2006	18	26	0.08	0
95	2006	18	27	0.01	0
95	2006	18	40	0.07	0
95	2006	19	16	0.09	0
95	2006	19	17	0.02	0
95	2006	19	20	5.88235294117647E-03	0
95	2006	19	26	0.04	0
95	2006	20	16	0.04	0
95	2006	20	17	0.07	0
95	2006	20	20	0.02	0
95	2006	20	26	0.02	0
95	2006	20	40	5.26315789473684E-03	0
95	2006	21	16	0.13	0
95	2006	21	17	0.02	0
95	2006	21	20	0.02	0
95	2006	21	26	0.01	0
95	2006	22	16	0.02	0
95	2006	22	17	0.01	0
95	2006	22	20	0.03	0
95	2006	22	26	0.02	0
95	2006	23	16	0.05	0
95	2006	23	17	0.05	0
95	2006	23	20	0.01	0
95	2006	23	26	3.2258064516129E-03	0
95	2006	24	16	8.89328063241107E-03	0
95	2006	24	26	6.45161290322581E-03	0
95	2006	24	40	5.26315789473684E-03	0
95	2006	25	16	0.02	0
95	2006	25	17	0.01	0
95	2006	25	20	5.88235294117647E-03	0
95	2006	26	16	0.01	0
95	2006	26	20	5.88235294117647E-03	0
95	2007	1	16	0.02	0
95	2007	1	17	0.02	0
95	2007	1	20	0.01	0
95	2007	1	26	0.02	0
95	2007	1	40	0.01	0
95	2007	2	16	0.01	0
95	2007	2	40	0.01	0
95	2007	3	16	4.34782608695652E-03	0
95	2007	3	20	5.88235294117647E-03	0
95	2007	4	16	0.07	0
95	2007	4	20	0.02	0
95	2007	4	25	0.05	0
95	2007	4	26	0.07	0
95	2007	4	40	0.01	0
95	2007	5	16	0.07	0
95	2007	5	20	0.07	0
95	2007	5	25	0.03	0
95	2007	5	26	0.04	0
95	2007	5	27	0.01	0
95	2007	5	40	0.005	0
95	2007	6	16	8.69565217391304E-03	0
95	2007	6	20	0.01	0
95	2007	7	16	0.01	0
95	2007	7	20	0.01	0
95	2007	8	16	0.08	0
95	2007	8	17	0.02	0
95	2007	8	20	0.01	0
95	2007	8	26	6.45161290322581E-03	0
95	2007	8	40	0.01	0
95	2007	10	16	0.01	0
95	2007	10	17	0.01	0
95	2007	10	26	3.2258064516129E-03	0
95	2007	10	40	0.005	0
95	2007	11	16	0.02	0
95	2007	11	40	0.01	0
95	2007	12	16	0.06	0
95	2007	12	17	0.05	0
95	2007	12	25	0.01	0
95	2007	12	26	0.01	0
95	2007	13	16	0.1	0
95	2007	13	17	0.01	0
95	2007	13	20	0.01	0
95	2007	13	26	0.04	0
95	2007	16	16	0.23	0
95	2007	16	17	0.06	0
95	2007	16	20	0.07	0
95	2007	16	25	0.03	0
95	2007	16	26	0.05	0
95	2007	16	40	0.05	0
95	2007	17	16	0.16	0
95	2007	17	17	0.08	0
95	2007	17	20	0.04	0
95	2007	17	25	0.01	0
95	2007	17	26	0.05	0
95	2007	17	40	0.02	0
95	2007	18	16	0.38	0
95	2007	18	17	0.07	0
95	2007	18	20	0.04	0
95	2007	18	25	0.05	0
95	2007	18	26	0.02	0
95	2007	18	40	0.03	0
95	2007	19	16	0.2	0
95	2007	19	17	0.03	0
95	2007	19	20	0.06	0
95	2007	19	25	0.01	0
95	2007	19	26	0.04	0
95	2007	19	40	0.03	0
95	2007	20	16	0.11	0
95	2007	20	20	0.01	0
95	2007	20	26	9.67741935483871E-03	0
95	2007	21	16	0.1	0
95	2007	21	17	0.17	0
95	2007	21	20	0.02	0
95	2007	21	25	0.15	0
95	2007	21	26	0.06	0
95	2007	21	40	0.01	0
95	2007	22	16	0.03	0
95	2007	22	17	0.07	0
95	2007	22	20	0.01	0
95	2007	22	25	0.03	0
95	2007	22	26	0.02	0
95	2007	22	40	0.005	0
95	2007	23	16	0.01	0
95	2007	23	17	0.1	0
95	2007	23	25	0.01	0
95	2007	23	26	0.01	0
95	2007	23	40	0.005	0
95	2007	24	17	0.01	0
95	2007	24	20	0.02	0
95	2007	24	26	0.01	0
95	2007	24	40	5.26315789473684E-03	0
95	2007	25	16	0.01	0
95	2007	25	17	0.01	0
95	2007	25	20	5.88235294117647E-03	0
95	2007	25	26	7.69230769230769E-03	0
95	2007	26	20	5.88235294117647E-03	0
95	2007	26	25	0.01	0
95	2007	26	26	5.55138784696174E-03	0
106	2000	1	32	0.04	2
106	2000	2	32	0.04	2
106	2000	3	32	0.03	2
106	2000	4	32	0.03	2
106	2000	5	32	0.02	2
106	2000	6	32	0.04	2
106	2000	7	32	0.02	2
106	2000	9	32	0.004	2
106	2000	11	32	8.15859815859816E-03	2
106	2000	12	32	9.66768655447901E-03	2
106	2000	13	32	0.23	2
106	2000	14	32	1.17	2
106	2000	16	32	1.42	2
106	2000	17	32	2.01	2
106	2000	18	32	1.31	2
106	2000	19	32	1.78	2
106	2000	20	32	1.34	2
106	2000	21	32	0.51	2
106	2000	22	32	0.19	2
106	2000	23	32	0.02	2
106	2000	24	32	0.02	2
106	2000	25	32	9.61538461538462E-03	2
106	2000	26	32	0.01	2
106	2001	1	32	0.04	2
106	2001	2	32	0.03	2
106	2001	3	32	3.37837837837838E-03	2
106	2001	4	32	0.01	2
106	2001	5	32	6.71171171171171E-03	2
106	2001	6	32	0.03	2
106	2001	7	32	0.05	2
106	2001	8	32	0.01	2
106	2001	10	32	0.003125	2
106	2001	11	32	0.01	2
106	2001	12	32	0.01	2
106	2001	13	32	0.03	2
106	2001	14	32	0.6	2
106	2001	15	32	1.8	2
106	2001	16	32	1.92	2
106	2001	17	32	1.73	2
106	2001	18	32	1.23	2
106	2001	18	32	1.53	2
106	2001	19	32	1.88	2
106	2001	20	32	0.64	2
106	2001	21	32	0.54	2
106	2001	22	32	0.09	2
106	2001	23	32	0.06	2
106	2001	24	32	0.14	2
106	2001	25	32	0.04	2
106	2001	26	32	8.14465408805031E-03	2
106	2002	1	32	0.08	2
106	2002	2	32	0.02	2
106	2002	3	32	0.01	2
106	2002	4	32	0.02	2
106	2002	5	32	0.03	2
106	2002	6	32	0.02	2
106	2002	7	32	0.04	2
106	2002	8	32	0.04	2
106	2002	9	32	0.15	2
106	2002	11	32	0.09	2
106	2002	12	32	0.63	2
106	2002	13	32	0.58	2
106	2002	14	32	1.39	2
106	2002	15	32	3.17	2
106	2002	16	32	1.61	2
106	2002	17	32	2.9	2
106	2002	18	32	1.12	2
106	2002	18	32	1.35	2
106	2002	19	32	1.35	2
106	2002	20	32	0.56	2
106	2002	21	32	0.23	2
106	2002	22	32	0.05	2
106	2002	22	32	0.07	2
106	2002	23	32	0.07	2
106	2002	24	32	0.03	2
106	2002	25	32	0.01	2
106	2002	26	32	0.01	2
106	2003	1	32	8.69565217391304E-03	2
106	2003	2	32	0.01	2
106	2003	3	32	0.01	2
106	2003	4	32	0.04	2
106	2003	5	32	0.02	2
106	2003	6	32	0.02	2
106	2003	7	32	4.85436893203883E-03	2
106	2003	8	32	0.07	2
106	2003	9	32	0.02	2
106	2003	10	32	0.04	2
106	2003	11	32	0.11	2
106	2003	12	32	0.92	2
106	2003	13	32	0.84	2
106	2003	15	32	5.01	2
106	2003	16	32	2.43	2
106	2003	17	32	2.7	2
106	2003	18	32	0.96	2
106	2003	18	32	2.92	2
106	2003	19	32	0.96	2
106	2003	20	32	0.78	2
106	2003	21	32	0.35	2
106	2003	22	32	0.02	2
106	2003	22	32	0.06	2
106	2003	23	32	0.06	2
106	2003	24	32	0.05	2
106	2003	25	32	7.64963503649635E-03	2
106	2003	26	32	3.37837837837838E-03	2
106	2004	1	32	0.03	2
106	2004	2	32	0.03	2
106	2004	3	32	0.01	2
106	2004	4	32	0.01	2
106	2004	5	32	0.02	2
106	2004	6	32	0.02	2
106	2004	7	32	0.01	2
106	2004	8	32	0.03	2
106	2004	9	32	0.01	2
106	2004	10	32	0.04	2
106	2004	11	32	0.04	2
106	2004	12	32	0.09	2
106	2004	13	32	0.19	2
106	2004	14	32	1.11	2
106	2004	15	32	1.19	2
106	2004	16	32	1.16	2
106	2004	17	32	1.77	2
106	2004	18	32	2.49	2
106	2004	19	32	3.2	2
106	2004	20	32	1.79	2
106	2004	21	32	0.31	2
106	2004	22	32	0.14	2
106	2004	23	32	0.05	2
106	2004	24	32	0.03	2
106	2004	25	32	0.02	2
106	2005	1	32	0.01	2
106	2005	2	32	0.01	2
106	2005	3	32	0.01	2
106	2005	4	32	0.03	2
106	2005	5	32	0.02	2
106	2005	5	32	0.04	2
106	2005	6	32	0.02	2
106	2005	7	32	0.1	2
106	2005	8	32	3.06748466257669E-03	2
106	2005	9	32	9.91928912454667E-03	2
106	2005	10	32	0.02	2
106	2005	11	32	0.01	2
106	2005	12	32	0.72	2
106	2005	13	32	3.16	2
106	2005	14	32	2.57	2
106	2005	15	32	4.57	2
106	2005	16	32	2.55	2
106	2005	17	32	5.44	2
106	2005	18	32	4.69	2
106	2005	19	32	3.72	2
106	2005	20	32	1.56	2
106	2005	21	32	0.93	2
106	2005	22	32	0.15	2
106	2005	23	32	0.02	2
106	2005	24	32	3.84615384615385E-03	2
106	2005	25	32	0.005	2
106	2005	26	32	0.005	2
106	2006	1	32	0.04	2
106	2006	3	32	0.02	2
106	2006	4	32	0.03	2
106	2006	5	32	9.70632815460402E-03	2
106	2006	6	32	0.01	2
106	2006	7	32	0.01	2
106	2006	8	32	3.64963503649635E-03	2
106	2006	9	32	0.02	2
106	2006	10	32	0.02	2
106	2006	11	32	7.17948717948718E-03	2
106	2006	12	32	0.05	2
106	2006	13	32	0.53	2
106	2006	14	32	2.97	2
106	2006	15	32	2.02	2
106	2006	16	32	2.03	2
106	2006	17	32	2.86	2
106	2006	18	32	1.21	2
106	2006	18	32	1.42	2
106	2006	19	32	2.45	2
106	2006	20	32	1.02	2
106	2006	21	32	0.3	2
106	2006	22	32	0.1	2
106	2006	23	32	0.11	2
106	2006	24	32	0.01	2
106	2006	25	32	9.88175675675676E-03	2
106	2007	1	32	0.07	2
106	2007	2	32	0.09	2
106	2007	3	32	0.07	2
106	2007	4	32	0.05	2
106	2007	5	32	3.64963503649635E-03	2
106	2007	7	32	0.02	2
106	2007	8	32	0.01	2
106	2007	9	32	0.01	2
106	2007	10	32	0.09	2
106	2007	11	32	0.09	2
106	2007	12	32	0.27	2
106	2007	13	32	0.32	2
106	2007	14	32	0.89	2
106	2007	15	32	1.91	2
106	2007	16	32	1.88	2
106	2007	17	32	0.89	2
106	2007	18	32	0.6	2
106	2007	19	32	0.52	2
106	2007	20	32	0.31	2
106	2007	21	32	0.13	2
106	2007	22	32	0.08	2
106	2007	23	32	0.02	2
106	2007	24	32	0.01	2
106	2007	25	32	0.04	2
106	2007	26	32	0.01	2
113	2000	4	18	0.01	1
113	2000	4	22	0.02	1
113	2000	4	31	0.05	1
113	2000	5	18	0.01	1
113	2000	5	22	0.01	1
113	2000	5	31	0.06	1
113	2000	6	18	0.01	1
113	2000	6	22	0.01	1
113	2000	6	31	0.05	1
113	2000	7	18	0.02	1
113	2000	7	22	0.01	1
113	2000	7	31	0.04	1
113	2000	8	18	6.22413793103448E-03	1
113	2000	8	22	7.33333333333333E-03	1
113	2000	8	31	0.01	1
113	2000	9	18	0.005	1
113	2000	9	22	0.02	1
113	2000	9	31	0.01	1
113	2000	10	18	0.01	1
113	2000	10	22	0.03	1
113	2000	10	31	0.03	1
113	2000	11	18	8.89655172413793E-03	1
113	2000	11	22	0.01	1
113	2000	11	31	0.01	1
113	2000	12	18	0.01	1
113	2000	12	22	0.01	1
113	2000	12	31	0.03	1
113	2000	13	18	0.01	1
113	2000	13	22	0.25	1
113	2000	13	31	0.07	1
113	2000	16	18	0.14	1
113	2000	16	22	0.15	1
113	2000	16	31	0.15	1
113	2000	17	18	0.18	1
113	2000	17	22	0.14	1
113	2000	17	31	0.16	1
113	2000	18	18	0.1	1
113	2000	18	18	0.29	1
113	2000	18	22	0.16	1
113	2000	18	22	0.31	1
113	2000	18	31	0.15	1
113	2000	18	31	0.32	1
113	2000	19	18	0.19	1
113	2000	19	22	0.27	1
113	2000	19	31	0.11	1
113	2000	20	18	0.08	1
113	2000	20	22	0.2	1
113	2000	20	31	0.05	1
113	2000	21	18	0.02	1
113	2000	21	22	0.2	1
113	2000	21	31	0.07	1
113	2000	22	18	0.01	1
113	2000	22	22	0.07	1
113	2000	22	31	0.03	1
113	2000	23	22	0.04	1
113	2000	23	31	0.02	1
113	2000	24	18	0.01	1
113	2000	24	22	0.01	1
113	2000	24	31	0.01	1
113	2000	25	18	6.72413793103448E-03	1
113	2000	25	22	0.008	1
113	2000	25	31	0.02	1
113	2000	26	18	1.72413793103448E-03	1
113	2000	26	22	0.02	1
113	2000	26	31	8.18713450292398E-03	1
113	2001	1	18	0.005	1
113	2001	1	22	0.01	1
113	2001	1	31	0.02	1
113	2001	6	18	0.01	1
113	2001	6	22	0.03	1
113	2001	6	31	0.08	1
113	2001	7	18	0.008	1
113	2001	7	22	0.01	1
113	2001	7	31	0.03	1
113	2001	8	18	0.004	1
113	2001	8	22	0.01	1
113	2001	8	31	0.02	1
113	2001	9	22	0.01	1
113	2001	9	31	3.33333333333333E-03	1
113	2001	10	18	0.002	1
113	2001	10	22	0.01	1
113	2001	10	31	3.07692307692308E-03	1
113	2001	11	18	0.01	1
113	2001	11	22	0.02	1
113	2001	11	31	0.04	1
113	2001	12	18	1.72413793103448E-03	1
113	2001	12	22	0.01	1
113	2001	12	31	0.01	1
113	2001	13	22	0.01	1
113	2001	13	31	0.01	1
113	2001	14	18	0.01	1
113	2001	14	22	0.12	1
113	2001	14	31	0.03	1
113	2001	15	18	0.09	1
113	2001	15	22	0.45	1
113	2001	15	31	0.29	1
113	2001	16	18	0.04	1
113	2001	16	22	0.21	1
113	2001	16	31	0.14	1
113	2001	17	18	0.22	1
113	2001	17	22	0.36	1
113	2001	17	31	0.29	1
113	2001	18	18	0.1	1
113	2001	18	22	0.09	1
113	2001	18	31	0.13	1
113	2001	19	18	0.07	1
113	2001	19	22	0.17	1
113	2001	19	31	0.05	1
113	2001	20	18	0.04	1
113	2001	20	22	0.25	1
113	2001	20	31	0.06	1
113	2001	21	18	0.02	1
113	2001	21	22	0.13	1
113	2001	21	31	0.04	1
113	2001	22	18	0.01	1
113	2001	22	22	0.05	1
113	2001	22	31	0.05	1
113	2001	23	18	0.0025	1
113	2001	23	22	0.05	1
113	2001	23	31	0.03	1
113	2001	25	18	0.0045	1
113	2001	25	22	0.008	1
113	2001	26	18	0.0025	1
113	2001	26	22	0.004	1
113	2002	3	18	0.0025	1
113	2002	3	31	0.01	1
113	2002	4	18	0.0025	1
113	2002	4	31	0.01	1
113	2002	6	18	0.01	1
113	2002	6	22	0.01	1
113	2002	6	31	5.77962577962578E-03	1
113	2002	7	18	0.02	1
113	2002	7	22	0.02	1
113	2002	7	31	0.01	1
113	2002	8	18	0.02	1
113	2002	8	22	0.03	1
113	2002	8	31	0.05	1
113	2002	9	18	0.01	1
113	2002	9	22	0.02	1
113	2002	9	31	0.04	1
113	2002	11	18	4.22413793103448E-03	1
113	2002	11	22	0.01	1
113	2002	11	31	0.01	1
113	2002	12	18	0.05	1
113	2002	12	22	0.2	1
113	2002	12	31	0.07	1
113	2002	13	18	0.04	1
113	2002	13	22	0.19	1
113	2002	13	31	0.05	1
113	2002	14	18	0.09	1
113	2002	14	22	0.15	1
113	2002	14	31	0.15	1
113	2002	15	18	0.09	1
113	2002	15	22	0.15	1
113	2002	15	31	0.15	1
113	2002	16	18	0.11	1
113	2002	16	22	0.18	1
113	2002	16	31	0.13	1
113	2002	17	18	0.25	1
113	2002	17	22	0.25	1
113	2002	17	31	0.24	1
113	2002	18	18	0.1	1
113	2002	18	18	0.13	1
113	2002	18	22	0.07	1
113	2002	18	22	0.1	1
113	2002	18	31	0.05	1
113	2002	18	31	0.11	1
113	2002	19	18	0.1	1
113	2002	19	22	0.1	1
113	2002	19	31	0.05	1
113	2002	20	18	0.08	1
113	2002	20	22	0.2	1
113	2002	20	31	0.05	1
113	2002	21	18	0.01	1
113	2002	21	22	0.22	1
113	2002	21	31	0.03	1
113	2002	22	18	0.01	1
113	2002	22	22	0.04	1
113	2002	22	31	0.02	1
113	2002	23	18	3.72413793103448E-03	1
113	2002	23	22	0.03	1
113	2002	23	31	0.01	1
113	2002	24	18	0.01	1
113	2002	24	22	0.04	1
113	2002	24	31	3.63636363636364E-03	1
113	2002	25	18	0.01	1
113	2002	25	22	0.02	1
113	2002	25	31	0.03	1
113	2002	26	18	0.0085	1
113	2002	26	22	0.01	1
113	2002	26	31	0.01	1
113	2003	2	22	0.004	1
113	2003	2	31	8.25825825825826E-03	1
113	2003	3	18	5.17241379310345E-03	1
113	2003	3	22	0.004	1
113	2003	3	31	8.5088848246743E-03	1
113	2003	5	18	0.0045	1
113	2003	5	22	0.004	1
113	2003	5	31	5.96491228070175E-03	1
113	2003	7	18	7.67241379310345E-03	1
113	2003	7	22	3.33333333333333E-03	1
113	2003	7	31	0.05	1
113	2003	8	18	4.22413793103448E-03	1
113	2003	8	22	6.66666666666667E-03	1
113	2003	8	31	0.01	1
113	2003	9	18	0.01	1
113	2003	9	18	0.02	1
113	2003	9	22	0.01	1
113	2003	9	22	0.04	1
113	2003	9	31	0.05	1
113	2003	9	31	0.06	1
113	2003	10	18	0.02	1
113	2003	10	22	0.04	1
113	2003	10	31	0.06	1
113	2003	11	18	0.01	1
113	2003	11	22	0.11	1
113	2003	11	31	0.05	1
113	2003	12	18	0.04	1
113	2003	12	22	0.06	1
113	2003	12	31	0.04	1
113	2003	13	18	0.06	1
113	2003	13	22	0.09	1
113	2003	13	31	0.1	1
113	2003	15	18	0.07	1
113	2003	15	22	0.09	1
113	2003	15	31	0.17	1
113	2003	16	18	0.07	1
113	2003	16	22	0.22	1
113	2003	16	31	0.24	1
113	2003	17	18	0.12	1
113	2003	17	22	0.24	1
113	2003	17	31	0.12	1
113	2003	19	18	0.02	1
113	2003	19	22	0.17	1
113	2003	19	31	0.02	1
113	2003	20	18	0.005	1
113	2003	20	22	0.05	1
113	2003	20	31	0.02	1
113	2004	1	22	0.01	1
113	2004	1	31	0.03	1
113	2004	4	18	0.006	1
113	2004	4	22	0.01	1
113	2004	4	31	0.02	1
113	2004	7	18	0.02	1
113	2004	7	22	0.01	1
113	2004	7	31	0.02	1
113	2004	8	18	0.01	1
113	2004	8	22	0.004	1
113	2004	8	31	6.33906633906634E-03	1
113	2004	9	18	7.72413793103448E-03	1
113	2004	9	22	3.33333333333333E-03	1
113	2004	9	31	5.87730587730588E-03	1
113	2004	10	22	0.01	1
113	2004	10	31	2.7027027027027E-03	1
113	2004	12	18	0.0085	1
113	2004	12	22	0.04	1
113	2004	12	31	0.04	1
113	2004	13	18	0.03	1
113	2004	13	22	0.09	1
113	2004	13	31	0.12	1
113	2004	14	18	0.1	1
113	2004	14	22	0.1	1
113	2004	14	31	0.23	1
113	2004	15	18	0.07	1
113	2004	15	22	0.1	1
113	2004	15	31	0.17	1
113	2004	16	18	0.19	1
113	2004	16	22	0.19	1
113	2004	16	31	0.25	1
113	2004	17	18	0.15	1
113	2004	17	22	0.14	1
113	2004	17	31	0.2	1
113	2004	18	18	0.15	1
113	2004	18	22	0.14	1
113	2004	18	31	0.17	1
113	2004	20	18	0.04	1
113	2004	20	22	0.09	1
113	2004	20	31	0.06	1
113	2004	21	18	0.04	1
113	2004	21	22	0.14	1
113	2004	21	31	0.05	1
113	2004	22	18	0.02	1
113	2004	22	22	0.07	1
113	2004	22	31	0.04	1
113	2004	23	18	0.01	1
113	2004	23	22	0.08	1
113	2004	23	31	0.03	1
113	2005	1	22	0.01	1
113	2005	1	31	0.02	1
113	2005	2	18	0.004	1
113	2005	2	22	7.33333333333333E-03	1
113	2005	2	31	0.01	1
113	2005	3	18	0.02	1
113	2005	3	22	0.004	1
113	2005	3	31	0.03	1
113	2005	4	18	0.01	1
113	2005	4	22	0.004	1
113	2005	4	31	0.02	1
113	2005	5	18	0.01	1
113	2005	5	22	0.04	1
113	2005	5	31	0.06	1
113	2005	7	18	0.04	1
113	2005	7	22	0.03	1
113	2005	7	31	0.03	1
113	2005	8	18	0.02	1
113	2005	8	22	0.01	1
113	2005	8	31	0.03	1
113	2005	9	18	0.02	1
113	2005	9	22	0.01	1
113	2005	9	31	0.03	1
113	2005	10	18	0.0045	1
113	2005	10	22	0.03	1
113	2005	10	31	0.01	1
113	2005	12	18	0.01	1
113	2005	12	22	0.03	1
113	2005	12	31	0.03	1
113	2005	15	18	0.08	1
113	2005	15	22	0.14	1
113	2005	15	31	0.18	1
113	2005	16	18	0.07	1
113	2005	16	22	0.16	1
113	2005	16	31	0.22	1
113	2005	17	18	0.07	1
113	2005	17	22	0.16	1
113	2005	17	31	0.22	1
113	2005	18	18	0.07	1
113	2005	18	22	0.08	1
113	2005	18	31	0.11	1
113	2005	19	18	0.06	1
113	2005	19	22	0.15	1
113	2005	19	31	0.1	1
113	2005	21	18	0.01	1
113	2005	21	22	0.04	1
113	2005	21	31	0.02	1
113	2005	22	18	0.01	1
113	2005	22	22	0.02	1
113	2005	22	31	0.04	1
113	2006	3	18	9.44827586206897E-03	1
113	2006	3	22	0.01	1
113	2006	3	31	0.01	1
113	2006	5	18	0.002	1
113	2006	5	22	3.33333333333333E-03	1
113	2006	5	31	6.96969696969697E-03	1
113	2006	5	31	8.5088848246743E-03	1
113	2006	6	18	0.004	1
113	2006	6	22	7.33333333333333E-03	1
113	2006	6	31	0.01	1
113	2006	10	18	0.002	1
113	2006	10	22	3.33333333333333E-03	1
113	2006	10	31	0.01	1
113	2006	11	22	0.01	1
113	2006	11	31	6.96969696969697E-03	1
113	2006	13	18	0.06	1
113	2006	13	22	0.12	1
113	2006	13	31	0.18	1
113	2006	14	18	0.04	1
113	2006	14	22	0.06	1
113	2006	14	31	0.11	1
113	2006	15	18	0.11	1
113	2006	15	22	0.2	1
113	2006	15	31	0.21	1
113	2006	16	18	0.22	1
113	2006	16	22	0.08	1
113	2006	16	31	0.19	1
113	2006	17	18	0.15	1
113	2006	17	22	0.15	1
113	2006	17	31	0.09	1
113	2006	18	18	0.05	1
113	2006	18	22	0.15	1
113	2006	18	31	0.06	1
113	2006	20	18	0.02	1
113	2006	20	22	0.07	1
113	2006	20	31	0.04	1
113	2007	1	18	5.17241379310345E-03	1
113	2007	1	22	0.01	1
113	2007	1	31	6.26794258373206E-03	1
113	2007	2	18	0.01	1
113	2007	2	22	0.01	1
113	2007	2	31	0.01	1
113	2007	3	18	0.0085	1
113	2007	3	22	3.33333333333333E-03	1
113	2007	3	31	6.03603603603604E-03	1
113	2007	4	18	0.01	1
113	2007	4	22	0.01	1
113	2007	4	31	0.02	1
113	2007	5	18	0.01	1
113	2007	5	22	3.33333333333333E-03	1
113	2007	5	31	0.01	1
113	2007	7	18	0.01	1
113	2007	7	22	0.01	1
113	2007	7	31	9.36936936936937E-03	1
113	2007	8	18	0.01	1
113	2007	8	22	0.01	1
113	2007	8	31	0.02	1
113	2007	9	18	7.44827586206897E-03	1
113	2007	9	22	0.01	1
113	2007	9	31	0.02	1
113	2007	10	22	6.66666666666667E-03	1
113	2007	10	31	0.02	1
113	2007	11	18	0.02	1
113	2007	11	22	3.33333333333333E-03	1
113	2007	11	31	0.05	1
113	2007	12	18	0.07	1
113	2007	12	22	0.05	1
113	2007	12	31	0.13	1
113	2007	14	18	0.07	1
113	2007	14	22	0.12	1
113	2007	14	31	0.13	1
113	2007	15	18	0.17	1
113	2007	15	22	0.16	1
113	2007	15	31	0.11	1
113	2007	16	18	0.07	1
113	2007	16	22	0.21	1
113	2007	16	31	0.26	1
113	2007	17	18	0.07	1
113	2007	17	22	0.08	1
113	2007	17	31	0.17	1
113	2007	18	18	0.05	1
113	2007	18	22	0.04	1
113	2007	18	31	0.09	1
113	2007	19	18	0.07	1
113	2007	19	22	0.08	1
113	2007	19	31	0.04	1
113	2007	20	18	0.02	1
113	2007	20	22	0.07	1
113	2007	20	31	0.05	1
113	2007	21	18	0.04	1
113	2007	21	22	0.13	1
113	2007	21	31	0.04	1
113	2007	22	18	0.01	1
113	2007	22	18	0.02	1
113	2007	22	22	0.02	1
113	2007	22	22	0.1	1
113	2007	22	31	0.02	1
113	2007	22	31	0.03	1
113	2007	23	18	0.01	1
113	2007	23	22	0.02	1
113	2007	23	31	0.03	1
160	2000	4	26	0.01	0
160	2000	5	26	3.33333333333333E-03	0
160	2000	5	26	0.01	0
160	2000	6	26	0.05	0
160	2000	7	26	0.03	0
160	2000	8	26	0.01	0
160	2000	9	26	6.66666666666667E-03	0
160	2000	14	26	6.66666666666667E-03	0
160	2000	16	26	0.01	0
160	2000	17	26	0.01	0
160	2000	19	26	6.66666666666667E-03	0
160	2001	5	26	0.01	0
160	2001	6	26	0.03	0
160	2001	7	26	0.03	0
160	2001	8	26	6.66666666666667E-03	0
160	2001	14	26	6.66666666666667E-03	0
160	2001	15	26	0.01	0
160	2001	16	26	0.06	0
160	2001	17	26	0.02	0
160	2001	21	26	3.33333333333333E-03	0
160	2002	1	26	3.33333333333333E-03	0
160	2002	7	26	0.01	0
160	2002	8	26	6.66666666666667E-03	0
160	2002	13	26	6.66666666666667E-03	0
160	2002	16	26	0.01	0
160	2002	17	26	3.33333333333333E-03	0
160	2002	18	26	3.33333333333333E-03	0
160	2002	26	26	3.33333333333333E-03	0
160	2003	2	26	6.66666666666667E-03	0
160	2003	3	26	6.66666666666667E-03	0
160	2003	5	26	3.33333333333333E-03	0
160	2003	13	26	0.03	0
160	2003	14	26	0.04	0
160	2003	15	26	0.01	0
160	2003	16	26	3.33333333333333E-03	0
160	2003	17	26	3.33333333333333E-03	0
160	2003	23	26	3.33333333333333E-03	0
160	2003	24	26	3.33333333333333E-03	0
160	2004	5	26	3.33333333333333E-03	0
160	2004	6	26	0.01	0
160	2004	15	26	6.66666666666667E-03	0
160	2004	16	26	3.33333333333333E-03	0
160	2004	21	26	3.33333333333333E-03	0
160	2005	3	26	3.33333333333333E-03	0
160	2005	6	26	0.01	0
160	2005	7	26	0.01	0
160	2005	8	26	3.33333333333333E-03	0
160	2005	9	26	3.33333333333333E-03	0
160	2005	13	26	3.33333333333333E-03	0
160	2005	14	26	6.66666666666667E-03	0
160	2005	15	26	6.66666666666667E-03	0
160	2005	16	26	3.33333333333333E-03	0
160	2006	3	26	3.33333333333333E-03	0
160	2006	9	26	3.33333333333333E-03	0
160	2006	14	26	3.33333333333333E-03	0
160	2006	15	26	0.01	0
160	2006	17	26	6.66666666666667E-03	0
160	2006	19	26	0.01	0
160	2006	20	26	0.01	0
160	2007	2	26	3.33333333333333E-03	0
160	2007	4	26	3.33333333333333E-03	0
160	2007	5	26	3.33333333333333E-03	0
160	2007	6	26	3.33333333333333E-03	0
160	2007	7	26	0.01	0
160	2007	8	26	0.01	0
160	2007	10	26	3.33333333333333E-03	0
160	2007	11	26	3.33333333333333E-03	0
160	2007	14	26	0.01	0
160	2007	15	26	0.01	0
160	2007	17	26	6.66666666666667E-03	0
160	2007	20	26	3.33333333333333E-03	0
175	2000	5	27	0.02	0
175	2000	6	27	0.02	0
175	2000	7	27	0.02	0
175	2000	8	27	0.008	0
175	2000	14	27	0.004	0
175	2000	17	27	0.004	0
175	2000	18	27	0.008	0
175	2000	19	27	0.004	0
175	2000	25	27	0.008	0
175	2003	3	27	0.02	0
175	2003	14	27	0.004	0
175	2004	4	27	0.004	0
175	2004	6	27	0.01	0
175	2004	8	27	0.01	0
175	2004	14	27	0.008	0
175	2004	15	27	0.008	0
175	2004	20	27	0.004	0
175	2005	9	27	0.004	0
175	2005	15	27	0.008	0
175	2005	16	27	0.004	0
175	2005	21	27	0.004	0
175	2006	9	27	0.004	0
175	2006	14	27	0.008	0
175	2006	15	27	0.004	0
175	2006	16	27	0.004	0
175	2006	17	27	0.008	0
175	2006	18	27	0.004	0
175	2007	14	27	0.004	0
175	2007	15	27	0.004	0
175	2007	21	27	0.004	0
1024	2000	2	23	0.01	0
1024	2000	2	26	0.06	0
1024	2000	2	31	0.03	0
1024	2000	3	23	0.01	0
1024	2000	3	26	0.05	0
1024	2000	3	31	0.02	0
1024	2000	4	26	0.06	0
1024	2000	4	31	0.03	0
1024	2000	5	23	0.03	0
1024	2000	5	26	0.08	0
1024	2000	5	31	0.06	0
1024	2000	6	23	0.04	0
1024	2000	6	26	0.18	0
1024	2000	6	31	0.12	0
1024	2000	7	23	0.005	0
1024	2000	7	26	0.07	0
1024	2000	7	31	0.04	0
1024	2000	9	26	0.04	0
1024	2000	9	31	0.02	0
1024	2000	10	23	0.005	0
1024	2000	10	26	0.04	0
1024	2000	10	31	0.03	0
1024	2000	11	23	0.005	0
1024	2000	11	26	0.05	0
1024	2000	11	31	0.04	0
1024	2000	12	23	0.005	0
1024	2000	12	26	0.05	0
1024	2000	12	31	0.02	0
1024	2000	13	26	0.1	0
1024	2000	13	31	0.06	0
1024	2000	14	23	0.04	0
1024	2000	14	26	0.58	0
1024	2000	14	31	0.34	0
1024	2000	15	23	0.03	0
1024	2000	15	26	0.9	0
1024	2000	15	31	0.66	0
1024	2000	16	23	0.05	0
1024	2000	16	26	1.8	0
1024	2000	16	31	1.25	0
1024	2000	17	23	0.04	0
1024	2000	17	26	1.05	0
1024	2000	17	31	0.56	0
1024	2000	18	23	0.07	0
1024	2000	18	26	1.2	0
1024	2000	18	31	0.68	0
1024	2000	19	23	0.09	0
1024	2000	19	26	0.68	0
1024	2000	19	31	0.39	0
1024	2000	20	23	0.02	0
1024	2000	20	26	0.34	0
1024	2000	20	31	0.16	0
1024	2000	21	26	0.21	0
1024	2000	21	31	0.13	0
1024	2000	22	26	0.11	0
1024	2000	22	31	0.05	0
1024	2000	23	26	0.03	0
1024	2000	23	31	0.02	0
1024	2000	24	23	0.005	0
1024	2000	24	26	0.07	0
1024	2000	24	31	0.03	0
1024	2001	2	23	0.01	0
1024	2001	2	26	0.03	0
1024	2001	2	31	0.04	0
1024	2001	4	23	0.02	0
1024	2001	4	26	0.03	0
1024	2001	4	31	0.02	0
1024	2001	5	23	0.01	0
1024	2001	5	26	0.06	0
1024	2001	5	31	0.02	0
1024	2001	6	23	0.01	0
1024	2001	6	26	0.16	0
1024	2001	6	31	0.11	0
1024	2001	7	26	0.08	0
1024	2001	7	31	0.05	0
1024	2001	8	23	0.01	0
1024	2001	8	26	0.05	0
1024	2001	8	31	0.03	0
1024	2001	9	23	0.005	0
1024	2001	9	26	0.02	0
1024	2001	9	26	0.06	0
1024	2001	9	31	9.04471544715447E-03	0
1024	2001	9	31	0.03	0
1024	2001	10	23	0.005	0
1024	2001	10	26	0.02	0
1024	2001	10	31	0.03	0
1024	2001	11	26	0.01	0
1024	2001	11	31	0.03	0
1024	2001	12	23	0.01	0
1024	2001	12	26	0.07	0
1024	2001	12	31	0.07	0
1024	2001	13	23	0.01	0
1024	2001	13	26	0.05	0
1024	2001	13	31	0.05	0
1024	2001	14	23	0.01	0
1024	2001	14	26	0.37	0
1024	2001	14	31	0.29	0
1024	2001	15	23	0.03	0
1024	2001	15	26	1.09	0
1024	2001	15	31	0.86	0
1024	2001	16	23	0.03	0
1024	2001	16	26	1.45	0
1024	2001	16	31	0.81	0
1024	2001	17	23	0.01	0
1024	2001	17	26	1.53	0
1024	2001	17	31	0.96	0
1024	2001	18	23	0.07	0
1024	2001	18	26	1.13	0
1024	2001	18	31	0.62	0
1024	2001	19	23	0.005	0
1024	2001	19	26	0.82	0
1024	2001	19	31	0.39	0
1024	2001	20	23	0.01	0
1024	2001	20	26	0.42	0
1024	2001	20	31	0.18	0
1024	2001	21	23	0.01	0
1024	2001	21	26	0.19	0
1024	2001	21	31	0.06	0
1024	2001	22	26	0.16	0
1024	2001	22	31	0.04	0
1024	2001	23	23	0.005	0
1024	2001	23	26	0.11	0
1024	2001	23	31	0.03	0
1024	2001	24	26	0.03	0
1024	2001	25	26	0.01	0
1024	2001	25	31	6.60569105691057E-03	0
1024	2001	26	26	0.03	0
1024	2001	26	31	0.02	0
1024	2002	1	23	0.005	0
1024	2002	1	26	0.07	0
1024	2002	1	31	0.04	0
1024	2002	2	23	0.02	0
1024	2002	2	26	0.1	0
1024	2002	2	31	0.06	0
1024	2002	3	23	0.03	0
1024	2002	3	26	0.27	0
1024	2002	3	31	0.09	0
1024	2002	4	26	0.16	0
1024	2002	4	31	0.06	0
1024	2002	5	23	0.005	0
1024	2002	5	26	0.1	0
1024	2002	5	31	0.02	0
1024	2002	6	23	0.01	0
1024	2002	6	26	0.11	0
1024	2002	6	31	0.05	0
1024	2002	7	23	0.01	0
1024	2002	7	26	0.11	0
1024	2002	7	31	0.04	0
1024	2002	8	26	0.22	0
1024	2002	8	31	0.1	0
1024	2002	9	23	0.01	0
1024	2002	9	26	0.08	0
1024	2002	9	26	0.09	0
1024	2002	9	31	0.05	0
1024	2002	10	23	0.01	0
1024	2002	10	26	0.08	0
1024	2002	10	31	0.05	0
1024	2002	11	23	0.005	0
1024	2002	11	26	0.07	0
1024	2002	11	31	0.07	0
1024	2002	12	23	0.005	0
1024	2002	12	26	0.15	0
1024	2002	12	31	0.05	0
1024	2002	13	23	0.01	0
1024	2002	13	26	0.32	0
1024	2002	13	31	0.12	0
1024	2002	14	23	0.04	0
1024	2002	14	26	0.94	0
1024	2002	14	31	0.4	0
1024	2002	15	23	0.05	0
1024	2002	15	26	1.82	0
1024	2002	15	31	0.84	0
1024	2002	16	23	0.03	0
1024	2002	16	26	0.86	0
1024	2002	16	31	0.39	0
1024	2002	17	23	0.07	0
1024	2002	17	26	1.94	0
1024	2002	17	31	0.86	0
1024	2002	18	23	0.04	0
1024	2002	18	26	0.86	0
1024	2002	18	31	0.41	0
1024	2002	19	23	0.02	0
1024	2002	19	26	0.88	0
1024	2002	19	31	0.28	0
1024	2002	20	23	0.01	0
1024	2002	20	26	0.73	0
1024	2002	20	31	0.23	0
1024	2002	21	23	0.02	0
1024	2002	21	26	0.66	0
1024	2002	21	31	0.13	0
1024	2002	22	23	0.01	0
1024	2002	22	23	0.03	0
1024	2002	22	26	0.19	0
1024	2002	22	26	0.35	0
1024	2002	22	31	0.04	0
1024	2002	22	31	0.1	0
1024	2002	23	23	0.01	0
1024	2002	23	26	0.16	0
1024	2002	23	31	0.05	0
1024	2002	24	23	0.005	0
1024	2002	24	26	0.08	0
1024	2002	24	31	0.04	0
1024	2002	25	23	0.005	0
1024	2002	25	26	0.08	0
1024	2002	25	31	0.05	0
1024	2002	26	26	0.04	0
1024	2002	26	31	0.02	0
1024	2003	1	23	0.005	0
1024	2003	1	26	0.03	0
1024	2003	1	31	0.01	0
1024	2003	2	23	0.01	0
1024	2003	2	26	0.02	0
1024	2003	2	31	6.66376306620209E-03	0
1024	2003	3	23	0.005	0
1024	2003	3	26	0.04	0
1024	2003	3	31	0.02	0
1024	2003	4	23	0.005	0
1024	2003	4	26	0.06	0
1024	2003	4	31	0.02	0
1024	2003	5	23	0.05	0
1024	2003	5	26	0.13	0
1024	2003	5	31	0.1	0
1024	2003	6	23	0.01	0
1024	2003	6	26	0.05	0
1024	2003	6	31	0.06	0
1024	2003	9	26	0.06	0
1024	2003	9	31	0.05	0
1024	2003	10	23	0.01	0
1024	2003	10	26	0.06	0
1024	2003	10	31	0.03	0
1024	2003	11	26	0.1	0
1024	2003	11	31	0.03	0
1024	2003	12	23	0.03	0
1024	2003	12	26	0.61	0
1024	2003	12	31	0.28	0
1024	2003	13	23	0.02	0
1024	2003	13	26	0.41	0
1024	2003	13	31	0.21	0
1024	2003	14	23	0.02	0
1024	2003	14	26	0.79	0
1024	2003	14	31	0.42	0
1024	2003	15	23	0.03	0
1024	2003	15	26	0.85	0
1024	2003	15	31	0.43	0
1024	2003	16	23	0.04	0
1024	2003	16	26	1.26	0
1024	2003	16	31	0.62	0
1024	2003	17	23	0.005	0
1024	2003	17	26	0.98	0
1024	2003	17	31	0.51	0
1024	2003	18	23	0.05	0
1024	2003	18	26	1.02	0
1024	2003	18	31	0.37	0
1024	2003	19	23	0.02	0
1024	2003	19	26	0.44	0
1024	2003	19	31	0.2	0
1024	2003	20	23	0.02	0
1024	2003	20	26	0.28	0
1024	2003	20	31	0.09	0
1024	2003	22	23	0.01	0
1024	2003	22	26	0.05	0
1024	2003	22	31	0.04	0
1024	2003	23	23	0.01	0
1024	2003	23	26	0.07	0
1024	2003	23	31	0.02	0
1024	2003	24	23	0.01	0
1024	2003	24	26	0.06	0
1024	2003	24	31	0.04	0
1024	2003	25	23	0.005	0
1024	2003	25	26	0.02	0
1024	2003	25	31	0.02	0
1024	2003	26	23	0.005	0
1024	2003	26	26	6.28205128205128E-03	0
1024	2003	26	31	0.01	0
1024	2004	4	23	0.005	0
1024	2004	4	26	0.1	0
1024	2004	4	31	0.03	0
1024	2004	7	26	0.12	0
1024	2004	7	31	0.04	0
1024	2004	8	23	0.005	0
1024	2004	8	26	0.09	0
1024	2004	8	31	0.06	0
1024	2004	9	23	0.01	0
1024	2004	9	26	0.1	0
1024	2004	9	31	0.06	0
1024	2004	10	23	0.005	0
1024	2004	10	26	0.05	0
1024	2004	10	31	0.05	0
1024	2004	11	23	0.02	0
1024	2004	11	26	0.15	0
1024	2004	11	31	0.07	0
1024	2004	13	23	0.02	0
1024	2004	13	26	0.26	0
1024	2004	13	31	0.12	0
1024	2004	14	23	0.005	0
1024	2004	14	26	0.67	0
1024	2004	14	31	0.34	0
1024	2004	15	23	0.02	0
1024	2004	15	26	0.64	0
1024	2004	15	31	0.37	0
1024	2004	16	23	0.06	0
1024	2004	16	26	1.26	0
1024	2004	16	31	0.51	0
1024	2004	17	23	0.07	0
1024	2004	17	26	1.47	0
1024	2004	17	31	0.66	0
1024	2004	18	23	0.06	0
1024	2004	18	26	1.24	0
1024	2004	18	31	0.51	0
1024	2004	19	23	0.03	0
1024	2004	19	26	1.51	0
1024	2004	19	31	0.63	0
1024	2004	20	23	0.005	0
1024	2004	20	26	0.33	0
1024	2004	20	31	0.14	0
1024	2004	22	23	0	0
1024	2004	22	26	0.2	0
1024	2004	22	31	0.07	0
1024	2004	23	26	0.13	0
1024	2004	23	31	0.03	0
1024	2004	24	26	0.08	0
1024	2004	24	31	0.01	0
1024	2004	26	26	0.03	0
1024	2004	26	31	0.01	0
1024	2005	1	26	0.02	0
1024	2005	1	31	0.03	0
1024	2005	2	26	0.09	0
1024	2005	2	31	0.04	0
1024	2005	3	23	0.05	0
1024	2005	3	26	0.14	0
1024	2005	3	31	0.07	0
1024	2005	4	23	0.03	0
1024	2005	4	26	0.09	0
1024	2005	4	31	0.04	0
1024	2005	5	23	0.01	0
1024	2005	5	26	0.11	0
1024	2005	5	31	0.07	0
1024	2005	6	23	0.01	0
1024	2005	6	26	0.15	0
1024	2005	6	31	0.09	0
1024	2005	7	23	0.005	0
1024	2005	7	26	0.08	0
1024	2005	7	31	0.05	0
1024	2005	8	23	0.005	0
1024	2005	8	26	0.09	0
1024	2005	8	31	0.07	0
1024	2005	9	23	0.005	0
1024	2005	9	26	0.06	0
1024	2005	9	31	0.05	0
1024	2005	10	23	0.005	0
1024	2005	10	26	0.15	0
1024	2005	10	31	0.09	0
1024	2005	12	26	0.05	0
1024	2005	12	31	0.05	0
1024	2005	13	23	0.02	0
1024	2005	13	26	0.78	0
1024	2005	13	31	0.53	0
1024	2005	14	23	0.01	0
1024	2005	14	26	0.36	0
1024	2005	14	31	0.3	0
1024	2005	15	23	0.09	0
1024	2005	15	26	2.37	0
1024	2005	15	31	1.18	0
1024	2005	16	23	0.06	0
1024	2005	16	26	1.48	0
1024	2005	16	31	0.65	0
1024	2005	17	23	0.01	0
1024	2005	17	26	0.7	0
1024	2005	17	31	0.38	0
1024	2005	18	23	0.06	0
1024	2005	18	26	0.88	0
1024	2005	18	31	0.67	0
1024	2005	19	23	0.005	0
1024	2005	19	26	0.63	0
1024	2005	19	31	0.31	0
1024	2005	20	26	0.23	0
1024	2005	20	31	0.14	0
1024	2005	21	23	0.01	0
1024	2005	21	26	0.06	0
1024	2005	21	31	0.01	0
1024	2005	22	23	0.005	0
1024	2005	22	26	0.06	0
1024	2005	22	31	0.03	0
1024	2005	23	23	0.005	0
1024	2005	23	26	0.06	0
1024	2005	23	31	0.03	0
1024	2005	24	26	5.88628762541806E-03	0
1024	2005	24	31	4.8780487804878E-03	0
1024	2005	25	26	0.02	0
1024	2005	25	31	4.16666666666667E-03	0
1024	2006	1	23	0.01	0
1024	2006	1	26	0.03	0
1024	2006	1	31	0.01	0
1024	2006	5	23	0.04	0
1024	2006	5	26	0.12	0
1024	2006	5	31	0.06	0
1024	2006	6	23	0.01	0
1024	2006	6	26	0.11	0
1024	2006	6	31	0.06	0
1024	2006	9	23	0.005	0
1024	2006	9	26	0.1	0
1024	2006	9	31	0.03	0
1024	2006	10	26	0.18	0
1024	2006	10	31	0.13	0
1024	2006	11	23	0.005	0
1024	2006	11	26	0.13	0
1024	2006	11	31	0.09	0
1024	2006	12	23	0.005	0
1024	2006	12	26	0.04	0
1024	2006	12	31	0.03	0
1024	2006	13	26	0.23	0
1024	2006	13	31	0.21	0
1024	2006	14	23	0.04	0
1024	2006	14	26	0.53	0
1024	2006	14	31	0.33	0
1024	2006	15	23	0.01	0
1024	2006	15	26	1.3	0
1024	2006	15	31	0.81	0
1024	2006	16	23	0.01	0
1024	2006	16	26	1.36	0
1024	2006	16	31	0.66	0
1024	2006	17	23	0.03	0
1024	2006	17	26	1.11	0
1024	2006	17	31	0.71	0
1024	2006	18	23	0.01	0
1024	2006	18	26	0.69	0
1024	2006	18	31	0.49	0
1024	2006	19	26	0.44	0
1024	2006	19	31	0.24	0
1024	2006	20	23	0.005	0
1024	2006	20	26	0.29	0
1024	2006	20	31	0.1	0
1024	2006	21	23	0.02	0
1024	2006	21	26	0.12	0
1024	2006	21	31	0.06	0
1024	2006	23	26	0.09	0
1024	2006	23	31	0.06	0
1024	2006	24	26	0.04	0
1024	2006	24	31	0.04	0
1024	2006	25	23	0.005	0
1024	2006	25	26	0.05	0
1024	2006	25	31	0.01	0
1024	2006	26	26	0.01	0
1024	2006	26	31	5.95238095238095E-03	0
1024	2007	1	23	0.04	0
1024	2007	1	26	0.21	0
1024	2007	1	31	0.1	0
1024	2007	2	23	0.03	0
1024	2007	2	26	0.08	0
1024	2007	2	31	0.03	0
1024	2007	3	23	0.01	0
1024	2007	3	26	0.27	0
1024	2007	3	31	0.08	0
1024	2007	4	23	0.02	0
1024	2007	4	26	0.25	0
1024	2007	4	31	0.13	0
1024	2007	5	23	0.005	0
1024	2007	5	23	0.01	0
1024	2007	5	26	0.06	0
1024	2007	5	26	0.09	0
1024	2007	5	31	0.05	0
1024	2007	5	31	0.09	0
1024	2007	6	23	0.005	0
1024	2007	6	26	0.06	0
1024	2007	6	31	0.05	0
1024	2007	7	23	0.01	0
1024	2007	7	26	0.15	0
1024	2007	7	31	0.09	0
1024	2007	8	26	0.1	0
1024	2007	8	31	0.02	0
1024	2007	9	26	0.05	0
1024	2007	9	31	0.01	0
1024	2007	10	23	0.005	0
1024	2007	10	26	0.1	0
1024	2007	10	31	0.09	0
1024	2007	11	23	0.005	0
1024	2007	11	26	0.04	0
1024	2007	11	31	0.06	0
1024	2007	12	26	0.25	0
1024	2007	12	31	0.12	0
1024	2007	13	23	0.005	0
1024	2007	13	26	0.23	0
1024	2007	13	31	0.14	0
1024	2007	14	23	0.005	0
1024	2007	14	26	0.35	0
1024	2007	14	31	0.41	0
1024	2007	15	23	0.01	0
1024	2007	15	26	0.73	0
1024	2007	15	31	0.39	0
1024	2007	16	23	0.05	0
1024	2007	16	26	1.06	0
1024	2007	16	31	0.63	0
1024	2007	17	23	0.03	0
1024	2007	17	26	0.39	0
1024	2007	17	31	0.3	0
1024	2007	18	23	0.005	0
1024	2007	18	26	0.69	0
1024	2007	18	31	0.39	0
1024	2007	19	23	0.01	0
1024	2007	19	26	0.39	0
1024	2007	19	31	0.16	0
1024	2007	20	23	0.005	0
1024	2007	20	26	0.16	0
1024	2007	20	31	0.04	0
1024	2007	21	23	0.02	0
1024	2007	21	26	0.07	0
1024	2007	21	31	0.01	0
1024	2007	23	26	0.06	0
1024	2007	23	31	0.01	0
1024	2007	24	26	0.04	0
1024	2007	24	31	0.01	0
1024	2007	25	26	0.01	0
1024	2007	25	31	6.60569105691057E-03	0
1035	2000	1	31	0.07	1
1035	2000	2	31	0.07	1
1035	2000	4	31	0.07	1
1035	2000	5	31	0.09	1
1035	2000	6	31	0.06	1
1035	2000	7	31	0.07	1
1035	2000	9	31	0.01	1
1035	2000	10	31	0.02	1
1035	2000	12	31	0.21	1
1035	2000	13	31	0.5	1
1035	2000	15	31	1.09	1
1035	2000	16	31	1.33	1
1035	2000	17	31	1.49	1
1035	2000	18	31	0.95	1
1035	2000	21	31	0.37	1
1035	2000	22	31	0.6	1
1035	2000	24	31	0.31	1
1035	2000	25	31	0.11	1
1035	2001	1	31	7.89840253697282E-03	1
1035	2001	2	31	7.89840253697282E-03	1
1035	2001	3	31	0.04	1
1035	2001	4	31	0.02	1
1035	2001	5	31	0.03	1
1035	2001	6	31	0.06	1
1035	2001	7	31	0.03	1
1035	2001	8	31	0.02	1
1035	2001	9	31	0.02	1
1035	2001	9	31	0.03	1
1035	2001	10	31	0.03	1
1035	2001	11	31	0.06	1
1035	2001	12	31	0.18	1
1035	2001	13	31	0.39	1
1035	2001	14	31	3.04	1
1035	2001	15	31	1.99	1
1035	2001	17	31	1.05	1
1035	2001	19	31	1.44	1
1035	2001	20	31	1.11	1
1035	2001	21	31	0.72	1
1035	2001	23	31	0.05	1
1035	2002	1	31	0.07	1
1035	2002	2	31	0.03	1
1035	2002	3	31	0.05	1
1035	2002	4	31	0.05	1
1035	2002	5	31	0.02	1
1035	2002	6	31	0.12	1
1035	2002	7	31	0.12	1
1035	2002	8	31	0.04	1
1035	2002	9	31	0.04	1
1035	2002	10	31	0.05	1
1035	2002	11	31	0.12	1
1035	2002	12	31	0.56	1
1035	2002	13	31	0.82	1
1035	2002	14	31	1.21	1
1035	2002	15	31	1.54	1
1035	2002	16	31	1.44	1
1035	2002	17	31	1.53	1
1035	2002	18	31	1.62	1
1035	2002	19	31	1.24	1
1035	2002	20	31	0.92	1
1035	2002	21	31	0.51	1
1035	2002	22	31	0.28	1
1035	2002	22	31	0.55	1
1035	2002	23	31	0.27	1
1035	2002	24	31	0.12	1
1035	2002	25	31	0.12	1
1035	2003	1	31	0.07	1
1035	2003	2	31	0.05	1
1035	2003	3	31	0.05	1
1035	2003	5	31	0.22	1
1035	2003	6	31	0.18	1
1035	2003	8	31	0.04	1
1035	2003	9	31	0.04	1
1035	2003	10	31	0.02	1
1035	2003	11	31	0.35	1
1035	2003	12	31	0.44	1
1035	2003	13	31	0.74	1
1035	2003	14	31	1.81	1
1035	2003	15	31	1.35	1
1035	2003	16	31	1.45	1
1035	2003	17	31	2.45	1
1035	2003	18	31	0.53	1
1035	2003	19	31	0.31	1
1035	2003	20	31	0.83	1
1035	2003	21	31	0.51	1
1035	2003	22	31	0.35	1
1035	2003	24	31	0.24	1
1035	2003	26	31	0.05	1
1035	2004	1	31	0.12	1
1035	2004	2	31	0.02	1
1035	2004	3	31	0.1	1
1035	2004	4	31	0.14	1
1035	2004	5	31	0.05	1
1035	2004	7	31	0.01	1
1035	2004	8	31	0.06	1
1035	2004	9	31	0.04	1
1035	2004	10	31	0.05	1
1035	2004	11	31	0.21	1
1035	2004	12	31	0.64	1
1035	2004	14	31	0.98	1
1035	2004	15	31	1.31	1
1035	2004	16	31	2.34	1
1035	2004	17	31	0.89	1
1035	2004	18	31	1.27	1
1035	2004	19	31	1.09	1
1035	2004	20	31	0.81	1
1035	2004	21	31	0.89	1
1035	2004	22	31	1.02	1
1035	2004	24	31	0.1	1
1035	2004	25	31	0.24	1
1035	2004	26	31	0.1	1
1035	2005	2	31	0.04	1
1035	2005	3	31	0.07	1
1035	2005	5	31	0.08	1
1035	2005	7	31	0.03	1
1035	2005	8	31	0.05	1
1035	2005	9	31	0.04	1
1035	2005	10	31	0.06	1
1035	2005	11	31	0.05	1
1035	2005	12	31	0.09	1
1035	2005	13	31	0.89	1
1035	2005	14	31	0.71	1
1035	2005	15	31	1.36	1
1035	2005	16	31	0.95	1
1035	2005	18	31	0.91	1
1035	2005	19	31	0.64	1
1035	2005	20	31	0.24	1
1035	2005	21	31	0.06	1
1035	2005	22	31	0.07	1
1035	2005	23	31	0.18	1
1035	2005	24	31	0.05	1
1035	2005	25	31	0.07	1
1035	2005	26	31	0.05	1
1035	2006	2	31	0.07	1
1035	2006	3	31	0.07	1
1035	2006	4	31	0.08	1
1035	2006	5	31	0.06	1
1035	2006	6	31	0.06	1
1035	2006	7	31	0.05	1
1035	2006	8	31	0.04	1
1035	2006	9	31	9.66183574879227E-03	1
1035	2006	9	31	0.01	1
1035	2006	10	31	0.1	1
1035	2006	11	31	0.09	1
1035	2006	12	31	0.93	1
1035	2006	13	31	1.28	1
1035	2006	14	31	0.69	1
1035	2006	15	31	2.13	1
1035	2006	16	31	1.26	1
1035	2006	17	31	0.76	1
1035	2006	18	31	1.15	1
1035	2006	19	31	0.97	1
1035	2006	20	31	0.44	1
1035	2006	21	31	0.29	1
1035	2006	22	31	0.24	1
1035	2006	23	31	0.12	1
1035	2006	24	31	0.11	1
1035	2006	25	31	0.03	1
1035	2006	26	31	0.03	1
1035	2007	1	31	0.06	1
1035	2007	3	31	0.03	1
1035	2007	4	31	0.02	1
1035	2007	5	31	0.07	1
1035	2007	7	31	0.03	1
1035	2007	8	31	0.07	1
1035	2007	9	31	0.04	1
1035	2007	10	31	0.07	1
1035	2007	11	31	0.22	1
1035	2007	12	31	0.55	1
1035	2007	13	31	0.46	1
1035	2007	14	31	0.61	1
1035	2007	15	31	0.28	1
1035	2007	16	31	0.09	1
1035	2007	18	31	0.13	1
1035	2007	19	31	0.14	1
1035	2007	23	31	0.1	1
1035	2007	24	31	0.08	1
1116	2000	1	15	0.01	0
1116	2000	1	26	0.04	0
1116	2000	2	15	0.01	0
1116	2000	2	26	0.02	0
1116	2000	3	26	0.03	0
1116	2000	5	15	8.40336134453781E-03	0
1116	2000	5	26	0.05	0
1116	2000	6	15	0.02	0
1116	2000	6	26	0.1	0
1116	2000	7	15	0.03	0
1116	2000	7	26	0.08	0
1116	2000	9	15	0.01	0
1116	2000	9	26	0.02	0
1116	2000	11	15	0.01	0
1116	2000	11	26	0.01	0
1116	2000	12	15	0.01	0
1116	2000	12	26	0.01	0
1116	2000	13	15	0.03	0
1116	2000	13	26	0.04	0
1116	2000	14	15	0.01	0
1116	2000	14	26	0.04	0
1116	2000	15	15	5.88235294117647E-03	0
1116	2000	15	26	0.04	0
1116	2000	16	15	0.04	0
1116	2000	16	26	0.07	0
1116	2000	17	15	0.03	0
1116	2000	17	26	0.12	0
1116	2000	19	15	0.03	0
1116	2000	19	26	0.07	0
1116	2000	20	15	0.02	0
1116	2000	20	26	0.08	0
1116	2000	21	15	0.01	0
1116	2000	21	26	0.1	0
1116	2000	23	15	0.01	0
1116	2000	23	26	0.03	0
1116	2000	25	26	0.01	0
1116	2002	1	26	0.03	0
1116	2002	2	15	4.20168067226891E-03	0
1116	2002	2	26	0.05	0
1116	2002	3	15	4.20168067226891E-03	0
1116	2002	3	26	0.04	0
1116	2002	5	26	0.03	0
1116	2002	6	26	0.06	0
1116	2002	7	15	0.02	0
1116	2002	7	26	0.06	0
1116	2002	8	15	4.20168067226891E-03	0
1116	2002	8	26	0.02	0
1116	2002	9	15	5.88235294117647E-03	0
1116	2002	9	26	0.02	0
1116	2002	12	15	4.20168067226891E-03	0
1116	2002	12	26	0.05	0
1116	2002	13	26	0.02	0
1116	2002	17	15	0.06	0
1116	2002	17	26	0.02	0
1116	2002	18	15	0.03	0
1116	2002	18	15	0.06	0
1116	2002	18	26	0.01	0
1116	2002	18	26	0.03	0
1116	2002	19	15	0.03	0
1116	2002	19	26	0.03	0
1116	2002	20	15	0.04	0
1116	2002	20	26	0.01	0
1116	2002	21	15	0.01	0
1116	2002	21	26	3.93700787401575E-03	0
1116	2002	22	15	0.02	0
1116	2002	22	26	0.06	0
1116	2002	23	26	0.03	0
1116	2002	24	26	0.01	0
1116	2003	1	26	0.04	0
1116	2003	3	15	4.20168067226891E-03	0
1116	2003	3	26	0.03	0
1116	2003	4	26	0.06	0
1116	2003	7	15	4.20168067226891E-03	0
1116	2003	7	26	0.04	0
1116	2003	8	26	0.01	0
1116	2003	11	15	0.02	0
1116	2003	11	26	0.13	0
1116	2003	12	26	0.07	0
1116	2003	13	15	0.06	0
1116	2003	13	26	0.15	0
1116	2003	14	15	0.04	0
1116	2003	14	26	0.09	0
1116	2003	15	15	0.13	0
1116	2003	15	26	0.33	0
1116	2003	16	15	0.07	0
1116	2003	16	26	0.15	0
1116	2003	18	15	0.05	0
1116	2003	18	26	0.24	0
1116	2003	19	15	0.05	0
1116	2003	19	26	0.15	0
1116	2003	20	15	0.03	0
1116	2003	20	26	0.1	0
1116	2003	21	26	0.02	0
1116	2003	22	15	0.03	0
1116	2003	22	26	0.2	0
1116	2003	24	26	0.09	0
1116	2003	25	15	0.02	0
1116	2003	25	26	0.19	0
1116	2004	4	15	0.01	0
1116	2004	4	26	0.08	0
1116	2004	5	26	0.09	0
1116	2004	6	26	0.1	0
1116	2004	7	26	0.03	0
1116	2004	8	15	0.01	0
1116	2004	8	26	0.12	0
1116	2004	9	15	0.04	0
1116	2004	9	26	0.07	0
1116	2004	10	26	0.05	0
1116	2004	12	26	0.02	0
1116	2004	15	26	0.04	0
1116	2004	18	15	0.03	0
1116	2004	18	26	0.05	0
1116	2004	19	15	0.06	0
1116	2004	19	26	0.06	0
1116	2004	20	26	0.05	0
1116	2004	22	15	0.01	0
1116	2004	22	26	0.01	0
1116	2005	3	26	0.02	0
1116	2005	4	26	0.02	0
1116	2005	6	26	0.11	0
1116	2005	7	15	0.01	0
1116	2005	7	26	0.13	0
1116	2005	9	26	0.04	0
1116	2005	10	26	0.03	0
1116	2005	13	15	0.01	0
1116	2005	13	26	0.05	0
1116	2005	14	15	0.01	0
1116	2005	14	26	0.05	0
1116	2005	15	26	0.05	0
1116	2005	16	15	0.01	0
1116	2005	16	26	0.02	0
1116	2005	18	15	0.03	0
1116	2005	18	26	0.05	0
1116	2005	21	26	0.11	0
1116	2006	3	26	0.05	0
1116	2006	4	15	8.40336134453781E-03	0
1116	2006	4	26	0.06	0
1116	2006	5	15	8.40336134453781E-03	0
1116	2006	5	26	0.09	0
1116	2006	6	15	8.40336134453781E-03	0
1116	2006	6	26	0.05	0
1116	2006	8	15	4.20168067226891E-03	0
1116	2006	8	26	0.03	0
1116	2006	9	15	4.20168067226891E-03	0
1116	2006	9	26	0.04	0
1116	2006	10	26	2.9673590504451E-03	0
1116	2006	11	15	0.01	0
1116	2006	11	26	0.19	0
1116	2006	12	15	0.01	0
1116	2006	12	26	0.09	0
1116	2006	13	15	8.40336134453781E-03	0
1116	2006	13	26	0.29	0
1116	2006	14	15	4.20168067226891E-03	0
1116	2006	14	26	0.16	0
1116	2006	15	26	0.13	0
1116	2006	16	15	8.40336134453781E-03	0
1116	2006	16	26	0.16	0
1116	2006	17	26	0.06	0
1116	2006	18	15	4.20168067226891E-03	0
1116	2006	18	26	0.01	0
1116	2006	19	15	4.20168067226891E-03	0
1116	2006	19	26	0.01	0
1116	2006	20	26	0.04	0
1116	2006	21	15	0.01	0
1116	2006	21	26	0.06	0
1116	2006	23	26	0.08	0
1116	2006	24	15	0.01	0
1116	2006	24	26	0.14	0
1116	2006	26	15	0.02	0
1116	2006	26	26	0.05	0
1116	2007	1	15	4.20168067226891E-03	0
1116	2007	1	26	0.07	0
1116	2007	2	15	8.40336134453781E-03	0
1116	2007	2	26	0.06	0
1116	2007	4	15	8.40336134453781E-03	0
1116	2007	4	26	0.13	0
1116	2007	6	15	8.40336134453781E-03	0
1116	2007	6	26	0.02	0
1116	2007	7	15	8.40336134453781E-03	0
1116	2007	7	26	0.02	0
1116	2007	8	26	0.04	0
1116	2007	9	15	4.20168067226891E-03	0
1116	2007	9	26	0.04	0
1116	2007	10	26	0.33	0
1116	2007	11	26	0.19	0
1116	2007	12	26	0.02	0
1116	2007	13	15	8.40336134453781E-03	0
1116	2007	13	26	0.07	0
1116	2007	15	15	0.01	0
1116	2007	15	26	0.07	0
1116	2007	16	26	3.01204819277108E-03	0
1116	2007	17	15	8.40336134453781E-03	0
1116	2007	17	26	0.05	0
1116	2007	21	15	4.20168067226891E-03	0
1116	2007	21	26	0.09	0
1116	2007	22	15	4.20168067226891E-03	0
1116	2007	22	26	0.02	0
1116	2007	23	15	8.40336134453781E-03	0
1116	2007	23	26	0.11	0
1117	2000	9	15	4.54545454545455E-03	0
1117	2000	9	26	7.40740740740741E-03	0
1117	2000	12	15	0.01	0
1117	2000	12	26	9.86378475740178E-03	0
1117	2000	12	31	8.33333333333333E-03	0
1117	2000	13	15	0.01	0
1117	2000	13	26	1.85185185185185E-03	0
1117	2000	13	31	0.01	0
1117	2000	14	15	0.01	0
1117	2000	14	20	0.02	0
1117	2000	14	26	0.01	0
1117	2001	5	26	1.88679245283019E-03	0
1117	2001	5	31	8.33333333333333E-03	0
1117	2001	6	15	0.01	0
1117	2001	6	20	0.01	0
1117	2001	6	26	0.07	0
1117	2001	6	31	0.04	0
1117	2001	8	20	0.02	0
1117	2001	8	26	0.03	0
1117	2001	8	31	0.04	0
1117	2001	12	15	0.01	0
1117	2001	12	31	8.33333333333333E-03	0
1117	2001	14	20	0.01	0
1117	2001	14	31	0.02	0
1117	2001	15	15	0.01	0
1117	2001	15	20	0.01	0
1117	2001	15	26	0.01	0
1117	2001	15	31	0.1	0
1117	2001	16	15	0.06	0
1117	2001	16	20	0.02	0
1117	2001	16	26	0.11	0
1117	2001	16	31	0.06	0
1117	2001	17	15	0.12	0
1117	2001	17	20	0.01	0
1117	2001	17	26	0.07	0
1117	2001	17	31	0.22	0
1117	2001	18	15	0.08	0
1117	2001	18	20	0.01	0
1117	2001	18	26	0.02	0
1117	2001	18	31	0.13	0
1117	2001	19	15	0.02	0
1117	2001	19	20	0.02	0
1117	2001	19	26	0.01	0
1117	2001	19	31	0.05	0
1117	2001	22	15	0.01	0
1117	2001	22	20	0.01	0
1117	2001	22	26	3.7037037037037E-03	0
1117	2001	22	31	0.01	0
1117	2002	2	15	4.54545454545455E-03	0
1117	2002	2	26	0.03	0
1117	2002	2	31	2.7027027027027E-03	0
1117	2002	3	15	0.02	0
1117	2002	3	20	0.01	0
1117	2002	3	26	0.04	0
1117	2002	3	31	0.02	0
1117	2002	4	15	0.04	0
1117	2002	4	20	0.03	0
1117	2002	4	26	0.06	0
1117	2002	4	31	0.03	0
1117	2002	7	15	0.01	0
1117	2002	7	26	0.04	0
1117	2002	7	31	0.04	0
1117	2002	9	15	0.01	0
1117	2002	9	26	0.01	0
1117	2002	9	31	8.33333333333333E-03	0
1117	2002	12	26	0.04	0
1117	2002	13	20	0.02	0
1117	2002	13	26	0.07	0
1117	2002	15	15	0.07	0
1117	2002	15	26	0.02	0
1117	2002	15	31	0.01	0
1117	2002	16	15	0.07	0
1117	2002	16	26	1.2987012987013E-03	0
1117	2002	16	31	0.06	0
1117	2002	19	15	0.24	0
1117	2002	19	26	0.08	0
1117	2002	19	31	0.37	0
1117	2002	20	15	0.18	0
1117	2002	20	20	0.01	0
1117	2002	20	26	0.12	0
1117	2002	20	31	0.36	0
1117	2002	21	15	0.03	0
1117	2002	21	26	0.05	0
1117	2002	21	31	0.16	0
1117	2002	22	15	0.01	0
1117	2002	22	15	0.03	0
1117	2002	22	20	0.01	0
1117	2002	22	20	0.02	0
1117	2002	22	26	0.03	0
1117	2002	22	26	0.05	0
1117	2002	22	31	8.10810810810811E-03	0
1117	2002	22	31	0.01	0
1117	2002	23	15	0.01	0
1117	2002	23	20	0.02	0
1117	2002	23	26	0.03	0
1117	2002	23	31	0.01	0
1117	2002	24	15	4.25531914893617E-03	0
1117	2002	24	26	0.03	0
1117	2002	24	31	0.04	0
1117	2003	1	15	0.04	0
1117	2003	1	26	0.04	0
1117	2003	1	31	2.7027027027027E-03	0
1117	2003	2	15	0.04	0
1117	2003	2	26	0.04	0
1117	2003	2	31	2.7027027027027E-03	0
1117	2003	3	15	0.12	0
1117	2003	3	26	0.12	0
1117	2003	3	31	0.07	0
1117	2003	4	15	0.1	0
1117	2003	4	26	0.05	0
1117	2003	4	31	0.03	0
1117	2003	6	15	0.01	0
1117	2003	6	20	0.01	0
1117	2003	6	26	0.08	0
1117	2003	6	31	0.07	0
1117	2003	9	26	1.2987012987013E-03	0
1117	2003	9	31	8.10810810810811E-03	0
1117	2003	11	15	0.11	0
1117	2003	11	26	0.07	0
1117	2003	11	31	0.02	0
1117	2003	12	15	0.14	0
1117	2003	12	26	0.23	0
1117	2003	12	31	0.09	0
1117	2003	13	15	0.14	0
1117	2003	13	26	0.23	0
1117	2003	13	31	0.09	0
1117	2003	14	15	0.24	0
1117	2003	14	26	0.23	0
1117	2003	14	31	0.13	0
1117	2003	16	15	0.12	0
1117	2003	16	20	0.03	0
1117	2003	16	26	0.2	0
1117	2003	16	31	0.15	0
1117	2003	19	15	0.12	0
1117	2003	19	20	0.15	0
1117	2003	19	26	0.44	0
1117	2003	19	31	0.11	0
1117	2003	21	15	0.01	0
1117	2003	21	20	0.06	0
1117	2003	21	26	0.13	0
1117	2003	21	31	0.02	0
1117	2004	7	15	0.01	0
1117	2004	7	20	0.01	0
1117	2004	7	26	0.2	0
1117	2004	7	31	0.07	0
1117	2004	8	15	0.02	0
1117	2004	8	20	0.03	0
1117	2004	8	26	0.14	0
1117	2004	8	31	0.01	0
1117	2004	11	15	0.12	0
1117	2004	11	20	0.01	0
1117	2004	11	26	0.14	0
1117	2004	11	31	0.06	0
1117	2004	12	15	0.27	0
1117	2004	12	20	0.02	0
1117	2004	12	26	0.15	0
1117	2004	12	31	0.08	0
1117	2004	14	15	0.44	0
1117	2004	14	20	0.08	0
1117	2004	14	26	0.2	0
1117	2004	14	31	0.23	0
1117	2004	16	15	0.18	0
1117	2004	16	26	0.12	0
1117	2004	16	31	0.04	0
1117	2004	17	15	0.18	0
1117	2004	17	26	0.12	0
1117	2004	17	31	0.04	0
1117	2004	23	20	0.01	0
1117	2004	23	26	0.05	0
1117	2004	23	31	0.06	0
1117	2005	4	15	0.03	0
1117	2005	4	26	0.1	0
1117	2005	4	31	0.02	0
1117	2005	5	15	0.01	0
1117	2005	5	20	0.01	0
1117	2005	5	26	0.06	0
1117	2005	5	31	0.02	0
1117	2005	10	15	0.01	0
1117	2005	10	26	0.03	0
1117	2005	10	31	8.10810810810811E-03	0
1117	2005	13	15	0.08	0
1117	2005	13	20	0.01	0
1117	2005	13	26	0.18	0
1117	2005	13	31	0.03	0
1117	2005	15	15	0.28	0
1117	2005	15	20	0.01	0
1117	2005	15	26	0.19	0
1117	2005	15	31	0.13	0
1117	2005	18	15	0.01	0
1117	2005	18	20	0.02	0
1117	2005	18	26	0.2	0
1117	2005	18	31	0.24	0
1117	2005	21	15	8.51063829787234E-03	0
1117	2005	21	20	0.01	0
1117	2005	21	26	0.12	0
1117	2005	21	31	0.01	0
1117	2006	9	15	0.05	0
1117	2006	9	26	0.01	0
1117	2006	9	31	8.10810810810811E-03	0
1117	2006	10	15	0.05	0
1117	2006	10	26	0.06	0
1117	2006	10	31	0.01	0
1117	2006	11	15	0.03	0
1117	2006	11	26	0.1	0
1117	2006	11	31	0.01	0
1117	2006	13	15	0.12	0
1117	2006	13	26	0.11	0
1117	2006	13	31	0.06	0
1117	2006	14	15	0.14	0
1117	2006	14	20	0.03	0
1117	2006	14	26	0.27	0
1117	2006	14	31	0.17	0
1117	2006	15	15	0.15	0
1117	2006	15	20	0.03	0
1117	2006	15	26	0.16	0
1117	2006	15	31	0.15	0
1117	2006	17	15	0.13	0
1117	2006	17	20	0.15	0
1117	2006	17	26	0.32	0
1117	2006	17	31	0.14	0
1117	2006	18	15	0.04	0
1117	2006	18	20	0.11	0
1117	2006	18	26	0.34	0
1117	2006	18	31	0.11	0
1117	2007	4	15	0.02	0
1117	2007	4	26	0.09	0
1117	2007	4	31	8.10810810810811E-03	0
1117	2007	5	15	0.06	0
1117	2007	5	26	0.11	0
1117	2007	5	31	0.03	0
1117	2007	8	15	8.80077369439072E-03	0
1117	2007	8	26	0.05	0
1117	2007	8	31	0.03	0
1117	2007	10	15	0.03	0
1117	2007	10	20	0.01	0
1117	2007	10	26	0.03	0
1117	2007	11	15	0.11	0
1117	2007	11	26	0.11	0
1117	2007	16	15	0.12	0
1117	2007	16	26	0.02	0
1117	2007	16	31	0.02	0
1117	2007	17	15	0.17	0
1117	2007	17	26	0.11	0
1117	2007	17	31	0.04	0
1117	2007	21	15	0.03	0
1117	2007	21	26	0.18	0
1117	2007	21	31	0.07	0
1117	2007	23	15	0.02	0
1117	2007	23	26	0.11	0
1117	2007	23	31	0.04	0
1117	2007	24	15	0.01	0
1117	2007	24	26	0.13	0
1117	2007	24	31	0.05	0
1124	2002	1	28	0.01	0
1124	2002	2	26	5.88235294117647E-03	0
1124	2002	2	28	0.03	0
1124	2002	3	26	0.02	0
1124	2002	3	28	0.02	0
1124	2002	4	26	0.03	0
1124	2002	4	28	0.03	0
1124	2002	5	26	0.05	0
1124	2002	5	28	0.03	0
1124	2002	6	26	0.04	0
1124	2002	6	28	0.05	0
1124	2002	7	26	0.04	0
1124	2002	7	28	0.03	0
1124	2002	8	26	0.01	0
1124	2002	8	28	0.01	0
1124	2002	9	26	0.02	0
1124	2002	9	28	0.01	0
1124	2002	10	26	4.79616306954436E-03	0
1124	2002	10	28	0.02	0
1124	2002	12	26	0.01	0
1124	2002	12	28	0.01	0
1124	2002	13	26	0.01	0
1124	2002	13	28	1.63398692810458E-03	0
1124	2002	14	26	2.39808153477218E-03	0
1124	2002	15	26	0.02	0
1124	2002	15	28	0.02	0
1124	2002	16	26	0.02	0
1124	2002	16	28	0.04	0
1124	2002	17	26	0.03	0
1124	2002	17	28	0.03	0
1124	2002	18	26	0.02	0
1124	2002	18	28	0.03	0
1124	2002	19	26	0.01	0
1124	2002	19	28	0.03	0
1124	2002	20	26	0.03	0
1124	2002	20	28	0.07	0
1124	2002	21	26	0.03	0
1124	2002	21	28	0.06	0
1124	2002	22	26	0.01	0
1124	2002	22	28	0.02	0
1124	2002	23	26	6.31965016222316E-03	0
1124	2002	23	28	4.90196078431373E-03	0
1124	2002	24	26	0.01	0
1124	2002	24	28	7.66439172354024E-03	0
1124	2002	25	26	4.79616306954436E-03	0
1124	2002	25	28	4.90196078431373E-03	0
1124	2002	26	26	4.35886584849767E-03	0
1124	2002	26	28	3.26797385620915E-03	0
1124	2003	1	26	0.01	0
1124	2003	1	28	0.01	0
1124	2003	2	26	3.92156862745098E-03	0
1124	2003	2	28	0.01	0
1124	2003	3	26	0.02	0
1124	2003	3	28	0.04	0
1124	2003	4	26	8.28043447594865E-03	0
1124	2003	4	28	0.03	0
1124	2003	6	26	0.03	0
1124	2003	6	28	0.03	0
1124	2003	7	26	7.19424460431655E-03	0
1124	2003	7	28	0.05	0
1124	2003	8	26	0.01	0
1124	2003	8	28	0.02	0
1124	2003	9	26	7.19424460431655E-03	0
1124	2003	9	28	0.01	0
1124	2003	10	26	9.15502891804204E-03	0
1124	2003	10	28	0.01	0
1124	2003	11	26	0.01	0
1124	2003	11	28	0.04	0
1124	2003	12	26	1.96078431372549E-03	0
1124	2003	12	28	0.01	0
1124	2003	13	26	0.02	0
1124	2003	13	28	0.1	0
1124	2003	14	26	0.03	0
1124	2003	14	28	0.1	0
1124	2003	15	26	0.12	0
1124	2003	15	28	0.27	0
1124	2003	16	26	0.04	0
1124	2003	16	28	0.12	0
1124	2003	17	26	0.05	0
1124	2003	17	28	0.15	0
1124	2003	18	26	0.02	0
1124	2003	18	28	0.16	0
1124	2003	19	26	0.04	0
1124	2003	19	28	0.17	0
1124	2003	20	26	0.01	0
1124	2003	20	28	0.06	0
1124	2003	21	26	6.75694738326985E-03	0
1124	2003	21	28	0.01	0
1124	2003	22	26	0.07	0
1124	2003	22	28	0.17	0
1124	2003	23	26	0.04	0
1124	2003	23	28	0.08	0
1124	2003	24	26	0.04	0
1124	2003	24	28	0.03	0
1124	2003	25	26	0.01	0
1124	2003	25	28	0.01	0
1124	2003	26	26	0.01	0
1124	2003	26	28	0.01	0
1124	2004	2	26	0.01	0
1124	2004	2	28	0.03	0
1124	2004	3	26	0.02	0
1124	2004	3	28	0.03	0
1124	2004	4	26	0.01	0
1124	2004	4	28	0.04	0
1124	2004	5	26	0.03	0
1124	2004	5	28	0.05	0
1124	2004	6	26	0.02	0
1124	2004	6	28	0.05	0
1124	2004	7	26	0.02	0
1124	2004	7	28	0.04	0
1124	2004	8	26	0.01	0
1124	2004	8	28	0.04	0
1124	2004	9	26	0.01	0
1124	2004	9	28	0.01	0
1124	2004	10	26	9.15502891804204E-03	0
1124	2004	10	28	0.01	0
1124	2004	11	26	0.03	0
1124	2004	11	28	0.07	0
1124	2004	12	26	0.01	0
1124	2004	12	28	0.04	0
1124	2004	13	26	0.03	0
1124	2004	13	28	0.1	0
1124	2004	14	26	0.01	0
1124	2004	14	28	0.05	0
1124	2004	15	26	0.04	0
1124	2004	15	28	0.08	0
1124	2004	16	26	0.01	0
1124	2004	16	28	0.04	0
1124	2004	17	26	0.02	0
1124	2004	17	28	0.12	0
1124	2004	18	26	0.03	0
1124	2004	18	28	0.15	0
1124	2004	19	26	0.06	0
1124	2004	19	28	0.19	0
1124	2004	20	26	9.59232613908873E-03	0
1124	2004	20	28	0.06	0
1124	2004	21	26	0.01	0
1124	2004	21	28	0.06	0
1124	2004	22	26	0.01	0
1124	2004	22	28	0.02	0
1124	2004	23	26	0.01	0
1124	2004	23	28	0.02	0
1124	2004	24	26	7.19424460431655E-03	0
1124	2004	24	28	1.63398692810458E-03	0
1124	2004	25	26	7.19424460431655E-03	0
1124	2004	25	28	1.63398692810458E-03	0
1124	2004	26	26	8.28043447594865E-03	0
1124	2004	26	28	4.39641786733109E-03	0
1124	2005	2	26	8.28043447594865E-03	0
1124	2005	2	28	9.80392156862745E-03	0
1124	2005	3	26	3.92156862745098E-03	0
1124	2005	3	28	0.03	0
1124	2005	4	26	0.02	0
1124	2005	4	28	0.02	0
1124	2005	5	26	0.06	0
1124	2005	5	28	0.03	0
1124	2005	6	26	0.02	0
1124	2005	6	28	0.06	0
1124	2005	7	26	0.03	0
1124	2005	7	28	0.04	0
1124	2005	8	26	0.02	0
1124	2005	8	28	0.03	0
1124	2005	9	26	0.01	0
1124	2005	9	28	0.02	0
1124	2005	10	26	9.15502891804204E-03	0
1124	2005	10	28	0.01	0
1124	2005	12	26	0.01	0
1124	2005	12	28	7.15884880655761E-03	0
1124	2005	13	26	0.02	0
1124	2005	13	28	0.04	0
1124	2005	14	26	0.03	0
1124	2005	14	28	0.05	0
1124	2005	15	26	0.05	0
1124	2005	15	28	0.11	0
1124	2005	16	26	0.08	0
1124	2005	16	28	0.17	0
1124	2005	17	26	0.11	0
1124	2005	17	28	0.12	0
1124	2005	18	26	0.01	0
1124	2005	18	28	0.05	0
1124	2005	19	26	0.07	0
1124	2005	19	28	0.18	0
1124	2005	20	26	0.04	0
1124	2005	20	28	0.15	0
1124	2005	21	26	0.06	0
1124	2005	21	28	0.12	0
1124	2005	22	26	0.04	0
1124	2005	22	28	0.09	0
1124	2005	23	26	0.06	0
1124	2005	23	28	0.08	0
1124	2005	24	26	0.08	0
1124	2005	24	28	0.08	0
1124	2005	25	26	0.01	0
1124	2005	25	28	0.02	0
1124	2005	26	26	0.05	0
1124	2005	26	28	0.02	0
1124	2007	1	26	0.01	0
1124	2007	1	28	0.08	0
1124	2007	2	26	0.03	0
1124	2007	2	28	0.11	0
1124	2007	3	26	0.02	0
1124	2007	3	28	0.06	0
1124	2007	4	26	0.05	0
1124	2007	4	28	0.06	0
1124	2007	5	26	0.03	0
1124	2007	5	28	0.06	0
1124	2007	7	26	5.88235294117647E-03	0
1124	2007	7	28	0.02	0
1124	2007	9	28	7.66439172354024E-03	0
1124	2007	10	26	1.96078431372549E-03	0
1124	2007	10	28	0.01	0
1124	2007	11	26	0.01	0
1124	2007	11	28	0.03	0
1124	2007	13	26	7.84313725490196E-03	0
1124	2007	13	28	0.02	0
1124	2007	14	28	0.01	0
1124	2007	15	26	0.01	0
1124	2007	15	28	0.17	0
1124	2007	16	28	1.63398692810458E-03	0
1124	2007	17	26	9.15502891804204E-03	0
1124	2007	17	28	0.02	0
1124	2007	19	26	0.01	0
1124	2007	19	28	0.02	0
1124	2007	20	26	7.84313725490196E-03	0
1124	2007	20	28	0.01	0
1124	2007	21	26	2.39808153477218E-03	0
1124	2007	21	28	8.98225957049486E-03	0
1124	2007	22	26	0.03	0
1124	2007	22	28	0.02	0
1126	2000	1	15	5.83333333333333E-03	2
1126	2000	1	26	0.04	2
1126	2000	1	31	0.02	2
1126	2000	1	32	0.01	2
1126	2000	3	15	0.0025	2
1126	2000	3	26	0.008	2
1126	2000	3	31	0.005	2
1126	2000	4	15	3.33333333333333E-03	2
1126	2000	4	26	0.01	2
1126	2000	4	31	0.03	2
1126	2000	4	32	0.0075	2
1126	2000	5	15	0.02	2
1126	2000	5	26	0.02	2
1126	2000	5	31	0.009	2
1126	2000	5	32	0.005	2
1126	2000	6	15	0.03	2
1126	2000	6	26	0.06	2
1126	2000	6	28	0.01	2
1126	2000	6	31	0.02	2
1126	2000	6	32	0.01	2
1126	2000	7	15	0.03	2
1126	2000	7	26	0.06	2
1126	2000	7	28	0.006	2
1126	2000	7	31	0.02	2
1126	2000	8	15	0.01	2
1126	2000	8	26	0.03	2
1126	2000	8	28	0.01	2
1126	2000	8	31	0.01	2
1126	2000	9	15	6.11111111111111E-03	2
1126	2000	9	31	0.008	2
1126	2000	10	15	8.33333333333333E-03	2
1126	2000	10	26	0.01	2
1126	2000	10	31	0.02	2
1126	2000	11	15	0.01	2
1126	2000	11	26	0.04	2
1126	2000	11	28	0.008	2
1126	2000	11	31	0.01	2
1126	2000	11	32	0.0075	2
1126	2000	12	15	0.04	2
1126	2000	12	26	0.08	2
1126	2000	12	28	0.01	2
1126	2000	12	31	0.06	2
1126	2000	12	32	0.01	2
1126	2000	13	15	0.06	2
1126	2000	13	26	0.06	2
1126	2000	13	28	0.01	2
1126	2000	13	31	0.03	2
1126	2000	13	32	0.03	2
1126	2000	14	15	0.06	2
1126	2000	14	26	0.13	2
1126	2000	14	28	0.01	2
1126	2000	14	31	0.09	2
1126	2000	14	32	0.03	2
1126	2000	15	15	0.1	2
1126	2000	15	26	0.13	2
1126	2000	15	28	0.008	2
1126	2000	15	31	0.12	2
1126	2000	15	32	0.03	2
1126	2000	16	15	0.11	2
1126	2000	16	26	0.02	2
1126	2000	16	28	0.008	2
1126	2000	16	31	0.07	2
1126	2000	16	32	0.06	2
1126	2000	17	15	0.12	2
1126	2000	17	26	0.11	2
1126	2000	17	28	0.01	2
1126	2000	17	31	0.03	2
1126	2000	17	32	0.03	2
1126	2000	18	15	0.07	2
1126	2000	18	26	0.05	2
1126	2000	18	28	0.006	2
1126	2000	18	31	0.04	2
1126	2000	18	32	0.01	2
1126	2000	19	15	0.01	2
1126	2000	19	26	0.03	2
1126	2000	19	31	0.04	2
1126	2000	19	32	0.01	2
1126	2000	20	15	0.02	2
1126	2000	20	26	0.02	2
1126	2000	20	28	0.004	2
1126	2000	20	31	0.05	2
1126	2000	20	32	0.0025	2
1126	2000	21	15	0.02	2
1126	2000	21	26	0.07	2
1126	2000	21	28	0.006	2
1126	2000	21	31	0.03	2
1126	2000	21	32	0.02	2
1126	2000	22	15	0.02	2
1126	2000	22	26	0.05	2
1126	2000	22	28	0.006	2
1126	2000	22	31	0.03	2
1126	2000	22	32	0.02	2
1126	2000	23	15	0.02	2
1126	2000	23	26	0.05	2
1126	2000	23	31	0.02	2
1126	2000	23	32	0.01	2
1126	2000	24	15	0.03	2
1126	2000	24	26	0.08	2
1126	2000	24	28	0.01	2
1126	2000	24	31	0.03	2
1126	2000	24	32	0.01	2
1126	2000	25	15	0.04	2
1126	2000	25	26	0.11	2
1126	2000	25	28	0.006	2
1126	2000	25	31	0.09	2
1126	2000	25	32	0.01	2
1126	2000	26	15	0.03	2
1126	2000	26	26	0.12	2
1126	2000	26	28	0.01	2
1126	2000	26	31	0.08	2
1126	2000	26	32	0.02	2
1126	2001	8	15	0.01	2
1126	2001	8	26	0.05	2
1126	2001	8	28	0.01	2
1126	2001	8	31	0.04	2
1126	2001	8	32	0.005	2
1126	2001	9	15	0.01	2
1126	2001	9	31	0.009	2
1126	2001	10	15	0.02	2
1126	2001	10	28	0.004	2
1126	2001	10	31	0.005	2
1126	2001	10	32	0.01	2
1126	2001	11	15	0.01	2
1126	2001	11	28	0.004	2
1126	2001	11	31	0.005	2
1126	2001	11	32	0.01	2
1126	2001	12	15	0.03	2
1126	2001	12	26	0.1	2
1126	2001	12	28	0.01	2
1126	2001	12	31	0.1	2
1126	2001	12	32	0.01	2
1126	2001	13	15	0.02	2
1126	2001	13	26	0.08	2
1126	2001	13	28	0.008	2
1126	2001	13	31	0.07	2
1126	2001	13	32	0.01	2
1126	2001	14	15	0.08	2
1126	2001	14	26	0.09	2
1126	2001	14	28	0.01	2
1126	2001	14	31	0.07	2
1126	2001	14	32	0.02	2
1126	2001	15	15	0.16	2
1126	2001	15	26	0.09	2
1126	2001	15	28	0.002	2
1126	2001	15	31	0.05	2
1126	2001	15	32	0.01	2
1126	2001	16	15	0.12	2
1126	2001	16	26	0.11	2
1126	2001	16	28	0.02	2
1126	2001	16	31	0.06	2
1126	2001	16	32	0.02	2
1126	2001	17	15	0.11	2
1126	2001	17	26	0.09	2
1126	2001	17	28	0.01	2
1126	2001	17	31	0.03	2
1126	2001	17	32	0.02	2
1126	2001	18	15	0.03	2
1126	2001	18	15	0.05	2
1126	2001	18	26	0.01	2
1126	2001	18	26	0.08	2
1126	2001	18	28	0.006	2
1126	2001	18	31	0.03	2
1126	2001	18	31	0.04	2
1126	2001	18	32	0.0025	2
1126	2001	18	32	0.01	2
1126	2001	19	15	0.03	2
1126	2001	19	26	0.01	2
1126	2001	19	28	0.006	2
1126	2001	19	31	0.04	2
1126	2001	19	32	0.0025	2
1126	2001	20	15	0.01	2
1126	2001	20	26	0.04	2
1126	2001	20	28	0.002	2
1126	2001	20	31	0.09	2
1126	2001	20	32	0.01	2
1126	2001	21	15	0.03	2
1126	2001	21	26	0.1	2
1126	2001	21	28	0.02	2
1126	2001	21	31	0.08	2
1126	2001	21	32	0.02	2
1126	2001	22	15	0.03	2
1126	2001	22	26	0.08	2
1126	2001	22	28	0.004	2
1126	2001	22	31	0.05	2
1126	2001	22	32	0.02	2
1126	2001	23	15	0.02	2
1126	2001	23	26	0.05	2
1126	2001	23	31	0.03	2
1126	2001	23	32	0.02	2
1126	2001	24	15	0.07	2
1126	2001	24	26	0.11	2
1126	2001	24	28	0.004	2
1126	2001	24	31	0.05	2
1126	2001	24	32	0.005	2
1126	2001	25	15	0.05	2
1126	2001	25	26	0.08	2
1126	2001	25	28	0.008	2
1126	2001	25	31	0.04	2
1126	2001	25	32	0.0075	2
1126	2001	26	15	0.01	2
1126	2001	26	28	0.004	2
1126	2001	26	31	0.005	2
1126	2001	26	32	0.005	2
1126	2002	1	15	0.01	2
1126	2002	1	26	0.01	2
1126	2002	1	31	0.02	2
1126	2002	1	32	0.005	2
1126	2002	2	15	0.02	2
1126	2002	2	26	0.01	2
1126	2002	2	28	0.002	2
1126	2002	2	31	0.009	2
1126	2002	2	32	0.01	2
1126	2002	3	15	0.02	2
1126	2002	3	26	0.01	2
1126	2002	3	28	0.002	2
1126	2002	3	31	0.009	2
1126	2002	3	32	0.01	2
1126	2002	4	15	0.02	2
1126	2002	4	26	0.06	2
1126	2002	4	28	0.01	2
1126	2002	4	31	0.03	2
1126	2002	4	32	0.0075	2
1126	2002	5	15	0.01	2
1126	2002	5	26	0.04	2
1126	2002	5	28	0.01	2
1126	2002	5	31	0.01	2
1126	2002	5	32	0.005	2
1126	2002	6	15	0.02	2
1126	2002	6	26	0.03	2
1126	2002	6	28	0.01	2
1126	2002	6	31	0.01	2
1126	2002	6	32	0.01	2
1126	2002	7	15	0.04	2
1126	2002	7	26	0.03	2
1126	2002	7	28	0.008	2
1126	2002	7	31	0.06	2
1126	2002	7	32	0.0025	2
1126	2002	8	15	0.03	2
1126	2002	8	26	0.02	2
1126	2002	8	28	0.01	2
1126	2002	8	31	0.03	2
1126	2002	8	32	0.0075	2
1126	2002	9	15	0.01	2
1126	2002	9	26	0.02	2
1126	2002	9	31	0.04	2
1126	2002	10	15	0.01	2
1126	2002	10	26	0.01	2
1126	2002	10	31	0.05	2
1126	2002	10	32	0.02	2
1126	2002	11	15	0.04	2
1126	2002	11	26	0.09	2
1126	2002	11	28	0.006	2
1126	2002	11	31	0.04	2
1126	2002	11	32	0.01	2
1126	2002	12	15	0.06	2
1126	2002	12	26	0.09	2
1126	2002	12	28	0.002	2
1126	2002	12	31	0.05	2
1126	2002	12	32	0.02	2
1126	2002	13	15	0.09	2
1126	2002	13	26	0.05	2
1126	2002	13	28	0.006	2
1126	2002	13	31	0.03	2
1126	2002	13	32	0.01	2
1126	2002	14	15	0.1	2
1126	2002	14	26	0.08	2
1126	2002	14	28	0.008	2
1126	2002	14	31	0.05	2
1126	2002	14	32	0.02	2
1126	2002	15	15	0.11	2
1126	2002	15	26	0.1	2
1126	2002	15	31	0.04	2
1126	2002	15	32	0.02	2
1126	2002	16	15	0.13	2
1126	2002	16	26	0.04	2
1126	2002	16	28	0.01	2
1126	2002	16	31	0.09	2
1126	2002	16	32	0.01	2
1126	2002	17	15	0.21	2
1126	2002	17	26	0.12	2
1126	2002	17	28	0.006	2
1126	2002	17	31	0.13	2
1126	2002	17	32	0.05	2
1126	2002	18	15	0.05	2
1126	2002	18	15	0.11	2
1126	2002	18	26	0.04	2
1126	2002	18	26	0.13	2
1126	2002	18	28	0.002	2
1126	2002	18	28	0.004	2
1126	2002	18	31	0.04	2
1126	2002	18	31	0.07	2
1126	2002	18	32	0.0025	2
1126	2002	18	32	0.02	2
1126	2002	19	15	0.05	2
1126	2002	19	26	0.13	2
1126	2002	19	28	0.004	2
1126	2002	19	31	0.04	2
1126	2002	19	32	0.0025	2
1126	2002	20	15	0.07	2
1126	2002	20	26	0.12	2
1126	2002	20	28	0.01	2
1126	2002	20	31	0.1	2
1126	2002	20	32	0.02	2
1126	2002	21	15	0.06	2
1126	2002	21	26	0.14	2
1126	2002	21	28	0.01	2
1126	2002	21	31	0.09	2
1126	2002	21	32	0.03	2
1126	2002	22	15	0.03	2
1126	2002	22	15	0.04	2
1126	2002	22	26	0.04	2
1126	2002	22	26	0.08	2
1126	2002	22	28	0.004	2
1126	2002	22	28	0.01	2
1126	2002	22	31	0.02	2
1126	2002	22	31	0.04	2
1126	2002	22	32	0.01	2
1126	2002	22	32	0.02	2
1126	2002	23	15	0.04	2
1126	2002	23	26	0.04	2
1126	2002	23	28	0.01	2
1126	2002	23	31	0.02	2
1126	2002	23	32	0.01	2
1126	2002	24	15	0.03	2
1126	2002	24	26	0.05	2
1126	2002	24	28	0.01	2
1126	2002	24	31	0.02	2
1126	2002	24	32	0.03	2
1126	2002	25	15	0.13	2
1126	2002	25	26	0.07	2
1126	2002	25	28	0.01	2
1126	2002	25	31	0.06	2
1126	2002	25	32	0.01	2
1126	2002	26	15	0.06	2
1126	2002	26	26	0.05	2
1126	2002	26	28	0.006	2
1126	2002	26	31	0.05	2
1126	2002	26	32	0.0025	2
1126	2003	1	31	0.01	2
1126	2003	2	15	6.66666666666667E-03	2
1126	2003	2	26	0.008	2
1126	2003	2	32	0.0025	2
1126	2003	3	15	5.55555555555556E-03	2
1126	2003	3	26	0.03	2
1126	2003	3	28	0.006	2
1126	2003	3	31	0.02	2
1126	2003	3	32	0.01	2
1126	2003	4	15	0.02	2
1126	2003	4	26	0.06	2
1126	2003	4	28	0.006	2
1126	2003	4	31	0.02	2
1126	2003	4	32	0.01	2
1126	2003	5	15	0.03	2
1126	2003	5	26	0.01	2
1126	2003	5	31	0.01	2
1126	2003	5	32	0.005	2
1126	2003	6	15	0.01	2
1126	2003	6	26	0.01	2
1126	2003	6	31	0.01	2
1126	2003	6	32	0.005	2
1126	2003	7	15	0.03	2
1126	2003	7	28	0.002	2
1126	2003	7	31	0.009	2
1126	2003	7	32	0.0025	2
1126	2003	8	15	0.02	2
1126	2003	8	31	0.004	2
1126	2003	9	15	0.02	2
1126	2003	9	26	0.01	2
1126	2003	9	31	0.01	2
1126	2003	10	15	0.06	2
1126	2003	10	26	0.06	2
1126	2003	10	28	0.006	2
1126	2003	10	31	0.04	2
1126	2003	10	32	0.02	2
1126	2003	11	15	0.03	2
1126	2003	11	26	0.02	2
1126	2003	11	28	0.006	2
1126	2003	11	31	0.01	2
1126	2003	11	32	0.01	2
1126	2003	12	15	0.25	2
1126	2003	12	26	0.27	2
1126	2003	12	28	0.01	2
1126	2003	12	31	0.11	2
1126	2003	12	32	0.04	2
1126	2003	13	15	0.16	2
1126	2003	13	26	0.23	2
1126	2003	13	28	0.008	2
1126	2003	13	31	0.06	2
1126	2003	13	32	0.01	2
1126	2003	14	15	0.15	2
1126	2003	14	26	0.1	2
1126	2003	14	28	0.008	2
1126	2003	14	31	0.09	2
1126	2003	14	32	0.03	2
1126	2003	15	15	0.26	2
1126	2003	15	26	0.18	2
1126	2003	15	28	0.06	2
1126	2003	15	31	0.21	2
1126	2003	15	32	0.04	2
1126	2003	16	15	0.14	2
1126	2003	16	26	0.07	2
1126	2003	16	28	0.02	2
1126	2003	16	31	0.11	2
1126	2003	16	32	0.01	2
1126	2003	17	15	0.04	2
1126	2003	17	26	0.04	2
1126	2003	17	28	0.002	2
1126	2003	17	31	0.03	2
1126	2003	17	32	0.03	2
1126	2003	18	15	0.05	2
1126	2003	18	26	0.17	2
1126	2003	18	28	0.008	2
1126	2003	18	31	0.05	2
1126	2003	18	32	0.04	2
1126	2003	19	15	0.02	2
1126	2003	19	26	0.12	2
1126	2003	19	28	0.008	2
1126	2003	19	31	0.02	2
1126	2003	19	32	0.03	2
1126	2003	20	15	0.02	2
1126	2003	20	26	0.03	2
1126	2003	20	28	0.002	2
1126	2003	20	31	0.03	2
1126	2003	20	32	0.01	2
1126	2003	21	15	0.04	2
1126	2003	21	26	0.04	2
1126	2003	21	28	0.008	2
1126	2003	21	31	0.01	2
1126	2003	22	15	0.09	2
1126	2003	22	26	0.11	2
1126	2003	22	28	0.01	2
1126	2003	22	31	0.09	2
1126	2003	22	32	0.01	2
1126	2003	23	15	0.13	2
1126	2003	23	26	0.17	2
1126	2003	23	28	0.03	2
1126	2003	23	31	0.08	2
1126	2003	23	32	0.04	2
1126	2003	24	15	0.15	2
1126	2003	24	26	0.09	2
1126	2003	24	28	0.01	2
1126	2003	24	31	0.03	2
1126	2003	24	32	0.02	2
1126	2003	25	15	0.15	2
1126	2003	25	26	0.22	2
1126	2003	25	28	0.02	2
1126	2003	25	31	0.07	2
1126	2003	25	32	0.03	2
1126	2003	26	15	0.03	2
1126	2003	26	26	0.11	2
1126	2003	26	28	0.008	2
1126	2003	26	31	0.02	2
1126	2003	26	32	0.01	2
1126	2004	1	26	0.01	2
1126	2004	1	31	0.004	2
1126	2004	1	32	0.005	2
1126	2004	2	15	5.83333333333333E-03	2
1126	2004	2	26	0.03	2
1126	2004	2	31	0.004	2
1126	2004	2	32	0.005	2
1126	2004	3	15	6.11111111111111E-03	2
1126	2004	3	26	0.008	2
1126	2004	3	31	0.01	2
1126	2004	4	15	0.02	2
1126	2004	4	26	0.03	2
1126	2004	4	31	0.02	2
1126	2004	4	32	0.0025	2
1126	2004	5	15	0.01	2
1126	2004	5	26	0.08	2
1126	2004	5	28	0.01	2
1126	2004	5	31	0.03	2
1126	2004	5	32	0.01	2
1126	2004	6	15	0.03	2
1126	2004	6	26	0.02	2
1126	2004	6	28	0.01	2
1126	2004	6	31	0.05	2
1126	2004	6	32	0.01	2
1126	2004	7	15	0.04	2
1126	2004	7	26	0.04	2
1126	2004	7	28	0.008	2
1126	2004	7	31	0.07	2
1126	2004	7	32	0.01	2
1126	2004	8	15	0.02	2
1126	2004	8	26	0.02	2
1126	2004	8	28	0.002	2
1126	2004	8	31	0.03	2
1126	2004	8	32	0.01	2
1126	2004	9	15	0.02	2
1126	2004	9	26	0.03	2
1126	2004	9	28	0.002	2
1126	2004	9	31	0.02	2
1126	2004	10	15	0.06	2
1126	2004	10	26	0.04	2
1126	2004	10	28	0.002	2
1126	2004	10	31	0.02	2
1126	2004	10	32	0.01	2
1126	2004	11	15	0.07	2
1126	2004	11	26	0.01	2
1126	2004	11	28	0.006	2
1126	2004	11	31	0.02	2
1126	2004	11	32	0.02	2
1126	2004	12	15	0.02	2
1126	2004	12	26	0.06	2
1126	2004	12	28	0.004	2
1126	2004	12	31	0.01	2
1126	2004	12	32	0.01	2
1126	2004	13	15	0.07	2
1126	2004	13	26	0.06	2
1126	2004	13	28	0.01	2
1126	2004	13	31	0.07	2
1126	2004	13	32	0.01	2
1126	2004	14	15	0.12	2
1126	2004	14	26	0.17	2
1126	2004	14	28	0.01	2
1126	2004	14	31	0.07	2
1126	2004	14	32	0.03	2
1126	2004	15	15	0.19	2
1126	2004	15	26	0.07	2
1126	2004	15	28	0.008	2
1126	2004	15	31	0.06	2
1126	2004	15	32	0.04	2
1126	2004	16	15	0.15	2
1126	2004	16	26	0.05	2
1126	2004	16	31	0.06	2
1126	2004	16	32	0.01	2
1126	2004	17	15	0.06	2
1126	2004	17	26	0.07	2
1126	2004	17	31	0.04	2
1126	2004	17	32	0.0075	2
1126	2004	18	15	0.08	2
1126	2004	18	26	0.01	2
1126	2004	18	31	0.02	2
1126	2004	18	32	0.01	2
1126	2004	19	15	0.06	2
1126	2004	19	26	0.1	2
1126	2004	19	28	0.01	2
1126	2004	19	31	0.09	2
1126	2004	19	32	0.02	2
1126	2004	20	15	0.05	2
1126	2004	20	26	0.09	2
1126	2004	20	28	0.02	2
1126	2004	20	31	0.04	2
1126	2004	20	32	0.02	2
1126	2004	21	15	0.04	2
1126	2004	21	26	0.02	2
1126	2004	21	28	0.01	2
1126	2004	21	31	0.04	2
1126	2004	21	32	0.01	2
1126	2004	22	15	0.01	2
1126	2004	22	26	0.04	2
1126	2004	22	31	0.04	2
1126	2004	22	32	0.01	2
1126	2004	23	15	0.06	2
1126	2004	23	26	0.09	2
1126	2004	23	28	0.02	2
1126	2004	23	31	0.08	2
1126	2004	23	32	0.04	2
1126	2004	24	15	0.04	2
1126	2004	24	26	0.12	2
1126	2004	24	28	0.01	2
1126	2004	24	31	0.08	2
1126	2004	24	32	0.03	2
1126	2004	26	15	0.03	2
1126	2004	26	26	0.04	2
1126	2004	26	28	0.008	2
1126	2004	26	31	0.01	2
1126	2004	26	32	0.02	2
1126	2005	1	15	0.01	2
1126	2005	1	26	0.03	2
1126	2005	1	28	0.004	2
1126	2005	1	31	0.01	2
1126	2005	1	32	0.005	2
1126	2005	2	15	0.0025	2
1126	2005	3	15	3.61111111111111E-03	2
1126	2005	3	26	0.01	2
1126	2005	3	28	0.004	2
1126	2005	3	31	0.009	2
1126	2005	3	32	0.0025	2
1126	2005	4	15	0.03	2
1126	2005	4	26	0.02	2
1126	2005	4	28	0.01	2
1126	2005	4	31	0.03	2
1126	2005	4	32	0.005	2
1126	2005	5	15	0.02	2
1126	2005	5	26	0.01	2
1126	2005	5	28	0.01	2
1126	2005	5	31	0.02	2
1126	2005	5	32	0.0025	2
1126	2005	6	15	0.01	2
1126	2005	6	26	0.1	2
1126	2005	6	28	0.006	2
1126	2005	6	31	0.01	2
1126	2005	7	15	0.03	2
1126	2005	7	26	0.07	2
1126	2005	7	28	0.004	2
1126	2005	7	31	0.05	2
1126	2005	7	32	0.0075	2
1126	2005	8	15	0.01	2
1126	2005	8	26	0.01	2
1126	2005	8	31	0.03	2
1126	2005	8	32	0.0025	2
1126	2005	9	15	0.0025	2
1126	2005	9	31	0.02	2
1126	2005	10	15	0.02	2
1126	2005	10	28	0.004	2
1126	2005	10	31	0.03	2
1126	2005	10	32	0.0075	2
1126	2005	12	15	0.01	2
1126	2005	12	26	0.03	2
1126	2005	12	28	0.004	2
1126	2005	12	31	0.02	2
1126	2005	12	32	0.01	2
1126	2005	13	15	0.18	2
1126	2005	13	26	0.08	2
1126	2005	13	28	0.01	2
1126	2005	13	31	0.09	2
1126	2005	13	32	0.05	2
1126	2005	14	15	0.25	2
1126	2005	14	26	0.09	2
1126	2005	14	28	0.01	2
1126	2005	14	31	0.08	2
1126	2005	14	32	0.1	2
1126	2005	15	15	0.16	2
1126	2005	15	26	0.06	2
1126	2005	15	28	0.01	2
1126	2005	15	31	0.04	2
1126	2005	15	32	0.07	2
1126	2005	16	15	0.27	2
1126	2005	16	26	0.1	2
1126	2005	16	28	0.02	2
1126	2005	16	31	0.1	2
1126	2005	16	32	0.05	2
1126	2005	17	15	0.14	2
1126	2005	17	26	0.05	2
1126	2005	17	28	0.01	2
1126	2005	17	31	0.04	2
1126	2005	17	32	0.02	2
1126	2005	18	15	0.05	2
1126	2005	18	15	0.1	2
1126	2005	18	26	0.05	2
1126	2005	18	26	0.15	2
1126	2005	18	28	0.006	2
1126	2005	18	28	0.01	2
1126	2005	18	31	0.08	2
1126	2005	18	31	0.15	2
1126	2005	18	32	0.01	2
1126	2005	19	15	0.05	2
1126	2005	19	26	0.09	2
1126	2005	19	28	0.01	2
1126	2005	19	31	0.07	2
1126	2005	19	32	0.0025	2
1126	2005	20	15	0.08	2
1126	2005	20	26	0.1	2
1126	2005	20	28	0.01	2
1126	2005	20	31	0.09	2
1126	2005	20	32	0.005	2
1126	2005	21	15	0.04	2
1126	2005	21	26	0.05	2
1126	2005	21	28	0.008	2
1126	2005	21	31	0.03	2
1126	2005	21	32	0.0025	2
1126	2005	22	15	0.02	2
1126	2005	22	15	0.04	2
1126	2005	22	26	0.06	2
1126	2005	22	26	0.09	2
1126	2005	22	28	0.002	2
1126	2005	22	28	0.004	2
1126	2005	22	31	0.03	2
1126	2005	22	31	0.04	2
1126	2005	22	32	0.01	2
1126	2005	23	15	0.04	2
1126	2005	23	26	0.06	2
1126	2005	23	28	0.004	2
1126	2005	23	31	0.04	2
1126	2005	23	32	0.01	2
1126	2005	24	15	0.07	2
1126	2005	24	26	0.1	2
1126	2005	24	28	0.02	2
1126	2005	24	31	0.09	2
1126	2005	24	32	0.03	2
1126	2005	25	15	0.03	2
1126	2005	25	26	0.01	2
1126	2005	25	28	0.02	2
1126	2005	25	31	0.04	2
1126	2005	25	32	0.02	2
1126	2006	2	15	4.72222222222222E-03	2
1126	2006	2	31	0.005	2
1126	2006	3	15	0.01	2
1126	2006	3	26	0.01	2
1126	2006	3	31	0.005	2
1126	2006	3	32	0.0075	2
1126	2006	4	15	0.02	2
1126	2006	4	26	0.03	2
1126	2006	4	28	0.004	2
1126	2006	4	31	0.03	2
1126	2006	4	32	0.01	2
1126	2006	5	15	7.22222222222222E-03	2
1126	2006	5	15	0.03	2
1126	2006	5	26	0.008	2
1126	2006	5	26	0.01	2
1126	2006	5	28	0.002	2
1126	2006	5	28	0.006	2
1126	2006	5	31	0.03	2
1126	2006	5	32	0.005	2
1126	2006	6	15	0.03	2
1126	2006	6	26	0.008	2
1126	2006	6	28	0.006	2
1126	2006	7	15	0.02	2
1126	2006	7	28	0.004	2
1126	2006	7	31	0.005	2
1126	2006	8	15	9.72222222222222E-03	2
1126	2006	8	31	0.03	2
1126	2006	8	32	0.005	2
1126	2006	9	15	0.01	2
1126	2006	9	26	0.01	2
1126	2006	9	26	0.02	2
1126	2006	9	28	0.002	2
1126	2006	9	31	0.004	2
1126	2006	9	31	0.009	2
1126	2006	9	32	0.0025	2
1126	2006	9	32	0.0075	2
1126	2006	10	15	0.01	2
1126	2006	10	26	0.01	2
1126	2006	10	28	0.002	2
1126	2006	10	31	0.004	2
1126	2006	10	32	0.0025	2
1126	2006	11	15	0.07	2
1126	2006	11	26	0.09	2
1126	2006	11	28	0.01	2
1126	2006	11	31	0.1	2
1126	2006	11	32	0.01	2
1126	2006	12	15	0.04	2
1126	2006	12	26	0.05	2
1126	2006	12	28	0.01	2
1126	2006	12	31	0.05	2
1126	2006	12	32	0.01	2
1126	2006	13	15	0.04	2
1126	2006	13	26	0.08	2
1126	2006	13	28	0.008	2
1126	2006	13	31	0.03	2
1126	2006	13	32	0.03	2
1126	2006	14	15	0.12	2
1126	2006	14	26	0.09	2
1126	2006	14	28	0.01	2
1126	2006	14	31	0.04	2
1126	2006	14	32	0.01	2
1126	2006	15	15	0.09	2
1126	2006	15	26	0.04	2
1126	2006	15	28	0.008	2
1126	2006	15	31	0.02	2
1126	2006	15	32	0.02	2
1126	2006	16	15	0.13	2
1126	2006	16	26	0.06	2
1126	2006	16	28	0.01	2
1126	2006	16	31	0.08	2
1126	2006	16	32	0.05	2
1126	2006	17	15	0.08	2
1126	2006	17	26	0.06	2
1126	2006	17	28	0.008	2
1126	2006	17	31	0.08	2
1126	2006	17	32	0.04	2
1126	2006	18	15	0.03	2
1126	2006	18	26	0.04	2
1126	2006	18	28	0.004	2
1126	2006	18	31	0.03	2
1126	2006	18	32	0.02	2
1126	2006	19	15	0.03	2
1126	2006	19	26	0.04	2
1126	2006	19	28	0.002	2
1126	2006	19	31	0.07	2
1126	2006	19	32	0.01	2
1126	2006	20	15	9.16666666666667E-03	2
1126	2006	20	26	0.01	2
1126	2006	20	31	0.04	2
1126	2006	20	32	0.005	2
1126	2006	21	15	0.02	2
1126	2006	21	26	0.03	2
1126	2006	21	28	0.004	2
1126	2006	21	31	0.02	2
1126	2006	21	32	0.0025	2
1126	2006	23	15	0.09	2
1126	2006	23	26	0.21	2
1126	2006	23	28	0.03	2
1126	2006	23	31	0.14	2
1126	2006	23	32	0.04	2
1126	2006	24	15	0.09	2
1126	2006	24	26	0.17	2
1126	2006	24	28	0.02	2
1126	2006	24	31	0.1	2
1126	2006	24	32	0.04	2
1126	2006	25	15	0.1	2
1126	2006	25	26	0.15	2
1126	2006	25	28	0.03	2
1126	2006	25	31	0.04	2
1126	2006	25	32	0.03	2
1126	2006	26	15	0.05	2
1126	2006	26	26	0.05	2
1126	2006	26	28	0.02	2
1126	2006	26	31	0.01	2
1126	2006	26	32	0.02	2
1126	2007	1	15	6.94444444444444E-03	2
1126	2007	1	26	0.07	2
1126	2007	1	28	0.004	2
1126	2007	1	31	0.009	2
1126	2007	2	15	0.01	2
1126	2007	2	26	0.02	2
1126	2007	2	28	0.002	2
1126	2007	2	31	0.02	2
1126	2007	2	32	0.01	2
1126	2007	3	15	9.72222222222222E-03	2
1126	2007	3	26	0.01	2
1126	2007	3	31	0.02	2
1126	2007	3	32	0.01	2
1126	2007	4	15	0.01	2
1126	2007	4	28	0.006	2
1126	2007	4	31	0.04	2
1126	2007	5	15	0.01	2
1126	2007	5	26	0.03	2
1126	2007	5	28	0.006	2
1126	2007	5	31	0.01	2
1126	2007	5	32	0.005	2
1126	2007	6	15	0.0025	2
1126	2007	7	15	0.0025	2
1126	2007	7	26	6.66666666666667E-03	2
1126	2007	7	28	0.002	2
1126	2007	7	32	0.005	2
1126	2007	8	15	2.22222222222222E-03	2
1126	2007	8	26	0.02	2
1126	2007	8	32	0.0075	2
1126	2007	9	15	9.44444444444444E-03	2
1126	2007	9	28	0.002	2
1126	2007	9	31	0.004	2
1126	2007	10	15	0.03	2
1126	2007	10	26	0.04	2
1126	2007	10	28	0.002	2
1126	2007	10	31	0.04	2
1126	2007	10	32	0.005	2
1126	2007	11	15	0.02	2
1126	2007	11	26	0.03	2
1126	2007	11	28	0.002	2
1126	2007	11	31	0.02	2
1126	2007	11	32	0.0025	2
1126	2007	12	15	0.03	2
1126	2007	12	26	0.008	2
1126	2007	12	31	0.01	2
1126	2007	12	32	0.01	2
1126	2007	13	15	0.04	2
1126	2007	13	26	0.04	2
1126	2007	13	31	0.02	2
1126	2007	13	32	0.01	2
1126	2007	15	15	0.06	2
1126	2007	15	26	0.02	2
1126	2007	15	28	0.02	2
1126	2007	15	31	0.04	2
1126	2007	15	32	0.0025	2
1126	2007	16	15	0.05	2
1126	2007	16	26	0.04	2
1126	2007	16	31	0.01	2
1126	2007	16	32	0.005	2
1126	2007	17	15	0.02	2
1126	2007	17	26	0.05	2
1126	2007	17	28	0.002	2
1126	2007	17	31	0.01	2
1126	2007	17	32	0.0025	2
1126	2007	18	15	0.04	2
1126	2007	18	26	0.02	2
1126	2007	18	28	0.002	2
1126	2007	18	28	0.004	2
1126	2007	18	31	0.01	2
1126	2007	18	31	0.03	2
1126	2007	18	32	0.0025	2
1126	2007	18	32	0.01	2
1126	2007	19	15	0.04	2
1126	2007	19	26	0.02	2
1126	2007	19	28	0.004	2
1126	2007	19	31	0.03	2
1126	2007	19	32	0.01	2
1126	2007	20	15	0.01	2
1126	2007	20	26	0.008	2
1126	2007	20	28	0.008	2
1126	2007	20	31	0.03	2
1126	2007	21	15	5.83333333333333E-03	2
1126	2007	21	26	0.04	2
1126	2007	21	28	0.006	2
1126	2007	21	31	0.03	2
1126	2007	21	32	0.005	2
1126	2007	22	15	9.44444444444444E-03	2
1126	2007	22	26	0.04	2
1126	2007	22	31	0.01	2
1126	2007	22	32	0.005	2
1126	2007	23	15	0.02	2
1126	2007	23	26	0.05	2
1126	2007	23	28	0.008	2
1126	2007	23	31	0.04	2
1126	2007	23	32	0.005	2
1126	2007	24	15	0.03	2
1126	2007	24	26	0.11	2
1126	2007	24	28	0.01	2
1126	2007	24	31	0.04	2
1126	2007	24	32	0.0075	2
1301	2001	8	17	0.01	0
1301	2001	8	18	0.0025	0
1301	2001	8	26	0.07	0
1301	2001	9	17	0.005	0
1301	2001	9	18	0.0025	0
1301	2001	9	26	0.06	0
1301	2001	9	31	0.03	0
1301	2001	11	17	0.008	0
1301	2001	11	18	0.0025	0
1301	2001	11	26	0.03	0
1301	2001	11	31	0.03	0
1301	2001	12	17	0.14	0
1301	2001	12	18	0.01	0
1301	2001	12	22	0.2	0
1301	2001	12	26	0.61	0
1301	2001	12	31	0.03	0
1301	2001	13	17	0.69	0
1301	2001	13	18	0.01	0
1301	2001	13	22	0.15	0
1301	2001	13	26	1.8	0
1301	2001	13	31	0.1	0
1301	2001	14	17	0.59	0
1301	2001	14	26	1.45	0
1301	2001	14	31	0.1	0
1301	2001	15	17	0.68	0
1301	2001	15	18	0.15	0
1301	2001	15	22	0.4	0
1301	2001	15	26	4.33	0
1301	2001	15	31	0.96	0
1301	2001	16	17	0.34	0
1301	2001	16	18	0.1	0
1301	2001	16	22	0.4	0
1301	2001	16	26	2.83	0
1301	2001	16	31	0.63	0
1301	2001	17	17	0.12	0
1301	2001	17	18	0.07	0
1301	2001	17	26	0.9	0
1301	2001	17	31	0.23	0
1301	2001	18	17	0.07	0
1301	2001	18	17	0.12	0
1301	2001	18	18	0.07	0
1301	2001	18	18	0.13	0
1301	2001	18	22	0.1	0
1301	2001	18	26	0.83	0
1301	2001	18	26	0.9	0
1301	2001	18	31	0.23	0
1301	2001	18	31	0.3	0
1301	2001	19	17	0.07	0
1301	2001	19	18	0.13	0
1301	2001	19	22	0.1	0
1301	2001	19	26	0.83	0
1301	2001	19	31	0.3	0
1301	2001	20	18	0.01	0
1301	2001	20	26	0.12	0
1301	2001	20	31	0.06	0
1301	2001	21	17	0.01	0
1301	2001	21	18	0.0025	0
1301	2001	21	26	0.14	0
1301	2001	21	31	0.13	0
1301	2001	22	17	0.01	0
1301	2001	22	18	0.0025	0
1301	2001	22	26	0.14	0
1301	2001	22	31	0.13	0
1301	2002	1	17	0.01	0
1301	2002	1	18	0.0025	0
1301	2002	1	26	0.04	0
1301	2002	6	17	0.02	0
1301	2002	6	18	0.01	0
1301	2002	6	26	0.16	0
1301	2002	7	17	0.02	0
1301	2002	7	18	0.02	0
1301	2002	7	22	0.2	0
1301	2002	7	26	0.14	0
1301	2002	9	17	0.01	0
1301	2002	9	18	0.0075	0
1301	2002	9	22	0.1	0
1301	2002	9	26	0.1	0
1301	2002	9	31	0.1	0
1301	2002	11	17	0.02	0
1301	2002	11	26	0.11	0
1301	2002	12	17	0.33	0
1301	2002	12	18	0.06	0
1301	2002	12	22	0.1	0
1301	2002	12	26	1.01	0
1301	2002	12	31	0.13	0
1301	2002	13	17	0.54	0
1301	2002	13	18	0.14	0
1301	2002	13	22	0.7	0
1301	2002	13	26	2.24	0
1301	2002	13	31	0.4	0
1301	2002	15	17	0.3	0
1301	2002	15	18	0.09	0
1301	2002	15	22	0.3	0
1301	2002	15	26	1.06	0
1301	2002	15	31	0.43	0
1301	2002	16	17	0.27	0
1301	2002	16	18	0.17	0
1301	2002	16	22	0.6	0
1301	2002	16	26	1.91	0
1301	2002	16	31	0.46	0
1301	2002	17	17	0.15	0
1301	2002	17	18	0.27	0
1301	2002	17	22	0.6	0
1301	2002	17	26	1.85	0
1301	2002	17	31	0.56	0
1301	2002	20	17	0.03	0
1301	2002	20	18	0.06	0
1301	2002	20	22	0.25	0
1301	2002	20	26	0.25	0
1301	2002	20	31	0.06	0
1301	2002	22	17	0.004	0
1301	2002	22	18	0.005	0
1301	2002	22	26	0.12	0
1301	2002	25	17	0.009	0
1301	2002	25	18	0.0075	0
1301	2002	25	26	0.01	0
1301	2002	26	18	0.005	0
1301	2002	26	26	0.02	0
1301	2003	9	18	0.0075	0
1301	2003	9	26	0.06	0
1301	2003	12	17	0.47	0
1301	2003	12	18	0.1	0
1301	2003	12	22	0.45	0
1301	2003	12	26	0.96	0
1301	2003	12	31	0.06	0
1301	2003	13	17	0.39	0
1301	2003	13	18	0.58	0
1301	2003	13	22	3.3	0
1301	2003	13	26	2.78	0
1301	2003	13	31	0.4	0
1301	2003	14	17	0.64	0
1301	2003	14	18	0.42	0
1301	2003	14	22	1.55	0
1301	2003	14	26	2.92	0
1301	2003	14	31	0.46	0
1301	2003	15	17	0.54	0
1301	2003	15	18	0.59	0
1301	2003	15	22	1.25	0
1301	2003	15	26	2.52	0
1301	2003	15	31	0.46	0
1301	2003	16	17	0.07	0
1301	2003	16	18	0.28	0
1301	2003	16	26	0.59	0
1301	2003	18	17	0.11	0
1301	2003	18	18	0.08	0
1301	2003	18	22	1.2	0
1301	2003	18	26	0.5	0
1301	2003	18	31	0.03	0
1301	2003	19	17	0.07	0
1301	2003	19	18	0.01	0
1301	2003	19	22	0.6	0
1301	2003	19	26	0.39	0
1301	2003	19	31	0.13	0
1301	2003	21	17	0.02	0
1301	2003	21	18	0.005	0
1301	2003	21	22	0.25	0
1301	2003	21	26	0.21	0
1301	2003	21	31	0.06	0
1301	2003	22	17	0.03	0
1301	2003	22	18	0.02	0
1301	2003	22	22	0.05	0
1301	2003	22	26	0.2	0
1301	2003	22	31	0.06	0
1301	2004	4	17	0.02	0
1301	2004	4	18	0.01	0
1301	2004	4	26	0.02	0
1301	2004	6	17	0.005	0
1301	2004	6	18	0.01	0
1301	2004	6	26	0.06	0
1301	2004	7	18	0.0075	0
1301	2004	7	22	0.05	0
1301	2004	7	26	0.08	0
1301	2004	8	17	0.009	0
1301	2004	8	18	0.0075	0
1301	2004	8	26	0.07	0
1301	2004	9	17	0.02	0
1301	2004	9	18	0.0025	0
1301	2004	9	26	0.11	0
1301	2004	10	17	0.02	0
1301	2004	10	18	0.0025	0
1301	2004	10	26	0.11	0
1301	2004	11	17	0.18	0
1301	2004	11	18	0.05	0
1301	2004	11	26	0.39	0
1301	2004	11	31	0.03	0
1301	2004	13	17	0.43	0
1301	2004	13	18	0.17	0
1301	2004	13	22	0.05	0
1301	2004	13	26	1.57	0
1301	2004	13	31	0.46	0
1301	2004	14	17	0.55	0
1301	2004	14	18	0.3	0
1301	2004	14	22	0.2	0
1301	2004	14	26	2.34	0
1301	2004	14	31	0.23	0
1301	2004	15	17	0.52	0
1301	2004	15	18	0.17	0
1301	2004	15	22	0.1	0
1301	2004	15	26	1.21	0
1301	2004	15	31	0.23	0
1301	2004	16	17	0.76	0
1301	2004	16	18	0.38	0
1301	2004	16	22	0.8	0
1301	2004	16	26	2.05	0
1301	2004	16	31	0.26	0
1301	2004	17	17	0.27	0
1301	2004	17	18	0.37	0
1301	2004	17	22	0.3	0
1301	2004	17	26	1.39	0
1301	2004	17	31	0.43	0
1301	2004	18	17	0.12	0
1301	2004	18	18	0.21	0
1301	2004	18	22	0.2	0
1301	2004	18	26	1.16	0
1301	2004	18	31	0.26	0
1301	2004	19	17	0.18	0
1301	2004	19	18	0.12	0
1301	2004	19	22	1.15	0
1301	2004	19	26	0.64	0
1301	2004	19	31	0.3	0
1301	2004	20	17	0.03	0
1301	2004	20	18	0.01	0
1301	2004	20	26	0.71	0
1301	2004	20	31	0.23	0
1301	2004	22	17	0.01	0
1301	2004	22	18	0.0075	0
1301	2004	22	22	0.05	0
1301	2004	22	26	0.16	0
1301	2004	22	31	0.03	0
1301	2004	23	18	0.01	0
1301	2004	23	26	0.1	0
1301	2004	23	31	0.03	0
1301	2004	24	18	0.0075	0
1301	2004	24	26	0.04	0
1301	2004	24	31	0.1	0
1301	2005	3	26	0.03	0
1301	2005	4	17	0.03	0
1301	2005	4	18	0.03	0
1301	2005	4	26	0.17	0
1301	2005	4	31	0.03	0
1301	2005	5	17	0.01	0
1301	2005	5	18	0.0075	0
1301	2005	5	26	0.12	0
1301	2005	6	17	0.02	0
1301	2005	6	18	0.01	0
1301	2005	6	22	0.1	0
1301	2005	6	26	0.14	0
1301	2005	6	31	0.1	0
1301	2005	8	17	0.03	0
1301	2005	8	18	0.0075	0
1301	2005	8	26	0.08	0
1301	2005	9	17	0.01	0
1301	2005	9	18	0.01	0
1301	2005	9	26	0.11	0
1301	2005	11	17	0.009	0
1301	2005	11	18	0.02	0
1301	2005	11	26	0.08	0
1301	2005	12	17	0.05	0
1301	2005	12	18	0.005	0
1301	2005	12	22	0.15	0
1301	2005	12	26	0.26	0
1301	2005	12	31	0.1	0
1301	2005	14	17	0.7	0
1301	2005	14	18	0.32	0
1301	2005	14	22	0.9	0
1301	2005	14	26	3.38	0
1301	2005	14	31	0.46	0
1301	2005	15	17	0.28	0
1301	2005	15	18	0.33	0
1301	2005	15	22	0.6	0
1301	2005	15	26	0.79	0
1301	2005	15	31	0.56	0
1301	2005	16	17	0.62	0
1301	2005	16	18	0.74	0
1301	2005	16	22	0.5	0
1301	2005	16	26	2.51	0
1301	2005	16	31	0.33	0
1301	2005	18	17	0.09	0
1301	2005	18	18	0.16	0
1301	2005	18	22	0.05	0
1301	2005	18	26	0.65	0
1301	2005	18	31	0.23	0
1301	2005	19	17	0.04	0
1301	2005	19	18	0.18	0
1301	2005	19	26	0.82	0
1301	2005	19	31	0.16	0
1301	2005	21	17	0.02	0
1301	2005	21	18	0.01	0
1301	2005	21	22	0.05	0
1301	2005	21	26	0.26	0
1301	2005	22	17	0.008	0
1301	2005	22	18	0.01	0
1301	2005	22	26	0.12	0
1301	2005	22	31	0.03	0
1301	2005	25	18	0.0075	0
1301	2005	25	26	0.04	0
1301	2006	3	17	0.01	0
1301	2006	3	18	0.01	0
1301	2006	3	26	0.09	0
1301	2006	4	17	0.01	0
1301	2006	4	18	0.01	0
1301	2006	4	26	0.09	0
1301	2006	5	17	0.01	0
1301	2006	5	26	0.04	0
1301	2006	5	31	0.03	0
1301	2006	8	17	0.005	0
1301	2006	8	18	0.005	0
1301	2006	8	26	0.03	0
1301	2006	9	18	0.005	0
1301	2006	9	26	0.02	0
1301	2006	10	17	0.02	0
1301	2006	10	18	0.005	0
1301	2006	10	26	0.05	0
1301	2006	11	17	0.01	0
1301	2006	11	18	0.0025	0
1301	2006	11	26	0.02	0
1301	2006	12	17	0.17	0
1301	2006	12	18	0.02	0
1301	2006	12	22	0.05	0
1301	2006	12	26	0.38	0
1301	2006	12	31	0.03	0
1301	2006	13	17	0.32	0
1301	2006	13	18	0.09	0
1301	2006	13	26	1.43	0
1301	2006	14	17	0.85	0
1301	2006	14	18	0.32	0
1301	2006	14	22	0.2	0
1301	2006	14	26	3.89	0
1301	2006	14	31	0.36	0
1301	2006	15	17	0.68	0
1301	2006	15	18	0.18	0
1301	2006	15	22	0.2	0
1301	2006	15	26	2.81	0
1301	2006	15	31	0.23	0
1301	2006	16	17	0.32	0
1301	2006	16	18	0.14	0
1301	2006	16	22	0.6	0
1301	2006	16	26	1.66	0
1301	2006	16	31	0.33	0
1301	2006	17	17	0.08	0
1301	2006	17	18	0.17	0
1301	2006	17	22	0.1	0
1301	2006	17	26	1.41	0
1301	2006	17	31	0.1	0
1301	2006	18	17	0.03	0
1301	2006	18	18	0.08	0
1301	2006	18	26	0.4	0
1301	2006	18	31	0.23	0
1301	2006	21	18	0.0025	0
1301	2006	21	26	0.06	0
1301	2006	22	17	0.005	0
1301	2006	22	18	0.0075	0
1301	2006	22	26	0.04	0
1301	2006	22	31	0.03	0
1301	2006	24	18	0.005	0
1301	2006	24	26	0.04	0
1301	2006	24	31	0.03	0
1301	2006	25	17	0.009	0
1301	2006	25	18	0.0075	0
1301	2006	25	26	0.01	0
1301	2006	25	31	0.06	0
1301	2006	26	17	0.009	0
1301	2006	26	18	0.0075	0
1301	2006	26	26	0.01	0
1301	2006	26	31	0.06	0
1301	2007	1	17	0.005	0
1301	2007	1	18	0.0075	0
1301	2007	1	26	0.08	0
1301	2007	2	17	0.01	0
1301	2007	2	18	0.02	0
1301	2007	2	26	0.07	0
1301	2007	5	17	0.01	0
1301	2007	5	18	0.01	0
1301	2007	5	26	0.12	0
1301	2007	6	17	0.01	0
1301	2007	6	18	0.01	0
1301	2007	6	26	0.12	0
1301	2007	8	17	0.01	0
1301	2007	8	18	0.0075	0
1301	2007	8	22	0.1	0
1301	2007	8	26	0.02	0
1301	2007	9	26	0.02	0
1301	2007	10	17	0.04	0
1301	2007	10	18	0.01	0
1301	2007	10	22	0.05	0
1301	2007	10	26	0.21	0
1301	2007	10	31	0.03	0
1301	2007	11	17	0.02	0
1301	2007	11	18	0.0075	0
1301	2007	11	26	0.18	0
1301	2007	11	31	0.03	0
1301	2007	12	17	0.09	0
1301	2007	12	18	0.01	0
1301	2007	12	22	0.05	0
1301	2007	12	26	0.56	0
1301	2007	15	17	0.22	0
1301	2007	15	18	0.05	0
1301	2007	15	22	0.05	0
1301	2007	15	26	1.24	0
1301	2007	15	31	0.03	0
1301	2007	16	17	0.34	0
1301	2007	16	18	0.07	0
1301	2007	16	22	0.3	0
1301	2007	16	26	1.93	0
1301	2007	16	31	0.13	0
1301	2007	17	17	0.09	0
1301	2007	17	18	0.11	0
1301	2007	17	22	0.4	0
1301	2007	17	26	1.53	0
1301	2007	17	31	0.06	0
1301	2007	18	17	0.06	0
1301	2007	18	18	0.05	0
1301	2007	18	22	0.15	0
1301	2007	18	26	0.82	0
1301	2007	18	31	0.06	0
1301	2007	19	17	0.02	0
1301	2007	19	18	0.03	0
1301	2007	19	22	0.1	0
1301	2007	19	26	0.23	0
1301	2007	20	17	0.02	0
1301	2007	20	18	0.02	0
1301	2007	20	26	0.12	0
1301	2007	21	17	0.004	0
1301	2007	21	18	0.005	0
1301	2007	21	26	0.12	0
1301	2007	21	31	0.06	0
1301	2007	22	17	0.004	0
1301	2007	22	17	0.009	0
1301	2007	22	18	0.01	0
1301	2007	22	26	0.08	0
1301	2007	22	26	0.1	0
1301	2007	22	31	0.03	0
1301	2007	23	17	0.004	0
1301	2007	23	18	0.01	0
1301	2007	23	26	0.1	0
1301	2007	23	31	0.03	0
1301	2007	24	17	0.009	0
1301	2007	24	18	0.0025	0
1301	2007	24	26	0.02	0
1301	2007	24	31	0.03	0
1301	2007	25	17	0.004	0
1301	2007	25	18	0.005	0
1301	2007	25	26	0.03	0
1301	2007	25	31	0.03	0
1311	2000	2	31	0.0075	0
1311	2000	2	32	0.02	0
1311	2000	4	31	0.0025	0
1311	2000	4	32	0.06	0
1311	2000	5	26	6.66666666666667E-03	0
1311	2000	5	31	0.01	0
1311	2000	5	32	0.09	0
1311	2000	6	31	0.005	0
1311	2000	6	32	0.1	0
1311	2000	7	31	0.02	0
1311	2000	7	32	0.11	0
1311	2000	9	32	0.04	0
1311	2000	10	31	0.0025	0
1311	2000	10	32	0.01	0
1311	2000	11	32	0.01	0
1311	2000	12	26	6.66666666666667E-03	0
1311	2000	12	31	0.0025	0
1311	2000	12	32	8.33333333333333E-03	0
1311	2000	13	31	0.01	0
1311	2000	13	32	0.03	0
1311	2000	16	31	0.11	0
1311	2000	16	32	0.37	0
1311	2000	17	31	0.02	0
1311	2000	17	32	0.25	0
1311	2000	18	31	0.09	0
1311	2000	18	32	0.41	0
1311	2000	19	31	0.14	0
1311	2000	19	32	0.6	0
1311	2000	21	31	0.0025	0
1311	2000	21	32	0.11	0
1311	2000	22	31	0.01	0
1311	2000	22	32	0.06	0
1311	2001	5	26	6.66666666666667E-03	0
1311	2001	5	31	0.005	0
1311	2001	5	32	0.09	0
1311	2001	6	31	0.005	0
1311	2001	6	32	0.03	0
1311	2001	7	32	0.04	0
1311	2001	8	31	0.0025	0
1311	2001	8	32	0.06	0
1311	2001	9	31	0.0025	0
1311	2001	9	32	0.02	0
1311	2001	11	32	0.02	0
1311	2001	12	31	0.0075	0
1311	2001	12	32	0.01	0
1311	2001	13	31	0.005	0
1311	2001	13	32	0.008	0
1311	2001	14	31	0.05	0
1311	2001	14	32	0.09	0
1311	2001	15	31	0.11	0
1311	2001	15	32	0.27	0
1311	2001	16	31	0.11	0
1311	2001	16	32	0.27	0
1311	2001	17	31	0.2	0
1311	2001	17	32	0.64	0
1311	2001	18	31	0.05	0
1311	2001	18	31	0.08	0
1311	2001	18	32	0.28	0
1311	2001	18	32	0.34	0
1311	2001	19	31	0.05	0
1311	2001	19	32	0.28	0
1311	2001	21	31	0.01	0
1311	2001	21	32	0.01	0
1311	2001	22	31	0.01	0
1311	2001	22	32	0.02	0
1311	2002	1	26	6.66666666666667E-03	0
1311	2002	1	31	0.01	0
1311	2002	1	32	0.1	0
1311	2002	3	31	0.01	0
1311	2002	3	32	0.06	0
1311	2002	4	31	0.0025	0
1311	2002	4	32	0.05	0
1311	2002	6	31	0.005	0
1311	2002	6	32	0.07	0
1311	2002	7	31	0.0075	0
1311	2002	7	32	0.07	0
1311	2002	9	32	0.05	0
1311	2002	12	31	0.0075	0
1311	2002	12	32	0.03	0
1311	2002	13	31	0.03	0
1311	2002	13	32	0.09	0
1311	2002	15	31	0.08	0
1311	2002	15	32	0.33	0
1311	2002	16	31	0.08	0
1311	2002	16	32	0.36	0
1311	2002	17	31	0.05	0
1311	2002	17	32	0.32	0
1311	2002	19	31	0.06	0
1311	2002	19	32	0.41	0
1311	2002	20	31	0.03	0
1311	2002	20	32	0.12	0
1311	2002	21	31	0.05	0
1311	2002	21	32	0.1	0
1311	2002	22	31	0.01	0
1311	2002	22	32	0.04	0
1311	2002	22	32	0.08	0
1311	2002	23	31	0.01	0
1311	2002	23	32	0.04	0
1311	2003	1	31	0.0025	0
1311	2003	1	32	0.03	0
1311	2003	2	31	0.0025	0
1311	2003	2	32	0.03	0
1311	2003	3	31	0.0025	0
1311	2003	3	32	0.11	0
1311	2003	4	31	0.0025	0
1311	2003	4	32	0.08	0
1311	2003	5	31	0.0025	0
1311	2003	5	32	0.04	0
1311	2003	6	32	0.03	0
1311	2003	7	32	0.03	0
1311	2003	8	31	0.01	0
1311	2003	8	32	0.05	0
1311	2003	9	31	0.0025	0
1311	2003	9	32	0.02	0
1311	2003	10	32	0.02	0
1311	2003	11	31	0.0075	0
1311	2003	11	32	0.02	0
1311	2003	12	31	0.08	0
1311	2003	12	32	0.37	0
1311	2003	13	31	0.07	0
1311	2003	13	32	0.29	0
1311	2003	15	26	0.02	0
1311	2003	15	31	0.12	0
1311	2003	15	32	0.98	0
1311	2003	16	26	0.02	0
1311	2003	16	31	0.04	0
1311	2003	16	32	0.44	0
1311	2003	17	31	0.05	0
1311	2003	17	32	0.35	0
1311	2003	18	31	0.07	0
1311	2003	18	32	0.27	0
1311	2003	19	31	0.02	0
1311	2003	19	32	0.09	0
1311	2003	20	26	6.66666666666667E-03	0
1311	2003	20	31	0.03	0
1311	2003	20	32	0.06	0
1311	2003	21	31	0.0025	0
1311	2003	21	32	0.04	0
1311	2003	22	26	6.66666666666667E-03	0
1311	2003	22	31	0.01	0
1311	2003	22	32	0.08	0
1311	2003	23	31	0.01	0
1311	2003	23	32	0.06	0
1311	2003	24	26	6.66666666666667E-03	0
1311	2003	24	31	0.005	0
1311	2003	24	32	0.03	0
1311	2003	25	26	6.66666666666667E-03	0
1311	2003	25	31	0.0025	0
1311	2003	25	32	0.01	0
1311	2004	2	31	0.005	0
1311	2004	2	32	0.05	0
1311	2004	3	31	0.005	0
1311	2004	3	32	0.05	0
1311	2004	4	31	0.01	0
1311	2004	4	32	0.07	0
1311	2004	5	31	0.005	0
1311	2004	5	32	0.03	0
1311	2004	6	31	0.01	0
1311	2004	6	32	0.13	0
1311	2004	7	26	6.66666666666667E-03	0
1311	2004	7	31	0.01	0
1311	2004	7	32	0.05	0
1311	2004	8	31	0.0075	0
1311	2004	8	32	0.03	0
1311	2004	9	31	0.005	0
1311	2004	9	32	0.04	0
1311	2004	10	31	0.0025	0
1311	2004	10	32	0.02	0
1311	2004	11	31	0.005	0
1311	2004	11	32	0.01	0
1311	2004	13	31	0.05	0
1311	2004	13	32	0.21	0
1311	2004	14	26	6.66666666666667E-03	0
1311	2004	14	31	0.06	0
1311	2004	14	32	0.5	0
1311	2004	16	31	0.07	0
1311	2004	16	32	0.47	0
1311	2004	17	26	6.66666666666667E-03	0
1311	2004	17	31	0.08	0
1311	2004	17	32	0.5	0
1311	2004	18	26	6.66666666666667E-03	0
1311	2004	18	31	0.06	0
1311	2004	18	32	0.46	0
1311	2004	19	31	0.06	0
1311	2004	19	32	0.34	0
1311	2004	20	31	0.06	0
1311	2004	20	32	0.21	0
1311	2004	21	31	0.02	0
1311	2004	21	32	0.13	0
1311	2004	22	31	0.0075	0
1311	2004	22	32	0.13	0
1311	2004	23	31	0.0075	0
1311	2004	23	32	0.06	0
1311	2004	25	31	0.01	0
1311	2004	25	32	0.01	0
1311	2004	26	31	0.0025	0
1311	2005	1	31	0.0025	0
1311	2005	1	32	0.05	0
1311	2005	2	26	6.66666666666667E-03	0
1311	2005	2	32	0.01	0
1311	2005	3	31	0.01	0
1311	2005	3	32	0.05	0
1311	2005	4	31	0.01	0
1311	2005	4	32	0.05	0
1311	2005	5	31	0.0075	0
1311	2005	5	32	0.08	0
1311	2005	6	31	0.0025	0
1311	2005	6	32	0.05	0
1311	2005	7	31	0.005	0
1311	2005	7	32	0.07	0
1311	2005	8	32	0.02	0
1311	2005	9	31	0.0025	0
1311	2005	9	32	0.04	0
1311	2005	10	26	6.66666666666667E-03	0
1311	2005	10	31	0.01	0
1311	2005	10	32	0.07	0
1311	2005	11	31	0.005	0
1311	2005	11	32	0.03	0
1311	2005	12	26	6.66666666666667E-03	0
1311	2005	12	31	0.0075	0
1311	2005	12	32	0.04	0
1311	2005	13	26	0.01	0
1311	2005	13	31	0.04	0
1311	2005	13	32	0.1	0
1311	2005	14	31	0.06	0
1311	2005	14	32	0.49	0
1311	2005	15	31	0.14	0
1311	2005	15	32	0.73	0
1311	2005	16	31	0.18	0
1311	2005	16	32	0.81	0
1311	2005	17	31	0.11	0
1311	2005	17	32	0.56	0
1311	2005	18	26	6.66666666666667E-03	0
1311	2005	18	31	0.1	0
1311	2005	18	32	0.51	0
1311	2005	19	31	0.05	0
1311	2005	19	32	0.17	0
1311	2005	20	31	0.03	0
1311	2005	20	32	0.06	0
1311	2005	22	31	0.01	0
1311	2005	22	32	0.01	0
1311	2005	23	31	0.01	0
1311	2005	23	32	0.01	0
1311	2006	3	31	0.01	0
1311	2006	3	32	0.11	0
1311	2006	4	31	0.01	0
1311	2006	4	32	0.07	0
1311	2006	5	31	0.005	0
1311	2006	5	32	0.03	0
1311	2006	6	31	0.0025	0
1311	2006	6	32	0.02	0
1311	2006	9	31	0.0025	0
1311	2006	10	32	0.01	0
1311	2006	11	32	0.01	0
1311	2006	12	31	0.0075	0
1311	2006	12	32	0.04	0
1311	2006	13	31	0.03	0
1311	2006	13	32	0.14	0
1311	2006	14	26	0.01	0
1311	2006	14	31	0.06	0
1311	2006	14	32	0.34	0
1311	2006	15	26	0.02	0
1311	2006	15	31	0.09	0
1311	2006	15	32	0.65	0
1311	2006	16	26	0.02	0
1311	2006	16	31	0.07	0
1311	2006	16	32	0.53	0
1311	2006	17	26	0.02	0
1311	2006	17	31	0.07	0
1311	2006	17	32	0.54	0
1311	2006	18	31	0.03	0
1311	2006	18	32	0.23	0
1311	2006	19	31	0.02	0
1311	2006	19	32	0.14	0
1311	2006	21	31	0.0025	0
1311	2006	21	32	0.06	0
1311	2006	22	26	0.01	0
1311	2006	22	31	0.0075	0
1311	2006	22	32	0.09	0
1311	2006	23	32	0.08	0
1311	2006	24	26	6.66666666666667E-03	0
1311	2006	24	31	0.005	0
1311	2006	24	32	0.01	0
1311	2006	25	31	0.01	0
1311	2006	25	32	0.04	0
1311	2006	26	31	0.005	0
1311	2006	26	32	0.02	0
1311	2007	1	31	0.0025	0
1311	2007	1	32	0.06	0
1311	2007	2	31	0.005	0
1311	2007	2	32	0.14	0
1311	2007	3	31	0.0075	0
1311	2007	3	32	0.14	0
1311	2007	4	26	0.01	0
1311	2007	4	31	0.01	0
1311	2007	4	32	0.2	0
1311	2007	5	26	0.01	0
1311	2007	5	31	0.005	0
1311	2007	5	32	0.16	0
1311	2007	7	32	0.03	0
1311	2007	8	32	0.03	0
1311	2007	9	31	0.0025	0
1311	2007	9	32	0.01	0
1311	2007	10	32	0.01	0
1311	2007	14	31	0.03	0
1311	2007	14	32	0.55	0
1311	2007	15	31	0.08	0
1311	2007	15	32	0.63	0
1311	2007	16	31	0.18	0
1311	2007	16	32	1.07	0
1311	2007	17	31	0.09	0
1311	2007	17	32	0.6	0
1311	2007	18	31	0.06	0
1311	2007	18	32	0.38	0
1311	2007	19	31	0.04	0
1311	2007	19	32	0.21	0
1311	2007	21	32	0.02	0
1311	2007	22	31	0.0025	0
1311	2007	22	32	0.02	0
1311	2007	24	32	0.008	0
1317	2000	2	26	3.87575590984057E-03	2
1317	2000	5	26	1.86915887850467E-03	2
1317	2000	6	17	7.2992700729927E-03	2
1317	2000	6	26	0.01	2
1317	2000	7	17	2.94117647058824E-03	2
1317	2000	7	26	7.32403177190954E-03	2
1317	2000	8	26	3.44827586206897E-03	2
1317	2000	10	17	7.2992700729927E-03	2
1317	2000	10	26	0.01	2
1317	2000	11	26	9.34579439252336E-04	2
1317	2000	13	17	0.02	2
1317	2000	13	23	0.03	2
1317	2000	13	26	0.02	2
1317	2000	14	17	0.02	2
1317	2000	14	23	9.23076923076923E-03	2
1317	2000	14	26	3.87575590984057E-03	2
1317	2000	15	17	0.07	2
1317	2000	15	23	9.23076923076923E-03	2
1317	2000	15	26	0.03	2
1317	2000	15	28	0.06	2
1317	2000	16	17	0.02	2
1317	2000	16	23	9.23076923076923E-03	2
1317	2000	16	26	0.02	2
1317	2000	17	17	0.07	2
1317	2000	17	23	0.04	2
1317	2000	17	26	0.05	2
1317	2000	18	17	0.02	2
1317	2000	18	23	0.03	2
1317	2000	18	26	0.06	2
1317	2000	19	17	0.04	2
1317	2000	19	23	2.38095238095238E-03	2
1317	2000	19	26	0.04	2
1317	2000	20	23	6.15384615384615E-03	2
1317	2000	20	26	0.01	2
1317	2000	21	23	2.38095238095238E-03	2
1317	2000	21	26	6.7816091954023E-03	2
1317	2000	22	26	2.12765957446809E-03	2
1317	2000	23	26	6.12447802744084E-03	2
1317	2000	24	26	9.34579439252336E-04	2
1317	2001	1	17	5.88235294117647E-03	2
1317	2001	1	26	0.03	2
1317	2001	2	26	3.44827586206897E-03	2
1317	2001	3	23	2.38095238095238E-03	2
1317	2001	4	12	5.55555555555556E-03	2
1317	2001	4	17	0.03	2
1317	2001	4	23	2.38095238095238E-03	2
1317	2001	4	26	0.01	2
1317	2001	5	17	0.01	2
1317	2001	5	23	6.15384615384615E-03	2
1317	2001	5	26	2.12765957446809E-03	2
1317	2001	6	26	0.01	2
1317	2001	7	26	9.34579439252336E-04	2
1317	2001	8	23	6.15384615384615E-03	2
1317	2001	9	26	2.22222222222222E-03	2
1317	2001	11	17	2.94117647058824E-03	2
1317	2001	11	26	3.44827586206897E-03	2
1317	2001	12	26	2.22222222222222E-03	2
1317	2001	13	17	2.94117647058824E-03	2
1317	2001	13	23	2.38095238095238E-03	2
1317	2001	13	26	2.12765957446809E-03	2
1317	2001	16	17	0.02	2
1317	2001	16	23	0.01	2
1317	2001	16	26	0.04	2
1317	2001	17	17	0.03	2
1317	2001	17	23	0.01	2
1317	2001	17	26	0.05	2
1317	2001	17	28	8.69565217391304E-03	2
1317	2001	18	17	8.82352941176471E-03	2
1317	2001	18	23	0.02	2
1317	2001	18	26	0.06	2
1317	2001	18	28	8.69565217391304E-03	2
1317	2001	19	26	8.82352941176471E-03	2
1317	2001	20	17	2.94117647058824E-03	2
1317	2001	20	23	0.01	2
1317	2001	20	26	0.01	2
1317	2001	21	17	5.88235294117647E-03	2
1317	2001	21	23	2.38095238095238E-03	2
1317	2001	21	26	9.34579439252336E-04	2
1317	2001	22	26	2.94117647058824E-03	2
1317	2001	23	26	0.01	2
1317	2001	24	17	7.2992700729927E-03	2
1317	2001	24	23	3.07692307692308E-03	2
1317	2001	24	26	8.13107505877674E-03	2
1317	2001	26	23	2.38095238095238E-03	2
1317	2001	26	26	8.51711190712529E-03	2
1317	2002	1	17	0.01	2
1317	2002	1	23	0.01	2
1317	2002	1	26	0.02	2
1317	2002	2	17	2.94117647058824E-03	2
1317	2002	2	26	7.96713701056747E-03	2
1317	2002	3	12	5.55555555555556E-03	2
1317	2002	3	23	7.14285714285714E-03	2
1317	2002	3	26	0.01	2
1317	2002	3	28	8.69565217391304E-03	2
1317	2002	4	12	5.55555555555556E-03	2
1317	2002	4	23	7.14285714285714E-03	2
1317	2002	4	26	0.01	2
1317	2002	4	28	8.69565217391304E-03	2
1317	2002	5	23	7.14285714285714E-03	2
1317	2002	5	26	0.01	2
1317	2002	7	17	0.01	2
1317	2002	7	23	2.38095238095238E-03	2
1317	2002	7	26	0.01	2
1317	2002	8	12	5.55555555555556E-03	2
1317	2002	8	17	5.88235294117647E-03	2
1317	2002	8	26	0.01	2
1317	2002	9	26	9.44521773712468E-03	2
1317	2002	11	26	9.34579439252336E-04	2
1317	2002	12	23	6.15384615384615E-03	2
1317	2002	12	26	3.33333333333333E-03	2
1317	2002	12	28	8.69565217391304E-03	2
1317	2002	13	23	6.15384615384615E-03	2
1317	2002	13	26	6.38297872340426E-03	2
1317	2002	14	17	5.88235294117647E-03	2
1317	2002	14	23	3.07692307692308E-03	2
1317	2002	14	26	0.01	2
1317	2002	15	17	0.03	2
1317	2002	15	23	0.04	2
1317	2002	15	26	0.02	2
1317	2002	15	28	8.69565217391304E-03	2
1317	2002	16	17	8.82352941176471E-03	2
1317	2002	16	23	0.01	2
1317	2002	16	26	0.01	2
1317	2002	16	28	8.69565217391304E-03	2
1317	2002	17	17	0.04	2
1317	2002	17	23	0.01	2
1317	2002	17	26	0.12	2
1317	2002	17	28	8.69565217391304E-03	2
1317	2002	18	17	0.02	2
1317	2002	18	23	7.83882783882784E-03	2
1317	2002	18	26	0.07	2
1317	2002	18	28	8.69565217391304E-03	2
1317	2002	19	17	0.01	2
1317	2002	19	23	4.76190476190476E-03	2
1317	2002	19	26	0.04	2
1317	2002	20	23	0.01	2
1317	2002	20	26	0.01	2
1317	2002	21	26	6.3894523326572E-03	2
1317	2002	22	26	0.01	2
1317	2002	23	17	2.94117647058824E-03	2
1317	2002	23	26	2.80373831775701E-03	2
1317	2002	24	23	2.38095238095238E-03	2
1317	2002	24	26	6.3894523326572E-03	2
1317	2002	26	26	9.34579439252336E-04	2
1317	2003	1	12	5.55555555555556E-03	2
1317	2003	1	26	0.02	2
1317	2003	2	17	7.2992700729927E-03	2
1317	2003	2	26	0.03	2
1317	2003	3	17	7.2992700729927E-03	2
1317	2003	3	26	0.04	2
1317	2003	4	26	5.60747663551402E-03	2
1317	2003	5	23	7.14285714285714E-03	2
1317	2003	5	26	0.01	2
1317	2003	6	26	3.44827586206897E-03	2
1317	2003	7	26	3.44827586206897E-03	2
1317	2003	9	17	2.94117647058824E-03	2
1317	2003	10	26	0.01	2
1317	2003	11	26	5.28446123594264E-03	2
1317	2003	12	23	2.38095238095238E-03	2
1317	2003	12	26	3.44827586206897E-03	2
1317	2003	13	17	0.01	2
1317	2003	13	23	9.23076923076923E-03	2
1317	2003	13	26	0.01	2
1317	2003	13	28	0.02	2
1317	2003	14	17	2.94117647058824E-03	2
1317	2003	14	23	0.01	2
1317	2003	14	26	0.02	2
1317	2003	15	17	0.03	2
1317	2003	15	23	0.01	2
1317	2003	15	26	0.04	2
1317	2003	16	17	0.03	2
1317	2003	16	23	0.01	2
1317	2003	16	26	0.02	2
1317	2003	17	17	0.01	2
1317	2003	17	23	0.01	2
1317	2003	17	26	0.02	2
1317	2003	18	12	0.01	2
1317	2003	18	17	0.07	2
1317	2003	18	23	0.01	2
1317	2003	18	26	0.07	2
1317	2003	18	28	0.02	2
1317	2003	19	12	5.55555555555556E-03	2
1317	2003	19	17	0.02	2
1317	2003	19	23	0.01	2
1317	2003	19	26	0.02	2
1317	2003	19	28	0.02	2
1317	2003	20	17	0.02	2
1317	2003	20	23	2.38095238095238E-03	2
1317	2003	20	26	6.89655172413793E-03	2
1317	2003	21	17	5.88235294117647E-03	2
1317	2003	21	26	0.01	2
1317	2003	22	26	4.25531914893617E-03	2
1317	2003	23	17	0.01	2
1317	2003	23	23	2.38095238095238E-03	2
1317	2003	23	26	0.03	2
1317	2003	23	28	8.69565217391304E-03	2
1317	2003	24	17	5.88235294117647E-03	2
1317	2003	24	26	0.02	2
1317	2003	24	28	8.69565217391304E-03	2
1317	2003	25	17	2.94117647058824E-03	2
1317	2003	25	26	8.82352941176471E-03	2
1317	2003	26	26	9.34579439252336E-04	2
1317	2004	1	23	6.15384615384615E-03	2
1317	2004	1	26	6.51051487578939E-03	2
1317	2004	2	26	5.31743474057364E-03	2
1317	2004	3	26	0.01	2
1317	2004	4	12	0.01	2
1317	2004	4	23	7.14285714285714E-03	2
1317	2004	4	26	0.01	2
1317	2004	4	28	8.69565217391304E-03	2
1317	2004	7	17	0.01	2
1317	2004	7	26	9.45169134637762E-03	2
1317	2004	8	17	5.88235294117647E-03	2
1317	2004	8	23	3.07692307692308E-03	2
1317	2004	8	26	3.33333333333333E-03	2
1317	2004	9	26	3.44827586206897E-03	2
1317	2004	11	23	3.07692307692308E-03	2
1317	2004	11	26	8.9017164498198E-03	2
1317	2004	11	28	0.01	2
1317	2004	13	12	5.55555555555556E-03	2
1317	2004	13	17	0.02	2
1317	2004	13	23	8.53479853479854E-03	2
1317	2004	13	26	0.01	2
1317	2004	14	17	0.03	2
1317	2004	14	23	0.02	2
1317	2004	14	26	0.04	2
1317	2004	15	17	0.01	2
1317	2004	15	23	0.01	2
1317	2004	15	26	0.02	2
1317	2004	16	12	5.55555555555556E-03	2
1317	2004	16	17	0.04	2
1317	2004	16	23	0.01	2
1317	2004	16	26	0.04	2
1317	2004	17	17	0.02	2
1317	2004	17	23	0.03	2
1317	2004	17	26	0.07	2
1317	2004	17	28	0.07	2
1317	2004	18	12	5.55555555555556E-03	2
1317	2004	18	17	8.82352941176471E-03	2
1317	2004	18	23	0.02	2
1317	2004	18	26	0.04	2
1317	2004	18	28	8.69565217391304E-03	2
1317	2004	20	17	0.01	2
1317	2004	20	23	3.07692307692308E-03	2
1317	2004	20	26	0.02	2
1317	2004	22	26	4.0913811007269E-03	2
1317	2004	22	28	8.69565217391304E-03	2
1317	2004	23	17	2.94117647058824E-03	2
1317	2004	23	26	7.44509431504172E-03	2
1317	2004	24	17	2.94117647058824E-03	2
1317	2004	24	26	8.94459195489689E-03	2
1317	2004	25	26	0.01	2
1317	2004	26	23	2.38095238095238E-03	2
1317	2005	2	17	0.01	2
1317	2005	2	23	3.07692307692308E-03	2
1317	2005	2	26	8.69976359338061E-03	2
1317	2005	3	17	0.02	2
1317	2005	3	23	3.07692307692308E-03	2
1317	2005	3	26	0.02	2
1317	2005	4	17	0.01	2
1317	2005	4	23	2.38095238095238E-03	2
1317	2005	4	26	0.02	2
1317	2005	5	17	2.94117647058824E-03	2
1317	2005	5	17	0.01	2
1317	2005	5	23	2.38095238095238E-03	2
1317	2005	5	26	6.31360332294912E-03	2
1317	2005	5	26	0.02	2
1317	2005	6	17	2.94117647058824E-03	2
1317	2005	6	26	6.31360332294912E-03	2
1317	2005	8	23	3.07692307692308E-03	2
1317	2005	8	26	3.87575590984057E-03	2
1317	2005	9	26	0.01	2
1317	2005	11	26	1.86915887850467E-03	2
1317	2005	12	23	2.38095238095238E-03	2
1317	2005	12	26	2.94117647058824E-03	2
1317	2005	13	23	0.03	2
1317	2005	13	26	9.19319065041421E-03	2
1317	2005	15	17	0.05	2
1317	2005	15	23	0.05	2
1317	2005	15	26	0.09	2
1317	2005	15	28	0.03	2
1317	2005	16	17	0.03	2
1317	2005	16	23	0.01	2
1317	2005	16	26	0.04	2
1317	2005	16	28	0.01	2
1317	2005	18	17	0.01	2
1317	2005	18	23	7.83882783882784E-03	2
1317	2005	18	26	0.03	2
1317	2005	19	12	5.55555555555556E-03	2
1317	2005	19	17	0.01	2
1317	2005	19	23	5.45787545787546E-03	2
1317	2005	19	26	0.02	2
1317	2005	20	17	8.82352941176471E-03	2
1317	2005	20	23	2.38095238095238E-03	2
1317	2005	20	26	4.81033534909291E-03	2
1317	2005	21	17	2.94117647058824E-03	2
1317	2005	21	23	5.45787545787546E-03	2
1317	2005	21	26	0.01	2
1317	2005	22	23	2.38095238095238E-03	2
1317	2005	22	23	8.53479853479854E-03	2
1317	2005	22	26	3.44827586206897E-03	2
1317	2005	22	26	5.06883604505632E-03	2
1317	2005	22	28	8.69565217391304E-03	2
1317	2005	23	17	2.94117647058824E-03	2
1317	2005	23	23	8.53479853479854E-03	2
1317	2005	23	26	9.41871784174663E-03	2
1317	2005	23	28	0.02	2
1317	2005	24	17	2.94117647058824E-03	2
1317	2005	24	26	4.34988179669031E-03	2
1317	2005	24	28	0.01	2
1317	2006	2	23	7.14285714285714E-03	2
1317	2006	2	26	2.94117647058824E-03	2
1317	2006	3	17	0.01	2
1317	2006	3	23	2.38095238095238E-03	2
1317	2006	3	26	0.02	2
1317	2006	4	17	0.02	2
1317	2006	4	26	1.86915887850467E-03	2
1317	2006	5	23	2.38095238095238E-03	2
1317	2006	5	26	6.81693238042881E-03	2
1317	2006	6	17	2.94117647058824E-03	2
1317	2006	6	23	3.07692307692308E-03	2
1317	2006	6	26	0.01	2
1317	2006	8	26	2.94117647058824E-03	2
1317	2006	10	26	9.34579439252336E-04	2
1317	2006	13	17	0.02	2
1317	2006	13	23	0.03	2
1317	2006	13	26	7.32403177190954E-03	2
1317	2006	14	17	5.88235294117647E-03	2
1317	2006	14	23	3.07692307692308E-03	2
1317	2006	14	26	0.02	2
1317	2006	15	17	0.03	2
1317	2006	15	23	0.03	2
1317	2006	15	26	0.06	2
1317	2006	16	17	0.03	2
1317	2006	16	23	0.02	2
1317	2006	16	26	0.04	2
1317	2006	16	28	0.01	2
1317	2006	17	17	0.01	2
1317	2006	17	23	2.38095238095238E-03	2
1317	2006	17	26	0.01	2
1317	2006	17	28	0.01	2
1317	2006	18	23	2.38095238095238E-03	2
1317	2006	18	26	9.03915460265103E-03	2
1317	2006	19	17	5.88235294117647E-03	2
1317	2006	19	23	2.38095238095238E-03	2
1317	2006	19	26	7.75151181968114E-03	2
1317	2006	20	26	6.81693238042881E-03	2
1317	2006	22	23	3.07692307692308E-03	2
1317	2006	22	26	4.25531914893617E-03	2
1317	2006	23	28	8.69565217391304E-03	2
1317	2006	24	17	7.2992700729927E-03	2
1317	2006	24	23	4.76190476190476E-03	2
1317	2006	24	26	3.87575590984057E-03	2
1317	2006	25	23	3.07692307692308E-03	2
1317	2006	25	26	8.82352941176471E-03	2
1317	2007	1	26	8.53582554517134E-03	2
1317	2007	2	26	6.3894523326572E-03	2
1317	2007	3	23	5.45787545787546E-03	2
1317	2007	3	26	5.60747663551402E-03	2
1317	2007	4	26	5.31743474057364E-03	2
1317	2007	5	17	8.82352941176471E-03	2
1317	2007	5	23	3.07692307692308E-03	2
1317	2007	5	26	0.02	2
1317	2007	5	28	8.69565217391304E-03	2
1317	2007	12	17	8.82352941176471E-03	2
1317	2007	13	17	0.01	2
1317	2007	13	23	7.83882783882784E-03	2
1317	2007	13	26	2.94117647058824E-03	2
1317	2007	14	17	0.02	2
1317	2007	14	23	0.03	2
1317	2007	14	26	0.04	2
1317	2007	15	17	0.02	2
1317	2007	15	23	3.07692307692308E-03	2
1317	2007	15	26	5.67049808429119E-03	2
1317	2007	16	17	0.04	2
1317	2007	16	23	0.01	2
1317	2007	16	26	0.06	2
1317	2007	17	17	0.01	2
1317	2007	17	23	0.01	2
1317	2007	17	26	6.21904067519498E-03	2
1317	2007	17	28	8.69565217391304E-03	2
1317	2007	18	17	2.94117647058824E-03	2
1317	2007	18	23	8.53479853479854E-03	2
1317	2007	19	17	0.01	2
1317	2007	19	23	0.01	2
1317	2007	19	26	7.70359501100514E-03	2
1317	2007	20	17	2.94117647058824E-03	2
1317	2007	20	23	4.76190476190476E-03	2
1317	2007	20	26	6.81693238042881E-03	2
1317	2007	21	17	2.94117647058824E-03	2
1317	2007	23	23	7.14285714285714E-03	2
1317	2007	23	26	7.75151181968114E-03	2
1317	2007	24	23	2.38095238095238E-03	2
1317	2007	25	26	9.34579439252336E-04	2
1317	2007	26	26	9.34579439252336E-04	2
1320	2000	1	10	0.01	0
1320	2000	1	17	0.01	0
1320	2000	1	18	5.88235294117647E-03	0
1320	2000	1	30	0.01	0
1320	2000	3	18	0.01	0
1320	2000	3	30	0.01	0
1320	2000	5	10	0.03	0
1320	2000	5	17	5.26315789473684E-03	0
1320	2000	5	18	0.02	0
1320	2000	5	30	0.02	0
1320	2000	6	10	0.04	0
1320	2000	6	17	5.26315789473684E-03	0
1320	2000	6	18	0.03	0
1320	2000	6	30	0.02	0
1320	2000	7	10	0.02	0
1320	2000	7	17	0.01	0
1320	2000	7	18	0.01	0
1320	2000	7	30	1.47058823529412E-03	0
1320	2000	8	17	0.01	0
1320	2000	8	18	0.03	0
1320	2000	8	30	8.82352941176471E-03	0
1320	2000	9	10	8.69565217391304E-03	0
1320	2000	9	17	2.63157894736842E-03	0
1320	2000	9	18	5.88235294117647E-03	0
1320	2000	9	30	7.48663101604278E-03	0
1320	2000	10	10	8.69565217391304E-03	0
1320	2000	10	17	7.89473684210526E-03	0
1320	2000	10	18	0.003125	0
1320	2000	10	30	7.35294117647059E-03	0
1320	2000	11	17	2.63157894736842E-03	0
1320	2000	11	30	1.47058823529412E-03	0
1320	2000	12	17	0.01	0
1320	2000	12	18	0.00625	0
1320	2000	12	30	4.41176470588235E-03	0
1320	2000	13	10	0.01	0
1320	2000	13	17	0.02	0
1320	2000	13	18	0.02	0
1320	2000	13	30	0.01	0
1320	2000	14	10	0.14	0
1320	2000	14	17	0.25	0
1320	2000	14	18	0.14	0
1320	2000	14	30	0.13	0
1320	2000	15	10	0.08	0
1320	2000	15	17	0.19	0
1320	2000	15	18	0.1	0
1320	2000	15	30	0.03	0
1320	2000	16	10	0.1	0
1320	2000	16	17	0.26	0
1320	2000	16	18	0.17	0
1320	2000	16	30	0.16	0
1320	2000	17	10	8.69565217391304E-03	0
1320	2000	17	17	0.14	0
1320	2000	17	18	0.12	0
1320	2000	17	30	0.06	0
1320	2000	18	10	0.03	0
1320	2000	18	17	0.16	0
1320	2000	18	18	0.15	0
1320	2000	18	30	0.14	0
1320	2000	19	10	0.02	0
1320	2000	19	17	0.02	0
1320	2000	19	18	0.04	0
1320	2000	19	30	0.1	0
1320	2000	20	10	0.02	0
1320	2000	20	17	0.02	0
1320	2000	20	18	0.03	0
1320	2000	20	30	0.1	0
1320	2000	21	10	0.09	0
1320	2000	21	17	5.26315789473684E-03	0
1320	2000	21	18	0.05	0
1320	2000	21	30	0.05	0
1320	2000	22	10	0.02	0
1320	2000	22	17	7.89473684210526E-03	0
1320	2000	22	18	0.01	0
1320	2000	22	30	0.04	0
1320	2000	23	10	0.01	0
1320	2000	23	18	5.88235294117647E-03	0
1320	2000	23	30	0.01	0
1320	2000	24	10	4.34782608695652E-03	0
1320	2000	24	18	0.01	0
1320	2000	24	30	1.47058823529412E-03	0
1320	2000	25	17	2.63157894736842E-03	0
1320	2001	5	10	4.34782608695652E-03	0
1320	2001	5	18	0.01	0
1320	2001	5	30	5.88235294117647E-03	0
1320	2001	6	10	0.02	0
1320	2001	6	17	0.01	0
1320	2001	6	18	0.02	0
1320	2001	6	30	0.02	0
1320	2001	7	10	0.03	0
1320	2001	7	18	0.03	0
1320	2001	7	30	0.03	0
1320	2001	8	10	8.69565217391304E-03	0
1320	2001	8	17	5.26315789473684E-03	0
1320	2001	8	18	0.00625	0
1320	2001	8	30	0.01	0
1320	2001	9	10	0.01	0
1320	2001	9	18	0.02	0
1320	2001	9	30	7.35294117647059E-03	0
1320	2001	10	17	7.89473684210526E-03	0
1320	2001	10	30	1.47058823529412E-03	0
1320	2001	11	10	4.34782608695652E-03	0
1320	2001	11	18	5.88235294117647E-03	0
1320	2001	11	30	1.47058823529412E-03	0
1320	2001	12	10	0.01	0
1320	2001	12	17	7.89473684210526E-03	0
1320	2001	12	18	5.88235294117647E-03	0
1320	2001	12	30	2.94117647058824E-03	0
1320	2001	13	10	0.01	0
1320	2001	13	17	0.02	0
1320	2001	13	18	0.02	0
1320	2001	13	30	0.01	0
1320	2001	14	10	0.04	0
1320	2001	14	17	0.16	0
1320	2001	14	18	0.08	0
1320	2001	14	30	0.06	0
1320	2001	15	10	0.15	0
1320	2001	15	17	0.17	0
1320	2001	15	18	0.17	0
1320	2001	15	30	0.07	0
1320	2001	16	10	0.15	0
1320	2001	16	17	0.25	0
1320	2001	16	18	0.21	0
1320	2001	16	30	0.26	0
1320	2001	17	10	0.07	0
1320	2001	17	17	0.05	0
1320	2001	17	18	0.06	0
1320	2001	17	30	0.11	0
1320	2001	18	10	0.16	0
1320	2001	18	17	0.2	0
1320	2001	18	18	0.06	0
1320	2001	18	30	0.16	0
1320	2001	19	10	0.04	0
1320	2001	19	17	0.04	0
1320	2001	19	18	0.07	0
1320	2001	19	30	0.09	0
1320	2001	20	10	0.08	0
1320	2001	20	17	0.01	0
1320	2001	20	18	0.02	0
1320	2001	20	30	0.06	0
1320	2001	21	10	0.02	0
1320	2001	21	17	0.01	0
1320	2001	21	18	0.02	0
1320	2001	21	30	0.01	0
1320	2001	22	10	0.01	0
1320	2001	22	17	2.63157894736842E-03	0
1320	2001	22	18	0.01	0
1320	2001	22	30	0.01	0
1320	2001	23	10	8.69565217391304E-03	0
1320	2001	23	30	0.01	0
1320	2001	24	17	5.26315789473684E-03	0
1320	2001	24	30	1.47058823529412E-03	0
1320	2001	25	10	8.69565217391304E-03	0
1320	2001	25	18	0.01	0
1320	2001	25	30	8.9572192513369E-03	0
1320	2002	1	10	0.05	0
1320	2002	1	18	5.88235294117647E-03	0
1320	2002	1	30	0.03	0
1320	2002	2	10	0.08	0
1320	2002	2	18	0.01	0
1320	2002	2	30	5.88235294117647E-03	0
1320	2002	3	10	0.04	0
1320	2002	3	17	5.26315789473684E-03	0
1320	2002	3	18	0.03	0
1320	2002	3	30	0.01	0
1320	2002	4	10	0.09	0
1320	2002	4	17	0.02	0
1320	2002	4	18	0.07	0
1320	2002	4	30	0.03	0
1320	2002	5	10	0.04	0
1320	2002	5	17	0.02	0
1320	2002	5	18	0.02	0
1320	2002	5	30	7.35294117647059E-03	0
1320	2002	6	10	0.1	0
1320	2002	6	17	0.01	0
1320	2002	6	18	0.03	0
1320	2002	6	30	0.04	0
1320	2002	7	10	0.08	0
1320	2002	7	17	0.02	0
1320	2002	7	18	0.06	0
1320	2002	7	30	0.05	0
1320	2002	8	10	0.03	0
1320	2002	8	18	0.01	0
1320	2002	9	10	0.01	0
1320	2002	9	17	5.26315789473684E-03	0
1320	2002	9	18	0.03	0
1320	2002	9	30	6.01604278074866E-03	0
1320	2002	10	17	5.26315789473684E-03	0
1320	2002	11	10	8.69565217391304E-03	0
1320	2002	11	17	5.26315789473684E-03	0
1320	2002	11	18	0.003125	0
1320	2002	12	10	0.01	0
1320	2002	12	17	0.1	0
1320	2002	12	18	0.05	0
1320	2002	12	30	0.02	0
1320	2002	13	10	0.01	0
1320	2002	13	17	0.08	0
1320	2002	13	18	0.04	0
1320	2002	13	30	0.02	0
1320	2002	14	10	4.34782608695652E-03	0
1320	2002	14	17	0.16	0
1320	2002	14	18	0.08	0
1320	2002	14	30	0.02	0
1320	2002	15	10	0.13	0
1320	2002	15	17	0.18	0
1320	2002	15	18	0.14	0
1320	2002	15	30	0.12	0
1320	2002	16	10	0.04	0
1320	2002	16	17	0.18	0
1320	2002	16	18	0.07	0
1320	2002	16	30	0.14	0
1320	2002	17	10	0.15	0
1320	2002	17	17	0.17	0
1320	2002	17	18	0.18	0
1320	2002	17	30	0.17	0
1320	2002	18	10	0.03	0
1320	2002	18	17	0.12	0
1320	2002	18	18	0.12	0
1320	2002	18	30	0.07	0
1320	2002	19	10	0.12	0
1320	2002	19	17	0.14	0
1320	2002	19	18	0.11	0
1320	2002	19	30	0.19	0
1320	2002	20	10	0.08	0
1320	2002	20	17	0.04	0
1320	2002	20	18	0.03	0
1320	2002	20	30	0.11	0
1320	2002	21	10	0.01	0
1320	2002	21	30	0.03	0
1320	2002	22	10	0.02	0
1320	2002	22	10	0.03	0
1320	2002	22	17	2.63157894736842E-03	0
1320	2002	22	17	5.26315789473684E-03	0
1320	2002	22	18	9.00735294117647E-03	0
1320	2002	22	30	5.88235294117647E-03	0
1320	2002	22	30	0.01	0
1320	2002	23	10	0.03	0
1320	2002	23	17	2.63157894736842E-03	0
1320	2002	23	30	5.88235294117647E-03	0
1320	2002	24	17	5.26315789473684E-03	0
1320	2002	24	30	2.94117647058824E-03	0
1320	2002	25	30	1.47058823529412E-03	0
1320	2003	1	10	0.01	0
1320	2003	1	17	2.63157894736842E-03	0
1320	2003	1	18	0.01	0
1320	2003	1	30	6.01604278074866E-03	0
1320	2003	2	10	0.01	0
1320	2003	2	17	5.26315789473684E-03	0
1320	2003	2	18	0.02	0
1320	2003	2	30	0.02	0
1320	2003	3	10	0.01	0
1320	2003	3	18	0.01	0
1320	2003	3	30	0.02	0
1320	2003	4	10	0.02	0
1320	2003	4	17	0.01	0
1320	2003	4	18	0.04	0
1320	2003	4	30	0.02	0
1320	2003	5	10	0.01	0
1320	2003	5	10	0.03	0
1320	2003	5	17	2.63157894736842E-03	0
1320	2003	5	17	5.26315789473684E-03	0
1320	2003	5	18	0.06	0
1320	2003	5	30	2.94117647058824E-03	0
1320	2003	5	30	0.01	0
1320	2003	6	10	0.03	0
1320	2003	6	17	5.26315789473684E-03	0
1320	2003	6	18	0.06	0
1320	2003	6	30	2.94117647058824E-03	0
1320	2003	7	10	8.69565217391304E-03	0
1320	2003	7	17	7.89473684210526E-03	0
1320	2003	7	18	0.01	0
1320	2003	7	30	0.01	0
1320	2003	8	17	0.03	0
1320	2003	8	18	0.01	0
1320	2003	8	30	0.01	0
1320	2003	9	17	5.26315789473684E-03	0
1320	2003	9	18	5.88235294117647E-03	0
1320	2003	9	30	0.02	0
1320	2003	10	18	5.88235294117647E-03	0
1320	2003	10	30	8.9572192513369E-03	0
1320	2003	11	10	4.34782608695652E-03	0
1320	2003	11	17	2.63157894736842E-03	0
1320	2003	11	18	0.01	0
1320	2003	11	30	2.94117647058824E-03	0
1320	2003	12	10	0.12	0
1320	2003	12	17	0.18	0
1320	2003	12	18	0.24	0
1320	2003	12	30	0.1	0
1320	2003	13	10	0.09	0
1320	2003	13	17	0.12	0
1320	2003	13	18	0.17	0
1320	2003	13	30	0.07	0
1320	2003	14	10	0.09	0
1320	2003	14	17	0.32	0
1320	2003	14	18	0.17	0
1320	2003	14	30	0.19	0
1320	2003	15	10	0.13	0
1320	2003	15	17	0.38	0
1320	2003	15	18	0.25	0
1320	2003	15	30	0.29	0
1320	2003	16	10	0.24	0
1320	2003	16	17	0.1	0
1320	2003	16	18	0.27	0
1320	2003	16	30	0.38	0
1320	2003	17	10	0.12	0
1320	2003	17	17	0.05	0
1320	2003	17	18	0.1	0
1320	2003	17	30	0.35	0
1320	2003	18	10	0.1	0
1320	2003	18	17	0.04	0
1320	2003	18	18	0.09	0
1320	2003	18	30	0.35	0
1320	2003	19	10	0.03	0
1320	2003	19	17	0.01	0
1320	2003	19	18	0.03	0
1320	2003	19	30	0.16	0
1320	2003	20	10	0.06	0
1320	2003	20	17	0.01	0
1320	2003	20	18	0.04	0
1320	2003	20	30	0.11	0
1320	2003	21	10	0.05	0
1320	2003	21	17	0.01	0
1320	2003	21	18	0.05	0
1320	2003	21	30	0.06	0
1320	2003	22	10	0.09	0
1320	2003	22	17	0.01	0
1320	2003	22	18	0.05	0
1320	2003	22	30	0.06	0
1320	2003	23	10	0.01	0
1320	2003	23	17	0.02	0
1320	2003	23	18	0.03	0
1320	2003	23	30	0.04	0
1320	2003	24	10	0.03	0
1320	2003	24	17	2.63157894736842E-03	0
1320	2003	24	18	9.00735294117647E-03	0
1320	2003	24	30	4.41176470588235E-03	0
1320	2003	25	17	5.26315789473684E-03	0
1320	2003	25	18	0.01	0
1320	2003	25	30	6.01604278074866E-03	0
1320	2003	26	18	0.009375	0
1320	2003	26	30	0.01	0
1320	2004	1	10	0.01	0
1320	2004	1	18	5.88235294117647E-03	0
1320	2004	1	30	0.02	0
1320	2004	2	10	0.01	0
1320	2004	2	17	0.01	0
1320	2004	2	18	0.003125	0
1320	2004	2	30	0.01	0
1320	2004	3	10	0.01	0
1320	2004	3	18	0.01	0
1320	2004	3	30	0.01	0
1320	2004	4	10	0.07	0
1320	2004	4	17	0.01	0
1320	2004	4	18	0.01	0
1320	2004	4	30	0.03	0
1320	2004	5	10	0.09	0
1320	2004	5	17	7.89473684210526E-03	0
1320	2004	5	18	0.04	0
1320	2004	5	30	0.02	0
1320	2004	6	10	0.05	0
1320	2004	6	17	0.04	0
1320	2004	6	18	0.06	0
1320	2004	6	30	0.03	0
1320	2004	7	10	4.34782608695652E-03	0
1320	2004	7	17	0.06	0
1320	2004	7	18	0.05	0
1320	2004	7	30	0.03	0
1320	2004	8	18	0.00625	0
1320	2004	8	30	0.01	0
1320	2004	9	10	0.06	0
1320	2004	9	17	0.04	0
1320	2004	9	18	0.02	0
1320	2004	9	30	0.04	0
1320	2004	10	10	4.34782608695652E-03	0
1320	2004	10	17	2.63157894736842E-03	0
1320	2004	10	18	9.00735294117647E-03	0
1320	2004	10	30	0.01	0
1320	2004	11	17	7.89473684210526E-03	0
1320	2004	11	18	0.02	0
1320	2004	11	30	0.01	0
1320	2004	12	17	0.02	0
1320	2004	12	18	0.03	0
1320	2004	12	30	4.41176470588235E-03	0
1320	2004	13	17	0.08	0
1320	2004	13	18	0.08	0
1320	2004	13	30	0.05	0
1320	2004	14	10	0.04	0
1320	2004	14	17	0.08	0
1320	2004	14	18	0.1	0
1320	2004	14	30	0.1	0
1320	2004	15	10	0.01	0
1320	2004	15	17	0.11	0
1320	2004	15	18	0.05	0
1320	2004	15	30	0.09	0
1320	2004	16	10	0.02	0
1320	2004	16	17	0.12	0
1320	2004	16	18	0.08	0
1320	2004	16	30	0.13	0
1320	2004	17	10	0.29	0
1320	2004	17	17	0.24	0
1320	2004	17	18	0.23	0
1320	2004	17	30	0.47	0
1320	2004	18	10	0.14	0
1320	2004	18	17	0.09	0
1320	2004	18	18	0.17	0
1320	2004	18	30	0.22	0
1320	2004	19	10	0.11	0
1320	2004	19	17	0.01	0
1320	2004	19	18	0.1	0
1320	2004	19	30	0.15	0
1320	2004	20	10	0.05	0
1320	2004	20	17	0.01	0
1320	2004	20	18	0.03	0
1320	2004	20	30	0.05	0
1320	2004	21	10	0.09	0
1320	2004	21	18	0.03	0
1320	2004	21	30	0.04	0
1320	2004	22	10	0.01	0
1320	2004	22	17	0.01	0
1320	2004	22	18	0.03	0
1320	2004	22	30	0.02	0
1320	2004	23	10	0.01	0
1320	2004	23	17	0.01	0
1320	2004	23	18	0.00625	0
1320	2004	23	30	0.01	0
1320	2004	24	10	8.69565217391304E-03	0
1320	2004	24	17	5.26315789473684E-03	0
1320	2004	24	30	7.48663101604278E-03	0
1320	2004	25	10	8.69565217391304E-03	0
1320	2004	25	17	5.26315789473684E-03	0
1320	2004	25	30	7.48663101604278E-03	0
1320	2004	26	10	4.34782608695652E-03	0
1320	2004	26	18	9.00735294117647E-03	0
1320	2004	26	30	2.94117647058824E-03	0
1320	2005	1	10	4.34782608695652E-03	0
1320	2005	1	18	0.003125	0
1320	2005	1	30	0.01	0
1320	2005	2	17	5.26315789473684E-03	0
1320	2005	2	18	9.00735294117647E-03	0
1320	2005	2	30	4.41176470588235E-03	0
1320	2005	3	10	0.01	0
1320	2005	3	30	0.01	0
1320	2005	4	10	0.02	0
1320	2005	4	17	0.01	0
1320	2005	4	18	0.01	0
1320	2005	4	30	0.01	0
1320	2005	5	10	0.03	0
1320	2005	5	17	0.01	0
1320	2005	5	18	0.01	0
1320	2005	5	30	0.04	0
1320	2005	6	10	8.69565217391304E-03	0
1320	2005	6	17	0.01	0
1320	2005	6	30	0.01	0
1320	2005	10	10	4.34782608695652E-03	0
1320	2005	10	18	0.03	0
1320	2005	10	30	0.01	0
1320	2005	11	18	9.00735294117647E-03	0
1320	2005	11	30	0.01	0
1320	2005	12	10	4.34782608695652E-03	0
1320	2005	12	17	0.02	0
1320	2005	12	18	0.01	0
1320	2005	12	30	0.01	0
1320	2005	13	10	0.01	0
1320	2005	13	17	0.08	0
1320	2005	13	18	0.05	0
1320	2005	13	30	0.09	0
1320	2005	14	10	0.03	0
1320	2005	14	17	0.13	0
1320	2005	14	18	0.07	0
1320	2005	14	30	0.12	0
1320	2005	15	10	0.04	0
1320	2005	15	17	0.12	0
1320	2005	15	18	0.14	0
1320	2005	15	30	0.15	0
1320	2005	16	10	0.1	0
1320	2005	16	17	0.13	0
1320	2005	16	18	0.11	0
1320	2005	16	30	0.14	0
1320	2005	17	10	0.16	0
1320	2005	17	17	0.11	0
1320	2005	17	18	0.21	0
1320	2005	17	30	0.18	0
1320	2005	18	10	8.69565217391304E-03	0
1320	2005	18	17	0.07	0
1320	2005	18	18	0.1	0
1320	2005	18	30	0.17	0
1320	2005	19	10	0.05	0
1320	2005	19	17	0.02	0
1320	2005	19	18	0.03	0
1320	2005	19	30	0.03	0
1320	2005	20	10	0.01	0
1320	2005	20	17	0.05	0
1320	2005	20	18	0.07	0
1320	2005	20	30	0.05	0
1320	2005	21	10	0.01	0
1320	2005	21	17	0.02	0
1320	2005	21	18	0.03	0
1320	2005	21	30	0.02	0
1320	2005	22	10	0.01	0
1320	2005	22	18	5.88235294117647E-03	0
1320	2005	22	30	0.04	0
1320	2005	23	10	4.34782608695652E-03	0
1320	2005	23	18	0.01	0
1320	2005	23	30	0.01	0
1320	2005	25	17	2.63157894736842E-03	0
1320	2005	25	18	0.003125	0
1320	2005	25	30	2.94117647058824E-03	0
1320	2006	1	10	0.03	0
1320	2006	1	30	4.54545454545455E-03	0
1320	2006	3	10	8.69565217391304E-03	0
1320	2006	3	18	0.01	0
1320	2006	3	30	6.01604278074866E-03	0
1320	2006	4	10	0.01	0
1320	2006	4	30	8.9572192513369E-03	0
1320	2006	5	10	0.03	0
1320	2006	5	18	0.01	0
1320	2006	5	30	0.02	0
1320	2006	6	10	0.03	0
1320	2006	6	17	5.26315789473684E-03	0
1320	2006	6	18	0.05	0
1320	2006	6	30	0.02	0
1320	2006	7	17	0.02	0
1320	2006	7	18	0.02	0
1320	2006	7	30	0.01	0
1320	2006	8	10	0.02	0
1320	2006	8	17	0.01	0
1320	2006	8	18	0.01	0
1320	2006	8	30	0.01	0
1320	2006	9	10	4.34782608695652E-03	0
1320	2006	9	17	5.26315789473684E-03	0
1320	2006	9	18	9.00735294117647E-03	0
1320	2006	10	10	4.34782608695652E-03	0
1320	2006	10	17	0.01	0
1320	2006	10	18	0.01	0
1320	2006	10	30	2.94117647058824E-03	0
1320	2006	11	10	4.34782608695652E-03	0
1320	2006	11	17	2.63157894736842E-03	0
1320	2006	11	18	9.00735294117647E-03	0
1320	2006	11	30	2.94117647058824E-03	0
1320	2006	12	10	0.01	0
1320	2006	12	17	0.03	0
1320	2006	12	18	0.05	0
1320	2006	12	30	4.41176470588235E-03	0
1320	2006	13	10	0.04	0
1320	2006	13	17	0.07	0
1320	2006	13	18	0.06	0
1320	2006	13	30	0.07	0
1320	2006	14	10	0.03	0
1320	2006	14	17	0.02	0
1320	2006	14	18	0.03	0
1320	2006	14	30	0.09	0
1320	2006	15	10	0.18	0
1320	2006	15	17	0.15	0
1320	2006	15	18	0.33	0
1320	2006	15	30	0.3	0
1320	2006	17	10	0.11	0
1320	2006	17	17	0.07	0
1320	2006	17	18	0.13	0
1320	2006	17	30	0.27	0
1320	2006	18	10	0.07	0
1320	2006	18	17	5.26315789473684E-03	0
1320	2006	18	18	0.13	0
1320	2006	18	30	0.25	0
1320	2006	19	10	0.03	0
1320	2006	19	17	0.02	0
1320	2006	19	18	0.03	0
1320	2006	19	30	0.09	0
1320	2006	20	10	0.02	0
1320	2006	20	18	0.01	0
1320	2006	20	30	0.08	0
1320	2006	21	10	0.01	0
1320	2006	21	17	5.26315789473684E-03	0
1320	2006	21	18	0.01	0
1320	2006	21	30	0.07	0
1320	2006	22	10	0.02	0
1320	2006	22	18	0.01	0
1320	2006	22	30	7.48663101604278E-03	0
1320	2006	23	10	4.34782608695652E-03	0
1320	2006	23	18	0.009375	0
1320	2006	23	30	0.04	0
1320	2006	24	10	8.69565217391304E-03	0
1320	2006	24	18	0.01	0
1320	2006	24	30	0.01	0
1320	2006	25	30	2.94117647058824E-03	0
1320	2006	26	18	0.03	0
1320	2007	1	10	0.05	0
1320	2007	1	18	0.03	0
1320	2007	1	30	0.01	0
1320	2007	2	10	0.05	0
1320	2007	2	18	5.88235294117647E-03	0
1320	2007	2	30	0.01	0
1320	2007	3	10	0.01	0
1320	2007	3	17	2.63157894736842E-03	0
1320	2007	3	18	0.04	0
1320	2007	3	30	0.01	0
1320	2007	4	18	0.01	0
1320	2007	4	30	0.03	0
1320	2007	5	10	0.04	0
1320	2007	5	17	0.02	0
1320	2007	5	18	0.08	0
1320	2007	5	30	0.02	0
1320	2007	6	17	0.01	0
1320	2007	6	18	0.06	0
1320	2007	6	30	1.47058823529412E-03	0
1320	2007	7	10	0.01	0
1320	2007	7	17	0.01	0
1320	2007	7	18	0.01	0
1320	2007	7	30	0.01	0
1320	2007	8	10	4.34782608695652E-03	0
1320	2007	8	17	0.02	0
1320	2007	8	18	0.02	0
1320	2007	8	30	0.01	0
1320	2007	9	10	0.01	0
1320	2007	9	30	2.94117647058824E-03	0
1320	2007	10	10	0.02	0
1320	2007	10	17	5.26315789473684E-03	0
1320	2007	10	18	5.88235294117647E-03	0
1320	2007	10	30	0.01	0
1320	2007	11	10	0.01	0
1320	2007	11	17	0.01	0
1320	2007	11	18	0.00625	0
1320	2007	11	30	5.88235294117647E-03	0
1320	2007	13	10	0.02	0
1320	2007	13	17	0.03	0
1320	2007	13	18	0.1	0
1320	2007	13	30	0.03	0
1320	2007	14	10	4.34782608695652E-03	0
1320	2007	14	17	0.09	0
1320	2007	14	18	0.1	0
1320	2007	14	30	0.03	0
1320	2007	15	10	0.02	0
1320	2007	15	17	0.05	0
1320	2007	15	18	9.00735294117647E-03	0
1320	2007	15	30	0.06	0
1320	2007	16	10	0.22	0
1320	2007	16	17	0.14	0
1320	2007	16	18	0.15	0
1320	2007	16	30	0.22	0
1320	2007	17	10	0.1	0
1320	2007	17	17	0.07	0
1320	2007	17	18	0.13	0
1320	2007	17	30	0.16	0
1320	2007	18	10	0.09	0
1320	2007	18	17	0.11	0
1320	2007	18	18	0.08	0
1320	2007	18	30	0.11	0
1320	2007	19	10	0.02	0
1320	2007	19	17	0.06	0
1320	2007	19	18	0.02	0
1320	2007	19	30	0.05	0
1320	2007	20	18	9.00735294117647E-03	0
1320	2007	20	30	4.54545454545455E-03	0
1320	2007	21	10	8.69565217391304E-03	0
1320	2007	21	17	2.63157894736842E-03	0
1320	2007	21	18	0.01	0
1320	2007	21	30	0.01	0
1320	2007	22	10	0.01	0
1320	2007	23	17	7.89473684210526E-03	0
1320	2007	23	18	9.00735294117647E-03	0
1320	2007	23	30	7.48663101604278E-03	0
1320	2007	24	17	7.89473684210526E-03	0
1320	2007	24	18	0.003125	0
1320	2007	24	30	4.54545454545455E-03	0
1320	2007	25	30	2.94117647058824E-03	0
1905	2000	1	25	3.77358490566038E-03	0
1905	2000	1	30	0.03	0
1905	2000	2	21	0.03	0
1905	2000	2	25	0.01	0
1905	2000	2	30	0.09	0
1905	2000	3	17	0.01	0
1905	2000	3	21	6.66666666666667E-03	0
1905	2000	5	17	0.02	0
1905	2000	5	21	0.05	0
1905	2000	5	25	0.08	0
1905	2000	5	30	0.1	0
1905	2000	6	17	0.01	0
1905	2000	6	21	0.07	0
1905	2000	6	25	0.03	0
1905	2000	6	30	0.07	0
1905	2000	7	21	0.02	0
1905	2000	7	25	0.01	0
1905	2000	7	30	0.03	0
1905	2000	8	21	5.88235294117647E-03	0
1905	2000	8	25	0.01	0
1905	2000	8	30	0.02	0
1905	2000	9	17	0.04	0
1905	2000	9	21	7.14285714285714E-03	0
1905	2000	9	25	0.01	0
1905	2000	9	30	0.05	0
1905	2000	10	17	0.01	0
1905	2000	10	21	0.02	0
1905	2000	10	25	0.02	0
1905	2000	10	30	0.01	0
1905	2000	11	17	0.01	0
1905	2000	11	21	0.02	0
1905	2000	11	25	3.77358490566038E-03	0
1905	2000	11	30	0.04	0
1905	2000	12	21	0.01	0
1905	2000	12	25	0.01	0
1905	2000	12	30	0.01	0
1905	2000	13	21	0.11	0
1905	2000	13	25	1.88679245283019E-03	0
1905	2000	13	30	4.34782608695652E-03	0
1905	2000	15	17	0.06	0
1905	2000	15	21	0.05	0
1905	2000	15	25	0.05	0
1905	2000	15	30	0.13	0
1905	2000	16	17	0.15	0
1905	2000	16	21	0.21	0
1905	2000	16	25	0.15	0
1905	2000	16	30	0.25	0
1905	2000	17	17	0.11	0
1905	2000	17	21	0.17	0
1905	2000	17	25	0.12	0
1905	2000	17	30	0.16	0
1905	2000	18	17	0.35	0
1905	2000	18	21	0.32	0
1905	2000	18	25	0.15	0
1905	2000	18	30	0.32	0
1905	2000	19	17	0.07	0
1905	2000	19	21	0.21	0
1905	2000	19	25	0.06	0
1905	2000	19	30	0.13	0
1905	2000	20	21	0.03	0
1905	2000	20	25	0.03	0
1905	2000	20	30	0.16	0
1905	2000	21	17	0.01	0
1905	2000	21	21	0.02	0
1905	2000	21	25	0.07	0
1905	2000	21	30	0.1	0
1905	2000	22	21	0.04	0
1905	2000	22	25	0.03	0
1905	2000	22	30	0.07	0
1905	2000	23	21	0.04	0
1905	2000	23	25	0.03	0
1905	2000	23	30	0.06	0
1905	2000	24	17	0.01	0
1905	2000	24	21	0.04	0
1905	2000	24	25	9.50653120464441E-03	0
1905	2000	24	30	0.07	0
1905	2000	25	21	0.01	0
1905	2000	25	25	5.73294629898403E-03	0
1905	2000	25	30	0.09	0
1905	2000	26	17	0.04	0
1905	2000	26	21	0.02	0
1905	2000	26	25	3.77358490566038E-03	0
1905	2000	26	30	0.02	0
1905	2003	1	21	7.14285714285714E-03	0
1905	2003	1	25	0.01	0
1905	2003	1	30	0.01	0
1905	2003	2	21	0.02	0
1905	2003	2	25	0.03	0
1905	2003	2	30	0.02	0
1905	2003	3	21	0.02	0
1905	2003	3	25	0.04	0
1905	2003	3	30	0.02	0
1905	2003	6	21	5.88235294117647E-03	0
1905	2003	6	25	1.88679245283019E-03	0
1905	2003	6	30	8.33333333333333E-03	0
1905	2003	7	25	7.54716981132075E-03	0
1905	2003	7	30	8.69565217391304E-03	0
1905	2003	8	21	7.14285714285714E-03	0
1905	2003	8	25	0.01	0
1905	2003	9	25	0.01	0
1905	2003	9	30	0.01	0
1905	2003	10	21	5.88235294117647E-03	0
1905	2003	10	25	0.01	0
1905	2003	10	30	0.11	0
1905	2003	11	17	0.03	0
1905	2003	11	21	0.04	0
1905	2003	11	25	0.02	0
1905	2003	11	30	0.1	0
1905	2003	12	17	0.3	0
1905	2003	12	21	0.21	0
1905	2003	12	25	0.1	0
1905	2003	12	30	0.12	0
1905	2003	13	17	0.17	0
1905	2003	13	21	0.17	0
1905	2003	13	25	0.05	0
1905	2003	13	30	0.06	0
1905	2004	1	21	7.14285714285714E-03	0
1905	2004	3	21	6.66666666666667E-03	0
1905	2004	3	25	0.02	0
1905	2004	3	30	0.02	0
1905	2004	4	21	0.05	0
1905	2004	4	25	0.04	0
1905	2004	4	30	0.11	0
1905	2004	5	21	0.02	0
1905	2004	5	25	5.73294629898403E-03	0
1905	2004	5	30	0.02	0
1905	2004	6	21	0.01	0
1905	2004	6	25	9.57910014513788E-03	0
1905	2004	6	30	0.02	0
1905	2004	7	17	0.01	0
1905	2004	7	21	0.02	0
1905	2004	7	25	0.01	0
1905	2004	7	30	8.69565217391304E-03	0
1905	2004	8	21	6.66666666666667E-03	0
1905	2004	8	30	0.05	0
1905	2004	9	21	5.88235294117647E-03	0
1905	2004	9	30	8.33333333333333E-03	0
1905	2004	10	21	6.66666666666667E-03	0
1905	2004	10	25	3.77358490566038E-03	0
1905	2004	11	21	5.88235294117647E-03	0
1905	2004	11	25	0.01	0
1905	2004	11	30	0.03	0
1905	2004	12	17	0.03	0
1905	2004	12	21	0.05	0
1905	2004	12	25	0.01	0
1905	2004	12	30	0.05	0
1905	2004	13	17	0.01	0
1905	2004	13	21	0.05	0
1905	2004	13	25	0.01	0
1905	2004	16	17	0.01	0
1905	2004	16	21	0.26	0
1905	2004	16	25	0.06	0
1905	2004	16	30	0.01	0
1905	2004	17	17	0.11	0
1905	2004	17	21	0.36	0
1905	2004	17	25	0.13	0
1905	2004	17	30	0.11	0
1905	2004	18	17	0.1	0
1905	2004	18	21	0.24	0
1905	2004	18	25	0.11	0
1905	2004	18	30	0.06	0
1905	2004	19	17	0.01	0
1905	2004	19	21	0.07	0
1905	2004	19	25	0.03	0
1905	2004	19	30	0.13	0
1905	2004	20	17	0.03	0
1905	2004	20	21	0.08	0
1905	2004	20	25	0.02	0
1905	2004	20	30	0.1	0
1905	2004	21	21	0.04	0
1905	2004	21	25	0.04	0
1905	2004	21	30	0.04	0
1905	2004	22	21	0.01	0
1905	2004	22	25	0.01	0
1905	2004	22	30	0.05	0
1905	2004	23	17	0.01	0
1905	2004	23	21	0.02	0
1905	2004	23	25	3.84615384615385E-03	0
1905	2004	23	30	8.33333333333333E-03	0
1905	2004	25	21	0.04	0
1905	2004	25	25	3.84615384615385E-03	0
1905	2004	25	30	0.01	0
1905	2004	26	21	5.88235294117647E-03	0
1905	2004	26	25	9.57910014513788E-03	0
1905	2004	26	30	4.34782608695652E-03	0
1905	2005	1	21	5.88235294117647E-03	0
1905	2005	1	25	5.73294629898403E-03	0
1905	2005	2	21	6.66666666666667E-03	0
1905	2005	2	25	0.01	0
1905	2005	2	30	0.05	0
1905	2005	3	17	0.01	0
1905	2005	3	21	0.04	0
1905	2005	3	25	0.05	0
1905	2005	3	30	0.09	0
1905	2005	4	17	0.01	0
1905	2005	4	21	0.01	0
1905	2005	4	25	0.04	0
1905	2005	4	30	0.03	0
1905	2005	5	21	0.05	0
1905	2005	5	25	9.50653120464441E-03	0
1905	2005	5	30	0.04	0
1905	2005	6	21	0.04	0
1905	2005	6	25	0.02	0
1905	2005	6	30	0.07	0
1905	2005	7	17	0.01	0
1905	2005	7	21	0.05	0
1905	2005	7	25	0.03	0
1905	2005	7	30	0.02	0
1905	2005	8	21	0.01	0
1905	2005	8	25	3.84615384615385E-03	0
1905	2005	9	21	0.01	0
1905	2005	9	25	7.61973875181422E-03	0
1905	2005	9	25	0.01	0
1905	2005	9	30	0.01	0
1905	2005	9	30	0.04	0
1905	2005	10	21	0.01	0
1905	2005	10	25	7.61973875181422E-03	0
1905	2005	10	30	0.04	0
1905	2005	11	21	6.66666666666667E-03	0
1905	2005	11	25	3.84615384615385E-03	0
1905	2005	11	30	0.02	0
1905	2005	12	17	0.01	0
1905	2005	12	21	0.05	0
1905	2005	12	25	0.05	0
1905	2005	12	30	0.08	0
1905	2005	13	17	0.01	0
1905	2005	13	21	0.07	0
1905	2005	13	25	0.05	0
1905	2005	13	30	0.07	0
1905	2005	14	17	0.01	0
1905	2005	14	21	0.02	0
1905	2005	14	25	9.43396226415094E-03	0
1905	2005	14	30	0.03	0
1905	2005	15	17	0.07	0
1905	2005	15	21	0.34	0
1905	2005	15	25	0.21	0
1905	2005	15	30	0.25	0
1905	2005	16	17	0.02	0
1905	2005	16	21	0.2	0
1905	2005	16	25	0.08	0
1905	2005	16	30	0.14	0
1905	2005	18	17	0.03	0
1905	2005	18	21	0.17	0
1905	2005	18	25	0.05	0
1905	2005	18	30	0.12	0
1905	2005	19	21	0.17	0
1905	2005	19	25	0.05	0
1905	2005	19	30	0.09	0
1905	2005	20	21	0.06	0
1905	2005	20	25	0.01	0
1905	2005	20	30	0.05	0
1905	2005	21	21	0.03	0
1905	2005	21	25	9.50653120464441E-03	0
1905	2005	21	30	0.07	0
1905	2005	22	21	0.01	0
1905	2005	22	25	3.84615384615385E-03	0
1905	2005	22	30	0.02	0
1905	2005	22	30	0.03	0
1905	2005	23	30	0.03	0
1905	2005	25	21	0.02	0
1905	2005	25	25	7.69230769230769E-03	0
1905	2005	25	30	8.69565217391304E-03	0
1905	2006	1	21	5.88235294117647E-03	0
1905	2006	1	25	3.77358490566038E-03	0
1905	2006	3	21	5.88235294117647E-03	0
1905	2006	3	25	0.01	0
1905	2006	3	30	0.06	0
1905	2006	4	21	5.88235294117647E-03	0
1905	2006	4	25	0.01	0
1905	2006	4	30	0.06	0
1905	2006	5	21	0.03	0
1905	2006	5	25	0.02	0
1905	2006	5	30	0.06	0
1905	2006	6	21	0.03	0
1905	2006	6	25	0.01	0
1905	2006	6	30	0.03	0
1905	2006	7	25	3.77358490566038E-03	0
1905	2006	9	21	0.04	0
1905	2006	9	25	7.61973875181422E-03	0
1905	2006	11	21	0.02	0
1905	2006	11	25	0.01	0
1905	2006	12	21	5.88235294117647E-03	0
1905	2006	12	25	9.50653120464441E-03	0
1905	2006	12	30	0.02	0
1905	2006	13	17	0.03	0
1905	2006	13	21	0.05	0
1905	2006	13	25	0.02	0
1905	2006	13	30	0.04	0
1905	2006	14	17	0.02	0
1905	2006	14	21	0.05	0
1905	2006	14	25	0.04	0
1905	2006	14	30	0.03	0
1905	2006	15	17	0.08	0
1905	2006	15	21	0.15	0
1905	2006	15	25	0.1	0
1905	2006	15	30	0.16	0
1905	2006	16	17	0.08	0
1905	2006	16	21	0.31	0
1905	2006	16	25	0.07	0
1905	2006	16	30	0.24	0
1905	2006	17	17	0.08	0
1905	2006	17	21	0.29	0
1905	2006	17	25	0.13	0
1905	2006	17	30	0.19	0
1905	2006	18	17	0.01	0
1905	2006	18	21	0.09	0
1905	2006	18	25	0.06	0
1905	2006	18	30	0.1	0
1905	2006	19	21	0.02	0
1905	2006	19	25	0.01	0
1905	2006	19	30	0.03	0
1905	2006	20	21	0.04	0
1905	2006	20	25	0.01	0
1905	2006	20	30	0.04	0
1905	2006	21	21	0.04	0
1905	2006	21	25	0.01	0
1905	2006	21	30	0.04	0
1905	2006	23	21	0.02	0
1905	2006	23	25	0.02	0
1905	2006	23	30	0.01	0
1905	2006	24	17	0.04	0
1905	2006	24	21	0.02	0
1905	2006	24	25	0.03	0
1905	2006	24	30	0.06	0
1905	2006	25	21	0.02	0
1905	2006	25	25	5.66037735849057E-03	0
1905	2006	25	30	4.34782608695652E-03	0
1905	2006	26	21	0.01	0
1905	2006	26	25	0.01	0
1905	2006	26	30	0.05	0
1905	2007	1	17	0.03	0
1905	2007	1	21	0.01	0
1905	2007	1	25	0.03	0
1905	2007	1	30	0.06	0
1905	2007	2	17	0.03	0
1905	2007	2	21	0.01	0
1905	2007	2	25	0.02	0
1905	2007	2	30	0.04	0
1905	2007	3	17	0.02	0
1905	2007	3	21	0.1	0
1905	2007	3	25	0.09	0
1905	2007	3	30	0.24	0
1905	2007	4	17	0.02	0
1905	2007	4	21	0.05	0
1905	2007	4	25	0.04	0
1905	2007	4	30	0.04	0
1905	2007	5	21	0.05	0
1905	2007	5	25	0.02	0
1905	2007	5	30	0.04	0
1905	2007	8	21	0.01	0
1905	2007	8	25	7.61973875181422E-03	0
1905	2007	9	25	1.88679245283019E-03	0
1905	2007	9	30	8.33333333333333E-03	0
1905	2007	11	17	0.02	0
1905	2007	11	21	0.05	0
1905	2007	11	25	0.01	0
1905	2007	11	30	0.02	0
1905	2007	12	17	0.02	0
1905	2007	12	21	0.01	0
1905	2007	12	25	9.57910014513788E-03	0
1905	2007	12	30	4.34782608695652E-03	0
1905	2007	14	21	0.04	0
1905	2007	14	25	0.02	0
1905	2007	14	30	0.01	0
1905	2007	15	21	0.04	0
1905	2007	15	25	0.02	0
1905	2007	15	30	0.01	0
1905	2007	16	17	0.05	0
1905	2007	16	21	0.33	0
1905	2007	16	25	0.09	0
1905	2007	16	30	0.08	0
1905	2007	17	17	0.02	0
1905	2007	17	21	0.21	0
1905	2007	17	25	0.06	0
1905	2007	17	30	8.69565217391304E-03	0
1905	2007	18	17	0.01	0
1905	2007	18	21	0.07	0
1905	2007	18	25	0.04	0
1905	2007	18	30	0.05	0
1905	2007	19	21	0.03	0
1905	2007	19	25	0.04	0
1905	2007	19	30	0.06	0
1905	2007	20	21	6.66666666666667E-03	0
1905	2007	20	25	0.01	0
1905	2007	20	30	0.02	0
1905	2007	21	30	0.01	0
1905	2007	22	30	0.01	0
1905	2007	23	21	7.14285714285714E-03	0
1905	2007	23	25	5.73294629898403E-03	0
1905	2007	24	21	0.01	0
1905	2007	24	25	0.01	0
1905	2007	24	30	0.03	0
1905	2007	25	21	0.01	0
1905	2007	25	25	0.01	0
1905	2007	25	30	4.34782608695652E-03	0
1932	2000	1	25	0.06	0
1932	2000	1	26	0.08	0
1932	2000	2	25	0.15	0
1932	2000	2	26	0.17	0
1932	2000	3	25	0.12	0
1932	2000	3	26	0.22	0
1932	2000	4	25	0.06	0
1932	2000	4	26	0.09	0
1932	2000	5	25	0.04	0
1932	2000	5	26	0.05	0
1932	2000	6	25	0.14	0
1932	2000	6	26	0.04	0
1932	2000	7	17	0.01	0
1932	2000	7	25	0.08	0
1932	2000	7	26	0.03	0
1932	2000	8	25	5.84795321637427E-03	0
1932	2000	8	26	0.01	0
1932	2000	9	25	0.06	0
1932	2000	9	26	0.1	0
1932	2000	10	25	0.02	0
1932	2000	10	26	0.03	0
1932	2000	11	25	0.08	0
1932	2000	11	26	0.02	0
1932	2000	12	25	0.03	0
1932	2000	12	26	0.02	0
1932	2000	13	17	0.03	0
1932	2000	13	25	0.08	0
1932	2000	13	26	0.19	0
1932	2000	14	17	0.1	0
1932	2000	14	25	0.04	0
1932	2000	14	26	0.13	0
1932	2000	15	17	0.1	0
1932	2000	15	25	0.03	0
1932	2000	15	26	0.02	0
1932	2000	16	17	0.19	0
1932	2000	16	25	0.12	0
1932	2000	16	26	0.3	0
1932	2000	17	17	0.4	0
1932	2000	17	25	0.22	0
1932	2000	17	26	0.17	0
1932	2000	18	17	0.21	0
1932	2000	18	25	0.26	0
1932	2000	18	26	0.16	0
1932	2000	19	17	0.2	0
1932	2000	19	25	0.1	0
1932	2000	19	26	0.07	0
1932	2000	20	17	0.13	0
1932	2000	20	25	0.19	0
1932	2000	20	26	0.1	0
1932	2000	21	17	0.02	0
1932	2000	21	25	0.2	0
1932	2000	21	26	0.04	0
1932	2000	22	17	0.01	0
1932	2000	22	25	0.05	0
1932	2000	22	26	0.08	0
1932	2000	23	25	0.08	0
1932	2000	23	26	0.02	0
1932	2000	24	25	0.03	0
1932	2000	24	26	7.46268656716418E-03	0
1932	2000	26	17	0.01	0
1932	2000	26	25	0.05	0
1932	2001	7	25	0.04	0
1932	2001	7	26	0.02	0
1932	2001	8	17	0.06	0
1932	2001	8	25	0.11	0
1932	2001	8	26	0.18	0
1932	2001	9	17	0.03	0
1932	2001	9	25	0.02	0
1932	2001	9	25	0.04	0
1932	2001	9	26	0.02	0
1932	2001	9	26	0.09	0
1932	2001	10	25	0.02	0
1932	2001	10	26	0.02	0
1932	2001	11	25	0.02	0
1932	2001	11	26	0.01	0
1932	2001	12	25	0.07	0
1932	2001	12	26	0.02	0
1932	2001	13	17	0.03	0
1932	2001	13	25	0.12	0
1932	2001	13	26	0.2	0
1932	2001	14	25	0.12	0
1932	2001	14	26	0.11	0
1932	2001	15	17	0.35	0
1932	2001	15	25	0.26	0
1932	2001	15	26	0.05	0
1932	2001	16	17	0.25	0
1932	2001	16	25	0.23	0
1932	2001	16	26	0.01	0
1932	2001	17	17	0.19	0
1932	2001	17	25	0.3	0
1932	2001	17	26	0.3	0
1932	2001	18	17	0.14	0
1932	2001	18	17	0.22	0
1932	2001	18	25	0.14	0
1932	2001	18	25	0.33	0
1932	2001	18	26	0.22	0
1932	2001	18	26	0.44	0
1932	2001	19	17	0.14	0
1932	2001	19	25	0.14	0
1932	2001	19	26	0.22	0
1932	2001	20	17	0.01	0
1932	2001	20	25	0.21	0
1932	2001	20	26	0.14	0
1932	2001	21	17	0.04	0
1932	2001	21	25	0.12	0
1932	2001	21	26	0.01	0
1932	2001	22	25	0.04	0
1932	2001	22	26	0.04	0
1932	2001	23	25	0.01	0
1932	2001	23	26	0.19	0
1932	2001	24	25	5.84795321637427E-03	0
1932	2001	24	26	0.08	0
1932	2001	25	26	0.09	0
1932	2001	26	26	7.46268656716418E-03	0
1932	2002	1	17	0.01	0
1932	2002	1	25	0.06	0
1932	2002	1	26	0.04	0
1932	2002	2	25	0.02	0
1932	2002	2	26	8.23045267489712E-03	0
1932	2002	3	25	0.15	0
1932	2002	3	26	0.07	0
1932	2002	4	17	0.01	0
1932	2002	4	25	0.21	0
1932	2002	4	26	0.08	0
1932	2002	5	25	0.07	0
1932	2002	5	26	7.46268656716418E-03	0
1932	2002	6	25	0.07	0
1932	2002	6	26	0.02	0
1932	2002	7	25	0.17	0
1932	2002	7	26	0.22	0
1932	2002	8	25	0.05	0
1932	2002	9	25	0.06	0
1932	2002	9	26	0.03	0
1932	2002	10	25	0.02	0
1932	2002	11	17	0.04	0
1932	2002	11	25	0.1	0
1932	2002	11	26	0.14	0
1932	2002	12	17	0.02	0
1932	2002	12	25	0.12	0
1932	2002	12	26	0.09	0
1932	2002	13	25	0.06	0
1932	2002	13	26	0.06	0
1932	2002	14	17	0.05	0
1932	2002	14	25	0.1	0
1932	2002	14	26	0.02	0
1932	2002	15	17	0.1	0
1932	2002	15	25	0.46	0
1932	2002	15	26	0.54	0
1932	2002	16	17	0.01	0
1932	2002	16	25	0.34	0
1932	2002	16	26	0.49	0
1932	2002	17	17	0.5	0
1932	2002	17	25	1	0
1932	2002	17	26	0.94	0
1932	2002	18	17	0.25	0
1932	2002	18	25	0.55	0
1932	2002	18	26	0.45	0
1932	2002	19	17	0.12	0
1932	2002	19	25	0.13	0
1932	2002	19	26	0.01	0
1932	2002	20	17	0.1	0
1932	2002	20	25	0.4	0
1932	2002	20	26	0.21	0
1932	2002	21	17	0.01	0
1932	2002	21	25	0.14	0
1932	2002	21	26	0.04	0
1932	2002	22	17	0.03	0
1932	2002	22	25	0.02	0
1932	2002	22	25	0.07	0
1932	2002	22	26	0.05	0
1932	2002	22	26	0.1	0
1932	2002	23	25	0.07	0
1932	2002	23	26	0.1	0
1932	2002	24	25	0.1	0
1932	2002	24	26	0.09	0
1932	2002	25	25	0.03	0
1932	2002	25	26	0.09	0
1932	2002	26	25	0.02	0
1932	2002	26	26	0.08	0
1932	2003	1	25	0.01	0
1932	2003	1	26	4.11522633744856E-03	0
1932	2003	2	17	0.03	0
1932	2003	2	25	0.09	0
1932	2003	2	26	0.03	0
1932	2003	3	17	0.01	0
1932	2003	3	25	0.19	0
1932	2003	3	26	0.16	0
1932	2003	4	17	0.01	0
1932	2003	4	25	0.12	0
1932	2003	4	26	0.07	0
1932	2003	5	17	0.01	0
1932	2003	5	25	0.06	0
1932	2003	5	26	0.08	0
1932	2003	6	25	0.11	0
1932	2003	6	26	0.05	0
1932	2003	7	17	0.01	0
1932	2003	7	25	0.05	0
1932	2003	7	26	7.46268656716418E-03	0
1932	2003	8	26	0.02	0
1932	2003	9	17	0.01	0
1932	2003	9	25	0.01	0
1932	2003	9	26	0.04	0
1932	2003	10	26	0.02	0
1932	2003	11	17	0.01	0
1932	2003	11	25	0.14	0
1932	2003	11	26	0.14	0
1932	2003	12	17	0.08	0
1932	2003	12	25	0.2	0
1932	2003	12	26	0.26	0
1932	2003	13	17	0.07	0
1932	2003	13	25	0.15	0
1932	2003	13	26	0.08	0
1932	2003	14	17	0.22	0
1932	2003	14	25	0.09	0
1932	2003	14	26	0.05	0
1932	2003	15	17	1	0
1932	2003	15	25	0.95	0
1932	2003	15	26	0.4	0
1932	2003	16	17	0.38	0
1932	2003	16	25	0.43	0
1932	2003	16	26	0.19	0
1932	2003	17	17	0.4	0
1932	2003	17	25	0.8	0
1932	2003	17	26	0.63	0
1932	2003	18	17	0.17	0
1932	2003	18	17	0.29	0
1932	2003	18	25	0.2	0
1932	2003	18	25	0.22	0
1932	2003	18	26	0.08	0
1932	2003	18	26	0.21	0
1932	2003	19	17	0.17	0
1932	2003	19	25	0.2	0
1932	2003	19	26	0.21	0
1932	2003	20	17	0.06	0
1932	2003	20	25	0.2	0
1932	2003	20	26	0.06	0
1932	2003	21	17	0.04	0
1932	2003	21	25	0.21	0
1932	2003	21	26	0.02	0
1932	2003	22	17	0.05	0
1932	2003	22	25	0.04	0
1932	2003	22	26	0.02	0
1932	2003	23	17	0.03	0
1932	2003	23	25	0.1	0
1932	2003	23	26	0.21	0
1932	2003	24	25	0.15	0
1932	2003	24	26	0.19	0
1932	2003	25	25	0.08	0
1932	2003	25	26	0.05	0
1932	2003	26	25	0.06	0
1932	2003	26	26	0.03	0
1932	2004	1	25	8.13008130081301E-03	0
1932	2004	2	17	0.01	0
1932	2004	2	25	0.02	0
1932	2004	2	26	0.04	0
1932	2004	3	17	0.01	0
1932	2004	3	25	0.02	0
1932	2004	3	26	0.04	0
1932	2004	4	25	0.1	0
1932	2004	4	26	0.07	0
1932	2004	6	17	0.03	0
1932	2004	6	25	0.11	0
1932	2004	6	26	0.18	0
1932	2004	7	17	0.02	0
1932	2004	7	25	0.09	0
1932	2004	7	26	0.01	0
1932	2004	8	17	0.04	0
1932	2004	8	26	7.46268656716418E-03	0
1932	2004	9	17	0.01	0
1932	2004	9	25	0.03	0
1932	2004	9	26	0.02	0
1932	2004	10	25	0.04	0
1932	2004	10	26	0.01	0
1932	2004	11	25	0.12	0
1932	2004	11	26	0.21	0
1932	2004	12	17	0.03	0
1932	2004	12	25	0.08	0
1932	2004	12	26	0.02	0
1932	2004	13	17	0.03	0
1932	2004	13	25	0.11	0
1932	2004	13	26	0.02	0
1932	2004	14	17	0.01	0
1932	2004	14	25	0.28	0
1932	2004	14	26	0.04	0
1932	2004	15	17	0.15	0
1932	2004	15	25	0.15	0
1932	2004	15	26	0.02	0
1932	2004	16	17	0.4	0
1932	2004	16	25	0.54	0
1932	2004	16	26	0.45	0
1932	2004	17	17	0.7	0
1932	2004	17	25	0.74	0
1932	2004	17	26	0.27	0
1932	2004	18	17	0.27	0
1932	2004	18	25	0.59	0
1932	2004	18	26	0.42	0
1932	2004	19	17	0.28	0
1932	2004	19	25	0.65	0
1932	2004	19	26	0.6	0
1932	2004	20	17	0.11	0
1932	2004	20	25	0.32	0
1932	2004	20	26	0.22	0
1932	2004	21	17	0.02	0
1932	2004	21	25	0.15	0
1932	2004	21	26	0.2	0
1932	2004	22	25	0.04	0
1932	2004	22	26	0.19	0
1932	2004	23	17	0.05	0
1932	2004	23	25	0.08	0
1932	2004	23	26	0.12	0
1932	2004	24	25	0.02	0
1932	2004	24	26	0.06	0
1932	2004	25	25	0.08	0
1932	2004	25	26	0.12	0
1932	2004	26	25	0.08	0
1932	2004	26	26	0.09	0
1932	2005	1	17	0.02	0
1932	2005	1	25	0.03	0
1932	2005	1	26	0.08	0
1932	2005	2	25	0.02	0
1932	2005	3	17	0.01	0
1932	2005	3	25	0.3	0
1932	2005	3	26	0.17	0
1932	2005	4	17	0.06	0
1932	2005	4	25	0.25	0
1932	2005	4	26	0.12	0
1932	2005	5	17	0.04	0
1932	2005	5	25	0.1	0
1932	2005	5	26	0.07	0
1932	2005	6	17	0.01	0
1932	2005	6	25	0.16	0
1932	2005	6	26	0.23	0
1932	2005	7	25	0.02	0
1932	2005	8	25	0.04	0
1932	2005	8	26	0.07	0
1932	2005	9	25	0.02	0
1932	2005	9	26	0.06	0
1932	2005	10	25	0.04	0
1932	2005	10	26	0.06	0
1932	2005	12	17	0.02	0
1932	2005	12	25	0.23	0
1932	2005	12	26	0.15	0
1932	2005	13	17	0.01	0
1932	2005	13	25	0.12	0
1932	2005	13	26	0.03	0
1932	2005	14	17	0.1	0
1932	2005	14	25	0.36	0
1932	2005	14	26	0.08	0
1932	2005	15	17	0.45	0
1932	2005	15	25	1.24	0
1932	2005	15	26	0.74	0
1932	2005	16	17	0.2	0
1932	2005	16	25	0.68	0
1932	2005	16	26	0.54	0
1932	2005	17	17	0.86	0
1932	2005	17	25	1.03	0
1932	2005	17	26	0.53	0
1932	2005	18	17	0.38	0
1932	2005	18	25	0.5	0
1932	2005	18	26	0.09	0
1932	2005	19	17	0.16	0
1932	2005	19	25	0.28	0
1932	2005	19	26	0.18	0
1932	2005	20	17	0.01	0
1932	2005	20	25	0.08	0
1932	2005	20	26	0.04	0
1932	2005	21	17	0.04	0
1932	2005	21	25	0.05	0
1932	2005	21	26	0.12	0
1932	2005	22	17	0.02	0
1932	2005	22	25	0.06	0
1932	2005	22	25	0.08	0
1932	2005	22	26	0.03	0
1932	2005	22	26	0.05	0
1932	2005	23	17	0.03	0
1932	2005	23	25	0.17	0
1932	2005	23	26	0.16	0
1932	2005	24	17	0.03	0
1932	2005	24	25	0.08	0
1932	2005	24	26	0.11	0
1932	2005	25	26	0.16	0
1932	2005	26	25	0.02	0
1932	2005	26	26	0.08	0
1932	2006	1	25	0.04	0
1932	2006	1	26	0.02	0
1932	2006	2	25	0.05	0
1932	2006	3	26	0.01	0
1932	2006	4	25	0.01	0
1932	2006	4	26	0.01	0
1932	2006	5	17	0.01	0
1932	2006	5	25	0.1	0
1932	2006	5	26	0.03	0
1932	2006	6	17	0.05	0
1932	2006	6	25	0.12	0
1932	2006	6	26	0.06	0
1932	2006	7	25	0.06	0
1932	2006	8	25	0.01	0
1932	2006	9	25	0.02	0
1932	2006	10	25	0.05	0
1932	2006	10	26	0.03	0
1932	2006	11	25	0.07	0
1932	2006	11	26	0.04	0
1932	2006	12	17	0.05	0
1932	2006	12	25	0.04	0
1932	2006	12	26	0.01	0
1932	2006	13	17	0.32	0
1932	2006	13	25	0.42	0
1932	2006	13	26	0.27	0
1932	2006	14	17	0.25	0
1932	2006	14	25	0.2	0
1932	2006	14	26	0.23	0
1932	2006	15	17	0.46	0
1932	2006	15	25	0.51	0
1932	2006	15	26	0.3	0
1932	2006	16	17	0.23	0
1932	2006	16	25	0.32	0
1932	2006	16	26	0.12	0
1932	2006	17	17	0.37	0
1932	2006	17	25	0.44	0
1932	2006	17	26	0.22	0
1932	2006	18	17	0.38	0
1932	2006	18	25	0.25	0
1932	2006	18	26	0.04	0
1932	2006	19	17	0.09	0
1932	2006	19	25	0.06	0
1932	2006	19	26	0.11	0
1932	2006	20	17	0.27	0
1932	2006	20	25	0.14	0
1932	2006	20	26	0.09	0
1932	2006	21	17	0.19	0
1932	2006	21	25	0.09	0
1932	2006	21	26	0.14	0
1932	2006	22	17	0.04	0
1932	2006	22	25	0.1	0
1932	2006	22	26	0.11	0
1932	2006	23	17	0.04	0
1932	2006	23	25	0.05	0
1932	2006	23	26	0.18	0
1932	2006	24	17	0.01	0
1932	2006	24	25	0.07	0
1932	2006	24	26	0.02	0
1932	2006	25	17	0.02	0
1932	2006	25	25	0.07	0
1932	2006	25	26	0.03	0
1932	2006	26	25	0.03	0
1932	2007	1	25	0.07	0
1932	2007	1	26	0.07	0
1932	2007	2	25	0.06	0
1932	2007	2	26	0.02	0
1932	2007	3	17	0.03	0
1932	2007	3	25	0.07	0
1932	2007	3	26	0.13	0
1932	2007	4	17	0.05	0
1932	2007	4	25	0.06	0
1932	2007	4	26	0.17	0
1932	2007	5	17	0.03	0
1932	2007	5	25	0.06	0
1932	2007	5	26	0.14	0
1932	2007	7	25	0.08	0
1932	2007	7	26	0.05	0
1932	2007	8	25	0.02	0
1932	2007	8	26	0.07	0
1932	2007	10	17	0.02	0
1932	2007	10	25	0.08	0
1932	2007	10	26	0.09	0
1932	2007	11	17	0.02	0
1932	2007	11	25	0.05	0
1932	2007	11	26	7.46268656716418E-03	0
1932	2007	12	17	0.05	0
1932	2007	12	25	0.07	0
1932	2007	12	26	0.01	0
1932	2007	13	17	0.01	0
1932	2007	13	25	0.02	0
1932	2007	14	17	0.13	0
1932	2007	14	25	0.24	0
1932	2007	14	26	0.04	0
1932	2007	15	17	0.18	0
1932	2007	15	25	0.37	0
1932	2007	15	26	0.12	0
1932	2007	16	17	0.43	0
1932	2007	16	25	0.67	0
1932	2007	16	26	0.29	0
1932	2007	17	17	0.19	0
1932	2007	17	25	0.2	0
1932	2007	17	26	0.14	0
1932	2007	18	17	0.14	0
1932	2007	18	17	0.26	0
1932	2007	18	25	0.23	0
1932	2007	18	25	0.45	0
1932	2007	18	26	0.15	0
1932	2007	18	26	0.28	0
1932	2007	19	17	0.14	0
1932	2007	19	25	0.39	0
1932	2007	19	26	0.4	0
1932	2007	20	17	0.02	0
1932	2007	20	25	0.17	0
1932	2007	20	26	0.27	0
1932	2007	21	25	0.15	0
1932	2007	21	26	0.22	0
1932	2007	22	25	0.07	0
1932	2007	22	25	0.09	0
1932	2007	22	26	0.09	0
1932	2007	22	26	0.13	0
1932	2007	23	25	0.09	0
1932	2007	23	26	0.22	0
1932	2007	24	25	0.02	0
1932	2007	24	26	0.09	0
1932	2007	25	25	7.63358778625954E-03	0
1932	2007	26	25	0.02	0
2214	2000	1	26	0.01	0
2214	2000	2	26	5.86635586635587E-03	0
2214	2000	4	26	0.07	0
2214	2000	5	26	0.07	0
2214	2000	6	26	0.11	0
2214	2000	7	26	0.1	0
2214	2000	8	26	0.09	0
2214	2000	9	26	0.15	0
2214	2000	10	26	0.11	0
2214	2000	11	26	0.06	0
2214	2000	13	26	0.23	0
2214	2000	14	26	0.31	0
2214	2000	15	26	0.3	0
2214	2000	16	26	0.17	0
2214	2000	17	26	0.27	0
2214	2000	19	26	0.1	0
2214	2000	20	26	0.2	0
2214	2000	21	26	0.08	0
2214	2000	22	26	0.08	0
2214	2000	23	26	0.05	0
2214	2000	26	26	0.04	0
2214	2001	8	26	0.08	0
2214	2001	11	26	0.06	0
2214	2001	12	26	0.13	0
2214	2001	13	26	0.06	0
2214	2001	14	26	0.14	0
2214	2001	15	26	0.65	0
2214	2001	16	26	0.41	0
2214	2001	17	26	0.24	0
2214	2001	18	26	0.1	0
2214	2001	20	26	0.07	0
2214	2001	21	26	0.11	0
2214	2001	23	26	0.05	0
2214	2001	24	26	0.02	0
2214	2001	25	26	0.01	0
2214	2001	26	26	0.03	0
2214	2002	1	26	0.05	0
2214	2002	2	26	0.06	0
2214	2002	3	26	0.07	0
2214	2002	4	26	0.03	0
2214	2002	5	26	0.06	0
2214	2002	6	26	0.1	0
2214	2002	7	26	0.04	0
2214	2002	8	26	0.12	0
2214	2002	9	26	0.05	0
2214	2002	10	26	0.06	0
2214	2002	11	26	0.07	0
2214	2002	12	26	0.07	0
2214	2002	13	26	0.05	0
2214	2002	14	26	0.09	0
2214	2002	16	26	0.32	0
2214	2002	17	26	0.19	0
2214	2002	18	26	0.12	0
2214	2002	19	26	0.09	0
2214	2002	20	26	0.09	0
2214	2002	21	26	0.05	0
2214	2002	23	26	0.07	0
2214	2002	24	26	0.04	0
2214	2002	25	26	0.08	0
2214	2002	26	26	0.03	0
2214	2003	1	26	0.06	0
2214	2003	2	26	0.12	0
2214	2003	3	26	0.12	0
2214	2003	4	26	0.02	0
2214	2003	5	26	0.07	0
2214	2003	5	26	0.15	0
2214	2003	6	26	0.08	0
2214	2003	7	26	0.02	0
2214	2003	9	26	0.03	0
2214	2003	10	26	0.15	0
2214	2003	11	26	0.07	0
2214	2003	12	26	0.3	0
2214	2003	13	26	0.1	0
2214	2003	14	26	0.22	0
2214	2003	15	26	0.4	0
2214	2003	16	26	0.38	0
2214	2003	17	26	0.39	0
2214	2003	18	26	0.05	0
2214	2003	19	26	0.12	0
2214	2003	20	26	0.15	0
2214	2003	21	26	0.05	0
2214	2003	22	26	0.08	0
2214	2003	22	26	0.14	0
2214	2003	23	26	0.08	0
2214	2003	24	26	0.14	0
2214	2003	25	26	0.06	0
2214	2003	26	26	0.01	0
2214	2004	1	26	0.01	0
2214	2004	2	26	0.04	0
2214	2004	3	26	0.06	0
2214	2004	4	26	0.02	0
2214	2004	5	26	0.02	0
2214	2004	6	26	0.06	0
2214	2004	7	26	0.06	0
2214	2004	8	26	0.03	0
2214	2004	9	26	0.04	0
2214	2004	10	26	0.03	0
2214	2004	11	26	0.07	0
2214	2004	12	26	0.06	0
2214	2004	13	26	0.28	0
2214	2004	14	26	0.12	0
2214	2004	15	26	0.11	0
2214	2004	16	26	0.11	0
2214	2004	17	26	0.22	0
2214	2004	18	26	0.1	0
2214	2004	19	26	0.17	0
2214	2004	20	26	0.02	0
2214	2004	21	26	0.08	0
2214	2004	22	26	0.02	0
2214	2004	23	26	0.06	0
2214	2004	24	26	0.06	0
2214	2005	1	26	0.02	0
2214	2005	2	26	0.01	0
2214	2005	3	26	0.01	0
2214	2005	5	26	0.18	0
2214	2005	6	26	0.09	0
2214	2005	7	26	0.08	0
2214	2005	8	26	0.05	0
2214	2005	9	26	0.08	0
2214	2005	10	26	0.05	0
2214	2005	11	26	0.05	0
2214	2005	12	26	0.05	0
2214	2005	13	26	0.48	0
2214	2005	14	26	0.52	0
2214	2005	15	26	0.46	0
2214	2005	16	26	0.25	0
2214	2005	17	26	0.12	0
2214	2005	18	26	0.11	0
2214	2005	19	26	0.07	0
2214	2005	20	26	0.08	0
2214	2005	21	26	0.12	0
2214	2005	22	26	0.03	0
2214	2005	22	26	0.09	0
2214	2005	23	26	0.03	0
2214	2005	24	26	0.01	0
2214	2005	25	26	6.92322314645481E-03	0
2214	2005	26	26	0.03	0
2214	2006	1	26	0.01	0
2214	2006	3	26	0.03	0
2214	2006	4	26	0.01	0
2214	2006	5	26	0.06	0
2214	2006	6	26	0.03	0
2214	2006	7	26	0.05	0
2214	2006	9	26	0.07	0
2214	2006	10	26	0.02	0
2214	2006	11	26	0.2	0
2214	2006	12	26	0.1	0
2214	2006	13	26	0.34	0
2214	2006	14	26	0.15	0
2214	2006	15	26	0.27	0
2214	2006	16	26	0.42	0
2214	2006	17	26	0.25	0
2214	2006	18	26	0.16	0
2214	2006	19	26	0.16	0
2214	2006	20	26	0.06	0
2214	2006	21	26	0.17	0
2214	2006	22	26	0.08	0
2214	2006	23	26	0.05	0
2214	2006	24	26	0.04	0
2214	2006	25	26	0.08	0
2214	2006	26	26	0.02	0
2214	2007	1	26	0.02	0
2214	2007	2	26	0.06	0
2214	2007	3	26	0.04	0
2214	2007	4	26	0.17	0
2214	2007	5	26	0.03	0
2214	2007	5	26	0.08	0
2214	2007	6	26	0.03	0
2214	2007	7	26	0.01	0
2214	2007	8	26	0.02	0
2214	2007	10	26	0.08	0
2214	2007	11	26	0.52	0
2214	2007	14	26	0.46	0
2214	2007	15	26	0.27	0
2214	2007	17	26	0.13	0
2214	2007	18	26	0.18	0
2214	2007	19	26	0.1	0
2214	2007	20	26	0.04	0
2214	2007	21	26	0.03	0
2214	2007	22	26	0.01	0
2214	2007	23	26	0.03	0
2214	2007	24	26	0.01	0
2214	2007	25	26	0.04	0
2214	2007	26	26	2.02020202020202E-03	0
2239	2000	2	26	4.82522796352584E-03	0
2239	2000	2	27	7.04545454545455E-03	0
2239	2000	2	31	0.01	0
2239	2000	4	26	3.57142857142857E-03	0
2239	2000	4	27	9.31818181818182E-03	0
2239	2000	4	28	0.01	0
2239	2000	4	31	0.005	0
2239	2000	4	32	8.62068965517241E-03	0
2239	2000	5	16	9.52380952380952E-03	0
2239	2000	5	26	5.35714285714286E-03	0
2239	2000	5	27	0.005	0
2239	2000	5	28	0.02	0
2239	2000	5	31	8.86100386100386E-03	0
2239	2000	6	27	0.01	0
2239	2000	6	28	0.02	0
2239	2000	6	31	0.01	0
2239	2000	6	32	0.03	0
2239	2000	8	16	6.34920634920635E-03	0
2239	2000	8	27	0.0025	0
2239	2000	8	28	9.52380952380952E-03	0
2239	2000	8	31	0.01	0
2239	2000	10	27	0.005	0
2239	2000	10	28	0.02	0
2239	2000	10	32	0.01	0
2239	2000	11	16	9.52380952380952E-03	0
2239	2000	11	26	4.82522796352584E-03	0
2239	2000	11	27	4.77272727272727E-03	0
2239	2000	11	28	3.17460317460317E-03	0
2239	2000	11	31	3.86100386100386E-03	0
2239	2000	12	16	0.02	0
2239	2000	12	26	3.57142857142857E-03	0
2239	2000	12	27	7.27272727272727E-03	0
2239	2000	12	28	0.01	0
2239	2000	12	31	0.01	0
2239	2000	12	32	8.62068965517241E-03	0
2239	2000	13	16	0.08	0
2239	2000	13	26	0.01	0
2239	2000	13	27	0.01	0
2239	2000	13	28	0.01	0
2239	2000	13	31	0.05	0
2239	2000	13	32	8.62068965517241E-03	0
2239	2000	15	16	0.14	0
2239	2000	15	26	0.01	0
2239	2000	15	27	0.02	0
2239	2000	15	28	0.02	0
2239	2000	15	31	0.08	0
2239	2000	15	32	0.06	0
2239	2000	16	16	0.17	0
2239	2000	16	26	0.05	0
2239	2000	16	27	0.02	0
2239	2000	16	28	0.05	0
2239	2000	16	31	0.17	0
2239	2000	16	32	0.04	0
2239	2000	17	16	0.08	0
2239	2000	17	26	0.04	0
2239	2000	17	27	0.06	0
2239	2000	17	28	0.03	0
2239	2000	17	31	0.27	0
2239	2000	17	32	0.07	0
2239	2000	18	16	0.06	0
2239	2000	18	26	0.04	0
2239	2000	18	27	0.04	0
2239	2000	18	28	0.04	0
2239	2000	18	31	0.08	0
2239	2000	19	16	0.13	0
2239	2000	19	26	0.04	0
2239	2000	19	27	0.08	0
2239	2000	19	28	0.09	0
2239	2000	19	31	0.16	0
2239	2000	20	16	0.01	0
2239	2000	20	26	0.01	0
2239	2000	20	27	0.03	0
2239	2000	20	28	9.52380952380952E-03	0
2239	2000	20	31	0.07	0
2239	2000	21	16	0.02	0
2239	2000	21	26	1.78571428571429E-03	0
2239	2000	21	27	0.01	0
2239	2000	21	28	0.01	0
2239	2000	21	31	0.03	0
2239	2000	22	16	3.17460317460317E-03	0
2239	2000	22	27	0.01	0
2239	2000	22	28	0.01	0
2239	2000	22	31	0.07	0
2239	2000	24	16	3.17460317460317E-03	0
2239	2000	24	26	1.78571428571429E-03	0
2239	2000	24	28	9.52380952380952E-03	0
2239	2000	24	31	8.40645840645841E-03	0
2239	2000	24	32	0.02	0
2239	2000	25	27	7.27272727272727E-03	0
2239	2000	25	31	0.04	0
2239	2000	26	27	7.27272727272727E-03	0
2239	2000	26	31	0.04	0
2239	2002	2	26	0.01	0
2239	2002	2	27	0.0025	0
2239	2002	2	28	3.17460317460317E-03	0
2239	2002	2	32	8.62068965517241E-03	0
2239	2002	4	16	9.52380952380952E-03	0
2239	2002	4	26	7.86474164133739E-03	0
2239	2002	4	27	7.04545454545455E-03	0
2239	2002	4	28	0.02	0
2239	2002	4	31	0.02	0
2239	2002	4	32	0.02	0
2239	2002	6	16	3.17460317460317E-03	0
2239	2002	6	26	4.82522796352584E-03	0
2239	2002	6	27	0.01	0
2239	2002	6	28	0.01	0
2239	2002	6	31	0.03	0
2239	2002	6	32	0.01	0
2239	2002	8	26	1.78571428571429E-03	0
2239	2002	8	27	4.77272727272727E-03	0
2239	2002	8	28	9.52380952380952E-03	0
2239	2002	8	31	5.61797752808989E-03	0
2239	2002	8	32	8.62068965517241E-03	0
2239	2002	11	16	0.02	0
2239	2002	11	26	3.57142857142857E-03	0
2239	2002	11	27	4.77272727272727E-03	0
2239	2002	11	28	0.01	0
2239	2002	11	32	8.62068965517241E-03	0
2239	2002	14	16	0.08	0
2239	2002	14	26	3.57142857142857E-03	0
2239	2002	14	27	0.02	0
2239	2002	14	31	0.07	0
2239	2002	15	16	0.1	0
2239	2002	15	26	0.03	0
2239	2002	15	27	0.04	0
2239	2002	15	28	6.34920634920635E-03	0
2239	2002	15	31	0.15	0
2239	2002	15	32	0.06	0
2239	2002	16	16	0.12	0
2239	2002	16	26	0.04	0
2239	2002	16	27	0.09	0
2239	2002	16	28	0.03	0
2239	2002	16	31	0.22	0
2239	2002	16	32	0.06	0
2239	2002	17	16	0.15	0
2239	2002	17	26	0.04	0
2239	2002	17	27	0.11	0
2239	2002	17	28	0.05	0
2239	2002	17	31	0.31	0
2239	2002	17	32	0.03	0
2239	2002	18	16	0.06	0
2239	2002	18	26	0.02	0
2239	2002	18	27	0.05	0
2239	2002	18	28	0.02	0
2239	2002	18	31	0.16	0
2239	2002	18	32	0.02	0
2239	2002	20	16	0.02	0
2239	2002	20	26	0.02	0
2239	2002	20	27	0.04	0
2239	2002	20	28	0.02	0
2239	2002	20	31	0.05	0
2239	2002	20	32	8.62068965517241E-03	0
2239	2002	21	16	0.02	0
2239	2002	21	26	6.61094224924012E-03	0
2239	2002	21	27	0.03	0
2239	2002	21	28	6.34920634920635E-03	0
2239	2002	21	31	0.08	0
2239	2002	21	32	0.01	0
2239	2002	22	16	9.52380952380952E-03	0
2239	2002	22	26	7.14285714285714E-03	0
2239	2002	22	26	9.65045592705167E-03	0
2239	2002	22	27	0.01	0
2239	2002	22	27	0.02	0
2239	2002	22	28	6.34920634920635E-03	0
2239	2002	22	28	0.03	0
2239	2002	22	31	0.01	0
2239	2002	22	31	0.04	0
2239	2002	22	32	0.04	0
2239	2002	23	16	9.52380952380952E-03	0
2239	2002	23	26	9.65045592705167E-03	0
2239	2002	23	27	0.01	0
2239	2002	23	28	6.34920634920635E-03	0
2239	2002	23	31	0.01	0
2239	2003	2	16	3.17460317460317E-03	0
2239	2003	2	28	3.17460317460317E-03	0
2239	2003	2	31	0.005	0
2239	2003	3	16	6.34920634920635E-03	0
2239	2003	3	26	0.02	0
2239	2003	3	27	9.77272727272727E-03	0
2239	2003	3	28	0.01	0
2239	2003	3	31	0.01	0
2239	2003	5	16	0.02	0
2239	2003	5	26	0.01	0
2239	2003	5	27	0.01	0
2239	2003	5	28	3.17460317460317E-03	0
2239	2003	5	31	0.04	0
2239	2003	5	32	0.01	0
2239	2003	6	16	0.01	0
2239	2003	6	26	0.01	0
2239	2003	6	27	9.77272727272727E-03	0
2239	2003	6	31	0.01	0
2239	2003	7	16	6.34920634920635E-03	0
2239	2003	7	26	3.57142857142857E-03	0
2239	2003	7	27	9.54545454545454E-03	0
2239	2003	7	28	0.01	0
2239	2003	7	31	0.02	0
2239	2003	8	16	3.17460317460317E-03	0
2239	2003	8	26	4.82522796352584E-03	0
2239	2003	8	27	0.0025	0
2239	2003	8	31	4.54545454545455E-03	0
2239	2003	9	16	3.17460317460317E-03	0
2239	2003	9	26	3.57142857142857E-03	0
2239	2003	9	27	0.01	0
2239	2003	9	28	3.17460317460317E-03	0
2239	2003	11	16	0.02	0
2239	2003	11	26	6.61094224924012E-03	0
2239	2003	11	27	0.01	0
2239	2003	11	28	3.17460317460317E-03	0
2239	2003	11	31	8.86100386100386E-03	0
2239	2003	12	16	0.07	0
2239	2003	12	26	0.02	0
2239	2003	12	27	0.03	0
2239	2003	12	28	9.52380952380952E-03	0
2239	2003	12	31	0.14	0
2239	2003	12	32	0.04	0
2239	2003	13	16	0.07	0
2239	2003	13	26	0.02	0
2239	2003	13	27	0.03	0
2239	2003	13	28	9.52380952380952E-03	0
2239	2003	13	31	0.14	0
2239	2003	13	32	0.04	0
2239	2003	14	16	0.1	0
2239	2003	14	26	0.05	0
2239	2003	14	27	0.05	0
2239	2003	14	28	0.02	0
2239	2003	14	31	0.19	0
2239	2003	14	32	0.09	0
2239	2003	15	16	0.11	0
2239	2003	15	26	0.07	0
2239	2003	15	27	0.1	0
2239	2003	15	28	0.05	0
2239	2003	15	31	0.44	0
2239	2003	15	32	0.12	0
2239	2003	16	16	0.04	0
2239	2003	16	26	0.03	0
2239	2003	16	27	0.01	0
2239	2003	16	28	0.03	0
2239	2003	16	31	0.15	0
2239	2003	16	32	0.02	0
2239	2003	17	16	0.08	0
2239	2003	17	26	0.02	0
2239	2003	17	27	0.02	0
2239	2003	17	28	0.01	0
2239	2003	17	31	0.01	0
2239	2003	18	16	0.11	0
2239	2003	18	26	0.01	0
2239	2003	18	27	0.02	0
2239	2003	18	28	0.01	0
2239	2003	18	31	0.17	0
2239	2003	18	32	0.02	0
2239	2003	20	16	0.06	0
2239	2003	20	26	0.06	0
2239	2003	20	27	0.08	0
2239	2003	20	28	6.34920634920635E-03	0
2239	2003	20	31	0.14	0
2239	2003	20	32	8.62068965517241E-03	0
2239	2003	21	16	0.04	0
2239	2003	21	26	0.03	0
2239	2003	21	27	0.06	0
2239	2003	21	28	3.17460317460317E-03	0
2239	2003	21	31	0.08	0
2239	2003	23	16	0.02	0
2239	2003	23	26	0.01	0
2239	2003	23	27	0.005	0
2239	2003	23	28	3.17460317460317E-03	0
2239	2003	23	31	0.05	0
2239	2003	23	32	0.03	0
2239	2003	24	16	0.02	0
2239	2003	24	26	5.35714285714286E-03	0
2239	2003	24	27	7.04545454545455E-03	0
2239	2003	24	28	6.34920634920635E-03	0
2239	2003	24	31	0.005	0
2239	2003	25	26	6.61094224924012E-03	0
2239	2003	25	27	9.31818181818182E-03	0
2239	2003	25	28	0.01	0
2239	2003	25	31	0.03	0
2239	2003	25	32	8.62068965517241E-03	0
2239	2003	26	16	9.52380952380952E-03	0
2239	2003	26	26	8.39665653495441E-03	0
2239	2003	26	27	0.01	0
2239	2003	26	28	0.01	0
2239	2003	26	31	4.54545454545455E-03	0
2239	2003	26	32	0.01	0
2239	2004	4	16	6.34920634920635E-03	0
2239	2004	4	26	3.03951367781155E-03	0
2239	2004	4	27	0.01	0
2239	2004	4	28	6.34920634920635E-03	0
2239	2004	4	31	0.01	0
2239	2004	5	16	6.34920634920635E-03	0
2239	2004	5	26	3.03951367781155E-03	0
2239	2004	5	27	9.31818181818182E-03	0
2239	2004	5	28	0.01	0
2239	2004	5	31	0.02	0
2239	2004	5	32	8.62068965517241E-03	0
2239	2004	7	16	6.34920634920635E-03	0
2239	2004	7	26	3.57142857142857E-03	0
2239	2004	7	28	3.17460317460317E-03	0
2239	2004	7	31	3.86100386100386E-03	0
2239	2004	8	16	3.17460317460317E-03	0
2239	2004	8	26	3.57142857142857E-03	0
2239	2004	8	27	4.54545454545455E-03	0
2239	2004	8	28	3.17460317460317E-03	0
2239	2004	8	31	0.01	0
2239	2004	9	16	6.34920634920635E-03	0
2239	2004	11	16	9.52380952380952E-03	0
2239	2004	11	26	0.01	0
2239	2004	11	27	0.02	0
2239	2004	11	28	0.02	0
2239	2004	11	31	0.02	0
2239	2004	16	16	0.1	0
2239	2004	16	26	0.08	0
2239	2004	16	27	0.08	0
2239	2004	16	28	9.52380952380952E-03	0
2239	2004	16	31	0.19	0
2239	2004	16	32	0.1	0
2239	2004	17	16	0.08	0
2239	2004	17	26	0.09	0
2239	2004	17	27	0.06	0
2239	2004	17	28	0.03	0
2239	2004	17	31	0.21	0
2239	2004	17	32	0.08	0
2239	2004	18	16	0.1	0
2239	2004	18	26	0.05	0
2239	2004	18	27	0.07	0
2239	2004	18	28	0.07	0
2239	2004	18	31	0.16	0
2239	2004	18	32	0.11	0
2239	2004	19	16	0.04	0
2239	2004	19	26	0.01	0
2239	2004	19	27	0.03	0
2239	2004	19	28	0.02	0
2239	2004	19	31	0.15	0
2239	2004	19	32	0.01	0
2239	2004	21	16	0.03	0
2239	2004	21	26	0.01	0
2239	2004	21	27	0.01	0
2239	2004	21	31	0.02	0
2239	2004	23	16	6.34920634920635E-03	0
2239	2004	23	26	8.39665653495441E-03	0
2239	2004	23	27	0.01	0
2239	2004	23	28	6.34920634920635E-03	0
2239	2004	23	31	0.02	0
2239	2004	24	16	3.17460317460317E-03	0
2239	2004	24	27	6.81818181818182E-03	0
2239	2005	5	16	9.52380952380952E-03	0
2239	2005	5	27	0.01	0
2239	2005	5	31	0.005	0
2239	2005	5	32	8.62068965517241E-03	0
2239	2005	6	16	6.34920634920635E-03	0
2239	2005	6	26	0.01	0
2239	2005	6	27	0.03	0
2239	2005	6	28	0.02	0
2239	2005	6	31	0.03	0
2239	2005	6	32	0.03	0
2239	2005	7	27	0.02	0
2239	2005	7	28	0.01	0
2239	2005	7	31	0.02	0
2239	2005	7	32	0.01	0
2239	2005	9	26	1.78571428571429E-03	0
2239	2005	9	27	0.005	0
2239	2005	10	16	9.52380952380952E-03	0
2239	2005	10	26	1.78571428571429E-03	0
2239	2005	10	27	0.03	0
2239	2005	10	28	0.02	0
2239	2005	10	31	0.02	0
2239	2005	11	16	9.52380952380952E-03	0
2239	2005	11	27	0.02	0
2239	2005	11	28	6.34920634920635E-03	0
2239	2005	11	31	5.61797752808989E-03	0
2239	2005	12	16	0.01	0
2239	2005	12	26	0.01	0
2239	2005	12	27	4.77272727272727E-03	0
2239	2005	12	28	6.34920634920635E-03	0
2239	2005	12	31	0.02	0
2239	2005	13	16	0.08	0
2239	2005	13	26	0.04	0
2239	2005	13	27	0.03	0
2239	2005	13	28	0.03	0
2239	2005	13	31	0.04	0
2239	2005	13	32	0.02	0
2239	2005	16	16	0.04	0
2239	2005	16	26	0.03	0
2239	2005	16	27	0.02	0
2239	2005	16	28	0.01	0
2239	2005	16	31	0.04	0
2239	2005	16	32	0.01	0
2239	2005	17	16	0.03	0
2239	2005	17	26	0.04	0
2239	2005	17	27	0.03	0
2239	2005	17	31	0.1	0
2239	2005	17	32	0.02	0
2239	2005	19	16	0.05	0
2239	2005	19	26	0.02	0
2239	2005	19	27	0.04	0
2239	2005	19	28	0.03	0
2239	2005	19	31	0.16	0
2239	2005	19	32	0.01	0
2239	2005	20	16	0.02	0
2239	2005	20	26	7.14285714285714E-03	0
2239	2005	20	27	0.03	0
2239	2005	20	28	0.01	0
2239	2005	20	31	0.06	0
2239	2005	20	32	8.62068965517241E-03	0
2239	2005	21	16	3.17460317460317E-03	0
2239	2005	21	26	7.86474164133739E-03	0
2239	2005	21	27	4.77272727272727E-03	0
2239	2005	21	28	3.17460317460317E-03	0
2239	2005	21	31	0.06	0
2239	2005	22	16	6.34920634920635E-03	0
2239	2005	22	16	0.01	0
2239	2005	22	26	7.14285714285714E-03	0
2239	2005	22	26	0.02	0
2239	2005	22	27	4.77272727272727E-03	0
2239	2005	22	27	0.01	0
2239	2005	22	28	3.17460317460317E-03	0
2239	2005	22	28	6.34920634920635E-03	0
2239	2005	22	31	0.04	0
2239	2005	22	31	0.05	0
2239	2005	23	16	0.01	0
2239	2005	23	26	7.14285714285714E-03	0
2239	2005	23	27	0.01	0
2239	2005	23	28	6.34920634920635E-03	0
2239	2005	23	31	0.05	0
2239	2005	24	16	3.17460317460317E-03	0
2239	2005	24	26	5.35714285714286E-03	0
2239	2005	24	27	0.01	0
2239	2005	24	28	6.34920634920635E-03	0
2239	2005	24	31	0.005	0
2239	2005	24	32	8.62068965517241E-03	0
2239	2005	25	16	3.17460317460317E-03	0
2239	2005	25	26	0.01	0
2239	2005	25	27	0.0075	0
2239	2005	25	28	0.01	0
2239	2005	25	31	0.005	0
2239	2005	25	32	0.01	0
2239	2005	26	16	3.17460317460317E-03	0
2239	2005	26	27	0.0075	0
2239	2005	26	28	9.52380952380952E-03	0
2239	2005	26	32	8.62068965517241E-03	0
2239	2006	1	16	3.17460317460317E-03	0
2239	2006	1	26	1.78571428571429E-03	0
2239	2006	1	27	0.01	0
2239	2006	1	28	3.17460317460317E-03	0
2239	2006	1	31	0.01	0
2239	2006	1	32	8.62068965517241E-03	0
2239	2006	2	26	1.78571428571429E-03	0
2239	2006	2	31	0.005	0
2239	2006	3	26	1.78571428571429E-03	0
2239	2006	3	31	0.005	0
2239	2006	4	26	6.0790273556231E-03	0
2239	2006	4	27	0.0025	0
2239	2006	4	28	3.17460317460317E-03	0
2239	2006	4	31	3.86100386100386E-03	0
2239	2006	5	26	6.0790273556231E-03	0
2239	2006	5	27	0.0025	0
2239	2006	5	28	3.17460317460317E-03	0
2239	2006	5	31	3.86100386100386E-03	0
2239	2006	6	16	3.17460317460317E-03	0
2239	2006	6	26	6.61094224924012E-03	0
2239	2006	6	27	2.27272727272727E-03	0
2239	2006	6	28	3.17460317460317E-03	0
2239	2006	6	31	0.02	0
2239	2006	6	32	8.62068965517241E-03	0
2239	2006	7	27	2.27272727272727E-03	0
2239	2006	7	28	0.01	0
2239	2006	8	32	0.01	0
2239	2006	9	16	6.34920634920635E-03	0
2239	2006	9	27	0.005	0
2239	2006	9	27	0.01	0
2239	2006	9	31	9.47898138909375E-03	0
2239	2006	9	31	0.01	0
2239	2006	9	32	0.07	0
2239	2006	10	27	9.54545454545454E-03	0
2239	2006	10	31	0.005	0
2239	2006	11	26	5.35714285714286E-03	0
2239	2006	11	27	0.01	0
2239	2006	11	28	3.17460317460317E-03	0
2239	2006	11	31	0.01	0
2239	2006	11	32	8.62068965517241E-03	0
2239	2006	12	26	5.35714285714286E-03	0
2239	2006	12	27	7.27272727272727E-03	0
2239	2006	12	28	3.17460317460317E-03	0
2239	2006	12	31	7.72200772200772E-03	0
2239	2006	12	32	8.62068965517241E-03	0
2239	2006	13	16	0.05	0
2239	2006	13	27	0.01	0
2239	2006	13	28	0.03	0
2239	2006	13	31	0.01	0
2239	2006	13	32	0.03	0
2239	2006	14	16	0.07	0
2239	2006	14	26	0.14	0
2239	2006	14	27	0.14	0
2239	2006	14	28	0.01	0
2239	2006	14	31	0.15	0
2239	2006	14	32	0.12	0
2239	2006	15	16	0.09	0
2239	2006	15	26	0.17	0
2239	2006	15	27	0.17	0
2239	2006	15	28	0.03	0
2239	2006	15	31	0.21	0
2239	2006	15	32	0.15	0
2239	2006	16	16	0.04	0
2239	2006	16	26	0.1	0
2239	2006	16	27	0.07	0
2239	2006	16	28	0.03	0
2239	2006	16	31	0.15	0
2239	2006	16	32	0.06	0
2239	2006	17	16	0.09	0
2239	2006	17	26	0.08	0
2239	2006	17	27	0.08	0
2239	2006	17	28	0.04	0
2239	2006	17	31	0.28	0
2239	2006	17	32	0.06	0
2239	2006	18	16	0.04	0
2239	2006	18	26	0.04	0
2239	2006	18	27	0.02	0
2239	2006	18	31	0.11	0
2239	2006	18	32	8.62068965517241E-03	0
2239	2006	19	16	6.34920634920635E-03	0
2239	2006	19	26	0.01	0
2239	2006	19	27	0.02	0
2239	2006	19	28	0.01	0
2239	2006	19	31	0.15	0
2239	2006	19	32	8.62068965517241E-03	0
2239	2006	20	26	6.61094224924012E-03	0
2239	2006	20	27	0.01	0
2239	2006	20	28	6.34920634920635E-03	0
2239	2006	20	31	0.06	0
2239	2006	20	32	8.62068965517241E-03	0
2239	2006	21	16	3.17460317460317E-03	0
2239	2006	21	26	0.01	0
2239	2006	21	27	0.01	0
2239	2006	21	28	6.34920634920635E-03	0
2239	2006	21	31	0.03	0
2239	2006	21	32	8.62068965517241E-03	0
2239	2006	22	16	3.17460317460317E-03	0
2239	2006	22	26	0.01	0
2239	2006	22	27	7.27272727272727E-03	0
2239	2006	22	28	0.01	0
2239	2006	22	31	0.05	0
2239	2006	22	32	8.62068965517241E-03	0
2239	2006	23	16	9.52380952380952E-03	0
2239	2006	23	26	0.02	0
2239	2006	23	27	0.01	0
2239	2006	23	28	0.01	0
2239	2006	23	31	0.01	0
2239	2006	23	32	0.01	0
2239	2007	1	16	0.01	0
2239	2007	1	26	0.02	0
2239	2007	1	27	0.0025	0
2239	2007	1	28	9.52380952380952E-03	0
2239	2007	1	31	0.04	0
2239	2007	2	16	6.34920634920635E-03	0
2239	2007	2	28	9.52380952380952E-03	0
2239	2007	2	31	0.01	0
2239	2007	3	16	0.01	0
2239	2007	3	26	0.02	0
2239	2007	3	27	0.01	0
2239	2007	3	28	0.01	0
2239	2007	3	31	0.02	0
2239	2007	5	16	0.01	0
2239	2007	5	26	8.39665653495441E-03	0
2239	2007	5	27	0.005	0
2239	2007	5	28	0.04	0
2239	2007	5	31	0.02	0
2239	2007	5	32	0.01	0
2239	2007	6	16	0.01	0
2239	2007	6	27	0.01	0
2239	2007	6	28	6.34920634920635E-03	0
2239	2007	6	31	0.03	0
2239	2007	6	32	8.62068965517241E-03	0
2239	2007	7	16	3.17460317460317E-03	0
2239	2007	7	28	6.34920634920635E-03	0
2239	2007	7	31	0.01	0
2239	2007	8	26	1.78571428571429E-03	0
2239	2007	8	27	0.0025	0
2239	2007	8	28	6.34920634920635E-03	0
2239	2007	8	31	3.86100386100386E-03	0
2239	2007	9	16	3.17460317460317E-03	0
2239	2007	9	16	0.01	0
2239	2007	9	26	3.57142857142857E-03	0
2239	2007	9	27	4.77272727272727E-03	0
2239	2007	9	27	6.81818181818182E-03	0
2239	2007	9	28	9.52380952380952E-03	0
2239	2007	9	31	5.61797752808989E-03	0
2239	2007	9	31	0.01	0
2239	2007	9	32	0.01	0
2239	2007	10	16	0.01	0
2239	2007	10	26	3.57142857142857E-03	0
2239	2007	10	27	6.81818181818182E-03	0
2239	2007	10	28	9.52380952380952E-03	0
2239	2007	10	31	0.01	0
2239	2007	10	32	0.01	0
2239	2007	11	16	0.04	0
2239	2007	11	26	0.01	0
2239	2007	11	27	0.04	0
2239	2007	11	28	0.02	0
2239	2007	11	31	0.04	0
2239	2007	11	32	0.03	0
2239	2007	12	16	0.01	0
2239	2007	12	26	5.35714285714286E-03	0
2239	2007	12	27	0.02	0
2239	2007	12	28	0.01	0
2239	2007	12	31	0.07	0
2239	2007	12	32	0.01	0
2239	2007	13	16	0.04	0
2239	2007	13	26	8.92857142857143E-03	0
2239	2007	13	27	0.05	0
2239	2007	13	28	3.17460317460317E-03	0
2239	2007	13	31	0.07	0
2239	2007	13	32	0.02	0
2239	2007	15	16	0.07	0
2239	2007	15	26	0.01	0
2239	2007	15	27	0.05	0
2239	2007	15	28	0.01	0
2239	2007	15	31	0.17	0
2239	2007	15	32	0.04	0
2239	2007	16	16	0.02	0
2239	2007	16	26	3.57142857142857E-03	0
2239	2007	16	27	0.01	0
2239	2007	16	28	9.52380952380952E-03	0
2239	2007	16	31	0.07	0
2239	2007	16	32	0.01	0
2239	2007	17	16	0.09	0
2239	2007	17	26	0.02	0
2239	2007	17	27	0.08	0
2239	2007	17	28	0.05	0
2239	2007	17	31	0.07	0
2239	2007	17	32	0.07	0
2239	2007	18	16	0.06	0
2239	2007	18	26	0.04	0
2239	2007	18	27	0.06	0
2239	2007	18	28	0.01	0
2239	2007	18	31	0.08	0
2239	2007	18	32	0.04	0
2239	2007	19	16	0.02	0
2239	2007	19	26	9.65045592705167E-03	0
2239	2007	19	27	0.02	0
2239	2007	19	28	9.52380952380952E-03	0
2239	2007	19	31	0.04	0
2239	2007	19	32	0.06	0
2239	2007	20	16	0.03	0
2239	2007	20	26	0.01	0
2239	2007	20	27	0.02	0
2239	2007	20	31	0.01	0
2239	2007	20	32	0.01	0
2239	2007	21	16	6.34920634920635E-03	0
2239	2007	21	26	0.01	0
2239	2007	21	27	7.04545454545455E-03	0
2239	2007	21	28	6.34920634920635E-03	0
2239	2007	21	31	0.02	0
2239	2007	21	32	0.02	0
2239	2007	22	16	6.34920634920635E-03	0
2239	2007	22	26	3.57142857142857E-03	0
2239	2007	22	26	4.82522796352584E-03	0
2239	2007	22	27	9.54545454545454E-03	0
2239	2007	22	27	0.01	0
2239	2007	22	28	3.17460317460317E-03	0
2239	2007	22	31	0.03	0
2239	2007	22	31	0.1	0
2239	2007	22	32	0.01	0
2239	2007	23	26	4.82522796352584E-03	0
2239	2007	23	27	9.54545454545454E-03	0
2239	2007	23	28	3.17460317460317E-03	0
2239	2007	23	31	0.1	0
2239	2007	23	32	0.01	0
2239	2007	24	26	3.57142857142857E-03	0
2239	2007	24	27	9.09090909090909E-03	0
2239	2007	24	31	0.02	0
2239	2007	24	32	8.62068965517241E-03	0
2239	2007	25	16	3.17460317460317E-03	0
2239	2007	25	26	3.57142857142857E-03	0
2239	2007	25	27	0.005	0
2239	2007	25	31	0.02	0
2246	2001	9	20	0.02	1
2246	2001	9	26	9.09090909090909E-03	1
2246	2001	9	27	0.01	1
2246	2001	9	28	0.02	1
2246	2001	10	20	0.05	1
2246	2001	10	26	9.09090909090909E-03	1
2246	2001	10	27	0.03	1
2246	2001	10	28	0.03	1
2246	2001	11	20	0.03	1
2246	2001	11	27	0.02	1
2246	2001	11	28	0.01	1
2246	2001	12	20	0.01	1
2246	2001	12	27	0.01	1
2246	2001	12	28	0.09	1
2246	2001	13	20	0.01	1
2246	2001	13	27	0.01	1
2246	2001	13	28	0.09	1
2246	2001	15	20	0.03	1
2246	2001	15	27	0.13	1
2246	2001	15	28	0.25	1
2246	2001	17	20	0.07	1
2246	2001	17	27	0.5	1
2246	2001	17	28	1.21	1
2246	2001	18	20	0.07	1
2246	2001	18	27	0.2	1
2246	2001	18	28	0.71	1
2246	2001	19	20	0.02	1
2246	2001	19	27	0.02	1
2246	2001	19	28	0.07	1
2246	2001	20	20	0.02	1
2246	2001	20	27	0.02	1
2246	2001	20	28	0.07	1
2246	2001	21	27	0.21	1
2246	2001	21	28	0.49	1
2246	2001	23	20	4.54545454545455E-03	1
2246	2001	23	26	0.02	1
2246	2001	23	27	0.06	1
2246	2001	23	28	0.09	1
2246	2002	1	20	0.01	1
2246	2002	1	26	0.04	1
2246	2002	1	27	0.02	1
2246	2002	1	28	0.03	1
2246	2002	3	26	9.09090909090909E-03	1
2246	2002	3	27	0.02	1
2246	2002	3	28	8.16483084185681E-03	1
2246	2002	5	20	9.09090909090909E-03	1
2246	2002	5	26	0.01	1
2246	2002	5	27	0.04	1
2246	2002	5	28	0.08	1
2246	2002	6	20	4.54545454545455E-03	1
2246	2002	6	27	0.02	1
2246	2002	6	28	0.07	1
2246	2002	8	26	9.09090909090909E-03	1
2246	2002	8	27	0.01	1
2246	2002	8	28	0.02	1
2246	2002	9	20	9.09090909090909E-03	1
2246	2002	9	27	0.02	1
2246	2002	9	28	0.01	1
2246	2002	11	20	4.54545454545455E-03	1
2246	2002	11	27	0.01	1
2246	2002	11	28	0.01	1
2246	2002	12	27	0.01	1
2246	2002	12	28	0.03	1
2246	2002	13	20	4.54545454545455E-03	1
2246	2002	13	27	0.05	1
2246	2002	13	28	0.14	1
2246	2002	14	20	4.54545454545455E-03	1
2246	2002	14	27	0.01	1
2246	2002	14	28	0.1	1
2246	2002	15	20	0.01	1
2246	2002	15	27	0.07	1
2246	2002	15	28	0.12	1
2246	2002	16	20	4.54545454545455E-03	1
2246	2002	16	26	9.09090909090909E-03	1
2246	2002	16	27	0.1	1
2246	2002	16	28	0.08	1
2246	2002	17	20	0.03	1
2246	2002	17	27	0.22	1
2246	2002	17	28	0.68	1
2246	2002	18	20	9.09090909090909E-03	1
2246	2002	18	27	0.1	1
2246	2002	18	28	0.28	1
2246	2002	20	27	0.21	1
2246	2002	20	28	0.31	1
2246	2002	21	20	0.06	1
2246	2002	21	26	9.09090909090909E-03	1
2246	2002	21	27	0.15	1
2246	2002	21	28	0.51	1
2246	2002	22	20	0.06	1
2246	2002	22	27	0.07	1
2246	2002	22	28	0.13	1
2246	2002	23	20	0.01	1
2246	2002	23	26	9.09090909090909E-03	1
2246	2002	23	27	0.03	1
2246	2002	23	28	0.07	1
2246	2002	24	26	0.01	1
2246	2002	24	27	0.02	1
2246	2002	24	28	0.03	1
2246	2003	1	26	9.09090909090909E-03	1
2246	2003	1	27	7.49729437229437E-03	1
2246	2003	1	28	0.02	1
2246	2003	2	27	0.03	1
2246	2003	2	28	0.1	1
2246	2003	3	27	0.02	1
2246	2003	3	28	0.06	1
2246	2003	5	26	0.02	1
2246	2003	5	27	0.02	1
2246	2003	5	28	0.05	1
2246	2003	6	26	0.02	1
2246	2003	6	27	0.02	1
2246	2003	6	28	0.05	1
2246	2003	8	20	4.54545454545455E-03	1
2246	2003	8	27	0.01	1
2246	2003	8	28	0.01	1
2246	2003	9	20	9.09090909090909E-03	1
2246	2003	9	26	9.09090909090909E-03	1
2246	2003	9	27	0.02	1
2246	2003	9	28	0.01	1
2246	2003	10	27	0.02	1
2246	2003	10	28	0.04	1
2246	2003	11	20	9.09090909090909E-03	1
2246	2003	11	27	0.03	1
2246	2003	11	28	0.06	1
2246	2003	12	20	4.54545454545455E-03	1
2246	2003	12	27	0.03	1
2246	2003	12	28	0.09	1
2246	2003	14	20	0.01	1
2246	2003	14	26	0.13	1
2246	2003	14	27	0.05	1
2246	2003	14	28	0.21	1
2246	2003	15	20	0.05	1
2246	2003	15	27	0.23	1
2246	2003	15	28	0.81	1
2246	2003	16	20	0.02	1
2246	2003	16	26	0.05	1
2246	2003	16	27	0.19	1
2246	2003	16	28	0.96	1
2246	2003	17	20	0.02	1
2246	2003	17	26	0.05	1
2246	2003	17	27	0.15	1
2246	2003	17	28	0.38	1
2246	2003	18	20	0.02	1
2246	2003	18	27	0.3	1
2246	2003	18	28	1.22	1
2246	2003	19	20	0.05	1
2246	2003	19	26	0.03	1
2246	2003	19	27	0.34	1
2246	2003	19	28	0.93	1
2246	2003	20	20	0.03	1
2246	2003	20	26	0.03	1
2246	2003	20	27	0.31	1
2246	2003	20	28	0.76	1
2246	2003	21	27	0.11	1
2246	2003	21	28	0.41	1
2246	2003	23	20	0.02	1
2246	2003	23	27	0.1	1
2246	2003	23	28	0.15	1
2246	2003	24	20	0.01	1
2246	2003	24	26	0.01	1
2246	2003	24	27	0.06	1
2246	2003	24	28	0.18	1
2246	2003	25	20	9.09090909090909E-03	1
2246	2003	25	26	9.09090909090909E-03	1
2246	2003	25	27	0.07	1
2246	2003	25	28	0.28	1
2246	2003	26	27	0.04	1
2246	2003	26	28	0.42	1
2246	2004	2	27	0.01	1
2246	2004	2	28	0.04	1
2246	2004	4	27	0.02	1
2246	2004	4	28	0.02	1
2246	2004	5	20	4.54545454545455E-03	1
2246	2004	5	27	0.03	1
2246	2004	5	28	0.03	1
2246	2004	7	27	0.01	1
2246	2004	8	20	4.54545454545455E-03	1
2246	2004	8	27	0.02	1
2246	2004	8	28	0.02	1
2246	2004	9	27	0.04	1
2246	2004	9	28	0.05	1
2246	2004	10	20	4.54545454545455E-03	1
2246	2004	10	26	9.09090909090909E-03	1
2246	2004	10	27	0.01	1
2246	2004	10	28	0.03	1
2246	2004	11	20	0.01	1
2246	2004	11	27	9.09090909090909E-03	1
2246	2004	11	28	0.04	1
2246	2004	12	20	9.09090909090909E-03	1
2246	2004	12	27	0.06	1
2246	2004	12	28	0.13	1
2246	2004	13	27	0.05	1
2246	2004	13	28	0.15	1
2246	2004	14	20	9.09090909090909E-03	1
2246	2004	14	26	0.05	1
2246	2004	14	27	0.09	1
2246	2004	14	28	0.21	1
2246	2004	15	27	0.1	1
2246	2004	15	28	0.35	1
2246	2005	1	26	0.03	1
2246	2005	1	27	0.01	1
2246	2005	1	28	0.1	1
2246	2005	2	27	0.01	1
2246	2005	2	28	0.06	1
2246	2005	3	27	0.01	1
2246	2005	3	28	0.03	1
2246	2005	5	20	4.54545454545455E-03	1
2246	2005	5	20	9.09090909090909E-03	1
2246	2005	5	27	0.03	1
2246	2005	5	27	0.06	1
2246	2005	5	28	0.05	1
2246	2005	5	28	0.07	1
2246	2005	6	20	4.54545454545455E-03	1
2246	2005	6	27	0.03	1
2246	2005	6	28	0.02	1
2246	2005	7	27	0.04	1
2246	2005	7	28	0.05	1
2246	2005	9	27	0.03	1
2246	2005	9	28	0.03	1
2246	2005	10	20	4.54545454545455E-03	1
2246	2005	10	26	9.09090909090909E-03	1
2246	2005	10	27	0.06	1
2246	2005	10	28	0.1	1
2246	2005	11	27	0.01	1
2246	2005	11	28	0.05	1
2246	2005	12	27	0.03	1
2246	2005	12	28	0.08	1
2246	2005	13	20	4.54545454545455E-03	1
2246	2005	13	27	0.15	1
2246	2005	13	28	0.24	1
2246	2005	14	27	0.32	1
2246	2005	14	28	1.07	1
2246	2005	15	27	0.15	1
2246	2005	15	28	0.55	1
2246	2005	16	27	0.24	1
2246	2005	16	28	0.8	1
2246	2005	18	20	0.02	1
2246	2005	18	26	0.04	1
2246	2005	18	27	0.09	1
2246	2005	18	28	0.22	1
2246	2005	19	20	0.03	1
2246	2005	19	26	9.09090909090909E-03	1
2246	2005	19	27	0.34	1
2246	2005	19	28	0.68	1
2246	2005	20	20	0.01	1
2246	2005	20	26	9.09090909090909E-03	1
2246	2005	20	27	0.15	1
2246	2005	20	28	0.37	1
2246	2005	22	27	0.06	1
2246	2005	22	28	0.13	1
2246	2005	23	27	0.04	1
2246	2005	23	28	0.12	1
2246	2005	24	20	4.54545454545455E-03	1
2246	2005	24	26	9.09090909090909E-03	1
2246	2005	24	27	0.02	1
2246	2005	24	28	0.07	1
2246	2005	25	20	4.54545454545455E-03	1
2246	2005	25	26	9.09090909090909E-03	1
2246	2005	25	27	0.02	1
2246	2005	25	28	0.07	1
2246	2005	26	27	5.71428571428571E-03	1
2246	2005	26	28	0.06	1
2246	2006	1	27	4.54545454545455E-03	1
2246	2006	1	28	0.01	1
2246	2006	3	27	5.71428571428571E-03	1
2246	2006	3	28	0.02	1
2246	2006	4	20	4.54545454545455E-03	1
2246	2006	4	26	0.01	1
2246	2006	4	27	5.88744588744589E-03	1
2246	2006	4	28	0.01	1
2246	2006	5	27	5.88744588744589E-03	1
2246	2006	5	28	0.01	1
2246	2006	6	27	0.04	1
2246	2006	6	28	0.05	1
2246	2006	7	27	0.01	1
2246	2006	7	28	0.02	1
2246	2006	9	26	0.03	1
2246	2006	9	27	6.06060606060606E-03	1
2246	2006	9	27	8.74458874458874E-03	1
2246	2006	9	28	0.02	1
2246	2006	10	26	0.03	1
2246	2006	10	27	8.74458874458874E-03	1
2246	2006	10	28	0.02	1
2246	2006	11	27	0.03	1
2246	2006	11	28	0.05	1
2246	2006	12	26	0.01	1
2246	2006	12	27	8.57142857142857E-03	1
2246	2006	12	28	0.05	1
2246	2006	13	27	0.07	1
2246	2006	13	28	0.2	1
2246	2006	15	27	0.12	1
2246	2006	15	28	0.64	1
2246	2006	16	26	9.09090909090909E-03	1
2246	2006	16	27	0.28	1
2246	2006	16	28	0.71	1
2246	2006	17	27	0.23	1
2246	2006	17	28	0.78	1
2246	2006	18	26	0.07	1
2246	2006	18	27	0.12	1
2246	2006	18	28	0.81	1
2246	2006	19	20	0.04	1
2246	2006	19	26	0.04	1
2246	2006	19	27	0.14	1
2246	2006	19	28	0.19	1
2246	2006	21	20	0.02	1
2246	2006	21	26	9.09090909090909E-03	1
2246	2006	21	27	0.08	1
2246	2006	21	28	0.23	1
2246	2006	23	20	0.01	1
2246	2006	23	26	0.04	1
2246	2006	23	27	0.02	1
2246	2006	23	28	0.12	1
2246	2006	24	20	9.09090909090909E-03	1
2246	2006	24	27	0.02	1
2246	2006	24	28	0.08	1
2246	2006	25	20	9.09090909090909E-03	1
2246	2006	25	27	0.02	1
2246	2006	25	28	0.08	1
2246	2006	26	27	3.03030303030303E-03	1
2246	2006	26	28	0.05	1
2246	2007	1	26	0.01	1
2246	2007	1	27	0.003125	1
2246	2007	1	28	0.04	1
2246	2007	2	27	0.01	1
2246	2007	2	28	0.03	1
2246	2007	3	26	9.09090909090909E-03	1
2246	2007	3	27	0.02	1
2246	2007	3	28	0.06	1
2246	2007	4	26	0.03	1
2246	2007	4	27	0.03	1
2246	2007	4	28	0.06	1
2246	2007	5	26	0.02	1
2246	2007	5	27	0.02	1
2246	2007	5	28	0.03	1
2246	2007	7	27	0.01	1
2246	2007	7	28	0.01	1
2246	2007	8	27	0.01	1
2246	2007	8	28	0.03	1
2246	2007	9	27	0.01	1
2246	2007	9	28	0.07	1
2246	2007	10	26	0.01	1
2246	2007	10	27	0.03	1
2246	2007	10	28	0.02	1
2246	2007	11	27	0.16	1
2246	2007	11	28	0.28	1
2246	2007	12	20	9.09090909090909E-03	1
2246	2007	12	27	0.24	1
2246	2007	12	28	0.5	1
2246	2007	13	20	9.09090909090909E-03	1
2246	2007	13	27	0.19	1
2246	2007	13	28	0.32	1
2246	2007	14	20	0.02	1
2246	2007	14	26	0.12	1
2246	2007	14	27	0.11	1
2246	2007	14	28	0.18	1
2246	2007	15	20	0.01	1
2246	2007	15	27	0.24	1
2246	2007	15	28	0.62	1
2246	2007	16	27	0.11	1
2246	2007	16	28	0.54	1
2246	2007	17	27	0.12	1
2246	2007	17	28	0.54	1
2246	2007	18	20	4.54545454545455E-03	1
2246	2007	18	26	0.05	1
2246	2007	18	27	0.09	1
2246	2007	18	27	0.1	1
2246	2007	18	28	0.34	1
2246	2007	18	28	0.36	1
2246	2007	19	20	4.54545454545455E-03	1
2246	2007	19	26	0.05	1
2246	2007	19	27	0.09	1
2246	2007	19	28	0.34	1
2246	2007	20	27	0.01	1
2246	2007	20	28	0.15	1
2246	2007	22	20	4.54545454545455E-03	1
2246	2007	22	26	9.09090909090909E-03	1
2246	2007	22	27	0.02	1
2246	2007	22	28	0.02	1
2246	2007	22	28	0.04	1
2246	2007	23	27	0.02	1
2246	2007	23	28	0.04	1
2246	2007	25	20	4.54545454545455E-03	1
2246	2007	25	26	9.09090909090909E-03	1
2246	2007	25	27	0.02	1
2246	2007	25	28	0.04	1
2322	2000	1	26	6.33333333333333E-03	0
2322	2000	1	28	0.01	0
2322	2000	1	31	0.0025	0
2322	2000	2	26	6.33333333333333E-03	0
2322	2000	2	28	0.01	0
2322	2000	2	31	0.0025	0
2322	2000	5	26	0.03	0
2322	2000	5	28	0.05	0
2322	2000	5	31	0.005	0
2322	2000	7	26	0.05	0
2322	2000	7	28	0.1	0
2322	2000	7	31	0.01	0
2322	2000	8	26	0.04	0
2322	2000	8	28	0.02	0
2322	2000	8	31	0.01	0
2322	2000	9	26	0.01	0
2322	2000	9	28	0.06	0
2322	2000	9	31	0.02	0
2322	2000	10	26	0.06	0
2322	2000	10	28	0.27	0
2322	2000	10	31	0.03	0
2322	2000	11	26	0.03	0
2322	2000	11	28	0.19	0
2322	2000	11	31	0.01	0
2322	2000	12	26	0.02	0
2322	2000	12	28	0.15	0
2322	2000	12	31	0.02	0
2322	2000	13	26	0.07	0
2322	2000	13	28	0.23	0
2322	2000	13	31	0.04	0
2322	2000	16	26	0.24	0
2322	2000	16	28	0.68	0
2322	2000	16	31	0.09	0
2322	2000	17	26	0.06	0
2322	2000	17	28	0.05	0
2322	2000	18	26	0.27	0
2322	2000	18	28	0.81	0
2322	2000	18	31	0.12	0
2322	2000	20	26	0.24	0
2322	2000	20	28	0.79	0
2322	2000	20	31	0.16	0
2322	2000	21	26	0.05	0
2322	2000	21	28	0.02	0
2322	2000	21	31	0.02	0
2322	2000	22	26	0.05	0
2322	2000	22	28	0.02	0
2322	2000	22	31	0.02	0
2322	2000	24	26	0.03	0
2322	2000	24	28	0.08	0
2322	2000	24	31	0.005	0
2322	2000	25	26	0.03	0
2322	2000	25	28	0.09	0
2322	2000	25	31	0.04	0
2322	2000	26	26	0.04	0
2322	2000	26	28	0.14	0
2322	2000	26	31	0.05	0
2322	2001	2	26	0.03	0
2322	2001	2	28	0.01	0
2322	2001	2	31	0.01	0
2322	2001	4	26	0.004	0
2322	2001	4	31	0.005	0
2322	2001	6	26	0.01	0
2322	2001	6	28	0.05	0
2322	2001	6	31	0.005	0
2322	2001	7	26	0.01	0
2322	2001	7	28	0.07	0
2322	2001	7	31	0.01	0
2322	2001	8	26	0.07	0
2322	2001	8	28	0.11	0
2322	2001	8	31	0.03	0
2322	2001	9	26	0.03	0
2322	2001	9	28	0.01	0
2322	2001	9	31	0.02	0
2322	2001	10	26	0.05	0
2322	2001	10	28	0.08	0
2322	2001	10	31	0.03	0
2322	2001	12	26	0.05	0
2322	2001	12	28	0.27	0
2322	2001	12	31	0.01	0
2322	2001	14	26	0.1	0
2322	2001	14	28	0.52	0
2322	2001	14	31	0.04	0
2322	2001	15	26	0.39	0
2322	2001	15	28	1.18	0
2322	2001	15	31	0.07	0
2322	2001	16	26	0.3	0
2322	2001	16	28	1.45	0
2322	2001	16	31	0.14	0
2322	2001	17	26	0.3	0
2322	2001	17	28	1.45	0
2322	2001	17	31	0.14	0
2322	2001	18	26	0.32	0
2322	2001	18	28	0.83	0
2322	2001	18	31	0.15	0
2322	2001	19	26	0.26	0
2322	2001	19	28	1.38	0
2322	2001	19	31	0.06	0
2322	2001	21	26	0.04	0
2322	2001	21	28	0.62	0
2322	2001	21	31	0.03	0
2322	2001	22	26	0.07	0
2322	2001	22	28	0.2	0
2322	2001	22	31	0.03	0
2322	2001	24	26	0.01	0
2322	2001	24	28	0.03	0
2322	2001	24	31	0.01	0
2322	2001	26	26	0.01	0
2322	2001	26	28	0.07	0
2322	2001	26	31	0.01	0
2322	2002	1	26	0.02	0
2322	2002	1	28	0.06	0
2322	2002	1	31	0.02	0
2322	2002	2	26	5.33333333333333E-03	0
2322	2002	2	31	0.0025	0
2322	2002	3	26	0.04	0
2322	2002	3	28	0.21	0
2322	2002	3	31	0.005	0
2322	2002	4	26	0.01	0
2322	2002	4	28	0.08	0
2322	2002	4	31	0.01	0
2322	2002	5	26	0.04	0
2322	2002	5	28	0.08	0
2322	2002	5	31	0.01	0
2322	2002	6	26	0.02	0
2322	2002	6	28	0.02	0
2322	2002	6	31	0.03	0
2322	2002	7	26	0.05	0
2322	2002	7	28	0.21	0
2322	2002	7	31	0.05	0
2322	2002	8	26	0.03	0
2322	2002	8	28	0.18	0
2322	2002	8	31	0.01	0
2322	2002	9	26	0.02	0
2322	2002	9	28	0.15	0
2322	2002	9	31	0.03	0
2322	2002	10	26	0.01	0
2322	2002	10	28	0.12	0
2322	2002	10	31	0.01	0
2322	2002	11	26	0.01	0
2322	2002	11	28	0.12	0
2322	2002	11	31	0.01	0
2322	2002	12	26	0.05	0
2322	2002	12	28	0.41	0
2322	2002	12	31	0.01	0
2322	2002	13	26	0.13	0
2322	2002	13	28	0.81	0
2322	2002	13	31	0.02	0
2322	2002	14	26	0.18	0
2322	2002	14	28	0.87	0
2322	2002	14	31	0.1	0
2322	2002	15	26	1.03	0
2322	2002	15	28	2.72	0
2322	2002	15	31	0.3	0
2322	2002	16	26	0.56	0
2322	2002	16	28	1.46	0
2322	2002	16	31	0.19	0
2322	2002	17	26	0.27	0
2322	2002	17	28	1.12	0
2322	2002	17	31	0.11	0
2322	2002	18	26	0.27	0
2322	2002	18	28	1.12	0
2322	2002	18	31	0.11	0
2322	2002	21	26	0.21	0
2322	2002	21	28	1.1	0
2322	2002	21	31	0.1	0
2322	2002	22	26	0.01	0
2322	2002	22	28	0.35	0
2322	2002	22	31	0.02	0
2322	2002	23	26	0.03	0
2322	2002	23	28	0.3	0
2322	2002	23	31	0.02	0
2322	2003	1	26	0.01	0
2322	2003	1	28	0.16	0
2322	2003	1	31	0.0075	0
2322	2003	2	26	0.002	0
2322	2003	2	28	3.33333333333333E-03	0
2322	2003	3	26	0.02	0
2322	2003	3	28	0.1	0
2322	2003	3	31	0.005	0
2322	2003	4	31	0.0075	0
2322	2003	5	26	0.02	0
2322	2003	5	28	0.21	0
2322	2003	5	31	0.05	0
2322	2003	6	26	0.01	0
2322	2003	6	28	0.2	0
2322	2003	6	31	0.03	0
2322	2003	7	26	0.004	0
2322	2003	7	31	0.02	0
2322	2003	8	26	0.03	0
2322	2003	8	28	0.07	0
2322	2003	8	31	0.03	0
2322	2003	9	26	0.02	0
2322	2003	9	28	0.34	0
2322	2003	9	31	0.02	0
2322	2003	10	26	0.01	0
2322	2003	10	28	0.22	0
2322	2003	10	31	0.03	0
2322	2003	11	26	0.04	0
2322	2003	11	28	0.08	0
2322	2003	11	31	0.01	0
2322	2003	12	26	0.07	0
2322	2003	12	28	0.12	0
2322	2003	12	31	0.02	0
2322	2003	13	26	0.32	0
2322	2003	13	28	0.71	0
2322	2003	13	31	0.1	0
2322	2003	14	26	0.45	0
2322	2003	14	28	1.35	0
2322	2003	14	31	0.16	0
2322	2003	15	26	0.68	0
2322	2003	15	28	1.93	0
2322	2003	15	31	0.09	0
2322	2003	16	26	0.33	0
2322	2003	16	28	1.83	0
2322	2003	16	31	0.26	0
2322	2003	17	26	0.39	0
2322	2003	17	28	0.95	0
2322	2003	17	31	0.33	0
2322	2003	18	26	0.43	0
2322	2003	18	28	2.17	0
2322	2003	18	31	0.2	0
2322	2003	19	26	0.39	0
2322	2003	19	28	1.64	0
2322	2003	19	31	0.37	0
2322	2003	20	26	0.3	0
2322	2003	20	28	1.8	0
2322	2003	20	31	0.24	0
2322	2003	21	26	0.1	0
2322	2003	21	28	0.62	0
2322	2003	21	31	0.06	0
2322	2003	23	26	0.08	0
2322	2003	23	28	0.95	0
2322	2003	23	31	0.04	0
2322	2003	25	26	0.02	0
2322	2003	25	28	0.27	0
2322	2003	25	31	0.02	0
2322	2003	26	26	0.02	0
2322	2003	26	28	0.35	0
2322	2003	26	31	0.01	0
2322	2004	2	26	0.01	0
2322	2004	2	28	0.02	0
2322	2004	2	31	0.005	0
2322	2004	3	26	0.01	0
2322	2004	3	28	0.005	0
2322	2004	4	26	0.01	0
2322	2004	4	28	0.01	0
2322	2004	4	31	0.0075	0
2322	2004	6	26	0.02	0
2322	2004	6	28	0.14	0
2322	2004	6	31	0.0025	0
2322	2004	7	26	0.04	0
2322	2004	7	28	0.04	0
2322	2004	7	31	0.03	0
2322	2004	8	31	0.01	0
2322	2004	9	26	0.06	0
2322	2004	9	28	0.28	0
2322	2004	9	31	0.03	0
2322	2004	10	26	0.1	0
2322	2004	10	28	0.13	0
2322	2004	10	31	0.02	0
2322	2004	11	26	0.09	0
2322	2004	11	28	0.37	0
2322	2004	11	31	0.03	0
2322	2004	14	26	0.46	0
2322	2004	14	28	1.55	0
2322	2004	14	31	0.1	0
2322	2004	22	26	0.03	0
2322	2004	22	28	0.42	0
2322	2004	22	31	0.01	0
2322	2004	23	26	0.03	0
2322	2004	23	28	0.42	0
2322	2004	23	31	0.01	0
2322	2005	5	26	0.05	0
2322	2005	5	28	0.23	0
2322	2005	5	31	0.01	0
2322	2005	6	26	0.05	0
2322	2005	6	28	0.23	0
2322	2005	6	31	0.01	0
2322	2005	7	26	0.03	0
2322	2005	7	28	0.23	0
2322	2005	7	31	0.03	0
2322	2005	8	26	0.1	0
2322	2005	8	28	0.28	0
2322	2005	8	31	0.11	0
2322	2005	9	26	0.08	0
2322	2005	9	28	0.14	0
2322	2005	9	31	0.06	0
2322	2005	10	26	0.19	0
2322	2005	10	28	1.08	0
2322	2005	10	31	0.1	0
2322	2005	11	26	0.12	0
2322	2005	11	28	0.66	0
2322	2005	11	31	0.04	0
2322	2005	12	26	0.15	0
2322	2005	12	28	1.18	0
2322	2005	12	31	0.04	0
2322	2005	13	26	0.09	0
2322	2005	13	28	1.21	0
2322	2005	13	31	0.08	0
2322	2005	14	26	0.09	0
2322	2005	14	28	1.21	0
2322	2005	14	31	0.08	0
2322	2005	15	26	1.04	0
2322	2005	15	28	5.25	0
2322	2005	15	31	0.18	0
2322	2005	16	26	0.58	0
2322	2005	16	28	3.76	0
2322	2005	16	31	0.11	0
2322	2005	19	26	0.28	0
2322	2005	19	28	3.3	0
2322	2005	19	31	0.09	0
2322	2005	21	26	0.01	0
2322	2005	21	28	0.82	0
2322	2005	21	31	0.02	0
2322	2005	22	26	0.02	0
2322	2005	22	28	0.43	0
2322	2005	22	31	0.0075	0
2322	2006	3	26	0.03	0
2322	2006	3	28	0.02	0
2322	2006	3	31	0.0075	0
2322	2006	5	26	0.01	0
2322	2006	5	28	0.19	0
2322	2006	5	31	0.0025	0
2322	2006	6	26	0.01	0
2322	2006	6	28	0.25	0
2322	2006	6	31	0.01	0
2322	2006	9	26	0.08	0
2322	2006	9	28	0.3	0
2322	2006	9	31	0.05	0
2322	2006	10	26	0.05	0
2322	2006	10	28	0.03	0
2322	2006	10	31	0.02	0
2322	2006	11	26	0.15	0
2322	2006	11	28	0.47	0
2322	2006	11	31	0.04	0
2322	2006	13	26	0.3	0
2322	2006	13	28	1.51	0
2322	2006	13	31	0.1	0
2322	2006	14	26	0.3	0
2322	2006	14	28	1.51	0
2322	2006	14	31	0.1	0
2322	2006	15	26	0.71	0
2322	2006	15	28	3.52	0
2322	2006	15	31	0.11	0
2322	2006	16	26	0.44	0
2322	2006	16	28	2.98	0
2322	2006	16	31	0.22	0
2322	2006	18	26	0.22	0
2322	2006	18	28	1.97	0
2322	2006	18	31	0.05	0
2322	2006	19	26	0.2	0
2322	2006	19	28	1.91	0
2322	2006	19	31	0.05	0
2322	2006	23	26	0.07	0
2322	2006	23	28	0.06	0
2322	2006	23	31	0.01	0
2322	2007	1	26	0.02	0
2322	2007	1	28	0.13	0
2322	2007	1	31	0.01	0
2322	2007	2	26	0.03	0
2322	2007	2	28	0.17	0
2322	2007	2	31	0.0075	0
2322	2007	3	31	0.005	0
2322	2007	4	26	0.02	0
2322	2007	4	28	0.41	0
2322	2007	4	31	0.05	0
2322	2007	5	26	0.06	0
2322	2007	5	26	0.12	0
2322	2007	5	28	0.46	0
2322	2007	5	28	0.68	0
2322	2007	5	31	0.06	0
2322	2007	5	31	0.1	0
2322	2007	6	26	0.05	0
2322	2007	6	28	0.21	0
2322	2007	6	31	0.03	0
2322	2007	7	26	0.02	0
2322	2007	7	28	0.1	0
2322	2007	7	31	0.01	0
2322	2007	8	26	0.03	0
2322	2007	8	28	0.28	0
2322	2007	8	31	0.03	0
2322	2007	9	26	0.04	0
2322	2007	9	28	0.3	0
2322	2007	9	31	0.02	0
2322	2007	10	26	0.06	0
2322	2007	10	28	0.61	0
2322	2007	10	31	0.01	0
2322	2007	14	26	0.3	0
2322	2007	14	28	2.31	0
2322	2007	14	31	0.1	0
2322	2007	15	26	0.37	0
2322	2007	15	28	2.05	0
2322	2007	15	31	0.13	0
2322	2007	16	26	0.16	0
2322	2007	16	28	2.16	0
2322	2007	16	31	0.08	0
2322	2007	17	26	0.06	0
2322	2007	17	28	0.45	0
2322	2007	17	31	0.01	0
2322	2007	18	26	0.16	0
2322	2007	18	28	0.88	0
2322	2007	18	31	0.04	0
2322	2007	19	26	0.18	0
2322	2007	19	28	1.28	0
2322	2007	19	31	0.11	0
2322	2007	21	26	0.09	0
2322	2007	21	28	1	0
2322	2007	21	31	0.03	0
2322	2007	23	26	0.01	0
2322	2007	23	28	0.37	0
2322	2007	23	31	0.01	0
2328	2000	1	15	0.0025	2
2328	2000	1	26	0.01	2
2328	2000	1	32	0.05	2
2328	2000	2	15	0.0025	2
2328	2000	2	26	0.01	2
2328	2000	2	32	0.07	2
2328	2000	3	15	0.02	2
2328	2000	3	26	0.01	2
2328	2000	3	32	0.01	2
2328	2000	4	26	0.01	2
2328	2000	4	32	0.01	2
2328	2000	5	15	0.005	2
2328	2000	5	26	8.33333333333333E-03	2
2328	2000	5	32	0.01	2
2328	2000	6	15	0.01	2
2328	2000	6	26	0.04	2
2328	2000	6	32	0.07	2
2328	2000	7	15	0.0075	2
2328	2000	7	26	0.04	2
2328	2000	7	32	0.14	2
2328	2000	8	15	0.01	2
2328	2000	8	26	0.02	2
2328	2000	8	32	0.08	2
2328	2000	9	15	0.01	2
2328	2000	9	26	0.04	2
2328	2000	9	32	0.07	2
2328	2000	10	15	0.005	2
2328	2000	10	26	0.02	2
2328	2000	10	32	0.06	2
2328	2000	11	26	3.33333333333333E-03	2
2328	2000	11	32	3.33333333333333E-03	2
2328	2000	12	15	0.02	2
2328	2000	12	26	0.09	2
2328	2000	12	32	0.1	2
2328	2000	13	15	0.06	2
2328	2000	13	26	0.04	2
2328	2000	13	32	0.19	2
2328	2000	14	15	0.22	2
2328	2000	14	26	0.07	2
2328	2000	14	32	0.22	2
2328	2000	15	15	0.16	2
2328	2000	15	26	0.03	2
2328	2000	15	32	0.08	2
2328	2000	16	15	0.17	2
2328	2000	16	26	0.08	2
2328	2000	16	32	0.3	2
2328	2000	17	15	0.09	2
2328	2000	17	26	0.01	2
2328	2000	17	32	0.01	2
2328	2000	18	15	0.29	2
2328	2000	18	26	0.19	2
2328	2000	18	32	0.15	2
2328	2000	19	15	0.18	2
2328	2000	19	26	0.06	2
2328	2000	19	32	0.07	2
2328	2000	20	15	0.12	2
2328	2000	20	26	0.04	2
2328	2000	20	32	0.1	2
2328	2000	21	15	0.09	2
2328	2000	21	26	0.09	2
2328	2000	21	32	0.11	2
2328	2000	23	15	0.01	2
2328	2000	23	26	0.01	2
2328	2000	23	32	0.04	2
2328	2000	24	15	0.03	2
2328	2000	24	26	0.01	2
2328	2000	24	32	0.06	2
2328	2000	25	15	0.0075	2
2328	2000	25	26	6.66666666666667E-03	2
2328	2000	25	32	0.03	2
2328	2000	26	32	0.01	2
2328	2001	12	15	0.02	2
2328	2001	12	26	3.33333333333333E-03	2
2328	2001	12	32	0.01	2
2328	2001	13	15	0.1	2
2328	2001	13	26	0.06	2
2328	2001	13	32	0.05	2
2328	2001	14	15	0.6	2
2328	2001	14	26	0.09	2
2328	2001	14	32	0.3	2
2328	2001	15	15	0.28	2
2328	2001	15	26	0.01	2
2328	2001	15	32	0.16	2
2328	2001	16	15	0.18	2
2328	2001	16	26	0.03	2
2328	2001	16	32	0.06	2
2328	2001	17	15	0.19	2
2328	2001	17	26	0.04	2
2328	2001	17	32	0.09	2
2328	2001	18	15	0.37	2
2328	2001	18	26	0.16	2
2328	2001	18	32	0.15	2
2328	2001	20	15	0.12	2
2328	2001	20	26	0.04	2
2328	2001	20	32	0.05	2
2328	2001	21	15	0.07	2
2328	2001	21	26	0.01	2
2328	2001	21	32	0.14	2
2328	2001	23	15	0.01	2
2328	2001	23	26	3.33333333333333E-03	2
2328	2001	23	32	0.01	2
2328	2001	24	15	0.03	2
2328	2001	24	26	6.66666666666667E-03	2
2328	2001	24	32	0.04	2
2328	2001	26	15	0.005	2
2328	2001	26	26	6.66666666666667E-03	2
2328	2002	1	15	0.01	2
2328	2002	1	26	0.03	2
2328	2002	1	32	0.02	2
2328	2002	2	26	3.33333333333333E-03	2
2328	2002	2	32	0.02	2
2328	2002	3	15	0.05	2
2328	2002	3	26	0.02	2
2328	2002	3	32	0.05	2
2328	2002	5	15	0.01	2
2328	2002	5	26	0.01	2
2328	2002	5	32	0.005	2
2328	2002	6	26	0.0025	2
2328	2002	6	32	0.08	2
2328	2002	7	15	0.01	2
2328	2002	7	26	0.05	2
2328	2002	7	32	0.02	2
2328	2002	8	26	0.01	2
2328	2002	8	32	0.03	2
2328	2002	9	15	0.02	2
2328	2002	9	26	0.02	2
2328	2002	9	32	0.04	2
2328	2002	10	15	0.02	2
2328	2002	10	26	0.01	2
2328	2002	10	32	0.03	2
2328	2002	11	26	0.01	2
2328	2002	11	32	0.06	2
2328	2002	12	15	0.03	2
2328	2002	12	26	0.01	2
2328	2002	12	32	0.07	2
2328	2002	13	15	0.03	2
2328	2002	13	26	0.03	2
2328	2002	13	32	0.05	2
2328	2002	14	15	0.09	2
2328	2002	14	26	0.02	2
2328	2002	14	32	0.07	2
2328	2002	15	15	0.34	2
2328	2002	15	26	0.1	2
2328	2002	15	32	0.25	2
2328	2002	16	15	0.3	2
2328	2002	16	26	0.13	2
2328	2002	16	32	0.21	2
2328	2002	17	15	0.4	2
2328	2002	17	26	0.12	2
2328	2002	17	32	0.16	2
2328	2002	18	15	0.21	2
2328	2002	18	26	0.1	2
2328	2002	18	32	0.27	2
2328	2002	19	15	0.19	2
2328	2002	19	26	0.06	2
2328	2002	19	32	0.12	2
2328	2002	20	15	0.2	2
2328	2002	20	26	0.03	2
2328	2002	20	32	0.1	2
2328	2002	21	15	0.06	2
2328	2002	21	26	5.83333333333333E-03	2
2328	2002	21	32	0.02	2
2328	2002	22	15	0.07	2
2328	2002	22	26	0.01	2
2328	2002	22	32	0.03	2
2328	2002	23	15	0.03	2
2328	2002	23	26	4.54545454545455E-03	2
2328	2002	23	32	0.08	2
2328	2002	24	15	0.02	2
2328	2002	24	26	8.33333333333333E-03	2
2328	2002	24	32	0.1	2
2328	2002	25	15	0.02	2
2328	2002	25	26	0.01	2
2328	2002	25	32	0.02	2
2328	2002	26	15	0.005	2
2328	2002	26	26	8.33333333333333E-03	2
2328	2002	26	32	0.04	2
2328	2003	1	15	0.0075	2
2328	2003	1	32	0.03	2
2328	2003	2	26	3.33333333333333E-03	2
2328	2003	3	15	0.03	2
2328	2003	3	26	0.04	2
2328	2003	3	32	0.09	2
2328	2003	4	15	0.04	2
2328	2003	4	26	0.05	2
2328	2003	4	32	0.1	2
2328	2003	5	15	0.04	2
2328	2003	5	26	0.05	2
2328	2003	5	32	0.07	2
2328	2003	6	15	0.02	2
2328	2003	6	26	0.06	2
2328	2003	6	32	0.16	2
2328	2003	7	26	3.33333333333333E-03	2
2328	2003	7	32	3.33333333333333E-03	2
2328	2003	8	15	0.01	2
2328	2003	8	26	6.66666666666667E-03	2
2328	2003	8	32	0.04	2
2328	2003	9	15	0.02	2
2328	2003	9	26	0.02	2
2328	2003	9	32	0.02	2
2328	2003	10	15	0.0025	2
2328	2003	10	26	6.66666666666667E-03	2
2328	2003	10	32	0.03	2
2328	2003	11	15	0.16	2
2328	2003	11	26	0.04	2
2328	2003	11	32	0.11	2
2328	2003	12	15	0.12	2
2328	2003	12	26	0.02	2
2328	2003	12	32	0.06	2
2328	2003	13	15	0.16	2
2328	2003	13	26	0.05	2
2328	2003	13	32	0.13	2
2328	2003	14	15	0.27	2
2328	2003	14	26	0.03	2
2328	2003	14	32	0.25	2
2328	2003	15	15	0.64	2
2328	2003	15	26	0.4	2
2328	2003	15	32	0.6	2
2328	2003	16	15	0.23	2
2328	2003	16	26	0.19	2
2328	2003	16	32	0.2	2
2328	2003	17	15	0.29	2
2328	2003	17	26	0.08	2
2328	2003	17	32	0.18	2
2328	2003	18	15	0.35	2
2328	2003	18	26	0.06	2
2328	2003	18	32	0.25	2
2328	2003	19	15	0.35	2
2328	2003	19	26	0.05	2
2328	2003	19	32	0.16	2
2328	2003	20	15	0.13	2
2328	2003	20	26	0.05	2
2328	2003	20	32	0.13	2
2328	2003	21	15	0.12	2
2328	2003	21	26	0.06	2
2328	2003	21	32	0.08	2
2328	2003	22	15	0.07	2
2328	2003	22	26	0.03	2
2328	2003	22	32	0.04	2
2328	2003	23	15	0.04	2
2328	2003	23	26	0.05	2
2328	2003	23	32	0.13	2
2328	2003	24	15	0.01	2
2328	2003	24	26	0.01	2
2328	2003	24	32	0.06	2
2328	2003	25	15	0.01	2
2328	2003	25	26	0.01	2
2328	2003	25	32	0.04	2
2328	2003	26	15	0.0075	2
2328	2003	26	26	3.33333333333333E-03	2
2328	2003	26	32	0.01	2
2328	2004	1	26	9.16666666666667E-03	2
2328	2004	2	15	0.0075	2
2328	2004	2	26	6.66666666666667E-03	2
2328	2004	2	32	0.03	2
2328	2004	3	15	0.01	2
2328	2004	3	26	0.02	2
2328	2004	3	32	0.01	2
2328	2004	4	15	0.01	2
2328	2004	4	26	0.01	2
2328	2004	4	32	0.06	2
2328	2004	6	15	0.02	2
2328	2004	6	26	0.02	2
2328	2004	6	32	0.04	2
2328	2004	7	15	0.02	2
2328	2004	7	26	0.02	2
2328	2004	7	32	0.01	2
2328	2004	8	15	0.04	2
2328	2004	8	26	0.03	2
2328	2004	8	32	0.04	2
2328	2004	9	15	0.01	2
2328	2004	9	26	0.03	2
2328	2004	9	32	0.01	2
2328	2004	10	15	0.06	2
2328	2004	10	26	0.01	2
2328	2004	10	32	0.02	2
2328	2004	11	15	0.1	2
2328	2004	11	26	0.06	2
2328	2004	11	32	0.09	2
2328	2004	12	15	0.09	2
2328	2004	12	26	0.03	2
2328	2004	12	32	0.04	2
2328	2004	13	15	0.51	2
2328	2004	13	26	0.09	2
2328	2004	13	32	0.23	2
2328	2004	14	15	0.87	2
2328	2004	14	26	0.12	2
2328	2004	14	32	0.31	2
2328	2004	15	15	0.38	2
2328	2004	15	26	0.07	2
2328	2004	15	32	0.13	2
2328	2004	16	15	0.28	2
2328	2004	16	26	0.15	2
2328	2004	16	32	0.18	2
2328	2004	17	15	0.23	2
2328	2004	17	26	0.03	2
2328	2004	17	32	0.07	2
2328	2004	18	15	0.58	2
2328	2004	18	26	0.1	2
2328	2004	18	32	0.32	2
2328	2004	19	15	0.39	2
2328	2004	19	26	0.07	2
2328	2004	19	32	0.12	2
2328	2004	20	15	0.06	2
2328	2004	20	32	0.03	2
2328	2004	21	15	0.05	2
2328	2004	21	26	0.08	2
2328	2004	21	32	0.12	2
2328	2004	22	15	0.02	2
2328	2004	22	26	0.01	2
2328	2004	22	32	0.08	2
2328	2004	23	15	0.03	2
2328	2004	23	26	0.04	2
2328	2004	23	32	0.13	2
2328	2004	24	15	0.03	2
2328	2004	24	26	0.03	2
2328	2004	24	32	0.09	2
2328	2004	25	15	0.02	2
2328	2004	25	26	0.0075	2
2328	2004	25	32	0.06	2
2328	2004	26	15	0.01	2
2328	2004	26	26	0.01	2
2328	2004	26	32	0.03	2
2328	2005	1	15	0.04	2
2328	2005	1	26	0.03	2
2328	2005	1	32	0.05	2
2328	2005	2	32	0.02	2
2328	2005	3	26	0.01	2
2328	2005	4	15	0.01	2
2328	2005	4	26	0.07	2
2328	2005	4	32	0.08	2
2328	2005	5	15	0.005	2
2328	2005	5	15	0.01	2
2328	2005	5	26	0.02	2
2328	2005	5	32	0.04	2
2328	2005	5	32	0.13	2
2328	2005	6	15	0.01	2
2328	2005	6	26	0.02	2
2328	2005	6	32	0.13	2
2328	2005	7	15	0.01	2
2328	2005	7	26	0.04	2
2328	2005	7	32	0.05	2
2328	2005	8	15	0.005	2
2328	2005	8	26	0.01	2
2328	2005	8	32	0.08	2
2328	2005	9	26	0.005	2
2328	2005	9	32	0.02	2
2328	2005	10	15	0.005	2
2328	2005	10	26	9.09090909090909E-03	2
2328	2005	10	32	0.03	2
2328	2005	11	26	9.16666666666667E-03	2
2328	2005	11	32	0.07	2
2328	2005	12	15	0.06	2
2328	2005	12	26	0.02	2
2328	2005	12	32	0.09	2
2328	2005	13	15	0.26	2
2328	2005	13	26	0.08	2
2328	2005	13	32	0.11	2
2328	2005	14	15	0.29	2
2328	2005	14	26	0.11	2
2328	2005	14	32	0.14	2
2328	2005	15	15	0.79	2
2328	2005	15	26	0.14	2
2328	2005	15	32	0.32	2
2328	2005	16	15	0.71	2
2328	2005	16	26	0.21	2
2328	2005	16	32	0.42	2
2328	2005	17	15	0.78	2
2328	2005	17	26	0.05	2
2328	2005	17	32	0.32	2
2328	2005	18	15	0.38	2
2328	2005	18	26	0.07	2
2328	2005	18	32	0.33	2
2328	2005	19	15	0.25	2
2328	2005	19	26	0.06	2
2328	2005	19	32	0.19	2
2328	2005	20	15	0.22	2
2328	2005	20	26	0.03	2
2328	2005	20	32	0.28	2
2328	2005	21	15	0.08	2
2328	2005	21	26	0.03	2
2328	2005	21	32	0.14	2
2328	2005	22	15	0.0075	2
2328	2005	22	26	0.02	2
2328	2005	22	32	0.06	2
2328	2005	23	15	0.06	2
2328	2005	23	26	0.01	2
2328	2005	23	32	0.12	2
2328	2005	24	15	0.05	2
2328	2005	24	26	0.01	2
2328	2005	24	32	0.11	2
2328	2005	25	15	0.02	2
2328	2005	25	26	0.0025	2
2328	2005	25	32	0.07	2
2328	2005	26	15	0.0025	2
2328	2005	26	26	6.66666666666667E-03	2
2328	2005	26	32	0.06	2
2328	2006	1	32	8.33333333333333E-03	2
2328	2006	2	15	0.005	2
2328	2006	2	26	0.01	2
2328	2006	2	32	0.05	2
2328	2006	3	15	0.02	2
2328	2006	3	26	0.01	2
2328	2006	3	32	0.08	2
2328	2006	4	15	0.0075	2
2328	2006	4	26	0.01	2
2328	2006	4	32	0.04	2
2328	2006	5	15	0.01	2
2328	2006	5	26	0.03	2
2328	2006	5	32	0.01	2
2328	2006	6	15	0.02	2
2328	2006	6	26	0.02	2
2328	2006	6	32	0.04	2
2328	2006	7	15	0.0025	2
2328	2006	7	32	0.01	2
2328	2006	8	15	0.01	2
2328	2006	8	26	0.01	2
2328	2006	8	32	0.06	2
2328	2006	9	15	0.02	2
2328	2006	9	15	0.03	2
2328	2006	9	26	9.16666666666667E-03	2
2328	2006	9	26	0.03	2
2328	2006	9	32	0.03	2
2328	2006	9	32	0.07	2
2328	2006	10	15	0.01	2
2328	2006	10	26	0.02	2
2328	2006	10	32	0.03	2
2328	2006	11	15	0.01	2
2328	2006	11	26	0.03	2
2328	2006	11	32	0.05	2
2328	2006	12	15	0.24	2
2328	2006	12	26	0.13	2
2328	2006	12	32	0.23	2
2328	2006	13	15	0.86	2
2328	2006	13	26	0.23	2
2328	2006	13	32	0.55	2
2328	2006	14	15	0.71	2
2328	2006	14	26	0.12	2
2328	2006	14	32	0.43	2
2328	2006	15	15	0.84	2
2328	2006	15	26	0.24	2
2328	2006	15	32	0.36	2
2328	2006	16	15	0.54	2
2328	2006	16	26	0.23	2
2328	2006	16	32	0.32	2
2328	2006	17	15	0.46	2
2328	2006	17	26	0.14	2
2328	2006	17	32	0.29	2
2328	2006	18	15	0.43	2
2328	2006	18	26	0.16	2
2328	2006	18	32	0.28	2
2328	2006	19	15	0.25	2
2328	2006	19	26	0.02	2
2328	2006	19	32	0.11	2
2328	2006	20	15	0.07	2
2328	2006	20	26	0.01	2
2328	2006	20	32	0.03	2
2328	2006	21	15	0.02	2
2328	2006	21	26	0.02	2
2328	2006	21	32	0.09	2
2328	2006	22	15	0.03	2
2328	2006	22	32	0.07	2
2328	2006	23	15	0.03	2
2328	2006	23	26	0.03	2
2328	2006	23	32	0.12	2
2328	2006	24	15	0.01	2
2328	2006	24	26	0.01	2
2328	2006	24	32	0.08	2
2328	2006	25	15	0.01	2
2328	2006	25	26	0.01	2
2328	2006	25	32	0.08	2
2328	2006	26	15	0.02	2
2328	2006	26	32	0.01	2
2328	2007	1	15	0.02	2
2328	2007	1	26	0.01	2
2328	2007	1	32	0.07	2
2328	2007	2	15	0.01	2
2328	2007	2	32	0.05	2
2328	2007	3	15	0.02	2
2328	2007	3	26	0.03	2
2328	2007	3	32	0.07	2
2328	2007	4	15	0.02	2
2328	2007	4	26	0.04	2
2328	2007	4	32	0.12	2
2328	2007	5	15	0.02	2
2328	2007	5	26	6.66666666666667E-03	2
2328	2007	5	32	0.1	2
2328	2007	6	15	0.0075	2
2328	2007	6	26	3.33333333333333E-03	2
2328	2007	6	32	0.07	2
2328	2007	7	15	0.01	2
2328	2007	7	26	0.03	2
2328	2007	7	32	0.1	2
2328	2007	8	15	0.0025	2
2328	2007	8	26	0.0025	2
2328	2007	8	32	0.01	2
2328	2007	9	15	0.02	2
2328	2007	9	26	0.01	2
2328	2007	9	32	0.05	2
2328	2007	10	15	0.01	2
2328	2007	10	26	0.02	2
2328	2007	10	32	0.07	2
2328	2007	11	15	0.05	2
2328	2007	11	26	0.01	2
2328	2007	11	32	0.05	2
2328	2007	12	15	0.04	2
2328	2007	12	32	0.02	2
2328	2007	13	15	0.08	2
2328	2007	13	26	0.04	2
2328	2007	13	32	0.29	2
2328	2007	14	15	0.24	2
2328	2007	14	26	0.09	2
2328	2007	14	32	0.46	2
2328	2007	15	15	0.11	2
2328	2007	15	26	0.04	2
2328	2007	15	32	0.29	2
2328	2007	16	15	0.22	2
2328	2007	16	26	0.08	2
2328	2007	16	32	0.28	2
2328	2007	17	15	0.33	2
2328	2007	17	26	0.1	2
2328	2007	17	32	0.22	2
2328	2007	18	15	0.26	2
2328	2007	18	26	0.1	2
2328	2007	18	32	0.5	2
2328	2007	19	15	0.17	2
2328	2007	19	26	0.05	2
2328	2007	19	32	0.21	2
2328	2007	20	15	0.09	2
2328	2007	20	26	0.05	2
2328	2007	20	32	0.08	2
2328	2007	21	15	0.05	2
2328	2007	21	26	0.02	2
2328	2007	21	32	0.1	2
2328	2007	22	15	0.02	2
2328	2007	22	26	0.005	2
2328	2007	22	32	0.05	2
2328	2007	23	15	0.005	2
2328	2007	23	26	0.02	2
2328	2007	23	32	0.08	2
2328	2007	24	15	0.03	2
2328	2007	24	26	0.01	2
2328	2007	24	32	0.2	2
2328	2007	25	15	0.02	2
2328	2007	25	26	6.66666666666667E-03	2
2328	2007	25	32	0.07	2
2328	2007	26	15	0.005	2
2328	2007	26	32	0.05	2
2333	2000	2	17	0.05	0
2333	2000	2	26	0.11	0
2333	2000	3	17	0.01	0
2333	2000	3	26	0.12	0
2333	2000	4	17	5.88235294117647E-03	0
2333	2000	4	26	0.25	0
2333	2000	5	17	0.04	0
2333	2000	5	26	0.3	0
2333	2000	6	17	0.05	0
2333	2000	6	26	0.37	0
2333	2000	7	17	0.03	0
2333	2000	7	26	0.41	0
2333	2000	8	17	0.15	0
2333	2000	8	26	0.2	0
2333	2000	9	17	8.33333333333333E-03	0
2333	2000	9	26	0.25	0
2333	2000	10	17	0.04	0
2333	2000	10	26	0.28	0
2333	2000	11	17	0.08	0
2333	2000	11	26	0.3	0
2333	2000	12	17	0.1	0
2333	2000	12	26	0.44	0
2333	2000	13	17	0.16	0
2333	2000	13	26	0.64	0
2333	2000	14	17	0.94	0
2333	2000	14	26	1.46	0
2333	2000	15	17	0.48	0
2333	2000	15	26	1.84	0
2333	2000	16	17	0.67	0
2333	2000	16	26	1.81	0
2333	2000	17	17	0.77	0
2333	2000	17	26	1.43	0
2333	2000	18	17	0.82	0
2333	2000	18	26	1.66	0
2333	2000	19	17	0.69	0
2333	2000	19	26	0.76	0
2333	2000	20	17	0.52	0
2333	2000	20	26	0.77	0
2333	2000	21	17	0.32	0
2333	2000	21	26	0.19	0
2333	2000	22	17	0.13	0
2333	2000	22	26	0.1	0
2333	2000	23	17	0.13	0
2333	2000	23	26	0.14	0
2333	2000	24	17	0.09	0
2333	2000	24	26	0.09	0
2333	2000	25	17	0.07	0
2333	2000	25	26	0.11	0
2333	2000	26	17	0.12	0
2333	2000	26	26	0.16	0
2333	2001	4	17	5.88235294117647E-03	0
2333	2001	4	26	0.04	0
2333	2001	5	17	5.88235294117647E-03	0
2333	2001	5	26	0.04	0
2333	2001	6	17	0.07	0
2333	2001	6	26	0.37	0
2333	2001	7	26	0.12	0
2333	2001	8	17	0.01	0
2333	2001	8	26	0.24	0
2333	2001	9	17	0.01	0
2333	2001	9	26	0.2	0
2333	2001	10	26	0.26	0
2333	2001	11	26	0.2	0
2333	2001	12	26	0.36	0
2333	2001	13	17	0.06	0
2333	2001	13	26	0.27	0
2333	2001	14	17	0.17	0
2333	2001	14	26	0.67	0
2333	2001	15	17	0.49	0
2333	2001	15	26	1.84	0
2333	2001	16	17	0.67	0
2333	2001	16	26	1.7	0
2333	2001	17	17	0.65	0
2333	2001	17	26	1.21	0
2333	2001	18	17	0.58	0
2333	2001	18	17	0.61	0
2333	2001	18	26	0.71	0
2333	2001	18	26	0.99	0
2333	2001	19	17	0.58	0
2333	2001	19	26	0.71	0
2333	2001	20	17	0.44	0
2333	2001	20	26	0.5	0
2333	2001	21	17	0.18	0
2333	2001	21	26	0.08	0
2333	2001	22	17	0.09	0
2333	2001	22	26	0.14	0
2333	2001	23	17	0.26	0
2333	2001	23	26	0.15	0
2333	2001	24	17	0.15	0
2333	2001	24	26	0.08	0
2333	2001	25	17	0.02	0
2333	2001	26	17	0.1	0
2333	2001	26	26	0.06	0
2333	2002	1	17	0.15	0
2333	2002	1	26	0.37	0
2333	2002	2	17	0.13	0
2333	2002	2	26	0.35	0
2333	2002	3	17	0.05	0
2333	2002	3	26	0.19	0
2333	2002	4	17	8.33333333333333E-03	0
2333	2002	4	26	0.3	0
2333	2002	5	17	0.01	0
2333	2002	5	26	0.46	0
2333	2002	6	17	0.04	0
2333	2002	6	26	0.38	0
2333	2002	7	17	0.11	0
2333	2002	7	26	0.39	0
2333	2002	8	17	0.02	0
2333	2002	8	26	0.33	0
2333	2002	9	17	0.07	0
2333	2002	9	26	0.26	0
2333	2002	10	17	0.12	0
2333	2002	10	26	0.25	0
2333	2002	11	17	0.08	0
2333	2002	11	26	0.21	0
2333	2002	12	17	0.35	0
2333	2002	12	26	0.68	0
2333	2002	13	17	0.25	0
2333	2002	13	26	0.36	0
2333	2002	14	17	0.12	0
2333	2002	14	26	0.55	0
2333	2002	15	17	1.07	0
2333	2002	15	26	1.66	0
2333	2002	16	17	0.72	0
2333	2002	16	26	0.95	0
2333	2002	17	17	1.36	0
2333	2002	17	26	2.12	0
2333	2002	18	17	0.8	0
2333	2002	18	26	0.92	0
2333	2002	19	17	1.18	0
2333	2002	19	26	1.53	0
2333	2002	20	17	0.55	0
2333	2002	20	26	0.81	0
2333	2002	21	17	0.32	0
2333	2002	21	26	0.26	0
2333	2002	22	17	0.03	0
2333	2002	22	17	0.2	0
2333	2002	22	26	0.02	0
2333	2002	22	26	0.25	0
2333	2002	23	17	0.03	0
2333	2002	23	26	0.02	0
2333	2002	24	17	0.05	0
2333	2002	24	26	0.04	0
2333	2002	25	17	0.01	0
2333	2002	25	26	0.02	0
2333	2003	1	17	0.07	0
2333	2003	1	26	0.22	0
2333	2003	2	17	0.03	0
2333	2003	2	26	0.03	0
2333	2003	3	17	0.05	0
2333	2003	3	26	0.17	0
2333	2003	4	17	0.05	0
2333	2003	4	26	0.16	0
2333	2003	5	17	0.06	0
2333	2003	5	26	0.36	0
2333	2003	6	17	0.02	0
2333	2003	6	26	0.18	0
2333	2003	7	17	5.88235294117647E-03	0
2333	2003	7	26	0.08	0
2333	2003	8	17	0.03	0
2333	2003	8	26	0.11	0
2333	2003	9	17	0.03	0
2333	2003	9	26	0.22	0
2333	2003	10	17	0.02	0
2333	2003	10	26	0.17	0
2333	2003	11	17	0.23	0
2333	2003	11	26	0.51	0
2333	2003	12	17	0.17	0
2333	2003	12	26	0.32	0
2333	2003	13	17	0.47	0
2333	2003	13	26	1.09	0
2333	2003	14	17	1.11	0
2333	2003	14	26	1.56	0
2333	2003	15	17	1.71	0
2333	2003	15	26	3.05	0
2333	2003	16	17	0.91	0
2333	2003	16	26	1.48	0
2333	2003	17	17	0.77	0
2333	2003	17	26	1.56	0
2333	2003	18	17	0.77	0
2333	2003	18	17	0.88	0
2333	2003	18	26	0.52	0
2333	2003	18	26	0.91	0
2333	2003	19	17	1.53	0
2333	2003	19	26	0.92	0
2333	2003	20	17	0.65	0
2333	2003	20	26	0.39	0
2333	2003	21	17	0.84	0
2333	2003	21	26	1.12	0
2333	2003	22	17	0.19	0
2333	2003	22	17	0.43	0
2333	2003	22	26	0.12	0
2333	2003	22	26	0.72	0
2333	2003	23	17	0.33	0
2333	2003	23	26	0.21	0
2333	2003	24	17	0.14	0
2333	2003	24	26	0.09	0
2333	2003	25	17	0.17	0
2333	2003	25	26	0.07	0
2333	2003	26	17	0.12	0
2333	2003	26	26	0.03	0
2333	2004	2	17	0.04	0
2333	2004	2	26	0.25	0
2333	2004	3	17	0.02	0
2333	2004	3	26	0.2	0
2333	2004	4	17	0.03	0
2333	2004	4	26	0.21	0
2333	2004	5	17	0.02	0
2333	2004	5	26	0.15	0
2333	2004	6	17	0.03	0
2333	2004	6	26	0.28	0
2333	2004	7	17	0.03	0
2333	2004	7	26	0.34	0
2333	2004	8	17	0.06	0
2333	2004	8	26	0.34	0
2333	2004	9	17	0.02	0
2333	2004	9	17	0.05	0
2333	2004	9	26	0.21	0
2333	2004	9	26	0.24	0
2333	2004	10	17	0.1	0
2333	2004	10	26	0.49	0
2333	2004	11	17	0.07	0
2333	2004	11	26	0.3	0
2333	2004	12	17	0.11	0
2333	2004	12	26	0.58	0
2333	2004	13	17	0.25	0
2333	2004	13	26	0.85	0
2333	2004	14	17	0.56	0
2333	2004	14	26	1.56	0
2333	2004	15	17	0.34	0
2333	2004	15	26	0.49	0
2333	2004	16	17	0.3	0
2333	2004	16	26	0.57	0
2333	2004	17	17	0.29	0
2333	2004	17	26	0.83	0
2333	2004	18	17	0.37	0
2333	2004	18	26	0.81	0
2333	2004	19	17	0.63	0
2333	2004	19	26	0.52	0
2333	2004	22	17	0.09	0
2333	2004	22	26	0.09	0
2333	2004	23	17	0.06	0
2333	2004	23	26	0.14	0
2333	2004	24	17	0.13	0
2333	2004	24	26	0.21	0
2333	2004	25	17	0.03	0
2333	2004	25	26	0.06	0
2333	2004	26	17	0.02	0
2333	2004	26	26	0.02	0
2333	2005	1	17	0.01	0
2333	2005	1	26	0.05	0
2333	2005	2	17	0.01	0
2333	2005	2	26	0.01	0
2333	2005	3	17	0.06	0
2333	2005	3	26	0.21	0
2333	2005	4	17	0.07	0
2333	2005	4	26	0.24	0
2333	2005	5	17	0.03	0
2333	2005	5	26	0.03	0
2333	2005	6	17	0.1	0
2333	2005	6	26	0.26	0
2333	2005	7	17	0.1	0
2333	2005	7	26	0.38	0
2333	2005	8	26	0.27	0
2333	2005	9	26	0.12	0
2333	2005	10	26	0.08	0
2333	2005	11	17	0.03	0
2333	2005	11	26	0.27	0
2333	2005	12	17	0.12	0
2333	2005	12	26	0.58	0
2333	2005	13	17	0.11	0
2333	2005	13	26	0.64	0
2333	2005	14	17	0.01	0
2333	2005	14	26	0.24	0
2333	2005	15	17	0.17	0
2333	2005	15	26	0.43	0
2333	2005	16	17	0.28	0
2333	2005	16	26	0.75	0
2333	2005	17	17	0.35	0
2333	2005	17	26	0.42	0
2333	2005	18	17	0.31	0
2333	2005	18	26	0.41	0
2333	2005	19	17	0.37	0
2333	2005	19	26	0.18	0
2333	2005	20	17	0.14	0
2333	2005	20	26	0.13	0
2333	2005	21	17	0.25	0
2333	2005	21	26	0.09	0
2333	2005	22	17	0.05	0
2333	2005	22	17	0.12	0
2333	2005	22	26	0.05	0
2333	2005	22	26	0.08	0
2333	2005	23	17	0.12	0
2333	2005	23	26	0.05	0
2333	2005	24	17	0.03	0
2333	2005	24	26	0.03	0
2333	2005	25	17	0.02	0
2333	2005	25	26	0.05	0
2333	2006	1	26	0.02	0
2333	2006	2	17	0.02	0
2333	2006	2	26	0.13	0
2333	2006	3	17	5.88235294117647E-03	0
2333	2006	3	26	0.03	0
2333	2006	4	17	0.04	0
2333	2006	4	26	0.09	0
2333	2006	5	17	0.03	0
2333	2006	5	26	0.08	0
2333	2006	6	17	0.04	0
2333	2006	6	26	0.27	0
2333	2006	7	17	0.01	0
2333	2006	7	26	0.06	0
2333	2006	8	17	0.01	0
2333	2006	8	26	0.1	0
2333	2006	9	26	0.04	0
2333	2006	10	26	0.08	0
2333	2006	11	17	0.01	0
2333	2006	11	26	0.06	0
2333	2006	12	17	0.05	0
2333	2006	12	26	0.11	0
2333	2006	13	17	0.22	0
2333	2006	13	26	0.51	0
2333	2006	14	17	0.78	0
2333	2006	14	26	0.95	0
2333	2006	15	17	0.38	0
2333	2006	15	26	0.39	0
2333	2006	16	17	0.31	0
2333	2006	16	26	0.54	0
2333	2006	17	17	0.39	0
2333	2006	17	26	0.48	0
2333	2006	18	17	0.16	0
2333	2006	18	26	0.17	0
2333	2006	19	17	0.06	0
2333	2006	19	26	0.12	0
2333	2006	20	17	0.12	0
2333	2006	20	26	0.09	0
2333	2006	21	17	0.02	0
2333	2006	21	26	0.07	0
2333	2006	22	17	0.02	0
2333	2006	22	26	0.04	0
2333	2006	23	17	0.08	0
2333	2006	23	26	0.1	0
2333	2006	24	17	0.11	0
2333	2006	24	26	0.06	0
2333	2006	25	17	0.07	0
2333	2006	25	26	0.03	0
2333	2006	26	17	5.88235294117647E-03	0
2333	2007	1	17	0.03	0
2333	2007	1	26	0.08	0
2333	2007	2	17	0.01	0
2333	2007	2	26	0.24	0
2333	2007	3	17	5.88235294117647E-03	0
2333	2007	3	26	0.15	0
2333	2007	4	17	8.33333333333333E-03	0
2333	2007	4	26	0.09	0
2333	2007	5	17	0.03	0
2333	2007	5	26	0.2	0
2333	2007	6	26	0.03	0
2333	2007	7	17	0.02	0
2333	2007	7	26	0.07	0
2333	2007	8	17	0.01	0
2333	2007	8	26	0.04	0
2333	2007	10	17	0.03	0
2333	2007	10	26	0.17	0
2333	2007	11	17	8.33333333333333E-03	0
2333	2007	11	26	0.14	0
2333	2007	12	17	0.14	0
2333	2007	12	26	0.54	0
2333	2007	13	17	0.3	0
2333	2007	13	26	0.59	0
2333	2007	15	17	0.12	0
2333	2007	15	26	0.59	0
2333	2007	16	17	0.27	0
2333	2007	16	26	0.63	0
2333	2007	17	17	0.13	0
2333	2007	17	26	0.38	0
2333	2007	18	17	0.25	0
2333	2007	18	26	0.36	0
2333	2007	19	17	0.32	0
2333	2007	19	26	0.21	0
2333	2007	20	17	0.03	0
2333	2007	20	26	0.09	0
2333	2007	21	17	0.18	0
2333	2007	21	26	0.08	0
2333	2007	22	17	0.01	0
2333	2007	22	26	0.03	0
2333	2007	23	17	0.02	0
2333	2007	23	26	0.1	0
2333	2007	24	17	0.02	0
2333	2007	24	26	0.02	0
2333	2007	25	17	5.88235294117647E-03	0
2333	2007	25	26	0.01	0
2333	2007	26	17	0.03	0
2403	2000	2	19	0.01	2
2403	2000	4	19	0.03	2
2403	2000	5	19	6.66666666666667E-03	2
2403	2000	6	19	0.02	2
2403	2000	7	19	0.01	2
2403	2000	9	19	0.02	2
2403	2000	10	19	0.01	2
2403	2000	12	19	0.02	2
2403	2000	13	19	0.02	2
2403	2000	14	19	0.13	2
2403	2000	15	19	0.19	2
2403	2000	16	19	0.14	2
2403	2000	17	19	0.11	2
2403	2000	18	19	6.66666666666667E-03	2
2403	2000	19	19	0.09	2
2403	2000	21	19	0.02	2
2403	2000	22	19	0.04	2
2403	2000	23	19	0.01	2
2403	2000	24	19	0.02	2
2403	2000	25	19	6.66666666666667E-03	2
2403	2000	26	19	6.66666666666667E-03	2
2403	2001	6	19	0.02	2
2403	2001	7	19	6.66666666666667E-03	2
2403	2001	8	19	6.66666666666667E-03	2
2403	2001	10	19	0.01	2
2403	2001	11	19	0.01	2
2403	2001	12	19	0.02	2
2403	2001	14	19	0.07	2
2403	2001	15	19	0.14	2
2403	2001	16	19	0.1	2
2403	2001	17	19	0.11	2
2403	2001	19	19	0.07	2
2403	2001	20	19	0.1	2
2403	2001	21	19	0.04	2
2403	2001	22	19	0.08	2
2403	2001	24	19	6.66666666666667E-03	2
2403	2002	3	19	0.03	2
2403	2002	4	19	0.02	2
2403	2002	6	19	6.66666666666667E-03	2
2403	2002	7	19	0.02	2
2403	2002	9	19	0.01	2
2403	2002	12	19	0.02	2
2403	2002	13	19	0.13	2
2403	2002	14	19	0.04	2
2403	2002	15	19	0.14	2
2403	2002	16	19	0.09	2
2403	2002	17	19	0.04	2
2403	2002	18	19	0.16	2
2403	2002	19	19	0.06	2
2403	2002	20	19	0.11	2
2403	2002	22	19	0.06	2
2403	2002	23	19	0.02	2
2403	2002	25	19	6.66666666666667E-03	2
2403	2003	1	19	6.66666666666667E-03	2
2403	2003	2	19	6.66666666666667E-03	2
2403	2003	3	19	0.02	2
2403	2003	4	19	0.01	2
2403	2003	6	19	6.66666666666667E-03	2
2403	2003	7	19	0.03	2
2403	2003	8	19	6.66666666666667E-03	2
2403	2003	11	19	6.66666666666667E-03	2
2403	2003	12	19	0.06	2
2403	2003	13	19	0.04	2
2403	2003	14	19	0.1	2
2403	2003	15	19	0.2	2
2403	2003	16	19	0.09	2
2403	2003	17	19	0.1	2
2403	2003	18	19	0.3	2
2403	2003	19	19	0.16	2
2403	2003	20	19	0.13	2
2403	2003	21	19	0.05	2
2403	2003	22	19	6.66666666666667E-03	2
2403	2003	22	19	0.05	2
2403	2003	23	19	6.66666666666667E-03	2
2403	2003	26	19	0.01	2
2403	2004	1	19	6.66666666666667E-03	2
2403	2004	2	19	6.66666666666667E-03	2
2403	2004	3	19	6.66666666666667E-03	2
2403	2004	4	19	0.01	2
2403	2004	8	19	6.66666666666667E-03	2
2403	2004	9	19	0.02	2
2403	2004	10	19	0.02	2
2403	2004	11	19	0.01	2
2403	2004	12	19	0.04	2
2403	2004	13	19	0.06	2
2403	2004	14	19	0.04	2
2403	2004	15	19	0.05	2
2403	2004	16	19	0.04	2
2403	2004	18	19	0.04	2
2403	2004	19	19	0.1	2
2403	2004	23	19	0.03	2
2403	2004	24	19	6.66666666666667E-03	2
2403	2005	1	19	6.66666666666667E-03	2
2403	2005	2	19	6.66666666666667E-03	2
2403	2005	8	19	6.66666666666667E-03	2
2403	2005	10	19	0.02	2
2403	2005	11	19	0.02	2
2403	2005	12	19	0.02	2
2403	2005	13	19	0.06	2
2403	2005	14	19	0.02	2
2403	2005	15	19	0.08	2
2403	2005	16	19	0.07	2
2403	2005	18	19	0.12	2
2403	2005	19	19	0.09	2
2403	2005	20	19	6.66666666666667E-03	2
2403	2005	21	19	0.05	2
2403	2005	22	19	0.01	2
2403	2005	23	19	0.02	2
2403	2005	24	19	6.66666666666667E-03	2
2403	2005	25	19	6.66666666666667E-03	2
2403	2006	1	19	6.66666666666667E-03	2
2403	2006	5	19	0.01	2
2403	2006	6	19	0.01	2
2403	2006	9	19	6.66666666666667E-03	2
2403	2006	10	19	0.02	2
2403	2006	11	19	0.01	2
2403	2006	13	19	0.08	2
2403	2006	14	19	0.12	2
2403	2006	15	19	0.18	2
2403	2006	16	19	0.15	2
2403	2006	17	19	0.04	2
2403	2006	18	19	0.26	2
2403	2006	19	19	0.05	2
2403	2006	20	19	0.02	2
2403	2006	21	19	6.66666666666667E-03	2
2403	2006	23	19	0.01	2
2403	2006	24	19	0.04	2
2403	2007	1	19	6.66666666666667E-03	2
2403	2007	3	19	6.66666666666667E-03	2
2403	2007	4	19	0.01	2
2403	2007	5	19	0.02	2
2403	2007	7	19	6.66666666666667E-03	2
2403	2007	11	19	0.08	2
2403	2007	14	19	0.05	2
2403	2007	17	19	0.04	2
2403	2007	18	19	0.02	2
2403	2007	18	19	0.03	2
2403	2007	19	19	6.66666666666667E-03	2
2403	2007	21	19	0.05	2
2403	2007	22	19	0.02	2
2411	2000	1	25	6.45161290322581E-03	0
2411	2000	1	32	0.04	0
2411	2000	2	25	0.01	0
2411	2000	2	32	0.08	0
2411	2000	3	25	3.2258064516129E-03	0
2411	2000	3	32	0.06	0
2411	2000	4	25	3.2258064516129E-03	0
2411	2000	4	32	0.06	0
2411	2000	5	21	7.69230769230769E-03	0
2411	2000	5	25	0.01	0
2411	2000	5	32	0.05	0
2411	2000	6	25	0.02	0
2411	2000	6	32	0.07	0
2411	2000	7	25	0.01	0
2411	2000	7	32	0.07	0
2411	2000	9	32	0.09	0
2411	2000	10	25	0.01	0
2411	2000	10	32	0.05	0
2411	2000	11	25	0.01	0
2411	2000	11	32	0.03	0
2411	2000	12	25	0.01	0
2411	2000	12	32	0.12	0
2411	2000	13	25	0.02	0
2411	2000	13	32	0.11	0
2411	2000	14	21	7.69230769230769E-03	0
2411	2000	14	25	0.06	0
2411	2000	14	32	0.67	0
2411	2000	16	21	0.02	0
2411	2000	16	25	0.07	0
2411	2000	16	32	0.67	0
2411	2000	17	21	0.09	0
2411	2000	17	25	0.15	0
2411	2000	17	32	0.58	0
2411	2000	18	21	0.02	0
2411	2000	18	25	0.1	0
2411	2000	18	32	0.62	0
2411	2000	19	21	0.03	0
2411	2000	19	25	0.12	0
2411	2000	19	32	0.65	0
2411	2000	20	21	0.02	0
2411	2000	20	25	0.06	0
2411	2000	20	32	0.44	0
2411	2000	21	21	0.03	0
2411	2000	21	25	0.05	0
2411	2000	21	32	0.33	0
2411	2000	23	25	0.02	0
2411	2000	23	32	0.08	0
2411	2000	24	25	8.72434017595308E-03	0
2411	2000	24	32	0.07	0
2411	2000	25	25	9.09090909090909E-03	0
2411	2000	25	32	2.12765957446809E-03	0
2411	2000	26	32	0.04	0
2411	2001	7	32	0.03	0
2411	2001	8	32	0.03	0
2411	2001	9	32	0.02	0
2411	2001	10	32	0.06	0
2411	2001	11	32	0.04	0
2411	2001	12	32	0.1	0
2411	2001	13	32	0.1	0
2411	2001	14	32	0.82	0
2411	2001	15	32	0.62	0
2411	2001	16	32	1.08	0
2411	2001	17	32	0.89	0
2411	2001	18	32	0.41	0
2411	2001	18	32	0.43	0
2411	2001	19	32	0.41	0
2411	2001	20	32	0.13	0
2411	2001	21	32	0.13	0
2411	2001	22	32	0.12	0
2411	2001	23	32	0.03	0
2411	2001	24	32	0.04	0
2411	2001	25	32	9.81996726677578E-03	0
2411	2002	1	25	0.01	0
2411	2002	1	32	0.04	0
2411	2002	3	21	7.69230769230769E-03	0
2411	2002	3	25	6.81818181818182E-03	0
2411	2002	3	32	0.07	0
2411	2002	4	25	2.27272727272727E-03	0
2411	2002	4	32	0.08	0
2411	2002	5	25	0.01	0
2411	2002	5	32	0.05	0
2411	2002	6	21	7.69230769230769E-03	0
2411	2002	6	25	0.01	0
2411	2002	6	32	0.1	0
2411	2002	7	25	0.01	0
2411	2002	7	32	0.05	0
2411	2002	9	25	0.02	0
2411	2002	9	32	0.04	0
2411	2002	10	21	7.69230769230769E-03	0
2411	2002	10	25	0.02	0
2411	2002	10	32	0.03	0
2411	2002	11	25	2.27272727272727E-03	0
2411	2002	11	32	0.04	0
2411	2002	12	25	0.02	0
2411	2002	12	32	0.06	0
2411	2002	13	25	4.54545454545455E-03	0
2411	2002	13	32	0.23	0
2411	2002	14	25	0.04	0
2411	2002	14	32	0.4	0
2411	2002	15	21	0.03	0
2411	2002	15	25	0.05	0
2411	2002	15	32	0.26	0
2411	2002	16	21	0.06	0
2411	2002	16	25	0.18	0
2411	2002	16	32	0.31	0
2411	2002	17	21	0.01	0
2411	2002	17	25	0.15	0
2411	2002	17	32	0.29	0
2411	2002	18	21	7.69230769230769E-03	0
2411	2002	18	25	0.14	0
2411	2002	18	32	0.13	0
2411	2002	20	21	0.01	0
2411	2002	20	25	0.05	0
2411	2002	20	32	0.16	0
2411	2002	21	21	0.01	0
2411	2002	21	25	0.05	0
2411	2002	21	32	0.15	0
2411	2002	22	25	0.02	0
2411	2002	22	32	0.06	0
2411	2002	23	25	9.09090909090909E-03	0
2411	2002	23	32	0.04	0
2411	2002	24	25	0.01	0
2411	2002	24	32	0.04	0
2411	2002	25	25	6.81818181818182E-03	0
2411	2002	25	32	0.02	0
2411	2002	26	25	2.27272727272727E-03	0
2411	2002	26	32	0.01	0
2411	2003	1	32	0.05	0
2411	2003	2	25	3.2258064516129E-03	0
2411	2003	2	32	0.03	0
2411	2003	3	25	0.01	0
2411	2003	3	32	0.02	0
2411	2003	4	25	4.54545454545455E-03	0
2411	2003	4	32	9.02421129860602E-03	0
2411	2003	5	25	0.01	0
2411	2003	5	32	0.05	0
2411	2003	6	25	2.27272727272727E-03	0
2411	2003	6	32	0.03	0
2411	2003	8	25	2.27272727272727E-03	0
2411	2003	8	32	0.04	0
2411	2003	9	25	0.02	0
2411	2003	9	32	0.02	0
2411	2003	10	25	0.01	0
2411	2003	10	32	0.02	0
2411	2003	11	25	0.02	0
2411	2003	11	32	0.04	0
2411	2003	12	25	0.07	0
2411	2003	12	32	0.16	0
2411	2003	13	21	0.03	0
2411	2003	13	25	0.09	0
2411	2003	13	32	0.5	0
2411	2003	14	21	0.02	0
2411	2003	14	25	0.12	0
2411	2003	14	32	0.47	0
2411	2003	15	21	0.01	0
2411	2003	15	25	0.1	0
2411	2003	15	32	0.46	0
2411	2003	16	21	0.01	0
2411	2003	16	25	0.06	0
2411	2003	16	32	0.48	0
2411	2003	17	21	0.06	0
2411	2003	17	25	0.08	0
2411	2003	17	32	0.47	0
2411	2003	18	21	0.03	0
2411	2003	18	25	0.1	0
2411	2003	18	32	0.36	0
2411	2003	19	21	0.03	0
2411	2003	19	25	0.05	0
2411	2003	19	32	0.32	0
2411	2003	20	21	0.01	0
2411	2003	20	25	0.07	0
2411	2003	20	32	0.88	0
2411	2003	21	25	0.05	0
2411	2003	21	32	0.49	0
2411	2003	22	21	0.02	0
2411	2003	22	25	0.03	0
2411	2003	22	32	0.4	0
2411	2003	23	25	0.01	0
2411	2003	23	32	0.39	0
2411	2003	24	25	0.02	0
2411	2003	24	32	0.29	0
2411	2003	25	21	7.69230769230769E-03	0
2411	2003	25	25	0.02	0
2411	2003	25	32	0.16	0
2411	2003	26	21	7.69230769230769E-03	0
2411	2003	26	25	0.02	0
2411	2003	26	32	0.08	0
2411	2004	2	25	6.45161290322581E-03	0
2411	2004	2	32	0.05	0
2411	2004	3	32	0.08	0
2411	2004	4	25	6.81818181818182E-03	0
2411	2004	4	32	0.03	0
2411	2004	6	25	0.01	0
2411	2004	6	32	0.01	0
2411	2004	7	21	0.01	0
2411	2004	7	25	0.01	0
2411	2004	7	32	0.05	0
2411	2004	8	25	0.01	0
2411	2004	8	32	0.03	0
2411	2004	9	25	0.01	0
2411	2004	9	32	0.02	0
2411	2004	10	25	0.02	0
2411	2004	10	32	0.1	0
2411	2004	11	25	0.04	0
2411	2004	11	32	0.15	0
2411	2004	12	21	0.02	0
2411	2004	12	25	0.07	0
2411	2004	12	32	0.18	0
2411	2004	13	21	0.02	0
2411	2004	13	25	0.03	0
2411	2004	13	32	0.35	0
2411	2004	14	21	7.69230769230769E-03	0
2411	2004	14	25	0.02	0
2411	2004	14	32	0.17	0
2411	2004	16	21	0.01	0
2411	2004	16	25	0.05	0
2411	2004	16	32	0.6	0
2411	2004	17	21	0.01	0
2411	2004	17	25	0.07	0
2411	2004	17	32	0.37	0
2411	2004	18	21	7.69230769230769E-03	0
2411	2004	18	25	0.09	0
2411	2004	18	32	0.5	0
2411	2004	19	21	0.05	0
2411	2004	19	25	0.1	0
2411	2004	19	32	0.44	0
2411	2004	20	21	0.02	0
2411	2004	20	25	0.06	0
2411	2004	20	32	0.35	0
2411	2004	21	25	0.04	0
2411	2004	21	32	0.32	0
2411	2004	22	25	0.01	0
2411	2004	22	32	0.19	0
2411	2004	23	25	0.02	0
2411	2004	23	32	0.06	0
2411	2004	25	25	4.54545454545455E-03	0
2411	2004	25	32	0.03	0
2411	2004	26	25	2.27272727272727E-03	0
2411	2004	26	32	0.01	0
2411	2005	1	25	2.27272727272727E-03	0
2411	2005	1	32	0.02	0
2411	2005	2	32	0.05	0
2411	2005	3	32	0.01	0
2411	2005	4	25	0.02	0
2411	2005	4	32	0.07	0
2411	2005	5	25	0.01	0
2411	2005	5	32	0.05	0
2411	2005	6	21	7.69230769230769E-03	0
2411	2005	6	25	0.02	0
2411	2005	6	32	0.05	0
2411	2005	7	21	7.69230769230769E-03	0
2411	2005	7	25	0.03	0
2411	2005	7	32	0.03	0
2411	2005	9	25	0.01	0
2411	2005	9	32	0.04	0
2411	2005	11	25	0.04	0
2411	2005	11	32	0.02	0
2411	2005	12	25	0.02	0
2411	2005	12	32	0.05	0
2411	2005	14	25	0.06	0
2411	2005	14	32	0.47	0
2411	2005	15	21	0.02	0
2411	2005	15	25	0.16	0
2411	2005	15	32	0.33	0
2411	2005	16	21	0.01	0
2411	2005	16	25	0.18	0
2411	2005	16	32	0.3	0
2411	2005	17	21	0.01	0
2411	2005	17	25	0.18	0
2411	2005	17	32	0.3	0
2411	2005	18	25	0.06	0
2411	2005	18	32	0.26	0
2411	2005	19	21	0.07	0
2411	2005	19	25	0.09	0
2411	2005	19	32	0.23	0
2411	2005	20	21	0.02	0
2411	2005	20	25	0.06	0
2411	2005	20	32	0.27	0
2411	2005	22	25	0.05	0
2411	2005	22	32	0.05	0
2411	2005	23	25	0.04	0
2411	2005	23	32	0.1	0
2411	2005	24	25	0.01	0
2411	2005	24	32	0.05	0
2411	2005	25	21	7.69230769230769E-03	0
2411	2005	25	25	0.01	0
2411	2005	25	32	0.01	0
2411	2005	26	25	0.01	0
2411	2005	26	32	0.01	0
2411	2006	1	25	2.27272727272727E-03	0
2411	2006	1	32	0.04	0
2411	2006	2	25	2.27272727272727E-03	0
2411	2006	2	32	0.03	0
2411	2006	3	25	8.72434017595308E-03	0
2411	2006	3	32	0.12	0
2411	2006	4	25	0.02	0
2411	2006	4	32	0.08	0
2411	2006	5	25	0.01	0
2411	2006	5	32	0.03	0
2411	2006	6	25	0.01	0
2411	2006	6	32	0.05	0
2411	2006	7	25	0.03	0
2411	2006	7	32	0.06	0
2411	2006	9	21	7.69230769230769E-03	0
2411	2006	9	25	0.02	0
2411	2006	9	32	0.05	0
2411	2006	10	25	0.01	0
2411	2006	10	32	0.02	0
2411	2006	11	25	0.08	0
2411	2006	11	32	0.16	0
2411	2006	12	21	0.01	0
2411	2006	12	25	0.09	0
2411	2006	12	32	0.35	0
2411	2006	13	21	0.01	0
2411	2006	13	25	0.04	0
2411	2006	13	32	0.28	0
2411	2006	14	21	0.05	0
2411	2006	14	25	0.21	0
2411	2006	14	32	1.01	0
2411	2006	15	21	0.05	0
2411	2006	15	25	0.11	0
2411	2006	15	32	0.62	0
2411	2006	16	21	0.02	0
2411	2006	16	25	0.26	0
2411	2006	16	32	0.51	0
2411	2006	17	21	7.69230769230769E-03	0
2411	2006	17	25	0.34	0
2411	2006	17	32	0.86	0
2411	2006	18	21	7.69230769230769E-03	0
2411	2006	18	25	0.12	0
2411	2006	18	32	0.29	0
2411	2006	19	21	7.69230769230769E-03	0
2411	2006	19	25	0.06	0
2411	2006	19	32	0.26	0
2411	2006	20	21	0.01	0
2411	2006	20	25	0.06	0
2411	2006	20	32	0.27	0
2411	2006	21	25	0.02	0
2411	2006	21	32	0.03	0
2411	2006	22	25	0.05	0
2411	2006	22	32	0.15	0
2411	2006	23	25	0.01	0
2411	2006	23	32	0.14	0
2411	2006	24	25	0.05	0
2411	2006	24	32	0.02	0
2411	2006	25	21	7.69230769230769E-03	0
2411	2006	25	25	0.03	0
2411	2006	25	32	0.04	0
2411	2006	26	21	7.69230769230769E-03	0
2411	2006	26	25	0.03	0
2411	2006	26	32	0.04	0
2411	2007	1	25	2.27272727272727E-03	0
2411	2007	1	32	0.04	0
2411	2007	2	21	7.69230769230769E-03	0
2411	2007	2	25	0.01	0
2411	2007	2	32	0.1	0
2411	2007	3	25	0.01	0
2411	2007	3	32	0.05	0
2411	2007	4	25	0.02	0
2411	2007	4	32	0.06	0
2411	2007	5	21	7.69230769230769E-03	0
2411	2007	5	25	0.04	0
2411	2007	5	32	0.06	0
2411	2007	7	25	0.02	0
2411	2007	7	32	0.04	0
2411	2007	8	25	0.01	0
2411	2007	8	32	0.04	0
2411	2007	9	25	0.01	0
2411	2007	9	32	0.02	0
2411	2007	10	25	0.06	0
2411	2007	10	32	0.11	0
2411	2007	11	25	0.06	0
2411	2007	11	32	0.27	0
2411	2007	12	25	0.03	0
2411	2007	12	32	0.21	0
2411	2007	14	21	7.69230769230769E-03	0
2411	2007	14	25	0.13	0
2411	2007	14	32	1.06	0
2411	2007	15	21	7.69230769230769E-03	0
2411	2007	15	25	0.06	0
2411	2007	15	32	0.45	0
2411	2007	16	21	0.02	0
2411	2007	16	25	0.14	0
2411	2007	16	32	0.82	0
2411	2007	17	21	0.03	0
2411	2007	17	25	0.2	0
2411	2007	17	32	0.69	0
2411	2007	18	21	0.01	0
2411	2007	18	25	0.14	0
2411	2007	18	32	0.31	0
2411	2007	19	21	0.01	0
2411	2007	19	25	0.11	0
2411	2007	19	32	0.55	0
2411	2007	20	21	7.69230769230769E-03	0
2411	2007	20	25	0.06	0
2411	2007	20	32	0.22	0
2411	2007	21	25	0.02	0
2411	2007	21	32	0.07	0
2411	2007	22	25	0.04	0
2411	2007	22	32	0.06	0
2411	2007	23	25	4.54545454545455E-03	0
2411	2007	23	32	0.01	0
2411	2007	24	25	6.81818181818182E-03	0
2411	2007	24	32	0.01	0
2411	2007	25	25	9.09090909090909E-03	0
2411	2007	25	32	7.69230769230769E-03	0
2411	2007	26	25	6.81818181818182E-03	0
2411	2007	26	32	0.02	0
3101	2000	1	26	0.005	0
3101	2000	3	14	0.005	0
3101	2000	3	16	0.01	0
3101	2000	3	25	0.005	0
3101	2000	3	26	0.005	0
3101	2000	4	14	0.005	0
3101	2000	4	16	0.01	0
3101	2000	4	25	0.005	0
3101	2000	4	26	0.005	0
3101	2000	5	16	0.01	0
3101	2000	5	26	0.005	0
3101	2000	6	14	0.01	0
3101	2000	6	16	0.03	0
3101	2000	6	25	0.01	0
3101	2000	6	26	0.02	0
3101	2000	8	16	0.005	0
3101	2000	8	25	0.01	0
3101	2000	8	26	0.01	0
3101	2000	8	32	0.005	0
3101	2000	10	14	0.005	0
3101	2000	10	16	0.03	0
3101	2000	10	25	0.005	0
3101	2000	11	14	0.005	0
3101	2000	11	16	0.01	0
3101	2000	11	25	0.01	0
3101	2000	11	26	0.01	0
3101	2000	14	14	0.03	0
3101	2000	14	16	0.04	0
3101	2000	14	25	0.04	0
3101	2000	14	26	0.31	0
3101	2000	14	32	0.06	0
3101	2000	15	14	0.04	0
3101	2000	15	16	0.06	0
3101	2000	15	25	0.02	0
3101	2000	15	26	0.18	0
3101	2000	15	32	0.08	0
3101	2000	16	14	0.08	0
3101	2000	16	16	0.08	0
3101	2000	16	25	0.05	0
3101	2000	16	26	0.29	0
3101	2000	16	32	0.01	0
3101	2000	17	14	0.05	0
3101	2000	17	16	0.13	0
3101	2000	17	22	0.12	0
3101	2000	17	25	0.13	0
3101	2000	17	26	0.87	0
3101	2000	17	32	0.06	0
3101	2000	18	14	0.03	0
3101	2000	18	14	0.05	0
3101	2000	18	16	0.13	0
3101	2000	18	16	0.25	0
3101	2000	18	22	0.12	0
3101	2000	18	25	0.13	0
3101	2000	18	25	0.14	0
3101	2000	18	26	0.69	0
3101	2000	18	26	0.87	0
3101	2000	18	32	0.06	0
3101	2000	18	32	0.19	0
3101	2000	19	14	0.14	0
3101	2000	19	16	0.21	0
3101	2000	19	22	0.02	0
3101	2000	19	25	0.24	0
3101	2000	19	26	0.58	0
3101	2000	19	32	0.11	0
3101	2000	20	14	0.14	0
3101	2000	20	16	0.21	0
3101	2000	20	22	0.02	0
3101	2000	20	25	0.24	0
3101	2000	20	26	0.58	0
3101	2000	20	32	0.11	0
3101	2000	21	14	0.05	0
3101	2000	21	16	0.22	0
3101	2000	21	22	0.04	0
3101	2000	21	25	0.13	0
3101	2000	21	26	0.36	0
3101	2000	21	32	0.01	0
3101	2000	22	14	0.01	0
3101	2000	22	16	0.09	0
3101	2000	22	25	0.05	0
3101	2000	22	26	0.23	0
3101	2000	22	32	0.02	0
3101	2000	23	14	0.01	0
3101	2000	23	16	0.03	0
3101	2000	23	25	0.04	0
3101	2000	23	26	0.09	0
3101	2000	23	32	0.02	0
3101	2000	24	14	0.01	0
3101	2000	24	16	0.01	0
3101	2000	24	22	0.01	0
3101	2000	24	25	0.04	0
3101	2000	24	26	0.03	0
3101	2000	24	32	0.01	0
3101	2000	25	14	0.01	0
3101	2000	25	16	0.01	0
3101	2000	25	22	0.01	0
3101	2000	25	25	0.04	0
3101	2000	25	26	0.03	0
3101	2000	25	32	0.01	0
3101	2001	1	26	0.005	0
3101	2001	2	26	0.01	0
3101	2001	2	32	0.005	0
3101	2001	3	26	0.005	0
3101	2001	3	32	0.005	0
3101	2001	5	14	0.005	0
3101	2001	5	16	0.005	0
3101	2001	5	22	0.005	0
3101	2001	13	14	0.01	0
3101	2001	13	16	0.02	0
3101	2001	13	22	0.005	0
3101	2001	13	25	0.005	0
3101	2001	13	26	0.01	0
3101	2001	13	32	0.005	0
3101	2001	14	14	0.02	0
3101	2001	14	16	0.17	0
3101	2001	14	25	0.07	0
3101	2001	14	26	0.53	0
3101	2001	14	32	0.06	0
3101	2001	15	14	0.02	0
3101	2001	15	16	0.17	0
3101	2001	15	25	0.07	0
3101	2001	15	26	0.53	0
3101	2001	15	32	0.06	0
3101	2001	16	14	0.04	0
3101	2001	16	16	0.24	0
3101	2001	16	25	0.1	0
3101	2001	16	26	0.5	0
3101	2001	16	32	0.16	0
3101	2001	17	14	0.06	0
3101	2001	17	16	0.46	0
3101	2001	17	22	0.16	0
3101	2001	17	25	0.16	0
3101	2001	17	26	0.59	0
3101	2001	17	32	0.11	0
3101	2001	18	14	0.1	0
3101	2001	18	16	0.43	0
3101	2001	18	22	0.1	0
3101	2001	18	25	0.23	0
3101	2001	18	26	0.24	0
3101	2001	18	32	0.07	0
3101	2001	20	14	0.04	0
3101	2001	20	16	0.13	0
3101	2001	20	22	0.04	0
3101	2001	20	25	0.09	0
3101	2001	20	26	0.24	0
3101	2001	20	32	0.02	0
3101	2001	23	14	0.01	0
3101	2001	23	16	0.02	0
3101	2001	23	22	0.01	0
3101	2001	23	25	0.02	0
3101	2001	23	26	0.04	0
3101	2001	23	32	0.01	0
3101	2001	24	14	0.005	0
3101	2001	24	16	0.05	0
3101	2001	24	22	0.01	0
3101	2001	24	25	0.02	0
3101	2001	25	14	0.005	0
3101	2001	25	16	0.07	0
3101	2001	25	22	0.02	0
3101	2001	25	25	0.03	0
3101	2001	26	16	0.02	0
3101	2001	26	22	0.005	0
3101	2001	26	25	0.01	0
3101	2002	1	14	0.005	0
3101	2002	1	16	0.01	0
3101	2002	1	22	0.01	0
3101	2002	1	25	0.01	0
3101	2002	1	26	0.07	0
3101	2002	1	32	0.005	0
3101	2002	2	16	0.005	0
3101	2002	2	22	0.005	0
3101	2002	2	26	0.03	0
3101	2002	3	14	0.005	0
3101	2002	3	16	0.01	0
3101	2002	3	25	0.005	0
3101	2002	3	26	0.01	0
3101	2002	5	14	0.005	0
3101	2002	5	16	0.02	0
3101	2002	5	22	0.005	0
3101	2002	5	25	0.01	0
3101	2002	5	26	0.01	0
3101	2002	5	32	0.005	0
3101	2002	6	14	0.01	0
3101	2002	6	16	0.04	0
3101	2002	6	25	0.02	0
3101	2002	6	26	0.03	0
3101	2002	6	32	0.005	0
3101	2002	7	14	0.05	0
3101	2002	7	16	0.16	0
3101	2002	7	22	0.02	0
3101	2002	7	25	0.03	0
3101	2002	7	26	0.08	0
3101	2002	7	32	0.02	0
3101	2002	8	14	0.01	0
3101	2002	8	16	0.12	0
3101	2002	8	22	0.005	0
3101	2002	8	25	0.02	0
3101	2002	8	26	0.04	0
3101	2002	8	32	0.01	0
3101	2002	9	14	0.01	0
3101	2002	9	16	0.04	0
3101	2002	9	22	0.01	0
3101	2002	9	25	0.005	0
3101	2002	9	26	0.005	0
3101	2002	11	14	0.01	0
3101	2002	11	16	0.04	0
3101	2002	11	22	0.01	0
3101	2002	11	25	0.01	0
3101	2002	11	26	0.02	0
3101	2002	11	32	0.005	0
3101	2002	12	14	0.02	0
3101	2002	12	16	0.15	0
3101	2002	12	26	0.08	0
3101	2002	12	32	0.06	0
3101	2002	13	14	0.03	0
3101	2002	13	16	0.23	0
3101	2002	13	22	0.01	0
3101	2002	13	25	0.06	0
3101	2002	13	26	0.27	0
3101	2002	13	32	0.06	0
3101	2002	14	14	0.07	0
3101	2002	14	16	0.32	0
3101	2002	14	22	0.02	0
3101	2002	14	25	0.05	0
3101	2002	14	26	0.44	0
3101	2002	14	32	0.23	0
3101	2002	15	14	0.1	0
3101	2002	15	16	0.36	0
3101	2002	15	22	0.06	0
3101	2002	15	25	0.08	0
3101	2002	15	26	0.42	0
3101	2002	15	32	0.16	0
3101	2002	16	14	0.14	0
3101	2002	16	16	0.54	0
3101	2002	16	22	0.05	0
3101	2002	16	25	0.22	0
3101	2002	16	26	0.45	0
3101	2002	16	32	0.07	0
3101	2002	17	14	0.09	0
3101	2002	17	16	0.35	0
3101	2002	17	22	0.04	0
3101	2002	17	25	0.11	0
3101	2002	17	26	0.46	0
3101	2002	17	32	0.11	0
3101	2002	18	14	0.06	0
3101	2002	18	16	0.27	0
3101	2002	18	22	0.12	0
3101	2002	18	25	0.17	0
3101	2002	18	26	0.23	0
3101	2002	18	32	0.13	0
3101	2002	20	14	0.02	0
3101	2002	20	16	0.17	0
3101	2002	20	22	0.04	0
3101	2002	20	25	0.09	0
3101	2002	20	26	0.09	0
3101	2002	20	32	0.02	0
3101	2002	21	14	0.05	0
3101	2002	21	16	0.05	0
3101	2002	21	22	0.03	0
3101	2002	21	25	0.08	0
3101	2002	21	26	0.05	0
3101	2002	22	14	0.03	0
3101	2002	22	16	0.03	0
3101	2002	22	22	0.01	0
3101	2002	22	25	0.03	0
3101	2002	22	26	0.01	0
3101	2002	22	32	0.01	0
3101	2002	25	14	0.01	0
3101	2002	25	16	0.01	0
3101	2002	25	22	0.02	0
3101	2002	25	25	0.01	0
3101	2002	25	26	0.01	0
3101	2002	25	32	0.005	0
3101	2002	26	16	0.01	0
3101	2002	26	22	0.005	0
3101	2002	26	26	0.005	0
3101	2002	26	32	0.005	0
3101	2003	1	25	0.005	0
3101	2003	1	26	0.005	0
3101	2003	3	14	0.01	0
3101	2003	3	16	0.01	0
3101	2003	3	22	0.02	0
3101	2003	3	25	0.01	0
3101	2003	3	26	0.05	0
3101	2003	3	32	0.005	0
3101	2003	4	14	0.01	0
3101	2003	4	16	0.03	0
3101	2003	4	25	0.01	0
3101	2003	4	26	0.03	0
3101	2003	4	32	0.005	0
3101	2003	5	14	0.03	0
3101	2003	5	16	0.03	0
3101	2003	5	22	0.01	0
3101	2003	5	25	0.03	0
3101	2003	5	26	0.02	0
3101	2003	5	32	0.02	0
3101	2003	6	14	0.03	0
3101	2003	6	16	0.02	0
3101	2003	6	22	0.005	0
3101	2003	6	25	0.02	0
3101	2003	6	26	0.02	0
3101	2003	6	32	0.01	0
3101	2003	7	14	0.005	0
3101	2003	7	16	0.005	0
3101	2003	7	22	0.005	0
3101	2003	7	26	0.04	0
3101	2003	7	32	0.01	0
3101	2003	8	16	0.01	0
3101	2003	8	25	0.01	0
3101	2003	8	26	0.01	0
3101	2003	8	32	0.04	0
3101	2003	9	14	0.01	0
3101	2003	9	16	0.01	0
3101	2003	9	22	0.005	0
3101	2003	9	25	0.01	0
3101	2003	9	26	0.005	0
3101	2003	9	32	0.005	0
3101	2003	10	16	0.15	0
3101	2003	10	25	0.02	0
3101	2003	10	26	0.005	0
3101	2003	11	14	0.005	0
3101	2003	11	16	0.03	0
3101	2003	11	22	0.005	0
3101	2003	11	25	0.02	0
3101	2003	12	16	0.07	0
3101	2003	12	22	0.02	0
3101	2003	12	25	0.01	0
3101	2003	12	26	0.05	0
3101	2003	12	32	0.07	0
3101	2003	13	14	0.04	0
3101	2003	13	16	0.32	0
3101	2003	13	22	0.03	0
3101	2003	13	25	0.05	0
3101	2003	13	26	0.19	0
3101	2003	13	32	0.13	0
3101	2003	14	14	0.02	0
3101	2003	14	16	0.48	0
3101	2003	14	22	0.04	0
3101	2003	14	25	0.28	0
3101	2003	14	26	0.45	0
3101	2003	14	32	0.25	0
3101	2003	15	14	0.04	0
3101	2003	15	16	1.35	0
3101	2003	15	22	0.07	0
3101	2003	15	25	0.66	0
3101	2003	15	26	0.66	0
3101	2003	15	32	0.27	0
3101	2003	16	14	0.24	0
3101	2003	16	16	1.26	0
3101	2003	16	22	0.09	0
3101	2003	16	25	2.08	0
3101	2003	16	26	0.49	0
3101	2003	16	32	0.22	0
3101	2003	18	14	0.05	0
3101	2003	18	16	0.5	0
3101	2003	18	22	0.05	0
3101	2003	18	25	0.51	0
3101	2003	18	26	0.2	0
3101	2003	18	32	0.15	0
3101	2003	19	14	0.01	0
3101	2003	19	16	0.06	0
3101	2003	19	22	0.005	0
3101	2003	19	25	0.06	0
3101	2003	19	26	0.09	0
3101	2003	19	32	0.01	0
3101	2003	20	14	0.01	0
3101	2003	20	16	0.06	0
3101	2003	20	22	0.005	0
3101	2003	20	25	0.06	0
3101	2003	20	26	0.09	0
3101	2003	20	32	0.01	0
3101	2003	22	14	0.02	0
3101	2003	22	16	0.1	0
3101	2003	22	22	0.005	0
3101	2003	22	25	0.03	0
3101	2003	22	26	0.02	0
3101	2003	23	14	0.02	0
3101	2003	23	16	0.08	0
3101	2003	23	22	0.01	0
3101	2003	23	25	0.05	0
3101	2003	23	26	0.02	0
3101	2003	23	32	0.005	0
3101	2003	24	14	0.02	0
3101	2003	24	16	0.04	0
3101	2003	24	22	0.02	0
3101	2003	24	25	0.06	0
3101	2003	24	26	0.02	0
3101	2003	24	32	0.005	0
3101	2003	25	14	0.02	0
3101	2003	25	16	0.07	0
3101	2003	25	25	0.06	0
3101	2003	25	26	0.02	0
3101	2003	25	32	0.01	0
3101	2003	26	14	0.01	0
3101	2003	26	16	0.06	0
3101	2003	26	22	0.01	0
3101	2003	26	25	0.05	0
3101	2003	26	26	0.01	0
3101	2003	26	32	0.005	0
3101	2004	2	14	0.005	0
3101	2004	2	16	0.06	0
3101	2004	2	22	0.01	0
3101	2004	2	26	0.04	0
3101	2004	2	32	0.005	0
3101	2004	3	14	0.01	0
3101	2004	3	16	0.1	0
3101	2004	3	22	0.02	0
3101	2004	3	25	0.005	0
3101	2004	3	26	0.05	0
3101	2004	3	32	0.005	0
3101	2004	4	14	0.01	0
3101	2004	4	16	0.04	0
3101	2004	4	22	0.01	0
3101	2004	4	25	0.01	0
3101	2004	4	26	0.01	0
3101	2004	4	32	0.005	0
3101	2004	5	16	0.02	0
3101	2004	5	22	0.01	0
3101	2004	5	26	0.005	0
3101	2004	5	32	0.005	0
3101	2004	6	14	0.005	0
3101	2004	6	16	0.05	0
3101	2004	6	22	0.01	0
3101	2004	6	25	0.005	0
3101	2004	6	26	0.02	0
3101	2004	6	32	0.01	0
3101	2004	7	14	0.02	0
3101	2004	7	16	0.13	0
3101	2004	7	22	0.02	0
3101	2004	7	25	0.02	0
3101	2004	7	26	0.02	0
3101	2004	7	32	0.04	0
3101	2004	8	16	0.11	0
3101	2004	8	22	0.02	0
3101	2004	8	25	0.01	0
3101	2004	8	26	0.005	0
3101	2004	8	32	0.005	0
3101	2004	9	14	0.005	0
3101	2004	9	16	0.15	0
3101	2004	9	22	0.01	0
3101	2004	9	25	0.02	0
3101	2004	9	26	0.01	0
3101	2004	10	14	0.01	0
3101	2004	10	16	0.04	0
3101	2004	10	22	0.01	0
3101	2004	10	25	0.005	0
3101	2004	10	32	0.01	0
3101	2004	11	14	0.02	0
3101	2004	11	16	0.05	0
3101	2004	11	22	0.01	0
3101	2004	11	25	0.02	0
3101	2004	11	26	0.005	0
3101	2004	11	32	0.01	0
3101	2004	12	14	0.01	0
3101	2004	12	16	0.04	0
3101	2004	12	22	0.01	0
3101	2004	12	25	0.04	0
3101	2004	12	26	0.02	0
3101	2004	12	32	0.01	0
3101	2004	13	14	0.06	0
3101	2004	13	16	0.24	0
3101	2004	13	22	0.01	0
3101	2004	13	25	0.05	0
3101	2004	13	26	0.15	0
3101	2004	13	32	0.11	0
3101	2004	14	14	0.12	0
3101	2004	14	16	0.69	0
3101	2004	14	22	0.11	0
3101	2004	14	25	0.19	0
3101	2004	14	26	0.42	0
3101	2004	14	32	0.18	0
3101	2004	15	14	0.13	0
3101	2004	15	16	0.4	0
3101	2004	15	22	0.05	0
3101	2004	15	25	0.21	0
3101	2004	15	26	0.63	0
3101	2004	15	32	0.08	0
3101	2004	16	14	0.15	0
3101	2004	16	16	0.25	0
3101	2004	16	22	0.07	0
3101	2004	16	25	0.25	0
3101	2004	16	26	0.24	0
3101	2004	16	32	0.11	0
3101	2004	17	14	0.25	0
3101	2004	17	16	0.93	0
3101	2004	17	22	0.11	0
3101	2004	17	25	0.65	0
3101	2004	17	26	0.39	0
3101	2004	17	32	0.12	0
3101	2004	18	14	0.16	0
3101	2004	18	16	0.71	0
3101	2004	18	22	0.09	0
3101	2004	18	25	0.62	0
3101	2004	18	26	0.25	0
3101	2004	18	32	0.1	0
3101	2004	19	14	0.13	0
3101	2004	19	16	0.52	0
3101	2004	19	22	0.09	0
3101	2004	19	25	0.3	0
3101	2004	19	26	0.14	0
3101	2004	19	32	0.04	0
3101	2004	20	14	0.04	0
3101	2004	20	16	0.45	0
3101	2004	20	22	0.09	0
3101	2004	20	25	0.25	0
3101	2004	20	26	0.18	0
3101	2004	20	32	0.06	0
3101	2004	21	14	0.05	0
3101	2004	21	16	0.04	0
3101	2004	21	22	0.01	0
3101	2004	21	25	0.06	0
3101	2004	21	26	0.11	0
3101	2004	21	32	0.02	0
3101	2004	22	14	0.07	0
3101	2004	22	16	0.11	0
3101	2004	22	22	0.05	0
3101	2004	22	25	0.23	0
3101	2004	22	26	0.17	0
3101	2004	22	32	0.04	0
3101	2004	23	14	0.06	0
3101	2004	23	16	0.06	0
3101	2004	23	22	0.03	0
3101	2004	23	25	0.11	0
3101	2004	23	26	0.08	0
3101	2004	23	32	0.02	0
3101	2004	25	14	0.02	0
3101	2004	25	16	0.1	0
3101	2004	25	22	0.02	0
3101	2004	25	25	0.12	0
3101	2004	25	26	0.01	0
3101	2004	26	14	0.01	0
3101	2004	26	16	0.04	0
3101	2004	26	22	0.01	0
3101	2004	26	25	0.07	0
3101	2004	26	26	0.01	0
3101	2004	26	32	0.01	0
3101	2005	2	14	0.005	0
3101	2005	2	16	0.01	0
3101	2005	2	22	0.01	0
3101	2005	2	25	0.005	0
3101	2005	2	26	0.01	0
3101	2005	4	14	0.04	0
3101	2005	4	16	0.05	0
3101	2005	4	22	0.02	0
3101	2005	4	25	0.01	0
3101	2005	4	26	0.06	0
3101	2005	4	32	0.005	0
3101	2005	5	14	0.005	0
3101	2005	5	14	0.04	0
3101	2005	5	16	0.03	0
3101	2005	5	16	0.04	0
3101	2005	5	22	0.005	0
3101	2005	5	22	0.01	0
3101	2005	5	25	0.01	0
3101	2005	5	26	0.04	0
3101	2005	5	26	0.05	0
3101	2005	5	32	0.005	0
3101	2005	5	32	0.03	0
3101	2005	6	14	0.005	0
3101	2005	6	16	0.03	0
3101	2005	6	22	0.005	0
3101	2005	6	25	0.01	0
3101	2005	6	26	0.05	0
3101	2005	6	32	0.03	0
3101	2005	7	14	0.01	0
3101	2005	7	16	0.08	0
3101	2005	7	22	0.01	0
3101	2005	7	25	0.01	0
3101	2005	7	26	0.02	0
3101	2005	7	32	0.03	0
3101	2005	8	14	0.01	0
3101	2005	8	16	0.09	0
3101	2005	8	22	0.005	0
3101	2005	8	25	0.01	0
3101	2005	8	26	0.03	0
3101	2005	8	32	0.01	0
3101	2005	9	14	0.03	0
3101	2005	9	16	0.06	0
3101	2005	9	25	0.005	0
3101	2005	9	26	0.02	0
3101	2005	9	32	0.01	0
3101	2005	10	14	0.01	0
3101	2005	10	16	0.04	0
3101	2005	10	22	0.005	0
3101	2005	10	25	0.005	0
3101	2005	10	26	0.01	0
3101	2005	10	32	0.01	0
3101	2005	11	14	0.01	0
3101	2005	11	16	0.01	0
3101	2005	11	25	0.01	0
3101	2005	11	26	0.03	0
3101	2005	12	14	0.005	0
3101	2005	12	16	0.07	0
3101	2005	12	22	0.01	0
3101	2005	12	25	0.02	0
3101	2005	12	26	0.03	0
3101	2005	12	32	0.005	0
3101	2005	15	14	0.18	0
3101	2005	15	16	0.73	0
3101	2005	15	22	0.11	0
3101	2005	15	25	0.5	0
3101	2005	15	26	0.97	0
3101	2005	15	32	0.38	0
3101	2005	16	14	0.1	0
3101	2005	16	16	0.26	0
3101	2005	16	22	0.01	0
3101	2005	16	25	0.24	0
3101	2005	16	26	0.42	0
3101	2005	16	32	0.07	0
3101	2005	17	14	0.06	0
3101	2005	17	16	0.41	0
3101	2005	17	22	0.03	0
3101	2005	17	25	0.3	0
3101	2005	17	26	0.52	0
3101	2005	17	32	0.24	0
3101	2005	18	14	0.18	0
3101	2005	18	16	0.61	0
3101	2005	18	22	0.03	0
3101	2005	18	25	0.31	0
3101	2005	18	26	0.21	0
3101	2005	18	32	0.13	0
3101	2005	20	14	0.07	0
3101	2005	20	16	0.19	0
3101	2005	20	22	0.03	0
3101	2005	20	25	0.08	0
3101	2005	20	26	0.07	0
3101	2005	20	32	0.02	0
3101	2005	21	14	0.05	0
3101	2005	21	16	0.06	0
3101	2005	21	22	0.01	0
3101	2005	21	25	0.08	0
3101	2005	21	26	0.04	0
3101	2005	21	32	0.01	0
3101	2005	22	14	0.04	0
3101	2005	22	14	0.07	0
3101	2005	22	16	0.07	0
3101	2005	22	16	0.1	0
3101	2005	22	22	0.01	0
3101	2005	22	22	0.02	0
3101	2005	22	25	0.03	0
3101	2005	22	25	0.05	0
3101	2005	22	26	0.04	0
3101	2005	22	32	0.005	0
3101	2005	22	32	0.01	0
3101	2005	23	14	0.07	0
3101	2005	23	16	0.1	0
3101	2005	23	22	0.02	0
3101	2005	23	25	0.05	0
3101	2005	23	26	0.04	0
3101	2005	23	32	0.01	0
3101	2005	25	14	0.02	0
3101	2005	25	16	0.07	0
3101	2005	25	22	0.02	0
3101	2005	25	25	0.05	0
3101	2005	25	26	0.03	0
3101	2005	25	32	0.02	0
3101	2005	26	14	0.005	0
3101	2005	26	16	0.04	0
3101	2005	26	26	0.01	0
3101	2006	2	26	0.02	0
3101	2006	2	32	0.005	0
3101	2006	3	14	0.005	0
3101	2006	3	16	0.005	0
3101	2006	3	26	0.005	0
3101	2006	4	14	0.01	0
3101	2006	4	16	0.02	0
3101	2006	4	25	0.01	0
3101	2006	4	26	0.005	0
3101	2006	4	32	0.005	0
3101	2006	5	14	0.03	0
3101	2006	5	16	0.04	0
3101	2006	5	22	0.005	0
3101	2006	5	25	0.005	0
3101	2006	5	26	0.03	0
3101	2006	6	14	0.07	0
3101	2006	6	16	0.03	0
3101	2006	6	22	0.01	0
3101	2006	6	25	0.01	0
3101	2006	6	26	0.08	0
3101	2006	6	32	0.03	0
3101	2006	7	14	0.03	0
3101	2006	7	16	0.09	0
3101	2006	7	22	0.005	0
3101	2006	7	25	0.02	0
3101	2006	7	26	0.05	0
3101	2006	7	32	0.005	0
3101	2006	8	16	0.01	0
3101	2006	8	22	0.005	0
3101	2006	8	25	0.01	0
3101	2006	8	26	0.02	0
3101	2006	8	32	0.01	0
3101	2006	9	14	0.01	0
3101	2006	9	16	0.01	0
3101	2006	9	25	0.005	0
3101	2006	9	26	0.02	0
3101	2006	9	32	0.01	0
3101	2006	10	14	0.01	0
3101	2006	10	16	0.005	0
3101	2006	10	22	0.01	0
3101	2006	10	25	0.005	0
3101	2006	10	26	0.005	0
3101	2006	10	32	0.005	0
3101	2006	11	14	0.005	0
3101	2006	11	16	0.03	0
3101	2006	11	22	0.005	0
3101	2006	11	25	0.01	0
3101	2006	11	26	0.02	0
3101	2006	11	32	0.01	0
3101	2006	12	14	0.02	0
3101	2006	12	16	0.07	0
3101	2006	12	22	0.005	0
3101	2006	12	26	0.03	0
3101	2006	12	32	0.01	0
3101	2006	13	14	0.02	0
3101	2006	13	16	0.11	0
3101	2006	13	22	0.03	0
3101	2006	13	25	0.04	0
3101	2006	13	26	0.13	0
3101	2006	13	32	0.01	0
3101	2006	14	14	0.09	0
3101	2006	14	16	0.33	0
3101	2006	14	22	0.03	0
3101	2006	14	25	0.11	0
3101	2006	14	26	0.29	0
3101	2006	14	32	0.09	0
3101	2006	15	14	0.17	0
3101	2006	15	16	0.44	0
3101	2006	15	22	0.05	0
3101	2006	15	25	0.15	0
3101	2006	15	26	0.41	0
3101	2006	15	32	0.08	0
3101	2006	16	14	0.19	0
3101	2006	16	16	0.48	0
3101	2006	16	22	0.05	0
3101	2006	16	25	0.26	0
3101	2006	16	26	0.46	0
3101	2006	16	32	0.09	0
3101	2006	17	14	0.18	0
3101	2006	17	16	0.52	0
3101	2006	17	22	0.06	0
3101	2006	17	25	0.32	0
3101	2006	17	26	0.27	0
3101	2006	17	32	0.05	0
3101	2006	19	14	0.05	0
3101	2006	19	16	0.18	0
3101	2006	19	22	0.03	0
3101	2006	19	25	0.11	0
3101	2006	19	26	0.05	0
3101	2006	19	32	0.005	0
3101	2006	20	14	0.05	0
3101	2006	20	16	0.17	0
3101	2006	20	22	0.01	0
3101	2006	20	25	0.2	0
3101	2006	20	26	0.03	0
3101	2006	20	32	0.01	0
3101	2006	21	14	0.02	0
3101	2006	21	16	0.05	0
3101	2006	21	25	0.08	0
3101	2006	21	26	0.02	0
3101	2006	21	32	0.005	0
3101	2006	22	14	0.02	0
3101	2006	22	16	0.04	0
3101	2006	22	25	0.06	0
3101	2006	22	26	0.04	0
3101	2006	22	32	0.02	0
3101	2006	23	14	0.13	0
3101	2006	23	16	0.05	0
3101	2006	23	25	0.07	0
3101	2006	23	26	0.05	0
3101	2006	23	32	0.03	0
3101	2006	24	14	0.04	0
3101	2006	24	16	0.02	0
3101	2006	24	22	0.005	0
3101	2006	24	25	0.01	0
3101	2006	25	14	0.06	0
3101	2006	25	16	0.04	0
3101	2006	25	22	0.005	0
3101	2006	25	25	0.04	0
3101	2006	25	26	0.01	0
3101	2006	26	16	0.005	0
3101	2006	26	25	0.005	0
3101	2006	26	32	0.005	0
3101	2007	1	14	0.01	0
3101	2007	1	16	0.03	0
3101	2007	1	25	0.005	0
3101	2007	1	26	0.02	0
3101	2007	1	32	0.005	0
3101	2007	2	16	0.02	0
3101	2007	2	25	0.005	0
3101	2007	2	26	0.06	0
3101	2007	2	32	0.01	0
3101	2007	3	14	0.03	0
3101	2007	3	16	0.05	0
3101	2007	3	22	0.01	0
3101	2007	3	25	0.01	0
3101	2007	3	26	0.02	0
3101	2007	3	32	0.01	0
3101	2007	4	14	0.05	0
3101	2007	4	16	0.06	0
3101	2007	4	22	0.01	0
3101	2007	4	25	0.03	0
3101	2007	4	26	0.04	0
3101	2007	4	32	0.005	0
3101	2007	7	14	0.005	0
3101	2007	7	16	0.02	0
3101	2007	7	25	0.005	0
3101	2007	7	26	0.01	0
3101	2007	7	32	0.005	0
3101	2007	8	14	0.01	0
3101	2007	8	16	0.03	0
3101	2007	8	22	0.005	0
3101	2007	8	26	0.03	0
3101	2007	8	32	0.01	0
3101	2007	9	14	0.005	0
3101	2007	9	26	0.02	0
3101	2007	9	32	0.01	0
3101	2007	10	14	0.005	0
3101	2007	10	25	0.005	0
3101	2007	10	32	0.01	0
3101	2007	11	14	0.03	0
3101	2007	11	16	0.01	0
3101	2007	11	22	0.02	0
3101	2007	11	25	0.01	0
3101	2007	11	26	0.02	0
3101	2007	11	32	0.005	0
3101	2007	12	14	0.03	0
3101	2007	12	16	0.03	0
3101	2007	12	22	0.03	0
3101	2007	12	25	0.01	0
3101	2007	12	26	0.04	0
3101	2007	12	32	0.01	0
3101	2007	13	14	0.01	0
3101	2007	13	16	0.11	0
3101	2007	13	22	0.02	0
3101	2007	13	25	0.01	0
3101	2007	13	26	0.04	0
3101	2007	13	32	0.1	0
3101	2007	14	14	0.13	0
3101	2007	14	16	0.23	0
3101	2007	14	22	0.02	0
3101	2007	14	25	0.09	0
3101	2007	14	26	0.23	0
3101	2007	14	32	0.11	0
3101	2007	15	14	0.12	0
3101	2007	15	16	0.18	0
3101	2007	15	22	0.005	0
3101	2007	15	25	0.03	0
3101	2007	15	26	0.14	0
3101	2007	15	32	0.13	0
3101	2007	16	14	0.16	0
3101	2007	16	16	0.32	0
3101	2007	16	22	0.07	0
3101	2007	16	25	0.15	0
3101	2007	16	26	0.18	0
3101	2007	16	32	0.06	0
3101	2007	17	14	0.13	0
3101	2007	17	16	0.22	0
3101	2007	17	22	0.02	0
3101	2007	17	25	0.26	0
3101	2007	17	26	0.12	0
3101	2007	17	32	0.05	0
3101	2007	18	14	0.06	0
3101	2007	18	16	0.21	0
3101	2007	18	22	0.02	0
3101	2007	18	25	0.2	0
3101	2007	18	26	0.23	0
3101	2007	18	32	0.07	0
3101	2007	19	14	0.03	0
3101	2007	19	16	0.08	0
3101	2007	19	22	0.04	0
3101	2007	19	25	0.08	0
3101	2007	19	26	0.02	0
3101	2007	19	32	0.02	0
3101	2007	20	14	0.005	0
3101	2007	20	16	0.06	0
3101	2007	20	22	0.02	0
3101	2007	20	25	0.06	0
3101	2007	20	26	0.03	0
3101	2007	22	14	0.03	0
3101	2007	22	16	0.02	0
3101	2007	22	22	0.005	0
3101	2007	22	25	0.05	0
3101	2007	22	32	0.03	0
3101	2007	23	14	0.02	0
3101	2007	23	16	0.02	0
3101	2007	23	22	0.01	0
3101	2007	23	25	0.01	0
3101	2007	23	26	0.02	0
3101	2007	24	14	0.02	0
3101	2007	24	16	0.02	0
3101	2007	24	22	0.005	0
3101	2007	24	25	0.02	0
3101	2007	24	26	0.02	0
3101	2007	24	32	0.01	0
3101	2007	25	14	0.01	0
3101	2007	25	16	0.05	0
3101	2007	25	25	0.005	0
3106	2000	4	24	5.10204081632653E-03	2
3106	2000	4	26	0.01	2
3106	2000	4	28	9.10569105691057E-03	2
3106	2000	4	30	7.69230769230769E-03	2
3106	2000	5	17	2.66666666666667E-03	2
3106	2000	6	17	0.07	2
3106	2000	6	24	9.18367346938776E-03	2
3106	2000	6	26	0.03	2
3106	2000	6	27	0.02	2
3106	2000	6	28	0.07	2
3106	2000	7	17	0.01	2
3106	2000	8	17	0.07	2
3106	2000	8	24	2.04081632653061E-03	2
3106	2000	8	28	2.4390243902439E-03	2
3106	2000	8	30	2.56410256410256E-03	2
3106	2000	9	17	5.33333333333333E-03	2
3106	2000	10	17	0.01	2
3106	2000	10	24	8.16326530612245E-03	2
3106	2000	10	26	0.02	2
3106	2000	10	28	0.04	2
3106	2000	11	17	0.04	2
3106	2000	11	24	6.12244897959184E-03	2
3106	2000	11	26	0.01	2
3106	2000	11	27	9.09090909090909E-03	2
3106	2000	11	28	0.06	2
3106	2000	11	30	5.12820512820513E-03	2
3106	2000	12	17	0.05	2
3106	2000	12	24	0.01	2
3106	2000	12	26	0.01	2
3106	2000	12	27	0.02	2
3106	2000	12	28	0.02	2
3106	2000	12	30	0.01	2
3106	2000	13	17	0.09	2
3106	2000	13	24	0.01	2
3106	2000	13	26	0.02	2
3106	2000	13	27	9.09090909090909E-03	2
3106	2000	13	28	0.01	2
3106	2000	13	30	0.05	2
3106	2000	16	17	0.15	2
3106	2000	16	24	0.03	2
3106	2000	16	26	0.05	2
3106	2000	16	27	0.05	2
3106	2000	16	28	0.02	2
3106	2000	16	30	0.13	2
3106	2000	17	17	0.34	2
3106	2000	17	24	0.06	2
3106	2000	17	26	0.05	2
3106	2000	17	27	0.12	2
3106	2000	17	28	0.08	2
3106	2000	17	30	0.16	2
3106	2000	18	17	0.23	2
3106	2000	18	24	0.06	2
3106	2000	18	26	0.11	2
3106	2000	18	27	0.13	2
3106	2000	18	28	0.13	2
3106	2000	18	30	0.11	2
3106	2000	19	17	0.29	2
3106	2000	19	24	0.06	2
3106	2000	19	26	0.16	2
3106	2000	19	27	0.1	2
3106	2000	19	28	0.07	2
3106	2000	19	30	0.08	2
3106	2000	20	17	0.16	2
3106	2000	20	24	0.04	2
3106	2000	20	26	0.12	2
3106	2000	20	27	0.07	2
3106	2000	20	28	0.12	2
3106	2000	20	30	0.06	2
3106	2000	21	17	0.09	2
3106	2000	21	24	0.01	2
3106	2000	21	26	0.06	2
3106	2000	21	27	0.01	2
3106	2000	21	28	0.06	2
3106	2000	21	30	0.01	2
3106	2000	22	17	0.06	2
3106	2000	22	24	7.14285714285714E-03	2
3106	2000	22	26	0.03	2
3106	2000	22	27	9.09090909090909E-03	2
3106	2000	22	28	0.04	2
3106	2000	22	30	0.01	2
3106	2000	24	17	0.03	2
3106	2000	24	24	6.12244897959184E-03	2
3106	2000	24	26	1.70940170940171E-03	2
3106	2000	24	27	0.03	2
3106	2000	24	28	7.88617886178862E-03	2
3106	2006	4	17	0.02	2
3106	2006	4	24	0.01	2
3106	2006	4	26	1.70940170940171E-03	2
3106	2006	4	28	0.01	2
3106	2006	4	30	2.56410256410256E-03	2
3106	2006	5	17	0.02	2
3106	2006	5	24	9.18367346938776E-03	2
3106	2006	5	26	0.01	2
3106	2006	5	28	3.65853658536585E-03	2
3106	2006	5	30	0.01	2
3106	2006	6	17	0.05	2
3106	2006	6	24	0.01	2
3106	2006	6	26	0.01	2
3106	2006	6	28	0.04	2
3106	2006	6	30	0.01	2
3106	2006	7	17	0.02	2
3106	2006	7	24	0.01	2
3106	2006	7	26	0.01	2
3106	2006	7	28	0.04	2
3106	2006	8	17	0.01	2
3106	2006	8	24	4.08163265306122E-03	2
3106	2006	8	26	3.41880341880342E-03	2
3106	2006	8	28	2.4390243902439E-03	2
3106	2006	10	17	0.01	2
3106	2006	10	24	6.12244897959184E-03	2
3106	2006	10	26	0.01	2
3106	2006	10	28	7.31707317073171E-03	2
3106	2006	10	30	2.56410256410256E-03	2
3106	2006	11	17	0.01	2
3106	2006	11	24	8.16326530612245E-03	2
3106	2006	11	26	0.01	2
3106	2006	11	27	0.01	2
3106	2006	11	28	0.01	2
3106	2006	11	30	5.12820512820513E-03	2
3106	2006	12	17	0.03	2
3106	2006	12	24	6.12244897959184E-03	2
3106	2006	12	26	6.70940170940171E-03	2
3106	2006	12	27	0.01	2
3106	2006	12	28	0.02	2
3106	2006	13	17	0.13	2
3106	2006	13	24	0.02	2
3106	2006	13	26	0.01	2
3106	2006	13	27	9.09090909090909E-03	2
3106	2006	13	28	0.01	2
3106	2006	13	30	0.02	2
3106	2006	15	17	0.3	2
3106	2006	15	24	0.06	2
3106	2006	15	26	0.27	2
3106	2006	15	27	0.11	2
3106	2006	15	28	0.17	2
3106	2006	15	30	0.06	2
3106	2006	17	17	0.49	2
3106	2006	17	24	0.09	2
3106	2006	17	26	0.14	2
3106	2006	17	27	9.09090909090909E-03	2
3106	2006	17	28	0.13	2
3106	2006	17	30	0.05	2
3106	2006	19	17	0.17	2
3106	2006	19	24	0.02	2
3106	2006	19	26	0.05	2
3106	2006	19	27	0.03	2
3106	2006	19	28	0.01	2
3106	2006	19	30	0.01	2
3106	2006	20	17	0.06	2
3106	2006	20	24	4.08163265306122E-03	2
3106	2006	20	26	0.01	2
3106	2006	20	28	0.03	2
3106	2006	20	30	0.01	2
3106	2006	23	17	0.1	2
3106	2006	23	24	4.08163265306122E-03	2
3106	2006	23	26	0.05	2
3106	2006	23	27	9.09090909090909E-03	2
3106	2006	23	28	0.02	2
3106	2006	23	30	0.01	2
3106	2006	24	17	0.03	2
3106	2006	24	24	6.12244897959184E-03	2
3106	2006	24	26	6.70940170940171E-03	2
3106	2006	24	28	4.8780487804878E-03	2
3106	2006	24	30	0.01	2
3106	2006	25	17	0.04	2
3106	2006	25	24	4.08163265306122E-03	2
3106	2006	25	26	0.01	2
3106	2006	25	28	0.02	2
3106	2006	25	30	0.01	2
3106	2006	26	17	8.33333333333333E-03	2
3106	2007	3	17	0.01	2
3106	2007	3	24	0.02	2
3106	2007	3	26	3.41880341880342E-03	2
3106	2007	3	28	0.01	2
3106	2007	3	30	0.01	2
3106	2007	4	17	0.05	2
3106	2007	4	24	0.01	2
3106	2007	4	26	0.02	2
3106	2007	4	27	0.02	2
3106	2007	4	28	0.01	2
3106	2007	4	30	0.01	2
3106	2007	5	17	0.1	2
3106	2007	5	24	0.01	2
3106	2007	5	26	3.41880341880342E-03	2
3106	2007	5	27	0.05	2
3106	2007	5	28	0.02	2
3106	2007	5	30	0.01	2
3106	2007	7	17	0.01	2
3106	2007	7	24	3.06122448979592E-03	2
3106	2007	7	26	3.41880341880342E-03	2
3106	2007	7	28	0.01	2
3106	2007	8	17	0.05	2
3106	2007	8	24	5.10204081632653E-03	2
3106	2007	8	26	1.70940170940171E-03	2
3106	2007	8	28	2.4390243902439E-03	2
3106	2007	9	17	0.04	2
3106	2007	9	24	3.06122448979592E-03	2
3106	2007	9	27	0.01	2
3106	2007	9	28	2.4390243902439E-03	2
3106	2007	9	30	0.01	2
3106	2007	10	17	0.05	2
3106	2007	10	24	5.10204081632653E-03	2
3106	2007	10	26	8.54700854700855E-03	2
3106	2007	10	27	9.09090909090909E-03	2
3106	2007	10	28	7.31707317073171E-03	2
3106	2007	10	30	2.56410256410256E-03	2
3106	2007	11	17	0.05	2
3106	2007	11	24	5.10204081632653E-03	2
3106	2007	11	26	0.02	2
3106	2007	11	28	4.8780487804878E-03	2
3106	2007	11	30	7.69230769230769E-03	2
3106	2007	12	17	0.08	2
3106	2007	12	24	4.08163265306122E-03	2
3106	2007	12	26	0.01	2
3106	2007	12	27	0.02	2
3106	2007	12	28	0.01	2
3106	2007	12	30	0.01	2
3106	2007	13	17	0.19	2
3106	2007	14	17	0.32	2
3106	2007	14	24	8.16326530612245E-03	2
3106	2007	14	26	0.1	2
3106	2007	14	27	0.04	2
3106	2007	14	28	8.53658536585366E-03	2
3106	2007	14	30	0.03	2
3106	2007	15	17	0.55	2
3106	2007	15	24	0.04	2
3106	2007	15	26	0.15	2
3106	2007	15	27	0.08	2
3106	2007	15	28	0.04	2
3106	2007	15	30	0.05	2
3106	2007	16	17	0.46	2
3106	2007	16	24	0.06	2
3106	2007	16	26	0.14	2
3106	2007	16	27	0.01	2
3106	2007	16	28	0.08	2
3106	2007	16	30	0.05	2
3106	2007	17	17	0.39	2
3106	2007	17	24	0.02	2
3106	2007	17	26	0.14	2
3106	2007	17	27	0.02	2
3106	2007	17	28	0.14	2
3106	2007	17	30	0.07	2
3106	2007	18	17	0.21	2
3106	2007	18	24	0.03	2
3106	2007	18	26	0.15	2
3106	2007	18	27	0.07	2
3106	2007	18	28	0.05	2
3106	2007	18	30	0.07	2
3106	2007	19	17	0.21	2
3106	2007	19	24	7.14285714285714E-03	2
3106	2007	19	26	0.05	2
3106	2007	19	27	0.09	2
3106	2007	19	28	0.03	2
3106	2007	19	30	0.01	2
3106	2007	22	17	0.03	2
3106	2007	22	24	5.10204081632653E-03	2
3106	2007	22	26	0.06	2
3106	2007	22	28	0.01	2
3106	2007	22	30	5.12820512820513E-03	2
3106	2007	23	17	0.09	2
3106	2007	23	24	1.02040816326531E-03	2
3106	2007	23	26	0.01	2
3106	2007	23	28	0.01	2
3106	2007	23	30	7.69230769230769E-03	2
3106	2007	24	17	0.07	2
3106	2007	24	24	4.08163265306122E-03	2
3106	2007	24	26	1.70940170940171E-03	2
3106	2007	24	28	2.4390243902439E-03	2
3800	2000	1	26	0.01	2
3800	2000	1	28	0.02	2
3800	2000	2	26	0.01	2
3800	2000	2	28	0.02	2
3800	2000	5	26	0.05	2
3800	2000	5	28	0.04	2
3800	2000	7	26	0.01	2
3800	2000	7	28	0.03	2
3800	2000	9	26	0.03	2
3800	2000	9	28	0.02	2
3800	2000	10	26	0.02	2
3800	2000	10	28	0.03	2
3800	2000	13	26	0.13	2
3800	2000	13	28	0.04	2
3800	2000	16	26	0.36	2
3800	2000	16	28	0.21	2
3800	2000	18	26	0.21	2
3800	2000	18	28	0.16	2
3800	2000	21	26	0.11	2
3800	2000	21	28	0.05	2
3800	2001	2	26	0.03	2
3800	2001	2	28	0.05	2
3800	2001	5	26	0.01	2
3800	2001	5	28	0.01	2
3800	2001	7	26	0.04	2
3800	2001	7	28	0.02	2
3800	2001	8	26	0.02	2
3800	2001	8	28	0.01	2
3800	2001	9	26	0.01	2
3800	2001	9	28	0.01	2
3800	2001	10	26	0.01	2
3800	2001	10	28	0.01	2
3800	2001	11	26	0.01	2
3800	2001	11	28	0.01	2
3800	2001	12	26	0.01	2
3800	2001	12	28	0.01	2
3800	2001	14	26	0.14	2
3800	2001	14	28	0.09	2
3800	2002	3	26	0.01	2
3800	2002	3	28	0.01	2
3800	2002	6	26	0.08	2
3800	2002	6	28	0.05	2
3800	2002	8	26	0.02	2
3800	2002	8	28	0.02	2
3800	2002	12	26	0.02	2
3800	2002	12	28	0.01	2
3800	2002	13	26	0.09	2
3800	2002	13	28	0.06	2
3800	2002	15	26	0.3	2
3800	2002	15	28	0.14	2
3800	2002	16	26	0.46	2
3800	2002	16	28	0.23	2
3800	2002	20	26	0.16	2
3800	2002	20	28	0.08	2
3800	2002	21	26	0.11	2
3800	2002	21	28	0.02	2
3800	2003	2	26	0.04	2
3800	2003	2	28	0.03	2
3800	2003	3	26	0.04	2
3800	2003	3	28	0.03	2
3800	2003	4	26	0.02	2
3800	2003	4	28	0.02	2
3800	2003	5	26	0.03	2
3800	2003	5	28	0.03	2
3800	2003	6	26	0.03	2
3800	2003	6	28	0.03	2
3800	2003	7	26	0.03	2
3800	2003	7	28	8.78564976125952E-03	2
3800	2003	9	26	0.03	2
3800	2003	9	28	0.01	2
3800	2003	11	26	0.03	2
3800	2003	11	28	0.04	2
3800	2003	12	26	0.23	2
3800	2003	12	28	0.08	2
3800	2003	13	26	0.21	2
3800	2003	13	28	0.06	2
3800	2003	17	26	0.85	2
3800	2003	17	28	0.27	2
3800	2003	19	26	0.51	2
3800	2003	19	28	0.2	2
3800	2003	20	26	0.18	2
3800	2003	20	28	0.07	2
3800	2003	21	26	0.16	2
3800	2003	21	28	0.04	2
3800	2003	22	26	0.05	2
3800	2003	22	28	0.02	2
3800	2003	23	26	0.15	2
3800	2003	23	28	0.01	2
3800	2004	2	26	0.02	2
3800	2004	2	28	0.01	2
3800	2004	4	26	0.05	2
3800	2004	4	28	0.04	2
3800	2004	5	26	0.03	2
3800	2004	5	28	0.02	2
3800	2004	6	26	0.02	2
3800	2004	6	28	0.03	2
3800	2004	7	26	0.03	2
3800	2004	7	28	0.02	2
3800	2004	8	26	0.02	2
3800	2004	8	28	0.01	2
3800	2004	9	26	0.01	2
3800	2004	9	28	5.5640243902439E-03	2
3800	2004	10	26	0.02	2
3800	2004	10	28	0.01	2
3800	2004	11	26	0.01	2
3800	2004	11	28	0.03	2
3800	2004	12	26	0.04	2
3800	2004	12	28	0.03	2
3800	2004	14	26	0.32	2
3800	2004	14	28	0.15	2
3800	2004	15	26	0.48	2
3800	2004	15	28	0.14	2
3800	2004	16	26	0.38	2
3800	2004	16	28	0.18	2
3800	2004	17	26	0.51	2
3800	2004	17	28	0.15	2
3800	2004	18	26	0.35	2
3800	2004	18	28	0.15	2
3800	2004	20	26	0.13	2
3800	2004	20	28	0.02	2
3800	2004	21	26	0.05	2
3800	2004	21	28	0.01	2
3800	2004	22	26	0.06	2
3800	2004	22	28	0.01	2
3800	2004	23	26	0.01	2
3800	2004	23	28	0.01	2
3800	2004	24	26	0.01	2
3800	2004	24	28	0.01	2
3800	2004	25	26	7.14285714285714E-03	2
3800	2004	25	28	2.4390243902439E-03	2
3800	2005	2	26	0.02	2
3800	2005	2	28	0.01	2
3800	2005	3	26	0.02	2
3800	2005	3	28	0.01	2
3800	2005	5	26	0.05	2
3800	2005	5	28	0.04	2
3800	2005	6	26	0.02	2
3800	2005	6	28	0.03	2
3800	2005	7	26	0.02	2
3800	2005	7	28	0.02	2
3800	2005	8	26	0.04	2
3800	2005	8	28	0.03	2
3800	2005	9	26	0.02	2
3800	2005	9	28	0.01	2
3800	2005	10	26	0.03	2
3800	2005	10	28	0.01	2
3800	2005	12	26	0.05	2
3800	2005	12	28	0.03	2
3800	2005	13	26	0.24	2
3800	2005	13	28	0.05	2
3800	2005	14	26	0.22	2
3800	2005	14	28	0.1	2
3800	2005	15	26	0.46	2
3800	2005	15	28	0.09	2
3800	2005	16	26	0.56	2
3800	2005	16	28	0.24	2
3800	2005	17	26	0.61	2
3800	2005	17	28	0.13	2
3800	2005	18	26	0.6	2
3800	2005	18	28	0.24	2
3800	2005	19	26	0.53	2
3800	2005	19	28	0.1	2
3800	2005	20	26	0.22	2
3800	2005	20	28	0.06	2
3800	2005	21	26	0.12	2
3800	2005	21	28	0.02	2
3800	2005	23	26	0.03	2
3800	2005	23	28	0.01	2
3800	2005	25	26	3.57142857142857E-03	2
3800	2005	25	28	2.4390243902439E-03	2
3800	2006	3	26	0.03	2
3800	2006	3	28	0.01	2
3800	2006	6	26	0.07	2
3800	2006	6	28	0.03	2
3800	2006	9	26	0.03	2
3800	2006	9	28	9.58704348948251E-03	2
3800	2006	10	26	0.08	2
3800	2006	10	28	0.02	2
3800	2006	11	26	0.04	2
3800	2006	11	28	0.01	2
3800	2006	12	26	0.05	2
3800	2006	12	28	0.03	2
3800	2006	13	26	0.2	2
3800	2006	13	28	0.05	2
3800	2006	14	26	0.32	2
3800	2006	14	28	0.1	2
3800	2006	15	26	0.51	2
3800	2006	15	28	0.14	2
3800	2006	16	26	0.76	2
3800	2006	16	28	0.19	2
3800	2006	17	26	0.97	2
3800	2006	17	28	0.13	2
3800	2006	18	26	0.74	2
3800	2006	18	28	0.14	2
3800	2006	19	26	0.44	2
3800	2006	19	28	0.05	2
3800	2006	21	26	0.03	2
3800	2006	21	28	0.01	2
3800	2006	22	26	0.07	2
3800	2006	22	28	0.01	2
3800	2006	23	26	0.06	2
3800	2006	23	28	0.01	2
3800	2006	24	26	0.03	2
3800	2006	24	28	0.01	2
3800	2006	25	26	0.01	2
3800	2006	25	28	1.21951219512195E-03	2
3800	2006	26	28	1.21951219512195E-03	2
3800	2007	1	26	0.02	2
3800	2007	1	28	0.01	2
3800	2007	2	26	0.02	2
3800	2007	2	28	0.01	2
3800	2007	3	26	0.02	2
3800	2007	3	28	0.02	2
3800	2007	4	26	0.05	2
3800	2007	4	28	0.03	2
3800	2007	5	26	0.04	2
3800	2007	5	28	0.02	2
3800	2007	7	26	0.01	2
3800	2007	7	28	0.01	2
3800	2007	8	26	0.03	2
3800	2007	8	28	7.14801909923861E-03	2
3800	2007	10	26	6.27450980392157E-03	2
3800	2007	10	28	5.29616724738676E-03	2
3800	2007	11	26	0.2	2
3800	2007	11	28	0.1	2
3800	2007	12	26	0.13	2
3800	2007	12	28	0.05	2
3800	2007	13	26	0.27	2
3800	2007	13	28	0.04	2
3800	2007	14	26	0.58	2
3800	2007	14	28	0.1	2
3800	2007	15	26	0.32	2
3800	2007	15	28	0.06	2
3800	2007	16	26	0.79	2
3800	2007	16	28	0.13	2
3800	2007	19	26	0.39	2
3800	2007	19	28	0.12	2
3800	2007	20	26	0.12	2
3800	2007	20	28	0.05	2
3800	2007	21	26	0.03	2
3800	2007	21	28	7.56613756613757E-03	2
3800	2007	22	26	0.03	2
3800	2007	22	28	7.56613756613757E-03	2
3800	2007	23	26	0.06	2
3800	2007	23	28	7.78035875596851E-03	2
3800	2007	24	26	0.01	2
3800	2007	24	28	4.07665505226481E-03	2
3800	2007	25	26	9.93506493506494E-03	2
3800	2007	25	28	1.21951219512195E-03	2
3800	2007	26	26	9.63203463203463E-03	2

From njbisaac at googlemail.com  Thu Jul  2 21:31:41 2009
From: njbisaac at googlemail.com (Nick Isaac)
Date: Thu, 2 Jul 2009 14:31:41 -0500
Subject: [R-sig-ME] Warning and Error using start argument in glmer
Message-ID: <a072ed700907021231q60ad627ax4e535b69efa7bc9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090702/9f1aa71f/attachment.pl>

From erich.studerus at bli.uzh.ch  Fri Jul  3 15:27:17 2009
From: erich.studerus at bli.uzh.ch (Erich Studerus)
Date: Fri, 3 Jul 2009 15:27:17 +0200
Subject: [R-sig-ME] Mixed effects model equivalent of a repeated measures
	ANOVA with multiple within subjects factors
Message-ID: <200907031327.n63DRN9h003897@idmailgate1.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090703/a1445f2e/attachment.pl>

From bates at stat.wisc.edu  Sat Jul  4 18:58:46 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 4 Jul 2009 18:58:46 +0200
Subject: [R-sig-ME] [R] 'singularity' between fixed effect and random
	factor in mixed model
In-Reply-To: <h2gssa$ofc$1@ger.gmane.org>
References: <h2gssa$ofc$1@ger.gmane.org>
Message-ID: <40e66e0b0907040958q1333a635g9d3f9f8a79ca8c9a@mail.gmail.com>

On Thu, Jul 2, 2009 at 1:52 AM, Thomas Mang<thomas.mang at fiwi.at> wrote:
> Hi,

> I just came across the following issue regarding mixed effects models:
> In a longitudinal study individuals (variable ind) are observed for some
> response variable. One explanatory variable, f, entering the model as fixed
> effect, is a (2-level) factor. The expression of that factor is constant for
> each individual across time (say, the sex of the individual). ind enters the
> model as grouping variable for random effects. So in a simple form, the
> formula could look like:
> y ~ f + ... + (1|ind)
> [and in the simplest model, the ellipsis is simply nothing]

> To me, this seems not to be an unusual design at all.

> However, the indicator matrix consisting of f and ind - say if ind had
> entered the model as fixed effect - shows a singularity.

Yes.

> My question is now
> what will this 'singularity' cause in a mixed-effects model ? I admit, I
> have never fully understood how the fitting of mixed-effects models happen
> internally (whether REML or ML) [so I am not even sure if it can be called a
> 'singularity'].

You do not encounter a singularity in solving for the conditional
means of the random effects and the conditional estimates of the fixed
effects because there is a penalty assigned to the size of the random
effects vector.  This removes the ill-conditioning of the least
squares problem.  It is sometimes called "regularization" of the
estimation.

Should you wish to find out what does go on inside the lmer function
for REML or ML estimation of the parameters in a linear mixed model,
you can check out the slides from a short course that I just finished
at the University of Lausanne.  Go to

http://lme4.R-forge.R-project.org/slides

and click on the link "2009-07-01-Lausanne".  The display version of
the slides for the theory section, 6TheoryD.pdf, is the best
explanation I have yet been able to formulate for the theory.  The
important thing to note is that in the penalized linear least squares
problem the predictions for the "pseudo-observations" are affected by
the random effects but not by the fixed-effects.



> Specifically, does it make the fit numerically more unstable? Would the
> degree of this depend on other variables of the model? Is the issue of
> degrees of freedom - complicated enough anyway for mixed models - further
> inflated by that? Have statistical inferences regarding the fixed effect be
> treated more carefully? Is the general situation something that should be
> avoided ?
>
> many thanks in advance for any insights and cheers,
> Thomas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bates at stat.wisc.edu  Sat Jul  4 18:58:46 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 4 Jul 2009 18:58:46 +0200
Subject: [R-sig-ME] [R] 'singularity' between fixed effect and random
	factor in mixed model
In-Reply-To: <h2gssa$ofc$1@ger.gmane.org>
References: <h2gssa$ofc$1@ger.gmane.org>
Message-ID: <40e66e0b0907040958q1333a635g9d3f9f8a79ca8c9a@mail.gmail.com>

On Thu, Jul 2, 2009 at 1:52 AM, Thomas Mang<thomas.mang at fiwi.at> wrote:
> Hi,

> I just came across the following issue regarding mixed effects models:
> In a longitudinal study individuals (variable ind) are observed for some
> response variable. One explanatory variable, f, entering the model as fixed
> effect, is a (2-level) factor. The expression of that factor is constant for
> each individual across time (say, the sex of the individual). ind enters the
> model as grouping variable for random effects. So in a simple form, the
> formula could look like:
> y ~ f + ... + (1|ind)
> [and in the simplest model, the ellipsis is simply nothing]

> To me, this seems not to be an unusual design at all.

> However, the indicator matrix consisting of f and ind - say if ind had
> entered the model as fixed effect - shows a singularity.

Yes.

> My question is now
> what will this 'singularity' cause in a mixed-effects model ? I admit, I
> have never fully understood how the fitting of mixed-effects models happen
> internally (whether REML or ML) [so I am not even sure if it can be called a
> 'singularity'].

You do not encounter a singularity in solving for the conditional
means of the random effects and the conditional estimates of the fixed
effects because there is a penalty assigned to the size of the random
effects vector.  This removes the ill-conditioning of the least
squares problem.  It is sometimes called "regularization" of the
estimation.

Should you wish to find out what does go on inside the lmer function
for REML or ML estimation of the parameters in a linear mixed model,
you can check out the slides from a short course that I just finished
at the University of Lausanne.  Go to

http://lme4.R-forge.R-project.org/slides

and click on the link "2009-07-01-Lausanne".  The display version of
the slides for the theory section, 6TheoryD.pdf, is the best
explanation I have yet been able to formulate for the theory.  The
important thing to note is that in the penalized linear least squares
problem the predictions for the "pseudo-observations" are affected by
the random effects but not by the fixed-effects.



> Specifically, does it make the fit numerically more unstable? Would the
> degree of this depend on other variables of the model? Is the issue of
> degrees of freedom - complicated enough anyway for mixed models - further
> inflated by that? Have statistical inferences regarding the fixed effect be
> treated more carefully? Is the general situation something that should be
> avoided ?
>
> many thanks in advance for any insights and cheers,
> Thomas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From andy.fugard at sbg.ac.at  Sat Jul  4 19:30:51 2009
From: andy.fugard at sbg.ac.at (Andy Fugard)
Date: Sat, 04 Jul 2009 19:30:51 +0200
Subject: [R-sig-ME] Plotting lmer estimates with individual points from
	residuals
Message-ID: <4A4F91CB.2010901@sbg.ac.at>

Dear all,

Are there any good reasons not to graph data points from

   fixed effects estimates + observation-level residuals

in models with random effects at levels above residuals?

Some code below to demonstrate what I mean.

I can see arguments against doing this when there are varying slopes in 
the model, but perhaps a separate graph can be used nearby to show how 
the slopes vary between (e.g.) subjects.

Interesting for the sleepstudy dataset that plotting the varying 
intercept (only) model shows a bow-tie effect, pointing to a need for 
random slopes.

Words of wisdom and pointers to literature very welcome.

Best wishes,

Andy


######################################################################

require(lme4)

# Varying intercept model
M1 = lmer(Reaction ~ Days + (1|Subject), sleepstudy)

# Varying slope model
M2 = lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

# Grab the fixed effect estimates
cs1 = fixef(M1)
cs2 = fixef(M1)

days = sleepstudy$Days

# Save residuals and predictions from fixed effects
sleepstudy$resid1     = resid(M1)
sleepstudy$fixedPred1 = with(sleepstudy, cs1[1] + cs1[2]*Days)
sleepstudy$resid2     = resid(M2)
sleepstudy$fixedPred2 = with(sleepstudy, cs2[1] + cs2[2]*Days)

# Plot
par(mfrow = c(1,3))
   plot(Reaction ~ Days, sleepstudy, main = "Original data")
   plot(I(fixedPred1+resid1) ~ Days, sleepstudy,
       main = "Varying intercept", ylab = "Reaction")
   curve(cs1[1] + cs1[2]*x, min(days), max(days), add=T)
   plot(I(fixedPred2+resid2) ~ Days, sleepstudy,
       main = "Varying slope + intercept", ylab = "Reaction")
   curve(cs2[1] + cs2[2]*x, min(days), max(days), add=T)
par(mfrow = c(1,1))

######################################################################


-- 
Andy Fugard, Post-doc, ESF LogICCC (LcpR) project
Fachbereich Psychologie, Universitaet Salzburg
   Hellbrunnerstr. 34, 5020 Salzburg, Austria
+43 (0)680 2199 346  http://figuraleffect.googlepages.com



From rlevy at ling.ucsd.edu  Sun Jul  5 21:51:05 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Sun, 5 Jul 2009 12:51:05 -0700
Subject: [R-sig-ME] how reliable are inferences drawn from binomial models
	for small datasets fitted with lme4?
Message-ID: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>

This post may be of interest in light of the recent discussion of PQL  
versus Laplace-approximated likelihood.  I'm facing an interestingly  
challenging analysis of a relatively small (190-observation) binary- 
response dataset with a single two-level treatment and two crossed  
random factors (call them F1 and F2).  The question of current  
interest is whether I can infer a difference in fixed effect of  
treatment; it is hard to figure out the right conclusions to draw.   
I'm putting the full dataset at the end of the message, but I'll start  
by presenting some summary statistics:

 > xtabs(~ Treatment + Response, dat)
          Response
Treatment   0   1
         1  12 117
         2   0  61

Fisher's exact test says "yes, the treatment has an effect" at  
p=0.01.  But of course that doesn't take into account the crossed  
hierarchical structure of the data.  Some statistics on this:

 > with(dat,tapply(Response, list(F1,Treatment),length))
     1  2
1  11  5
2   7  6
3   9  3
4   4 NA
5   3  3
6  11 NA
7   3  3
8   9  4
9  11  3
10 12  6
11 11  8
12  5  6
13  1 NA
14 11  1
15 12  9
16  9  4
 > with(dat,tapply(Response, list(F1,Treatment),mean))
            1  2
1  1.0000000  1
2  0.5714286  1
3  0.8888889  1
4  1.0000000 NA
5  0.0000000  1
6  1.0000000 NA
7  0.6666667  1
8  1.0000000  1
9  1.0000000  1
10 1.0000000  1
11 0.8181818  1
12 0.6000000  1
13 1.0000000 NA
14 1.0000000  1
15 1.0000000  1
16 1.0000000  1
 > with(dat,tapply(Response, list(F2,Treatment),length))
    1  2
1  4  2
2  8  2
3  3  1
4  5  2
5  6  3
6  7  2
7  5  5
8  8  1
9  6  6
10 5  2
11 6 NA
12 6  6
13 4  1
14 6  2
15 4  6
16 5  2
17 5  2
18 4  1
19 5 NA
20 4 NA
21 5  6
22 6  3
23 6  5
24 6  1
 > with(dat,tapply(Response, list(F2,Treatment),mean))
            1  2
1  1.0000000  1
2  0.8750000  1
3  1.0000000  1
4  1.0000000  1
5  1.0000000  1
6  1.0000000  1
7  0.8000000  1
8  0.8750000  1
9  0.8333333  1
10 1.0000000  1
11 0.8333333 NA
12 0.6666667  1
13 1.0000000  1
14 0.8333333  1
15 1.0000000  1
16 1.0000000  1
17 1.0000000  1
18 1.0000000  1
19 1.0000000 NA
20 1.0000000 NA
21 1.0000000  1
22 0.6666667  1
23 0.8333333  1
24 0.8333333  1

So there is some sign of inter-cluster variability, though of course  
the binary response makes it hard to see.  Crossed random-slope models  
converge both with and without a fixed effect of treatment...

 > print(m1 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +  
(Treatment - 1 | F2), dat, family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (Treatment - 1 | F1) + (Treatment - 1  
|      F2)
    Data: dat
    AIC   BIC logLik deviance
  82.65 108.6 -33.33    66.65
Random effects:
  Groups Name       Variance   Std.Dev.   Corr
  F2     Treatment1 4.1354e-12 2.0336e-06
         Treatment2 1.0492e+00 1.0243e+00 0.000
  F1     Treatment1 9.4589e+00 3.0755e+00
         Treatment2 6.9945e-01 8.3633e-01 0.000
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    3.943      1.004   3.929 8.54e-05 ***
Treatment2    17.289   5221.110   0.003    0.997
 > print(m0 <- lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment -  
1 | F2), dat, family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)
    Data: dat
   AIC   BIC logLik deviance
  81.5 104.2 -33.75     67.5
Random effects:
  Groups Name       Variance   Std.Dev.   Corr
  F2     Treatment1 0.0000e+00 0.00000000
         Treatment2 1.7654e-08 0.00013287   NaN
  F1     Treatment1 2.3858e+01 4.88443481
         Treatment2 3.0185e-02 0.17373716 -1.000
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)    5.855      1.384   4.232 2.32e-05 ***


...but I am concerned (a) about the NaN correlation for F2 (this must  
be a sign of something broken somewhere!?), and (b) about the minimal  
difference in log-likelihood for m1 versus m0.  (Note that it's  
possible to fix (a) by dropping random effects of F2 from m0, and the  
log-likelihood doesn't change.)  It seems hard to believe that the  
marginal log-likelihoods of the models given estimates of the fixed  
effects and of the random-effect covariance matrices differs by only  
0.42.  I draw further evidence for this conclusion by imagining that  
one response in Treatment 2 were a failure rather than a success:

 > dat[142,"Response"] <- 0
 > logLik(lmer(Response ~ Treatment + (Treatment - 1 | F1) +  
(Treatment - 1 | F2), dat, family=binomial))
'log Lik.' -35.29494 (df=8)
 > logLik(lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 |  
F2), dat, family=binomial))
'log Lik.' -37.60635 (df=7)

Now there's a considerable difference in log-likelihood; this would  
turn out significant in a chi-squared test (though of course we'd want  
to calibrate with simulation if this were the actual dataset).

Note that I can't use the Wald statistic here to address my hypothesis  
for the real dataset, because the lack of failure responses in  
Treatment 2 blows up the MLE and also the standard error of its  
parameter.  I was hoping to use a likelihood-ratio comparison (perhaps  
calibrated with simulation), but it seems to me that the minimal  
observed difference in likelihood ratio for the actual dataset throws  
that idea out the window.

So here are some questions:

1) Is there something specific to the Laplace approximation being used  
that renders logit models with extreme response proportions generally  
unreliable?  (I can't check this directly against other packages  
because of the crossed random effects.)

2) Is this dataset simply small enough that the uncertainty in  
estimating of the random-effect variance pararameters makes point- 
estimate inference on fixed effects unreliable, and I should go the  
Bayesian route and integrate over the uncertainty?  Following this  
possibility, I implemented the fixed-effect-of-treatment model (m1) in  
JAGS with diffuse normal priors over the intercept and Treatment 2  
parameter, and diffuse Wishart priors over the random-effect  
covariance matrices.  Here are 95% Bayesian confidence intervals that  
result:


                       lower        upper
Omega.F2[1,1]  5.316465e+02 5.922489e+05
Omega.F2[2,1] -3.016791e+05 2.899492e+05
Omega.F2[1,2] -3.016791e+05 2.899492e+05
Omega.F2[2,2]  2.116783e+02 5.911579e+05
Omega.F1[1,1]  5.186791e+01 5.979535e+05
Omega.F1[2,1] -3.073216e+05 2.898743e+05
Omega.F1[1,2] -3.073216e+05 2.898743e+05
Omega.F1[2,2]  2.764357e+02 5.972545e+05
intercept      1.749505e+00 2.938812e+00
Treatment2     1.240127e+00 6.279801e+02

and here is the posterior mode:

Omega.F2[1,1]  70299.472805
Omega.F2[2,1]  -1324.272662
Omega.F2[1,2]  -1324.272662
Omega.F2[2,2]  70810.193188
Omega.F1[1,1]  70426.234086
Omega.F1[2,1] -46977.070058
Omega.F1[1,2] -46977.070058
Omega.F1[2,2]  87987.091315
intercept      1.977808
Treatment2     5.846867

Some notable differences between these Bayesian results and the lme4- 
fit m1:

* lme4 inferred considerably larger random effects of F1 than of F2,  
which doesn't seem supported by the marginal means I listed near the  
beginning of the email; whereas the Bayesian inference puts F1 and F2  
on roughly equal footing;

* the severe lack of evidence regarding the correlations of random  
effects across treatment is clearly evident in the Bayesian confidence  
intervals;

* the fixed-effects posterior modes are much closer to zero than the  
Laplace-approximated MLEs;

* The Bayesian inference seems strongly supportive of a fixed effect  
of treatment, whereas lme4 superficially seemed to lead to the  
opposite conclusions.

I'd love to hear people's thoughts on my approach to these data.  Many  
thanks in advance.

Roger

**

     Treatment F1 F2 Response
1           1  6  1        1
2           1  7  1        1
3           1  8  1        1
4           1 15  1        1
5           1  1  2        1
6           1  2  2        1
7           1  3  2        1
8           1  4  2        1
9           1  9  2        1
10          1 10  2        1
11          1 11  2        1
12          1 12  2        0
13          1  6  3        1
14          1 14  3        1
15          1 15  3        1
16          1  3  4        1
17          1  4  4        1
18          1  9  4        1
19          1 10  4        1
20          1 11  4        1
21          1  6  5        1
22          1  8  5        1
23          1 13  5        1
24          1 14  5        1
25          1 15  5        1
26          1 16  5        1
27          1  1  6        1
28          1  2  6        1
29          1  3  6        1
30          1  9  6        1
31          1 10  6        1
32          1 11  6        1
33          1 12  6        1
34          1  5  7        0
35          1  6  7        1
36          1 14  7        1
37          1 15  7        1
38          1 16  7        1
39          1  1  8        1
40          1  2  8        1
41          1  3  8        1
42          1  4  8        1
43          1  9  8        1
44          1 10  8        1
45          1 11  8        0
46          1 12  8        1
47          1  5  9        0
48          1  7  9        1
49          1  8  9        1
50          1 14  9        1
51          1 15  9        1
52          1 16  9        1
53          1  1 10        1
54          1  3 10        1
55          1  9 10        1
56          1 10 10        1
57          1 11 10        1
58          1  5 11        0
59          1  6 11        1
60          1  8 11        1
61          1 14 11        1
62          1 15 11        1
63          1 16 11        1
64          1  1 12        1
65          1  2 12        1
66          1  9 12        1
67          1 10 12        1
68          1 11 12        0
69          1 12 12        0
70          1  6 13        1
71          1 14 13        1
72          1 15 13        1
73          1 16 13        1
74          1  1 14        1
75          1  2 14        0
76          1  3 14        1
77          1 10 14        1
78          1 11 14        1
79          1 12 14        1
80          1  6 15        1
81          1  8 15        1
82          1 14 15        1
83          1 15 15        1
84          1  1 16        1
85          1  3 16        1
86          1  4 16        1
87          1  9 16        1
88          1 10 16        1
89          1  6 17        1
90          1  8 17        1
91          1 14 17        1
92          1 15 17        1
93          1 16 17        1
94          1  1 18        1
95          1  9 18        1
96          1 10 18        1
97          1 11 18        1
98          1  6 19        1
99          1  8 19        1
100         1 14 19        1
101         1 15 19        1
102         1 16 19        1
103         1  1 20        1
104         1  9 20        1
105         1 10 20        1
106         1 11 20        1
107         1  6 21        1
108         1  8 21        1
109         1 14 21        1
110         1 15 21        1
111         1 16 21        1
112         1  1 22        1
113         1  2 22        0
114         1  3 22        0
115         1  9 22        1
116         1 10 22        1
117         1 11 22        1
118         1  6 23        1
119         1  7 23        0
120         1  8 23        1
121         1 14 23        1
122         1 15 23        1
123         1 16 23        1
124         1  1 24        1
125         1  2 24        0
126         1  3 24        1
127         1  9 24        1
128         1 10 24        1
129         1 11 24        1
130         2  3  1        1
131         2 11  1        1
132         2 15  2        1
133         2 16  2        1
134         2  2  3        1
135         2  7  4        1
136         2 15  4        1
137         2 10  5        1
138         2 11  5        1
139         2 12  5        1
140         2  8  6        1
141         2 15  6        1
142         2  1  7        0
143         2  2  7        1
144         2 10  7        1
145         2 11  7        1
146         2 12  7        1
147         2  8  8        1
148         2  1  9        1
149         2  2  9        1
150         2  9  9        1
151         2 10  9        1
152         2 11  9        1
153         2 12  9        1
154         2  5 10        1
155         2  8 10        1
156         2  5 12        1
157         2  7 12        1
158         2  8 12        1
159         2 14 12        1
160         2 15 12        1
161         2 16 12        1
162         2  1 13        1
163         2  5 14        1
164         2 15 14        1
165         2  2 15        1
166         2  3 15        1
167         2  9 15        1
168         2 10 15        1
169         2 11 15        1
170         2 12 15        1
171         2 15 16        1
172         2 16 16        1
173         2 11 17        1
174         2 12 17        1
175         2 15 18        1
176         2  1 21        1
177         2  2 21        1
178         2  3 21        1
179         2  9 21        1
180         2 10 21        1
181         2 11 21        1
182         2  7 22        1
183         2 15 22        1
184         2 16 22        1
185         2  1 23        1
186         2  2 23        1
187         2 10 23        1
188         2 11 23        1
189         2 12 23        1
190         2 15 24        1

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy



From j.hadfield at ed.ac.uk  Sun Jul  5 23:44:16 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 05 Jul 2009 22:44:16 +0100
Subject: [R-sig-ME] how reliable are inferences drawn from
	binomial	models for small datasets fitted with lme4?
In-Reply-To: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
References: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
Message-ID: <20090705224416.vfuldpedc0gc8o0c@www.staffmail.ed.ac.uk>

Dear Roger,

I think part of your problem is that in treatment 2 there are 60  
success but only a single failure. This means that there will be  
little (no?) information in the data to estimate F1 and F2 variances  
that are specific to treatment 2.
I suspect this explains the NaN, and also the discrepancy between JAGS  
and lmer: in the Bayesian analysis this information is coming  
completely from your prior, as are the between treatment covariances.   
I would recommend the simpler model:

m1 <- lmer(Response ~ Treatment+(1 | F1)+(1 | F2), dat, family=binomial)

The F2 variance is fixed at zero, and the treatment effect is  
significant at p=0.0268

For this model the lmer and MCMCglmm results agree for the fixed  
effects. The variance components are sensitive to the prior however,  
but with weak priors the posterior distributions of the variances are  
very wide.

Cheers,

Jarrod



Quoting Roger Levy <rlevy at ling.ucsd.edu>:

> This post may be of interest in light of the recent discussion of PQL
> versus Laplace-approximated likelihood.  I'm facing an interestingly
> challenging analysis of a relatively small (190-observation)
> binary-response dataset with a single two-level treatment and two
> crossed random factors (call them F1 and F2).  The question of current
> interest is whether I can infer a difference in fixed effect of
> treatment; it is hard to figure out the right conclusions to draw.  I'm
> putting the full dataset at the end of the message, but I'll start by
> presenting some summary statistics:
>
>> xtabs(~ Treatment + Response, dat)
>          Response
> Treatment   0   1
>         1  12 117
>         2   0  61
>
> Fisher's exact test says "yes, the treatment has an effect" at p=0.01.
> But of course that doesn't take into account the crossed hierarchical
> structure of the data.  Some statistics on this:
>
>> with(dat,tapply(Response, list(F1,Treatment),length))
>     1  2
> 1  11  5
> 2   7  6
> 3   9  3
> 4   4 NA
> 5   3  3
> 6  11 NA
> 7   3  3
> 8   9  4
> 9  11  3
> 10 12  6
> 11 11  8
> 12  5  6
> 13  1 NA
> 14 11  1
> 15 12  9
> 16  9  4
>> with(dat,tapply(Response, list(F1,Treatment),mean))
>            1  2
> 1  1.0000000  1
> 2  0.5714286  1
> 3  0.8888889  1
> 4  1.0000000 NA
> 5  0.0000000  1
> 6  1.0000000 NA
> 7  0.6666667  1
> 8  1.0000000  1
> 9  1.0000000  1
> 10 1.0000000  1
> 11 0.8181818  1
> 12 0.6000000  1
> 13 1.0000000 NA
> 14 1.0000000  1
> 15 1.0000000  1
> 16 1.0000000  1
>> with(dat,tapply(Response, list(F2,Treatment),length))
>    1  2
> 1  4  2
> 2  8  2
> 3  3  1
> 4  5  2
> 5  6  3
> 6  7  2
> 7  5  5
> 8  8  1
> 9  6  6
> 10 5  2
> 11 6 NA
> 12 6  6
> 13 4  1
> 14 6  2
> 15 4  6
> 16 5  2
> 17 5  2
> 18 4  1
> 19 5 NA
> 20 4 NA
> 21 5  6
> 22 6  3
> 23 6  5
> 24 6  1
>> with(dat,tapply(Response, list(F2,Treatment),mean))
>            1  2
> 1  1.0000000  1
> 2  0.8750000  1
> 3  1.0000000  1
> 4  1.0000000  1
> 5  1.0000000  1
> 6  1.0000000  1
> 7  0.8000000  1
> 8  0.8750000  1
> 9  0.8333333  1
> 10 1.0000000  1
> 11 0.8333333 NA
> 12 0.6666667  1
> 13 1.0000000  1
> 14 0.8333333  1
> 15 1.0000000  1
> 16 1.0000000  1
> 17 1.0000000  1
> 18 1.0000000  1
> 19 1.0000000 NA
> 20 1.0000000 NA
> 21 1.0000000  1
> 22 0.6666667  1
> 23 0.8333333  1
> 24 0.8333333  1
>
> So there is some sign of inter-cluster variability, though of course
> the binary response makes it hard to see.  Crossed random-slope models
> converge both with and without a fixed effect of treatment...
>
>> print(m1 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +
> (Treatment - 1 | F2), dat, family=binomial))
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Response ~ Treatment + (Treatment - 1 | F1) + (Treatment - 1 |
>      F2)
>    Data: dat
>    AIC   BIC logLik deviance
>  82.65 108.6 -33.33    66.65
> Random effects:
>  Groups Name       Variance   Std.Dev.   Corr
>  F2     Treatment1 4.1354e-12 2.0336e-06
>         Treatment2 1.0492e+00 1.0243e+00 0.000
>  F1     Treatment1 9.4589e+00 3.0755e+00
>         Treatment2 6.9945e-01 8.3633e-01 0.000
> Number of obs: 190, groups: F2, 24; F1, 16
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)    3.943      1.004   3.929 8.54e-05 ***
> Treatment2    17.289   5221.110   0.003    0.997
>> print(m0 <- lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1
> | F2), dat, family=binomial))
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)
>    Data: dat
>   AIC   BIC logLik deviance
>  81.5 104.2 -33.75     67.5
> Random effects:
>  Groups Name       Variance   Std.Dev.   Corr
>  F2     Treatment1 0.0000e+00 0.00000000
>         Treatment2 1.7654e-08 0.00013287   NaN
>  F1     Treatment1 2.3858e+01 4.88443481
>         Treatment2 3.0185e-02 0.17373716 -1.000
> Number of obs: 190, groups: F2, 24; F1, 16
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)    5.855      1.384   4.232 2.32e-05 ***
>
>
> ...but I am concerned (a) about the NaN correlation for F2 (this must
> be a sign of something broken somewhere!?), and (b) about the minimal
> difference in log-likelihood for m1 versus m0.  (Note that it's
> possible to fix (a) by dropping random effects of F2 from m0, and the
> log-likelihood doesn't change.)  It seems hard to believe that the
> marginal log-likelihoods of the models given estimates of the fixed
> effects and of the random-effect covariance matrices differs by only
> 0.42.  I draw further evidence for this conclusion by imagining that
> one response in Treatment 2 were a failure rather than a success:
>
>> dat[142,"Response"] <- 0
>> logLik(lmer(Response ~ Treatment + (Treatment - 1 | F1) + (Treatment
> - 1 | F2), dat, family=binomial))
> 'log Lik.' -35.29494 (df=8)
>> logLik(lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 |
> F2), dat, family=binomial))
> 'log Lik.' -37.60635 (df=7)
>
> Now there's a considerable difference in log-likelihood; this would
> turn out significant in a chi-squared test (though of course we'd want
> to calibrate with simulation if this were the actual dataset).
>
> Note that I can't use the Wald statistic here to address my hypothesis
> for the real dataset, because the lack of failure responses in
> Treatment 2 blows up the MLE and also the standard error of its
> parameter.  I was hoping to use a likelihood-ratio comparison (perhaps
> calibrated with simulation), but it seems to me that the minimal
> observed difference in likelihood ratio for the actual dataset throws
> that idea out the window.
>
> So here are some questions:
>
> 1) Is there something specific to the Laplace approximation being used
> that renders logit models with extreme response proportions generally
> unreliable?  (I can't check this directly against other packages
> because of the crossed random effects.)
>
> 2) Is this dataset simply small enough that the uncertainty in
> estimating of the random-effect variance pararameters makes
> point-estimate inference on fixed effects unreliable, and I should go
> the Bayesian route and integrate over the uncertainty?  Following this
> possibility, I implemented the fixed-effect-of-treatment model (m1) in
> JAGS with diffuse normal priors over the intercept and Treatment 2
> parameter, and diffuse Wishart priors over the random-effect covariance
> matrices.  Here are 95% Bayesian confidence intervals that result:
>
>
>                       lower        upper
> Omega.F2[1,1]  5.316465e+02 5.922489e+05
> Omega.F2[2,1] -3.016791e+05 2.899492e+05
> Omega.F2[1,2] -3.016791e+05 2.899492e+05
> Omega.F2[2,2]  2.116783e+02 5.911579e+05
> Omega.F1[1,1]  5.186791e+01 5.979535e+05
> Omega.F1[2,1] -3.073216e+05 2.898743e+05
> Omega.F1[1,2] -3.073216e+05 2.898743e+05
> Omega.F1[2,2]  2.764357e+02 5.972545e+05
> intercept      1.749505e+00 2.938812e+00
> Treatment2     1.240127e+00 6.279801e+02
>
> and here is the posterior mode:
>
> Omega.F2[1,1]  70299.472805
> Omega.F2[2,1]  -1324.272662
> Omega.F2[1,2]  -1324.272662
> Omega.F2[2,2]  70810.193188
> Omega.F1[1,1]  70426.234086
> Omega.F1[2,1] -46977.070058
> Omega.F1[1,2] -46977.070058
> Omega.F1[2,2]  87987.091315
> intercept      1.977808
> Treatment2     5.846867
>
> Some notable differences between these Bayesian results and the lme4-fit m1:
>
> * lme4 inferred considerably larger random effects of F1 than of F2,
> which doesn't seem supported by the marginal means I listed near the
> beginning of the email; whereas the Bayesian inference puts F1 and F2
> on roughly equal footing;
>
> * the severe lack of evidence regarding the correlations of random
> effects across treatment is clearly evident in the Bayesian confidence
> intervals;
>
> * the fixed-effects posterior modes are much closer to zero than the
> Laplace-approximated MLEs;
>
> * The Bayesian inference seems strongly supportive of a fixed effect of
> treatment, whereas lme4 superficially seemed to lead to the opposite
> conclusions.
>
> I'd love to hear people's thoughts on my approach to these data.  Many
> thanks in advance.
>
> Roger
>
> **
>
>     Treatment F1 F2 Response
> 1           1  6  1        1
> 2           1  7  1        1
> 3           1  8  1        1
> 4           1 15  1        1
> 5           1  1  2        1
> 6           1  2  2        1
> 7           1  3  2        1
> 8           1  4  2        1
> 9           1  9  2        1
> 10          1 10  2        1
> 11          1 11  2        1
> 12          1 12  2        0
> 13          1  6  3        1
> 14          1 14  3        1
> 15          1 15  3        1
> 16          1  3  4        1
> 17          1  4  4        1
> 18          1  9  4        1
> 19          1 10  4        1
> 20          1 11  4        1
> 21          1  6  5        1
> 22          1  8  5        1
> 23          1 13  5        1
> 24          1 14  5        1
> 25          1 15  5        1
> 26          1 16  5        1
> 27          1  1  6        1
> 28          1  2  6        1
> 29          1  3  6        1
> 30          1  9  6        1
> 31          1 10  6        1
> 32          1 11  6        1
> 33          1 12  6        1
> 34          1  5  7        0
> 35          1  6  7        1
> 36          1 14  7        1
> 37          1 15  7        1
> 38          1 16  7        1
> 39          1  1  8        1
> 40          1  2  8        1
> 41          1  3  8        1
> 42          1  4  8        1
> 43          1  9  8        1
> 44          1 10  8        1
> 45          1 11  8        0
> 46          1 12  8        1
> 47          1  5  9        0
> 48          1  7  9        1
> 49          1  8  9        1
> 50          1 14  9        1
> 51          1 15  9        1
> 52          1 16  9        1
> 53          1  1 10        1
> 54          1  3 10        1
> 55          1  9 10        1
> 56          1 10 10        1
> 57          1 11 10        1
> 58          1  5 11        0
> 59          1  6 11        1
> 60          1  8 11        1
> 61          1 14 11        1
> 62          1 15 11        1
> 63          1 16 11        1
> 64          1  1 12        1
> 65          1  2 12        1
> 66          1  9 12        1
> 67          1 10 12        1
> 68          1 11 12        0
> 69          1 12 12        0
> 70          1  6 13        1
> 71          1 14 13        1
> 72          1 15 13        1
> 73          1 16 13        1
> 74          1  1 14        1
> 75          1  2 14        0
> 76          1  3 14        1
> 77          1 10 14        1
> 78          1 11 14        1
> 79          1 12 14        1
> 80          1  6 15        1
> 81          1  8 15        1
> 82          1 14 15        1
> 83          1 15 15        1
> 84          1  1 16        1
> 85          1  3 16        1
> 86          1  4 16        1
> 87          1  9 16        1
> 88          1 10 16        1
> 89          1  6 17        1
> 90          1  8 17        1
> 91          1 14 17        1
> 92          1 15 17        1
> 93          1 16 17        1
> 94          1  1 18        1
> 95          1  9 18        1
> 96          1 10 18        1
> 97          1 11 18        1
> 98          1  6 19        1
> 99          1  8 19        1
> 100         1 14 19        1
> 101         1 15 19        1
> 102         1 16 19        1
> 103         1  1 20        1
> 104         1  9 20        1
> 105         1 10 20        1
> 106         1 11 20        1
> 107         1  6 21        1
> 108         1  8 21        1
> 109         1 14 21        1
> 110         1 15 21        1
> 111         1 16 21        1
> 112         1  1 22        1
> 113         1  2 22        0
> 114         1  3 22        0
> 115         1  9 22        1
> 116         1 10 22        1
> 117         1 11 22        1
> 118         1  6 23        1
> 119         1  7 23        0
> 120         1  8 23        1
> 121         1 14 23        1
> 122         1 15 23        1
> 123         1 16 23        1
> 124         1  1 24        1
> 125         1  2 24        0
> 126         1  3 24        1
> 127         1  9 24        1
> 128         1 10 24        1
> 129         1 11 24        1
> 130         2  3  1        1
> 131         2 11  1        1
> 132         2 15  2        1
> 133         2 16  2        1
> 134         2  2  3        1
> 135         2  7  4        1
> 136         2 15  4        1
> 137         2 10  5        1
> 138         2 11  5        1
> 139         2 12  5        1
> 140         2  8  6        1
> 141         2 15  6        1
> 142         2  1  7        0
> 143         2  2  7        1
> 144         2 10  7        1
> 145         2 11  7        1
> 146         2 12  7        1
> 147         2  8  8        1
> 148         2  1  9        1
> 149         2  2  9        1
> 150         2  9  9        1
> 151         2 10  9        1
> 152         2 11  9        1
> 153         2 12  9        1
> 154         2  5 10        1
> 155         2  8 10        1
> 156         2  5 12        1
> 157         2  7 12        1
> 158         2  8 12        1
> 159         2 14 12        1
> 160         2 15 12        1
> 161         2 16 12        1
> 162         2  1 13        1
> 163         2  5 14        1
> 164         2 15 14        1
> 165         2  2 15        1
> 166         2  3 15        1
> 167         2  9 15        1
> 168         2 10 15        1
> 169         2 11 15        1
> 170         2 12 15        1
> 171         2 15 16        1
> 172         2 16 16        1
> 173         2 11 17        1
> 174         2 12 17        1
> 175         2 15 18        1
> 176         2  1 21        1
> 177         2  2 21        1
> 178         2  3 21        1
> 179         2  9 21        1
> 180         2 10 21        1
> 181         2 11 21        1
> 182         2  7 22        1
> 183         2 15 22        1
> 184         2 16 22        1
> 185         2  1 23        1
> 186         2  2 23        1
> 187         2 10 23        1
> 188         2 11 23        1
> 189         2 12 23        1
> 190         2 15 24        1
>
> --
>
> Roger Levy                      Email: rlevy at ling.ucsd.edu
> Assistant Professor             Phone: 858-534-7219
> Department of Linguistics       Fax:   858-534-4789
> UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From rlevy at ling.ucsd.edu  Mon Jul  6 02:06:56 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Sun, 5 Jul 2009 17:06:56 -0700
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
	models for small datasets fitted with lme4?
In-Reply-To: <20090705224416.vfuldpedc0gc8o0c@www.staffmail.ed.ac.uk>
References: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
	<20090705224416.vfuldpedc0gc8o0c@www.staffmail.ed.ac.uk>
Message-ID: <CE3ABF0C-B0B0-404C-A094-B04AC327AFA9@ling.ucsd.edu>

Dear Jarrod,

Many thanks for your thoughts on this!  (more below)

On Jul 5, 2009, at 2:44 PM, Jarrod Hadfield wrote:

> Dear Roger,
>
> I think part of your problem is that in treatment 2 there are 60  
> success but only a single failure.

Actually in the original data there are 61 successes and no failures.   
In the imagined version of the data with 60 successes and one failure,  
the lme4 and Bayesian results are more in agreement.

> This means that there will be little (no?) information in the data  
> to estimate F1 and F2 variances that are specific to treatment 2.
> I suspect this explains the NaN, and also the discrepancy between  
> JAGS and lmer: in the Bayesian analysis this information is coming  
> completely from your prior, as are the between treatment  
> covariances.  I would recommend the simpler model:
>
> m1 <- lmer(Response ~ Treatment+(1 | F1)+(1 | F2), dat,  
> family=binomial)
>
> The F2 variance is fixed at zero, and the treatment effect is  
> significant at p=0.0268
>
> For this model the lmer and MCMCglmm results agree for the fixed  
> effects. The variance components are sensitive to the prior however,  
> but with weak priors the posterior distributions of the variances  
> are very wide.

Ah, but the trouble is that there *does* seem to be a reasonable  
amount of evidence for treatment-specific random effects of at least  
one of F1 and F2.  For example:

 > print (m1 <- lmer(Response ~ Treatment + (1 | F1) + (1  | F2), dat,  
family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (1 | F1) + (1 | F2)
    Data: dat
    AIC   BIC logLik deviance
  90.15 103.1 -41.08    82.15
Random effects:
  Groups Name        Variance Std.Dev.
  F2     (Intercept) 0.0000   0.0000
  F1     (Intercept) 3.4413   1.8551
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   2.9542     0.6277   4.706 2.52e-06 ***
Treatment2    2.6760     1.2083   2.215   0.0268 *
 > print (m01 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +  
(1  | F2), dat, family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (Treatment - 1 | F1) + (1 | F2)
    Data: dat
    AIC   BIC logLik deviance
  87.58 107.1 -37.79    75.58
Random effects:
  Groups Name        Variance   Std.Dev.   Corr
  F2     (Intercept) 1.6467e-12 1.2832e-06
  F1     Treatment1  9.0240e+00 3.0040e+00
         Treatment2  3.4832e+00 1.8663e+00 -1.000
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   3.8284     0.9857   3.884 0.000103 ***
Treatment2    1.3655     2.0034   0.682 0.495487

Going by the reported log-likelihoods and applying the reasoning of  
Baayen, Bates, and Davidson, a likelihood ratio test should be  
conservative and there so there is quite a bit of evidence for m01  
over m00 above.

This leads back to the original issue, though.  One intuition that I  
have is that for the two models

   Response ~ Treatment + (Treatment - 1 | F1) + (Treatment - 1 | F2)
   Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)

the log-likelihood should really have to be a fair bit better in the  
former than in the latter model (more than a difference of 0.42!),  
because whereas both models have to explain the observed proportions,  
the latter model also has to be lucky enough for the random effects to  
line up such that the observed proportions have a non-trivial  
likelihood.  That is, with the log-likelihood of interest being

   f(y | \beta, \theta) = \int P(y | \beta, b) P(b | \sigma) db

the former model should have much more probability from P(b | \sigma)  
in the region of b where P(y | \beta, b) is large enough to matter.

Best

Roger

> Quoting Roger Levy <rlevy at ling.ucsd.edu>:
>
>> This post may be of interest in light of the recent discussion of PQL
>> versus Laplace-approximated likelihood.  I'm facing an interestingly
>> challenging analysis of a relatively small (190-observation)
>> binary-response dataset with a single two-level treatment and two
>> crossed random factors (call them F1 and F2).  The question of  
>> current
>> interest is whether I can infer a difference in fixed effect of
>> treatment; it is hard to figure out the right conclusions to draw.   
>> I'm
>> putting the full dataset at the end of the message, but I'll start by
>> presenting some summary statistics:
>>
>>> xtabs(~ Treatment + Response, dat)
>>         Response
>> Treatment   0   1
>>        1  12 117
>>        2   0  61
>>
>> Fisher's exact test says "yes, the treatment has an effect" at  
>> p=0.01.
>> But of course that doesn't take into account the crossed hierarchical
>> structure of the data.  Some statistics on this:
>>
>>> with(dat,tapply(Response, list(F1,Treatment),length))
>>    1  2
>> 1  11  5
>> 2   7  6
>> 3   9  3
>> 4   4 NA
>> 5   3  3
>> 6  11 NA
>> 7   3  3
>> 8   9  4
>> 9  11  3
>> 10 12  6
>> 11 11  8
>> 12  5  6
>> 13  1 NA
>> 14 11  1
>> 15 12  9
>> 16  9  4
>>> with(dat,tapply(Response, list(F1,Treatment),mean))
>>           1  2
>> 1  1.0000000  1
>> 2  0.5714286  1
>> 3  0.8888889  1
>> 4  1.0000000 NA
>> 5  0.0000000  1
>> 6  1.0000000 NA
>> 7  0.6666667  1
>> 8  1.0000000  1
>> 9  1.0000000  1
>> 10 1.0000000  1
>> 11 0.8181818  1
>> 12 0.6000000  1
>> 13 1.0000000 NA
>> 14 1.0000000  1
>> 15 1.0000000  1
>> 16 1.0000000  1
>>> with(dat,tapply(Response, list(F2,Treatment),length))
>>   1  2
>> 1  4  2
>> 2  8  2
>> 3  3  1
>> 4  5  2
>> 5  6  3
>> 6  7  2
>> 7  5  5
>> 8  8  1
>> 9  6  6
>> 10 5  2
>> 11 6 NA
>> 12 6  6
>> 13 4  1
>> 14 6  2
>> 15 4  6
>> 16 5  2
>> 17 5  2
>> 18 4  1
>> 19 5 NA
>> 20 4 NA
>> 21 5  6
>> 22 6  3
>> 23 6  5
>> 24 6  1
>>> with(dat,tapply(Response, list(F2,Treatment),mean))
>>           1  2
>> 1  1.0000000  1
>> 2  0.8750000  1
>> 3  1.0000000  1
>> 4  1.0000000  1
>> 5  1.0000000  1
>> 6  1.0000000  1
>> 7  0.8000000  1
>> 8  0.8750000  1
>> 9  0.8333333  1
>> 10 1.0000000  1
>> 11 0.8333333 NA
>> 12 0.6666667  1
>> 13 1.0000000  1
>> 14 0.8333333  1
>> 15 1.0000000  1
>> 16 1.0000000  1
>> 17 1.0000000  1
>> 18 1.0000000  1
>> 19 1.0000000 NA
>> 20 1.0000000 NA
>> 21 1.0000000  1
>> 22 0.6666667  1
>> 23 0.8333333  1
>> 24 0.8333333  1
>>
>> So there is some sign of inter-cluster variability, though of course
>> the binary response makes it hard to see.  Crossed random-slope  
>> models
>> converge both with and without a fixed effect of treatment...
>>
>>> print(m1 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +
>> (Treatment - 1 | F2), dat, family=binomial))
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Response ~ Treatment + (Treatment - 1 | F1) + (Treatment -  
>> 1 |
>>     F2)
>>   Data: dat
>>   AIC   BIC logLik deviance
>> 82.65 108.6 -33.33    66.65
>> Random effects:
>> Groups Name       Variance   Std.Dev.   Corr
>> F2     Treatment1 4.1354e-12 2.0336e-06
>>        Treatment2 1.0492e+00 1.0243e+00 0.000
>> F1     Treatment1 9.4589e+00 3.0755e+00
>>        Treatment2 6.9945e-01 8.3633e-01 0.000
>> Number of obs: 190, groups: F2, 24; F1, 16
>>
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    3.943      1.004   3.929 8.54e-05 ***
>> Treatment2    17.289   5221.110   0.003    0.997
>>> print(m0 <- lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment  
>>> - 1
>> | F2), dat, family=binomial))
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)
>>   Data: dat
>>  AIC   BIC logLik deviance
>> 81.5 104.2 -33.75     67.5
>> Random effects:
>> Groups Name       Variance   Std.Dev.   Corr
>> F2     Treatment1 0.0000e+00 0.00000000
>>        Treatment2 1.7654e-08 0.00013287   NaN
>> F1     Treatment1 2.3858e+01 4.88443481
>>        Treatment2 3.0185e-02 0.17373716 -1.000
>> Number of obs: 190, groups: F2, 24; F1, 16
>>
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    5.855      1.384   4.232 2.32e-05 ***
>>
>>
>> ...but I am concerned (a) about the NaN correlation for F2 (this must
>> be a sign of something broken somewhere!?), and (b) about the minimal
>> difference in log-likelihood for m1 versus m0.  (Note that it's
>> possible to fix (a) by dropping random effects of F2 from m0, and the
>> log-likelihood doesn't change.)  It seems hard to believe that the
>> marginal log-likelihoods of the models given estimates of the fixed
>> effects and of the random-effect covariance matrices differs by only
>> 0.42.  I draw further evidence for this conclusion by imagining that
>> one response in Treatment 2 were a failure rather than a success:
>>
>>> dat[142,"Response"] <- 0
>>> logLik(lmer(Response ~ Treatment + (Treatment - 1 | F1) + (Treatment
>> - 1 | F2), dat, family=binomial))
>> 'log Lik.' -35.29494 (df=8)
>>> logLik(lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 |
>> F2), dat, family=binomial))
>> 'log Lik.' -37.60635 (df=7)
>>
>> Now there's a considerable difference in log-likelihood; this would
>> turn out significant in a chi-squared test (though of course we'd  
>> want
>> to calibrate with simulation if this were the actual dataset).
>>
>> Note that I can't use the Wald statistic here to address my  
>> hypothesis
>> for the real dataset, because the lack of failure responses in
>> Treatment 2 blows up the MLE and also the standard error of its
>> parameter.  I was hoping to use a likelihood-ratio comparison  
>> (perhaps
>> calibrated with simulation), but it seems to me that the minimal
>> observed difference in likelihood ratio for the actual dataset throws
>> that idea out the window.
>>
>> So here are some questions:
>>
>> 1) Is there something specific to the Laplace approximation being  
>> used
>> that renders logit models with extreme response proportions generally
>> unreliable?  (I can't check this directly against other packages
>> because of the crossed random effects.)
>>
>> 2) Is this dataset simply small enough that the uncertainty in
>> estimating of the random-effect variance pararameters makes
>> point-estimate inference on fixed effects unreliable, and I should go
>> the Bayesian route and integrate over the uncertainty?  Following  
>> this
>> possibility, I implemented the fixed-effect-of-treatment model (m1)  
>> in
>> JAGS with diffuse normal priors over the intercept and Treatment 2
>> parameter, and diffuse Wishart priors over the random-effect  
>> covariance
>> matrices.  Here are 95% Bayesian confidence intervals that result:
>>
>>
>>                      lower        upper
>> Omega.F2[1,1]  5.316465e+02 5.922489e+05
>> Omega.F2[2,1] -3.016791e+05 2.899492e+05
>> Omega.F2[1,2] -3.016791e+05 2.899492e+05
>> Omega.F2[2,2]  2.116783e+02 5.911579e+05
>> Omega.F1[1,1]  5.186791e+01 5.979535e+05
>> Omega.F1[2,1] -3.073216e+05 2.898743e+05
>> Omega.F1[1,2] -3.073216e+05 2.898743e+05
>> Omega.F1[2,2]  2.764357e+02 5.972545e+05
>> intercept      1.749505e+00 2.938812e+00
>> Treatment2     1.240127e+00 6.279801e+02
>>
>> and here is the posterior mode:
>>
>> Omega.F2[1,1]  70299.472805
>> Omega.F2[2,1]  -1324.272662
>> Omega.F2[1,2]  -1324.272662
>> Omega.F2[2,2]  70810.193188
>> Omega.F1[1,1]  70426.234086
>> Omega.F1[2,1] -46977.070058
>> Omega.F1[1,2] -46977.070058
>> Omega.F1[2,2]  87987.091315
>> intercept      1.977808
>> Treatment2     5.846867
>>
>> Some notable differences between these Bayesian results and the  
>> lme4-fit m1:
>>
>> * lme4 inferred considerably larger random effects of F1 than of F2,
>> which doesn't seem supported by the marginal means I listed near the
>> beginning of the email; whereas the Bayesian inference puts F1 and F2
>> on roughly equal footing;
>>
>> * the severe lack of evidence regarding the correlations of random
>> effects across treatment is clearly evident in the Bayesian  
>> confidence
>> intervals;
>>
>> * the fixed-effects posterior modes are much closer to zero than the
>> Laplace-approximated MLEs;
>>
>> * The Bayesian inference seems strongly supportive of a fixed  
>> effect of
>> treatment, whereas lme4 superficially seemed to lead to the opposite
>> conclusions.
>>
>> I'd love to hear people's thoughts on my approach to these data.   
>> Many
>> thanks in advance.
>>
>> Roger
>>
>> **
>>
>>    Treatment F1 F2 Response
>> 1           1  6  1        1
>> 2           1  7  1        1
>> 3           1  8  1        1
>> 4           1 15  1        1
>> 5           1  1  2        1
>> 6           1  2  2        1
>> 7           1  3  2        1
>> 8           1  4  2        1
>> 9           1  9  2        1
>> 10          1 10  2        1
>> 11          1 11  2        1
>> 12          1 12  2        0
>> 13          1  6  3        1
>> 14          1 14  3        1
>> 15          1 15  3        1
>> 16          1  3  4        1
>> 17          1  4  4        1
>> 18          1  9  4        1
>> 19          1 10  4        1
>> 20          1 11  4        1
>> 21          1  6  5        1
>> 22          1  8  5        1
>> 23          1 13  5        1
>> 24          1 14  5        1
>> 25          1 15  5        1
>> 26          1 16  5        1
>> 27          1  1  6        1
>> 28          1  2  6        1
>> 29          1  3  6        1
>> 30          1  9  6        1
>> 31          1 10  6        1
>> 32          1 11  6        1
>> 33          1 12  6        1
>> 34          1  5  7        0
>> 35          1  6  7        1
>> 36          1 14  7        1
>> 37          1 15  7        1
>> 38          1 16  7        1
>> 39          1  1  8        1
>> 40          1  2  8        1
>> 41          1  3  8        1
>> 42          1  4  8        1
>> 43          1  9  8        1
>> 44          1 10  8        1
>> 45          1 11  8        0
>> 46          1 12  8        1
>> 47          1  5  9        0
>> 48          1  7  9        1
>> 49          1  8  9        1
>> 50          1 14  9        1
>> 51          1 15  9        1
>> 52          1 16  9        1
>> 53          1  1 10        1
>> 54          1  3 10        1
>> 55          1  9 10        1
>> 56          1 10 10        1
>> 57          1 11 10        1
>> 58          1  5 11        0
>> 59          1  6 11        1
>> 60          1  8 11        1
>> 61          1 14 11        1
>> 62          1 15 11        1
>> 63          1 16 11        1
>> 64          1  1 12        1
>> 65          1  2 12        1
>> 66          1  9 12        1
>> 67          1 10 12        1
>> 68          1 11 12        0
>> 69          1 12 12        0
>> 70          1  6 13        1
>> 71          1 14 13        1
>> 72          1 15 13        1
>> 73          1 16 13        1
>> 74          1  1 14        1
>> 75          1  2 14        0
>> 76          1  3 14        1
>> 77          1 10 14        1
>> 78          1 11 14        1
>> 79          1 12 14        1
>> 80          1  6 15        1
>> 81          1  8 15        1
>> 82          1 14 15        1
>> 83          1 15 15        1
>> 84          1  1 16        1
>> 85          1  3 16        1
>> 86          1  4 16        1
>> 87          1  9 16        1
>> 88          1 10 16        1
>> 89          1  6 17        1
>> 90          1  8 17        1
>> 91          1 14 17        1
>> 92          1 15 17        1
>> 93          1 16 17        1
>> 94          1  1 18        1
>> 95          1  9 18        1
>> 96          1 10 18        1
>> 97          1 11 18        1
>> 98          1  6 19        1
>> 99          1  8 19        1
>> 100         1 14 19        1
>> 101         1 15 19        1
>> 102         1 16 19        1
>> 103         1  1 20        1
>> 104         1  9 20        1
>> 105         1 10 20        1
>> 106         1 11 20        1
>> 107         1  6 21        1
>> 108         1  8 21        1
>> 109         1 14 21        1
>> 110         1 15 21        1
>> 111         1 16 21        1
>> 112         1  1 22        1
>> 113         1  2 22        0
>> 114         1  3 22        0
>> 115         1  9 22        1
>> 116         1 10 22        1
>> 117         1 11 22        1
>> 118         1  6 23        1
>> 119         1  7 23        0
>> 120         1  8 23        1
>> 121         1 14 23        1
>> 122         1 15 23        1
>> 123         1 16 23        1
>> 124         1  1 24        1
>> 125         1  2 24        0
>> 126         1  3 24        1
>> 127         1  9 24        1
>> 128         1 10 24        1
>> 129         1 11 24        1
>> 130         2  3  1        1
>> 131         2 11  1        1
>> 132         2 15  2        1
>> 133         2 16  2        1
>> 134         2  2  3        1
>> 135         2  7  4        1
>> 136         2 15  4        1
>> 137         2 10  5        1
>> 138         2 11  5        1
>> 139         2 12  5        1
>> 140         2  8  6        1
>> 141         2 15  6        1
>> 142         2  1  7        0
>> 143         2  2  7        1
>> 144         2 10  7        1
>> 145         2 11  7        1
>> 146         2 12  7        1
>> 147         2  8  8        1
>> 148         2  1  9        1
>> 149         2  2  9        1
>> 150         2  9  9        1
>> 151         2 10  9        1
>> 152         2 11  9        1
>> 153         2 12  9        1
>> 154         2  5 10        1
>> 155         2  8 10        1
>> 156         2  5 12        1
>> 157         2  7 12        1
>> 158         2  8 12        1
>> 159         2 14 12        1
>> 160         2 15 12        1
>> 161         2 16 12        1
>> 162         2  1 13        1
>> 163         2  5 14        1
>> 164         2 15 14        1
>> 165         2  2 15        1
>> 166         2  3 15        1
>> 167         2  9 15        1
>> 168         2 10 15        1
>> 169         2 11 15        1
>> 170         2 12 15        1
>> 171         2 15 16        1
>> 172         2 16 16        1
>> 173         2 11 17        1
>> 174         2 12 17        1
>> 175         2 15 18        1
>> 176         2  1 21        1
>> 177         2  2 21        1
>> 178         2  3 21        1
>> 179         2  9 21        1
>> 180         2 10 21        1
>> 181         2 11 21        1
>> 182         2  7 22        1
>> 183         2 15 22        1
>> 184         2 16 22        1
>> 185         2  1 23        1
>> 186         2  2 23        1
>> 187         2 10 23        1
>> 188         2 11 23        1
>> 189         2 12 23        1
>> 190         2 15 24        1
>>
>> --
>>
>> Roger Levy                      Email: rlevy at ling.ucsd.edu
>> Assistant Professor             Phone: 858-534-7219
>> Department of Linguistics       Fax:   858-534-4789
>> UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy



From lborger at uoguelph.ca  Mon Jul  6 05:58:04 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Sun, 5 Jul 2009 23:58:04 -0400 (EDT)
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
 models for small datasets fitted with lme4?
In-Reply-To: <168188240.470651246852546867.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <2066838191.470841246852683956.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

but for m01 I think the model output:

####
> print (m01 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +  
(1  | F2), dat, family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (Treatment - 1 | F1) + (1 | F2)
    Data: dat
    AIC   BIC logLik deviance
  87.58 107.1 -37.79    75.58
Random effects:
  Groups Name        Variance   Std.Dev.   Corr
  F2     (Intercept) 1.6467e-12 1.2832e-06
  F1     Treatment1  9.0240e+00 3.0040e+00
         Treatment2  3.4832e+00 1.8663e+00 -1.000
Number of obs: 190, groups: F2, 24; F1, 16
###


indicates that there is not enough information to estimate that model (Corr=-1.00) and that the random effects part should be simplified notwithstanding the logLik value? Sorry fpr adding a question and hope this is relevant.




Cheers,

Luca





----- Messaggio originale -----
Da: "Roger Levy" <rlevy at ling.ucsd.edu>
A: "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Inviato: Domenica, 5 luglio 2009 20:06:56 GMT -05:00 U.S.A./Canada, stati orientali
Oggetto: Re: [R-sig-ME] how reliable are inferences drawn from binomial models for small datasets fitted with lme4?

Dear Jarrod,

Many thanks for your thoughts on this!  (more below)

On Jul 5, 2009, at 2:44 PM, Jarrod Hadfield wrote:

> Dear Roger,
>
> I think part of your problem is that in treatment 2 there are 60  
> success but only a single failure.

Actually in the original data there are 61 successes and no failures.   
In the imagined version of the data with 60 successes and one failure,  
the lme4 and Bayesian results are more in agreement.

> This means that there will be little (no?) information in the data  
> to estimate F1 and F2 variances that are specific to treatment 2.
> I suspect this explains the NaN, and also the discrepancy between  
> JAGS and lmer: in the Bayesian analysis this information is coming  
> completely from your prior, as are the between treatment  
> covariances.  I would recommend the simpler model:
>
> m1 <- lmer(Response ~ Treatment+(1 | F1)+(1 | F2), dat,  
> family=binomial)
>
> The F2 variance is fixed at zero, and the treatment effect is  
> significant at p=0.0268
>
> For this model the lmer and MCMCglmm results agree for the fixed  
> effects. The variance components are sensitive to the prior however,  
> but with weak priors the posterior distributions of the variances  
> are very wide.

Ah, but the trouble is that there *does* seem to be a reasonable  
amount of evidence for treatment-specific random effects of at least  
one of F1 and F2.  For example:

 > print (m1 <- lmer(Response ~ Treatment + (1 | F1) + (1  | F2), dat,  
family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (1 | F1) + (1 | F2)
    Data: dat
    AIC   BIC logLik deviance
  90.15 103.1 -41.08    82.15
Random effects:
  Groups Name        Variance Std.Dev.
  F2     (Intercept) 0.0000   0.0000
  F1     (Intercept) 3.4413   1.8551
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   2.9542     0.6277   4.706 2.52e-06 ***
Treatment2    2.6760     1.2083   2.215   0.0268 *
 > print (m01 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +  
(1  | F2), dat, family=binomial))
Generalized linear mixed model fit by the Laplace approximation
Formula: Response ~ Treatment + (Treatment - 1 | F1) + (1 | F2)
    Data: dat
    AIC   BIC logLik deviance
  87.58 107.1 -37.79    75.58
Random effects:
  Groups Name        Variance   Std.Dev.   Corr
  F2     (Intercept) 1.6467e-12 1.2832e-06
  F1     Treatment1  9.0240e+00 3.0040e+00
         Treatment2  3.4832e+00 1.8663e+00 -1.000
Number of obs: 190, groups: F2, 24; F1, 16

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   3.8284     0.9857   3.884 0.000103 ***
Treatment2    1.3655     2.0034   0.682 0.495487

Going by the reported log-likelihoods and applying the reasoning of  
Baayen, Bates, and Davidson, a likelihood ratio test should be  
conservative and there so there is quite a bit of evidence for m01  
over m00 above.

This leads back to the original issue, though.  One intuition that I  
have is that for the two models

   Response ~ Treatment + (Treatment - 1 | F1) + (Treatment - 1 | F2)
   Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)

the log-likelihood should really have to be a fair bit better in the  
former than in the latter model (more than a difference of 0.42!),  
because whereas both models have to explain the observed proportions,  
the latter model also has to be lucky enough for the random effects to  
line up such that the observed proportions have a non-trivial  
likelihood.  That is, with the log-likelihood of interest being

   f(y | \beta, \theta) = \int P(y | \beta, b) P(b | \sigma) db

the former model should have much more probability from P(b | \sigma)  
in the region of b where P(y | \beta, b) is large enough to matter.

Best

Roger

> Quoting Roger Levy <rlevy at ling.ucsd.edu>:
>
>> This post may be of interest in light of the recent discussion of PQL
>> versus Laplace-approximated likelihood.  I'm facing an interestingly
>> challenging analysis of a relatively small (190-observation)
>> binary-response dataset with a single two-level treatment and two
>> crossed random factors (call them F1 and F2).  The question of  
>> current
>> interest is whether I can infer a difference in fixed effect of
>> treatment; it is hard to figure out the right conclusions to draw.   
>> I'm
>> putting the full dataset at the end of the message, but I'll start by
>> presenting some summary statistics:
>>
>>> xtabs(~ Treatment + Response, dat)
>>         Response
>> Treatment   0   1
>>        1  12 117
>>        2   0  61
>>
>> Fisher's exact test says "yes, the treatment has an effect" at  
>> p=0.01.
>> But of course that doesn't take into account the crossed hierarchical
>> structure of the data.  Some statistics on this:
>>
>>> with(dat,tapply(Response, list(F1,Treatment),length))
>>    1  2
>> 1  11  5
>> 2   7  6
>> 3   9  3
>> 4   4 NA
>> 5   3  3
>> 6  11 NA
>> 7   3  3
>> 8   9  4
>> 9  11  3
>> 10 12  6
>> 11 11  8
>> 12  5  6
>> 13  1 NA
>> 14 11  1
>> 15 12  9
>> 16  9  4
>>> with(dat,tapply(Response, list(F1,Treatment),mean))
>>           1  2
>> 1  1.0000000  1
>> 2  0.5714286  1
>> 3  0.8888889  1
>> 4  1.0000000 NA
>> 5  0.0000000  1
>> 6  1.0000000 NA
>> 7  0.6666667  1
>> 8  1.0000000  1
>> 9  1.0000000  1
>> 10 1.0000000  1
>> 11 0.8181818  1
>> 12 0.6000000  1
>> 13 1.0000000 NA
>> 14 1.0000000  1
>> 15 1.0000000  1
>> 16 1.0000000  1
>>> with(dat,tapply(Response, list(F2,Treatment),length))
>>   1  2
>> 1  4  2
>> 2  8  2
>> 3  3  1
>> 4  5  2
>> 5  6  3
>> 6  7  2
>> 7  5  5
>> 8  8  1
>> 9  6  6
>> 10 5  2
>> 11 6 NA
>> 12 6  6
>> 13 4  1
>> 14 6  2
>> 15 4  6
>> 16 5  2
>> 17 5  2
>> 18 4  1
>> 19 5 NA
>> 20 4 NA
>> 21 5  6
>> 22 6  3
>> 23 6  5
>> 24 6  1
>>> with(dat,tapply(Response, list(F2,Treatment),mean))
>>           1  2
>> 1  1.0000000  1
>> 2  0.8750000  1
>> 3  1.0000000  1
>> 4  1.0000000  1
>> 5  1.0000000  1
>> 6  1.0000000  1
>> 7  0.8000000  1
>> 8  0.8750000  1
>> 9  0.8333333  1
>> 10 1.0000000  1
>> 11 0.8333333 NA
>> 12 0.6666667  1
>> 13 1.0000000  1
>> 14 0.8333333  1
>> 15 1.0000000  1
>> 16 1.0000000  1
>> 17 1.0000000  1
>> 18 1.0000000  1
>> 19 1.0000000 NA
>> 20 1.0000000 NA
>> 21 1.0000000  1
>> 22 0.6666667  1
>> 23 0.8333333  1
>> 24 0.8333333  1
>>
>> So there is some sign of inter-cluster variability, though of course
>> the binary response makes it hard to see.  Crossed random-slope  
>> models
>> converge both with and without a fixed effect of treatment...
>>
>>> print(m1 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +
>> (Treatment - 1 | F2), dat, family=binomial))
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Response ~ Treatment + (Treatment - 1 | F1) + (Treatment -  
>> 1 |
>>     F2)
>>   Data: dat
>>   AIC   BIC logLik deviance
>> 82.65 108.6 -33.33    66.65
>> Random effects:
>> Groups Name       Variance   Std.Dev.   Corr
>> F2     Treatment1 4.1354e-12 2.0336e-06
>>        Treatment2 1.0492e+00 1.0243e+00 0.000
>> F1     Treatment1 9.4589e+00 3.0755e+00
>>        Treatment2 6.9945e-01 8.3633e-01 0.000
>> Number of obs: 190, groups: F2, 24; F1, 16
>>
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    3.943      1.004   3.929 8.54e-05 ***
>> Treatment2    17.289   5221.110   0.003    0.997
>>> print(m0 <- lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment  
>>> - 1
>> | F2), dat, family=binomial))
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 | F2)
>>   Data: dat
>>  AIC   BIC logLik deviance
>> 81.5 104.2 -33.75     67.5
>> Random effects:
>> Groups Name       Variance   Std.Dev.   Corr
>> F2     Treatment1 0.0000e+00 0.00000000
>>        Treatment2 1.7654e-08 0.00013287   NaN
>> F1     Treatment1 2.3858e+01 4.88443481
>>        Treatment2 3.0185e-02 0.17373716 -1.000
>> Number of obs: 190, groups: F2, 24; F1, 16
>>
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)    5.855      1.384   4.232 2.32e-05 ***
>>
>>
>> ...but I am concerned (a) about the NaN correlation for F2 (this must
>> be a sign of something broken somewhere!?), and (b) about the minimal
>> difference in log-likelihood for m1 versus m0.  (Note that it's
>> possible to fix (a) by dropping random effects of F2 from m0, and the
>> log-likelihood doesn't change.)  It seems hard to believe that the
>> marginal log-likelihoods of the models given estimates of the fixed
>> effects and of the random-effect covariance matrices differs by only
>> 0.42.  I draw further evidence for this conclusion by imagining that
>> one response in Treatment 2 were a failure rather than a success:
>>
>>> dat[142,"Response"] <- 0
>>> logLik(lmer(Response ~ Treatment + (Treatment - 1 | F1) + (Treatment
>> - 1 | F2), dat, family=binomial))
>> 'log Lik.' -35.29494 (df=8)
>>> logLik(lmer(Response ~ 1 + (Treatment - 1 | F1) + (Treatment - 1 |
>> F2), dat, family=binomial))
>> 'log Lik.' -37.60635 (df=7)
>>
>> Now there's a considerable difference in log-likelihood; this would
>> turn out significant in a chi-squared test (though of course we'd  
>> want
>> to calibrate with simulation if this were the actual dataset).
>>
>> Note that I can't use the Wald statistic here to address my  
>> hypothesis
>> for the real dataset, because the lack of failure responses in
>> Treatment 2 blows up the MLE and also the standard error of its
>> parameter.  I was hoping to use a likelihood-ratio comparison  
>> (perhaps
>> calibrated with simulation), but it seems to me that the minimal
>> observed difference in likelihood ratio for the actual dataset throws
>> that idea out the window.
>>
>> So here are some questions:
>>
>> 1) Is there something specific to the Laplace approximation being  
>> used
>> that renders logit models with extreme response proportions generally
>> unreliable?  (I can't check this directly against other packages
>> because of the crossed random effects.)
>>
>> 2) Is this dataset simply small enough that the uncertainty in
>> estimating of the random-effect variance pararameters makes
>> point-estimate inference on fixed effects unreliable, and I should go
>> the Bayesian route and integrate over the uncertainty?  Following  
>> this
>> possibility, I implemented the fixed-effect-of-treatment model (m1)  
>> in
>> JAGS with diffuse normal priors over the intercept and Treatment 2
>> parameter, and diffuse Wishart priors over the random-effect  
>> covariance
>> matrices.  Here are 95% Bayesian confidence intervals that result:
>>
>>
>>                      lower        upper
>> Omega.F2[1,1]  5.316465e+02 5.922489e+05
>> Omega.F2[2,1] -3.016791e+05 2.899492e+05
>> Omega.F2[1,2] -3.016791e+05 2.899492e+05
>> Omega.F2[2,2]  2.116783e+02 5.911579e+05
>> Omega.F1[1,1]  5.186791e+01 5.979535e+05
>> Omega.F1[2,1] -3.073216e+05 2.898743e+05
>> Omega.F1[1,2] -3.073216e+05 2.898743e+05
>> Omega.F1[2,2]  2.764357e+02 5.972545e+05
>> intercept      1.749505e+00 2.938812e+00
>> Treatment2     1.240127e+00 6.279801e+02
>>
>> and here is the posterior mode:
>>
>> Omega.F2[1,1]  70299.472805
>> Omega.F2[2,1]  -1324.272662
>> Omega.F2[1,2]  -1324.272662
>> Omega.F2[2,2]  70810.193188
>> Omega.F1[1,1]  70426.234086
>> Omega.F1[2,1] -46977.070058
>> Omega.F1[1,2] -46977.070058
>> Omega.F1[2,2]  87987.091315
>> intercept      1.977808
>> Treatment2     5.846867
>>
>> Some notable differences between these Bayesian results and the  
>> lme4-fit m1:
>>
>> * lme4 inferred considerably larger random effects of F1 than of F2,
>> which doesn't seem supported by the marginal means I listed near the
>> beginning of the email; whereas the Bayesian inference puts F1 and F2
>> on roughly equal footing;
>>
>> * the severe lack of evidence regarding the correlations of random
>> effects across treatment is clearly evident in the Bayesian  
>> confidence
>> intervals;
>>
>> * the fixed-effects posterior modes are much closer to zero than the
>> Laplace-approximated MLEs;
>>
>> * The Bayesian inference seems strongly supportive of a fixed  
>> effect of
>> treatment, whereas lme4 superficially seemed to lead to the opposite
>> conclusions.
>>
>> I'd love to hear people's thoughts on my approach to these data.   
>> Many
>> thanks in advance.
>>
>> Roger
>>
>> **
>>
>>    Treatment F1 F2 Response
>> 1           1  6  1        1
>> 2           1  7  1        1
>> 3           1  8  1        1
>> 4           1 15  1        1
>> 5           1  1  2        1
>> 6           1  2  2        1
>> 7           1  3  2        1
>> 8           1  4  2        1
>> 9           1  9  2        1
>> 10          1 10  2        1
>> 11          1 11  2        1
>> 12          1 12  2        0
>> 13          1  6  3        1
>> 14          1 14  3        1
>> 15          1 15  3        1
>> 16          1  3  4        1
>> 17          1  4  4        1
>> 18          1  9  4        1
>> 19          1 10  4        1
>> 20          1 11  4        1
>> 21          1  6  5        1
>> 22          1  8  5        1
>> 23          1 13  5        1
>> 24          1 14  5        1
>> 25          1 15  5        1
>> 26          1 16  5        1
>> 27          1  1  6        1
>> 28          1  2  6        1
>> 29          1  3  6        1
>> 30          1  9  6        1
>> 31          1 10  6        1
>> 32          1 11  6        1
>> 33          1 12  6        1
>> 34          1  5  7        0
>> 35          1  6  7        1
>> 36          1 14  7        1
>> 37          1 15  7        1
>> 38          1 16  7        1
>> 39          1  1  8        1
>> 40          1  2  8        1
>> 41          1  3  8        1
>> 42          1  4  8        1
>> 43          1  9  8        1
>> 44          1 10  8        1
>> 45          1 11  8        0
>> 46          1 12  8        1
>> 47          1  5  9        0
>> 48          1  7  9        1
>> 49          1  8  9        1
>> 50          1 14  9        1
>> 51          1 15  9        1
>> 52          1 16  9        1
>> 53          1  1 10        1
>> 54          1  3 10        1
>> 55          1  9 10        1
>> 56          1 10 10        1
>> 57          1 11 10        1
>> 58          1  5 11        0
>> 59          1  6 11        1
>> 60          1  8 11        1
>> 61          1 14 11        1
>> 62          1 15 11        1
>> 63          1 16 11        1
>> 64          1  1 12        1
>> 65          1  2 12        1
>> 66          1  9 12        1
>> 67          1 10 12        1
>> 68          1 11 12        0
>> 69          1 12 12        0
>> 70          1  6 13        1
>> 71          1 14 13        1
>> 72          1 15 13        1
>> 73          1 16 13        1
>> 74          1  1 14        1
>> 75          1  2 14        0
>> 76          1  3 14        1
>> 77          1 10 14        1
>> 78          1 11 14        1
>> 79          1 12 14        1
>> 80          1  6 15        1
>> 81          1  8 15        1
>> 82          1 14 15        1
>> 83          1 15 15        1
>> 84          1  1 16        1
>> 85          1  3 16        1
>> 86          1  4 16        1
>> 87          1  9 16        1
>> 88          1 10 16        1
>> 89          1  6 17        1
>> 90          1  8 17        1
>> 91          1 14 17        1
>> 92          1 15 17        1
>> 93          1 16 17        1
>> 94          1  1 18        1
>> 95          1  9 18        1
>> 96          1 10 18        1
>> 97          1 11 18        1
>> 98          1  6 19        1
>> 99          1  8 19        1
>> 100         1 14 19        1
>> 101         1 15 19        1
>> 102         1 16 19        1
>> 103         1  1 20        1
>> 104         1  9 20        1
>> 105         1 10 20        1
>> 106         1 11 20        1
>> 107         1  6 21        1
>> 108         1  8 21        1
>> 109         1 14 21        1
>> 110         1 15 21        1
>> 111         1 16 21        1
>> 112         1  1 22        1
>> 113         1  2 22        0
>> 114         1  3 22        0
>> 115         1  9 22        1
>> 116         1 10 22        1
>> 117         1 11 22        1
>> 118         1  6 23        1
>> 119         1  7 23        0
>> 120         1  8 23        1
>> 121         1 14 23        1
>> 122         1 15 23        1
>> 123         1 16 23        1
>> 124         1  1 24        1
>> 125         1  2 24        0
>> 126         1  3 24        1
>> 127         1  9 24        1
>> 128         1 10 24        1
>> 129         1 11 24        1
>> 130         2  3  1        1
>> 131         2 11  1        1
>> 132         2 15  2        1
>> 133         2 16  2        1
>> 134         2  2  3        1
>> 135         2  7  4        1
>> 136         2 15  4        1
>> 137         2 10  5        1
>> 138         2 11  5        1
>> 139         2 12  5        1
>> 140         2  8  6        1
>> 141         2 15  6        1
>> 142         2  1  7        0
>> 143         2  2  7        1
>> 144         2 10  7        1
>> 145         2 11  7        1
>> 146         2 12  7        1
>> 147         2  8  8        1
>> 148         2  1  9        1
>> 149         2  2  9        1
>> 150         2  9  9        1
>> 151         2 10  9        1
>> 152         2 11  9        1
>> 153         2 12  9        1
>> 154         2  5 10        1
>> 155         2  8 10        1
>> 156         2  5 12        1
>> 157         2  7 12        1
>> 158         2  8 12        1
>> 159         2 14 12        1
>> 160         2 15 12        1
>> 161         2 16 12        1
>> 162         2  1 13        1
>> 163         2  5 14        1
>> 164         2 15 14        1
>> 165         2  2 15        1
>> 166         2  3 15        1
>> 167         2  9 15        1
>> 168         2 10 15        1
>> 169         2 11 15        1
>> 170         2 12 15        1
>> 171         2 15 16        1
>> 172         2 16 16        1
>> 173         2 11 17        1
>> 174         2 12 17        1
>> 175         2 15 18        1
>> 176         2  1 21        1
>> 177         2  2 21        1
>> 178         2  3 21        1
>> 179         2  9 21        1
>> 180         2 10 21        1
>> 181         2 11 21        1
>> 182         2  7 22        1
>> 183         2 15 22        1
>> 184         2 16 22        1
>> 185         2  1 23        1
>> 186         2  2 23        1
>> 187         2 10 23        1
>> 188         2 11 23        1
>> 189         2 12 23        1
>> 190         2 15 24        1
>>
>> --
>>
>> Roger Levy                      Email: rlevy at ling.ucsd.edu
>> Assistant Professor             Phone: 858-534-7219
>> Department of Linguistics       Fax:   858-534-4789
>> UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Mon Jul  6 07:38:44 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 6 Jul 2009 15:38:44 +1000 (EST)
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
 modelsfor small datasets fitted with lme4?
In-Reply-To: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
References: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
Message-ID: <Pine.LNX.4.64.0907061439560.24982@orpheus.qimr.edu.au>

On Sun, 5 Jul 2009, Roger Levy wrote:

> This post may be of interest in light of the recent discussion of PQL versus 
> Laplace-approximated likelihood.  I'm facing an interestingly challenging 
> analysis of a relatively small (190-observation) binary-response dataset with 
> a single two-level treatment and two crossed random factors (call them F1 and 
> F2).  The question of current interest is whether I can infer a difference in 
> fixed effect of treatment ...  [SNIP]

Although F1 has an effect, F2 doesn't seem as impressive:

For Response, Tarone score test for extrabinomial variance gives
F1 3.86 (P=0.0493), F2 0.54 (P=0.4616).

So it seems reasonable just to ignore F2.  Then the conditional logistic 
regression stratifying on F1 is nicely significant:

clogit(Response ~ Treatment + strata(F1), method="exact", data = x)

            coef exp(coef) se(coef)    z     p
Treatment2 2.73      15.3     1.10 2.49 0.013

Likelihood ratio test=10.9  on 1 df, p=0.000957  n= 190

(and equivalent score test 9.054, P=0.0026).

The conditional logistic should be fairly robust, and at least
gives some kind of benchmark for other models.

Cheers, David Duffy.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Thierry.ONKELINX at inbo.be  Mon Jul  6 12:13:57 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 6 Jul 2009 12:13:57 +0200
Subject: [R-sig-ME] Question about nested design
Message-ID: <2E9C414912813E4EB981326983E0A10406990009@inboexch.inbo.be>

Dear all,

I have a rather theoretical question about nested random effects.
Suppose the design has three levels S(ample), R(eplicate) and M(arker).
M is crossed with both S and R. R is nested in S. M has about 40 levels,
S 206 levels and R 251 levels. The difference in the number of levels
between S and R is rather small because 171 samples have only one
replicate. 22 samples have two replicates and 13 samples have three
replicates. Does it makes sense to add the nested effect of R to the
model? So the random structure would look like (1|M) + (1|S) + (1|S:R).
Or should I better stick to a model without the replicates (1|M) +
(1|S)?
Changing the design to get replicates for all samples is not an option
as that would be too expensive and too much work.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From DAfshartous at med.miami.edu  Mon Jul  6 17:59:32 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 6 Jul 2009 11:59:32 -0400
Subject: [R-sig-ME] Multivariate mixed effects model
In-Reply-To: <005a01c9f9c0$5cdf87c0$0a01a8c0@medion>
Message-ID: <C67797A4.AB5E%dafshartous@med.miami.edu>


Thanks for the reference Mareike.  This approach works fine for simple models, but I don't see how to extend to more complex models. A variety of more complex structures can apparently be fit in SAS (Gao et al, Fitting Multivariate Longitudinal Data Using SAS, Paper 187-31).
In the context of the pseudo example below, does anyone  know how to do the following?
## 1) residual error correlated across variables at the same time point?
## 2) residual error correlated across variables at different time point? (e.g., AR1)
## 3) different AR1 coefficient for different variables?

Thanks,
David


## basic bivariate model with correlated intercept random-effects
mv1.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time, random = ~ -1 + y1.ind + y2.ind  | subject,
            data = data.mv, control=nlmeControl(msMaxIter = 500))
## different residual error variance per variable
mv3.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time, random = ~ -1 + y1.ind + y2.ind  | subject,
            data = data.mv, control=nlmeControl(msMaxIter = 500), weights = varIdent(form = ~1 | y1.ind))

## for comparison, basic model in lmer below, but don't think residual variance extensions above currently available:
library("lme4")
mv1.lmer  = lmer(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time +  (0 + y1.ind + y2.ind + y1.time + y2.time | subject) ,
            data = data.mv)

###############
## simulated data:
set.seed(100); n1 = 30; n2 = 4
library("MASS"); library("nlme")
y1 = y2 = matrix(0, n2, n1)
for (i in 1:n1) {
    b.i = mvrnorm(n = 1, mu = c(0,0), Sigma = matrix(c(3, 1, 1, 6), nrow = 2, ncol = 2)) # correlated random effects
   for (j in 1:n2) {
        eps =  mvrnorm(n = 1, mu = c(0,0), Sigma = matrix(c(2, 0, 0, 5), nrow = 2, ncol = 2))  ##  uncorrelated error term
       y1[j,i] = 4 + 2 * j + b.i[1] + eps[1]  ## fixed intercept and sloped effects + random-intercept
       y2[j,i] = 25 + 13 * j + b.i[2] + eps[2] }}
data.mv = data.frame(subject = rep(seq(1,n1), each = n2, 2), time = rep(c(1:n2), n1*2), y = c(as.vector(y1), as.vector(y2)), y1.ind = rep( c(1,0),
    each = n1*n2), y2.ind = rep( c(0,1), each = n1*n2), y1.time = c(rep(seq(1:4), n1), rep(0, n1*n2)), y2.time = c(rep(0, n1*n2), rep(seq(1,4), n1)))



On 6/30/09 4:21 PM, "Mareike Kohlmann" <mareike.kohlmann at stat.uni-muenchen.de> wrote:

Hi,

lme or lmer can be used when the multivariate variables are structured in
the same way as if only a univariate variable was analyzed. A set of dummy
codes need to be created to "flag" the outcomes accordingly.

For more details, see e.g:
Doran, H., Lockwood, J., 2006. Fitting value-added models in R. Journal of
Educational and Behavioral Statistics 31 (2), p. 205-230.

Cheers,
Mareike

***************************************
Mareike Kohlmann
Department of Statistics
Ludwig-Maximilians-University Munich
Germany
E-Mail: mareike.kohlmann at stat.uni-muenchen.de



From rlevy at ling.ucsd.edu  Mon Jul  6 19:47:55 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Mon, 6 Jul 2009 10:47:55 -0700
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
	modelsfor small datasets fitted with lme4?
In-Reply-To: <Pine.LNX.4.64.0907061439560.24982@orpheus.qimr.edu.au>
References: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
	<Pine.LNX.4.64.0907061439560.24982@orpheus.qimr.edu.au>
Message-ID: <011A62C5-EBBE-42FC-ACE8-2831EA6C0CF0@ling.ucsd.edu>

On Jul 5, 2009, at 10:38 PM, David Duffy wrote:

> On Sun, 5 Jul 2009, Roger Levy wrote:
>
>> This post may be of interest in light of the recent discussion of  
>> PQL versus Laplace-approximated likelihood.  I'm facing an  
>> interestingly challenging analysis of a relatively small (190- 
>> observation) binary-response dataset with a single two-level  
>> treatment and two crossed random factors (call them F1 and F2).   
>> The question of current interest is whether I can infer a  
>> difference in fixed effect of treatment ...  [SNIP]
>
> Although F1 has an effect, F2 doesn't seem as impressive:
>
> For Response, Tarone score test for extrabinomial variance gives
> F1 3.86 (P=0.0493), F2 0.54 (P=0.4616).
>
> So it seems reasonable just to ignore F2.  Then the conditional  
> logistic regression stratifying on F1 is nicely significant:
>
> clogit(Response ~ Treatment + strata(F1), method="exact", data = x)
>
>           coef exp(coef) se(coef)    z     p
> Treatment2 2.73      15.3     1.10 2.49 0.013
>
> Likelihood ratio test=10.9  on 1 df, p=0.000957  n= 190
>
> (and equivalent score test 9.054, P=0.0026).
>
> The conditional logistic should be fairly robust, and at least
> gives some kind of benchmark for other models.

Dear David,

Many thanks for your input -- I'm not familiar with the Tarone score  
test (looking around -- is this Tarone 1979, Biometrika?) or with  
stratified conditional logistic models.  Could you perhaps give me  
pointers to R code for the former, and references for both?

Best & many thanks again.

Roger

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy



From rlevy at ling.ucsd.edu  Mon Jul  6 20:10:49 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Mon, 6 Jul 2009 11:10:49 -0700
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
	models for small datasets fitted with lme4?
In-Reply-To: <2066838191.470841246852683956.JavaMail.root@huron.cs.uoguelph.ca>
References: <2066838191.470841246852683956.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <25B91258-A0EC-471E-ABE1-7CD523AA426A@ling.ucsd.edu>

On Jul 5, 2009, at 8:58 PM, Luca Borger wrote:

> Hello,
>
> but for m01 I think the model output:
>
> ####
>> print (m01 <- lmer(Response ~ Treatment + (Treatment - 1 | F1) +
> (1  | F2), dat, family=binomial))
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Response ~ Treatment + (Treatment - 1 | F1) + (1 | F2)
>    Data: dat
>    AIC   BIC logLik deviance
>  87.58 107.1 -37.79    75.58
> Random effects:
>  Groups Name        Variance   Std.Dev.   Corr
>  F2     (Intercept) 1.6467e-12 1.2832e-06
>  F1     Treatment1  9.0240e+00 3.0040e+00
>         Treatment2  3.4832e+00 1.8663e+00 -1.000
> Number of obs: 190, groups: F2, 24; F1, 16
> ###
>
>
> indicates that there is not enough information to estimate that  
> model (Corr=-1.00) and that the random effects part should be  
> simplified notwithstanding the logLik value? Sorry fpr adding a  
> question and hope this is relevant.

Dear Luca,

Many thanks for your thoughts on this -- I did notice the correlation  
for F1 but in my thinking, this was sensible behavior by the model and  
didn't necessarily indicate a need to simplify the F1 random effects  
component.  Let me explain my reasoning.  Going back to the marginal  
mean responses per F1/Treatment combination:

 > with(dat,tapply(Response, list(F1, Treatment), mean))
            1  2
1  1.0000000  1
2  0.5714286  1
3  0.8888889  1
4  1.0000000 NA
5  0.0000000  1
6  1.0000000 NA
7  0.6666667  1
8  1.0000000  1
9  1.0000000  1
10 1.0000000  1
11 0.8181818  1
12 0.6000000  1
13 1.0000000 NA
14 1.0000000  1
15 1.0000000  1
16 1.0000000  1

it seems to me that the only way a random effect can contribute to the  
likelihood is by bringing down the linear predictor in Treatment for  
levels 2, 3, 7, 11, and 12 of F1.  So the random effects for these  
levels in Treatment 1 must be negative.  Now, given this constraint,  
what choice random effects for these levels in Treatment 2 maximize  
the likelihood?  Since there are never any Treatment 2 failures, these  
random effects should be as high as possible.  This leads to an  
inferred correlation of -1 for the random effects of F1.

The surprise to me isn't really that the random-effect correlation is  
so extreme, but rather that the model log-likelihoods seem to indicate  
that there's sufficient evidence to go with the model with more  
complex random-effects structure.  Which leads me to ask about how  
reliable log-likelihood differences for mixed-effects logit models on  
small datasets like this may be.

Many thanks once more!

Roger

--

Roger Levy                      Email: rlevy at ling.ucsd.edu
Assistant Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://ling.ucsd.edu/~rlevy



From rlevy at ling.ucsd.edu  Mon Jul  6 22:54:48 2009
From: rlevy at ling.ucsd.edu (Roger Levy)
Date: Mon, 6 Jul 2009 13:54:48 -0700
Subject: [R-sig-ME] how reliable are inferences drawn from binomial
	models for small datasets fitted with lme4?
In-Reply-To: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
References: <65AF2C0B-8B29-4D18-AF61-A25853A3091C@ling.ucsd.edu>
Message-ID: <250E8174-D734-44B2-8C10-62E0BC9E74F2@ling.ucsd.edu>

On Jul 5, 2009, at 12:51 PM, Roger Levy wrote:

> This post may be of interest in light of the recent discussion of  
> PQL versus Laplace-approximated likelihood.

Oh dear, I made a mistake in posting the original dataset -- I posted  
the hypothesized dataset where I had converted one Treatment-2 success  
to failure, rather than the original data.  This line:

>    Treatment F1 F2 Response
> ...
> 142         2  1  7        0
> ...


should have been

>    Treatment F1 F2 Response
> ...
> 142         2  1  7        1
> ...

Apologies to all...

Best

Roger



From njbisaac at googlemail.com  Mon Jul  6 22:55:00 2009
From: njbisaac at googlemail.com (Nick Isaac)
Date: Mon, 6 Jul 2009 15:55:00 -0500
Subject: [R-sig-ME] problems with 'false convergence' in lmer
In-Reply-To: <a0743530906220923j584a62e9y76f320bc791a9650@mail.gmail.com>
References: <a0743530906220751w5f7e3f66h48fa4e13ca63d275@mail.gmail.com>
	<OF27C0228E.8754AB2C-ON862575DD.0054EE5D-862575DD.00559A3E@unl.edu>
	<a0743530906220923j584a62e9y76f320bc791a9650@mail.gmail.com>
Message-ID: <44C8DD0F-826A-49C5-B015-E38CA19D04A0@googlemail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090706/21904ab8/attachment.pl>

From Aditi.Singh at bristol.ac.uk  Thu Jul  9 18:52:46 2009
From: Aditi.Singh at bristol.ac.uk (A Singh)
Date: Thu, 09 Jul 2009 17:52:46 +0100
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
Message-ID: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>

Dear All,

I am trying to run a nested random effects model in lmer (for R 2.9.1, lme4 
version 0.999375-31 ) using data which is structured as follows:

family offsp. P1L74 P1L77 P1L91 P1L96..(n=426) peg.no ec.length  syll.length
1   	 2      1	  0	  0	  0	            86	5.445	     2.479
1   	 3      1	  0	  0	  0	    		91	5.215	     2.356
1   	 4      0	  0	  0	  0	    	      79	5.682	     2.896
1   	 5      1	  0	  0	  0	   		83	5.149	     2.641
1   	 6      0	  0	  0	  0	    		77	5.044	     2.288
1   	 7      1	  0	  0	  0	    	      78	5.450	     2.420
1   	 8      1	  0	  1	  1	    		82	5.377	     2.505
1   	 9      1	  0	  0	  0	    		95	5.389	     2.706
1   	10      1	  0	  0	  0	    		88	5.354	     2.461
1   	11      1	  0	  0	  0	    		87	5.262	     3.079	
1   	12      1	  0	  0	  0	    		84	5.191	     2.858
1   	13      1	  0	  0	  1	    	      87	5.194	     2.264
2   	23      1	  0	  0	  1	    	      116	5.863	     2.876
2   	24      1	  0	  0	  0	    		122	5.475	     3.114
2   	25      1	  0	  0	  0	    		110	5.563	     3.059
.       .       .   .     .     .               .         .          .
.       .       .   .     .     .               .         .          .
.
.
(60 families)

'Family' is the first Random effect (categorical variable), with 60 levels.

All columns labeled P1L(x) are a matrix of presence/absence genetic markers 
for each individual in each family. There are 426 such columns(not numbered 
in sequence) and each one is a random effect.

The last three columns (peg.no, ec.length and syll.length) are the three 
dependent variables.

Each genetic marker column needs to be nested within each family, which 
means that if I take the first phenotype, peg.no, for example, then I need 
to run an analysis that partitions variance 60*426 times (~25,00 runs) for 
that phenotype.
I also need an output with the Anova table, and summary, at each stage of 
the run, so that I can get P values for each marker for each family, as a 
way of determining whether it contributes significantly to explaining 
within-family variance for that trait.

To do the above, I tried to write code for lmer() using two nested 'for' 
loops, one for each level of random factor nesting (marker within family) 
as follows (using a test data set [please find attached] with only the 
first 10 marker columns, to see if this works):


> vc<-read.table("P:\\R\\Testvcomp10.txt",header=T)
> attach(vc)

> family<-factor(family)
> colms<-(vc)[,4:13] ## this to assign the 10 columns containing marker 
data    to a new variable, as column names are themselves not in any 
recognisable sequence

> vcdf<-data.frame(family,peg.no,ec.length,syll.length,colms)
> library(lme4)

> for (c in levels(family))
+ {    for (i in 1:length(colms))
+        { fit<-lmer(peg.no~1 + (1|c/i), vcdf)
+        }
+    summ<-summary(fit)
+    av<-anova(fit)
+    print(summ)
+    print(av)
+ }

This gives me:

Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
  variable lengths differ (found for 'c')



On suggestion from a colleague I reframed this as:


> for(c in levels(family))
+ {
+ print("----New C:----")
+ print(c)
+ for (i in 1:length(colms))
+ {
+ fit<-lmer(peg.no~1+ (1|c/i),vcdf)
+ print(i)
+ summ<-summary(fit)
+ av<-anova(fit)
+ print(summ)
+ print(av)
+ }
+ }

..and this gave me the output:

[1] "----New C:----"
[1] "1"
Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
  variable lengths differ (found for 'c')


Google-ing the error message has led me to plenty of links that suggest 
forcing data into a data frame to fix this, but that hasn't worked.
My markers and phenotypes both have plenty of missing data (NA's in the 
data.frame), and na.action=na.omit isn't solving the problem.

(I have tried this with lme, and tried to do it with the aov() command as 
well and the error is pretty much the same).

I am completely new to R, and despite searching and trying various things, 
can't get the code to work.

I really appreciate any corrections to this code, or alternative 
command/function suggestions that I can look into, to try to do this again.


Thanks a bunch for your help,

Aditi


----------------------
A Singh
Aditi.Singh at bristol.ac.uk
School of Biological Sciences
University of Bristol



-------------- next part --------------
male.parent	family	offspring.id	P1L55	P1L73	P1L74	P1L77	P1L91	P1L96	P1L98	P1L100	P1L114	P1L118	peg.no	ec.length	syll.length
1	1	3	0	0	1	0	0	0	1	1	1	0	86	5.445	2.479
1	1	4	0	0	1	0	0	0	1	1	1	0	91	5.215	2.356
1	1	5	0	1	0	0	0	0	1	1	1	0	79	5.682	2.896
1	1	6	0	0	1	0	0	0	1	1	1	0	83	5.149	2.641
1	1	7	0	0	0	0	0	0	1	1	1	0	77	5.044	2.288
1	1	8	0	0	1	0	0	0	1	1	1	0	78	5.450	2.420
1	1	9	0	0	1	0	1	1	1	1	0	0	82	5.377	2.505
1	1	10	0	0	1	0	0	0	1	1	1	0	95	5.389	2.706
1	1	11	0	0	1	0	0	0	1	1	1	0	88	5.354	2.461
1	1	12	0	0	1	0	0	0	1	1	1	1	87	5.262	3.079
1	1	13	0	0	1	0	0	0	1	1	1	0	77	5.219	2.106
1	1	14	0	0	1	0	0	0	1	1	1	0	74	5.464	2.677
1	1	15	0	0	1	0	0	0	1	1	1	0	85	5.230	2.929
1	1	16	0	1	1	0	0	0	1	1	1	0	107	5.609	2.752
1	1	17	0	0	1	0	0	0	1	1	1	0	76	5.306	2.785
1	1	18	0	0	1	0	0	0	1	1	1	0	86	5.306	2.374
1	1	19	0	0	1	0	0	0	1	1	1	0	84	5.191	2.858
1	1	20	0	0	1	0	0	1	1	1	1	0	87	5.194	2.264
21	2	23	0	1	1	0	0	1	1	1	1	0	116	5.863	2.876
21	2	24	0	0	1	0	0	0	1	1	1	0	122	5.475	3.114
21	2	25	0	1	1	0	0	0	1	1	1	0	110	5.563	3.059
21	2	26	1	0	1	0	0	0	1	0	0	0	120	5.723	2.755
21	2	27	0	0	0	0	0	0	0	1	1	0	NA	NA	NA
21	2	28	0	1	1	0	0	1	1	1	1	0	107	5.867	2.473
21	2	29	0	1	1	1	0	0	1	1	1	0	NA	5.956	2.436
21	2	30	0	0	1	0	0	0	1	1	1	0	103	5.601	2.544
21	2	31	1	0	1	0	0	1	1	1	1	0	92	5.768	2.978
21	2	32	0	0	1	0	0	0	1	1	1	0	127	5.710	2.461
21	2	33	0	0	1	0	0	0	1	1	1	0	115	5.697	2.528
21	2	34	0	0	1	1	0	0	1	1	1	0	105	5.743	2.813
21	2	35	0	0	1	0	1	0	1	1	1	1	103	5.745	2.609
21	2	36	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	106	5.901	2.884
21	2	37	0	0	1	1	0	0	1	1	1	0	108	5.639	2.292
21	2	38	0	1	1	0	0	0	1	1	1	0	105	5.588	2.839
21	2	39	0	0	1	0	0	1	1	1	1	0	112	5.543	2.172
21	2	40	0	1	1	0	0	0	1	1	1	0	NA	NA	NA
21	2	41	0	0	1	0	0	1	1	1	1	0	NA	NA	NA
42	3	44	0	0	1	0	0	0	1	0	1	0	107	6.026	2.778
42	3	45	0	0	1	0	0	0	1	1	1	0	91	5.962	2.708
42	3	46	1	0	1	0	0	0	1	1	1	0	82	5.756	2.614
42	3	47	0	0	1	0	0	0	1	1	1	0	92	5.828	2.571
42	3	48	0	0	1	1	0	1	1	1	1	0	80	5.423	2.314
42	3	49	1	0	1	0	0	0	1	1	1	0	82	5.183	2.173
42	3	50	1	0	1	1	0	0	1	1	1	0	90	5.609	2.211
42	3	51	1	0	1	0	0	0	1	1	1	0	92	5.556	2.615
42	3	52	0	0	1	0	0	0	0	0	1	0	99	5.507	2.184
42	3	53	0	0	1	0	0	1	1	1	1	0	NA	NA	NA
54	4	56	0	1	0	0	0	0	1	1	1	0	118	6.380	3.339
54	4	57	0	0	0	0	0	0	1	1	1	0	104	5.919	2.805
54	4	58	0	0	1	0	0	0	1	1	1	0	120	6.183	3.097
54	4	59	0	0	1	0	0	0	1	1	0	0	103	6.414	3.554
54	4	60	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
54	4	61	0	0	0	0	0	0	1	1	0	1	112	5.966	2.814
54	4	62	0	0	0	0	0	1	1	1	1	0	113	6.000	2.724
54	4	63	0	0	1	0	1	0	1	1	1	0	NA	NA	NA
54	4	64	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA
65	5	67	0	0	1	0	0	0	1	1	1	0	104	5.602	2.404
65	5	68	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	99	5.683	3.045
65	5	69	1	0	1	0	0	1	1	0	1	0	98	5.979	2.465
65	5	70	0	0	1	0	0	0	1	1	1	0	108	5.936	2.343
65	5	71	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	5.754	2.687
65	5	72	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
65	5	73	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA
74	6	76	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA
74	6	77	0	0	1	0	0	1	1	1	1	0	110	5.767	3.392
74	6	78	0	0	1	0	0	0	0	0	1	0	99	5.515	2.924
74	6	79	0	0	1	1	0	0	1	1	1	0	93	5.582	2.368
74	6	80	0	0	1	0	0	0	1	1	1	0	104	5.933	2.536
74	6	81	0	0	1	0	0	0	1	1	1	0	98	5.683	3.112
74	6	82	0	0	1	0	0	0	1	1	1	0	97	5.706	2.817
74	6	83	0	0	1	0	0	0	1	1	1	0	113	5.938	2.839
74	6	84	0	0	1	1	0	0	1	1	1	0	84	5.796	2.120
74	6	85	1	1	1	0	0	0	1	1	1	0	98	5.643	2.695
74	6	86	0	0	1	0	0	0	1	1	1	0	95	5.855	2.553
74	6	87	0	0	1	0	0	0	1	1	1	0	101	5.938	2.212
74	6	88	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
89	7	91	0	0	1	0	0	0	1	1	0	0	NA	5.596	2.597
89	7	92	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	79	5.288	2.187
89	7	93	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	93	5.448	2.717
89	7	94	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	77	5.612	2.619
89	7	95	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	89	5.586	2.560
89	7	96	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
89	7	97	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
89	7	98	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
89	7	99	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
89	7	100	0	0	1	0	0	0	1	1	0	0	NA	NA	NA
89	7	101	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA
102	8	104	1	0	1	0	0	0	1	1	1	0	113	6.352	3.074
102	8	105	0	0	1	0	0	0	1	1	1	0	117	5.894	2.505
102	8	106	1	0	0	0	0	0	1	1	1	0	103	6.118	2.651
102	8	107	1	0	1	0	0	0	1	1	1	0	134	6.336	2.669
102	8	108	0	0	1	0	0	0	1	1	1	0	112	6.212	2.412
102	8	109	1	0	1	0	0	0	1	1	1	0	130	6.095	2.744
102	8	110	1	0	1	0	0	0	1	1	1	0	112	6.410	2.874
102	8	111	0	0	1	0	0	0	1	1	1	0	102	5.788	2.578
102	8	112	0	0	1	0	0	0	1	1	1	0	115	5.996	2.490
102	8	113	0	0	1	0	0	0	1	1	1	0	124	5.977	2.860
102	8	114	0	0	0	0	0	0	1	1	1	0	108	5.863	2.704
102	8	115	0	0	1	0	0	0	1	1	1	0	116	6.102	2.515
102	8	116	0	0	1	0	0	0	1	1	1	0	105	5.811	2.506
102	8	117	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
118	9	120	0	0	1	1	1	0	1	1	0	0	111	5.728	2.193
118	9	121	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	114	5.438	2.449
118	9	122	0	0	1	0	0	0	1	1	1	0	94	5.142	2.540
118	9	123	0	0	1	0	0	1	1	1	1	0	101	5.590	2.644
118	9	124	0	0	1	0	0	0	0	1	1	0	94	5.788	2.647
118	9	125	0	0	1	0	0	0	1	1	1	0	110	5.740	2.940
118	9	126	0	0	1	0	0	0	1	1	1	0	106	5.280	2.833
118	9	127	0	0	0	0	0	0	1	1	1	0	124	5.646	2.797
118	9	128	0	0	1	0	0	0	0	0	0	0	99	5.595	2.502
118	9	129	0	0	1	0	0	0	1	0	0	0	98	5.762	2.664
118	9	130	0	0	1	0	0	0	1	1	1	0	NA	5.697	2.305
131	10	133	0	0	0	0	0	0	1	1	1	0	118	6.339	2.800
131	10	134	0	0	1	0	0	0	1	1	1	0	121	6.007	2.869
131	10	135	0	0	1	0	0	0	1	1	1	0	122	6.044	2.612
131	10	136	0	0	1	0	0	0	1	1	1	0	113	6.517	2.632
131	10	137	1	0	0	0	0	0	1	0	0	0	NA	5.962	2.919
131	10	138	1	0	1	0	0	0	1	1	1	0	116	6.084	2.723
131	10	139	0	0	0	0	0	1	0	1	1	1	117	6.095	2.793
131	10	140	0	0	0	0	0	0	1	1	1	0	114	6.445	2.831
131	10	141	0	0	0	0	0	0	1	1	1	0	115	6.232	2.480
131	10	142	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	109	5.956	2.742
131	10	143	0	0	1	0	0	0	1	1	1	0	123	5.839	2.583
131	10	144	0	0	1	0	0	0	1	1	1	1	112	6.016	2.770
131	10	145	0	0	0	0	0	0	1	1	1	0	110	5.895	2.421
131	10	146	0	0	1	0	0	0	1	1	1	0	98	6.019	2.971
131	10	147	0	0	0	0	0	0	1	1	1	0	103	6.505	2.749
131	10	148	0	0	0	0	0	0	1	1	1	0	100	5.969	2.724
149	11	151	0	0	1	0	0	0	1	1	1	0	NA	5.727	2.978
149	11	152	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
153	12	155	0	0	1	0	0	0	1	1	1	0	91	6.049	3.183
153	12	156	0	0	1	0	0	0	1	1	1	0	95	6.094	2.948
153	12	157	0	0	1	0	0	0	1	1	1	0	109	5.916	3.146
153	12	158	0	0	1	0	0	0	1	1	1	1	94	6.021	3.017
153	12	159	0	0	1	0	0	0	1	1	1	0	115	5.849	3.164
153	12	160	0	0	1	0	0	0	1	1	1	1	94	5.833	2.737
153	12	161	0	0	1	0	0	0	1	1	1	0	85	5.924	2.915
153	12	162	0	0	1	0	0	0	1	1	1	1	94	5.624	2.614
153	12	163	0	1	1	0	0	0	1	1	1	1	87	6.181	3.213
153	12	164	0	0	1	0	0	0	1	1	1	1	100	5.690	2.680
153	12	165	0	0	1	0	0	0	1	1	1	1	115	5.832	3.350
153	12	166	0	0	0	0	0	0	1	1	0	1	102	6.075	2.682
153	12	167	0	0	1	0	0	0	1	1	1	0	120	5.869	2.970
153	12	168	0	0	0	0	0	0	1	1	1	0	NA	NA	NA
169	13	171	1	0	1	1	0	0	1	1	1	0	87	5.590	3.360
169	13	172	0	0	1	0	0	0	1	1	1	0	80	5.673	2.606
169	13	173	0	0	1	0	0	0	0	0	1	0	91	5.875	2.452
169	13	174	0	0	0	0	0	0	1	1	0	0	79	5.622	2.566
169	13	175	0	0	1	0	0	1	1	1	1	0	82	5.960	3.270
169	14	177	1	0	1	0	0	0	1	1	1	0	83	5.640	2.411
169	14	178	0	0	1	0	0	0	1	1	1	0	84	5.668	3.251
169	14	179	1	0	1	0	0	0	1	1	1	0	79	5.704	3.227
169	14	180	0	0	1	0	0	0	1	0	1	0	103	6.024	2.972
169	14	181	0	0	1	0	0	0	1	1	1	0	76	5.756	2.742
169	14	182	1	0	1	0	0	0	0	1	1	0	85	6.049	2.998
169	14	183	0	0	1	0	0	0	1	1	1	0	74	5.880	3.246
169	14	184	0	0	1	0	0	0	1	1	1	0	102	5.978	2.655
169	14	185	1	0	1	0	0	0	1	1	1	0	83	5.532	2.716
169	14	186	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	75	5.619	2.358
169	14	187	1	0	1	0	0	0	1	1	1	0	NA	NA	NA
169	15	189	0	0	1	0	0	0	1	1	1	0	74	5.697	3.234
169	15	190	1	1	1	1	0	0	1	1	1	0	78	5.710	2.277
169	15	191	1	0	1	0	0	0	1	0	1	0	100	6.318	3.650
169	15	192	0	0	1	0	0	0	1	1	1	0	87	5.969	2.988
169	15	193	0	0	1	1	0	1	1	0	1	0	96	6.020	2.791
169	15	194	0	0	1	0	0	0	1	1	1	1	90	5.950	2.619
169	15	195	1	0	1	0	0	0	1	1	1	0	83	6.299	3.515
169	15	196	1	0	0	0	0	0	1	1	1	0	80	5.410	2.354
169	15	197	1	0	1	0	0	0	1	1	1	0	90	5.717	3.085
169	15	198	1	0	1	0	0	0	1	1	1	0	90	5.762	3.013
169	15	199	0	0	0	0	0	0	1	0	0	0	87	5.685	2.858
169	15	200	0	0	1	0	0	0	1	1	1	0	86	5.641	2.565
169	15	201	0	0	1	0	0	0	1	1	1	0	80	5.950	2.423
169	15	202	0	0	1	0	0	0	1	1	1	0	NA	5.775	2.670
169	15	203	1	1	0	0	0	1	1	1	1	0	75	5.859	2.837
169	15	204	0	0	1	0	0	0	1	1	1	1	NA	NA	NA
169	15	205	1	0	1	0	0	0	1	1	1	0	NA	NA	NA
169	15	206	0	0	1	0	0	0	1	1	1	1	NA	NA	NA
207	16	209	1	0	0	0	1	0	1	1	1	0	111	5.798	2.518
207	16	210	0	0	1	0	0	0	1	1	1	0	117	6.021	2.657
207	16	211	0	0	0	0	0	0	1	0	0	0	109	5.871	2.771
212	17	214	0	1	1	0	0	0	1	1	1	0	125	5.934	3.060
212	17	215	0	0	1	1	0	0	1	1	1	0	122	5.825	3.232
212	17	216	0	1	1	1	0	0	1	1	1	0	107	6.003	2.974
212	17	217	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	118	5.562	3.475
212	17	218	0	1	1	1	0	0	1	1	1	0	119	5.946	2.923
212	17	219	0	0	1	0	0	0	1	1	0	0	120	5.320	2.828
212	17	220	0	0	1	0	0	0	1	1	1	0	110	5.706	2.578
212	17	221	0	0	1	0	0	0	1	1	1	0	100	5.547	2.652
212	17	222	0	0	0	0	0	1	1	0	0	0	106	5.515	2.708
212	17	223	0	0	1	1	0	0	1	1	1	0	105	5.555	2.862
212	17	224	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
212	17	225	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
226	18	228	0	1	1	0	0	0	1	1	0	1	89	6.044	3.091
226	18	229	0	0	1	0	0	0	1	1	1	1	86	5.720	2.700
226	18	230	1	0	1	0	0	0	1	1	1	0	101	5.912	3.142
226	18	231	0	0	1	0	0	0	1	1	1	0	100	5.910	3.224
226	18	232	1	0	1	0	0	0	1	0	1	0	90	5.822	2.543
226	18	233	1	0	1	0	0	0	1	1	1	0	108	5.814	2.668
226	18	234	0	1	1	0	0	0	0	0	1	0	99	6.067	3.154
226	18	235	0	0	1	0	0	0	1	0	0	0	103	5.850	3.239
226	18	236	0	0	1	0	0	0	1	1	1	0	84	6.112	3.067
226	18	237	0	0	1	0	0	0	1	1	1	0	86	5.628	2.598
226	18	238	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
239	19	241	1	0	1	0	0	0	0	0	0	1	81	5.721	2.649
239	19	242	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	93	5.847	2.240
239	19	243	0	0	1	0	0	0	0	1	1	0	84	5.974	3.258
239	19	244	0	0	1	0	0	0	1	1	1	0	77	5.842	3.101
239	19	245	0	0	1	0	0	0	1	1	1	0	88	5.837	2.612
239	19	246	0	0	1	0	0	1	1	1	1	0	78	5.932	2.364
239	19	247	0	0	1	0	0	1	1	1	1	1	88	5.845	3.039
239	19	248	0	0	1	0	0	1	1	1	1	0	75	5.526	2.648
249	20	251	0	0	1	0	0	0	1	1	1	0	88	5.961	2.602
249	20	252	0	0	1	0	0	0	1	1	1	0	97	6.018	2.600
249	20	253	0	0	1	0	0	0	1	1	1	0	94	5.686	3.035
249	20	254	0	0	1	0	0	0	1	1	1	0	100	6.179	2.697
249	20	255	0	1	1	1	0	0	1	1	1	0	97	5.873	2.478
249	20	256	0	0	1	0	0	1	1	1	1	0	99	5.702	2.578
249	20	257	0	0	1	0	0	0	1	1	1	0	104	6.001	2.697
249	20	258	0	0	1	0	0	0	1	1	1	0	96	5.627	2.959
249	20	259	0	0	0	0	0	0	1	1	0	0	98	5.920	2.820
249	20	260	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
249	20	261	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
262	21	264	0	0	1	0	0	0	0	1	1	0	95	5.719	2.757
262	21	265	0	0	1	0	1	0	1	1	1	0	104	5.540	3.159
262	21	266	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	115	5.858	2.812
262	21	267	0	0	1	0	0	0	1	1	1	0	89	6.034	2.915
262	21	268	0	0	1	0	0	0	1	1	1	0	116	5.984	3.408
262	21	269	0	0	1	0	0	0	0	0	1	0	100	5.886	3.085
262	21	270	0	1	1	0	0	0	1	1	1	0	85	5.615	2.613
262	21	271	0	0	1	0	0	0	1	1	1	0	120	6.127	2.747
262	21	272	0	0	1	0	0	0	1	1	1	0	112	5.469	2.809
262	21	273	0	0	1	0	0	0	1	1	1	0	107	5.599	2.459
262	21	274	0	0	1	0	0	0	1	1	1	0	88	5.686	2.589
262	21	275	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
276	22	278	0	0	1	0	0	0	1	1	1	0	75	5.852	2.881
276	22	279	0	0	1	0	0	0	1	1	1	0	79	5.544	2.632
276	22	280	0	0	1	0	0	0	1	1	1	0	89	5.530	2.594
276	22	281	0	0	0	0	1	0	0	0	1	0	82	5.572	2.604
276	22	282	0	0	0	0	0	1	1	1	0	0	87	5.948	2.719
276	22	283	0	0	0	0	0	0	1	1	1	0	73	5.398	2.932
276	22	284	0	0	0	0	0	0	1	1	1	0	86	6.062	2.795
276	22	285	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	87	6.389	3.069
276	22	286	0	0	1	0	0	0	1	1	1	0	74	5.529	2.667
276	22	287	0	0	1	0	0	0	1	1	1	1	NA	5.715	2.322
276	22	288	0	0	0	0	0	0	1	1	1	0	88	5.718	2.628
276	22	289	0	0	1	0	0	1	1	1	1	0	83	5.641	2.704
276	22	290	0	0	0	0	0	0	1	1	1	0	72	5.359	2.327
276	22	291	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
276	23	293	0	0	0	0	0	0	1	1	0	0	80	5.658	2.574
276	23	294	0	0	0	0	0	0	1	1	1	0	89	5.770	2.875
276	23	295	0	0	0	0	0	0	1	1	0	0	96	5.743	2.734
276	23	296	0	0	1	0	0	0	1	1	0	0	96	5.902	2.617
276	23	297	0	0	0	0	0	0	1	1	1	0	100	5.942	3.248
298	24	300	0	0	0	0	0	0	0	1	1	0	84	5.935	3.061
298	24	301	0	0	0	0	0	0	1	1	1	0	109	5.567	3.084
298	24	302	1	0	1	0	0	0	1	1	1	0	88	6.133	2.965
298	24	303	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	105	5.539	2.799
298	24	304	1	0	1	0	0	1	1	1	1	0	94	5.585	2.546
298	24	305	0	0	1	0	0	0	1	1	1	0	100	5.794	2.828
298	24	306	0	0	1	0	0	0	1	1	1	0	99	5.678	2.703
298	24	307	0	0	1	0	0	1	1	1	1	0	103	5.547	2.333
298	24	308	1	0	1	0	0	1	1	1	1	0	90	5.240	2.752
298	24	309	0	0	1	0	0	1	0	0	1	0	83	5.703	2.732
298	24	310	0	0	1	0	0	1	1	1	1	0	86	5.863	2.404
298	24	311	0	0	1	0	0	0	1	1	1	0	103	5.735	2.628
298	24	312	0	0	0	0	0	0	1	1	1	0	99	5.474	2.695
298	24	313	0	0	1	0	0	0	1	1	1	0	83	5.661	2.858
298	24	314	0	0	1	0	0	0	1	1	1	0	96	5.799	3.250
298	24	315	0	1	0	0	0	1	0	0	0	0	89	5.674	2.264
298	24	316	1	0	1	0	0	0	1	1	1	0	101	5.884	2.819
298	24	317	0	0	1	0	0	0	1	1	1	0	95	5.408	2.459
298	24	318	0	0	1	0	0	1	0	1	0	0	85	5.523	2.371
298	24	319	0	0	1	0	0	1	1	1	1	0	93	5.625	2.709
298	24	320	0	0	1	0	0	1	1	1	1	0	89	5.791	2.578
298	24	321	0	0	1	0	0	1	1	1	1	0	86	5.730	2.410
298	24	322	0	0	1	0	0	0	1	1	1	0	93	5.520	2.184
298	24	323	1	0	1	0	0	1	1	1	1	0	90	5.402	2.246
298	24	324	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	5.930	3.012
298	24	325	0	0	1	0	0	1	1	1	1	0	100	5.405	2.463
298	24	326	0	0	1	0	0	1	1	1	1	0	81	5.501	2.353
298	24	327	0	0	1	0	0	0	1	1	1	0	94	5.452	2.576
328	25	330	0	0	1	0	0	0	1	1	1	0	107	5.895	2.539
328	25	331	0	0	1	0	0	1	1	0	1	0	107	5.962	3.701
328	25	332	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	92	6.074	2.427
328	25	333	0	0	1	0	0	0	1	1	1	0	85	5.398	2.664
328	25	334	0	0	1	0	0	0	1	0	1	0	94	6.103	2.333
328	25	335	0	0	1	0	0	0	1	1	1	0	100	5.962	2.487
328	25	336	1	0	1	0	0	0	1	1	1	0	116	5.974	2.438
328	25	337	0	0	1	0	0	0	1	1	1	0	92	5.892	2.333
328	25	338	0	0	1	0	0	0	1	0	1	0	113	5.998	2.742
328	25	339	1	0	1	0	0	0	1	1	1	0	104	5.849	2.620
328	25	340	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
341	26	343	0	0	1	0	0	0	0	1	1	0	NA	5.731	2.670
29	27	344	0	1	1	0	1	0	1	1	1	0	103	5.931	2.598
29	27	345	0	0	1	0	0	0	1	1	1	0	94	NA	NA
29	27	346	0	0	1	0	0	0	1	1	1	0	110	NA	NA
57	28	347	0	0	1	0	0	0	1	1	1	0	115	5.933	2.800
57	28	348	0	1	0	0	0	0	0	1	1	0	105	5.663	2.584
57	28	349	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	131	6.238	2.344
57	28	350	0	0	1	0	0	0	1	1	1	0	111	5.762	2.902
57	28	351	0	0	1	0	0	0	1	1	1	0	119	5.744	2.533
57	28	352	0	0	1	0	0	1	1	1	1	0	89	NA	NA
60	29	353	0	0	1	0	0	1	1	1	1	0	106	5.539	2.764
60	29	354	0	0	1	0	0	0	1	1	1	0	122	5.896	2.811
60	29	355	0	0	1	0	0	1	1	1	1	0	112	5.728	2.795
60	29	356	0	0	0	0	0	0	1	0	0	1	93	5.476	2.060
60	29	357	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	119	5.690	2.462
60	29	358	0	0	0	0	0	1	1	1	1	0	97	NA	NA
91	30	359	0	0	1	0	0	0	1	1	1	0	85	5.609	2.183
91	30	360	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	92	5.775	2.296
91	30	361	1	0	0	0	0	0	1	1	0	0	84	5.700	2.127
91	30	362	0	1	1	0	0	0	1	0	1	0	85	NA	NA
91	30	363	0	0	1	0	0	0	1	1	1	0	75	5.634	2.189
91	30	364	0	0	1	0	0	0	1	1	1	0	74	5.533	2.298
91	30	365	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
76	31	366	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	92	6.169	2.336
76	31	367	0	1	0	0	0	0	1	1	1	0	91	5.992	2.289
76	31	368	NA	NA	NA	NA	NA	NA	NA	NA	NA	NA	105	6.431	2.455
76	31	369	0	0	1	0	0	0	1	0	1	0	105	5.834	2.402
76	31	370	0	0	1	0	0	0	1	1	1	0	108	6.341	2.440
76	31	371	0	0	1	0	1	1	1	0	1	0	110	6.448	2.687
76	31	372	0	1	0	0	0	0	1	1	1	0	NA	NA	NA
37	32	373	0	0	1	0	0	0	1	1	1	0	96	5.435	2.267
37	32	374	0	0	1	0	0	0	1	1	1	0	93	5.365	2.179
37	32	375	0	0	1	0	0	0	1	1	1	0	97	5.577	2.381
37	32	376	0	0	1	0	0	0	1	1	0	0	97	5.685	2.232
37	32	377	0	0	1	0	0	0	1	1	0	0	109	5.682	2.802
37	32	378	0	0	1	0	0	0	1	1	0	0	96	NA	NA
37	32	379	0	0	1	0	0	0	1	1	1	0	118	NA	NA
37	32	380	0	0	1	0	0	0	1	1	1	0	90	NA	NA
38	33	381	0	0	1	0	0	0	1	1	1	0	94	5.262	2.855
38	33	382	0	0	1	0	0	0	1	1	1	0	103	5.949	2.338
38	33	383	0	0	1	0	0	0	1	1	1	0	89	NA	NA
38	33	384	0	0	1	0	0	0	1	1	1	0	120	NA	NA
38	33	385	0	0	1	0	0	0	1	1	1	0	111	5.591	2.572
38	33	386	0	0	1	0	1	0	1	1	1	0	84	5.569	2.257
38	33	387	0	0	1	0	0	0	1	1	1	0	86	5.248	2.175
38	33	388	0	0	1	0	0	0	1	1	1	0	87	NA	NA
35	34	389	0	0	1	0	0	0	1	1	1	0	78	5.465	2.095
35	34	390	0	1	1	0	0	0	1	1	1	0	73	5.499	2.043
35	34	391	0	0	1	1	0	0	1	1	1	0	87	5.740	2.268
35	34	392	0	0	1	1	0	0	1	1	1	0	79	5.948	2.360
35	34	393	0	0	1	0	0	0	1	1	1	0	101	5.549	2.478
35	34	394	0	0	0	0	0	0	1	1	1	0	86	5.713	2.889
35	34	395	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
71	35	396	0	0	1	0	0	0	1	1	1	0	98	6.062	2.840
71	35	397	0	0	1	0	0	1	1	1	1	0	89	5.774	2.374
71	35	398	0	0	1	0	0	1	1	1	1	0	101	NA	NA
71	35	399	0	0	0	0	0	0	1	1	1	0	96	6.260	3.063
71	35	400	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
71	35	401	0	0	1	0	0	0	1	1	0	0	NA	NA	NA
19	36	402	0	0	0	1	0	0	1	1	0	1	73	5.134	2.147
19	36	403	0	0	1	0	0	0	1	0	1	0	85	5.170	2.148
77	37	404	0	0	1	0	0	1	1	1	1	0	87	5.965	2.463
77	37	405	1	0	1	0	0	0	1	1	1	0	84	5.383	2.257
77	37	406	0	0	1	0	0	0	1	1	1	0	74	5.314	2.860
147	38	407	0	0	1	0	0	1	1	1	1	0	96	6.187	2.467
147	38	408	0	1	1	0	0	0	1	1	1	0	82	5.773	2.828
147	38	409	0	0	1	0	0	0	1	1	1	0	81	5.731	2.661
147	38	410	0	0	1	0	0	0	1	1	1	0	94	5.684	2.731
147	38	411	0	0	1	0	0	0	1	1	1	0	73	5.829	2.568
147	38	412	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
147	38	413	0	0	1	0	0	0	1	1	1	0	NA	NA	NA
147	38	414	1	0	1	0	0	0	1	1	1	0	NA	NA	NA
147	38	415	0	0	1	0	0	0	1	0	0	0	NA	NA	NA
130	39	416	0	0	1	0	0	0	1	1	1	0	90	6.066	2.436
152	40	417	1	0	1	0	0	1	1	1	1	0	71	5.819	2.533
152	40	418	1	0	1	0	0	0	1	1	1	0	78	5.373	2.177
152	40	419	0	0	1	0	0	0	1	1	1	0	115	5.724	2.513
152	40	420	0	0	1	0	0	0	1	1	1	0	97	5.703	2.317
152	40	421	1	0	1	0	0	0	1	1	1	0	NA	NA	NA
267	41	422	0	0	1	1	0	0	1	1	1	0	104	5.734	2.539
267	41	423	0	0	1	0	0	0	1	1	1	1	98	5.855	2.400
184	42	424	0	0	0	0	0	0	1	0	0	0	79	5.958	2.727
184	42	425	0	0	1	0	0	1	1	1	1	0	88	5.789	2.971
184	42	426	1	0	1	0	0	0	1	1	1	0	95	5.840	2.613
184	42	427	0	0	1	0	0	0	1	1	1	0	98	5.971	2.673
184	42	428	0	0	0	0	0	0	1	1	1	0	99	5.715	2.479
184	42	429	0	0	1	0	0	0	1	1	1	0	94	5.738	2.695
184	42	430	0	0	1	0	0	0	1	1	1	0	102	5.919	2.613
195	43	431	1	0	0	0	0	1	1	0	0	0	102	5.592	2.734
236	44	432	1	0	1	0	0	0	1	1	1	0	94	6.156	2.389
324	45	433	0	0	1	0	0	0	1	1	1	0	100	5.835	2.624
324	45	434	0	1	1	0	0	0	1	1	1	0	84	5.712	2.329
324	45	435	1	0	0	0	0	0	1	1	1	0	106	5.646	2.229
324	45	436	1	0	1	0	0	0	1	1	1	0	78	5.770	2.502
324	45	437	1	0	1	0	0	0	1	1	1	0	97	5.591	2.203
324	45	438	1	0	1	0	0	0	1	1	1	0	110	5.764	2.121
324	45	439	0	0	1	0	0	0	1	1	1	0	100	5.568	3.039
324	45	440	0	0	1	0	0	0	1	1	1	0	96	5.565	2.157
164	46	441	0	0	1	0	0	0	1	0	1	1	101	5.687	2.664
164	46	442	0	0	1	0	0	0	1	1	1	1	100	5.692	2.741
280	47	443	0	0	1	0	0	0	1	1	1	0	89	5.537	3.162
280	47	444	0	0	1	0	0	0	1	1	1	1	88	5.668	2.841
280	47	445	0	0	1	0	0	0	1	1	1	0	69	5.556	2.915
280	47	446	0	0	0	0	0	0	1	1	1	0	86	5.662	3.254
320	48	447	0	0	1	0	0	1	1	1	1	0	97	5.821	2.565
320	48	448	0	0	1	0	0	0	1	1	1	0	102	5.986	2.491
320	48	449	0	0	1	0	0	0	1	1	1	0	98	5.525	2.591
320	48	450	0	0	1	0	0	1	1	1	1	0	100	5.815	2.353
320	48	451	1	0	1	0	0	1	1	1	1	0	94	6.013	2.380
320	48	452	0	0	0	0	0	0	1	1	1	0	96	5.864	2.212
165	49	453	1	0	1	0	0	0	1	1	1	1	78	5.890	2.443
165	49	454	0	0	0	0	0	0	1	1	1	1	102	5.963	2.368
331	50	455	0	0	1	0	0	1	1	1	1	0	125	6.137	2.692
331	50	456	0	0	0	0	0	0	1	0	1	1	105	5.676	2.536
331	50	457	0	0	1	0	0	0	1	1	1	0	113	6.201	2.471
331	50	458	0	0	1	0	0	1	1	1	1	0	110	5.986	2.614
331	50	459	1	0	0	0	1	1	1	1	0	0	103	5.946	2.605
241	51	460	0	0	1	0	0	0	1	1	1	0	75	6.132	2.553
241	51	461	1	0	1	0	0	0	1	1	1	0	79	5.852	2.462
343	52	462	0	0	1	0	0	1	1	1	1	0	87	5.886	2.795
343	52	463	0	0	1	0	0	0	1	1	1	0	102	6.156	2.595
343	52	464	0	0	1	0	0	1	1	1	1	0	120	5.226	2.394
343	52	465	0	0	1	0	0	1	1	1	0	0	128	5.364	2.821
343	52	466	0	0	1	0	0	0	1	1	1	0	102	5.496	2.621
343	52	467	0	0	1	0	0	1	1	1	0	0	115	5.414	2.570
389	53	468	0	0	1	0	0	0	1	1	1	0	103	6.177	2.511
389	53	469	0	0	1	0	0	0	1	1	1	0	105	5.626	2.310
377	54	470	0	0	1	0	0	0	1	1	1	0	81	5.851	2.149
377	54	471	1	0	1	0	0	0	1	1	1	0	80	5.403	2.676
463	55	472	0	0	0	0	0	1	1	1	1	0	120	5.906	2.433
463	55	473	0	1	0	0	0	0	1	1	0	0	75	5.944	2.433
463	55	474	0	0	1	0	0	0	1	1	1	0	110	6.075	2.629
463	55	475	0	1	1	0	0	1	1	1	1	0	78	5.650	2.165
463	55	476	0	0	1	0	0	1	1	1	1	0	75	5.274	2.242
463	55	477	1	0	1	0	0	0	1	1	1	0	82	5.814	2.227
463	55	478	0	1	1	0	0	0	1	1	1	0	121	5.873	2.305
463	55	479	0	0	1	0	0	1	1	1	1	0	115	5.647	2.740
463	55	480	0	0	0	0	0	0	1	1	1	0	116	5.723	2.492
463	55	481	0	0	1	0	0	0	1	1	1	0	104	5.776	2.307
463	55	482	0	0	1	0	0	1	1	1	1	0	112	5.923	2.459
463	55	483	0	0	1	0	0	1	1	1	1	0	121	5.809	2.481
375	56	484	0	0	1	0	0	0	1	1	1	0	102	5.456	2.260
375	56	485	0	0	1	0	0	0	1	1	1	0	112	5.613	2.338
462	57	486	0	0	1	0	0	0	1	1	1	0	92	5.728	2.958
462	57	487	0	0	1	0	0	0	1	1	1	0	99	5.881	2.471
462	57	488	0	0	1	0	0	0	1	1	1	0	93	5.869	2.062
462	57	489	0	0	1	0	0	0	1	1	1	0	110	NA	NA
408	58	490	0	1	1	0	0	0	1	1	1	0	107	5.644	2.681
408	58	491	0	0	1	1	0	0	1	1	1	0	74	5.826	2.594
408	58	492	0	0	1	1	0	0	1	1	1	0	110	5.901	2.642
408	58	493	0	0	1	0	0	0	1	1	1	0	95	5.999	2.512
408	58	494	0	0	1	1	0	0	1	1	1	0	92	5.396	2.269
392	59	495	0	1	1	0	0	0	1	1	1	0	93	6.029	2.284
392	59	496	0	0	1	0	0	0	1	1	1	0	87	5.591	2.202
392	59	497	0	0	0	0	0	0	1	1	0	0	84	5.777	2.200
392	59	498	0	0	1	0	0	0	1	1	1	0	80	6.262	2.095
392	59	499	0	0	1	1	0	0	1	1	1	0	86	5.966	2.079
392	59	500	0	0	1	0	0	0	1	1	1	0	NA	6.083	2.597
392	59	501	0	0	1	0	0	0	1	1	1	0	88	5.528	2.582
392	59	502	0	0	1	0	0	0	1	1	1	0	92	5.703	2.277
392	59	503	0	0	1	0	0	0	0	0	1	0	101	6.116	2.369
376	60	504	0	0	1	0	0	0	1	1	0	0	109	5.724	2.859
376	60	505	0	1	1	0	0	0	1	1	1	0	84	5.555	2.244
376	60	506	0	0	1	0	0	0	1	1	0	0	100	5.457	2.192
376	60	507	0	0	1	0	0	0	1	1	0	0	117	5.603	2.586
376	60	508	0	0	1	0	0	0	1	1	1	0	116	5.917	2.364
376	60	509	0	0	1	0	0	0	1	1	1	0	112	6.040	2.328
376	60	510	0	0	1	0	0	1	1	1	1	0	92	5.608	2.443
376	60	511	0	0	1	0	0	0	1	1	0	0	102	5.628	2.208
376	60	512	0	0	1	0	0	0	1	1	0	0	116	5.690	2.249

From bendantzer at gmail.com  Thu Jul  9 19:42:04 2009
From: bendantzer at gmail.com (Benjamin Dantzer)
Date: Thu, 9 Jul 2009 13:42:04 -0400
Subject: [R-sig-ME] Prudent steps for overdispersion in glmer models (logit
	link)
Message-ID: <0649F5C9-02AF-4D32-B8E1-C05F8FBFDAD0@gmail.com>

Dear Mixed Modelers,

I encounter much overdispersion (dispersion parameters >13) when  
analyzing unbalanced proportion data and I'm trying to understand what  
are prudent steps for ecologists to follow when performing GLMMs  
(logit link) with overdispersion using lme4. I recognize other sources  
of information about this topic and have read widely, but much of my  
uncertainty comes from the current issue with lme4 and quasilikelihood  
(quasibinomial in my case) that is discussed elsewhere (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001404.html 
) and (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q4/001632.html 
)

I use the following behavioral data as an example. These behavioral  
data are from 7 min focals where specific behaviors are recorded at 30  
s intervals. In addition to multivariate approaches, I try to  
determine how the proportions of specific behaviors vary across a  
season or breeding attempts using GLMMs.
	In the example below, I'm interested in how the proportion of time a  
squirrel spends eating changes seasonally. A quadratic effect is  
included for non-linearities. I first do an entirely fixed effects GLM  
to look for overdispersion and then a GLMM with random effects for  
both animal and observer (because repeated measures on animals and by  
observers).


Mac OS X, R version 2.9.0, lme4 version 0.999375-31

GLM Example to assess overdispersion:

Call:
glm (formula = cbind (No.Nest, 15 - No.Nest) ~ poly (Day, 2),  family  
= binomial (link=logit), data = focals)

Deviance Residuals:
    Min      1Q  Median      3Q     Max
-5.326  -2.910  -2.664   3.189   6.967

Coefficients:
                  	  Estimate 	Std. Error z value Pr(>|z|)
(Intercept)        -1.08320    0.02004 -54.042   <2e-16 ***
poly(Day, 2)1 -8.36175    0.59299 -14.101   <2e-16 ***
poly(Day, 2)2  4.92777    0.58027   8.492   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 14476  on 902  degrees of freedom
Residual deviance: 14179  on 900  degrees of freedom
AIC: 14362

Number of Fisher Scoring iterations: 5




GLMER Example:

Because there are repeated samples on the same animals and potentially  
observer effects, I include random effects for both animal and observer.


glmer (cbind (No.Nest, 15-No.Nest) ~ poly (Day,2) + (1|OBS) + (1|ID),  
family=binomial (link = logit), focals, verbose=TRUE)

   0:     12075.576: 0.607569 0.343693 -1.08320 -8.36175  4.92777
   1:     11752.951:  1.49913 0.795727 -1.10953 -8.37088  4.92682
   2:     11744.740:  1.47953  1.04743 -1.38218 -8.54319  4.89649
   3:     11726.917:  1.88345  1.10659 -1.40701 -8.58032  4.89063
   4:     11721.286:  2.01823  1.03093 -1.87186 -9.31820  4.75224
   5:     11718.158:  2.41774  1.44964 -1.63616 -9.95216  4.64645
   6:     11713.721:  2.26994  1.26734 -1.55596 -10.8047  4.52269
   7:     11712.202:  2.22602  1.19583 -1.59063 -11.6781  4.70304
   8:     11712.095:  2.20938  1.18793 -1.66349 -12.1621  4.17028
   9:     11711.920:  2.20456  1.20150 -1.70144 -12.1439  4.55884
  10:     11711.912:  2.20558  1.20779 -1.68434 -12.0797  4.51719
  11:     11711.912:  2.20180  1.20734 -1.68745 -12.0847  4.51349
  12:     11711.912:  2.20177  1.20903 -1.68700 -12.0926  4.51477
  13:     11711.912:  2.20155  1.20892 -1.68680 -12.0894  4.51528
  14:     11711.912:  2.20153  1.20893 -1.68678 -12.0893  4.51523

Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(No.Nest, 15 - No.Nest) ~ poly(Day, 2) + (1 | OBS)  
+      (1 | ID)
    Data: focals.all.repro
    AIC   BIC logLik deviance
  11722 11746  -5856    11712
Random effects:
  Groups Name        Variance Std.Dev.
  ID         (Intercept) 4.8467   2.2015
  OBS    (Intercept) 1.4615   1.2089
Number of obs: 903, groups: ID, 125; OBS, 40

Fixed effects:
                    		Estimate 	Std. Error 	z value 	  Pr(>|z|)
(Intercept)         	     -1.6868     0.3776  -	4.467 	  7.95e-06 ***
poly(Day , 2)1 	    -12.0893    1.0519 		-11.492    < 2e-16 ***
poly(Day, 2)2  	      4.5139     0.8527     	5.294 	  1.20e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) p(RD,2)1
ply(RpD,2)1  0.000
ply(RpD,2)2 -0.013 -0.027



Because of the current issue with quasi- and lme4 (see links above),  
am I basically restricted to either 1) dropping random effects and  
using quasibinomial with GLM, or 2) acknowledging the presence of  
overdispersion but arguing that much of this is due to heterogeneity  
across individuals and observers? In other examples I frequently get  
std. devs. of random effects nearly as large as the estimates of the  
fixed effects (as in the example in Bolker et al., 2008)? There are no  
high leverage outlying observations for the fixed or random effects  
and including additional covariates doesn't significantly decrease  
dispersion parameter.

Looking forward to your opinions.


-Ben Dantzer

__________________________________
Ben Dantzer
PhD Candidate

Ecology, Evolutionary Biology, and Behavior Program
Department of Zoology
203 Natural Science Building
Michigan State University
East Lansing, MI 48824-115

Phone: 	517-432-5555
Fax:	 	517-432-2789
Web:	http://www.msu.edu/~dantzer
		http://www.redsquirrel.msu.edu



From Aditi.Singh at bristol.ac.uk  Thu Jul  9 20:09:16 2009
From: Aditi.Singh at bristol.ac.uk (A Singh)
Date: Thu, 09 Jul 2009 19:09:16 +0100
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
Message-ID: <66072001BD3C6CB84D8672C6@bio-bridlepost1.bio.bris.ac.uk>


Dear All,

Faux pas..
I'm sorry about the attachment. Did not know a .txt attachment would do 
that.

I am posting the link to the original files, available for downloading.

<http://www.filesanywhere.com/fs/v.aspx?v=896d6b88616173be71ab> (excel- 
.xlsx)

<http://www.filesanywhere.com/fs/v.aspx?v=896d6b88616174a76e9e>
(.txt file)

Thanks again,

Aditi
----------------------
A Singh
Aditi.Singh at bristol.ac.uk
School of Biological Sciences
University of Bristol



From jerome.goudet at unil.ch  Thu Jul  9 21:21:57 2009
From: jerome.goudet at unil.ch (Jerome Goudet)
Date: Thu, 09 Jul 2009 21:21:57 +0200
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
In-Reply-To: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>
References: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>
Message-ID: <4A564355.6000801@unil.ch>

Dear Aditi,

I'm puzzled with the nesting of loci within families (the presence of an 
allele at a locus means the same whatever the family, I would think). I 
would treat loci as fixed effect and hence use something like that:

 (fm1<-lmer(peg.no~P1L55+P1L73+P1L74+P1L77+P1L91+P1L96+P1L98+P1L100+P1L114+P1L118+(1|family),dat))
Linear mixed model fit by REML
Formula: peg.no ~ P1L55 + P1L73 + P1L74 + P1L77 + P1L91 + P1L96 + P1L98 
+      P1L100 + P1L114 + P1L118 + (1 | family)
   Data: dat
  AIC  BIC logLik deviance REMLdev
 2954 3006  -1464     2963    2928
Random effects:
 Groups   Name        Variance Std.Dev.
 family   (Intercept) 89.043   9.4363 
 Residual             91.377   9.5592 
Number of obs: 390, groups: family, 57

Fixed effects:
            Estimate Std. Error t value
(Intercept)  96.2793     3.2169  29.929
P1L55        -2.0185     1.5831  -1.275
P1L73        -3.0256     1.8900  -1.601
P1L74         1.5112     1.6189   0.933
P1L77        -2.7898     2.3529  -1.186
P1L91         0.6480     3.3118   0.196
P1L96        -1.4718     1.4938  -0.985
P1L98         2.6431     2.6401   1.001
P1L100       -3.4529     2.0842  -1.657
P1L114        0.8099     1.9218   0.421
P1L118       -2.7119     2.3635  -1.147


But perhaps I missed something?

Best wishes,

A Singh wrote:
> Dear All,
>
> I am trying to run a nested random effects model in lmer (for R 2.9.1, 
> lme4 version 0.999375-31 ) using data which is structured as follows:
>
> family offsp. P1L74 P1L77 P1L91 P1L96..(n=426) peg.no ec.length  
> syll.length
> 1        2      1      0      0      0                86    
> 5.445         2.479
> 1        3      1      0      0      0                91    
> 5.215         2.356
> 1        4      0      0      0      0                  79    
> 5.682         2.896
> 1        5      1      0      0      0               83    
> 5.149         2.641
> 1        6      0      0      0      0                77    
> 5.044         2.288
> 1        7      1      0      0      0                  78    
> 5.450         2.420
> 1        8      1      0      1      1                82    
> 5.377         2.505
> 1        9      1      0      0      0                95    
> 5.389         2.706
> 1       10      1      0      0      0                88    
> 5.354         2.461
> 1       11      1      0      0      0                87    
> 5.262         3.079   
> 1       12      1      0      0      0                84    
> 5.191         2.858
> 1       13      1      0      0      1                  87    
> 5.194         2.264
> 2       23      1      0      0      1                  116    
> 5.863         2.876
> 2       24      1      0      0      0                122    
> 5.475         3.114
> 2       25      1      0      0      0                110    
> 5.563         3.059
> .       .       .   .     .     .               .         .          .
> .       .       .   .     .     .               .         .          .
> .
> .
> (60 families)
>
> 'Family' is the first Random effect (categorical variable), with 60 
> levels.
>
> All columns labeled P1L(x) are a matrix of presence/absence genetic 
> markers for each individual in each family. There are 426 such 
> columns(not numbered in sequence) and each one is a random effect.
>
> The last three columns (peg.no, ec.length and syll.length) are the 
> three dependent variables.
>
> Each genetic marker column needs to be nested within each family, 
> which means that if I take the first phenotype, peg.no, for example, 
> then I need to run an analysis that partitions variance 60*426 times 
> (~25,00 runs) for that phenotype.
> I also need an output with the Anova table, and summary, at each stage 
> of the run, so that I can get P values for each marker for each 
> family, as a way of determining whether it contributes significantly 
> to explaining within-family variance for that trait.
>
> To do the above, I tried to write code for lmer() using two nested 
> 'for' loops, one for each level of random factor nesting (marker 
> within family) as follows (using a test data set [please find 
> attached] with only the first 10 marker columns, to see if this works):
>
>
>> vc<-read.table("P:\\R\\Testvcomp10.txt",header=T)
>> attach(vc)
>
>> family<-factor(family)
>> colms<-(vc)[,4:13] ## this to assign the 10 columns containing marker 
> data    to a new variable, as column names are themselves not in any 
> recognisable sequence
>
>> vcdf<-data.frame(family,peg.no,ec.length,syll.length,colms)
>> library(lme4)
>
>> for (c in levels(family))
> + {    for (i in 1:length(colms))
> +        { fit<-lmer(peg.no~1 + (1|c/i), vcdf)
> +        }
> +    summ<-summary(fit)
> +    av<-anova(fit)
> +    print(summ)
> +    print(av)
> + }
>
> This gives me:
>
> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
>  variable lengths differ (found for 'c')
>
>
>
> On suggestion from a colleague I reframed this as:
>
>
>> for(c in levels(family))
> + {
> + print("----New C:----")
> + print(c)
> + for (i in 1:length(colms))
> + {
> + fit<-lmer(peg.no~1+ (1|c/i),vcdf)
> + print(i)
> + summ<-summary(fit)
> + av<-anova(fit)
> + print(summ)
> + print(av)
> + }
> + }
>
> ..and this gave me the output:
>
> [1] "----New C:----"
> [1] "1"
> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
>  variable lengths differ (found for 'c')
>
>
> Google-ing the error message has led me to plenty of links that 
> suggest forcing data into a data frame to fix this, but that hasn't 
> worked.
> My markers and phenotypes both have plenty of missing data (NA's in 
> the data.frame), and na.action=na.omit isn't solving the problem.
>
> (I have tried this with lme, and tried to do it with the aov() command 
> as well and the error is pretty much the same).
>
> I am completely new to R, and despite searching and trying various 
> things, can't get the code to work.
>
> I really appreciate any corrections to this code, or alternative 
> command/function suggestions that I can look into, to try to do this 
> again.
>
>
> Thanks a bunch for your help,
>
> Aditi
>
>
> ----------------------
> A Singh
> Aditi.Singh at bristol.ac.uk
> School of Biological Sciences
> University of Bristol
>
>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
J?r?me Goudet
Dept. Ecology & Evolution
UNIL-Sorge, CH-1015 Lausanne

mail:jerome.goudet at unil.ch
Tel:+41 (0)21 692 4242
Fax:+41 (0)21 692 4265



From desja004 at umn.edu  Thu Jul  9 21:24:40 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Thu, 09 Jul 2009 14:24:40 -0500
Subject: [R-sig-ME] Error with glmer when nesting students in school
Message-ID: <4A5643F8.5070807@umn.edu>

Hi,
I am running a model where my outcome variable is a count variable (# of 
suspensions) and I am trying to nest students (id.f) within school 
(schno.f). When I run this model I get the following error:

glmer.quad.sch <- glmer(sus ~ (grade)^2 + male*(grade)^2 + 
sped*(grade)^2 + ethnic*(grade)^2 + risk*(grade)^2 + (1+ (grade)^2 | 
schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)
Error message:
Error in mer_finalize(ans) : q = 209642 > n = 175975
Calls: system.time ... glmer -> do.call -> <Anonymous> -> mer_finalize 
-> .Call
Execution halted

I am treating both id.f and schno.f as factors as glmer wouldn't run 
without them.
Thanks,
Chris

 > sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25

loaded via a namespace (and not attached):
[1] grid_2.9.1


-- 
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://cddesjardins.wordpress.com/



From jerome.goudet at unil.ch  Thu Jul  9 21:36:29 2009
From: jerome.goudet at unil.ch (Jerome Goudet)
Date: Thu, 09 Jul 2009 21:36:29 +0200
Subject: [R-sig-ME] Error with glmer when nesting students in school
In-Reply-To: <4A5643F8.5070807@umn.edu>
References: <4A5643F8.5070807@umn.edu>
Message-ID: <4A5646BD.1030501@unil.ch>



Christopher David Desjardins wrote:
> Hi,
> I am running a model where my outcome variable is a count variable (# 
> of suspensions) and I am trying to nest students (id.f) within school 
> (schno.f). When I run this model I get the following error:
>
> glmer.quad.sch <- glmer(sus ~ (grade)^2 + male*(grade)^2 + 
> sped*(grade)^2 + ethnic*(grade)^2 + risk*(grade)^2 + (1+ (grade)^2 | 
> schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)
Would:

glmer.quad.sch <- glmer(sus ~ I(grade^2) + male*I(grade^2) + 
sped*I(grade^2) + ethnic*I(grade^2) + risk*I(grade^2) + (1+ I(grade^2) | 
schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)


do the trick?

> Error message:
> Error in mer_finalize(ans) : q = 209642 > n = 175975
> Calls: system.time ... glmer -> do.call -> <Anonymous> -> mer_finalize 
> -> .Call
> Execution halted
>
> I am treating both id.f and schno.f as factors as glmer wouldn't run 
> without them.
> Thanks,
> Chris
>
> > sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-apple-darwin8.11.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.1
>
>

-- 
J?r?me Goudet
Dept. Ecology & Evolution
UNIL-Sorge, CH-1015 Lausanne

mail:jerome.goudet at unil.ch
Tel:+41 (0)21 692 4242
Fax:+41 (0)21 692 4265



From desja004 at umn.edu  Thu Jul  9 21:47:50 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Thu, 09 Jul 2009 14:47:50 -0500
Subject: [R-sig-ME] Error with glmer when nesting students in school
In-Reply-To: <4A5646BD.1030501@unil.ch>
References: <4A5643F8.5070807@umn.edu> <4A5646BD.1030501@unil.ch>
Message-ID: <4A564966.2050407@umn.edu>

Unfortunately, that gives me a similar error.

 > glmer(sus ~ I(grade^2) + male*I(grade^2) + sped*I(grade^2) + 
ethnic*I(grade^2) + risk*I(grade^2) + (1+ I(grade^2) | schno.f/id.f), 
family=poisson, nAGQ=1, data= enroll.long.m)
Error in mer_finalize(ans) : q = 209642 > n = 175975

Cheers,
Chris


On 7/9/09 2:36 PM, Jerome Goudet wrote:
>
>
> Christopher David Desjardins wrote:
>> Hi,
>> I am running a model where my outcome variable is a count variable (# 
>> of suspensions) and I am trying to nest students (id.f) within school 
>> (schno.f). When I run this model I get the following error:
>>
>> glmer.quad.sch <- glmer(sus ~ (grade)^2 + male*(grade)^2 + 
>> sped*(grade)^2 + ethnic*(grade)^2 + risk*(grade)^2 + (1+ (grade)^2 | 
>> schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)
> Would:
>
> glmer.quad.sch <- glmer(sus ~ I(grade^2) + male*I(grade^2) + 
> sped*I(grade^2) + ethnic*I(grade^2) + risk*I(grade^2) + (1+ I(grade^2) 
> | schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)
>
>
> do the trick?
>
>> Error message:
>> Error in mer_finalize(ans) : q = 209642 > n = 175975
>> Calls: system.time ... glmer -> do.call -> <Anonymous> -> 
>> mer_finalize -> .Call
>> Execution halted
>>
>> I am treating both id.f and schno.f as factors as glmer wouldn't run 
>> without them.
>> Thanks,
>> Chris
>>
>> > sessionInfo()
>> R version 2.9.1 (2009-06-26)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.1
>>
>>
>

-- 
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://cddesjardins.wordpress.com/



From wuolong at gmail.com  Thu Jul  9 23:08:00 2009
From: wuolong at gmail.com (Michael Li)
Date: Thu, 9 Jul 2009 17:08:00 -0400
Subject: [R-sig-ME] error from using variance function on Theoph data
Message-ID: <30b434fe0907091408g17268ed4sc58ae77ff3d4a8f7@mail.gmail.com>

Hi, I was trying out nlme function.  For some reason, it did work for
me when I tried to use the power variance function,
even though this is a well known example (and I copied the code from
one of J Pinheiro's presentations).

What could be wrong? I'm using R 2.9.0.

Thanks

Michael

> library (nlme)
> m1 = nlme (conc ~ SSfol (Dose, Time, lKe, lKa, lCl), Theoph,
+ fixed = lKe + lKa + lCl ~ 1,
+ start = list (fixed = c(-2.5, 0.4, -3)),
+ random = pdDiag (lKa + lCl ~ 1))
> m1
Nonlinear mixed-effects model fit by maximum likelihood
  Model: conc ~ SSfol(Dose, Time, lKe, lKa, lCl)
  Data: Theoph
  Log-likelihood: -177.0215
  Fixed: lKe + lKa + lCl ~ 1
       lKe        lKa        lCl
-2.4547019  0.4657267 -3.2272219

Random effects:
 Formula: list(lKa ~ 1, lCl ~ 1)
 Level: Subject
 Structure: Diagonal
              lKa       lCl  Residual
StdDev: 0.6435864 0.1669279 0.7092533

Number of Observations: 132
Number of Groups: 12
> update (m1, weights = varConstPower (power = 0.1))
Error in eigen(val) : infinite or missing values in 'x'



From desja004 at umn.edu  Thu Jul  9 23:10:56 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Thu, 09 Jul 2009 16:10:56 -0500
Subject: [R-sig-ME] Error with glmer when nesting students in school
In-Reply-To: <4A565428.1000001@unil.ch>
References: <4A5643F8.5070807@umn.edu> <4A5646BD.1030501@unil.ch>
	<4A564966.2050407@umn.edu> <4A565428.1000001@unil.ch>
Message-ID: <4A565CE0.5050204@umn.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090709/fd3d2b86/attachment.pl>

From dacostaj at bu.edu  Thu Jul  9 23:37:56 2009
From: dacostaj at bu.edu (Jeff DaCosta)
Date: Thu, 9 Jul 2009 17:37:56 -0400
Subject: [R-sig-ME] nested model with random factors
Message-ID: <8B4C3E00-0BF5-404D-9EC5-6360A2C0E83B@bu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090709/7f1c3bd2/attachment.pl>

From ken at kjbeath.com.au  Fri Jul 10 07:29:06 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Fri, 10 Jul 2009 15:29:06 +1000
Subject: [R-sig-ME] Error with glmer when nesting students in school
In-Reply-To: <4A5643F8.5070807@umn.edu>
References: <4A5643F8.5070807@umn.edu>
Message-ID: <C236F972-0846-4977-85A8-2E4BCB26FADF@kjbeath.com.au>

I expect this is the same as https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/002081.html

I can understand Dougs reluctance to change this, as it would allow  
some silly things. A compromise might be to improve the error message  
to explain that lmer thinks the model is overparameterised and allow  
the user to force these models to be fitted. eg forcefit=TRUE as a  
parameter.

Ken


On 10/07/2009, at 5:24 AM, Christopher David Desjardins wrote:

> Hi,
> I am running a model where my outcome variable is a count variable  
> (# of suspensions) and I am trying to nest students (id.f) within  
> school (schno.f). When I run this model I get the following error:
>
> glmer.quad.sch <- glmer(sus ~ (grade)^2 + male*(grade)^2 +  
> sped*(grade)^2 + ethnic*(grade)^2 + risk*(grade)^2 + (1+ (grade)^2 |  
> schno.f/id.f), family=poisson, nAGQ=1, data= enroll.long.ting)
> Error message:
> Error in mer_finalize(ans) : q = 209642 > n = 175975
> Calls: system.time ... glmer -> do.call -> <Anonymous> ->  
> mer_finalize -> .Call
> Execution halted
>
> I am treating both id.f and schno.f as factors as glmer wouldn't run  
> without them.
> Thanks,
> Chris
>
> > sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-apple-darwin8.11.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.1
>
>
> -- 
> Christopher David Desjardins
> Ph.D. Student
> Quantitative Methods in Education
> Department of Educational Psychology
> University of  Minnesota
> http://cddesjardins.wordpress.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Aditi.Singh at bristol.ac.uk  Fri Jul 10 12:25:42 2009
From: Aditi.Singh at bristol.ac.uk (A Singh)
Date: Fri, 10 Jul 2009 11:25:42 +0100
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
In-Reply-To: <4A564355.6000801@unil.ch>
References: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>
	<4A564355.6000801@unil.ch>
Message-ID: <DB4837765C76AD75B8098AEA@bio-bridlepost1.bio.bris.ac.uk>

Dear Jerome,

Thank you very much for your suggestion, and apologies for the late 
response..

I have tried exactly the same approach when I was still going through this 
in my preliminary stages, and I've tried to run lmer() using them as fixed 
effects; however the catch here, as my supervisors explained to me is this-
- the alleles are not fixed effects because we don't just want to see if 
they differ significantly in their presence/absence across all 60 families.

We want to see if they show associations with phenotype-measurements within 
each family so that we can see if they account for the unexplained 
variation within each family, if that makes sense? And this makes them 
random effects.

We are trying to (as a larger goal) look for marker-trait associations, map 
QTL's and  identify fragments of genes responsible for speciation/genes 
under selection.
Nesting the markers within each family is a sort of mini-within-family 
ANOVA with random effects to see whether particular families have a 
phenotypic trait more accounted for by a particular marker/combination of 
markers, than the trait may be accounted for in other families based on the 
same markers.

Working on this principle, I need to run my lmer model they way I was 
trying to, using the for loops to nest markers within families so that for 
each phenotype, I would have (no of families*no of markers) runs..

Hope this makes it clearer...

Thanks again,

Aditi




--On 09 July 2009 21:21 +0200 Jerome Goudet <jerome.goudet at unil.ch> wrote:

> Dear Aditi,
>
> I'm puzzled with the nesting of loci within families (the presence of an
> allele at a locus means the same whatever the family, I would think). I
> would treat loci as fixed effect and hence use something like that:
>
>  (fm1<-lmer(peg.no~P1L55+P1L73+P1L74+P1L77+P1L91+P1L96+P1L98+P1L100+P1L11
> 4+P1L118+(1|family),dat))
> Linear mixed model fit by REML
> Formula: peg.no ~ P1L55 + P1L73 + P1L74 + P1L77 + P1L91 + P1L96 + P1L98 +
> P1L100 + P1L114 + P1L118 + (1 | family)
>    Data: dat
>   AIC  BIC logLik deviance REMLdev
>  2954 3006  -1464     2963    2928
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  family   (Intercept) 89.043   9.4363  Residual             91.377
> 9.5592 Number of obs: 390, groups: family, 57
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  96.2793     3.2169  29.929
> P1L55        -2.0185     1.5831  -1.275
> P1L73        -3.0256     1.8900  -1.601
> P1L74         1.5112     1.6189   0.933
> P1L77        -2.7898     2.3529  -1.186
> P1L91         0.6480     3.3118   0.196
> P1L96        -1.4718     1.4938  -0.985
> P1L98         2.6431     2.6401   1.001
> P1L100       -3.4529     2.0842  -1.657
> P1L114        0.8099     1.9218   0.421
> P1L118       -2.7119     2.3635  -1.147
>
>
> But perhaps I missed something?
>
> Best wishes,
>
> A Singh wrote:
>> Dear All,
>>
>> I am trying to run a nested random effects model in lmer (for R 2.9.1,
>> lme4 version 0.999375-31 ) using data which is structured as follows:
>>
>> family offsp. P1L74 P1L77 P1L91 P1L96..(n=426) peg.no ec.length
>> syll.length
>> 1        2      1      0      0      0                86
>> 5.445         2.479
>> 1        3      1      0      0      0                91
>> 5.215         2.356
>> 1        4      0      0      0      0                  79
>> 5.682         2.896
>> 1        5      1      0      0      0               83
>> 5.149         2.641
>> 1        6      0      0      0      0                77
>> 5.044         2.288
>> 1        7      1      0      0      0                  78
>> 5.450         2.420
>> 1        8      1      0      1      1                82
>> 5.377         2.505
>> 1        9      1      0      0      0                95
>> 5.389         2.706
>> 1       10      1      0      0      0                88
>> 5.354         2.461
>> 1       11      1      0      0      0                87
>> 5.262         3.079
>> 1       12      1      0      0      0                84
>> 5.191         2.858
>> 1       13      1      0      0      1                  87
>> 5.194         2.264
>> 2       23      1      0      0      1                  116
>> 5.863         2.876
>> 2       24      1      0      0      0                122
>> 5.475         3.114
>> 2       25      1      0      0      0                110
>> 5.563         3.059
>> .       .       .   .     .     .               .         .          .
>> .       .       .   .     .     .               .         .          .
>> .
>> .
>> (60 families)
>>
>> 'Family' is the first Random effect (categorical variable), with 60
>> levels.
>>
>> All columns labeled P1L(x) are a matrix of presence/absence genetic
>> markers for each individual in each family. There are 426 such
>> columns(not numbered in sequence) and each one is a random effect.
>>
>> The last three columns (peg.no, ec.length and syll.length) are the
>> three dependent variables.
>>
>> Each genetic marker column needs to be nested within each family,
>> which means that if I take the first phenotype, peg.no, for example,
>> then I need to run an analysis that partitions variance 60*426 times
>> (~25,00 runs) for that phenotype.
>> I also need an output with the Anova table, and summary, at each stage
>> of the run, so that I can get P values for each marker for each
>> family, as a way of determining whether it contributes significantly
>> to explaining within-family variance for that trait.
>>
>> To do the above, I tried to write code for lmer() using two nested
>> 'for' loops, one for each level of random factor nesting (marker
>> within family) as follows (using a test data set [please find
>> attached] with only the first 10 marker columns, to see if this works):
>>
>>
>>> vc<-read.table("P:\\R\\Testvcomp10.txt",header=T)
>>> attach(vc)
>>
>>> family<-factor(family)
>>> colms<-(vc)[,4:13] ## this to assign the 10 columns containing marker
>> data    to a new variable, as column names are themselves not in any
>> recognisable sequence
>>
>>> vcdf<-data.frame(family,peg.no,ec.length,syll.length,colms)
>>> library(lme4)
>>
>>> for (c in levels(family))
>> + {    for (i in 1:length(colms))
>> +        { fit<-lmer(peg.no~1 + (1|c/i), vcdf)
>> +        }
>> +    summ<-summary(fit)
>> +    av<-anova(fit)
>> +    print(summ)
>> +    print(av)
>> + }
>>
>> This gives me:
>>
>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
>>  variable lengths differ (found for 'c')
>>
>>
>>
>> On suggestion from a colleague I reframed this as:
>>
>>
>>> for(c in levels(family))
>> + {
>> + print("----New C:----")
>> + print(c)
>> + for (i in 1:length(colms))
>> + {
>> + fit<-lmer(peg.no~1+ (1|c/i),vcdf)
>> + print(i)
>> + summ<-summary(fit)
>> + av<-anova(fit)
>> + print(summ)
>> + print(av)
>> + }
>> + }
>>
>> ..and this gave me the output:
>>
>> [1] "----New C:----"
>> [1] "1"
>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 +  :
>>  variable lengths differ (found for 'c')
>>
>>
>> Google-ing the error message has led me to plenty of links that
>> suggest forcing data into a data frame to fix this, but that hasn't
>> worked.
>> My markers and phenotypes both have plenty of missing data (NA's in
>> the data.frame), and na.action=na.omit isn't solving the problem.
>>
>> (I have tried this with lme, and tried to do it with the aov() command
>> as well and the error is pretty much the same).
>>
>> I am completely new to R, and despite searching and trying various
>> things, can't get the code to work.
>>
>> I really appreciate any corrections to this code, or alternative
>> command/function suggestions that I can look into, to try to do this
>> again.
>>
>>
>> Thanks a bunch for your help,
>>
>> Aditi
>>
>>
>> ----------------------
>> A Singh
>> Aditi.Singh at bristol.ac.uk
>> School of Biological Sciences
>> University of Bristol
>>
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> J?r?me Goudet
> Dept. Ecology & Evolution
> UNIL-Sorge, CH-1015 Lausanne
>
> mail:jerome.goudet at unil.ch
> Tel:+41 (0)21 692 4242
> Fax:+41 (0)21 692 4265
>



----------------------
A Singh
Aditi.Singh at bristol.ac.uk
School of Biological Sciences
University of Bristol



From jerome.goudet at unil.ch  Fri Jul 10 15:31:24 2009
From: jerome.goudet at unil.ch (Jerome Goudet)
Date: Fri, 10 Jul 2009 15:31:24 +0200
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
In-Reply-To: <DB4837765C76AD75B8098AEA@bio-bridlepost1.bio.bris.ac.uk>
References: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>
	<4A564355.6000801@unil.ch>
	<DB4837765C76AD75B8098AEA@bio-bridlepost1.bio.bris.ac.uk>
Message-ID: <4A5742AC.1040106@unil.ch>

Dear Aditi,

Would'nt it be simpler then to remove the family effect (by using e.g. 
the residuals of lmer(peg.no~1+(1|Family))) and to look at the effect of 
individual loci on the residuals (I think this is what was suggested by 
Aulchenko etal (Genetics 2007  177:577)? But I may be wrong and missing 
something...

Best wishes,

A Singh wrote:
> Dear Jerome,
>
> Thank you very much for your suggestion, and apologies for the late 
> response..
>
> I have tried exactly the same approach when I was still going through 
> this in my preliminary stages, and I've tried to run lmer() using them 
> as fixed effects; however the catch here, as my supervisors explained 
> to me is this-
> - the alleles are not fixed effects because we don't just want to see 
> if they differ significantly in their presence/absence across all 60 
> families.
>
> We want to see if they show associations with phenotype-measurements 
> within each family so that we can see if they account for the 
> unexplained variation within each family, if that makes sense? And 
> this makes them random effects.
>
> We are trying to (as a larger goal) look for marker-trait 
> associations, map QTL's and  identify fragments of genes responsible 
> for speciation/genes under selection.
> Nesting the markers within each family is a sort of mini-within-family 
> ANOVA with random effects to see whether particular families have a 
> phenotypic trait more accounted for by a particular marker/combination 
> of markers, than the trait may be accounted for in other families 
> based on the same markers.
>
> Working on this principle, I need to run my lmer model they way I was 
> trying to, using the for loops to nest markers within families so that 
> for each phenotype, I would have (no of families*no of markers) runs..
>
> Hope this makes it clearer...
>
> Thanks again,
>
> Aditi
>
>
>
>
> --On 09 July 2009 21:21 +0200 Jerome Goudet <jerome.goudet at unil.ch> 
> wrote:
>
>> Dear Aditi,
>>
>> I'm puzzled with the nesting of loci within families (the presence of an
>> allele at a locus means the same whatever the family, I would think). I
>> would treat loci as fixed effect and hence use something like that:
>>
>>  (fm1<-lmer(peg.no~P1L55+P1L73+P1L74+P1L77+P1L91+P1L96+P1L98+P1L100+P1L11 
>>
>> 4+P1L118+(1|family),dat))
>> Linear mixed model fit by REML
>> Formula: peg.no ~ P1L55 + P1L73 + P1L74 + P1L77 + P1L91 + P1L96 + 
>> P1L98 +
>> P1L100 + P1L114 + P1L118 + (1 | family)
>>    Data: dat
>>   AIC  BIC logLik deviance REMLdev
>>  2954 3006  -1464     2963    2928
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  family   (Intercept) 89.043   9.4363  Residual             91.377
>> 9.5592 Number of obs: 390, groups: family, 57
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)  96.2793     3.2169  29.929
>> P1L55        -2.0185     1.5831  -1.275
>> P1L73        -3.0256     1.8900  -1.601
>> P1L74         1.5112     1.6189   0.933
>> P1L77        -2.7898     2.3529  -1.186
>> P1L91         0.6480     3.3118   0.196
>> P1L96        -1.4718     1.4938  -0.985
>> P1L98         2.6431     2.6401   1.001
>> P1L100       -3.4529     2.0842  -1.657
>> P1L114        0.8099     1.9218   0.421
>> P1L118       -2.7119     2.3635  -1.147
>>
>>
>> But perhaps I missed something?
>>
>> Best wishes,
>>
>> A Singh wrote:
>>> Dear All,
>>>
>>> I am trying to run a nested random effects model in lmer (for R 2.9.1,
>>> lme4 version 0.999375-31 ) using data which is structured as follows:
>>>
>>> family offsp. P1L74 P1L77 P1L91 P1L96..(n=426) peg.no ec.length
>>> syll.length
>>> 1        2      1      0      0      0                86
>>> 5.445         2.479
>>> 1        3      1      0      0      0                91
>>> 5.215         2.356
>>> 1        4      0      0      0      0                  79
>>> 5.682         2.896
>>> 1        5      1      0      0      0               83
>>> 5.149         2.641
>>> 1        6      0      0      0      0                77
>>> 5.044         2.288
>>> 1        7      1      0      0      0                  78
>>> 5.450         2.420
>>> 1        8      1      0      1      1                82
>>> 5.377         2.505
>>> 1        9      1      0      0      0                95
>>> 5.389         2.706
>>> 1       10      1      0      0      0                88
>>> 5.354         2.461
>>> 1       11      1      0      0      0                87
>>> 5.262         3.079
>>> 1       12      1      0      0      0                84
>>> 5.191         2.858
>>> 1       13      1      0      0      1                  87
>>> 5.194         2.264
>>> 2       23      1      0      0      1                  116
>>> 5.863         2.876
>>> 2       24      1      0      0      0                122
>>> 5.475         3.114
>>> 2       25      1      0      0      0                110
>>> 5.563         3.059
>>> .       .       .   .     .     .               .         .          .
>>> .       .       .   .     .     .               .         .          .
>>> .
>>> .
>>> (60 families)
>>>
>>> 'Family' is the first Random effect (categorical variable), with 60
>>> levels.
>>>
>>> All columns labeled P1L(x) are a matrix of presence/absence genetic
>>> markers for each individual in each family. There are 426 such
>>> columns(not numbered in sequence) and each one is a random effect.
>>>
>>> The last three columns (peg.no, ec.length and syll.length) are the
>>> three dependent variables.
>>>
>>> Each genetic marker column needs to be nested within each family,
>>> which means that if I take the first phenotype, peg.no, for example,
>>> then I need to run an analysis that partitions variance 60*426 times
>>> (~25,00 runs) for that phenotype.
>>> I also need an output with the Anova table, and summary, at each stage
>>> of the run, so that I can get P values for each marker for each
>>> family, as a way of determining whether it contributes significantly
>>> to explaining within-family variance for that trait.
>>>
>>> To do the above, I tried to write code for lmer() using two nested
>>> 'for' loops, one for each level of random factor nesting (marker
>>> within family) as follows (using a test data set [please find
>>> attached] with only the first 10 marker columns, to see if this works):
>>>
>>>
>>>> vc<-read.table("P:\\R\\Testvcomp10.txt",header=T)
>>>> attach(vc)
>>>
>>>> family<-factor(family)
>>>> colms<-(vc)[,4:13] ## this to assign the 10 columns containing marker
>>> data    to a new variable, as column names are themselves not in any
>>> recognisable sequence
>>>
>>>> vcdf<-data.frame(family,peg.no,ec.length,syll.length,colms)
>>>> library(lme4)
>>>
>>>> for (c in levels(family))
>>> + {    for (i in 1:length(colms))
>>> +        { fit<-lmer(peg.no~1 + (1|c/i), vcdf)
>>> +        }
>>> +    summ<-summary(fit)
>>> +    av<-anova(fit)
>>> +    print(summ)
>>> +    print(av)
>>> + }
>>>
>>> This gives me:
>>>
>>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 
>>> +  :
>>>  variable lengths differ (found for 'c')
>>>
>>>
>>>
>>> On suggestion from a colleague I reframed this as:
>>>
>>>
>>>> for(c in levels(family))
>>> + {
>>> + print("----New C:----")
>>> + print(c)
>>> + for (i in 1:length(colms))
>>> + {
>>> + fit<-lmer(peg.no~1+ (1|c/i),vcdf)
>>> + print(i)
>>> + summ<-summary(fit)
>>> + av<-anova(fit)
>>> + print(summ)
>>> + print(av)
>>> + }
>>> + }
>>>
>>> ..and this gave me the output:
>>>
>>> [1] "----New C:----"
>>> [1] "1"
>>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1 
>>> +  :
>>>  variable lengths differ (found for 'c')
>>>
>>>
>>> Google-ing the error message has led me to plenty of links that
>>> suggest forcing data into a data frame to fix this, but that hasn't
>>> worked.
>>> My markers and phenotypes both have plenty of missing data (NA's in
>>> the data.frame), and na.action=na.omit isn't solving the problem.
>>>
>>> (I have tried this with lme, and tried to do it with the aov() command
>>> as well and the error is pretty much the same).
>>>
>>> I am completely new to R, and despite searching and trying various
>>> things, can't get the code to work.
>>>
>>> I really appreciate any corrections to this code, or alternative
>>> command/function suggestions that I can look into, to try to do this
>>> again.
>>>
>>>
>>> Thanks a bunch for your help,
>>>
>>> Aditi
>>>
>>>
>>> ----------------------
>>> A Singh
>>> Aditi.Singh at bristol.ac.uk
>>> School of Biological Sciences
>>> University of Bristol
>>>
>>>
>>>
>>> ------------------------------------------------------------------------ 
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> -- 
>> J?r?me Goudet
>> Dept. Ecology & Evolution
>> UNIL-Sorge, CH-1015 Lausanne
>>
>> mail:jerome.goudet at unil.ch
>> Tel:+41 (0)21 692 4242
>> Fax:+41 (0)21 692 4265
>>
>
>
>
> ----------------------
> A Singh
> Aditi.Singh at bristol.ac.uk
> School of Biological Sciences
> University of Bristol
>
>
>
>
>

-- 
J?r?me Goudet
Dept. Ecology & Evolution
UNIL-Sorge, CH-1015 Lausanne

mail:jerome.goudet at unil.ch
Tel:+41 (0)21 692 4242
Fax:+41 (0)21 692 4265



From Aditi.Singh at bristol.ac.uk  Fri Jul 10 16:23:50 2009
From: Aditi.Singh at bristol.ac.uk (A Singh)
Date: Fri, 10 Jul 2009 15:23:50 +0100
Subject: [R-sig-ME] Differing variable lengths (missing data) and Model
 errors in lmer()
In-Reply-To: <4A5742AC.1040106@unil.ch>
References: <4361990400C7D6188C2DF38E@bio-bridlepost1.bio.bris.ac.uk>
	<4A564355.6000801@unil.ch>
	<DB4837765C76AD75B8098AEA@bio-bridlepost1.bio.bris.ac.uk>
	<4A5742AC.1040106@unil.ch>
Message-ID: <B3215530380951C31C29E885@bio-bridlepost1.bio.bris.ac.uk>

Dear Jerome,

Thank you very much indeed for your suggestion!
I have just gotten the paper off Genetics, and it seems to be very spot on. 
I will have a quick read, try to isolate residuals from my lmer() formula 
using 'family' and  will get back to you with what it gives me. This could 
be my key.

Thanks again,

Aditi



--On 10 July 2009 15:31 +0200 Jerome Goudet <jerome.goudet at unil.ch> wrote:

> Dear Aditi,
>
> Would'nt it be simpler then to remove the family effect (by using e.g.
> the residuals of lmer(peg.no~1+(1|Family))) and to look at the effect of
> individual loci on the residuals (I think this is what was suggested by
> Aulchenko etal (Genetics 2007  177:577)? But I may be wrong and missing
> something...
>
> Best wishes,
>
> A Singh wrote:
>> Dear Jerome,
>>
>> Thank you very much for your suggestion, and apologies for the late
>> response..
>>
>> I have tried exactly the same approach when I was still going through
>> this in my preliminary stages, and I've tried to run lmer() using them
>> as fixed effects; however the catch here, as my supervisors explained
>> to me is this-
>> - the alleles are not fixed effects because we don't just want to see
>> if they differ significantly in their presence/absence across all 60
>> families.
>>
>> We want to see if they show associations with phenotype-measurements
>> within each family so that we can see if they account for the
>> unexplained variation within each family, if that makes sense? And
>> this makes them random effects.
>>
>> We are trying to (as a larger goal) look for marker-trait
>> associations, map QTL's and  identify fragments of genes responsible
>> for speciation/genes under selection.
>> Nesting the markers within each family is a sort of mini-within-family
>> ANOVA with random effects to see whether particular families have a
>> phenotypic trait more accounted for by a particular marker/combination
>> of markers, than the trait may be accounted for in other families
>> based on the same markers.
>>
>> Working on this principle, I need to run my lmer model they way I was
>> trying to, using the for loops to nest markers within families so that
>> for each phenotype, I would have (no of families*no of markers) runs..
>>
>> Hope this makes it clearer...
>>
>> Thanks again,
>>
>> Aditi
>>
>>
>>
>>
>> --On 09 July 2009 21:21 +0200 Jerome Goudet <jerome.goudet at unil.ch>
>> wrote:
>>
>>> Dear Aditi,
>>>
>>> I'm puzzled with the nesting of loci within families (the presence of an
>>> allele at a locus means the same whatever the family, I would think). I
>>> would treat loci as fixed effect and hence use something like that:
>>>
>>>  (fm1<-lmer(peg.no~P1L55+P1L73+P1L74+P1L77+P1L91+P1L96+P1L98+P1L100+P1L
>>>  11
>>>
>>> 4+P1L118+(1|family),dat))
>>> Linear mixed model fit by REML
>>> Formula: peg.no ~ P1L55 + P1L73 + P1L74 + P1L77 + P1L91 + P1L96 +
>>> P1L98 +
>>> P1L100 + P1L114 + P1L118 + (1 | family)
>>>    Data: dat
>>>   AIC  BIC logLik deviance REMLdev
>>>  2954 3006  -1464     2963    2928
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  family   (Intercept) 89.043   9.4363  Residual             91.377
>>> 9.5592 Number of obs: 390, groups: family, 57
>>>
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept)  96.2793     3.2169  29.929
>>> P1L55        -2.0185     1.5831  -1.275
>>> P1L73        -3.0256     1.8900  -1.601
>>> P1L74         1.5112     1.6189   0.933
>>> P1L77        -2.7898     2.3529  -1.186
>>> P1L91         0.6480     3.3118   0.196
>>> P1L96        -1.4718     1.4938  -0.985
>>> P1L98         2.6431     2.6401   1.001
>>> P1L100       -3.4529     2.0842  -1.657
>>> P1L114        0.8099     1.9218   0.421
>>> P1L118       -2.7119     2.3635  -1.147
>>>
>>>
>>> But perhaps I missed something?
>>>
>>> Best wishes,
>>>
>>> A Singh wrote:
>>>> Dear All,
>>>>
>>>> I am trying to run a nested random effects model in lmer (for R 2.9.1,
>>>> lme4 version 0.999375-31 ) using data which is structured as follows:
>>>>
>>>> family offsp. P1L74 P1L77 P1L91 P1L96..(n=426) peg.no ec.length
>>>> syll.length
>>>> 1        2      1      0      0      0                86
>>>> 5.445         2.479
>>>> 1        3      1      0      0      0                91
>>>> 5.215         2.356
>>>> 1        4      0      0      0      0                  79
>>>> 5.682         2.896
>>>> 1        5      1      0      0      0               83
>>>> 5.149         2.641
>>>> 1        6      0      0      0      0                77
>>>> 5.044         2.288
>>>> 1        7      1      0      0      0                  78
>>>> 5.450         2.420
>>>> 1        8      1      0      1      1                82
>>>> 5.377         2.505
>>>> 1        9      1      0      0      0                95
>>>> 5.389         2.706
>>>> 1       10      1      0      0      0                88
>>>> 5.354         2.461
>>>> 1       11      1      0      0      0                87
>>>> 5.262         3.079
>>>> 1       12      1      0      0      0                84
>>>> 5.191         2.858
>>>> 1       13      1      0      0      1                  87
>>>> 5.194         2.264
>>>> 2       23      1      0      0      1                  116
>>>> 5.863         2.876
>>>> 2       24      1      0      0      0                122
>>>> 5.475         3.114
>>>> 2       25      1      0      0      0                110
>>>> 5.563         3.059
>>>> .       .       .   .     .     .               .         .          .
>>>> .       .       .   .     .     .               .         .          .
>>>> .
>>>> .
>>>> (60 families)
>>>>
>>>> 'Family' is the first Random effect (categorical variable), with 60
>>>> levels.
>>>>
>>>> All columns labeled P1L(x) are a matrix of presence/absence genetic
>>>> markers for each individual in each family. There are 426 such
>>>> columns(not numbered in sequence) and each one is a random effect.
>>>>
>>>> The last three columns (peg.no, ec.length and syll.length) are the
>>>> three dependent variables.
>>>>
>>>> Each genetic marker column needs to be nested within each family,
>>>> which means that if I take the first phenotype, peg.no, for example,
>>>> then I need to run an analysis that partitions variance 60*426 times
>>>> (~25,00 runs) for that phenotype.
>>>> I also need an output with the Anova table, and summary, at each stage
>>>> of the run, so that I can get P values for each marker for each
>>>> family, as a way of determining whether it contributes significantly
>>>> to explaining within-family variance for that trait.
>>>>
>>>> To do the above, I tried to write code for lmer() using two nested
>>>> 'for' loops, one for each level of random factor nesting (marker
>>>> within family) as follows (using a test data set [please find
>>>> attached] with only the first 10 marker columns, to see if this works):
>>>>
>>>>
>>>>> vc<-read.table("P:\\R\\Testvcomp10.txt",header=T)
>>>>> attach(vc)
>>>>
>>>>> family<-factor(family)
>>>>> colms<-(vc)[,4:13] ## this to assign the 10 columns containing marker
>>>> data    to a new variable, as column names are themselves not in any
>>>> recognisable sequence
>>>>
>>>>> vcdf<-data.frame(family,peg.no,ec.length,syll.length,colms)
>>>>> library(lme4)
>>>>
>>>>> for (c in levels(family))
>>>> + {    for (i in 1:length(colms))
>>>> +        { fit<-lmer(peg.no~1 + (1|c/i), vcdf)
>>>> +        }
>>>> +    summ<-summary(fit)
>>>> +    av<-anova(fit)
>>>> +    print(summ)
>>>> +    print(av)
>>>> + }
>>>>
>>>> This gives me:
>>>>
>>>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1
>>>> +  :
>>>>  variable lengths differ (found for 'c')
>>>>
>>>>
>>>>
>>>> On suggestion from a colleague I reframed this as:
>>>>
>>>>
>>>>> for(c in levels(family))
>>>> + {
>>>> + print("----New C:----")
>>>> + print(c)
>>>> + for (i in 1:length(colms))
>>>> + {
>>>> + fit<-lmer(peg.no~1+ (1|c/i),vcdf)
>>>> + print(i)
>>>> + summ<-summary(fit)
>>>> + av<-anova(fit)
>>>> + print(summ)
>>>> + print(av)
>>>> + }
>>>> + }
>>>>
>>>> ..and this gave me the output:
>>>>
>>>> [1] "----New C:----"
>>>> [1] "1"
>>>> Error in model.frame.default(data = vcdf, formula = peg.no ~ 1 + (1
>>>> +  :
>>>>  variable lengths differ (found for 'c')
>>>>
>>>>
>>>> Google-ing the error message has led me to plenty of links that
>>>> suggest forcing data into a data frame to fix this, but that hasn't
>>>> worked.
>>>> My markers and phenotypes both have plenty of missing data (NA's in
>>>> the data.frame), and na.action=na.omit isn't solving the problem.
>>>>
>>>> (I have tried this with lme, and tried to do it with the aov() command
>>>> as well and the error is pretty much the same).
>>>>
>>>> I am completely new to R, and despite searching and trying various
>>>> things, can't get the code to work.
>>>>
>>>> I really appreciate any corrections to this code, or alternative
>>>> command/function suggestions that I can look into, to try to do this
>>>> again.
>>>>
>>>>
>>>> Thanks a bunch for your help,
>>>>
>>>> Aditi
>>>>
>>>>
>>>> ----------------------
>>>> A Singh
>>>> Aditi.Singh at bristol.ac.uk
>>>> School of Biological Sciences
>>>> University of Bristol
>>>>
>>>>
>>>>
>>>> ----------------------------------------------------------------------
>>>> --
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> --
>>> J?r?me Goudet
>>> Dept. Ecology & Evolution
>>> UNIL-Sorge, CH-1015 Lausanne
>>>
>>> mail:jerome.goudet at unil.ch
>>> Tel:+41 (0)21 692 4242
>>> Fax:+41 (0)21 692 4265
>>>
>>
>>
>>
>> ----------------------
>> A Singh
>> Aditi.Singh at bristol.ac.uk
>> School of Biological Sciences
>> University of Bristol
>>
>>
>>
>>
>>
>
> --
> J?r?me Goudet
> Dept. Ecology & Evolution
> UNIL-Sorge, CH-1015 Lausanne
>
> mail:jerome.goudet at unil.ch
> Tel:+41 (0)21 692 4242
> Fax:+41 (0)21 692 4265
>



----------------------
A Singh
Aditi.Singh at bristol.ac.uk
School of Biological Sciences
University of Bristol



From Djibril.Dayamba at ess.slu.se  Sun Jul 12 19:43:30 2009
From: Djibril.Dayamba at ess.slu.se (Djibril Dayamba)
Date: Sun, 12 Jul 2009 19:43:30 +0200
Subject: [R-sig-ME] Need some advice on my model specification
Message-ID: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090712/5c341332/attachment.pl>

From kingsfordjones at gmail.com  Sun Jul 12 22:01:15 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Sun, 12 Jul 2009 14:01:15 -0600
Subject: [R-sig-ME] Need some advice on my model specification
In-Reply-To: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
References: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
Message-ID: <2ad0cc110907121301o32d684f8vc7e18fbd38fb71e1@mail.gmail.com>

Hi Djibril,

The model is overspecified.  I strongly suspect a call of
intervals(Model) will throw an error, or possibly produce intervals of
infinite width.  A more likely candidate is:

Model <- lme(BA.B ~ Grazing*Fire + Year, data = <your data>,
    random = ~<random intercept and possible linear and quadratic slopes>|Plot,
    correlation = corAR1(form=~Year|Plot), weights = <possible
heterogeneity structure>)

Without being familiar with the data this is of course only a suggestion.

One strategy is to start with the fit with no correlation structure
and explore residual temporal correlation within plots using the ACF
function and its plot method, choosing a structure, fitting it, and
repeating the exploration.  The same can be done for variance
structures with the weights argument.  The following link (and P&B
2000) will suggest plots for exploration:

http://bm2.genes.nig.ac.jp/RGM2/index.php?query=nlme

As I mentioned in reply to your r-help post there are a variety of
tricky issues surrounding inference; nonetheless, if you carefully
build your linear model, checking that you are reasonably meeting
normality assumptions (for errors and random effects), and using the
lme arguments to structure error covariance so as to account for lack
of independence and heterogeneity of variance, you will have results
that should be quite defensible to reviewers.

best of luck,

Kingsford


On Sun, Jul 12, 2009 at 11:43 AM, Djibril
Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
> Hello,
> I previously wrote to R-help, I got some advices and was kindly redirected by Kingsford to this specific Help-list (mixed models) for further questions. Since then I have moved a bit but I still have some points where I would appreciate having clarification.
>
> I have a factorial experiment ( with 4 repetitions for each treatment combination) to study the effects of Grazing and Fire on Forest biomass production. The experimental unit (to which the treatment combinations are applied) are PLOTs. The measures were made repeatedly for 13 years. Below is how I organized my data; Plot is the plot naming in the field; BA.B is the response variable (Basal area) I am using to express myself here
>
>
> Grazing ? ? ? ? ? ? Fire ? ? ? ? ? ? ? ? ? ? Plot ? ? ? ? ? ? ? ? ? ? Year ? ? ? ? ? ? ? ? ? ?BA.B
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 398.13
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 4728.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2092.05
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? ? ? 3076.70
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? ? ? 2578.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? ? ? 2541.07
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? ? ? 3191.61
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? ? ? 2526.75
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ? ? ? 3665.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? ? ? ? ? ? ? ? ?3077.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?11 ? ? ? ? ? ? ? ? ? ? ? ?3911.63
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?12 ? ? ? ? ? ? ? ? ? ? ? ?4067.28
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?13 ? ? ? ? ? ? ? ? ? ? ? ?4457.94
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 370.99
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 2184.39
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2008.66
> .
> .
> .
> .
> .
>
> I fitted the below model to account for the temporal autocorrelation and the variance heterogeneity. I also have a missing value.
>
> Model<-lme(BA.B~Grazing*Fire*Year, random=~1|Year/Plot/Fire/Grazing, correlation=corAR1(form=~Year), weights=varIdent(form=~1|Grazing*Fire*Year), na.action=na.omit)
>
> For the random effect I got something like this
>
> Random effects:
> ?Formula: ~1 | Year
> ? ? ? ?(Intercept)
> StdDev: ? ?234.6285
>
> ?Formula: ~1 | Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?67.01272
>
> ?Formula: ~1 | Fire %in% Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?66.80442
>
> ?Formula: ~1 | Grazing %in% Fire %in% Plot %in% Year
> ? ? ? ?(Intercept) Residual
> StdDev: ? ?66.83408 ? ? ? ? ? 153.0221
>
>
> For the correlation structure, the Phi value is 0 (zero)
>
> Correlation Structure: AR(1)
> ?Formula: ~Year | Year/Plot/Fire/Grazing
> ?Parameter estimate(s):
> Phi
> ?0
>
> For the fixed effects, please note the identical degree of freedom for every term (except Year)
>
> Fixed effects: BA.B ~ Grazing * Fire * Year
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Value ? ? ? ? ? ? ? ? ? Std.Error ? ? ? DF ? ? ? ? ? ? ? ? t-value ? ? ? ? ? p-value
> (Intercept) ? ? ? ? ? ? ? ? ? ? ? 461.4655 ? ? ? ? ?178.15612 ? ? 396 ? ? ? ? ? ? ? ?2.590231 ? ? ? 0.0099
> GrazingUngrazed ? ? ? ? ? ? ? ? ?-180.1041 ? 104.88596 ? ? 396 ? ? ? ? ? ? ? ?-1.717143 ? ? ?0.0867
> FireUnburnt ? ? ? ? ? ? ? ? ? ? ?-236.3691 ? ? ? 124.54654 ? ? 396 ? ? ? ? ? ? ? ?-1.897837 ? ? ?0.0584
> Year ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?410.9426 ? ? ? ? ? ? 31.68234 ? ? ? 11 ? ? ? ? ? ? ? ? ?12.970718 ? ? 0.0000
> GrazingUngrazed:FireUnburnt 224.5099 153.17048 ? ?396 ? ? ? ? ? ? ? ?1.465752 ? ? ? 0.1435
> GrazingUngrazed:Year ? ? ? ? -104.4984 ?28.99989 ? ? ? 396 ? ? ? ? ? ? ? ?-3.603406 ? ? ?0.0004
> FireUnburnt:Year ? ? ? ? ? ? ? ? ?-21.3375 ? ? 38.52046 ? ? ? 396 ? ? ? ? ? ? ? ?-0.553927 ? ? ?0.5799
> GrazingUngrazed:FireUnburnt:Year 85.2475 ?44.47663 ? 396 ? ? ? ? ? 1.916680 ? ? ? 0.0560
>
>
> My concern is:
> Does my model specification looks ok?
> Is Phi = 0 real and what does this mean (in all case studies I have seen, it had value different from zero)?
> I am also wondering about the identical degree of freedom for all term (except for Year).
> Thanks in advance
>
>
> With regards,
>
> Djibril.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kingsfordjones at gmail.com  Mon Jul 13 00:58:31 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Sun, 12 Jul 2009 16:58:31 -0600
Subject: [R-sig-ME] Need some advice on my model specification
In-Reply-To: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
References: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
Message-ID: <2ad0cc110907121558m4e2b7185j44713a524917acbe@mail.gmail.com>

One more tip...

I avoided the degrees of freedom question in my response, but perhaps
the following link will help:

http://tinyurl.com/kmlsf7

hth,
Kingsford

On Sun, Jul 12, 2009 at 11:43 AM, Djibril
Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
> Hello,
> I previously wrote to R-help, I got some advices and was kindly redirected by Kingsford to this specific Help-list (mixed models) for further questions. Since then I have moved a bit but I still have some points where I would appreciate having clarification.
>
> I have a factorial experiment ( with 4 repetitions for each treatment combination) to study the effects of Grazing and Fire on Forest biomass production. The experimental unit (to which the treatment combinations are applied) are PLOTs. The measures were made repeatedly for 13 years. Below is how I organized my data; Plot is the plot naming in the field; BA.B is the response variable (Basal area) I am using to express myself here
>
>
> Grazing ? ? ? ? ? ? Fire ? ? ? ? ? ? ? ? ? ? Plot ? ? ? ? ? ? ? ? ? ? Year ? ? ? ? ? ? ? ? ? ?BA.B
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 398.13
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 4728.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2092.05
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? ? ? 3076.70
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? ? ? 2578.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? ? ? 2541.07
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? ? ? 3191.61
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? ? ? 2526.75
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ? ? ? 3665.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? ? ? ? ? ? ? ? ?3077.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?11 ? ? ? ? ? ? ? ? ? ? ? ?3911.63
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?12 ? ? ? ? ? ? ? ? ? ? ? ?4067.28
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?13 ? ? ? ? ? ? ? ? ? ? ? ?4457.94
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 370.99
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 2184.39
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2008.66
> .
> .
> .
> .
> .
>
> I fitted the below model to account for the temporal autocorrelation and the variance heterogeneity. I also have a missing value.
>
> Model<-lme(BA.B~Grazing*Fire*Year, random=~1|Year/Plot/Fire/Grazing, correlation=corAR1(form=~Year), weights=varIdent(form=~1|Grazing*Fire*Year), na.action=na.omit)
>
> For the random effect I got something like this
>
> Random effects:
> ?Formula: ~1 | Year
> ? ? ? ?(Intercept)
> StdDev: ? ?234.6285
>
> ?Formula: ~1 | Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?67.01272
>
> ?Formula: ~1 | Fire %in% Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?66.80442
>
> ?Formula: ~1 | Grazing %in% Fire %in% Plot %in% Year
> ? ? ? ?(Intercept) Residual
> StdDev: ? ?66.83408 ? ? ? ? ? 153.0221
>
>
> For the correlation structure, the Phi value is 0 (zero)
>
> Correlation Structure: AR(1)
> ?Formula: ~Year | Year/Plot/Fire/Grazing
> ?Parameter estimate(s):
> Phi
> ?0
>
> For the fixed effects, please note the identical degree of freedom for every term (except Year)
>
> Fixed effects: BA.B ~ Grazing * Fire * Year
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Value ? ? ? ? ? ? ? ? ? Std.Error ? ? ? DF ? ? ? ? ? ? ? ? t-value ? ? ? ? ? p-value
> (Intercept) ? ? ? ? ? ? ? ? ? ? ? 461.4655 ? ? ? ? ?178.15612 ? ? 396 ? ? ? ? ? ? ? ?2.590231 ? ? ? 0.0099
> GrazingUngrazed ? ? ? ? ? ? ? ? ?-180.1041 ? 104.88596 ? ? 396 ? ? ? ? ? ? ? ?-1.717143 ? ? ?0.0867
> FireUnburnt ? ? ? ? ? ? ? ? ? ? ?-236.3691 ? ? ? 124.54654 ? ? 396 ? ? ? ? ? ? ? ?-1.897837 ? ? ?0.0584
> Year ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?410.9426 ? ? ? ? ? ? 31.68234 ? ? ? 11 ? ? ? ? ? ? ? ? ?12.970718 ? ? 0.0000
> GrazingUngrazed:FireUnburnt 224.5099 153.17048 ? ?396 ? ? ? ? ? ? ? ?1.465752 ? ? ? 0.1435
> GrazingUngrazed:Year ? ? ? ? -104.4984 ?28.99989 ? ? ? 396 ? ? ? ? ? ? ? ?-3.603406 ? ? ?0.0004
> FireUnburnt:Year ? ? ? ? ? ? ? ? ?-21.3375 ? ? 38.52046 ? ? ? 396 ? ? ? ? ? ? ? ?-0.553927 ? ? ?0.5799
> GrazingUngrazed:FireUnburnt:Year 85.2475 ?44.47663 ? 396 ? ? ? ? ? 1.916680 ? ? ? 0.0560
>
>
> My concern is:
> Does my model specification looks ok?
> Is Phi = 0 real and what does this mean (in all case studies I have seen, it had value different from zero)?
> I am also wondering about the identical degree of freedom for all term (except for Year).
> Thanks in advance
>
>
> With regards,
>
> Djibril.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lorenz.gygax at art.admin.ch  Mon Jul 13 09:42:34 2009
From: lorenz.gygax at art.admin.ch (lorenz.gygax at art.admin.ch)
Date: Mon, 13 Jul 2009 09:42:34 +0200
Subject: [R-sig-ME] Multivariate mixed effects model
In-Reply-To: <C67797A4.AB5E%dafshartous@med.miami.edu>
Message-ID: <145C63777EF3ED41A5A99035845F7DD90241D223@EVD-C8001.bk.evdad.admin.ch>

Dear David and others interested,

I am also trying to get to terms with mixed-effects models having several symultaneous outcomes. Thus, I was very pleased to see the Reference that Mareike provided (and slightly disappointed when I saw how little of the publication actually referred to the multiple outcomes - it nevertheless seems/seemed to be a good starting point).

When running a couple of toy examples the following points struck me. I am not quite sure which of those are actually relevant and which ones just seemed odd to me because my understanding of the corresponding math does not reach far enough.

> This approach works fine for simple models, but I don't see how to
> extend to more complex models.

I agree (see below). And my hunch is that we are asking too much and that lme/lmer can not currently be "tricked" into including all aspects of interest to us. This is just not the application, these methods were programmed to deal with.

> A variety of more complex structures can apparently be fit in SAS
> (Gao et al, Fitting Multivariate Longitudinal Data Using SAS, Paper
> 187-31).

As complex as what you are aiming at? What we would like seems way more complex than the standard mixed models ... which explains why the approach in lme/lmer is somewhat limited (or perhaps I am missing something).

> In the context of the pseudo example below, does anyone  know 
> how to do the following?
> ## 1) residual error correlated across variables at the same 
> time point?

This would be one of the main points for running multiple simultaneous outcomes in one model, wouldn't it?

In my view, one would want to have variance-covariance Matrices (or possibly correlation matrices) for all random terms in the model (i.e. random effects and residuals). For that all random terms should end up in Matrices with their number of columns corresponding to the number of outcomes. Whereas this is the case for the random effects - e.g. ranef (mv1.lme) - the residuals are just assumed to be independt resulting in one vector - e.g. resid (mv1.lme).

This is also reflected in the degrees of freedom (were we inclined to rely on them, which, of course, we are not ;-) in that the dfs in such a model result from the total number of rows in the data set and not the number of observations per outcome.

The way to specify correlation structures of the errors in lme is via the corStruct methods. At least with the methods available in the package, it does not seem to be possible to model such a 'block'-structure of covariance (the residuals of the different outcomes co-varying with each other). Some of the pdMat classes might do the trick for random effects but I would not see how these could easily be applied to the residuals.

> ## 2) residual error correlated across variables at different 
> time point? (e.g., AR1)

The following might do the trick:
mv4.lme <- update (mv3.lme,
                   correlation= corAR1 (form= ~ 1 | subject/y1.ind))

(In the more general case with more than two outcomes, y1.ind would need to be replaced by a factor indicating the differen outcomes, i.e. y1.ind, y2.ind, ... "de-dummied", so to speak).

> ## 3) different AR1 coefficient for different variables?

No idea for that, either.
 
> ## basic bivariate model with correlated intercept random-effects
> mv1.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time, 
> random = ~ -1 + y1.ind + y2.ind  | subject,
>             data = data.mv, control=nlmeControl(msMaxIter = 500))
> ## different residual error variance per variable
> mv3.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time, 
> random = ~ -1 + y1.ind + y2.ind  | subject,
>             data = data.mv, control=nlmeControl(msMaxIter = 
> 500), weights = varIdent(form = ~1 | y1.ind))
> 
> ## for comparison, basic model in lmer below, but don't think 
> residual variance extensions above currently available:
> library("lme4")
> mv1.lmer  = lmer(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time 
> +  (0 + y1.ind + y2.ind + y1.time + y2.time | subject) ,
>             data = data.mv)

This includes the random slopes which were not included above, correct?

I am currently thinking about implementing such models in flavour of Bugs and just use the simple but fast methods in lme/lmer as plausibility checks for the more complex models.

Best wishes, Lorenz
- 
Lorenz Gygax
Federal Veterinary Office
Centre for proper housing of ruminants and pigs
CH-8356 Ettenhausen / Switzerland


> ###############
> ## simulated data:
> set.seed(100); n1 = 30; n2 = 4
> library("MASS"); library("nlme")
> y1 = y2 = matrix(0, n2, n1)
> for (i in 1:n1) {
>     b.i = mvrnorm(n = 1, mu = c(0,0), Sigma = matrix(c(3, 1, 
> 1, 6), nrow = 2, ncol = 2)) # correlated random effects
>    for (j in 1:n2) {
>         eps =  mvrnorm(n = 1, mu = c(0,0), Sigma = 
> matrix(c(2, 0, 0, 5), nrow = 2, ncol = 2))  ##  uncorrelated 
> error term
>        y1[j,i] = 4 + 2 * j + b.i[1] + eps[1]  ## fixed 
> intercept and sloped effects + random-intercept
>        y2[j,i] = 25 + 13 * j + b.i[2] + eps[2] }}
> data.mv = data.frame(subject = rep(seq(1,n1), each = n2, 2), 
> time = rep(c(1:n2), n1*2), y = c(as.vector(y1), 
> as.vector(y2)), y1.ind = rep( c(1,0),
>     each = n1*n2), y2.ind = rep( c(0,1), each = n1*n2), 
> y1.time = c(rep(seq(1:4), n1), rep(0, n1*n2)), y2.time = 
> c(rep(0, n1*n2), rep(seq(1,4), n1)))



From madzientist at gmail.com  Tue Jul 14 16:03:00 2009
From: madzientist at gmail.com (Suresh Krishna)
Date: Tue, 14 Jul 2009 16:03:00 +0200
Subject: [R-sig-ME] 2 x 2 x 10 x 2 binomial setup
Message-ID: <op.uw19bau0hgmlxk@osiris.gwdg.de>


Hello,

I posted the query below on r-help and Marc Schwartz graciously pointed me  
to this list.... he said I would likely have to use glmer(), but that I  
should check with the people on this list.

I would be really grateful if you could help me !!

Thanks much, Suresh

===================================================================================================

Hello,

I have a hierarchical dataset of this form and am trying to analyze it in  
R.

1 subject
Tested under 2 conditions: A and B
10 sesssions in each condition
In each session, 2 kinds of tests: Test 1 and Test 2
200 independent repetitions of each test-type, with 200 Yes/No answers

So I think this is a 2 x 2 x 10 x 2 setup

What I want to know is whether the difference in percentage of yes answers  
between Test1 and Test2 is different for the 2 conditions A and B. I guess  
I could also state this as looking for an effect at the highest stratum,  
after correctly pooling over all the lower strata... i.e. Is there an  
"interaction" between the Effect of Condition and the Effect of Test.

I looked through Agresti and Pinheiro/Bates and couldn't find an example  
covering this situation. I would be really grateful if you could suggest a  
way to go about this analysis in R, or a place where I could read about  
this.

I considered:

Pool data from all the sessions for a given condition and test together,  
thus getting 2000 repetitions of Test1 and Test 2 in each condition. Now I  
have a 2x2x2 setup, which maps on to something in Agresti, but then I am  
ignoring within-session correlation information.

I could simply get a difference between Test1 and Test2 percentages for  
each session, and then compare the distribution of these differences in  
conditions A and B (with something like a t-test), but then I only have 10  
points (one for each session) and so I guess I am throwing away a lot of  
information.

Very best,

Suresh



From kagba2006 at yahoo.com  Tue Jul 14 16:57:29 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 14 Jul 2009 07:57:29 -0700 (PDT)
Subject: [R-sig-ME] Problem with GroupedData
Message-ID: <795563.31212.qm@web38301.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090714/e0f90242/attachment.pl>

From danielezrajohnson at gmail.com  Tue Jul 14 17:02:45 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 14 Jul 2009 11:02:45 -0400
Subject: [R-sig-ME] 2 x 2 x 10 x 2 binomial setup
In-Reply-To: <op.uw19bau0hgmlxk@osiris.gwdg.de>
References: <op.uw19bau0hgmlxk@osiris.gwdg.de>
Message-ID: <a46630750907140802i600c683dpdf7c43d4a1124f33@mail.gmail.com>

> 1 subject
> Tested under 2 conditions: A and B
> 10 sesssions in each condition
> In each session, 2 kinds of tests: Test 1 and Test 2
> 200 independent repetitions of each test-type, with 200 Yes/No answers
>
> So I think this is a 2 x 2 x 10 x 2 setup
>
> What I want to know is whether the difference in percentage of yes answers
> between Test1 and Test2 is different for the 2 conditions A and B. I guess I
> could also state this as looking for an effect at the highest stratum, after
> correctly pooling over all the lower strata... i.e. Is there an
> "interaction" between the Effect of Condition and the Effect of Test.

yes, that sounds exactly right, you're testing for the interaction, so

mod1 <- glmer(Response ~ Test*Condition + (1|Session),binomial,data)
mod0 <- glmer(Response ~ Test+Condition + (1|Session),binomial,data)

as far as getting a p-value, that's a debate but you can use
anova(mod0,mod1) as a first approximation?

dan

p.s. make sure you label your sessions correctly to avoid "implicit nesting"...



From orzack at freshpond.org  Wed Jul 15 04:34:26 2009
From: orzack at freshpond.org (orzack)
Date: Tue, 14 Jul 2009 22:34:26 -0400
Subject: [R-sig-ME] predicted values of GLMM
Message-ID: <p06230902c682f025ee5a@[192.168.1.104]>

What do people typically use to plot a predicted trend and its 95% CI 
for a GLMM given the estimates of the fixed effects and their 
standard errors? for a glm, I have been using predict or predict.glm, 
which work nicely. However, these will not work for lmer output.
   I see one previous post about this: 
http://finzi.psych.upenn.edu/R-sig-mixed-models/2009q1/002076.html

many thanks!

S.
-- 
Steven Orzack

The Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA. 02140
617 864-4307

www.freshpond.org



From madzientist at gmail.com  Wed Jul 15 12:15:26 2009
From: madzientist at gmail.com (Suresh Krishna)
Date: Wed, 15 Jul 2009 12:15:26 +0200
Subject: [R-sig-ME] 2 x 2 x 10 x 2 binomial setup
In-Reply-To: <a46630750907140802i600c683dpdf7c43d4a1124f33@mail.gmail.com>
References: <op.uw19bau0hgmlxk@osiris.gwdg.de>
	<a46630750907140802i600c683dpdf7c43d4a1124f33@mail.gmail.com>
Message-ID: <op.uw3tf0dzhgmlxk@osiris.gwdg.de>



On Tue, 14 Jul 2009 17:02:45 +0200, Daniel Ezra Johnson  
<danielezrajohnson at gmail.com> wrote:

>> 1 subject
>> Tested under 2 conditions: A and B
>> 10 sesssions in each condition
>> In each session, 2 kinds of tests: Test 1 and Test 2
>> 200 independent repetitions of each test-type, with 200 Yes/No answers
>>
>> So I think this is a 2 x 2 x 10 x 2 setup
>>
>> What I want to know is whether the difference in percentage of yes  
>> answers
>> between Test1 and Test2 is different for the 2 conditions A and B. I  
>> guess I
>> could also state this as looking for an effect at the highest stratum,  
>> after
>> correctly pooling over all the lower strata... i.e. Is there an
>> "interaction" between the Effect of Condition and the Effect of Test.
>
> yes, that sounds exactly right, you're testing for the interaction, so
>
> mod1 <- glmer(Response ~ Test*Condition + (1|Session),binomial,data)
> mod0 <- glmer(Response ~ Test+Condition + (1|Session),binomial,data)
>
> as far as getting a p-value, that's a debate but you can use
> anova(mod0,mod1) as a first approximation?


Dan, Thank you very much !!

Just to finish the picture, how would the call to glmer look if I had 2  
subjects instead of one, and wanted to pool everything together, taking  
into account the subject factor (instead of doing separate tests for each  
subject) ?

Very best, Suresh



From a.beckerman at sheffield.ac.uk  Wed Jul 15 15:14:05 2009
From: a.beckerman at sheffield.ac.uk (Andrew Beckerman)
Date: Wed, 15 Jul 2009 14:14:05 +0100
Subject: [R-sig-ME] nlmer error: ...coercing "labelled" to "CsparseMatrix"
Message-ID: <06123050-B40F-4547-8C70-A55A6C772851@sheffield.ac.uk>

Dear list -

R 2.9.1, OSX

I am trying to re-fit an old nlme model of mine using nlmer, but  
getting an error about labels and the CsparseMatrix.

The data are in the following form

 > head(induct)
    clone    id trt ind  ind.adj
1 barney 0.1a1 0.1  30 21.42858
2 barney 0.1a2 0.1  65 46.42858
3 barney 0.1a3 0.1  30 21.42858
4 barney 0.1a4 0.1  60 42.85715
5 barney 0.1a5 0.1  70 50.00001
6 barney 0.1b1 0.1  60 42.85715

The nlme model was fit via the following, which works well:

#grouped data
gd1<-groupedData(ind.adj~trt|clone,data=induct)

# SS starting values
Asym<-50
xmid<-0.25
scale<-1

induction<-nlsList(ind.adj~SSlogis(trt,Asym,xmid,scale)|clone,gd1)
nlc <- nlmeControl(maxIter = 25)
m1<-nlme(induction,random=pdDiag(Asym+xmid+scale~1),control=nlc)

My attempt at fitting with nlmer, ignoring the groupedData object,  
with a single random effect in the Asymptote and with nlme detached, is:

induction.lme4<-nlmer(ind.adj~SSlogis(trt,Asym,xmid,scal)~Asym|clone,
	data=induct,
	start=c(Asym=50,xmid=0.25,scal=1))

Which is resulting in the following error message and traceback.  Any  
insight, or requests for more of the data graciously accepted.

 > induction.lme4<-nlmer(ind.adj~SSlogis(trt,Asym,xmid,scal)~Asym| 
clone,data=induct,start=c(Asym=50,xmid=0.25,scal=1))
Error in as(from, "CsparseMatrix") :
   no method or default for coercing "labelled" to "CsparseMatrix"

 > traceback()
8: stop(gettextf("no method or default for coercing \"%s\" to \"%s\"",
        thisClass, Class), domain = NA)
7: as(from, "CsparseMatrix")
6: asMethod(object)
5: as(ff, "sparseMatrix")
4: FUN(X[[1L]], ...)
3: lapply(bars, function(x) {
        ff <- eval(substitute(as.factor(fac)[, drop = TRUE], list(fac  
= x[[3]])),
            mf)
        im <- as(ff, "sparseMatrix")
        if (!isTRUE(validObject(im, test = TRUE)))
            stop("invalid conditioning factor in random effect: ",
                format(x[[3]]))
        mm <- model.matrix(eval(substitute(~expr, list(expr = x[[2]]))),
            mf)
        if (rmInt) {
            if (is.na(icol <- match("(Intercept)", colnames(mm))))
                break
            if (ncol(mm) < 2)
                stop("lhs of a random-effects term cannot be an  
intercept only")
            mm <- mm[, -icol, drop = FALSE]
        }
        ans <- list(f = ff, A = do.call(rBind, lapply(seq_len(ncol(mm)),
            function(j) im)), Zt = do.call(rBind,  
lapply(seq_len(ncol(mm)),
            function(j) {
                im at x <- mm[, j]
                im
            })), ST = matrix(0, ncol(mm), ncol(mm), dimnames =  
list(colnames(mm),
            colnames(mm))))
        if (drop) {
            ans$A at x <- rep(0, length(ans$A at x))
            ans$Zt <- drop0(ans$Zt)
        }
        ans
    })
2: lmerFactorList(substitute(foo ~ bar, list(foo = nlform[[2]],
        bar = formula[[3]])), fr, TRUE, TRUE)
1: nlmer(ind.adj ~ SSlogis(trt, Asym, xmid, scal) ~ Asym | clone,
        data = induct, start = c(Asym = 50, xmid = 0.25, scal = 1))


---------------------------------------------------------------------------------
Dr. Andrew Beckerman
Department of Animal and Plant Sciences, University of Sheffield,
Alfred Denny Building, Western Bank, Sheffield S10 2TN, UK
ph +44 (0)114 222 0026; fx +44 (0)114 222 0002
http://www.beckslab.staff.shef.ac.uk/

http://www.flickr.com/photos/apbeckerman/
http://www.warblefly.co.uk



From Djibril.Dayamba at ess.slu.se  Thu Jul 16 10:43:46 2009
From: Djibril.Dayamba at ess.slu.se (Djibril Dayamba)
Date: Thu, 16 Jul 2009 10:43:46 +0200
Subject: [R-sig-ME] Problem with convergence, please help
In-Reply-To: <2ad0cc110907121301o32d684f8vc7e18fbd38fb71e1@mail.gmail.com>
References: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
	<2ad0cc110907121301o32d684f8vc7e18fbd38fb71e1@mail.gmail.com>
Message-ID: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD451@exmbx1.ad.slu.se>

Hello,
Thanks a lot Kingsford for all your help. I went through the process step by step and my model kept improving. Fitting the Model with correlation structure corAR1(form=~Year) gave the smaller AIC but when checking the model there was a trend in the spread of the residuals. I then tried to account for the heterogeneity using varIdent as specified in the model below. 

lme(BA.130~Grazing*Fire*Year,random=~Year|Plot,correlation=corAR1(form=~Year), weights=varIdent(form=~1|Plot),na.action=na.omit)

But this model could not work and I got an error message about convergence (see below).

Error in lme.formula(BA.130 ~ Grazing * Fire * Year, random = ~Year |  : 
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (9)

Since then I have been reading but could not get the point. Could anyone tell me something about this problem and how it could be solved? Thanks in advance.

With regards,

Djibril.

 

-----Original Message-----
From: Kingsford Jones [mailto:kingsfordjones at gmail.com] 
Sent: den 12 juli 2009 22:01
To: Djibril Dayamba
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Need some advice on my model specification

Hi Djibril,

The model is overspecified.  I strongly suspect a call of
intervals(Model) will throw an error, or possibly produce intervals of
infinite width.  A more likely candidate is:

Model <- lme(BA.B ~ Grazing*Fire + Year, data = <your data>,
    random = ~<random intercept and possible linear and quadratic slopes>|Plot,
    correlation = corAR1(form=~Year|Plot), weights = <possible
heterogeneity structure>)

Without being familiar with the data this is of course only a suggestion.

One strategy is to start with the fit with no correlation structure
and explore residual temporal correlation within plots using the ACF
function and its plot method, choosing a structure, fitting it, and
repeating the exploration.  The same can be done for variance
structures with the weights argument.  The following link (and P&B
2000) will suggest plots for exploration:

http://bm2.genes.nig.ac.jp/RGM2/index.php?query=nlme

As I mentioned in reply to your r-help post there are a variety of
tricky issues surrounding inference; nonetheless, if you carefully
build your linear model, checking that you are reasonably meeting
normality assumptions (for errors and random effects), and using the
lme arguments to structure error covariance so as to account for lack
of independence and heterogeneity of variance, you will have results
that should be quite defensible to reviewers.

best of luck,

Kingsford


On Sun, Jul 12, 2009 at 11:43 AM, Djibril
Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
> Hello,
> I previously wrote to R-help, I got some advices and was kindly redirected by Kingsford to this specific Help-list (mixed models) for further questions. Since then I have moved a bit but I still have some points where I would appreciate having clarification.
>
> I have a factorial experiment ( with 4 repetitions for each treatment combination) to study the effects of Grazing and Fire on Forest biomass production. The experimental unit (to which the treatment combinations are applied) are PLOTs. The measures were made repeatedly for 13 years. Below is how I organized my data; Plot is the plot naming in the field; BA.B is the response variable (Basal area) I am using to express myself here
>
>
> Grazing ? ? ? ? ? ? Fire ? ? ? ? ? ? ? ? ? ? Plot ? ? ? ? ? ? ? ? ? ? Year ? ? ? ? ? ? ? ? ? ?BA.B
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 398.13
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 4728.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2092.05
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? ? ? 3076.70
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? ? ? 2578.54
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? ? ? 2541.07
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? ? ? 3191.61
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? ? ? 2526.75
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ? ? ? 3665.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? ? ? ? ? ? ? ? ?3077.42
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?11 ? ? ? ? ? ? ? ? ? ? ? ?3911.63
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?12 ? ? ? ? ? ? ? ? ? ? ? ?4067.28
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?13 ? ? ? ? ? ? ? ? ? ? ? ?4457.94
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 370.99
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 2184.39
> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2008.66
> .
> .
> .
> .
> .
>
> I fitted the below model to account for the temporal autocorrelation and the variance heterogeneity. I also have a missing value.
>
> Model<-lme(BA.B~Grazing*Fire*Year, random=~1|Year/Plot/Fire/Grazing, correlation=corAR1(form=~Year), weights=varIdent(form=~1|Grazing*Fire*Year), na.action=na.omit)
>
> For the random effect I got something like this
>
> Random effects:
> ?Formula: ~1 | Year
> ? ? ? ?(Intercept)
> StdDev: ? ?234.6285
>
> ?Formula: ~1 | Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?67.01272
>
> ?Formula: ~1 | Fire %in% Plot %in% Year
> ? ? ? ?(Intercept)
> StdDev: ? ?66.80442
>
> ?Formula: ~1 | Grazing %in% Fire %in% Plot %in% Year
> ? ? ? ?(Intercept) Residual
> StdDev: ? ?66.83408 ? ? ? ? ? 153.0221
>
>
> For the correlation structure, the Phi value is 0 (zero)
>
> Correlation Structure: AR(1)
> ?Formula: ~Year | Year/Plot/Fire/Grazing
> ?Parameter estimate(s):
> Phi
> ?0
>
> For the fixed effects, please note the identical degree of freedom for every term (except Year)
>
> Fixed effects: BA.B ~ Grazing * Fire * Year
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Value ? ? ? ? ? ? ? ? ? Std.Error ? ? ? DF ? ? ? ? ? ? ? ? t-value ? ? ? ? ? p-value
> (Intercept) ? ? ? ? ? ? ? ? ? ? ? 461.4655 ? ? ? ? ?178.15612 ? ? 396 ? ? ? ? ? ? ? ?2.590231 ? ? ? 0.0099
> GrazingUngrazed ? ? ? ? ? ? ? ? ?-180.1041 ? 104.88596 ? ? 396 ? ? ? ? ? ? ? ?-1.717143 ? ? ?0.0867
> FireUnburnt ? ? ? ? ? ? ? ? ? ? ?-236.3691 ? ? ? 124.54654 ? ? 396 ? ? ? ? ? ? ? ?-1.897837 ? ? ?0.0584
> Year ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?410.9426 ? ? ? ? ? ? 31.68234 ? ? ? 11 ? ? ? ? ? ? ? ? ?12.970718 ? ? 0.0000
> GrazingUngrazed:FireUnburnt 224.5099 153.17048 ? ?396 ? ? ? ? ? ? ? ?1.465752 ? ? ? 0.1435
> GrazingUngrazed:Year ? ? ? ? -104.4984 ?28.99989 ? ? ? 396 ? ? ? ? ? ? ? ?-3.603406 ? ? ?0.0004
> FireUnburnt:Year ? ? ? ? ? ? ? ? ?-21.3375 ? ? 38.52046 ? ? ? 396 ? ? ? ? ? ? ? ?-0.553927 ? ? ?0.5799
> GrazingUngrazed:FireUnburnt:Year 85.2475 ?44.47663 ? 396 ? ? ? ? ? 1.916680 ? ? ? 0.0560
>
>
> My concern is:
> Does my model specification looks ok?
> Is Phi = 0 real and what does this mean (in all case studies I have seen, it had value different from zero)?
> I am also wondering about the identical degree of freedom for all term (except for Year).
> Thanks in advance
>
>
> With regards,
>
> Djibril.
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kagba2006 at yahoo.com  Thu Jul 16 13:19:55 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 16 Jul 2009 04:19:55 -0700 (PDT)
Subject: [R-sig-ME] plot problem
Message-ID: <529755.85606.qm@web38305.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090716/7f17b1e5/attachment.pl>

From datkins at u.washington.edu  Thu Jul 16 18:01:15 2009
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 16 Jul 2009 09:01:15 -0700
Subject: [R-sig-ME] over-dispersed Poisson with lmer -- a trick,
	with a catch?
Message-ID: <4A5F4ECB.1070801@u.washington.edu>


Hi all--

I'm currently working on analyses of longitudinal count data (number of 
drinking related problems over 2 years in a randomized trial for alcohol 
interventions).

The data are pretty clearly over-dispersed relative to Poisson, which is 
  clear when I fit the model using MCMCglmm, which includes a residual 
error term to account for over-dispersion (thank you, Jarrod!).

However, I'm collaborating with a colleague who uses Stata.  He 
mentioned that Sophia Rabe-Hesketh in her mixed-models book discusses 
fitting over-dispersed Poisson mixed-effects models using the following 
"trick":

Create a new variable with a unique value for each observation and 
include this as an additional random-effect term.

Basically, this will soak up any residual dispersion, over and above 
that accounted for in Poisson model and other random-effects.  On the 
face of it, it makes sense to me.  Though, we hit a snag in trying to do 
this in lmer().  Using the data that I have been analyzing:

### create new var with unique value for each obs/row
 > snap.df$over <- 1:nrow(snap.df)

### include as separate random-effect in model
 > rapi.glmer2.1 <- glmer(rapisum ~ asex*time + (time|ID) + (1|over),
+ 					data = snap.df, verbose = TRUE,
+ 					family = poisson)
Error in mer_finalize(ans) : q = 5252 > n = 3616

So, we already have a random intercept and slope for time [ie, 
(time|ID)].  With 818 participants the random-effects specify 818 
intercepts plus 818 slopes, and now with an observation level 
random-effect [ie, (1|over)] with 3616 observations... we get 5252 
estimates.  lmer() doesn't like it.

I know there's been a bit of chatter about this error before, and I 
believe Doug mentioned that it was to avoid people radically 
over-parameterizing/over-fitting their data via random-effects.  Though, 
I believe there is some room for debate (ie, the model above does not 
fit 5252 unique parameters).

Anyhow, I would be curious for any input on:

1. Does this seem like a sensible approach to account for 
over-dispersion?  (caveat: I don't have Rabe-Hesketh's book, so just 
going on recounting from colleague)

2. If so, I wonder if we might be able to coax Doug to change the error 
to an argument in the model (that defaults to the error msg but could be 
over-ridden)?

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



From bolker at ufl.edu  Thu Jul 16 18:09:24 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 16 Jul 2009 12:09:24 -0400
Subject: [R-sig-ME] over-dispersed Poisson with lmer -- a trick,
 with a catch?
In-Reply-To: <4A5F4ECB.1070801@u.washington.edu>
References: <4A5F4ECB.1070801@u.washington.edu>
Message-ID: <4A5F50B4.8060203@ufl.edu>

David Atkins wrote:

[snip]

> ### create new var with unique value for each obs/row
>  > snap.df$over <- 1:nrow(snap.df)
> 
> ### include as separate random-effect in model
>  > rapi.glmer2.1 <- glmer(rapisum ~ asex*time + (time|ID) + (1|over),
> + 					data = snap.df, verbose = TRUE,
> + 					family = poisson)
> Error in mer_finalize(ans) : q = 5252 > n = 3616
> 
> So, we already have a random intercept and slope for time [ie, 
> (time|ID)].  With 818 participants the random-effects specify 818 
> intercepts plus 818 slopes, and now with an observation level 
> random-effect [ie, (1|over)] with 3616 observations... we get 5252 
> estimates.  lmer() doesn't like it.
> 
> I know there's been a bit of chatter about this error before, and I 
> believe Doug mentioned that it was to avoid people radically 
> over-parameterizing/over-fitting their data via random-effects.  Though, 
> I believe there is some room for debate (ie, the model above does not 
> fit 5252 unique parameters).
> 
> Anyhow, I would be curious for any input on:
> 
> 1. Does this seem like a sensible approach to account for 
> over-dispersion?  (caveat: I don't have Rabe-Hesketh's book, so just 
> going on recounting from colleague)

  I think so.  It's done in other places (for example, it's exactly
equivalent to what MCMCglmm does), and in Elston et al 2001 (they use a
PQL estimation procedure in Genstat).  (Although "everybody does it"
doesn't *mean* it's correct ...)

> 2. If so, I wonder if we might be able to coax Doug to change the error 
> to an argument in the model (that defaults to the error msg but could be 
> over-ridden)?

  Good luck with that ...

  If you can conveniently build from source, you can just comment out
line 1068 (search for "> n =") in lmer.c ...

  cheers
    Ben


Elston, D.A., Moss, R., Boulinier, T., Arrowsmith, C. & Lambin, X.
(2001) Analysis of aggregation, a worked example: numbers of ticks on
red grouse chicks. Parasitology, 122, 563-569.

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From datkins at u.washington.edu  Thu Jul 16 18:21:23 2009
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 16 Jul 2009 09:21:23 -0700
Subject: [R-sig-ME] over-dispersed Poisson with lmer -- a trick,
 with a catch?
In-Reply-To: <4A5F5127.1050202@ufl.edu>
References: <4A5F4ECB.1070801@u.washington.edu> <4A5F5127.1050202@ufl.edu>
Message-ID: <4A5F5383.7070203@u.washington.edu>



Ben Bolker wrote:
>   PS -- if MCMCglmm works, why not stop there?  Do you absolutely need
> it to work in lme4?

Ben--

Thanks for the comments (and, yes, I am very hesitant to ever request 
anything from Doug given the Herculean amount of work he has put into 
developing lmer()... suppose I should take this opportunity to learn how 
to build from sources).

As for the comment above, on the one hand, you're right.  We've got a 
solution that works.  Moreover, a lot of our addictions data is 
zero-inflated, and MCMCglmm() can handle that as well (again, thank you 
Jarrod!).

However, I've been using lme/lmer for 12 years and am really comfortable 
with it.  In addition, it's sssssmoking fast, and some of our problems 
get large.  An alternative model with daily drinking reports for past 90 
days on several hundred participants took a couple hours to fit in 
MCMCglmm().  Now, it's great that we can fit the model, but speed does 
count for something.

[Actually, as an aside, my colleague who uses Stata called me while the 
over-dispersed model was running in Stata, "Eh, Dave, this is going to 
take a while in Stata, any chance you could fit this in R?" ;)]

cheers, Dave

Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



From otter at otter-rsch.com  Thu Jul 16 19:07:35 2009
From: otter at otter-rsch.com (dave fournier)
Date: Thu, 16 Jul 2009 10:07:35 -0700
Subject: [R-sig-ME] over-dispersed Poisson with lmer -- a trick,
 with a catch?
In-Reply-To: <4A5F4ECB.1070801@u.washington.edu>
References: <4A5F4ECB.1070801@u.washington.edu>
Message-ID: <4A5F5E57.2050901@otter-rsch.com>

Hi,

Instead of "tricks", why don't you just fit a negative binomial mixed
model. That should deal with the over-dispersion. You can do this with
AD Model Builder's random effects package which is now freely available
at http://admb-project.org.

    Dave

-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From bolker at UFL.EDU  Thu Jul 16 18:11:19 2009
From: bolker at UFL.EDU (Ben Bolker)
Date: Thu, 16 Jul 2009 12:11:19 -0400
Subject: [R-sig-ME] over-dispersed Poisson with lmer -- a trick,
 with a catch?
In-Reply-To: <4A5F4ECB.1070801@u.washington.edu>
References: <4A5F4ECB.1070801@u.washington.edu>
Message-ID: <4A5F5127.1050202@ufl.edu>


  PS -- if MCMCglmm works, why not stop there?  Do you absolutely need
it to work in lme4?



From kingsfordjones at gmail.com  Fri Jul 17 00:17:01 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Thu, 16 Jul 2009 16:17:01 -0600
Subject: [R-sig-ME] Problem with convergence, please help
In-Reply-To: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD451@exmbx1.ad.slu.se>
References: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
	<2ad0cc110907121301o32d684f8vc7e18fbd38fb71e1@mail.gmail.com>
	<C1CE865EFF7A544789C6C7C46FEF264A3806CDD451@exmbx1.ad.slu.se>
Message-ID: <2ad0cc110907161517p3e400330gc8798a3884c61354@mail.gmail.com>

It's a complex model with algorithms trying to optimize many estimates
together:  random intercept and slope, residual variances within each
plot and AR1 correlation parameter for points across years, as well as
the 8? fixed effects.  Fitting residual covariance structures is
particularly tricky, and you're structuring diagonals and
off-diagonals, so it's not too surprising you've run into a
convergence problem.

As for solutions, take a look at the 'control' argument to lme, and
the lmeControl function.  At a minimum, try increasing the number of
iterations (maxIter=<something more than 50>) and set msVerbose=TRUE
to view progress during iterations.  If the algorithm is having
trouble with the varFunc or corStruct classes, you can use the 'value'
argument to specify starting values (e.g. correlation = corAR1(value =
.6, form = ~Year)).  You can also try simpler structures; e.g.,
weights = varPower(form =~fitted(.)) for the situation where variance
increases with the predicted response.

And of course P&B is the place to look for details...

hth,
Kingsford

On Thu, Jul 16, 2009 at 2:43 AM, Djibril
Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
> Hello,
> Thanks a lot Kingsford for all your help. I went through the process step by step and my model kept improving. Fitting the Model with correlation structure corAR1(form=~Year) gave the smaller AIC but when checking the model there was a trend in the spread of the residuals. I then tried to account for the heterogeneity using varIdent as specified in the model below.
>
> lme(BA.130~Grazing*Fire*Year,random=~Year|Plot,correlation=corAR1(form=~Year), weights=varIdent(form=~1|Plot),na.action=na.omit)
>
> But this model could not work and I got an error message about convergence (see below).
>
> Error in lme.formula(BA.130 ~ Grazing * Fire * Year, random = ~Year | ?:
> ?nlminb problem, convergence error code = 1
> ?message = iteration limit reached without convergence (9)
>
> Since then I have been reading but could not get the point. Could anyone tell me something about this problem and how it could be solved? Thanks in advance.
>
> With regards,
>
> Djibril.
>
>
>
> -----Original Message-----
> From: Kingsford Jones [mailto:kingsfordjones at gmail.com]
> Sent: den 12 juli 2009 22:01
> To: Djibril Dayamba
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Need some advice on my model specification
>
> Hi Djibril,
>
> The model is overspecified. ?I strongly suspect a call of
> intervals(Model) will throw an error, or possibly produce intervals of
> infinite width. ?A more likely candidate is:
>
> Model <- lme(BA.B ~ Grazing*Fire + Year, data = <your data>,
> ? ?random = ~<random intercept and possible linear and quadratic slopes>|Plot,
> ? ?correlation = corAR1(form=~Year|Plot), weights = <possible
> heterogeneity structure>)
>
> Without being familiar with the data this is of course only a suggestion.
>
> One strategy is to start with the fit with no correlation structure
> and explore residual temporal correlation within plots using the ACF
> function and its plot method, choosing a structure, fitting it, and
> repeating the exploration. ?The same can be done for variance
> structures with the weights argument. ?The following link (and P&B
> 2000) will suggest plots for exploration:
>
> http://bm2.genes.nig.ac.jp/RGM2/index.php?query=nlme
>
> As I mentioned in reply to your r-help post there are a variety of
> tricky issues surrounding inference; nonetheless, if you carefully
> build your linear model, checking that you are reasonably meeting
> normality assumptions (for errors and random effects), and using the
> lme arguments to structure error covariance so as to account for lack
> of independence and heterogeneity of variance, you will have results
> that should be quite defensible to reviewers.
>
> best of luck,
>
> Kingsford
>
>
> On Sun, Jul 12, 2009 at 11:43 AM, Djibril
> Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
>> Hello,
>> I previously wrote to R-help, I got some advices and was kindly redirected by Kingsford to this specific Help-list (mixed models) for further questions. Since then I have moved a bit but I still have some points where I would appreciate having clarification.
>>
>> I have a factorial experiment ( with 4 repetitions for each treatment combination) to study the effects of Grazing and Fire on Forest biomass production. The experimental unit (to which the treatment combinations are applied) are PLOTs. The measures were made repeatedly for 13 years. Below is how I organized my data; Plot is the plot naming in the field; BA.B is the response variable (Basal area) I am using to express myself here
>>
>>
>> Grazing ? ? ? ? ? ? Fire ? ? ? ? ? ? ? ? ? ? Plot ? ? ? ? ? ? ? ? ? ? Year ? ? ? ? ? ? ? ? ? ?BA.B
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 398.13
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 4728.54
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2092.05
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? ? ? 3076.70
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? ? ? 2578.54
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? ? ? 2541.07
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? ? ? 3191.61
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? ? ? 2526.75
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ? ? ? 3665.42
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? ? ? ? ? ? ? ? ?3077.42
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?11 ? ? ? ? ? ? ? ? ? ? ? ?3911.63
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?12 ? ? ? ? ? ? ? ? ? ? ? ?4067.28
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?13 ? ? ? ? ? ? ? ? ? ? ? ?4457.94
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 370.99
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 2184.39
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2008.66
>> .
>> .
>> .
>> .
>> .
>>
>> I fitted the below model to account for the temporal autocorrelation and the variance heterogeneity. I also have a missing value.
>>
>> Model<-lme(BA.B~Grazing*Fire*Year, random=~1|Year/Plot/Fire/Grazing, correlation=corAR1(form=~Year), weights=varIdent(form=~1|Grazing*Fire*Year), na.action=na.omit)
>>
>> For the random effect I got something like this
>>
>> Random effects:
>> ?Formula: ~1 | Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?234.6285
>>
>> ?Formula: ~1 | Plot %in% Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?67.01272
>>
>> ?Formula: ~1 | Fire %in% Plot %in% Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?66.80442
>>
>> ?Formula: ~1 | Grazing %in% Fire %in% Plot %in% Year
>> ? ? ? ?(Intercept) Residual
>> StdDev: ? ?66.83408 ? ? ? ? ? 153.0221
>>
>>
>> For the correlation structure, the Phi value is 0 (zero)
>>
>> Correlation Structure: AR(1)
>> ?Formula: ~Year | Year/Plot/Fire/Grazing
>> ?Parameter estimate(s):
>> Phi
>> ?0
>>
>> For the fixed effects, please note the identical degree of freedom for every term (except Year)
>>
>> Fixed effects: BA.B ~ Grazing * Fire * Year
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Value ? ? ? ? ? ? ? ? ? Std.Error ? ? ? DF ? ? ? ? ? ? ? ? t-value ? ? ? ? ? p-value
>> (Intercept) ? ? ? ? ? ? ? ? ? ? ? 461.4655 ? ? ? ? ?178.15612 ? ? 396 ? ? ? ? ? ? ? ?2.590231 ? ? ? 0.0099
>> GrazingUngrazed ? ? ? ? ? ? ? ? ?-180.1041 ? 104.88596 ? ? 396 ? ? ? ? ? ? ? ?-1.717143 ? ? ?0.0867
>> FireUnburnt ? ? ? ? ? ? ? ? ? ? ?-236.3691 ? ? ? 124.54654 ? ? 396 ? ? ? ? ? ? ? ?-1.897837 ? ? ?0.0584
>> Year ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?410.9426 ? ? ? ? ? ? 31.68234 ? ? ? 11 ? ? ? ? ? ? ? ? ?12.970718 ? ? 0.0000
>> GrazingUngrazed:FireUnburnt 224.5099 153.17048 ? ?396 ? ? ? ? ? ? ? ?1.465752 ? ? ? 0.1435
>> GrazingUngrazed:Year ? ? ? ? -104.4984 ?28.99989 ? ? ? 396 ? ? ? ? ? ? ? ?-3.603406 ? ? ?0.0004
>> FireUnburnt:Year ? ? ? ? ? ? ? ? ?-21.3375 ? ? 38.52046 ? ? ? 396 ? ? ? ? ? ? ? ?-0.553927 ? ? ?0.5799
>> GrazingUngrazed:FireUnburnt:Year 85.2475 ?44.47663 ? 396 ? ? ? ? ? 1.916680 ? ? ? 0.0560
>>
>>
>> My concern is:
>> Does my model specification looks ok?
>> Is Phi = 0 real and what does this mean (in all case studies I have seen, it had value different from zero)?
>> I am also wondering about the identical degree of freedom for all term (except for Year).
>> Thanks in advance
>>
>>
>> With regards,
>>
>> Djibril.
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From Christine.Griffiths at bristol.ac.uk  Sat Jul 18 14:58:36 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Sat, 18 Jul 2009 13:58:36 +0100
Subject: [R-sig-ME] Too small a sample size for lmer?
Message-ID: <F31561C5673B2B2D28591BAC@bio-mammal026.bio.bris.ac.uk>

Dear R users,

Many of you may be familiar with my design as I have posted a number of 
queries before. Having consulted with someone in my department about 
estimating bias corrected confidence intervals for small sample sizes 
(rather than MCMC which Baayen et al. 2008 suggest should not be used), 
they implied that I should not be using lmer for such a small sample size 
as lmer was designed to deal with very large datasets. Is this still the 
case? If so what is regarded as a small sample size?

Below is a description of my data. I have 5/6 enclosures (replicates) per 
treatment - Aldabra/Radiata/control. Aldabra and radiata refer to two 
different tortoise species, while control lacks tortoises. The enclosures 
were assigned to a block: a block containing each of the 3 treatments, i.e. 
6 blocks in total. Each month for ten months I collected data: a repeated 
crossed design. Unfortunately, I have non-orthogonal, unbalanced data (5/6 
enclosures per treatment) as I cannot use a replicate within the aldabra 
and radiata treatments. These are however from different blocks so I am 
reluctant to axe them to achieve balanced data as this would leave me only 
4 blocks. I measured various attributes which I think that tortoises would 
have an impact on, e.g. plant count, species richness. Because my data is 
unbalanced and a repeated measures design I had chosen lmer to best model 
this.

For one other aspect, I calculate food web properties, for which I have no 
replication, i.e. only one observation per treatment per month. Would lmer 
be an acceptable way to analyse this data?

If lmer is not advised for the analyses of these data, what other analyses 
techniques should I investigate?

Baayen et al. (2008)Mixed-effects modeling with crossed random effects
for subjects and items. Journal of Memory and Language, 59, 390-412.

Many thanks,
Christine



From maechler at stat.math.ethz.ch  Sat Jul 18 16:59:00 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 18 Jul 2009 16:59:00 +0200
Subject: [R-sig-ME] Too small a sample size for lmer?
In-Reply-To: <F31561C5673B2B2D28591BAC@bio-mammal026.bio.bris.ac.uk>
References: <F31561C5673B2B2D28591BAC@bio-mammal026.bio.bris.ac.uk>
Message-ID: <19041.58164.202262.729052@cmath-5.math.ethz.ch>

>>>>> "CG" == Christine Griffiths <Christine.Griffiths at bristol.ac.uk>
>>>>>     on Sat, 18 Jul 2009 13:58:36 +0100 writes:

    CG> Dear R users,
    CG> Many of you may be familiar with my design as I have posted a number of 
    CG> queries before. Having consulted with someone in my department about 
    CG> estimating bias corrected confidence intervals for small sample sizes 
    CG> (rather than MCMC which Baayen et al. 2008 suggest should not be used), 
    CG> they implied that I should not be using lmer for such a small sample size 
    CG> as lmer was designed to deal with very large datasets. Is this still the 
    CG> case? If so what is regarded as a small sample size?

The fact that it was designed *to be able* to deal with big data
sets does not mean that it was not appropriate for small data
sets as well.
It's just that mixed effect models with large data sets an
crossed random effects really currently can *only* be
analyzed with lmer {no other software available, not even if you
pay much}.

Said all that, I think your situation looks like a case where I
would want to use (probably a parametric) bootstrap,
and interestingly enough, at the UseR! 2009 meeting in Rennes,
10 days ago, there was a nice talk on this topic:

   Jose A. Sanchez-Espigares, Jordi Oca?a 	 
   An R implementation of bootstrap procedures for mixed models 

You can find the abstract *and* slides on
  http://www.agrocampus-ouest.fr/math/useR-2009/abstracts/user_author.html

I don't think that their R code is already publicly available,
but I've CC'ed one of the authors, and they may be willing to
let you use their code before release.

Martin Maechler, ETH Zurich

    CG> Below is a description of my data. I have 5/6 enclosures (replicates) per 
    CG> treatment - Aldabra/Radiata/control. Aldabra and radiata refer to two 
    CG> different tortoise species, while control lacks tortoises. The enclosures 
    CG> were assigned to a block: a block containing each of the 3 treatments, i.e. 
    CG> 6 blocks in total. Each month for ten months I collected data: a repeated 
    CG> crossed design. Unfortunately, I have non-orthogonal, unbalanced data (5/6 
    CG> enclosures per treatment) as I cannot use a replicate within the aldabra 
    CG> and radiata treatments. These are however from different blocks so I am 
    CG> reluctant to axe them to achieve balanced data as this would leave me only 
    CG> 4 blocks. I measured various attributes which I think that tortoises would 
    CG> have an impact on, e.g. plant count, species richness. Because my data is 
    CG> unbalanced and a repeated measures design I had chosen lmer to best model 
    CG> this.

    CG> For one other aspect, I calculate food web properties, for which I have no 
    CG> replication, i.e. only one observation per treatment per month. Would lmer 
    CG> be an acceptable way to analyse this data?

    CG> If lmer is not advised for the analyses of these data, what other analyses 
    CG> techniques should I investigate?

    CG> Baayen et al. (2008)Mixed-effects modeling with crossed random effects
    CG> for subjects and items. Journal of Memory and Language, 59, 390-412.

    CG> Many thanks,
    CG> Christine



From bolker at ufl.edu  Sat Jul 18 19:18:50 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 18 Jul 2009 13:18:50 -0400
Subject: [R-sig-ME] Too small a sample size for lmer?
In-Reply-To: <19041.58164.202262.729052@cmath-5.math.ethz.ch>
References: <F31561C5673B2B2D28591BAC@bio-mammal026.bio.bris.ac.uk>
	<19041.58164.202262.729052@cmath-5.math.ethz.ch>
Message-ID: <4A6203FA.6070508@ufl.edu>


  Why do Baayen et al 2008 recommend against MCMC?  Do you mean mcmcsamp
 (which may or may not be unreliable in this incarnation, I don't know)
or MCMC in general?  I tried to find it in the paper -- do you mean for
variance parameters (where the zero component gets in the way)?

  Your response variables are also interesting -- unless both plant
count and species richness are large numbers, they'll probably have
non-normal distributions, which adds to complication (it is possible,
but not really really easy, to deal with overdispersed [negative
binomial / log-normal-Poisson / quasi-Poisson ] count data in glmer, and
species richness often has quite an odd distribution depending on the
characteristics of the "regional species pool" ...)

  Ben Bolker


Martin Maechler wrote:
>>>>>> "CG" == Christine Griffiths <Christine.Griffiths at bristol.ac.uk>
>>>>>>     on Sat, 18 Jul 2009 13:58:36 +0100 writes:
> 
>     CG> Dear R users,
>     CG> Many of you may be familiar with my design as I have posted a number of 
>     CG> queries before. Having consulted with someone in my department about 
>     CG> estimating bias corrected confidence intervals for small sample sizes 
>     CG> (rather than MCMC which Baayen et al. 2008 suggest should not be used), 
>     CG> they implied that I should not be using lmer for such a small sample size 
>     CG> as lmer was designed to deal with very large datasets. Is this still the 
>     CG> case? If so what is regarded as a small sample size?
> 
> The fact that it was designed *to be able* to deal with big data
> sets does not mean that it was not appropriate for small data
> sets as well.
> It's just that mixed effect models with large data sets an
> crossed random effects really currently can *only* be
> analyzed with lmer {no other software available, not even if you
> pay much}.
> 
> Said all that, I think your situation looks like a case where I
> would want to use (probably a parametric) bootstrap,
> and interestingly enough, at the UseR! 2009 meeting in Rennes,
> 10 days ago, there was a nice talk on this topic:
> 
>    Jose A. Sanchez-Espigares, Jordi Oca?a 	 
>    An R implementation of bootstrap procedures for mixed models 
> 
> You can find the abstract *and* slides on
>   http://www.agrocampus-ouest.fr/math/useR-2009/abstracts/user_author.html
> 
> I don't think that their R code is already publicly available,
> but I've CC'ed one of the authors, and they may be willing to
> let you use their code before release.
> 
> Martin Maechler, ETH Zurich
> 
>     CG> Below is a description of my data. I have 5/6 enclosures (replicates) per 
>     CG> treatment - Aldabra/Radiata/control. Aldabra and radiata refer to two 
>     CG> different tortoise species, while control lacks tortoises. The enclosures 
>     CG> were assigned to a block: a block containing each of the 3 treatments, i.e. 
>     CG> 6 blocks in total. Each month for ten months I collected data: a repeated 
>     CG> crossed design. Unfortunately, I have non-orthogonal, unbalanced data (5/6 
>     CG> enclosures per treatment) as I cannot use a replicate within the aldabra 
>     CG> and radiata treatments. These are however from different blocks so I am 
>     CG> reluctant to axe them to achieve balanced data as this would leave me only 
>     CG> 4 blocks. I measured various attributes which I think that tortoises would 
>     CG> have an impact on, e.g. plant count, species richness. Because my data is 
>     CG> unbalanced and a repeated measures design I had chosen lmer to best model 
>     CG> this.
> 
>     CG> For one other aspect, I calculate food web properties, for which I have no 
>     CG> replication, i.e. only one observation per treatment per month. Would lmer 
>     CG> be an acceptable way to analyse this data?
> 
>     CG> If lmer is not advised for the analyses of these data, what other analyses 
>     CG> techniques should I investigate?
> 
>     CG> Baayen et al. (2008)Mixed-effects modeling with crossed random effects
>     CG> for subjects and items. Journal of Memory and Language, 59, 390-412.
> 
>     CG> Many thanks,
>     CG> Christine
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Christine.Griffiths at bristol.ac.uk  Sat Jul 18 19:26:25 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Sat, 18 Jul 2009 18:26:25 +0100
Subject: [R-sig-ME] Too small a sample size for lmer?
In-Reply-To: <4A6203FA.6070508@ufl.edu>
References: <F31561C5673B2B2D28591BAC@bio-mammal026.bio.bris.ac.uk>
	<19041.58164.202262.729052@cmath-5.math.ethz.ch>
	<4A6203FA.6070508@ufl.edu>
Message-ID: <3396546BC4684083216D9E75@bio-mammal026.bio.bris.ac.uk>

Sorry I meant mcmcsamp. Page 398, second column, after the table of 
coefficients estimated.

yeah, I have had lots of problems with modeling this data and so was really 
wondering whether there was a better way to look at it, but maintaining the 
repeated design.

Martin, thanks for the guidance. I have had a look at the link you 
suggested and will wait and see whether code is brought out to do this.

Thank you
Christine

--On 18 July 2009 13:18 -0400 Ben Bolker <bolker at ufl.edu> wrote:

>
>   Why do Baayen et al 2008 recommend against MCMC?  Do you mean mcmcsamp
>  (which may or may not be unreliable in this incarnation, I don't know)
> or MCMC in general?  I tried to find it in the paper -- do you mean for
> variance parameters (where the zero component gets in the way)?
>
>   Your response variables are also interesting -- unless both plant
> count and species richness are large numbers, they'll probably have
> non-normal distributions, which adds to complication (it is possible,
> but not really really easy, to deal with overdispersed [negative
> binomial / log-normal-Poisson / quasi-Poisson ] count data in glmer, and
> species richness often has quite an odd distribution depending on the
> characteristics of the "regional species pool" ...)
>
>   Ben Bolker
>
>
> Martin Maechler wrote:
>>>>>>> "CG" == Christine Griffiths <Christine.Griffiths at bristol.ac.uk>
>>>>>>>     on Sat, 18 Jul 2009 13:58:36 +0100 writes:
>>
>>     CG> Dear R users,
>>     CG> Many of you may be familiar with my design as I have posted a
>>     number of  CG> queries before. Having consulted with someone in my
>>     department about  CG> estimating bias corrected confidence intervals
>>     for small sample sizes  CG> (rather than MCMC which Baayen et al.
>>     2008 suggest should not be used),  CG> they implied that I should
>>     not be using lmer for such a small sample size  CG> as lmer was
>>     designed to deal with very large datasets. Is this still the  CG>
>>     case? If so what is regarded as a small sample size?
>>
>> The fact that it was designed *to be able* to deal with big data
>> sets does not mean that it was not appropriate for small data
>> sets as well.
>> It's just that mixed effect models with large data sets an
>> crossed random effects really currently can *only* be
>> analyzed with lmer {no other software available, not even if you
>> pay much}.
>>
>> Said all that, I think your situation looks like a case where I
>> would want to use (probably a parametric) bootstrap,
>> and interestingly enough, at the UseR! 2009 meeting in Rennes,
>> 10 days ago, there was a nice talk on this topic:
>>
>>    Jose A. Sanchez-Espigares, Jordi Oca?a 	
>>    An R implementation of bootstrap procedures for mixed models
>>
>> You can find the abstract *and* slides on
>>   http://www.agrocampus-ouest.fr/math/useR-2009/abstracts/user_author.ht
>>   ml
>>
>> I don't think that their R code is already publicly available,
>> but I've CC'ed one of the authors, and they may be willing to
>> let you use their code before release.
>>
>> Martin Maechler, ETH Zurich
>>
>>     CG> Below is a description of my data. I have 5/6 enclosures
>>     (replicates) per  CG> treatment - Aldabra/Radiata/control. Aldabra
>>     and radiata refer to two  CG> different tortoise species, while
>>     control lacks tortoises. The enclosures  CG> were assigned to a
>>     block: a block containing each of the 3 treatments, i.e.  CG> 6
>>     blocks in total. Each month for ten months I collected data: a
>>     repeated  CG> crossed design. Unfortunately, I have non-orthogonal,
>>     unbalanced data (5/6  CG> enclosures per treatment) as I cannot use
>>     a replicate within the aldabra  CG> and radiata treatments. These
>>     are however from different blocks so I am  CG> reluctant to axe them
>>     to achieve balanced data as this would leave me only  CG> 4 blocks.
>>     I measured various attributes which I think that tortoises would
>>     CG> have an impact on, e.g. plant count, species richness. Because
>>     my data is  CG> unbalanced and a repeated measures design I had
>>     chosen lmer to best model  CG> this.
>>
>>     CG> For one other aspect, I calculate food web properties, for which
>>     I have no  CG> replication, i.e. only one observation per treatment
>>     per month. Would lmer  CG> be an acceptable way to analyse this data?
>>
>>     CG> If lmer is not advised for the analyses of these data, what
>>     other analyses  CG> techniques should I investigate?
>>
>>     CG> Baayen et al. (2008)Mixed-effects modeling with crossed random
>>     effects CG> for subjects and items. Journal of Memory and Language,
>>     59, 390-412.
>>
>>     CG> Many thanks,
>>     CG> Christine
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From desja004 at umn.edu  Mon Jul 20 00:38:49 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Sun, 19 Jul 2009 17:38:49 -0500
Subject: [R-sig-ME] Undefined R-structure MCMCglmm
Message-ID: <4A63A079.6010502@umn.edu>

Hi,
I am getting the following error when fitting a zip model in MCMCglmm.

 > fit1 <- MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male + grade, 
random=~id.f, data=enroll.long.m, verbose=TRUE, DIC=TRUE, 
family="zipoisson") # Random intercept only model
Error in MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male + grade,  :
   R-structure does not define unique residual for each data point

I was able to run fit a poisson model but my data is zero-inflated.

Thanks,
Chris

-- 
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://cddesjardins.wordpress.com/



From slu at ccsr.uchicago.edu  Mon Jul 20 04:22:38 2009
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Sun, 19 Jul 2009 21:22:38 -0500
Subject: [R-sig-ME] Starting values slot
Message-ID: <1248056558.32112.57.camel@musume.snl.home>

A long time ago (2005) Doug Bates wrote this (in the R-help list,
perhaps) with regard to specifying starting values for lmer:

> > for linear mixed models. The object "mer" is a mixed-effects
> > representation and the list "cv" is the control values. The only
> > thing that the C function "lmer_initial" does is set the initial
> > values of the relative precision matrices for the random effects.
> > These are the inverses of the variance-covariance matrices relative to
> > the variance of the per-observation noise term. They are stored
> > (upper triangle only) in a slot called "Omega" of the mer class (which
> > is contained in the lmer class).

Was this ever implemented? I don't see the Omega slot mentioned in the
mer-class documentation. I have a model that has been running for more
than 8 hours now (on a *very* fast machine, even) -- 2.6 million records
within two grouping factors containing 75,000 and 33,000 levels. (And
this version is just with a random sample of the full data.) When adding
fixed effects to the model, I'd like to avoid having to wait many hours
for it to finish, so I'd like to be able to speed things up by giving it
starting values from the previous version of the model. 

Can I use start=lm.previous at Omega, or is there another way to do this?

Thanks.
-- 
Stuart Luppescu -=- s-luppescu .at. uchicago.edu        
University of Chicago (^_^)/ CCSR 
???????? -=-=- Kernel 2.6.28-gentoo-r
It is more rational to sacrifice one life than
 six.   -- Spock, "The Galileo Seven", stardate
 2822.3 
 



From bolker at ufl.edu  Mon Jul 20 04:40:57 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 19 Jul 2009 22:40:57 -0400
Subject: [R-sig-ME] Starting values slot
In-Reply-To: <1248056558.32112.57.camel@musume.snl.home>
References: <1248056558.32112.57.camel@musume.snl.home>
Message-ID: <4A63D939.40901@ufl.edu>

Stuart Luppescu wrote:
> A long time ago (2005) Doug Bates wrote this (in the R-help list,
> perhaps) with regard to specifying starting values for lmer:
> 
>>> for linear mixed models. The object "mer" is a mixed-effects
>>> representation and the list "cv" is the control values. The only
>>> thing that the C function "lmer_initial" does is set the initial
>>> values of the relative precision matrices for the random effects.
>>> These are the inverses of the variance-covariance matrices relative to
>>> the variance of the per-observation noise term. They are stored
>>> (upper triangle only) in a slot called "Omega" of the mer class (which
>>> is contained in the lmer class).
> 
> Was this ever implemented? I don't see the Omega slot mentioned in the
> mer-class documentation. I have a model that has been running for more
> than 8 hours now (on a *very* fast machine, even) -- 2.6 million records
> within two grouping factors containing 75,000 and 33,000 levels. (And
> this version is just with a random sample of the full data.) When adding
> fixed effects to the model, I'd like to avoid having to wait many hours
> for it to finish, so I'd like to be able to speed things up by giving it
> starting values from the previous version of the model. 
> 
> Can I use start=lm.previous at Omega, or is there another way to do this?
> 
> Thanks.

  There's a function called ST2Omega() hidden in the namespace
(lme4:::ST2Omega), but reading the help for "lme4" it looks like you
should now just use the ST slot:

library(lme4)

fm0 <- lmer(Reaction ~ (Days|Subject), sleepstudy)

fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

fm1B <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
             start = fm0 at ST)

  ?  I'm a little out of my depth here ?

  Ben Bolker



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bates at stat.wisc.edu  Mon Jul 20 07:48:27 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 20 Jul 2009 07:48:27 +0200
Subject: [R-sig-ME] Starting values slot
In-Reply-To: <4A63D939.40901@ufl.edu>
References: <1248056558.32112.57.camel@musume.snl.home>
	<4A63D939.40901@ufl.edu>
Message-ID: <40e66e0b0907192248m2cbcc691p87ddd0c3153d1019@mail.gmail.com>

On Mon, Jul 20, 2009 at 4:40 AM, Ben Bolker<bolker at ufl.edu> wrote:
> Stuart Luppescu wrote:
>> A long time ago (2005) Doug Bates wrote this (in the R-help list,
>> perhaps) with regard to specifying starting values for lmer:
>>
>>>> for linear mixed models. The object "mer" is a mixed-effects
>>>> representation and the list "cv" is the control values. The only
>>>> thing that the C function "lmer_initial" does is set the initial
>>>> values of the relative precision matrices for the random effects.
>>>> These are the inverses of the variance-covariance matrices relative to
>>>> the variance of the per-observation noise term. They are stored
>>>> (upper triangle only) in a slot called "Omega" of the mer class (which
>>>> is contained in the lmer class).
>>
>> Was this ever implemented? I don't see the Omega slot mentioned in the
>> mer-class documentation. I have a model that has been running for more
>> than 8 hours now (on a *very* fast machine, even) -- 2.6 million records
>> within two grouping factors containing 75,000 and 33,000 levels. (And
>> this version is just with a random sample of the full data.) When adding
>> fixed effects to the model, I'd like to avoid having to wait many hours
>> for it to finish, so I'd like to be able to speed things up by giving it
>> starting values from the previous version of the model.
>>
>> Can I use start=lm.previous at Omega, or is there another way to do this?
>>
>> Thanks.
>
> ?There's a function called ST2Omega() hidden in the namespace
> (lme4:::ST2Omega), but reading the help for "lme4" it looks like you
> should now just use the ST slot:

> library(lme4)
> fm0 <- lmer(Reaction ~ (Days|Subject), sleepstudy)
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> fm1B <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> ? ? ? ? ? ? start = fm0 at ST)
> ?? ?I'm a little out of my depth here ?

The Omega slot is now gone.  It has been replaced by the relative
covariance factor, which I call Lambda and which is implemented as the
product of two matrices, a diagonal matrix, S, and a unit lower
triangular matrix, T.  The best recent description of the derivation
of the computational methods is in the slides for my presentation with
Martin at the DSC2009 conference, available at
http://matrix.r-forge.r-project.org/slides/2009-07-14-Copenhagen/

For setting starting values you do not need the details of the
implementation.  The fixed-effects parameters, beta, and the common
scale parameter, sigma, have been profiled out of the deviance and
REML criterion.  Thus the optimization is over the parameters that
determine Lambda only.  I usually call these theta.  If you use
verbose = TRUE in a call to lmer you will get output with the value of
the criterion being optimized (either the REML criterion or, for ML
estimation, the deviance) and the values of the components of theta at
each iteration.  This provides some assurance that progress is being
made if, as in your case, the optimization is taking a long time.  For
the next model fit you simply specify the converged value of theta as
the start argument to lmer.



From j.hadfield at ed.ac.uk  Mon Jul 20 10:20:11 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Jul 2009 09:20:11 +0100
Subject: [R-sig-ME] Undefined R-structure MCMCglmm
In-Reply-To: <4A63A079.6010502@umn.edu>
References: <4A63A079.6010502@umn.edu>
Message-ID: <C6FC66EE-2583-4EB5-AEC0-D292C8EE6F7F@ed.ac.uk>

Hi Chris,

Zip models are essentially bivariate in MCMCglmm with the first  
"trait" being the poisson part and the second "trait" the zero- 
inflation part.  An appropriate models would be something of the form:

fit1 <- MCMCglmm(sus ~ trait + trait:ethnic + trait:sped + trait:ell +  
trait:risk + trait:male + trait:grade-1, random=~us(trait):id.f,  
rcov~idh(trait):units, data=enroll.long.m, verbose=TRUE, DIC=TRUE,  
family="zipoisson")

This model is probably the least parsimonious model. Each fixed effect  
can have an effect on the zero-inflation and the poisson process  
(hence the interaction with trait) and there are separate id.f random  
effects for each process with the covariance estimated.  Because there  
is no information to estimate this covariance within a data point I  
usually set it to zero using the idh(...) structure. Moreover, the  
residual variance of the zero-inflation cannot be estimated as in  
standard binary analyses so it should be fixed (I fix at 1 usually).  
The appropriate prior in this case would be something like

prior=list(R=list(V=matrix(V=diag(c(v1, 1)), fix=2, n=2),  
G=list(G1=list(V=V2, n=2)))

where v1 is the prior for the Poisson over-dispersion, and V2 is a 2x2  
matrix specifying the covariance matrix for id.f.

You may also want to consider not having a random effect for the zero  
inflation, but only for the Poisson part, in which case you can set  
this value close to zero.

prior=list(R=list(V=matrix(V=diag(c(v1, 1)), fix=2, n=2),  
G=list(G1=list(V=diag(c(v2, 1e-10)), n=2)))

where v2 is now the id.f variance component  for the Poisson part.   
Note, you cannot do this for the residual variance or the chain will  
not mix.

You can also do the same for the fixed effects by placing strong  
priors around zero for the zero-inflation coefficients.

Typically ZIP and high dimensional multinomial models are the hardest  
to fit, and mixing may be a problem. Specifying pl=TRUE and looking at  
the posterior traces of the latent variables can often be a better  
indicator of problem than looking at the traces of  the fixed effects  
and variance components. I usually see problems with zip mdoels when  
the mean of the Poisson process is so high that zero's are not  
expected from the Poisson process alone.

I'd be interested to know how you get on.

Cheers,

Jarrod


On 19 Jul 2009, at 23:38, Christopher David Desjardins wrote:

> Hi,
> I am getting the following error when fitting a zip model in MCMCglmm.
>
> > fit1 <- MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male +  
> grade, random=~id.f, data=enroll.long.m, verbose=TRUE, DIC=TRUE,  
> family="zipoisson") # Random intercept only model
> Error in MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male +  
> grade,  :
>  R-structure does not define unique residual for each data point
>
> I was able to run fit a poisson model but my data is zero-inflated.
>
> Thanks,
> Chris
>
> -- 
> Christopher David Desjardins
> Ph.D. Student
> Quantitative Methods in Education
> Department of Educational Psychology
> University of  Minnesota
> http://cddesjardins.wordpress.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From desja004 at umn.edu  Mon Jul 20 16:43:29 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Mon, 20 Jul 2009 09:43:29 -0500
Subject: [R-sig-ME] Undefined R-structure MCMCglmm
In-Reply-To: <C6FC66EE-2583-4EB5-AEC0-D292C8EE6F7F@ed.ac.uk>
References: <4A63A079.6010502@umn.edu>
	<C6FC66EE-2583-4EB5-AEC0-D292C8EE6F7F@ed.ac.uk>
Message-ID: <4A648291.6020402@umn.edu>

Thanks Jarrod. I'll let you know if I have success.
Chris

On 7/20/09 3:20 AM, Jarrod Hadfield wrote:
> Hi Chris,
>
> Zip models are essentially bivariate in MCMCglmm with the first 
> "trait" being the poisson part and the second "trait" the 
> zero-inflation part.  An appropriate models would be something of the 
> form:
>
> fit1 <- MCMCglmm(sus ~ trait + trait:ethnic + trait:sped + trait:ell + 
> trait:risk + trait:male + trait:grade-1, random=~us(trait):id.f, 
> rcov~idh(trait):units, data=enroll.long.m, verbose=TRUE, DIC=TRUE, 
> family="zipoisson")
>
> This model is probably the least parsimonious model. Each fixed effect 
> can have an effect on the zero-inflation and the poisson process 
> (hence the interaction with trait) and there are separate id.f random 
> effects for each process with the covariance estimated.  Because there 
> is no information to estimate this covariance within a data point I 
> usually set it to zero using the idh(...) structure. Moreover, the 
> residual variance of the zero-inflation cannot be estimated as in 
> standard binary analyses so it should be fixed (I fix at 1 usually). 
> The appropriate prior in this case would be something like
>
> prior=list(R=list(V=matrix(V=diag(c(v1, 1)), fix=2, n=2), 
> G=list(G1=list(V=V2, n=2)))
>
> where v1 is the prior for the Poisson over-dispersion, and V2 is a 2x2 
> matrix specifying the covariance matrix for id.f.
>
> You may also want to consider not having a random effect for the zero 
> inflation, but only for the Poisson part, in which case you can set 
> this value close to zero.
>
> prior=list(R=list(V=matrix(V=diag(c(v1, 1)), fix=2, n=2), 
> G=list(G1=list(V=diag(c(v2, 1e-10)), n=2)))
>
> where v2 is now the id.f variance component  for the Poisson part.  
> Note, you cannot do this for the residual variance or the chain will 
> not mix.
>
> You can also do the same for the fixed effects by placing strong 
> priors around zero for the zero-inflation coefficients.
>
> Typically ZIP and high dimensional multinomial models are the hardest 
> to fit, and mixing may be a problem. Specifying pl=TRUE and looking at 
> the posterior traces of the latent variables can often be a better 
> indicator of problem than looking at the traces of  the fixed effects 
> and variance components. I usually see problems with zip mdoels when 
> the mean of the Poisson process is so high that zero's are not 
> expected from the Poisson process alone.
>
> I'd be interested to know how you get on.
>
> Cheers,
>
> Jarrod
>
>
> On 19 Jul 2009, at 23:38, Christopher David Desjardins wrote:
>
>> Hi,
>> I am getting the following error when fitting a zip model in MCMCglmm.
>>
>> > fit1 <- MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male + 
>> grade, random=~id.f, data=enroll.long.m, verbose=TRUE, DIC=TRUE, 
>> family="zipoisson") # Random intercept only model
>> Error in MCMCglmm(sus ~ 1 + ethnic + sped + ell + risk + male + 
>> grade,  :
>>  R-structure does not define unique residual for each data point
>>
>> I was able to run fit a poisson model but my data is zero-inflated.
>>
>> Thanks,
>> Chris
>>
>> -- 
>> Christopher David Desjardins
>> Ph.D. Student
>> Quantitative Methods in Education
>> Department of Educational Psychology
>> University of  Minnesota
>> http://cddesjardins.wordpress.com/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

-- 
Christopher David Desjardins
Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of  Minnesota
http://cddesjardins.wordpress.com/



From harlancampbell at gmail.com  Mon Jul 20 20:55:28 2009
From: harlancampbell at gmail.com (H c)
Date: Mon, 20 Jul 2009 14:55:28 -0400
Subject: [R-sig-ME] Confidence intervals on correlation parameter estimates
Message-ID: <222824550907201155q29f4136dna0c1846961fa454f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090720/0549af50/attachment.pl>

From DAfshartous at med.miami.edu  Mon Jul 20 21:48:04 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 20 Jul 2009 15:48:04 -0400
Subject: [R-sig-ME] Multivariate mixed effects model
In-Reply-To: <145C63777EF3ED41A5A99035845F7DD90241D223@EVD-C8001.bk.evdad.admin.ch>
Message-ID: <C68A4234.AE53%dafshartous@med.miami.edu>

Dear Lorenz and others interested,
Please see reply below.   In summary, the basic issue that remains is how to specify a general covariance matrix for the residual errors of several response variables at the same time point.
Any ideas much appreciated.
Cheers,
David


On 7/13/09 3:42 AM, "lorenz.gygax at art.admin.ch" <lorenz.gygax at art.admin.ch> wrote:

Dear David and others interested,

I am also trying to get to terms with mixed-effects models having several symultaneous outcomes. Thus, I was very pleased to see the Reference that Mareike provided (and slightly disappointed when I saw how little of the publication actually referred to the multiple outcomes - it nevertheless seems/seemed to be a good starting point).

When running a couple of toy examples the following points struck me. I am not quite sure which of those are actually relevant and which ones just seemed odd to me because my understanding of the corresponding math does not reach far enough.

> This approach works fine for simple models, but I don't see how to
> extend to more complex models.

I agree (see below). And my hunch is that we are asking too much and that lme/lmer can not currently be "tricked" into including all aspects of interest to us. This is just not the application, these methods were programmed to deal with.

<DA> The fact that the data is multivariate is actually not that much of an extension.  For instance, if we had only one response variable but say k groups with random effect variance or residual error variance stratified per group, the situation would be identical.  Just replace "response variable" by "group": Instead of k different response variables we have k groups for one variable and the data structure and model statement with appropriate dummy variables would be the same in lme/lmer.

> A variety of more complex structures can apparently be fit in SAS
> (Gao et al, Fitting Multivariate Longitudinal Data Using SAS, Paper
> 187-31).

As complex as what you are aiming at? What we would like seems way more complex than the standard mixed models ... which explains why the approach in lme/lmer is somewhat limited (or perhaps I am missing something).

<DA> one example would be to have the residual error of the different variables to be correlated at each time point as mentioned below.

> In the context of the pseudo example below, does anyone  know
> how to do the following?
> ## 1) residual error correlated across variables at the same
> time point?

This would be one of the main points for running multiple simultaneous outcomes in one model, wouldn't it?

<DA> Also, presumably the association structure of the random effects would often be of interest.   VarIdent allows different residual variances per variable, but does not allow them to be correlated.  Based on the list of varFunc classes (p.208, Pinheiro & Bates) I don't see how this would be done.  One wants something akin to pdSymm that is used for random effects.

In my view, one would want to have variance-covariance Matrices (or possibly correlation matrices) for all random terms in the model (i.e. random effects and residuals). For that all random terms should end up in Matrices with their number of columns corresponding to the number of outcomes. Whereas this is the case for the random effects - e.g. ranef (mv1.lme) - the residuals are just assumed to be independt resulting in one vector - e.g. resid (mv1.lme).

This is also reflected in the degrees of freedom (were we inclined to rely on them, which, of course, we are not ;-) in that the dfs in such a model result from the total number of rows in the data set and not the number of observations per outcome.

The way to specify correlation structures of the errors in lme is via the corStruct methods. At least with the methods available in the package, it does not seem to be possible to model such a 'block'-structure of covariance (the residuals of the different outcomes co-varying with each other). Some of the pdMat classes might do the trick for random effects but I would not see how these could easily be applied to the residuals.

> ## 2) residual error correlated across variables at different
> time point? (e.g., AR1)

The following might do the trick:
mv4.lme <- update (mv3.lme,
                   correlation= corAR1 (form= ~ 1 | subject/y1.ind))

<DA> Thanks.  I also noticed that the statement below accomplishes the same thing:
mv4.lme <- update (mv3.lme,   correlation= corAR1 ())


(In the more general case with more than two outcomes, y1.ind would need to be replaced by a factor indicating the differen outcomes, i.e. y1.ind, y2.ind, ... "de-dummied", so to speak).

> ## 3) different AR1 coefficient for different variables?

No idea for that, either.

> ## basic bivariate model with correlated intercept random-effects
> mv1.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time,
> random = ~ -1 + y1.ind + y2.ind  | subject,
>             data = data.mv, control=nlmeControl(msMaxIter = 500))
> ## different residual error variance per variable
> mv3.lme = lme(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time,
> random = ~ -1 + y1.ind + y2.ind  | subject,
>             data = data.mv, control=nlmeControl(msMaxIter =
> 500), weights = varIdent(form = ~1 | y1.ind))
>
> ## for comparison, basic model in lmer below, but don't think
> residual variance extensions above currently available:
> library("lme4")
> mv1.lmer  = lmer(y ~ -1 + y1.ind + y2.ind + y1.time + y2.time
> +  (0 + y1.ind + y2.ind + y1.time + y2.time | subject) ,
>             data = data.mv)

This includes the random slopes which were not included above, correct?

<DA> Yes

I am currently thinking about implementing such models in flavour of Bugs and just use the simple but fast methods in lme/lmer as plausibility checks for the more complex models.

Best wishes, Lorenz
-
Lorenz Gygax
Federal Veterinary Office
Centre for proper housing of ruminants and pigs
CH-8356 Ettenhausen / Switzerland


> ###############
> ## simulated data:
> set.seed(100); n1 = 30; n2 = 4
> library("MASS"); library("nlme")
> y1 = y2 = matrix(0, n2, n1)
> for (i in 1:n1) {
>     b.i = mvrnorm(n = 1, mu = c(0,0), Sigma = matrix(c(3, 1,
> 1, 6), nrow = 2, ncol = 2)) # correlated random effects
>    for (j in 1:n2) {
>         eps =  mvrnorm(n = 1, mu = c(0,0), Sigma =
> matrix(c(2, 0, 0, 5), nrow = 2, ncol = 2))  ##  uncorrelated
> error term
>        y1[j,i] = 4 + 2 * j + b.i[1] + eps[1]  ## fixed
> intercept and sloped effects + random-intercept
>        y2[j,i] = 25 + 13 * j + b.i[2] + eps[2] }}
> data.mv = data.frame(subject = rep(seq(1,n1), each = n2, 2),
> time = rep(c(1:n2), n1*2), y = c(as.vector(y1),
> as.vector(y2)), y1.ind = rep( c(1,0),
>     each = n1*n2), y2.ind = rep( c(0,1), each = n1*n2),
> y1.time = c(rep(seq(1:4), n1), rep(0, n1*n2)), y2.time =
> c(rep(0, n1*n2), rep(seq(1,4), n1)))



From kingsfordjones at gmail.com  Tue Jul 21 02:09:12 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Mon, 20 Jul 2009 18:09:12 -0600
Subject: [R-sig-ME] Confidence intervals on correlation parameter
	estimates
In-Reply-To: <222824550907201155q29f4136dna0c1846961fa454f@mail.gmail.com>
References: <222824550907201155q29f4136dna0c1846961fa454f@mail.gmail.com>
Message-ID: <2ad0cc110907201709q2cba4725s6f5ea34ae1aeb87a@mail.gmail.com>

Hi Harlan,

>From ?intervals.lme it sounds as though normal approximations are
used, with standard errors coming from the inverse Hessian of the log
(RE)ML function evaluated at the
estimates.  I don't have P&B with me, but IIRC Ch 5 begins with a
discussion of how the likelihood functions are adjusted to accommodate
error covariance parameters.

hth,

Kingsford Jones

On Mon, Jul 20, 2009 at 12:55 PM, H c<harlancampbell at gmail.com> wrote:
> Hello all,
> When incorporating correlation structures into a lme model with the nlme()
> library, one can produce confidence intervals for the correlation parameter
> estimates. ?The Pinheiro and Bates book has a simple example:
>
> "We can assess the precision of the correlation parameter estimate in
> fm20var.lme with the 'intervals' ?method.
>
>> fm1 <- lme(distance ~ age, data =
> Orthodont,correlation=corAR1(0.5,fixed=FALSE)) # random is ~ age
>> intervals(fm1)
> Approximate 95% confidence intervals
> ...
> ?Correlation structure:
> ? ? ? ? lower ? ? ? est. ? ? ? upper
> Phi -0.7615846 -0.4898957 -0.07174523
> attr(,"label")
> [1] "Correlation structure:"
>
> ?Within-group standard error:
> ? ?lower ? ? ?est. ? ? upper
> 0.9002138 1.0900639 1.3199522
> "
>
> Any thoughts on how these C.I.s are obtained?
> As far as I cant tell, the Pinheiro and Bates book does not go into details,
> but perhaps I am wrong.
>
> Any thoughts or references would be greatly appreciated,
>
> Harlan Campbell
> McGill University
> Montreal, Canada
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From juliet.hannah at gmail.com  Tue Jul 21 14:43:11 2009
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 21 Jul 2009 08:43:11 -0400
Subject: [R-sig-ME] strategy to iterate over repeated measures/longitudinal
	data
Message-ID: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>

Hi list,

I had posted this question to R-help, but I did not receive
any suggestions. I have rewritten my question, and I think it
may be more famililar to those who use lme4. Let me start with
a basic description.

Let's say we are interested in the regression of y on x1.
We could run lm(). Now let's say
y is measured multiple times on the same individual. This data is in
wide format and resembles
longitudinal data. lmer is used to take into account that the observations
y on the same individual are correlated.  But I'm still only interested in
the relationship between y and x1.

So I just convert from wide to long, run lmer, and extract the
coefficient I want.

Now let's say I have several xs: x1, x2, ...xn.  I want to know what is the
coefficient for the regression of y on each x separately. I now have to
iterate through the xs somehow.

Here is an example.

head(wide_data)

 id predictor1 predictor2 predictor3 measurement1 measurement2
1  1          a          a          b  -0.04493361  -0.05612874
2  2          a          a          a  -0.01619026  -0.15579551
3  3          b          b          b   0.94383621  -1.47075238
4  4          b          a          a   0.82122120  -0.47815006
5  5          a          b          a   0.59390132   0.41794156
6  6          b          a          a   0.91897737   1.35867955

The measurements are repeated measures, and I am looking at one
predictor at a time. In the actual problem, there are around 400,000
predictors.

Currently, I do the following.

For each predictor:
1. create a long data set using the predictor and all measurements
(using make.univ function from  multilevel package)
2. run lmer, extract the coefficient of interest
3. go to next predictor

The end result is a vector of 400,000 coefficients.

Do you have any suggestions on how I can improve this strategy?

Thanks for your help.

Juliet Hannah


Here is an example with inefficient, working code.

library(multilevel)
library(lme4)

#Same data as above
set.seed(1)
wide_data <- data.frame(
   id=c(1:10),
   predictor1 = sample(c("a","b"),10,replace=TRUE),
   predictor2 = sample(c("a","b"),10,replace=TRUE),
  predictor3 = sample(c("a","b"),10,replace=TRUE),
   measurement1=rnorm(10),
   measurement2=rnorm(10))


#vector of names to iterate over
predictor_names <- colnames(wide_data)[2:4]
#vector to store coefficients
mycoefs <- rep(-1,length(predictor_names))
names(mycoefs) <- predictor_names

for (predictor in predictor_names)
{
  long_data <-  make.univ( data.frame(wide_data$id,wide_data[,predictor]),
   data.frame(
        wide_data$measurement1,
        wide_data$measurement2
   )
 )
  names(long_data) <- c('id', 'predictor', 'time','measurement')
  myfit <- lmer(measurement ~ predictor + (1|id),data=long_data)
  mycoefs[predictor] <- myfit at fixef[2]
}

mycoefs



From h.wickham at gmail.com  Tue Jul 21 15:42:17 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 21 Jul 2009 08:42:17 -0500
Subject: [R-sig-ME] strategy to iterate over repeated
	measures/longitudinal data
In-Reply-To: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
References: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
Message-ID: <f8e6ff050907210642n374d3620iee21cfaab319e7d9@mail.gmail.com>

> For each predictor:
> 1. create a long data set using the predictor and all measurements
> (using make.univ function from ?multilevel package)
> 2. run lmer, extract the coefficient of interest
> 3. go to next predictor
>
> The end result is a vector of 400,000 coefficients.
>
> Do you have any suggestions on how I can improve this strategy?

What sort of improvement are you looking for?  Speed?  Elegance?  Ease of use?

Hadley

-- 
http://had.co.nz/



From juliet.hannah at gmail.com  Tue Jul 21 16:02:40 2009
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 21 Jul 2009 10:02:40 -0400
Subject: [R-sig-ME] strategy to iterate over repeated
	measures/longitudinal data
In-Reply-To: <f8e6ff050907210642n374d3620iee21cfaab319e7d9@mail.gmail.com>
References: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
	<f8e6ff050907210642n374d3620iee21cfaab319e7d9@mail.gmail.com>
Message-ID: <93d6f2a80907210702i7b6e3282l94860a02d53da8b8@mail.gmail.com>

Hi Hadley,

I wanted to check if there is anything obviously incorrect/inefficient with the
strategy I outlined. I can, of course, try out various wide to long
conversions.
But apart from that, I was
worried that I should try to convert the data all at once beforehand,
and iterate
through the converted data somehow.

If you see nothing horribly wrong with my current strategy, then
that is helpful in itself. :)

My main concern is efficiency and memory use. Speed is a secondary
concern. Really, I just want it to work. In looping through
this data (when I wasn't using repeated measures), I have had
several problems with memory usage going up (about 20G). I never
figured it out (using GEEs for that one), but I suspected that
maybe I wasn't iterating in a proper manner. Now when I am going
to use all of the measurements, I fear I am going to run into
more problems.

Thanks for responding.

Regards,

Juliet

On Tue, Jul 21, 2009 at 9:42 AM, hadley wickham<h.wickham at gmail.com> wrote:
>> For each predictor:
>> 1. create a long data set using the predictor and all measurements
>> (using make.univ function from ?multilevel package)
>> 2. run lmer, extract the coefficient of interest
>> 3. go to next predictor
>>
>> The end result is a vector of 400,000 coefficients.
>>
>> Do you have any suggestions on how I can improve this strategy?
>
> What sort of improvement are you looking for? ?Speed? ?Elegance? ?Ease of use?
>
> Hadley
>
> --
> http://had.co.nz/
>



From harlancampbell at gmail.com  Tue Jul 21 16:09:07 2009
From: harlancampbell at gmail.com (H c)
Date: Tue, 21 Jul 2009 10:09:07 -0400
Subject: [R-sig-ME] Confidence intervals on correlation parameter
	estimates
In-Reply-To: <2ad0cc110907201709q2cba4725s6f5ea34ae1aeb87a@mail.gmail.com>
References: <222824550907201155q29f4136dna0c1846961fa454f@mail.gmail.com>
	<2ad0cc110907201709q2cba4725s6f5ea34ae1aeb87a@mail.gmail.com>
Message-ID: <222824550907210709v1b42af68tfc45246ddbe873d3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090721/54e71b04/attachment.pl>

From bolker at ufl.edu  Tue Jul 21 16:21:52 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 21 Jul 2009 10:21:52 -0400
Subject: [R-sig-ME] Confidence intervals on correlation
	parameter	estimates
In-Reply-To: <222824550907210709v1b42af68tfc45246ddbe873d3@mail.gmail.com>
References: <222824550907201155q29f4136dna0c1846961fa454f@mail.gmail.com>	<2ad0cc110907201709q2cba4725s6f5ea34ae1aeb87a@mail.gmail.com>
	<222824550907210709v1b42af68tfc45246ddbe873d3@mail.gmail.com>
Message-ID: <4A65CF00.6040208@ufl.edu>

H c wrote:
> Hi,
> Thanks for the reply and advice.  unfortunately when incorporating
> correlation structures(e.g. AR(1)) into a mixed model, lme() uses numerical
> methods for the calculation of the related parameters(e.g. Phi).  (the
> numerical methods used are in the nlminb()).  In any case, it is because no
> closed form of the derivative of the log-likelihood with respect to these
> parameters is available.  This suggests to me that the inverse Hessian of
> the log ML function is also unavailable.
> 
> If anyone knows of a source that can confirm or refute any of these
> thoughts, that would be GREAT!
> 
> Harlan
> 

  Don't know of a source, but it's extremely standard in this situations
for the system to use the Hessian estimated by (second) finite differences.
  If you need to know badly enough, why not look at the code ... ?

  good luck,
    Ben Bolker



From jeremiahrounds at hotmail.com  Tue Jul 21 20:32:54 2009
From: jeremiahrounds at hotmail.com (Jeremiah Rounds)
Date: Tue, 21 Jul 2009 11:32:54 -0700
Subject: [R-sig-ME] strategy to iterate over
	repeated	measures/longitudinal data
In-Reply-To: <93d6f2a80907210702i7b6e3282l94860a02d53da8b8@mail.gmail.com>
References: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
	<f8e6ff050907210642n374d3620iee21cfaab319e7d9@mail.gmail.com> 
	<93d6f2a80907210702i7b6e3282l94860a02d53da8b8@mail.gmail.com>
Message-ID: <BLU127-W296DE722B5555B1278D2BFCB1A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090721/ae01f6a0/attachment.pl>

From David.Duffy at qimr.edu.au  Tue Jul 21 23:35:01 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 22 Jul 2009 07:35:01 +1000 (EST)
Subject: [R-sig-ME] strategy to iterate over repeated
	measures/longitudinaldata
In-Reply-To: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
References: <93d6f2a80907210543v33fcb673qfc0a08fc8b375fdc@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0907220729180.2837@orpheus.qimr.edu.au>

On Tue, 21 Jul 2009, Juliet Hannah wrote:

> Here is an example with inefficient, working code.
>

You could try using the jit compiler -- it does speed up looping

> for (predictor in predictor_names)
> {
>  long_data <-  make.univ( data.frame(wide_data$id,wide_data[,predictor]),
>   data.frame(
>        wide_data$measurement1,
>        wide_data$measurement2
>   )
> )
>  names(long_data) <- c('id', 'predictor', 'time','measurement')
>  myfit <- lmer(measurement ~ predictor + (1|id),data=long_data)
>  mycoefs[predictor] <- myfit at fixef[2]
> }
>


Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From slu at ccsr.uchicago.edu  Tue Jul 21 23:54:19 2009
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 21 Jul 2009 16:54:19 -0500
Subject: [R-sig-ME] lme error message
Message-ID: <1248213259.6769.41.camel@musuko.spc.uchicago.edu>

Running a nested model with lme, and getting this message:

Error in MEEM(object, conLin, control$niterEM) : 
  Singularity in backsolve at level 0, block 1

Can anyone explain this?

Thanks.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 2.6.28-gentoo-r5                
Xander: What's going on here? People are going all 
 Felicity with  their hair.  
 
 
 
 
 
 
 



From ken at kjbeath.com.au  Wed Jul 22 00:15:09 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 22 Jul 2009 08:15:09 +1000
Subject: [R-sig-ME] lme error message
In-Reply-To: <1248213259.6769.41.camel@musuko.spc.uchicago.edu>
References: <1248213259.6769.41.camel@musuko.spc.uchicago.edu>
Message-ID: <E5C39D41-0D39-4254-B1AF-8AAD44703939@kjbeath.com.au>


On 22/07/2009, at 7:54 AM, Stuart Luppescu wrote:

> Running a nested model with lme, and getting this message:
>
> Error in MEEM(object, conLin, control$niterEM) :
>  Singularity in backsolve at level 0, block 1
>
> Can anyone explain this?
>

Usually means that some of the random effects are highly correlated or  
possibly zero.

Ken



> Thanks.
> -- 
> Stuart Luppescu -=- slu .at. ccsr.uchicago.edu
> University of Chicago -=- CCSR
> ???????? -=-    Kernel 2.6.28-gentoo-r5
> Xander: What's going on here? People are going all
> Felicity with  their hair.
>
>
>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From slu at ccsr.uchicago.edu  Wed Jul 22 00:22:56 2009
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Tue, 21 Jul 2009 17:22:56 -0500
Subject: [R-sig-ME] lme error message
In-Reply-To: <E5C39D41-0D39-4254-B1AF-8AAD44703939@kjbeath.com.au>
References: <1248213259.6769.41.camel@musuko.spc.uchicago.edu>
	<E5C39D41-0D39-4254-B1AF-8AAD44703939@kjbeath.com.au>
Message-ID: <1248214976.6769.43.camel@musuko.spc.uchicago.edu>

On ?, 2009-07-22 at 08:15 +1000, Ken Beath wrote:
> On 22/07/2009, at 7:54 AM, Stuart Luppescu wrote:
> 
> > Running a nested model with lme, and getting this message:
> >
> > Error in MEEM(object, conLin, control$niterEM) :
> >  Singularity in backsolve at level 0, block 1
> >
> > Can anyone explain this?
> >
> 
> Usually means that some of the random effects are highly correlated or
> possibly zero.

Random effects? Only the intercept is random, and in a more restricted
model there's tons of variance.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 2.6.28-gentoo-r5                
Oz: Sometimes when I'm sitting in class...you know,
 I'm not  thinking about class 'cause that would
 never happen... I think  about kissing you. And
 it's like everything stops, it's like,  freeze
 frame: Willow kissage. 
 
 
 
 



From ken at kjbeath.com.au  Wed Jul 22 04:58:46 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 22 Jul 2009 12:58:46 +1000
Subject: [R-sig-ME] lme error message
In-Reply-To: <1248214976.6769.43.camel@musuko.spc.uchicago.edu>
References: <1248213259.6769.41.camel@musuko.spc.uchicago.edu>
	<E5C39D41-0D39-4254-B1AF-8AAD44703939@kjbeath.com.au>
	<1248214976.6769.43.camel@musuko.spc.uchicago.edu>
Message-ID: <44BC41C7-28F8-42CA-B72B-F996E4AB6D64@kjbeath.com.au>


On 22/07/2009, at 8:22 AM, Stuart Luppescu wrote:

> On ?, 2009-07-22 at 08:15 +1000, Ken Beath wrote:
>> On 22/07/2009, at 7:54 AM, Stuart Luppescu wrote:
>>
>>> Running a nested model with lme, and getting this message:
>>>
>>> Error in MEEM(object, conLin, control$niterEM) :
>>> Singularity in backsolve at level 0, block 1
>>>
>>> Can anyone explain this?
>>>
>>
>> Usually means that some of the random effects are highly correlated  
>> or
>> possibly zero.
>
> Random effects? Only the intercept is random, and in a more restricted
> model there's tons of variance.

If by a more restricted model, you mean one with less covariates, then  
either the covariates are reducing your random effects variance to  
zero or causing some other collinearity problem.

Try control option for verbose output, and see if the numbers are very  
large.

Ken


From ccleland at optonline.net  Wed Jul 22 21:13:00 2009
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 22 Jul 2009 15:13:00 -0400
Subject: [R-sig-ME] MCMCglmm Bivariate Binary Model
Message-ID: <4A6764BC.8080106@optonline.net>

Hi All,

  I attempted to fit a bivariate binary model similar to the example in
the Tutorial:

prior = list(R = list(V = diag(2), n = 0, fix = 2),
             G = list(G1 = list(V = diag(2), n = 1)))

model5 <- MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
~us(trait):PROGRAM, rcov = ~idh(trait):units, family=c("categorical",
"categorical"), data = radars, prior = prior, verbose = FALSE)

Error in MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
~us(trait):PROGRAM,  :
  ill-conditioned G/R structure: use proper priors if you haven't or
rescale data if you have

  In this dataset, one of the four cells in the 2x2 table is empty:

   Cell Contents
|-------------------------|
|                   Count |
|-------------------------|

Total Observations in Table:  21335

             | ANYPO
       ANYHR |        0  |        1  | Row Total |
-------------|-----------|-----------|-----------|
           0 |        0  |     8999  |     8999  |
-------------|-----------|-----------|-----------|
           1 |     6458  |     5878  |    12336  |
-------------|-----------|-----------|-----------|
Column Total |     6458  |    14877  |    21335  |
-------------|-----------|-----------|-----------|

  Is there a way to change the specification for prior to make this work?

thanks,

Chuck

-- 
Chuck Cleland, Ph.D.
NDRI, Inc. (www.ndri.org)
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From lborger at uoguelph.ca  Thu Jul 23 10:17:38 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 23 Jul 2009 04:17:38 -0400 (EDT)
Subject: [R-sig-ME] lme error message
In-Reply-To: <1248214976.6769.43.camel@musuko.spc.uchicago.edu>
Message-ID: <388510203.6081271248337058002.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

>  Singularity in backsolve at level 0, block 1

in fact my experience is that in this case there is some problem with the fixed effects (e.g. not enough data for all factor combinations etc.), otherwise it would say level 1 or higher. By fitting a simpler model usually it disappears.

Disclaimer: just limited empirical experience, I have never checked the code to understand better this error message, so take this with caution ;-)


HTH


Cheers,

Luca


----- Original Message -----
From: "Stuart Luppescu" <slu at ccsr.uchicago.edu>
To: "Ken Beath" <ken at kjbeath.com.au>
Cc: r-sig-mixed-models at r-project.org
Sent: Wednesday, July 22, 2009 12:22:56 AM GMT +01:00 Amsterdam / Berlin / Bern / Rome / Stockholm / Vienna
Subject: Re: [R-sig-ME] lme error message

On ?, 2009-07-22 at 08:15 +1000, Ken Beath wrote:
> On 22/07/2009, at 7:54 AM, Stuart Luppescu wrote:
> 
> > Running a nested model with lme, and getting this message:
> >
> > Error in MEEM(object, conLin, control$niterEM) :
> >  Singularity in backsolve at level 0, block 1
> >
> > Can anyone explain this?
> >
> 
> Usually means that some of the random effects are highly correlated or
> possibly zero.

Random effects? Only the intercept is random, and in a more restricted
model there's tons of variance.
-- 
Stuart Luppescu -=- slu .at. ccsr.uchicago.edu        
University of Chicago -=- CCSR 
???????? -=-    Kernel 2.6.28-gentoo-r5                
Oz: Sometimes when I'm sitting in class...you know,
 I'm not  thinking about class 'cause that would
 never happen... I think  about kissing you. And
 it's like everything stops, it's like,  freeze
 frame: Willow kissage. 
 
 
 
 

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Thu Jul 23 12:13:35 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 23 Jul 2009 11:13:35 +0100
Subject: [R-sig-ME] MCMCglmm Bivariate Binary Model
In-Reply-To: <4A6764BC.8080106@optonline.net>
References: <4A6764BC.8080106@optonline.net>
Message-ID: <20090723111335.51f6wb8pc8cok480@www.staffmail.ed.ac.uk>

Hi Chuck,

The problem you encounter is because the prior specification is not  
proper. Something of the form:

prior = list(R = list(V = diag(2), n = 0, fix = 1),
               G = list(G1 = list(V = diag(2), n = 2)))

would be more appropriate. Note I've changed fix=2 to fix=1 so that  
the whole R structure is fixed as an Identity matrix. I've also  
changed n=1 to n=2 in the G structure because a 2x2 matrix requires a  
minimum of n=2 to be proper.  I use identity matrices in the tutorial  
out of convenience, but better priors should be used if they exist.  
Failing that checking sensitivity to different prior specifications  
would be a good idea.

My guess is that it is the R-structure definition that is creating  
problems because the residual variance for ANYHR was being estimated,  
but there is no information in the data for this parameter (because  
its binary).

I don't recommend bivariate binary models in MCMCglmm yet because you  
can't restrict the residual covariance structure to a correlation  
matrix.   This would fix the two residual variances because they  
cannot be estimated, but would allow the residual correlation between  
the outcomes to be estimated. Fixing this correlation to 0 (using  
idh()) will almost certainly bias the random effect correlation.

One possibility would be to treat your bivariate binary model as a  
3-level multinomial 1/0 0/1 1/1. This would also result in a bivariate  
model (where one of the three categories becomes the base line  
category) but it may be easier to set up the model in a way that  
captures the lack of 0/0 outcome.

Cheers,

Jarrod


Quoting Chuck Cleland <ccleland at optonline.net>:

> Hi All,
>
>   I attempted to fit a bivariate binary model similar to the example in
> the Tutorial:
>
> prior = list(R = list(V = diag(2), n = 0, fix = 2),
>              G = list(G1 = list(V = diag(2), n = 1)))
>
> model5 <- MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
> ~us(trait):PROGRAM, rcov = ~idh(trait):units, family=c("categorical",
> "categorical"), data = radars, prior = prior, verbose = FALSE)
>
> Error in MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
> ~us(trait):PROGRAM,  :
>   ill-conditioned G/R structure: use proper priors if you haven't or
> rescale data if you have
>
>   In this dataset, one of the four cells in the 2x2 table is empty:
>
>    Cell Contents
> |-------------------------|
> |                   Count |
> |-------------------------|
>
> Total Observations in Table:  21335
>
>              | ANYPO
>        ANYHR |        0  |        1  | Row Total |
> -------------|-----------|-----------|-----------|
>            0 |        0  |     8999  |     8999  |
> -------------|-----------|-----------|-----------|
>            1 |     6458  |     5878  |    12336  |
> -------------|-----------|-----------|-----------|
> Column Total |     6458  |    14877  |    21335  |
> -------------|-----------|-----------|-----------|
>
>   Is there a way to change the specification for prior to make this work?
>
> thanks,
>
> Chuck
>
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc. (www.ndri.org)
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kagba2006 at yahoo.com  Thu Jul 23 13:04:27 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 23 Jul 2009 04:04:27 -0700 (PDT)
Subject: [R-sig-ME] Error when including the  correlation structure in lme
Message-ID: <569105.38524.qm@web38305.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090723/39685b46/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Jul 23 13:52:15 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 23 Jul 2009 13:52:15 +0200
Subject: [R-sig-ME] Error when including the correlation structure in lme
In-Reply-To: <569105.38524.qm@web38305.mail.mud.yahoo.com>
References: <569105.38524.qm@web38305.mail.mud.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A104069D9C10@inboexch.inbo.be>

Dear Fir,

I presume you have a rather large dataset? I got similar problems with the spatial correlation structures on a large dataset. The background is that (at least the spatial correlation structures) require an n x n matrix. Which is huge with large n. Adding a grouping structure (like a random effect) fixes lots of entries of that matrix to zero. So that leads to a smaller sparse matrix. Therefore I would recommend to look for an extra variable that you can add as grouping factor, nested in Depth. 

The code would look like

update(lm.lme1, correlation = corARMA(p=2, form = ~t1| Depth/ExtraVariable))

HTH,

THierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens FMH
Verzonden: donderdag 23 juli 2009 13:04
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Error when including the correlation structure in lme

Dear All,

I'm running the lme command in R and have a problem as i include the correlation structure with AR1 model.

At first, i run this command without including the correlation structure, and the program works fine. But, after including the correlation structure with AR1 model,?my computer drastically takes almost?two minutes to process on this command.


#################################################################
lm.lme1 <- lme(Temp ~ t1 + t2, tmp, random = ~t1 + t2| Depth, method = "REML")
lm.lme2 <- update(lm.lme1, correlation = corARMA(p=2, form = ~t1| Depth)) #################################################################
?
Eventually, it gives this output, which i guess related with the memory problem.
?
#################################################################
Error: cannot allocate vector of size 715.6 Mb In addition: Warning messages:
1: In corFactor.corARMA(object) :
? Reached total allocation of 958Mb: see help(memory.size)
2: In corFactor.corARMA(object) :
? Reached total allocation of 958Mb: see help(memory.size)
3: In corFactor.corARMA(object) :
? Reached total allocation of 958Mb: see help(memory.size)
4: In corFactor.corARMA(object) :
? Reached total allocation of 958Mb: see help(memory.size) ################################################################
?
Could someone advice me on how to sort out on this problem? 
?
Thank you.
?
Fir


      
	[[alternative HTML version deleted]]


Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From julien.martin2 at usherbrooke.ca  Thu Jul 23 14:18:03 2009
From: julien.martin2 at usherbrooke.ca (Julien Martin)
Date: Thu, 23 Jul 2009 08:18:03 -0400
Subject: [R-sig-ME] MCMCglmm Bivariate Binary Model
In-Reply-To: <mailman.7.1248343202.7451.r-sig-mixed-models@r-project.org>
References: <mailman.7.1248343202.7451.r-sig-mixed-models@r-project.org>
Message-ID: <4A6854FB.10201@usherbrooke.ca>

Hi Chuck
I think you need to fix residual variance and covariance to 1 and 0 for 
both traits because they are both binary traits. With your actual prior, 
you fix it only for the second trait.
So I think it should work with

prior = list(R = list(V = diag(2), n = 0, fix = 1),
             G = list(G1 = list(V = diag(2), n = 1)))


Hope this would work
Sincerely

Julien

-- 
Julien Martin, Ph.D. Candidate
Universit? de Sherbrooke
Sherbrooke, Qc
J1A 2R1
Canada



> Date: Wed, 22 Jul 2009 15:13:00 -0400
> From: Chuck Cleland <ccleland at optonline.net>
> Subject: [R-sig-ME] MCMCglmm Bivariate Binary Model
> To: r-sig-mixed-models at r-project.org
> Message-ID: <4A6764BC.8080106 at optonline.net>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Hi All,
>
>   I attempted to fit a bivariate binary model similar to the example in
> the Tutorial:
>
> prior = list(R = list(V = diag(2), n = 0, fix = 2),
>              G = list(G1 = list(V = diag(2), n = 1)))
>
> model5 <- MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
> ~us(trait):PROGRAM, rcov = ~idh(trait):units, family=c("categorical",
> "categorical"), data = radars, prior = prior, verbose = FALSE)
>
> Error in MCMCglmm(cbind(ANYHR, ANYPO) ~ trait - 1, random =
> ~us(trait):PROGRAM,  :
>   ill-conditioned G/R structure: use proper priors if you haven't or
> rescale data if you have
>
>   In this dataset, one of the four cells in the 2x2 table is empty:
>
>    Cell Contents
> |-------------------------|
> |                   Count |
> |-------------------------|
>
> Total Observations in Table:  21335
>
>              | ANYPO
>        ANYHR |        0  |        1  | Row Total |
> -------------|-----------|-----------|-----------|
>            0 |        0  |     8999  |     8999  |
> -------------|-----------|-----------|-----------|
>            1 |     6458  |     5878  |    12336  |
> -------------|-----------|-----------|-----------|
> Column Total |     6458  |    14877  |    21335  |
> -------------|-----------|-----------|-----------|
>
>   Is there a way to change the specification for prior to make this work?
>
> thanks,
>
> Chuck
>



From bates at stat.wisc.edu  Thu Jul 23 18:39:33 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 23 Jul 2009 18:39:33 +0200
Subject: [R-sig-ME] Using lme (possibly nlme) in R
In-Reply-To: <3200229.2371691248341299803.JavaMail.nabble@isper.nabble.com>
References: <3200229.2371691248341299803.JavaMail.nabble@isper.nabble.com>
Message-ID: <40e66e0b0907230939l11e7278dgb599fc4468380fd5@mail.gmail.com>

Sarah sent this directly to me and I am pretty much wiped out right
now having finished the third short course in a month and preparing or
helping to prepare three other presentations.  Could someone else take
a stab at answering this?  I'm tired and I have a full day of
international travel ahead of me tomorrow and I would probably give
nonsense advice.  It looks as if it is urgent for her.


On Thu, Jul 23, 2009 at 11:28 AM, <s.buckmaster.08 at aberdeen.ac.uk> wrote:
> I am an MSc Ecology student in Scotland, UK and am struggling to analyse my dissertation data in R - I only have today and tomorrow to understand my output and so was hoping you could offer some advice. I would be really grateful!
>
> I carried out a plant experiment examining plant interactions between two species (A and B) under different watering treatments. I had
> - 7 watering treatments (7 different watering frequencies labelled 1-7) ...and...
> - 3 replicates of each treatment
>
> At each watering treatment, I had 5 different combinations of plants. I have shown how I have labelled these in brackets for species A:
> A in isolation (Aiso)
> A+A monoculture (Amono)
> A+B interspecific competition (Amix)
> .. and the same for species B.
>
> The first step is to check species A for interspecific competition.... I need to see whether I have a significant replicate effect (block effect) and as this will be a random effect, I am going to use a lme. I have the following factors:
>
> Response variable: ?Amix
> Random effect: ? ? ?Block (replicates labelled as 1,2,3)
> Main effect: ? ? ? ? ?watering treatment (wt) (1-7)
> Covariate: ? ? ? ? ? ? Aiso
> Covariate: ? ? ? ? ? ? Amix.initialsize (initial biomass of Amix to account for any size variation before treatment was started)
>
> I used following formula in lm (before I thought I'd have to include block as random effect):
> lm1<-lm(Amix~Aiso+wt+block+Amix.initialsize+Aiso:wt)
>
> but do not know how to structure it in an lme. How would I do this?
> Also, what is the difference between an lme and an lmer as I was unsure which one to use,
>
>
> Thank you,
>
> Sarah Buckmaster
> E-mail: s.buckmaster.08 at aberdeen.ac.uk
>



From bolker at ufl.edu  Thu Jul 23 19:49:20 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 23 Jul 2009 13:49:20 -0400
Subject: [R-sig-ME] Using lme (possibly nlme) in R
In-Reply-To: <40e66e0b0907230939l11e7278dgb599fc4468380fd5@mail.gmail.com>
References: <3200229.2371691248341299803.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0907230939l11e7278dgb599fc4468380fd5@mail.gmail.com>
Message-ID: <4A68A2A0.1040709@ufl.edu>

  She posted to r-help as well, I gave her basic advice (either lme or
lmer will work for this problem, basic syntax, consider treating blocks
as fixed, or possibly using aov(), since there are only 3 blocks) and
expect that she will reply to r-sig-mixed-models when she hits the next
roadblock ...

  Ben

Douglas Bates wrote:
> Sarah sent this directly to me and I am pretty much wiped out right
> now having finished the third short course in a month and preparing or
> helping to prepare three other presentations.  Could someone else take
> a stab at answering this?  I'm tired and I have a full day of
> international travel ahead of me tomorrow and I would probably give
> nonsense advice.  It looks as if it is urgent for her.
> 
> 
> On Thu, Jul 23, 2009 at 11:28 AM, <s.buckmaster.08 at aberdeen.ac.uk> wrote:
>> I am an MSc Ecology student in Scotland, UK and am struggling to analyse my dissertation data in R - I only have today and tomorrow to understand my output and so was hoping you could offer some advice. I would be really grateful!
>>
>> I carried out a plant experiment examining plant interactions between two species (A and B) under different watering treatments. I had
>> - 7 watering treatments (7 different watering frequencies labelled 1-7) ...and...
>> - 3 replicates of each treatment
>>
>> At each watering treatment, I had 5 different combinations of plants. I have shown how I have labelled these in brackets for species A:
>> A in isolation (Aiso)
>> A+A monoculture (Amono)
>> A+B interspecific competition (Amix)
>> .. and the same for species B.
>>
>> The first step is to check species A for interspecific competition.... I need to see whether I have a significant replicate effect (block effect) and as this will be a random effect, I am going to use a lme. I have the following factors:
>>
>> Response variable:  Amix
>> Random effect:      Block (replicates labelled as 1,2,3)
>> Main effect:          watering treatment (wt) (1-7)
>> Covariate:             Aiso
>> Covariate:             Amix.initialsize (initial biomass of Amix to account for any size variation before treatment was started)
>>
>> I used following formula in lm (before I thought I'd have to include block as random effect):
>> lm1<-lm(Amix~Aiso+wt+block+Amix.initialsize+Aiso:wt)
>>
>> but do not know how to structure it in an lme. How would I do this?
>> Also, what is the difference between an lme and an lmer as I was unsure which one to use,
>>
>>
>> Thank you,
>>
>> Sarah Buckmaster
>> E-mail: s.buckmaster.08 at aberdeen.ac.uk
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From biolger at yahoo.com.ar  Thu Jul 23 23:17:38 2009
From: biolger at yahoo.com.ar (German Garcia)
Date: Thu, 23 Jul 2009 14:17:38 -0700 (PDT)
Subject: [R-sig-ME] consult about fixed factors
Message-ID: <832792.72461.qm@web56403.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090723/32eb7663/attachment.pl>

From slu at ccsr.uchicago.edu  Fri Jul 24 00:33:34 2009
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Thu, 23 Jul 2009 17:33:34 -0500
Subject: [R-sig-ME] lme error message
In-Reply-To: <388510203.6081271248337058002.JavaMail.root@huron.cs.uoguelph.ca>
References: <388510203.6081271248337058002.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <1248388414.9688.5.camel@musuko.spc.uchicago.edu>

On ?, 2009-07-23 at 04:17 -0400, Luca Borger wrote:
> Hello,
> 
> >  Singularity in backsolve at level 0, block 1
> 
> in fact my experience is that in this case there is some problem with
> the fixed effects (e.g. not enough data for all factor combinations
> etc.), otherwise it would say level 1 or higher. By fitting a simpler
> model usually it disappears.
> 
> Disclaimer: just limited empirical experience, I have never checked
> the code to understand better this error message, so take this with
> caution ;-)

I found the problem. One of my predictors was all 0s. (Dumb me.) Thanks
to everyone for the help.

-- 
Stuart Luppescu -=-=- slu <AT> ccsr <DOT> uchicago <DOT> edu
CCSR at U of C ,.;-*^*-;.,  ccsr.uchicago.edu
     (^_^)/    ????????
[Crash programs] fail because they are based on the theory that, 
with nine women pregnant, you can get a baby a month.
                -- Wernher von Braun



From may.katharina at googlemail.com  Fri Jul 24 16:51:06 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Fri, 24 Jul 2009 16:51:06 +0200
Subject: [R-sig-ME] lmer (lme4): % total variance explained by random effect
Message-ID: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090724/dd85f7bc/attachment.pl>

From may.katharina at googlemail.com  Sat Jul 25 13:44:16 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Sat, 25 Jul 2009 13:44:16 +0200
Subject: [R-sig-ME] lmer (lme4): % total variance explained by random
	effect
In-Reply-To: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
Message-ID: <dd40a8b0907250444s7a60b146j453e283eb89465e2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090725/1d84f919/attachment.pl>

From may.katharina at googlemail.com  Sat Jul 25 15:50:21 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Sat, 25 Jul 2009 15:50:21 +0200
Subject: [R-sig-ME] lmer (lme4): extract random effects variance
Message-ID: <dd40a8b0907250650y28faad78pc033cf6ad439e788@mail.gmail.com>

Hi *,

I struggling with extracting some information out of a lmer model:

How can I extract the random effects Groups (Name, Variance) like seen in output
from summary(allo.lmer.ml):
<snip>
Random effects:
 Groups                          Name          Variance  Std.Dev. Corr
 as.factor(biomass_data$site.ID) (Intercept)   0.9714604 0.98563
                                 log(BM_roots) 0.0047707 0.06907  -0.131
</snap>


Somehow I cannot find anything within str(allo.lmer.ml) and
str(summary(allo.lmer.ml))...

I know to extract the AIC and the fixed effects part addressing the
following slots
of the summary output:

summary(allo.lmer.ml)@AICtab
summary(allo.lmer.ml)@coefs


Thanks in advance for any hint, I'm still hoping to avoid copy paste
as I've got several models.

-Katharina



From aalisiyan at gmail.com  Mon Jul 27 15:27:21 2009
From: aalisiyan at gmail.com (alis villiyam)
Date: Mon, 27 Jul 2009 15:27:21 +0200
Subject: [R-sig-ME] Fwd: randomized block design analysis in R
In-Reply-To: <509507040907270047q2cb4a2d7k6ee7bcb05e8d392d@mail.gmail.com>
References: <509507040907270047q2cb4a2d7k6ee7bcb05e8d392d@mail.gmail.com>
Message-ID: <509507040907270627r7f28c538l1ea34a7bf08564b8@mail.gmail.com>

---------- Forwarded message ----------
From: alis villiyam <aalisiyan at gmail.com>
Date: Mon, Jul 27, 2009 at 9:47 AM
Subject: randomized block design analysis in R
To: bolker at zoology.ufl.edu


Dear Tae-kyun Kim

Hello,

I'm a  student and I have some trouble with the experimental
(columns-experiments) design of my project. I use a randomized block design
with 4 treatments including a control. For each treatment, I use 3
replicates and 3 blocks.

The treatments are:

-T1 = COD (300 mg/Lit)   COD=chemical oxygen demand

-T2 = COD (200 mg/Lit)

-T3 = COD (100 mg/Lit)

-T4 = COD (0 mg/Lit) as a control

The experiment is conducted during three months and a sample is taken each
Week in every experimental unit.

At the first, I irrigated all soil columns (12 columns) with demonize water
for 1 week.

Then during 8 weeks, I irrigated all columns with waste water with different
concentration. Then, gain, I irrigated all columns with demonize water for 4
weeks.

Now I want to know how I can analyses the results in R. For example, I want
to detect the
Effect of waste water on some physical properties of soil, before, during
use waste water and after use waste water (Is there any significant change
in properties of soil.) Time is also important, so I want to know the
interaction between time and some physical properties of soil, like water
content .first comprises between Treatments and then comprise between
weeks).

Questions to be answered:

1)      Theta (water content), before (1 week) and after the COD; is there a
difference?
2)      Theta, during, before and after the COD; is there a difference?
3)      Is there a trend in Theta, during COD (8 weeks)?
4)      Is there a difference in Theta, during COD between the treatments?
I hope somebody can help me to find correct statistical analyses in R.


Kind regards,

Alisia

From matejus106 at googlemail.com  Mon Jul 27 16:19:14 2009
From: matejus106 at googlemail.com (jos matejus)
Date: Mon, 27 Jul 2009 15:19:14 +0100
Subject: [R-sig-ME] modelling saturated random effects with glmm
Message-ID: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>

Dear all,

I was wondering whether anyone could enlighten me on the following.

Why is it I can fit a generalized linear mixed model (family = poisson
for example) with lmer where I have as many levels of my random effect
as data points whereas with a linear mixed effects model (gaussian
distributed errors) I get an error message. I understand that the
random effect variance is completely confounded with the residual
variance in the case of a linear mixed model, but why is this not so
with a generalized linear mixed model?

for example

data(ergoStool, package="nlme") # load data
ergoStool$rantest <- 1:36 #create a pseudo random effect to illustrate

library(lme4)

stool.lmm <- lmer(effort~Type+(1|rantest),  data=ergoStool)
#Error: length(levels(dm$flist[[1]])) < length(Y) is not TRUE

stool.glmm <- lmer(effort~Type+(1|rantest) , family=poisson,  data=ergoStool)

summary(stool.glmm)

Generalized linear mixed model fit by the Laplace approximation
#Formula: effort ~ Type + (1 | rantest)
   Data: ergoStool
   AIC   BIC logLik deviance
 19.47 27.39 -4.737    9.474
Random effects:
 Groups  Name        Variance Std.Dev.
 rantest (Intercept)  0        0
Number of obs: 36, groups: rantest, 36

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  2.14658    0.11396  18.836   <2e-16 ***
TypeT2       0.37469    0.14804   2.531   0.0114 *
TypeT3       0.23091    0.15263   1.513   0.1303
TypeT4       0.07503    0.15823   0.474   0.6354
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
       (Intr) TypeT2 TypeT3
TypeT2 -0.770
TypeT3 -0.747  0.575
TypeT4 -0.720  0.554  0.538

Many thanks in advance
Jos



From Greg.Snow at imail.org  Mon Jul 27 17:46:37 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 27 Jul 2009 09:46:37 -0600
Subject: [R-sig-ME] modelling saturated random effects with glmm
In-Reply-To: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>
References: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>

This is a basic property of the distributions.

The normal distribution has 2 parameters, the mean and the variance which are independent of each other.  Therefore in any type of model based on the normal distribution you need at least 1 degree of freedom left over after estimating the mean in order to estimate the variance.

The poisson distribution only has 1 parameter because the variance is equal to the mean in the poisson, so you can use all the degrees of freedom estimating the mean, and that gives you the variance, you don't need additional information to estimate it.  

All this of course is dependent on your assumptions about the distributions being reasonable (the routines do what you tell them too whether they make sense or not).  And any model that uses all or even the majority of the degrees of freedom is unlikely to be very precise or informative even if you do get an "answer".

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of jos matejus
> Sent: Monday, July 27, 2009 8:19 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] modelling saturated random effects with glmm
> 
> Dear all,
> 
> I was wondering whether anyone could enlighten me on the following.
> 
> Why is it I can fit a generalized linear mixed model (family = poisson
> for example) with lmer where I have as many levels of my random effect
> as data points whereas with a linear mixed effects model (gaussian
> distributed errors) I get an error message. I understand that the
> random effect variance is completely confounded with the residual
> variance in the case of a linear mixed model, but why is this not so
> with a generalized linear mixed model?
> 
> for example
> 
> data(ergoStool, package="nlme") # load data
> ergoStool$rantest <- 1:36 #create a pseudo random effect to illustrate
> 
> library(lme4)
> 
> stool.lmm <- lmer(effort~Type+(1|rantest),  data=ergoStool)
> #Error: length(levels(dm$flist[[1]])) < length(Y) is not TRUE
> 
> stool.glmm <- lmer(effort~Type+(1|rantest) , family=poisson,
> data=ergoStool)
> 
> summary(stool.glmm)
> 
> Generalized linear mixed model fit by the Laplace approximation
> #Formula: effort ~ Type + (1 | rantest)
>    Data: ergoStool
>    AIC   BIC logLik deviance
>  19.47 27.39 -4.737    9.474
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  rantest (Intercept)  0        0
> Number of obs: 36, groups: rantest, 36
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.14658    0.11396  18.836   <2e-16 ***
> TypeT2       0.37469    0.14804   2.531   0.0114 *
> TypeT3       0.23091    0.15263   1.513   0.1303
> TypeT4       0.07503    0.15823   0.474   0.6354
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Correlation of Fixed Effects:
>        (Intr) TypeT2 TypeT3
> TypeT2 -0.770
> TypeT3 -0.747  0.575
> TypeT4 -0.720  0.554  0.538
> 
> Many thanks in advance
> Jos
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Mon Jul 27 19:58:35 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 27 Jul 2009 13:58:35 -0400
Subject: [R-sig-ME] modelling saturated random effects with glmm
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>
References: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <4A6DEACB.4070502@ufl.edu>

Greg Snow wrote:
> This is a basic property of the distributions.
> 
> The normal distribution has 2 parameters, the mean and the variance
> which are independent of each other.  Therefore in any type of model
> based on the normal distribution you need at least 1 degree of
> freedom left over after estimating the mean in order to estimate the
> variance.
> 
> The poisson distribution only has 1 parameter because the variance is
> equal to the mean in the poisson, so you can use all the degrees of
> freedom estimating the mean, and that gives you the variance, you
> don't need additional information to estimate it.
> 
> All this of course is dependent on your assumptions about the
> distributions being reasonable (the routines do what you tell them
> too whether they make sense or not).  And any model that uses all or
> even the majority of the degrees of freedom is unlikely to be very
> precise or informative even if you do get an "answer".
> 

  Yes, but ... modeling overdispersion in this way can definitely be
reasonable.  Adding a random-effect level per individual (e.g. assuming
a lognormal-Poisson model, in the Poisson/log link case) is not using
all or even the majority of the degrees of freedom ... there's still
plenty of room left for systematic departures from both the
deterministic and stochastic components of the model ...



From may.katharina at googlemail.com  Mon Jul 27 20:10:10 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Mon, 27 Jul 2009 20:10:10 +0200
Subject: [R-sig-ME] lmer (lme4): extract random effects variance
In-Reply-To: <dd40a8b0907250650y28faad78pc033cf6ad439e788@mail.gmail.com>
References: <dd40a8b0907250650y28faad78pc033cf6ad439e788@mail.gmail.com>
Message-ID: <dd40a8b0907271110h7d6e1067q433ebf8ccddd60b4@mail.gmail.com>

quite embarrassing but I've seemed to completely overlooked
VarCorr()

this does the work (just in case somebody else might have the same
problem): sqrt(VarCorr(fm1)$Subject)


2009/7/25 Katharina May <may.katharina at googlemail.com>:
> Hi *,
>
> I struggling with extracting some information out of a lmer model:
>
> How can I extract the random effects Groups (Name, Variance) like seen in output
> from summary(allo.lmer.ml):
> <snip>
> Random effects:
> ?Groups ? ? ? ? ? ? ? ? ? ? ? ? ?Name ? ? ? ? ?Variance ?Std.Dev. Corr
> ?as.factor(biomass_data$site.ID) (Intercept) ? 0.9714604 0.98563
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? log(BM_roots) 0.0047707 0.06907 ?-0.131
> </snap>
>
>
> Somehow I cannot find anything within str(allo.lmer.ml) and
> str(summary(allo.lmer.ml))...
>
> I know to extract the AIC and the fixed effects part addressing the
> following slots
> of the summary output:
>
> summary(allo.lmer.ml)@AICtab
> summary(allo.lmer.ml)@coefs
>
>
> Thanks in advance for any hint, I'm still hoping to avoid copy paste
> as I've got several models.
>
> -Katharina
>



-- 
Time flies like an arrow, fruit flies like bananas.



From aalisiyan at gmail.com  Tue Jul 28 10:37:04 2009
From: aalisiyan at gmail.com (alis villiyam)
Date: Tue, 28 Jul 2009 10:37:04 +0200
Subject: [R-sig-ME] randomized block design analysis in R
In-Reply-To: <509507040907270627r7f28c538l1ea34a7bf08564b8@mail.gmail.com>
References: <509507040907270047q2cb4a2d7k6ee7bcb05e8d392d@mail.gmail.com>
	<509507040907270627r7f28c538l1ea34a7bf08564b8@mail.gmail.com>
Message-ID: <509507040907280137l2997a93ctd55c5d2e91162a83@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090728/1014a8c2/attachment.pl>

From matejus106 at googlemail.com  Tue Jul 28 10:52:46 2009
From: matejus106 at googlemail.com (jos matejus)
Date: Tue, 28 Jul 2009 09:52:46 +0100
Subject: [R-sig-ME] modelling saturated random effects with glmm
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>
References: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <d003a00f0907280152u61fa7564l3c154d6fec74ed0b@mail.gmail.com>

Thank you Greg and Ben for clearing that up. Sometimes I get so caught
up in the detail of mixed modelling that I forget some of the
fundamentals. By the way, I can see how adding a random effect level
per observation would account for some of the heterogeniety causing
overdispersion, but wouldn't this be dependent on the potential
underlying causes of the overdispersion? For example, if you have a
high proportion of  zeros in the data, would this approach still be
valid? Wouldn't it be better to address the causes of overdispersion
directly by refining the fixed and random effects structure more or by
using a more appropriate distribution such as a negative binomial, zip
or zinb?

Best
Jos

2009/7/27 Greg Snow <Greg.Snow at imail.org>:
> This is a basic property of the distributions.
>
> The normal distribution has 2 parameters, the mean and the variance which are independent of each other. ?Therefore in any type of model based on the normal distribution you need at least 1 degree of freedom left over after estimating the mean in order to estimate the variance.
>
> The poisson distribution only has 1 parameter because the variance is equal to the mean in the poisson, so you can use all the degrees of freedom estimating the mean, and that gives you the variance, you don't need additional information to estimate it.
>
> All this of course is dependent on your assumptions about the distributions being reasonable (the routines do what you tell them too whether they make sense or not). ?And any model that uses all or even the majority of the degrees of freedom is unlikely to be very precise or informative even if you do get an "answer".
>
> Hope this helps,
>
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
>> models-bounces at r-project.org] On Behalf Of jos matejus
>> Sent: Monday, July 27, 2009 8:19 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] modelling saturated random effects with glmm
>>
>> Dear all,
>>
>> I was wondering whether anyone could enlighten me on the following.
>>
>> Why is it I can fit a generalized linear mixed model (family = poisson
>> for example) with lmer where I have as many levels of my random effect
>> as data points whereas with a linear mixed effects model (gaussian
>> distributed errors) I get an error message. I understand that the
>> random effect variance is completely confounded with the residual
>> variance in the case of a linear mixed model, but why is this not so
>> with a generalized linear mixed model?
>>
>> for example
>>
>> data(ergoStool, package="nlme") # load data
>> ergoStool$rantest <- 1:36 #create a pseudo random effect to illustrate
>>
>> library(lme4)
>>
>> stool.lmm <- lmer(effort~Type+(1|rantest), ?data=ergoStool)
>> #Error: length(levels(dm$flist[[1]])) < length(Y) is not TRUE
>>
>> stool.glmm <- lmer(effort~Type+(1|rantest) , family=poisson,
>> data=ergoStool)
>>
>> summary(stool.glmm)
>>
>> Generalized linear mixed model fit by the Laplace approximation
>> #Formula: effort ~ Type + (1 | rantest)
>> ? ?Data: ergoStool
>> ? ?AIC ? BIC logLik deviance
>> ?19.47 27.39 -4.737 ? ?9.474
>> Random effects:
>> ?Groups ?Name ? ? ? ?Variance Std.Dev.
>> ?rantest (Intercept) ?0 ? ? ? ?0
>> Number of obs: 36, groups: rantest, 36
>>
>> Fixed effects:
>> ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ?2.14658 ? ?0.11396 ?18.836 ? <2e-16 ***
>> TypeT2 ? ? ? 0.37469 ? ?0.14804 ? 2.531 ? 0.0114 *
>> TypeT3 ? ? ? 0.23091 ? ?0.15263 ? 1.513 ? 0.1303
>> TypeT4 ? ? ? 0.07503 ? ?0.15823 ? 0.474 ? 0.6354
>> ---
>> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>> ? ? ? ?(Intr) TypeT2 TypeT3
>> TypeT2 -0.770
>> TypeT3 -0.747 ?0.575
>> TypeT4 -0.720 ?0.554 ?0.538
>>
>> Many thanks in advance
>> Jos
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Jul 28 13:58:18 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 28 Jul 2009 07:58:18 -0400
Subject: [R-sig-ME] modelling saturated random effects with glmm
In-Reply-To: <d003a00f0907280152u61fa7564l3c154d6fec74ed0b@mail.gmail.com>
References: <d003a00f0907270719na5ad69av898938a931e711ad@mail.gmail.com>	
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6212CC71B9@LP-EXMBVS10.CO.IHC.COM>
	<d003a00f0907280152u61fa7564l3c154d6fec74ed0b@mail.gmail.com>
Message-ID: <4A6EE7DA.6040500@ufl.edu>

jos matejus wrote:
> Thank you Greg and Ben for clearing that up. Sometimes I get so
> caught up in the detail of mixed modelling that I forget some of the 
> fundamentals. By the way, I can see how adding a random effect level 
> per observation would account for some of the heterogeniety causing 
> overdispersion, but wouldn't this be dependent on the potential 
> underlying causes of the overdispersion? For example, if you have a 
> high proportion of  zeros in the data, would this approach still be 
> valid? Wouldn't it be better to address the causes of overdispersion 
> directly by refining the fixed and random effects structure more or
> by using a more appropriate distribution such as a negative binomial,
> zip or zinerb?
> 
> Best Jos

   Yes, of course adding more known covariates or grouping factors, or
using a zero-inflated distribution if the data suggest it, might be
better than adding individual-level heterogeneity -- but it depends on
the data.  Remember that "lots of zeros" is not in itself a prescription
to use a zero-inflated distribution -- Poissons or negative binomials
with small means also have lots of zeros.

Warton, David I. ?Many zeros does not mean zero inflation: comparing the
goodness-of-fit of parametric models to multivariate abundance data.?
Environmetrics 16, no. 3 (2005): 275-289.

> 
> 2009/7/27 Greg Snow <Greg.Snow at imail.org>:
>> This is a basic property of the distributions.
>> 
>> The normal distribution has 2 parameters, the mean and the variance
>> which are independent of each other.  Therefore in any type of
>> model based on the normal distribution you need at least 1 degree
>> of freedom left over after estimating the mean in order to estimate
>> the variance.
>> 
>> The poisson distribution only has 1 parameter because the variance
>> is equal to the mean in the poisson, so you can use all the degrees
>> of freedom estimating the mean, and that gives you the variance,
>> you don't need additional information to estimate it.
>> 
>> All this of course is dependent on your assumptions about the
>> distributions being reasonable (the routines do what you tell them
>> too whether they make sense or not).  And any model that uses all
>> or even the majority of the degrees of freedom is unlikely to be
>> very precise or informative even if you do get an "answer".
>> 
>> Hope this helps,
>> 
>> -- Gregory (Greg) L. Snow Ph.D. Statistical Data Center 
>> Intermountain Healthcare greg.snow at imail.org 801.408.8111
>> 
>> 
>>> -----Original Message----- From:
>>> r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed- 
>>> models-bounces at r-project.org] On Behalf Of jos matejus Sent:
>>> Monday, July 27, 2009 8:19 AM To:
>>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] modelling
>>> saturated random effects with glmm
>>> 
>>> Dear all,
>>> 
>>> I was wondering whether anyone could enlighten me on the
>>> following.
>>> 
>>> Why is it I can fit a generalized linear mixed model (family =
>>> poisson for example) with lmer where I have as many levels of my
>>> random effect as data points whereas with a linear mixed effects
>>> model (gaussian distributed errors) I get an error message. I
>>> understand that the random effect variance is completely
>>> confounded with the residual variance in the case of a linear
>>> mixed model, but why is this not so with a generalized linear
>>> mixed model?
>>> 
>>> for example
>>> 
>>> data(ergoStool, package="nlme") # load data ergoStool$rantest <-
>>> 1:36 #create a pseudo random effect to illustrate
>>> 
>>> library(lme4)
>>> 
>>> stool.lmm <- lmer(effort~Type+(1|rantest),  data=ergoStool) 
>>> #Error: length(levels(dm$flist[[1]])) < length(Y) is not TRUE
>>> 
>>> stool.glmm <- lmer(effort~Type+(1|rantest) , family=poisson, 
>>> data=ergoStool)
>>> 
>>> summary(stool.glmm)
>>> 
>>> Generalized linear mixed model fit by the Laplace approximation 
>>> #Formula: effort ~ Type + (1 | rantest) Data: ergoStool AIC   BIC
>>> logLik deviance 19.47 27.39 -4.737    9.474 Random effects: 
>>> Groups  Name        Variance Std.Dev. rantest (Intercept)  0
>>> 0 Number of obs: 36, groups: rantest, 36
>>> 
>>> Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept)
>>> 2.14658    0.11396  18.836   <2e-16 *** TypeT2       0.37469
>>> 0.14804   2.531   0.0114 * TypeT3       0.23091    0.15263
>>> 1.513   0.1303 TypeT4       0.07503    0.15823   0.474   0.6354 
>>> --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' '
>>> 1
>>> 
>>> Correlation of Fixed Effects: (Intr) TypeT2 TypeT3 TypeT2 -0.770 
>>> TypeT3 -0.747  0.575 TypeT4 -0.720  0.554  0.538
>>> 
>>> Many thanks in advance Jos
>>> 
>>> _______________________________________________ 
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From levyofi at gmail.com  Tue Jul 28 17:41:25 2009
From: levyofi at gmail.com (Ofir Levy)
Date: Tue, 28 Jul 2009 18:41:25 +0300
Subject: [R-sig-ME] An advice needed on paper statistical analysis
	description
Message-ID: <4A6F1C25.2090807@gmail.com>

Dear list members,


I in the final stages of writing a paper which summarized some of my PhD 
aspects. I did a lot of mixed effects modelling. I have started with the 
lme function (I prefer it on `lmer` becuase it is more documented and 
more flexible in terms of weight and correlation structures). I came out 
with non-convincing p-values (As Zuur's 2009 book describes it - between 
0.001 to 0.1) on most models so I decided to run the models with MCMC 
simulations using BUGS with the JAGS software in order to make 
statistical inferences from the confidence intervals. Some models are 
simple ANOVAs with random effects and sometimes a variance structure and 
some models are ANCOVA models. I also used a GLMM with negative binomial 
distribution model with dispersion parameter structure using JAGS. This 
latter kind of model is not yet implemented in R as well as I know.


Now I wonder what to write on the paper. I guess I should explain why I 
used the somehow more complex approach (writing the models myself in 
JAGS) and I hope the reviewers will not reject the paper... I want to 
submit the paper to Ecology and most papers in this journal with BUGS 
analysis are much more complex and unique to a specific problem.


I will be thankful to hear your advices.


Thanks,

Ofir.



From highstat at highstat.com  Wed Jul 29 12:36:06 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Wed, 29 Jul 2009 11:36:06 +0100
Subject: [R-sig-ME] An advice needed on paper statistical analysis,
	description
Message-ID: <4A702616.4010000@highstat.com>


>I in the final stages of writing a paper which summarized some of my PhD 
aspects. I did a lot of mixed effects modelling. I have started with the 
lme function (I prefer it on `lmer` becuase it is more documented and 
more flexible in terms of weight and correlation structures). I came out 
with non-convincing p-values (As Zuur's 2009 book describes it - between 
0.001 to 0.1) 




Did we say that? We may have said that p-values in the order of 0.01 are not convincing for a GAM(M).





Now I wonder what to write on the paper. 



We all do!
Alain




I guess I should explain why I 
used the somehow more complex approach (writing the models myself in 
JAGS) and I hope the reviewers will not reject the paper... I want to 
submit the paper to Ecology and most papers in this journal with BUGS 
analysis are much more complex and unique to a specific problem.
I will be thankful to hear your advices.














Thanks,

Ofir.

-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From levyofi at gmail.com  Wed Jul 29 13:42:50 2009
From: levyofi at gmail.com (Ofir Levy)
Date: Wed, 29 Jul 2009 14:42:50 +0300
Subject: [R-sig-ME] An advice needed on paper statistical analysis
	description
Message-ID: <4A7035BA.8070103@gmail.com>


I will rephrase my question...
Does it reasonable to perform the statistical analysis using MCMC 
simulations instead of available well-tested and documented functions 
when p-values may mislead? If looking at the 0.05 order p-values. I had 
2 tests of 5 with p-values between 0.1 and 0.01 so I decided to perform 
the whole analysis with MCMC simulations. Under what kind of models I 
should also submit the BUGS code and detailed description of the models?
I know some of you have wonders sometimes what to write in your 
statistical description part of a paper so this might be a helpful 
discussion...

Cheers,
Ofir.

>

Highland Statistics Ltd. wrote:

>
>> I in the final stages of writing a paper which summarized some of my PhD 
> aspects. I did a lot of mixed effects modelling. I have started with 
> the lme function (I prefer it on `lmer` becuase it is more documented 
> and more flexible in terms of weight and correlation structures). I 
> came out with non-convincing p-values (As Zuur's 2009 book describes 
> it - between 0.001 to 0.1)
>
>


> Did we say that? We may have said that p-values in the order of 0.01 
> are not convincing for a GAM(M).
>
>
> Now I wonder what to write on the paper.
>
>
> We all do!
> Alain
>
>
>
> I guess I should explain why I used the somehow more complex approach 
> (writing the models myself in JAGS) and I hope the reviewers will not 
> reject the paper... I want to submit the paper to Ecology and most 
> papers in this journal with BUGS analysis are much more complex and 
> unique to a specific problem.
> I will be thankful to hear your advices.
>
>
>
>
> Thanks,
>
> Ofir.
>



From pogola at Princeton.EDU  Thu Jul 30 05:09:37 2009
From: pogola at Princeton.EDU (Patrick Onyango)
Date: Wed, 29 Jul 2009 23:09:37 -0400
Subject: [R-sig-ME] Nested and crossed random effects
Message-ID: <2D0A0629-213C-4E93-8B82-6C1B4E63CAAB@Princeton.EDU>

Dear All,
I am in transition from SPSS to R and so I am trying to read as much  
as I can to address some of my immediate statistical needs. And so,  
as with most transitions, I am plagued by haste that some of you may  
find quite sublime; but I ask for leniency.

I am trying to model a response variable, response,  as a function of  
the following fixed terms: a, b, c, d, and e; and 3 random effects:  
f, g, h such that g denotes the ID of my sampling subjects sampled  
over time and the subjects are distributed in 5 groups, here denoted  
by f. An important note is that I sampled g as part of a pair with h  
such that overall I have 131 samples involving 39 different gs and 45  
different hs where h may be or may not be at 2 levels of two of the  
fixed terms, let's for convenience call those terms d and e, each  
with levels 1 and 2. The number of samples among h are pretty uneven.

The main idea is to find out what g does given the level of h; and  
how is that influenced by a,b,c as well as vary by the IDs f,g,h  
where f is the highest level of random effects and g and h should  
probably be crossed terms?

This is what I did:
model<-lmer(response~a+b+c+d+e+(1|f)+(1|f/g)+(1|g)+(1|h), method='ML')

but got the following warning message
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In g:f:
   numerical expression has 131 elements: only the first used
2: In g:f:
   numerical expression has 131 elements: only the first used
3: In h:f :
   numerical expression has 131 elements: only the first used
4: In h:f :
   numerical expression has 131 elements: only the first used

Then I tried
model<-lmer(response~a+b+c+d+e+(1|f)+(1+f|g)+(1|g)+(1|h),  
method='ML') only making one change at the nested term; and got the  
following Error message

In mer_finalize(ans) : singular convergence (7)

Further, the output from the latter call found a perfect correlation  
for the intercept and slope of g indicating overparametization; and  
so I sought to simplify the model by removing the correlation term  
and assuming homoscedasticity for g in respect to f by replacing the  
nested term in the previous call with (1|f:g), and also adding corr =  
FALSE in the call

But got the following
Error: length(f1) == length(f2) is not TRUE

I go in your records as probably having the longest post. An  
achievement indeed.

I need and will be most thankful for help in figuring how to handle  
my data and in deciphering the error messages.

Many thanks in advance; and please let me if further clarifications  
would suffice.
Patrick



From reinhold.kliegl at gmail.com  Thu Jul 30 10:10:20 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 30 Jul 2009 10:10:20 +0200
Subject: [R-sig-ME] Nested and crossed random effects
In-Reply-To: <2D0A0629-213C-4E93-8B82-6C1B4E63CAAB@Princeton.EDU>
References: <2D0A0629-213C-4E93-8B82-6C1B4E63CAAB@Princeton.EDU>
Message-ID: <aefe4d0a0907300110m448e6353w99fde7909cdc2e36@mail.gmail.com>

I predict you will receive constructive feedback if you provide a
dataframe with (simulated) data.
Reinhold Kliegl

On Thu, Jul 30, 2009 at 5:09 AM, Patrick Onyango<pogola at princeton.edu> wrote:
> Dear All,
> I am in transition from SPSS to R and so I am trying to read as much as I
> can to address some of my immediate statistical needs. And so, as with most
> transitions, I am plagued by haste that some of you may find quite sublime;
> but I ask for leniency.
>
> I am trying to model a response variable, response, ?as a function of the
> following fixed terms: a, b, c, d, and e; and 3 random effects: f, g, h such
> that g denotes the ID of my sampling subjects sampled over time and the
> subjects are distributed in 5 groups, here denoted by f. An important note
> is that I sampled g as part of a pair with h such that overall I have 131
> samples involving 39 different gs and 45 different hs where h may be or may
> not be at 2 levels of two of the fixed terms, let's for convenience call
> those terms d and e, each with levels 1 and 2. The number of samples among h
> are pretty uneven.
>
> The main idea is to find out what g does given the level of h; and how is
> that influenced by a,b,c as well as vary by the IDs f,g,h where f is the
> highest level of random effects and g and h should probably be crossed
> terms?
>
> This is what I did:
> model<-lmer(response~a+b+c+d+e+(1|f)+(1|f/g)+(1|g)+(1|h), method='ML')
>
> but got the following warning message
> Error: length(f1) == length(f2) is not TRUE
> In addition: Warning messages:
> 1: In g:f:
> ?numerical expression has 131 elements: only the first used
> 2: In g:f:
> ?numerical expression has 131 elements: only the first used
> 3: In h:f :
> ?numerical expression has 131 elements: only the first used
> 4: In h:f :
> ?numerical expression has 131 elements: only the first used
>
> Then I tried
> model<-lmer(response~a+b+c+d+e+(1|f)+(1+f|g)+(1|g)+(1|h), method='ML') only
> making one change at the nested term; and got the following Error message
>
> In mer_finalize(ans) : singular convergence (7)
>
> Further, the output from the latter call found a perfect correlation for the
> intercept and slope of g indicating overparametization; and so I sought to
> simplify the model by removing the correlation term and assuming
> homoscedasticity for g in respect to f by replacing the nested term in the
> previous call with (1|f:g), and also adding corr = FALSE in the call
>
> But got the following
> Error: length(f1) == length(f2) is not TRUE
>
> I go in your records as probably having the longest post. An achievement
> indeed.
>
> I need and will be most thankful for help in figuring how to handle my data
> and in deciphering the error messages.
>
> Many thanks in advance; and please let me if further clarifications would
> suffice.
> Patrick
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From aalisiyan at gmail.com  Thu Jul 30 10:29:44 2009
From: aalisiyan at gmail.com (alis villiyam)
Date: Thu, 30 Jul 2009 10:29:44 +0200
Subject: [R-sig-ME] RCBD in R
Message-ID: <509507040907300129j59b5eadcl3be30e6e7d89f721@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090730/1987f953/attachment.pl>

From bolker at ufl.edu  Thu Jul 30 23:30:17 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 30 Jul 2009 17:30:17 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
Message-ID: <4A7210E9.8050602@ufl.edu>


  When I use the latest r-forge version of lme4
(  0.999375-32 ) it seems to fail R CMD check on a tiny
numerical mismatch of two objects that are supposed
(??) to be identical (I also
get a mangled CHOLMOD error message, but I suspect that
comes from somewhere within Matrix ...)

  can anyone confirm? any ideas for a fix?

  The offending mismatch between ranef(m2) and ranef(m3)
is very small ...

> ranef(m2)
$ff
  (Intercept)          x2
1  -0.8896154  0.06947426
2   1.9253111 -0.15035662
3  -0.1315062  0.01026994
4   0.2420718 -0.01890453

> ranef(m3)
$ff
  (Intercept)          x2
1  -0.8896130  0.06947407
2   1.9253069 -0.15035628
3  -0.1315054  0.01026988
4   0.2420710 -0.01890446

  (this doesn't affect anything I'm doing directly, but
I want to build some Windows binaries of a hacked version
using the CRAN win-builder, and to do that I think it
needs to pass R CMD check ... for now I am going to
try commenting out the offending test, but that seems
like a bad idea in general ...)



> getwd()
[1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"

> source("lmer-1.R",echo=TRUE)

...
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
                 x1=rnorm(20,3), x2=rnorm(20,7),
                 x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)),
+           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
[TRUNCATED]
CHOLMOD error: =*?1????@????T??o????
Error: identical(ranef(m0), ranef(m1)) is not TRUE
In addition: Warning message:
In Ops.factor(ff, x1) : + not meaningful for factors

sessionInfo():

R version 2.9.1 (2009-06-26)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MASS_7.2-47        lme4_0.999375-32   Matrix_0.999375-29
lattice_0.17-25

loaded via a namespace (and not attached):
[1] grid_2.9.1

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From maechler at stat.math.ethz.ch  Fri Jul 31 10:41:18 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 31 Jul 2009 10:41:18 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4A7210E9.8050602@ufl.edu>
References: <4A7210E9.8050602@ufl.edu>
Message-ID: <19058.44590.672088.932344@lynne.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:

    BB> When I use the latest r-forge version of lme4
    BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
    BB> numerical mismatch of two objects that are supposed
    BB> (??) to be identical (I also
    BB> get a mangled CHOLMOD error message, but I suspect that
    BB> comes from somewhere within Matrix ...)

yes, and those should be gone with the version of Matrix 
(0.999375-30) of two days ago.

    BB> can anyone confirm? 

No.  To the contrary.
I have had a slightly updated version of tests/lmer-1.Rout.save
ready to be committed for a while, but that's only trivial
changes.

and below, from your sessionInfo(), it looks like you are using
a current version of R and packages ... 
hmm ...

Regards,
Martin


    BB> can anyone confirm? any ideas for a fix?


    BB> The offending mismatch between ranef(m2) and ranef(m3)
    BB> is very small ...

well; it's interesting that the offending mismatch in the error
message below is between  m0 and m1,  ...

    >> ranef(m2)
    BB> $ff
    BB> (Intercept)          x2
    BB> 1  -0.8896154  0.06947426
    BB> 2   1.9253111 -0.15035662
    BB> 3  -0.1315062  0.01026994
    BB> 4   0.2420718 -0.01890453

    >> ranef(m3)
    BB> $ff
    BB> (Intercept)          x2
    BB> 1  -0.8896130  0.06947407
    BB> 2   1.9253069 -0.15035628
    BB> 3  -0.1315054  0.01026988
    BB> 4   0.2420710 -0.01890446

    BB> (this doesn't affect anything I'm doing directly, but
    BB> I want to build some Windows binaries of a hacked version
    BB> using the CRAN win-builder, and to do that I think it
    BB> needs to pass R CMD check ... for now I am going to
    BB> try commenting out the offending test, but that seems
    BB> like a bad idea in general ...)

yes, "bad idea ..".

BTW: Have you noticed that we (Doug Bates and I, when at the
useR/DSC meetings) have moved the former 'allcoef' branch into a
``regular R-forge package''  called  'lme4a'

But yes, that definitely does not pass 'CMD check at the moment'.

    >> getwd()
    BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"

    >> source("lmer-1.R",echo=TRUE)

    BB> ...
    >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
    BB> x1=rnorm(20,3), x2=rnorm(20,7),
    BB> x3=rnorm(20,1))
    >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
    >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)

We had added these checks exactly *because* we wanted to be sure
that a slightly different use of formulas would lead to the
identical 'X', 'Z', .... matrices, and L(theta)
parametrizations,
so I wonder how your version of lme4 could give different
results here....

    >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
    >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
    >> stopifnot(identical(ranef(m0), ranef(m1)),
    BB> +           identical(ranef(m2), ranef(m3)),
    BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
    BB> [TRUNCATED]
    BB> CHOLMOD error: =*?1????@???T??o????
    BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
    BB> In addition: Warning message:
    BB> In Ops.factor(ff, x1) : + not meaningful for factors

Note that the cholmod error and warning is from the 
   lmer(y ~ x2|ff + x1, data = D)
part {which is wrapped in  tryCatch(...)}.

Also, if I execute

##----------------------------------------------------
D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
                 x1=rnorm(20,3), x2=rnorm(20,7),
                 x3=rnorm(20,1))
m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
m1 <- lmer(y ~ x1 + x2|ff  , data = D)
m2 <- lmer(y ~ x1 + (x2|ff), data = D)
m3 <- lmer(y ~ (x2|ff) + x1, data = D)
stopifnot(identical(ranef(m0), ranef(m1)),
          identical(ranef(m2), ranef(m3)))
cat("Ok\n")
##----------------------------------------------------

many times, I never see a problem.

Are you sure you are not using your already-hacked version of
lme4 ???

Martin Maechler, ETH Zurich

    BB> sessionInfo():

    BB> R version 2.9.1 (2009-06-26)
    BB> i486-pc-linux-gnu

    BB> locale:
    BB> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

    BB> attached base packages:
    BB> [1] stats     graphics  grDevices utils     datasets  methods   base

    BB> other attached packages:
    BB> [1] MASS_7.2-47        lme4_0.999375-32   Matrix_0.999375-29
    BB> lattice_0.17-25

    BB> loaded via a namespace (and not attached):
    BB> [1] grid_2.9.1

    BB> -- 
    BB> Ben Bolker
    BB> Associate professor, Biology Dep't, Univ. of Florida
    BB> bolker at ufl.edu / www.zoology.ufl.edu/bolker
    BB> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

    BB> _______________________________________________
    BB> R-sig-mixed-models at r-project.org mailing list
    BB> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From cacabelos at uvigo.es  Wed Jul 29 18:11:04 2009
From: cacabelos at uvigo.es (cacabelos at uvigo.es)
Date: Wed, 29 Jul 2009 18:11:04 +0200
Subject: [R-sig-ME] AIC comparisons between lmer and glm
Message-ID: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>

Hi R-users,

I was unfortunately not able to find a solution to my problem about  
model selection. I have fixed (e.g. Height) and random (e.g.Time)  
factors, and I created these kind of model structures:

Model1<-lmer(H~Height+(1|Time)+Biomass)+(Biomass|Time),data=dat,family=gaussian)
Model2<-glm(H~Height+Biomass,data=dat,family=gaussian)

I am using the criterion ?the best model is the one that has the  
lowest AIC?, but are these AIC from different procedures (i.e. glm and  
lmer) comparable?

I wonder if anyone can help me... Thank you!



From nicolajday at gmail.com  Fri Jul 31 05:11:12 2009
From: nicolajday at gmail.com (Nicola Day)
Date: Fri, 31 Jul 2009 15:11:12 +1200
Subject: [R-sig-ME] glmms and mcmc
Message-ID: <cacda07f0907302011s47326cc7o70a0d040fa2edb6e@mail.gmail.com>

Hi there,

I?d like to use Markov Chain Monte Carlo methods to create Highest
Posterior Density intervals for the parameter estimates in my glmm in
an ecological study. I see that the mcmcsamp function in lme4 is still
under review - could anyone recommend another package that could do
this?  Is the mcmc method still generally accepted as okay for glmms
or should I be looking for alternative methods?

Any help is much appreciated.

Thanks,
Nicola



From pogola at Princeton.EDU  Sat Aug  1 03:22:31 2009
From: pogola at Princeton.EDU (Patrick Onyango)
Date: Fri, 31 Jul 2009 21:22:31 -0400
Subject: [R-sig-ME] AIC comparisons between lmer and glm
In-Reply-To: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
References: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
Message-ID: <F2CF4597-66DB-42B9-9E7A-5C1EF64F2B37@princeton.edu>

I will let the more knowledgeable folks get back address the issues  
regarding specification of your model structure; but try to give you  
my thoughts on comparison of AIC or other information criteria for  
that matter.

1. Yes, the best model is the one with the smallest AIC value; and it  
is also advisable to check the p values generated when you run the  
anova command.
2. I don't think you can compare AIC values obtained from lmer and  
glm; and so the short answer to your question is no.

Good luck,
Patrick


On Jul 29, 2009, at 12:11 PM, cacabelos at uvigo.es wrote:

> Hi R-users,
>
> I was unfortunately not able to find a solution to my problem about  
> model selection. I have fixed (e.g. Height) and random (e.g.Time)  
> factors, and I created these kind of model structures:
>
> Model1<-lmer(H~Height+(1|Time)+Biomass)+(Biomass| 
> Time),data=dat,family=gaussian)
> Model2<-glm(H~Height+Biomass,data=dat,family=gaussian)
>
> I am using the criterion ?the best model is the one that has the  
> lowest AIC?, but are these AIC from different procedures (i.e. glm  
> and lmer) comparable?
>
> I wonder if anyone can help me... Thank you!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken at kjbeath.com.au  Sat Aug  1 03:44:07 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Sat, 1 Aug 2009 11:44:07 +1000
Subject: [R-sig-ME] AIC comparisons between lmer and glm
In-Reply-To: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
References: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
Message-ID: <367AA0B3-C3B4-4ADC-A42D-727571BCFD20@kjbeath.com.au>

Not necessarily. Some routines calculate incorrect log likelihoods and  
thus AIC by ignoring constants, but I'm not certain what the status of  
lmer is. It happens in other programs.

Maybe try some simulated data with a negligible random effect, then  
there should be no difference whether the random effect is included.

Ken

On 30/07/2009, at 2:11 AM, cacabelos at uvigo.es wrote:

> Hi R-users,
>
> I was unfortunately not able to find a solution to my problem about  
> model selection. I have fixed (e.g. Height) and random (e.g.Time)  
> factors, and I created these kind of model structures:
>
> Model1<-lmer(H~Height+(1|Time)+Biomass)+(Biomass| 
> Time),data=dat,family=gaussian)
> Model2<-glm(H~Height+Biomass,data=dat,family=gaussian)
>
> I am using the criterion ?the best model is the one that has the  
> lowest AIC?, but are these AIC from different procedures (i.e. glm  
> and lmer) comparable?
>
> I wonder if anyone can help me... Thank you!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From peter.dixon at ualberta.ca  Sat Aug  1 16:57:50 2009
From: peter.dixon at ualberta.ca (Peter Dixon)
Date: Sat, 1 Aug 2009 08:57:50 -0600
Subject: [R-sig-ME] AIC comparisons between lmer and glm
In-Reply-To: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
References: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
Message-ID: <C1789BB4-F5DC-420C-92A8-5C6862BDDABE@ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090801/b3a39be4/attachment.pl>

From bolker at ufl.edu  Sat Aug  1 18:31:31 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 01 Aug 2009 12:31:31 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
References: <4A7210E9.8050602@ufl.edu>	
	<19058.44590.672088.932344@lynne.math.ethz.ch>	
	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
Message-ID: <4A746DE3.3000704@ufl.edu>


  I don't mind it being public.

  I got similar results with the CRAN lme4 (0.999375-31),
with Matrix ...-30.  BATCH fails on m2 != m3 (consistently);
source() fails on m0 != m1.

  I'm probably doing something really really dumb, would appreciate
anyone else who can try this on their systems ...

  If you don't feel like downloading or running all of lmer-1.R, the
following code chunk should demonstrate the problem ...

=================
library(lme4)

set.seed(1)
## Wrong formula gave a seg.fault at times:
D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
                 x1=rnorm(20,3), x2=rnorm(20,7),
                 x3=rnorm(20,1))
m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
m1 <- lmer(y ~ x1 + x2|ff  , data = D)
m2 <- lmer(y ~ x1 + (x2|ff), data = D)
m3 <- lmer(y ~ (x2|ff) + x1, data = D)
stopifnot(identical(ranef(m0), ranef(m1)),
          identical(ranef(m2), ranef(m3)),
          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
function(e)e),
                   "error"))

## Check the use of offset
om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)

stopifnot(identical(ranef(om2), ranef(om3)),
          identical(deviance(om2), deviance(om3)))
if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
    stop("offset does not change the fixed effects")

cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''


Martin Maechler wrote:
> Hi Ben,
> as you took this "private", I'd like at least Doug Bates
> to be in the CC ..
> Personally I would prefer to have this continue in the R-SIG-ME list
> rather than privately...  I'll be pretty offline from now till Monday
> in any case
> 
> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>> Martin Maechler wrote:
>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>     BB> When I use the latest r-forge version of lme4
>>>     BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
>>>     BB> numerical mismatch of two objects that are supposed
>>>     BB> (??) to be identical (I also
>>>     BB> get a mangled CHOLMOD error message, but I suspect that
>>>     BB> comes from somewhere within Matrix ...)
>>>
>>> yes, and those should be gone with the version of Matrix
>>> (0.999375-30) of two days ago.
>>>
>>>     BB> can anyone confirm?
>>>
>>> No.  To the contrary.
>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>> ready to be committed for a while, but that's only trivial
>>> changes.
>>>
>>> and below, from your sessionInfo(), it looks like you are using
>>> a current version of R and packages ...
>>> hmm ...
>>>
>>> Regards,
>>> Martin
>>>
>>>
>>>     BB> can anyone confirm? any ideas for a fix?
>>>
>>>
>>>     BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>     BB> is very small ...
>>>
>>> well; it's interesting that the offending mismatch in the error
>>> message below is between  m0 and m1,  ...
>>  hmmm indeed.  Maybe I was already hacking things.  I have
>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>> sessionInfo() says
>>
>>  lme4_0.999375-32   Matrix_0.999375-30
>>
>> in ../tests, I do
>>
>> R --vanilla
>> library(lme4)
>> source("lmer-1.R",echo=TRUE)
>>
>> or
>>
>> R CMD BATCH --vanilla lmer-1.R
>>
>>  oddly, the second (BATCH) always fails on m0/m1; the
>> first (source) fails at different comparisons (sometimes m0/m1;
>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
> 
> I just can't understand how that *can* happen.
> It would mean that the algorithms used were slightly "random",  or
> e.g. using slightly different precision depending on memory
> allocation, or ??,
> ???
> 
> As I said i the first e-mail: The slightly different formula should
> produce absolutely identical matrices and vectors which define the
> loglikelihood (or RE-LogLik.) and then the minimization really should
> be 100% reproducible on a given R+Platform+Installed-Packages setup.
> 
> I assume you have tried the same with the CRAN-version of lme4 ...
> which has exactly the same tests/lmer-1.R  ?
> ....
> the phenomenon looks so illogical,  I even start to wonder if it's a
> bug in your computer (hardware-low-level software combination)?
> Maybe you could ask again on R-SIg-ME if others could reproduce?
> 
>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>> ``regular R-forge package''  called  'lme4a'
>>  yes.
>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>
>>>     >> getwd()
>>>     BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>
>>>     >> source("lmer-1.R",echo=TRUE)
>>>
>>>     BB> ...
>>>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>     BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>     BB> x3=rnorm(20,1))
>>>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>
>>> We had added these checks exactly *because* we wanted to be sure
>>> that a slightly different use of formulas would lead to the
>>> identical 'X', 'Z', .... matrices, and L(theta)
>>> parametrizations,
>>> so I wonder how your version of lme4 could give different
>>> results here....
>>>
>>>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>     BB> +           identical(ranef(m2), ranef(m3)),
>>>     BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>     BB> [TRUNCATED]
>>>     BB> CHOLMOD error: =*?1????@???T??o????
>>>     BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>     BB> In addition: Warning message:
>>>     BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>
>>> Note that the cholmod error and warning is from the
>>>    lmer(y ~ x2|ff + x1, data = D)
>>> part {which is wrapped in  tryCatch(...)}.
>>>
>>> Also, if I execute
>>>
>>> ##----------------------------------------------------
>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>                  x1=rnorm(20,3), x2=rnorm(20,7),
>>>                  x3=rnorm(20,1))
>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>           identical(ranef(m2), ranef(m3)))
>>> cat("Ok\n")
>>> ##----------------------------------------------------
>>>
>>> many times, I never see a problem.
>>>
>>> Are you sure you are not using your already-hacked version of
>>> lme4 ???
>>>
>>> Martin Maechler, ETH Zurich
>>>
>>  I'm not 100.0000% sure, but I don't see how I could be ...
>>
>>  Ben
>>
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From reinhold.kliegl at gmail.com  Sat Aug  1 19:37:14 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 1 Aug 2009 19:37:14 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4A746DE3.3000704@ufl.edu>
References: <4A7210E9.8050602@ufl.edu>
	<19058.44590.672088.932344@lynne.math.ethz.ch>
	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
Message-ID: <aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>

Ben's problem shows up with my implementation, too. Info below.

Reinhold

> stopifnot(identical(ranef(m0), ranef(m1)),
+          identical(ranef(m2), ranef(m3)),
+          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
function(e)e),"error"))
CHOLMOD error: xG?L?R
Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
Zus?tzlich: Warnmeldung:
In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
+
> ## Check the use of offset
> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>
> stopifnot(identical(ranef(om2), ranef(om3)),
+          identical(deviance(om2), deviance(om3)))
> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
+    stop("offset does not change the fixed effects")
>
> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
Time elapsed:  11.608 0.369 12.353 0 0
> sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25

loaded via a namespace (and not attached):
[1] grid_2.9.1
>


On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>
> ?I don't mind it being public.
>
> ?I got similar results with the CRAN lme4 (0.999375-31),
> with Matrix ...-30. ?BATCH fails on m2 != m3 (consistently);
> source() fails on m0 != m1.
>
> ?I'm probably doing something really really dumb, would appreciate
> anyone else who can try this on their systems ...
>
> ?If you don't feel like downloading or running all of lmer-1.R, the
> following code chunk should demonstrate the problem ...
>
> =================
> library(lme4)
>
> set.seed(1)
> ## Wrong formula gave a seg.fault at times:
> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
> ? ? ? ? ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
> ? ? ? ? ? ? ? ? x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
> ? ? ? ? ?identical(ranef(m2), ranef(m3)),
> ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
> function(e)e),
> ? ? ? ? ? ? ? ? ? "error"))
>
> ## Check the use of offset
> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>
> stopifnot(identical(ranef(om2), ranef(om3)),
> ? ? ? ? ?identical(deviance(om2), deviance(om3)))
> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
> ? ?stop("offset does not change the fixed effects")
>
> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>
>
> Martin Maechler wrote:
>> Hi Ben,
>> as you took this "private", I'd like at least Doug Bates
>> to be in the CC ..
>> Personally I would prefer to have this continue in the R-SIG-ME list
>> rather than privately... ?I'll be pretty offline from now till Monday
>> in any case
>>
>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>> Martin Maechler wrote:
>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>> ? ? on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>> ? ? BB> When I use the latest r-forge version of lme4
>>>> ? ? BB> ( ?0.999375-32 ) it seems to fail R CMD check on a tiny
>>>> ? ? BB> numerical mismatch of two objects that are supposed
>>>> ? ? BB> (??) to be identical (I also
>>>> ? ? BB> get a mangled CHOLMOD error message, but I suspect that
>>>> ? ? BB> comes from somewhere within Matrix ...)
>>>>
>>>> yes, and those should be gone with the version of Matrix
>>>> (0.999375-30) of two days ago.
>>>>
>>>> ? ? BB> can anyone confirm?
>>>>
>>>> No. ?To the contrary.
>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>> ready to be committed for a while, but that's only trivial
>>>> changes.
>>>>
>>>> and below, from your sessionInfo(), it looks like you are using
>>>> a current version of R and packages ...
>>>> hmm ...
>>>>
>>>> Regards,
>>>> Martin
>>>>
>>>>
>>>> ? ? BB> can anyone confirm? any ideas for a fix?
>>>>
>>>>
>>>> ? ? BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>> ? ? BB> is very small ...
>>>>
>>>> well; it's interesting that the offending mismatch in the error
>>>> message below is between ?m0 and m1, ?...
>>> ?hmmm indeed. ?Maybe I was already hacking things. ?I have
>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>> sessionInfo() says
>>>
>>> ?lme4_0.999375-32 ? Matrix_0.999375-30
>>>
>>> in ../tests, I do
>>>
>>> R --vanilla
>>> library(lme4)
>>> source("lmer-1.R",echo=TRUE)
>>>
>>> or
>>>
>>> R CMD BATCH --vanilla lmer-1.R
>>>
>>> ?oddly, the second (BATCH) always fails on m0/m1; the
>>> first (source) fails at different comparisons (sometimes m0/m1;
>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>
>> I just can't understand how that *can* happen.
>> It would mean that the algorithms used were slightly "random", ?or
>> e.g. using slightly different precision depending on memory
>> allocation, or ??,
>> ???
>>
>> As I said i the first e-mail: The slightly different formula should
>> produce absolutely identical matrices and vectors which define the
>> loglikelihood (or RE-LogLik.) and then the minimization really should
>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>
>> I assume you have tried the same with the CRAN-version of lme4 ...
>> which has exactly the same tests/lmer-1.R ??
>> ....
>> the phenomenon looks so illogical, ?I even start to wonder if it's a
>> bug in your computer (hardware-low-level software combination)?
>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>
>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>> ``regular R-forge package'' ?called ?'lme4a'
>>> ?yes.
>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>
>>>> ? ? >> getwd()
>>>> ? ? BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>
>>>> ? ? >> source("lmer-1.R",echo=TRUE)
>>>>
>>>> ? ? BB> ...
>>>> ? ? >> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>> ? ? BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>> ? ? BB> x3=rnorm(20,1))
>>>> ? ? >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>> ? ? >> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>
>>>> We had added these checks exactly *because* we wanted to be sure
>>>> that a slightly different use of formulas would lead to the
>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>> parametrizations,
>>>> so I wonder how your version of lme4 could give different
>>>> results here....
>>>>
>>>> ? ? >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>> ? ? >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>> ? ? >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> ? ? BB> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
>>>> ? ? BB> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>> ? ? BB> [TRUNCATED]
>>>> ? ? BB> CHOLMOD error: =*?1????@???T??o????
>>>> ? ? BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>> ? ? BB> In addition: Warning message:
>>>> ? ? BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>
>>>> Note that the cholmod error and warning is from the
>>>> ? ?lmer(y ~ x2|ff + x1, data = D)
>>>> part {which is wrapped in ?tryCatch(...)}.
>>>>
>>>> Also, if I execute
>>>>
>>>> ##----------------------------------------------------
>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>> ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>>>> ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>>>> cat("Ok\n")
>>>> ##----------------------------------------------------
>>>>
>>>> many times, I never see a problem.
>>>>
>>>> Are you sure you are not using your already-hacked version of
>>>> lme4 ???
>>>>
>>>> Martin Maechler, ETH Zurich
>>>>
>>> ?I'm not 100.0000% sure, but I don't see how I could be ...
>>>
>>> ?Ben
>>>
>>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Sat Aug  1 19:50:25 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 1 Aug 2009 19:50:25 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
References: <4A7210E9.8050602@ufl.edu>
	<19058.44590.672088.932344@lynne.math.ethz.ch>
	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
Message-ID: <aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>

Just updated to Matrix_0.999375-30. The previous problem persists and
now it also reports:
Fehler: identical(ranef(om2), ranef(om3)) is not TRUE

Reinhold

> stopifnot(identical(ranef(om2), ranef(om3)),
+          identical(deviance(om2), deviance(om3)))
Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
+ if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
+    stop("offset does not change the fixed effects")
>
> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
Time elapsed:  13.588 0.399 14.297 0 0
> sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25


On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
Kliegl<reinhold.kliegl at gmail.com> wrote:
> Ben's problem shows up with my implementation, too. Info below.
>
> Reinhold
>
>> stopifnot(identical(ranef(m0), ranef(m1)),
> + ? ? ? ? ?identical(ranef(m2), ranef(m3)),
> + ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
> function(e)e),"error"))
> CHOLMOD error: xG? L?R
> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
> Zus?tzlich: Warnmeldung:
> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
> +
>> ## Check the use of offset
>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>
>> stopifnot(identical(ranef(om2), ranef(om3)),
> + ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
> + ? ?stop("offset does not change the fixed effects")
>>
>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
> Time elapsed: ?11.608 0.369 12.353 0 0
>> sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-apple-darwin8.11.1
>
> locale:
> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
> [7] base
>
> other attached packages:
> [1] lme4_0.999375-31 ? Matrix_0.999375-29 lattice_0.17-25
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.1
>>
>
>
> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>
>> ?I don't mind it being public.
>>
>> ?I got similar results with the CRAN lme4 (0.999375-31),
>> with Matrix ...-30. ?BATCH fails on m2 != m3 (consistently);
>> source() fails on m0 != m1.
>>
>> ?I'm probably doing something really really dumb, would appreciate
>> anyone else who can try this on their systems ...
>>
>> ?If you don't feel like downloading or running all of lmer-1.R, the
>> following code chunk should demonstrate the problem ...
>>
>> =================
>> library(lme4)
>>
>> set.seed(1)
>> ## Wrong formula gave a seg.fault at times:
>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>> ? ? ? ? ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
>> ? ? ? ? ? ? ? ? x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
>> ? ? ? ? ?identical(ranef(m2), ranef(m3)),
>> ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>> function(e)e),
>> ? ? ? ? ? ? ? ? ? "error"))
>>
>> ## Check the use of offset
>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>
>> stopifnot(identical(ranef(om2), ranef(om3)),
>> ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>> ? ?stop("offset does not change the fixed effects")
>>
>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>
>>
>> Martin Maechler wrote:
>>> Hi Ben,
>>> as you took this "private", I'd like at least Doug Bates
>>> to be in the CC ..
>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>> rather than privately... ?I'll be pretty offline from now till Monday
>>> in any case
>>>
>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>> Martin Maechler wrote:
>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>> ? ? on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>> ? ? BB> When I use the latest r-forge version of lme4
>>>>> ? ? BB> ( ?0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>> ? ? BB> numerical mismatch of two objects that are supposed
>>>>> ? ? BB> (??) to be identical (I also
>>>>> ? ? BB> get a mangled CHOLMOD error message, but I suspect that
>>>>> ? ? BB> comes from somewhere within Matrix ...)
>>>>>
>>>>> yes, and those should be gone with the version of Matrix
>>>>> (0.999375-30) of two days ago.
>>>>>
>>>>> ? ? BB> can anyone confirm?
>>>>>
>>>>> No. ?To the contrary.
>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>> ready to be committed for a while, but that's only trivial
>>>>> changes.
>>>>>
>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>> a current version of R and packages ...
>>>>> hmm ...
>>>>>
>>>>> Regards,
>>>>> Martin
>>>>>
>>>>>
>>>>> ? ? BB> can anyone confirm? any ideas for a fix?
>>>>>
>>>>>
>>>>> ? ? BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>> ? ? BB> is very small ...
>>>>>
>>>>> well; it's interesting that the offending mismatch in the error
>>>>> message below is between ?m0 and m1, ?...
>>>> ?hmmm indeed. ?Maybe I was already hacking things. ?I have
>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>> sessionInfo() says
>>>>
>>>> ?lme4_0.999375-32 ? Matrix_0.999375-30
>>>>
>>>> in ../tests, I do
>>>>
>>>> R --vanilla
>>>> library(lme4)
>>>> source("lmer-1.R",echo=TRUE)
>>>>
>>>> or
>>>>
>>>> R CMD BATCH --vanilla lmer-1.R
>>>>
>>>> ?oddly, the second (BATCH) always fails on m0/m1; the
>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>
>>> I just can't understand how that *can* happen.
>>> It would mean that the algorithms used were slightly "random", ?or
>>> e.g. using slightly different precision depending on memory
>>> allocation, or ??,
>>> ???
>>>
>>> As I said i the first e-mail: The slightly different formula should
>>> produce absolutely identical matrices and vectors which define the
>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>
>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>> which has exactly the same tests/lmer-1.R ??
>>> ....
>>> the phenomenon looks so illogical, ?I even start to wonder if it's a
>>> bug in your computer (hardware-low-level software combination)?
>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>
>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>> ``regular R-forge package'' ?called ?'lme4a'
>>>> ?yes.
>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>
>>>>> ? ? >> getwd()
>>>>> ? ? BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>
>>>>> ? ? >> source("lmer-1.R",echo=TRUE)
>>>>>
>>>>> ? ? BB> ...
>>>>> ? ? >> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>> ? ? BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>> ? ? BB> x3=rnorm(20,1))
>>>>> ? ? >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>> ? ? >> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>
>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>> that a slightly different use of formulas would lead to the
>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>> parametrizations,
>>>>> so I wonder how your version of lme4 could give different
>>>>> results here....
>>>>>
>>>>> ? ? >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>> ? ? >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>> ? ? >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>> ? ? BB> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
>>>>> ? ? BB> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>> ? ? BB> [TRUNCATED]
>>>>> ? ? BB> CHOLMOD error: =*?1????@???T??o????
>>>>> ? ? BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>> ? ? BB> In addition: Warning message:
>>>>> ? ? BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>
>>>>> Note that the cholmod error and warning is from the
>>>>> ? ?lmer(y ~ x2|ff + x1, data = D)
>>>>> part {which is wrapped in ?tryCatch(...)}.
>>>>>
>>>>> Also, if I execute
>>>>>
>>>>> ##----------------------------------------------------
>>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>> ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>>>>> ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>> ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>>>>> cat("Ok\n")
>>>>> ##----------------------------------------------------
>>>>>
>>>>> many times, I never see a problem.
>>>>>
>>>>> Are you sure you are not using your already-hacked version of
>>>>> lme4 ???
>>>>>
>>>>> Martin Maechler, ETH Zurich
>>>>>
>>>> ?I'm not 100.0000% sure, but I don't see how I could be ...
>>>>
>>>> ?Ben
>>>>
>>>>
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bolker at ufl.edu  Sat Aug  1 19:53:32 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 01 Aug 2009 13:53:32 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
References: <4A7210E9.8050602@ufl.edu>	
	<19058.44590.672088.932344@lynne.math.ethz.ch>	
	<4A733528.4020107@ufl.edu>	
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>	
	<4A746DE3.3000704@ufl.edu>	
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
Message-ID: <4A74811C.7080004@ufl.edu>

  Thanks, Reinhold, I'm glad I'm not completely nuts.  With Doug Bates
(quite reasonably) occupied with other things, it strikes me it might be
a little hard to dig deep enough into the guts to see what's going on
...  I will see how far I can get, but this is the kind of problem where
**if** we understood what was going on and it looked hard to fix, it
would seem reasonable to replace the "must be identical" criterion with
"abs(difference)<1e-7" or some such in the tests ...

  Ben

Reinhold Kliegl wrote:
> Just updated to Matrix_0.999375-30. The previous problem persists and
> now it also reports:
> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
> 
> Reinhold
> 
>> stopifnot(identical(ranef(om2), ranef(om3)),
> +          identical(deviance(om2), deviance(om3)))
> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
> +    stop("offset does not change the fixed effects")
>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
> Time elapsed:  13.588 0.399 14.297 0 0
>> sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-apple-darwin8.11.1
> 
> locale:
> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> 
> other attached packages:
> [1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25
> 
> 
> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
> Kliegl<reinhold.kliegl at gmail.com> wrote:
>> Ben's problem shows up with my implementation, too. Info below.
>>
>> Reinhold
>>
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>> +          identical(ranef(m2), ranef(m3)),
>> +          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>> function(e)e),"error"))
>> CHOLMOD error: xG? L?R
>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>> Zus?tzlich: Warnmeldung:
>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>> +
>>> ## Check the use of offset
>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>
>>> stopifnot(identical(ranef(om2), ranef(om3)),
>> +          identical(deviance(om2), deviance(om3)))
>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>> +    stop("offset does not change the fixed effects")
>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>> Time elapsed:  11.608 0.369 12.353 0 0
>>> sessionInfo()
>> R version 2.9.1 (2009-06-26)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods
>> [7] base
>>
>> other attached packages:
>> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.1
>>
>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>  I don't mind it being public.
>>>
>>>  I got similar results with the CRAN lme4 (0.999375-31),
>>> with Matrix ...-30.  BATCH fails on m2 != m3 (consistently);
>>> source() fails on m0 != m1.
>>>
>>>  I'm probably doing something really really dumb, would appreciate
>>> anyone else who can try this on their systems ...
>>>
>>>  If you don't feel like downloading or running all of lmer-1.R, the
>>> following code chunk should demonstrate the problem ...
>>>
>>> =================
>>> library(lme4)
>>>
>>> set.seed(1)
>>> ## Wrong formula gave a seg.fault at times:
>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>                 x1=rnorm(20,3), x2=rnorm(20,7),
>>>                 x3=rnorm(20,1))
>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>          identical(ranef(m2), ranef(m3)),
>>>          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>> function(e)e),
>>>                   "error"))
>>>
>>> ## Check the use of offset
>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>
>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>          identical(deviance(om2), deviance(om3)))
>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>    stop("offset does not change the fixed effects")
>>>
>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>
>>>
>>> Martin Maechler wrote:
>>>> Hi Ben,
>>>> as you took this "private", I'd like at least Doug Bates
>>>> to be in the CC ..
>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>> rather than privately...  I'll be pretty offline from now till Monday
>>>> in any case
>>>>
>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>> Martin Maechler wrote:
>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>     BB> When I use the latest r-forge version of lme4
>>>>>>     BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>     BB> numerical mismatch of two objects that are supposed
>>>>>>     BB> (??) to be identical (I also
>>>>>>     BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>     BB> comes from somewhere within Matrix ...)
>>>>>>
>>>>>> yes, and those should be gone with the version of Matrix
>>>>>> (0.999375-30) of two days ago.
>>>>>>
>>>>>>     BB> can anyone confirm?
>>>>>>
>>>>>> No.  To the contrary.
>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>> ready to be committed for a while, but that's only trivial
>>>>>> changes.
>>>>>>
>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>> a current version of R and packages ...
>>>>>> hmm ...
>>>>>>
>>>>>> Regards,
>>>>>> Martin
>>>>>>
>>>>>>
>>>>>>     BB> can anyone confirm? any ideas for a fix?
>>>>>>
>>>>>>
>>>>>>     BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>     BB> is very small ...
>>>>>>
>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>> message below is between  m0 and m1,  ...
>>>>>  hmmm indeed.  Maybe I was already hacking things.  I have
>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>> sessionInfo() says
>>>>>
>>>>>  lme4_0.999375-32   Matrix_0.999375-30
>>>>>
>>>>> in ../tests, I do
>>>>>
>>>>> R --vanilla
>>>>> library(lme4)
>>>>> source("lmer-1.R",echo=TRUE)
>>>>>
>>>>> or
>>>>>
>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>
>>>>>  oddly, the second (BATCH) always fails on m0/m1; the
>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>> I just can't understand how that *can* happen.
>>>> It would mean that the algorithms used were slightly "random",  or
>>>> e.g. using slightly different precision depending on memory
>>>> allocation, or ??,
>>>> ???
>>>>
>>>> As I said i the first e-mail: The slightly different formula should
>>>> produce absolutely identical matrices and vectors which define the
>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>
>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>> which has exactly the same tests/lmer-1.R  ?
>>>> ....
>>>> the phenomenon looks so illogical,  I even start to wonder if it's a
>>>> bug in your computer (hardware-low-level software combination)?
>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>
>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>> ``regular R-forge package''  called  'lme4a'
>>>>>  yes.
>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>
>>>>>>     >> getwd()
>>>>>>     BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>
>>>>>>     >> source("lmer-1.R",echo=TRUE)
>>>>>>
>>>>>>     BB> ...
>>>>>>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>     BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>     BB> x3=rnorm(20,1))
>>>>>>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>
>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>> that a slightly different use of formulas would lead to the
>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>> parametrizations,
>>>>>> so I wonder how your version of lme4 could give different
>>>>>> results here....
>>>>>>
>>>>>>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>     BB> +           identical(ranef(m2), ranef(m3)),
>>>>>>     BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>     BB> [TRUNCATED]
>>>>>>     BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>     BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>     BB> In addition: Warning message:
>>>>>>     BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>
>>>>>> Note that the cholmod error and warning is from the
>>>>>>    lmer(y ~ x2|ff + x1, data = D)
>>>>>> part {which is wrapped in  tryCatch(...)}.
>>>>>>
>>>>>> Also, if I execute
>>>>>>
>>>>>> ##----------------------------------------------------
>>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>                  x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>                  x3=rnorm(20,1))
>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>           identical(ranef(m2), ranef(m3)))
>>>>>> cat("Ok\n")
>>>>>> ##----------------------------------------------------
>>>>>>
>>>>>> many times, I never see a problem.
>>>>>>
>>>>>> Are you sure you are not using your already-hacked version of
>>>>>> lme4 ???
>>>>>>
>>>>>> Martin Maechler, ETH Zurich
>>>>>>
>>>>>  I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>
>>>>>  Ben
>>>>>
>>>>>
>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida
>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From reinhold.kliegl at gmail.com  Sat Aug  1 20:57:58 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 1 Aug 2009 20:57:58 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4A74811C.7080004@ufl.edu>
References: <4A7210E9.8050602@ufl.edu>
	<19058.44590.672088.932344@lynne.math.ethz.ch>
	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
	<4A74811C.7080004@ufl.edu>
Message-ID: <aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>

When I run Martin's example several times, using "set.seed(1)" before
each run, I get all possible outcomes:
(a) Error for m0 vs. m1, (b) Error for m2 vs m3, and (c) no error.

Reinhold

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-30 lattice_0.17-25

> ##------------------------------------------
> # Maechler 01-08-09
> set.seed(1)
> ##----------------------------------------------------
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)))
Fehler: identical(ranef(m2), ranef(m3)) is not TRUE
+ cat("Ok\n")
Ok
> ##------------------------------------------
> # Maechler 01-08-09
> set.seed(1)
> ##----------------------------------------------------
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)))
Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
+ cat("Ok\n")
Ok
> ##------------------------------------------
> # Maechler 01-08-09
> set.seed(1)
> ##----------------------------------------------------
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)))
> cat("Ok\n")
Ok
> ##------------------------------------------


On Sat, Aug 1, 2009 at 7:53 PM, Ben Bolker<bolker at ufl.edu> wrote:
> ?Thanks, Reinhold, I'm glad I'm not completely nuts. ?With Doug Bates
> (quite reasonably) occupied with other things, it strikes me it might be
> a little hard to dig deep enough into the guts to see what's going on
> ... ?I will see how far I can get, but this is the kind of problem where
> **if** we understood what was going on and it looked hard to fix, it
> would seem reasonable to replace the "must be identical" criterion with
> "abs(difference)<1e-7" or some such in the tests ...
>
> ?Ben
>
> Reinhold Kliegl wrote:
>> Just updated to Matrix_0.999375-30. The previous problem persists and
>> now it also reports:
>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>
>> Reinhold
>>
>>> stopifnot(identical(ranef(om2), ranef(om3)),
>> + ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>> + ? ?stop("offset does not change the fixed effects")
>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>> Time elapsed: ?13.588 0.399 14.297 0 0
>>> sessionInfo()
>> R version 2.9.1 (2009-06-26)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>> [7] base
>>
>> other attached packages:
>> [1] lme4_0.999375-31 ? Matrix_0.999375-30 lattice_0.17-25
>>
>>
>> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
>> Kliegl<reinhold.kliegl at gmail.com> wrote:
>>> Ben's problem shows up with my implementation, too. Info below.
>>>
>>> Reinhold
>>>
>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>> + ? ? ? ? ?identical(ranef(m2), ranef(m3)),
>>> + ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>> function(e)e),"error"))
>>> CHOLMOD error: xG? L?R
>>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>>> Zus?tzlich: Warnmeldung:
>>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>>> +
>>>> ## Check the use of offset
>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>
>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>> + ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>> + ? ?stop("offset does not change the fixed effects")
>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>> Time elapsed: ?11.608 0.369 12.353 0 0
>>>> sessionInfo()
>>> R version 2.9.1 (2009-06-26)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>>> [7] base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-31 ? Matrix_0.999375-29 lattice_0.17-25
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.9.1
>>>
>>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>> ?I don't mind it being public.
>>>>
>>>> ?I got similar results with the CRAN lme4 (0.999375-31),
>>>> with Matrix ...-30. ?BATCH fails on m2 != m3 (consistently);
>>>> source() fails on m0 != m1.
>>>>
>>>> ?I'm probably doing something really really dumb, would appreciate
>>>> anyone else who can try this on their systems ...
>>>>
>>>> ?If you don't feel like downloading or running all of lmer-1.R, the
>>>> following code chunk should demonstrate the problem ...
>>>>
>>>> =================
>>>> library(lme4)
>>>>
>>>> set.seed(1)
>>>> ## Wrong formula gave a seg.fault at times:
>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>> ? ? ? ? ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
>>>> ? ? ? ? ? ? ? ? x3=rnorm(20,1))
>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> ? ? ? ? ?identical(ranef(m2), ranef(m3)),
>>>> ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>> function(e)e),
>>>> ? ? ? ? ? ? ? ? ? "error"))
>>>>
>>>> ## Check the use of offset
>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>
>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>> ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>> ? ?stop("offset does not change the fixed effects")
>>>>
>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>
>>>>
>>>> Martin Maechler wrote:
>>>>> Hi Ben,
>>>>> as you took this "private", I'd like at least Doug Bates
>>>>> to be in the CC ..
>>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>>> rather than privately... ?I'll be pretty offline from now till Monday
>>>>> in any case
>>>>>
>>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>> Martin Maechler wrote:
>>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>> ? ? on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>> ? ? BB> When I use the latest r-forge version of lme4
>>>>>>> ? ? BB> ( ?0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>> ? ? BB> numerical mismatch of two objects that are supposed
>>>>>>> ? ? BB> (??) to be identical (I also
>>>>>>> ? ? BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>> ? ? BB> comes from somewhere within Matrix ...)
>>>>>>>
>>>>>>> yes, and those should be gone with the version of Matrix
>>>>>>> (0.999375-30) of two days ago.
>>>>>>>
>>>>>>> ? ? BB> can anyone confirm?
>>>>>>>
>>>>>>> No. ?To the contrary.
>>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>>> ready to be committed for a while, but that's only trivial
>>>>>>> changes.
>>>>>>>
>>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>>> a current version of R and packages ...
>>>>>>> hmm ...
>>>>>>>
>>>>>>> Regards,
>>>>>>> Martin
>>>>>>>
>>>>>>>
>>>>>>> ? ? BB> can anyone confirm? any ideas for a fix?
>>>>>>>
>>>>>>>
>>>>>>> ? ? BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>> ? ? BB> is very small ...
>>>>>>>
>>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>>> message below is between ?m0 and m1, ?...
>>>>>> ?hmmm indeed. ?Maybe I was already hacking things. ?I have
>>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>>> sessionInfo() says
>>>>>>
>>>>>> ?lme4_0.999375-32 ? Matrix_0.999375-30
>>>>>>
>>>>>> in ../tests, I do
>>>>>>
>>>>>> R --vanilla
>>>>>> library(lme4)
>>>>>> source("lmer-1.R",echo=TRUE)
>>>>>>
>>>>>> or
>>>>>>
>>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>>
>>>>>> ?oddly, the second (BATCH) always fails on m0/m1; the
>>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>>> I just can't understand how that *can* happen.
>>>>> It would mean that the algorithms used were slightly "random", ?or
>>>>> e.g. using slightly different precision depending on memory
>>>>> allocation, or ??,
>>>>> ???
>>>>>
>>>>> As I said i the first e-mail: The slightly different formula should
>>>>> produce absolutely identical matrices and vectors which define the
>>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>>
>>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>>> which has exactly the same tests/lmer-1.R ??
>>>>> ....
>>>>> the phenomenon looks so illogical, ?I even start to wonder if it's a
>>>>> bug in your computer (hardware-low-level software combination)?
>>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>>
>>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>>> ``regular R-forge package'' ?called ?'lme4a'
>>>>>> ?yes.
>>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>>
>>>>>>> ? ? >> getwd()
>>>>>>> ? ? BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>>
>>>>>>> ? ? >> source("lmer-1.R",echo=TRUE)
>>>>>>>
>>>>>>> ? ? BB> ...
>>>>>>> ? ? >> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>> ? ? BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>> ? ? BB> x3=rnorm(20,1))
>>>>>>> ? ? >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>> ? ? >> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>>>
>>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>>> that a slightly different use of formulas would lead to the
>>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>>> parametrizations,
>>>>>>> so I wonder how your version of lme4 could give different
>>>>>>> results here....
>>>>>>>
>>>>>>> ? ? >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>> ? ? >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>> ? ? >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>> ? ? BB> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
>>>>>>> ? ? BB> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>> ? ? BB> [TRUNCATED]
>>>>>>> ? ? BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>> ? ? BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>> ? ? BB> In addition: Warning message:
>>>>>>> ? ? BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>>
>>>>>>> Note that the cholmod error and warning is from the
>>>>>>> ? ?lmer(y ~ x2|ff + x1, data = D)
>>>>>>> part {which is wrapped in ?tryCatch(...)}.
>>>>>>>
>>>>>>> Also, if I execute
>>>>>>>
>>>>>>> ##----------------------------------------------------
>>>>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>> ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>> ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>> ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>>>>>>> cat("Ok\n")
>>>>>>> ##----------------------------------------------------
>>>>>>>
>>>>>>> many times, I never see a problem.
>>>>>>>
>>>>>>> Are you sure you are not using your already-hacked version of
>>>>>>> lme4 ???
>>>>>>>
>>>>>>> Martin Maechler, ETH Zurich
>>>>>>>
>>>>>> ?I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>>
>>>>>> ?Ben
>>>>>>
>>>>>>
>>>>
>>>> --
>>>> Ben Bolker
>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>



From bolker at ufl.edu  Sat Aug  1 21:12:18 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 01 Aug 2009 15:12:18 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>
References: <4A7210E9.8050602@ufl.edu>	
	<19058.44590.672088.932344@lynne.math.ethz.ch>	
	<4A733528.4020107@ufl.edu>	
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>	
	<4A746DE3.3000704@ufl.edu>	
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>	
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>	
	<4A74811C.7080004@ufl.edu>
	<aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>
Message-ID: <4A749392.8030307@ufl.edu>


  Does this suggest a memory/pointer reference problem (the only way I
can think of getting non-deterministic behavior of this type) ... ? ugh,
ugh, ugh.

  Tried running with valgrind, but nothing pops up.

  After running the example below to create D, I can get two different
results from the *same* lmer call ...

> table(replicate(40,ranef(lmer(y~(x1+x2)|ff,data=D))$ff[1,1]))

8.35055995996088 8.48042553563304
              17               23

  I am also worried (without much justification) that the problem might
lie in Matrix, which is even Deeper Magic to me than lme4 ...

  Ben



Reinhold Kliegl wrote:
> When I run Martin's example several times, using "set.seed(1)" before
> each run, I get all possible outcomes:
> (a) Error for m0 vs. m1, (b) Error for m2 vs m3, and (c) no error.
> 
> Reinhold
> 
> other attached packages:
> [1] lme4_0.999375-32   Matrix_0.999375-30 lattice_0.17-25
> 
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m2), ranef(m3)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
>> cat("Ok\n")
> Ok
>> ##------------------------------------------
> 
> 
> On Sat, Aug 1, 2009 at 7:53 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>  Thanks, Reinhold, I'm glad I'm not completely nuts.  With Doug Bates
>> (quite reasonably) occupied with other things, it strikes me it might be
>> a little hard to dig deep enough into the guts to see what's going on
>> ...  I will see how far I can get, but this is the kind of problem where
>> **if** we understood what was going on and it looked hard to fix, it
>> would seem reasonable to replace the "must be identical" criterion with
>> "abs(difference)<1e-7" or some such in the tests ...
>>
>>  Ben
>>
>> Reinhold Kliegl wrote:
>>> Just updated to Matrix_0.999375-30. The previous problem persists and
>>> now it also reports:
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>>
>>> Reinhold
>>>
>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>> +          identical(deviance(om2), deviance(om3)))
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>> +    stop("offset does not change the fixed effects")
>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>> Time elapsed:  13.588 0.399 14.297 0 0
>>>> sessionInfo()
>>> R version 2.9.1 (2009-06-26)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods
>>> [7] base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25
>>>
>>>
>>> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
>>> Kliegl<reinhold.kliegl at gmail.com> wrote:
>>>> Ben's problem shows up with my implementation, too. Info below.
>>>>
>>>> Reinhold
>>>>
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> +          identical(ranef(m2), ranef(m3)),
>>>> +          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>> function(e)e),"error"))
>>>> CHOLMOD error: xG? L?R
>>>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>>>> Zus?tzlich: Warnmeldung:
>>>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>>>> +
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>> +          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>> +    stop("offset does not change the fixed effects")
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>> Time elapsed:  11.608 0.369 12.353 0 0
>>>>> sessionInfo()
>>>> R version 2.9.1 (2009-06-26)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods
>>>> [7] base
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.9.1
>>>>
>>>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>  I don't mind it being public.
>>>>>
>>>>>  I got similar results with the CRAN lme4 (0.999375-31),
>>>>> with Matrix ...-30.  BATCH fails on m2 != m3 (consistently);
>>>>> source() fails on m0 != m1.
>>>>>
>>>>>  I'm probably doing something really really dumb, would appreciate
>>>>> anyone else who can try this on their systems ...
>>>>>
>>>>>  If you don't feel like downloading or running all of lmer-1.R, the
>>>>> following code chunk should demonstrate the problem ...
>>>>>
>>>>> =================
>>>>> library(lme4)
>>>>>
>>>>> set.seed(1)
>>>>> ## Wrong formula gave a seg.fault at times:
>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>                 x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>                 x3=rnorm(20,1))
>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>          identical(ranef(m2), ranef(m3)),
>>>>>          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>>> function(e)e),
>>>>>                   "error"))
>>>>>
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>>>          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>>>    stop("offset does not change the fixed effects")
>>>>>
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>>
>>>>>
>>>>> Martin Maechler wrote:
>>>>>> Hi Ben,
>>>>>> as you took this "private", I'd like at least Doug Bates
>>>>>> to be in the CC ..
>>>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>>>> rather than privately...  I'll be pretty offline from now till Monday
>>>>>> in any case
>>>>>>
>>>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>>> Martin Maechler wrote:
>>>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>>>     BB> When I use the latest r-forge version of lme4
>>>>>>>>     BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>>>     BB> numerical mismatch of two objects that are supposed
>>>>>>>>     BB> (??) to be identical (I also
>>>>>>>>     BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>>>     BB> comes from somewhere within Matrix ...)
>>>>>>>>
>>>>>>>> yes, and those should be gone with the version of Matrix
>>>>>>>> (0.999375-30) of two days ago.
>>>>>>>>
>>>>>>>>     BB> can anyone confirm?
>>>>>>>>
>>>>>>>> No.  To the contrary.
>>>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>>>> ready to be committed for a while, but that's only trivial
>>>>>>>> changes.
>>>>>>>>
>>>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>>>> a current version of R and packages ...
>>>>>>>> hmm ...
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>> Martin
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> can anyone confirm? any ideas for a fix?
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>>>     BB> is very small ...
>>>>>>>>
>>>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>>>> message below is between  m0 and m1,  ...
>>>>>>>  hmmm indeed.  Maybe I was already hacking things.  I have
>>>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>>>> sessionInfo() says
>>>>>>>
>>>>>>>  lme4_0.999375-32   Matrix_0.999375-30
>>>>>>>
>>>>>>> in ../tests, I do
>>>>>>>
>>>>>>> R --vanilla
>>>>>>> library(lme4)
>>>>>>> source("lmer-1.R",echo=TRUE)
>>>>>>>
>>>>>>> or
>>>>>>>
>>>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>>>
>>>>>>>  oddly, the second (BATCH) always fails on m0/m1; the
>>>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>>>> I just can't understand how that *can* happen.
>>>>>> It would mean that the algorithms used were slightly "random",  or
>>>>>> e.g. using slightly different precision depending on memory
>>>>>> allocation, or ??,
>>>>>> ???
>>>>>>
>>>>>> As I said i the first e-mail: The slightly different formula should
>>>>>> produce absolutely identical matrices and vectors which define the
>>>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>>>
>>>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>>>> which has exactly the same tests/lmer-1.R  ?
>>>>>> ....
>>>>>> the phenomenon looks so illogical,  I even start to wonder if it's a
>>>>>> bug in your computer (hardware-low-level software combination)?
>>>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>>>
>>>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>>>> ``regular R-forge package''  called  'lme4a'
>>>>>>>  yes.
>>>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>>>
>>>>>>>>     >> getwd()
>>>>>>>>     BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>>>
>>>>>>>>     >> source("lmer-1.R",echo=TRUE)
>>>>>>>>
>>>>>>>>     BB> ...
>>>>>>>>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>     BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>     BB> x3=rnorm(20,1))
>>>>>>>>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>>
>>>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>>>> that a slightly different use of formulas would lead to the
>>>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>>>> parametrizations,
>>>>>>>> so I wonder how your version of lme4 could give different
>>>>>>>> results here....
>>>>>>>>
>>>>>>>>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>     BB> +           identical(ranef(m2), ranef(m3)),
>>>>>>>>     BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>>>     BB> [TRUNCATED]
>>>>>>>>     BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>>>     BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>>>     BB> In addition: Warning message:
>>>>>>>>     BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>>>
>>>>>>>> Note that the cholmod error and warning is from the
>>>>>>>>    lmer(y ~ x2|ff + x1, data = D)
>>>>>>>> part {which is wrapped in  tryCatch(...)}.
>>>>>>>>
>>>>>>>> Also, if I execute
>>>>>>>>
>>>>>>>> ##----------------------------------------------------
>>>>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>                  x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>                  x3=rnorm(20,1))
>>>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>           identical(ranef(m2), ranef(m3)))
>>>>>>>> cat("Ok\n")
>>>>>>>> ##----------------------------------------------------
>>>>>>>>
>>>>>>>> many times, I never see a problem.
>>>>>>>>
>>>>>>>> Are you sure you are not using your already-hacked version of
>>>>>>>> lme4 ???
>>>>>>>>
>>>>>>>> Martin Maechler, ETH Zurich
>>>>>>>>
>>>>>>>  I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>>>
>>>>>>>  Ben
>>>>>>>
>>>>>>>
>>>>> --
>>>>> Ben Bolker
>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From bolker at ufl.edu  Sat Aug  1 21:42:10 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 01 Aug 2009 15:42:10 -0400
Subject: [R-sig-ME] AIC comparisons between lmer and glm
In-Reply-To: <C1789BB4-F5DC-420C-92A8-5C6862BDDABE@ualberta.ca>
References: <20090729181104.81ka0sclcw48owgw@correoweb.uvigo.es>
	<C1789BB4-F5DC-420C-92A8-5C6862BDDABE@ualberta.ca>
Message-ID: <4A749A92.7060501@ufl.edu>


   Yes, but: if treating the random effects as a nuisance parameter or
making inferences at the population level (see Vaida and Blanchard
2005), treating the random effect as 1 parameter is probably
approximately OK, although it is likely to be conservative because of
boundary issues (Greven et al 2008) ...

  Some proof that the deviance calculated with variance set equal to
zero in the glmer fit is not the same as the deviance from the glm --
don't know if this is a mismatch in which constants etc. are included,
or something about the limit of the penalized likelihood ...


### function to evaluate likelihood etc. with a new value of the
### random-effects variance
### DANGER DANGER DANGER DANGER
###  at least with some versions of lme4, this code will modify
### the original model.

update_dev <- function(mm,sd) {
  .Call("mer_ST_setPars", mm, sd, PACKAGE = "lme4")
  .Call("mer_update_L", mm, PACKAGE = "lme4")
  res <- try(.Call("mer_update_RX", mm, PACKAGE = "lme4"), silent = TRUE)
  if (inherits(res, "try-error")) {
    val <- NA
  } else {
    .Call("mer_update_ranef", mm, PACKAGE = "lme4")
    .Call("mer_update_dev", mm, PACKAGE = "lme4") ## added for glmmML
    val <- mm at deviance
  }
  val
}

library(lme4)
(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              family = binomial, data = cbpp))

gm1 at deviance["ML"] ## deviance from original model (100.0959)


dd = update_dev(gm1,sd=0)
dd["ML"]  ## deviance with random effects variance set to zero
## (114.9793)
(gm0 <- glm(cbind(incidence, size - incidence) ~ period,
              family = binomial, data = cbpp))

deviance(gm0) ## deviance from glm fit
## (114.1017)


Peter Dixon wrote:
> I think one of the issues, discussed elsewhere on this list if I  
> recall, is that the status of the random effects estimates is unclear  
> ? they are not parameters of the model in the same sense as the fixed  
> effects are. Because AIC depends on counting parameters, comparing AIC  
> values with different random-effects structures is suspect.
> 
> - Pete
> 
> On Jul 29, 2009, at 10:11 AM, cacabelos at uvigo.es wrote:
> 
>> Hi R-users,
>>
>> I was unfortunately not able to find a solution to my problem about  
>> model selection. I have fixed (e.g. Height) and random (e.g.Time)  
>> factors, and I created these kind of model structures:
>>
>> Model1<-lmer(H~Height+(1|Time)+Biomass)+(Biomass| 
>> Time),data=dat,family=gaussian)
>> Model2<-glm(H~Height+Biomass,data=dat,family=gaussian)
>>
>> I am using the criterion ?the best model is the one that has the  
>> lowest AIC?, but are these AIC from different procedures (i.e. glm  
>> and lmer) comparable?
>>
>> I wonder if anyone can help me... Thank you!
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
> 
> 
> ---
> Peter Dixon
> peter.dixon at ualberta.ca
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Djibril.Dayamba at ess.slu.se  Sun Aug  2 16:02:57 2009
From: Djibril.Dayamba at ess.slu.se (Djibril Dayamba)
Date: Sun, 2 Aug 2009 16:02:57 +0200
Subject: [R-sig-ME] Just to say thanks to Kingsford
In-Reply-To: <2ad0cc110907161517p3e400330gc8798a3884c61354@mail.gmail.com>
References: <C1CE865EFF7A544789C6C7C46FEF264A3806CDD2B3@exmbx1.ad.slu.se>
	<2ad0cc110907121301o32d684f8vc7e18fbd38fb71e1@mail.gmail.com>
	<C1CE865EFF7A544789C6C7C46FEF264A3806CDD451@exmbx1.ad.slu.se>
	<2ad0cc110907161517p3e400330gc8798a3884c61354@mail.gmail.com>
Message-ID: <C1CE865EFF7A544789C6C7C46FEF264A3806E79F0E@exmbx1.ad.slu.se>

Hello Kingsford,
I just want to say thanks to you for the guidance I have got in linear mixed effect modeling with my data. I believe there is much left to learn but at this point, I have made a lot of progress and I am happy with it.

Best wishes,

Djibril.

-----Original Message-----
From: Kingsford Jones [mailto:kingsfordjones at gmail.com] 
Sent: den 17 juli 2009 00:17
To: Djibril Dayamba; R-Sig Mixed-models
Subject: Re: Problem with convergence, please help

It's a complex model with algorithms trying to optimize many estimates
together:  random intercept and slope, residual variances within each
plot and AR1 correlation parameter for points across years, as well as
the 8? fixed effects.  Fitting residual covariance structures is
particularly tricky, and you're structuring diagonals and
off-diagonals, so it's not too surprising you've run into a
convergence problem.

As for solutions, take a look at the 'control' argument to lme, and
the lmeControl function.  At a minimum, try increasing the number of
iterations (maxIter=<something more than 50>) and set msVerbose=TRUE
to view progress during iterations.  If the algorithm is having
trouble with the varFunc or corStruct classes, you can use the 'value'
argument to specify starting values (e.g. correlation = corAR1(value =
.6, form = ~Year)).  You can also try simpler structures; e.g.,
weights = varPower(form =~fitted(.)) for the situation where variance
increases with the predicted response.

And of course P&B is the place to look for details...

hth,
Kingsford

On Thu, Jul 16, 2009 at 2:43 AM, Djibril
Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
> Hello,
> Thanks a lot Kingsford for all your help. I went through the process step by step and my model kept improving. Fitting the Model with correlation structure corAR1(form=~Year) gave the smaller AIC but when checking the model there was a trend in the spread of the residuals. I then tried to account for the heterogeneity using varIdent as specified in the model below.
>
> lme(BA.130~Grazing*Fire*Year,random=~Year|Plot,correlation=corAR1(form=~Year), weights=varIdent(form=~1|Plot),na.action=na.omit)
>
> But this model could not work and I got an error message about convergence (see below).
>
> Error in lme.formula(BA.130 ~ Grazing * Fire * Year, random = ~Year | ?:
> ?nlminb problem, convergence error code = 1
> ?message = iteration limit reached without convergence (9)
>
> Since then I have been reading but could not get the point. Could anyone tell me something about this problem and how it could be solved? Thanks in advance.
>
> With regards,
>
> Djibril.
>
>
>
> -----Original Message-----
> From: Kingsford Jones [mailto:kingsfordjones at gmail.com]
> Sent: den 12 juli 2009 22:01
> To: Djibril Dayamba
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Need some advice on my model specification
>
> Hi Djibril,
>
> The model is overspecified. ?I strongly suspect a call of
> intervals(Model) will throw an error, or possibly produce intervals of
> infinite width. ?A more likely candidate is:
>
> Model <- lme(BA.B ~ Grazing*Fire + Year, data = <your data>,
> ? ?random = ~<random intercept and possible linear and quadratic slopes>|Plot,
> ? ?correlation = corAR1(form=~Year|Plot), weights = <possible
> heterogeneity structure>)
>
> Without being familiar with the data this is of course only a suggestion.
>
> One strategy is to start with the fit with no correlation structure
> and explore residual temporal correlation within plots using the ACF
> function and its plot method, choosing a structure, fitting it, and
> repeating the exploration. ?The same can be done for variance
> structures with the weights argument. ?The following link (and P&B
> 2000) will suggest plots for exploration:
>
> http://bm2.genes.nig.ac.jp/RGM2/index.php?query=nlme
>
> As I mentioned in reply to your r-help post there are a variety of
> tricky issues surrounding inference; nonetheless, if you carefully
> build your linear model, checking that you are reasonably meeting
> normality assumptions (for errors and random effects), and using the
> lme arguments to structure error covariance so as to account for lack
> of independence and heterogeneity of variance, you will have results
> that should be quite defensible to reviewers.
>
> best of luck,
>
> Kingsford
>
>
> On Sun, Jul 12, 2009 at 11:43 AM, Djibril
> Dayamba<Djibril.Dayamba at ess.slu.se> wrote:
>> Hello,
>> I previously wrote to R-help, I got some advices and was kindly redirected by Kingsford to this specific Help-list (mixed models) for further questions. Since then I have moved a bit but I still have some points where I would appreciate having clarification.
>>
>> I have a factorial experiment ( with 4 repetitions for each treatment combination) to study the effects of Grazing and Fire on Forest biomass production. The experimental unit (to which the treatment combinations are applied) are PLOTs. The measures were made repeatedly for 13 years. Below is how I organized my data; Plot is the plot naming in the field; BA.B is the response variable (Basal area) I am using to express myself here
>>
>>
>> Grazing ? ? ? ? ? ? Fire ? ? ? ? ? ? ? ? ? ? Plot ? ? ? ? ? ? ? ? ? ? Year ? ? ? ? ? ? ? ? ? ?BA.B
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 398.13
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 4728.54
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2092.05
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? ? ? 3076.70
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? ? ? 2578.54
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? ? ? 2541.07
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? ? ? 3191.61
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? ? ? 2526.75
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ? ? ? 3665.42
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? ? ? ? ? ? ? ? ?3077.42
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?11 ? ? ? ? ? ? ? ? ? ? ? ?3911.63
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?12 ? ? ? ? ? ? ? ? ? ? ? ?4067.28
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?102 ? ? ? ? ? ? ? ? ? ? ?13 ? ? ? ? ? ? ? ? ? ? ? ?4457.94
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? ? ? 370.99
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? ? ? 2184.39
>> Ungrazed ? ? ? ? Unburnt ? ? ? ? ? ?108 ? ? ? ? ? ? ? ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? ? ? 2008.66
>> .
>> .
>> .
>> .
>> .
>>
>> I fitted the below model to account for the temporal autocorrelation and the variance heterogeneity. I also have a missing value.
>>
>> Model<-lme(BA.B~Grazing*Fire*Year, random=~1|Year/Plot/Fire/Grazing, correlation=corAR1(form=~Year), weights=varIdent(form=~1|Grazing*Fire*Year), na.action=na.omit)
>>
>> For the random effect I got something like this
>>
>> Random effects:
>> ?Formula: ~1 | Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?234.6285
>>
>> ?Formula: ~1 | Plot %in% Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?67.01272
>>
>> ?Formula: ~1 | Fire %in% Plot %in% Year
>> ? ? ? ?(Intercept)
>> StdDev: ? ?66.80442
>>
>> ?Formula: ~1 | Grazing %in% Fire %in% Plot %in% Year
>> ? ? ? ?(Intercept) Residual
>> StdDev: ? ?66.83408 ? ? ? ? ? 153.0221
>>
>>
>> For the correlation structure, the Phi value is 0 (zero)
>>
>> Correlation Structure: AR(1)
>> ?Formula: ~Year | Year/Plot/Fire/Grazing
>> ?Parameter estimate(s):
>> Phi
>> ?0
>>
>> For the fixed effects, please note the identical degree of freedom for every term (except Year)
>>
>> Fixed effects: BA.B ~ Grazing * Fire * Year
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Value ? ? ? ? ? ? ? ? ? Std.Error ? ? ? DF ? ? ? ? ? ? ? ? t-value ? ? ? ? ? p-value
>> (Intercept) ? ? ? ? ? ? ? ? ? ? ? 461.4655 ? ? ? ? ?178.15612 ? ? 396 ? ? ? ? ? ? ? ?2.590231 ? ? ? 0.0099
>> GrazingUngrazed ? ? ? ? ? ? ? ? ?-180.1041 ? 104.88596 ? ? 396 ? ? ? ? ? ? ? ?-1.717143 ? ? ?0.0867
>> FireUnburnt ? ? ? ? ? ? ? ? ? ? ?-236.3691 ? ? ? 124.54654 ? ? 396 ? ? ? ? ? ? ? ?-1.897837 ? ? ?0.0584
>> Year ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?410.9426 ? ? ? ? ? ? 31.68234 ? ? ? 11 ? ? ? ? ? ? ? ? ?12.970718 ? ? 0.0000
>> GrazingUngrazed:FireUnburnt 224.5099 153.17048 ? ?396 ? ? ? ? ? ? ? ?1.465752 ? ? ? 0.1435
>> GrazingUngrazed:Year ? ? ? ? -104.4984 ?28.99989 ? ? ? 396 ? ? ? ? ? ? ? ?-3.603406 ? ? ?0.0004
>> FireUnburnt:Year ? ? ? ? ? ? ? ? ?-21.3375 ? ? 38.52046 ? ? ? 396 ? ? ? ? ? ? ? ?-0.553927 ? ? ?0.5799
>> GrazingUngrazed:FireUnburnt:Year 85.2475 ?44.47663 ? 396 ? ? ? ? ? 1.916680 ? ? ? 0.0560
>>
>>
>> My concern is:
>> Does my model specification looks ok?
>> Is Phi = 0 real and what does this mean (in all case studies I have seen, it had value different from zero)?
>> I am also wondering about the identical degree of freedom for all term (except for Year).
>> Thanks in advance
>>
>>
>> With regards,
>>
>> Djibril.
>>
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From may.katharina at googlemail.com  Sun Aug  2 17:23:38 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Sun, 2 Aug 2009 17:23:38 +0200
Subject: [R-sig-ME] lmer (lme4): % total variance explained by random
	effect
In-Reply-To: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
Message-ID: <dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>

Hi,

just out of curiosity because nobody is answering:
is it not not possible to calculate the variance described by a random
effect on slope and intercept as percentage of the total variance
(variance of random effect + unexplained variance)?

Would be more than happy if somebody can help me...

Thanks,

       Katharina


2009/7/24 Katharina May <may.katharina at googlemail.com>:
> Hello,
>
> just to say sorry if this questions may be somewhat "inappropriate": I'm a
> bachelor student,
> recently started with R and with trying to understand mixed models, but I'm
> somewhat stuck with
> the following problem and hope somebody might be able to help me finding a
> solution:
>
> How can I get the variance (in % of the total variance) which is explained
> by the random effect (both on slope
> and intercept together)?
> My aim is to say something like xx% of the variance is explained by the
> random effect...
>
> As I'm not sure how to deal with this I would be more than happy for any
> hints...
>
> Thank you very much and With Best Wishes from Freising/Germany,
>
> ??????????????????????? Katharina
>
>
>
> here an example output of a mixed model I use with 1 random effect on both
> slope and intercept,
> fitted with method=ML:
>
>
> Linear mixed model fit by maximum likelihood
> Formula: log(AGB) ~ log(BM_roots) + (log(BM_roots) |
> as.factor(biomass_data[which(biomass_data$woody ==????? 1), 2]))
> ?? Data: biomass_data[which(biomass_data$woody == 1), ]
> ?? AIC?? BIC logLik deviance REMLdev
> ?588.6 619.6 -288.3??? 576.6???? 583
> Random effects:
> ?Groups???????????????????????????????????????????????????? Name
> ? ? ? ? ? ? ?? ? ??????? Variance?? Std.Dev.?? Corr
> ?as.factor(biomass_data[which(biomass_data$woody == 1), 2]) (Intercept)
> 1.7568529? 1.325463
> ??????????????????????????????????????????????????????????? log(BM_roots)
> ? ? ? ? ? ? ? ? ? ? ? ? ? 0.0071313? 0.084447? -0.393
> ?Residual
> 0.0809467 0.284511
> Number of obs: 1282, groups: as.factor(biomass_data[which(biomass_data$woody
> == 1), 2]), 22
>
> Fixed effects:
> ????????????? Estimate Std. Error t value
> (Intercept)??? 1.33062??? 0.29669??? 4.48
> log(BM_roots)? 0.93182??? 0.02441?? 38.17
>
> Correlation of Fixed Effects:
> ??????????? (Intr)
> log(BM_rts) -0.446
>
>



-- 
Time flies like an arrow, fruit flies like bananas.



From ltiana_m at yahoo.com  Sun Aug  2 23:27:51 2009
From: ltiana_m at yahoo.com (Liliana Martinez)
Date: Sun, 2 Aug 2009 14:27:51 -0700 (PDT)
Subject: [R-sig-ME] Vedr. lmer (lme4): % total variance explained by random
	effect
In-Reply-To: <dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
	<dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
Message-ID: <843929.3707.qm@web53008.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090802/c671c458/attachment.pl>

From reinhold.kliegl at gmail.com  Mon Aug  3 00:09:24 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 3 Aug 2009 00:09:24 +0200
Subject: [R-sig-ME] Vedr. lmer (lme4): % total variance explained by
	random effect
In-Reply-To: <843929.3707.qm@web53008.mail.re2.yahoo.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
	<dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
	<843929.3707.qm@web53008.mail.re2.yahoo.com>
Message-ID: <aefe4d0a0908021509v22adcfd7v899e698fcefe1f03@mail.gmail.com>

There is a recent paper that may give you a start on why this is a
difficult question.

Edwards, L.J. et al. (2008). An R2 statistic for fixed effects in the
linear mixed model.
Statistics in Medicine, 27, 6137-6157.
DOI: 10.1002/sim.3429

Reinhold Kliegl


On Sun, Aug 2, 2009 at 11:27 PM, Liliana Martinez<ltiana_m at yahoo.com> wrote:
> Yes,?I hoped too that somebody would answer this question. I read in Baayen (2008, pp.258-259,??http://www.monkproject.org/MONK.wiki/attachments/2006595/2130450) that the variance described by a random effect can be calculated by dividing the amount of variance accounted for by the random effects with the variance explained jointly by the random and fixed effects . Is there a less roundabout way?
>
>
> regards
>
> Liliana Martinez
>
>
>
>
>
>
>
>
>
> ________________________________
> Fra: Katharina May <may.katharina at googlemail.com>
> Til: r-sig-mixed-models at r-project.org
> Sendt: S?ndag, august 2, 2009 17:23:38
> Emne: Re: [R-sig-ME] lmer (lme4): % total variance explained by random effect
>
> Hi,
>
> just out of curiosity because nobody is answering:
> is it not not possible to calculate the variance described by a random
> effect on slope and intercept as percentage of the total variance
> (variance of random effect + unexplained variance)?
>
> Would be more than happy if somebody can help me...
>
> Thanks,
>
> ? ? ? Katharina
>
>
> 2009/7/24 Katharina May <may.katharina at googlemail.com>:
>> Hello,
>>
>> just to say sorry if this questions may be somewhat "inappropriate": I'm a
>> bachelor student,
>> recently started with R and with trying to understand mixed models, but I'm
>> somewhat stuck with
>> the following problem and hope somebody might be able to help me finding a
>> solution:
>>
>> How can I get the variance (in % of the total variance) which is explained
>> by the random effect (both on slope
>> and intercept together)?
>> My aim is to say something like xx% of the variance is explained by the
>> random effect...
>>
>> As I'm not sure how to deal with this I would be more than happy for any
>> hints...
>>
>> Thank you very much and With Best Wishes from Freising/Germany,
>>
>> ??????????????????????? Katharina
>>
>>
>>
>> here an example output of a mixed model I use with 1 random effect on both
>> slope and intercept,
>> fitted with method=ML:
>>
>>
>> Linear mixed model fit by maximum likelihood
>> Formula: log(AGB) ~ log(BM_roots) + (log(BM_roots) |
>> as.factor(biomass_data[which(biomass_data$woody ==????? 1), 2]))
>> ?? Data: biomass_data[which(biomass_data$woody == 1), ]
>> ?? AIC?? BIC logLik deviance REMLdev
>> ?588.6 619.6 -288.3??? 576.6???? 583
>> Random effects:
>> ?Groups???????????????????????????????????????????????????? Name
>> ? ? ? ? ? ? ?? ? ??????? Variance?? Std.Dev.?? Corr
>> ?as.factor(biomass_data[which(biomass_data$woody == 1), 2]) (Intercept)
>> 1.7568529? 1.325463
>> ??????????????????????????????????????????????????????????? log(BM_roots)
>> ? ? ? ? ? ? ? ? ? ? ? ? ? 0.0071313? 0.084447? -0.393
>> ?Residual
>> 0.0809467 0.284511
>> Number of obs: 1282, groups: as.factor(biomass_data[which(biomass_data$woody
>> == 1), 2]), 22
>>
>> Fixed effects:
>> ????????????? Estimate Std. Error t value
>> (Intercept)??? 1.33062??? 0.29669??? 4.48
>> log(BM_roots)? 0.93182??? 0.02441?? 38.17
>>
>> Correlation of Fixed Effects:
>> ??????????? (Intr)
>> log(BM_rts) -0.446
>>
>>
>
>
>
> --
> Time flies like an arrow, fruit flies like bananas.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> ? ? ?_________________________________________________________
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From maechler at stat.math.ethz.ch  Mon Aug  3 12:06:11 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Aug 2009 12:06:11 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4A749392.8030307@ufl.edu>
References: <4A7210E9.8050602@ufl.edu>
	<19058.44590.672088.932344@lynne.math.ethz.ch>
	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
	<4A74811C.7080004@ufl.edu>
	<aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>
	<4A749392.8030307@ufl.edu>
Message-ID: <19062.46739.997974.752682@lynne.math.ethz.ch>


    BB>   Does this suggest a memory/pointer reference problem
    BB> (the only way I can think of getting non-deterministic
    BB> behavior of this type) ... ? ugh, ugh, ugh.


    BB>   Tried running with valgrind, but nothing pops up.

You could try
    gctorture()
as well.  But beware, that needs a lot of patience.

    BB>   After running the example below to create D, I can get
    BB> two different results from the *same* lmer call ...

    >> table(replicate(40,ranef(lmer(y~(x1+x2)|ff,data=D))$ff[1,1]))

    BB> 8.35055995996088 8.48042553563304 17 23

aha.  This at least seems "logical" to me, given the  identical()
problems mentioned earlier.
Since, I've said all the time,  the two ways really must give
identical results, and using all.equal() instead is really the
wrong test for the purpose ...


    BB>   I am also worried (without much justification) that
    BB> the problem might lie in Matrix, which is even Deeper
    BB> Magic to me than lme4 ...

:-)

If I only found a way to reproduce your findings on one of my
Linux platforms,...
then I could start digging...

Martin


    BB> Reinhold Kliegl wrote:
    >> When I run Martin's example several times, using
    >> "set.seed(1)" before each run, I get all possible
    >> outcomes: (a) Error for m0 vs. m1, (b) Error for m2 vs
    >> m3, and (c) no error.
    >> 
    >> Reinhold
    >> 
    >> other attached packages: [1] lme4_0.999375-32
    >> Matrix_0.999375-30 lattice_0.17-25
    >> 
    >>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m2), ranef(m3)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
>> cat("Ok\n")
> Ok
>> ##------------------------------------------
> 
> 
> On Sat, Aug 1, 2009 at 7:53 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>  Thanks, Reinhold, I'm glad I'm not completely nuts.  With Doug Bates
>> (quite reasonably) occupied with other things, it strikes me it might be
>> a little hard to dig deep enough into the guts to see what's going on
>> ...  I will see how far I can get, but this is the kind of problem where
>> **if** we understood what was going on and it looked hard to fix, it
>> would seem reasonable to replace the "must be identical" criterion with
>> "abs(difference)<1e-7" or some such in the tests ...
>>
>>  Ben
>>
>> Reinhold Kliegl wrote:
>>> Just updated to Matrix_0.999375-30. The previous problem persists and
>>> now it also reports:
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>>
>>> Reinhold
>>>
>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>> +          identical(deviance(om2), deviance(om3)))
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>> +    stop("offset does not change the fixed effects")
>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>> Time elapsed:  13.588 0.399 14.297 0 0
>>>> sessionInfo()
>>> R version 2.9.1 (2009-06-26)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods
>>> [7] base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25
>>>
>>>
>>> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
>>> Kliegl<reinhold.kliegl at gmail.com> wrote:
>>>> Ben's problem shows up with my implementation, too. Info below.
>>>>
>>>> Reinhold
>>>>
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> +          identical(ranef(m2), ranef(m3)),
>>>> +          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>> function(e)e),"error"))
>>>> CHOLMOD error: xG? L?R
>>>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>>>> Zus?tzlich: Warnmeldung:
>>>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>>>> +
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>> +          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>> +    stop("offset does not change the fixed effects")
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>> Time elapsed:  11.608 0.369 12.353 0 0
>>>>> sessionInfo()
>>>> R version 2.9.1 (2009-06-26)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods
>>>> [7] base
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.9.1
>>>>
>>>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>  I don't mind it being public.
>>>>>
>>>>>  I got similar results with the CRAN lme4 (0.999375-31),
>>>>> with Matrix ...-30.  BATCH fails on m2 != m3 (consistently);
>>>>> source() fails on m0 != m1.
>>>>>
>>>>>  I'm probably doing something really really dumb, would appreciate
>>>>> anyone else who can try this on their systems ...
>>>>>
>>>>>  If you don't feel like downloading or running all of lmer-1.R, the
>>>>> following code chunk should demonstrate the problem ...
>>>>>
>>>>> =================
>>>>> library(lme4)
>>>>>
>>>>> set.seed(1)
>>>>> ## Wrong formula gave a seg.fault at times:
>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>                 x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>                 x3=rnorm(20,1))
>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>          identical(ranef(m2), ranef(m3)),
>>>>>          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>>> function(e)e),
>>>>>                   "error"))
>>>>>
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>>>          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>>>    stop("offset does not change the fixed effects")
>>>>>
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>>
>>>>>
>>>>> Martin Maechler wrote:
>>>>>> Hi Ben,
>>>>>> as you took this "private", I'd like at least Doug Bates
>>>>>> to be in the CC ..
>>>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>>>> rather than privately...  I'll be pretty offline from now till Monday
>>>>>> in any case
>>>>>>
>>>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>>> Martin Maechler wrote:
>>>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>>>     BB> When I use the latest r-forge version of lme4
>>>>>>>>     BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>>>     BB> numerical mismatch of two objects that are supposed
>>>>>>>>     BB> (??) to be identical (I also
>>>>>>>>     BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>>>     BB> comes from somewhere within Matrix ...)
>>>>>>>>
>>>>>>>> yes, and those should be gone with the version of Matrix
>>>>>>>> (0.999375-30) of two days ago.
>>>>>>>>
>>>>>>>>     BB> can anyone confirm?
>>>>>>>>
>>>>>>>> No.  To the contrary.
>>>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>>>> ready to be committed for a while, but that's only trivial
>>>>>>>> changes.
>>>>>>>>
>>>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>>>> a current version of R and packages ...
>>>>>>>> hmm ...
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>> Martin
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> can anyone confirm? any ideas for a fix?
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>>>     BB> is very small ...
>>>>>>>>
>>>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>>>> message below is between  m0 and m1,  ...
>>>>>>>  hmmm indeed.  Maybe I was already hacking things.  I have
>>>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>>>> sessionInfo() says
>>>>>>>
>>>>>>>  lme4_0.999375-32   Matrix_0.999375-30
>>>>>>>
>>>>>>> in ../tests, I do
>>>>>>>
>>>>>>> R --vanilla
>>>>>>> library(lme4)
>>>>>>> source("lmer-1.R",echo=TRUE)
>>>>>>>
>>>>>>> or
>>>>>>>
>>>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>>>
>>>>>>>  oddly, the second (BATCH) always fails on m0/m1; the
>>>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>>>> I just can't understand how that *can* happen.
>>>>>> It would mean that the algorithms used were slightly "random",  or
>>>>>> e.g. using slightly different precision depending on memory
>>>>>> allocation, or ??,
>>>>>> ???
>>>>>>
>>>>>> As I said i the first e-mail: The slightly different formula should
>>>>>> produce absolutely identical matrices and vectors which define the
>>>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>>>
>>>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>>>> which has exactly the same tests/lmer-1.R  ?
>>>>>> ....
>>>>>> the phenomenon looks so illogical,  I even start to wonder if it's a
>>>>>> bug in your computer (hardware-low-level software combination)?
>>>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>>>
>>>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>>>> ``regular R-forge package''  called  'lme4a'
>>>>>>>  yes.
>>>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>>>
>>>>>>>>     >> getwd()
>>>>>>>>     BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>>>
>>>>>>>>     >> source("lmer-1.R",echo=TRUE)
>>>>>>>>
>>>>>>>>     BB> ...
>>>>>>>>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>     BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>     BB> x3=rnorm(20,1))
>>>>>>>>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>>
>>>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>>>> that a slightly different use of formulas would lead to the
>>>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>>>> parametrizations,
>>>>>>>> so I wonder how your version of lme4 could give different
>>>>>>>> results here....
>>>>>>>>
>>>>>>>>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>     BB> +           identical(ranef(m2), ranef(m3)),
>>>>>>>>     BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>>>     BB> [TRUNCATED]
>>>>>>>>     BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>>>     BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>>>     BB> In addition: Warning message:
>>>>>>>>     BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>>>
>>>>>>>> Note that the cholmod error and warning is from the
>>>>>>>>    lmer(y ~ x2|ff + x1, data = D)
>>>>>>>> part {which is wrapped in  tryCatch(...)}.
>>>>>>>>
>>>>>>>> Also, if I execute
>>>>>>>>
>>>>>>>> ##----------------------------------------------------
>>>>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>                  x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>                  x3=rnorm(20,1))
>>>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>           identical(ranef(m2), ranef(m3)))
>>>>>>>> cat("Ok\n")
>>>>>>>> ##----------------------------------------------------
>>>>>>>>
>>>>>>>> many times, I never see a problem.
>>>>>>>>
>>>>>>>> Are you sure you are not using your already-hacked version of
>>>>>>>> lme4 ???
>>>>>>>>
>>>>>>>> Martin Maechler, ETH Zurich
>>>>>>>>
>>>>>>>  I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>>>
>>>>>>>  Ben
>>>>>>>
>>>>>>>
>>>>> --
>>>>> Ben Bolker
>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From may.katharina at googlemail.com  Mon Aug  3 14:49:14 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Mon, 3 Aug 2009 14:49:14 +0200
Subject: [R-sig-ME] Vedr. lmer (lme4): % total variance explained by
	random effect
In-Reply-To: <aefe4d0a0908021509v22adcfd7v899e698fcefe1f03@mail.gmail.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
	<dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
	<843929.3707.qm@web53008.mail.re2.yahoo.com>
	<aefe4d0a0908021509v22adcfd7v899e698fcefe1f03@mail.gmail.com>
Message-ID: <dd40a8b0908030549i7c09f6cei197a33fff5b5c03a@mail.gmail.com>

Hi,

great thanks for answering me: now I understand why my question was rather a
bit "naive" in a way....


-Katharina

2009/8/3 Reinhold Kliegl <reinhold.kliegl at gmail.com>:
> There is a recent paper that may give you a start on why this is a
> difficult question.
>
> Edwards, L.J. et al. (2008). An R2 statistic for fixed effects in the
> linear mixed model.
> Statistics in Medicine, 27, 6137-6157.
> DOI: 10.1002/sim.3429
>
> Reinhold Kliegl
>
>
> On Sun, Aug 2, 2009 at 11:27 PM, Liliana Martinez<ltiana_m at yahoo.com> wrote:
>> Yes,?I hoped too that somebody would answer this question. I read in Baayen (2008, pp.258-259,??http://www.monkproject.org/MONK.wiki/attachments/2006595/2130450) that the variance described by a random effect can be calculated by dividing the amount of variance accounted for by the random effects with the variance explained jointly by the random and fixed effects . Is there a less roundabout way?
>>
>>
>> regards
>>
>> Liliana Martinez
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ________________________________
>> Fra: Katharina May <may.katharina at googlemail.com>
>> Til: r-sig-mixed-models at r-project.org
>> Sendt: S?ndag, august 2, 2009 17:23:38
>> Emne: Re: [R-sig-ME] lmer (lme4): % total variance explained by random effect
>>
>> Hi,
>>
>> just out of curiosity because nobody is answering:
>> is it not not possible to calculate the variance described by a random
>> effect on slope and intercept as percentage of the total variance
>> (variance of random effect + unexplained variance)?
>>
>> Would be more than happy if somebody can help me...
>>
>> Thanks,
>>
>> ? ? ? Katharina
>>
>>
>> 2009/7/24 Katharina May <may.katharina at googlemail.com>:
>>> Hello,
>>>
>>> just to say sorry if this questions may be somewhat "inappropriate": I'm a
>>> bachelor student,
>>> recently started with R and with trying to understand mixed models, but I'm
>>> somewhat stuck with
>>> the following problem and hope somebody might be able to help me finding a
>>> solution:
>>>
>>> How can I get the variance (in % of the total variance) which is explained
>>> by the random effect (both on slope
>>> and intercept together)?
>>> My aim is to say something like xx% of the variance is explained by the
>>> random effect...
>>>
>>> As I'm not sure how to deal with this I would be more than happy for any
>>> hints...
>>>
>>> Thank you very much and With Best Wishes from Freising/Germany,
>>>
>>> ??????????????????????? Katharina
>>>
>>>
>>>
>>> here an example output of a mixed model I use with 1 random effect on both
>>> slope and intercept,
>>> fitted with method=ML:
>>>
>>>
>>> Linear mixed model fit by maximum likelihood
>>> Formula: log(AGB) ~ log(BM_roots) + (log(BM_roots) |
>>> as.factor(biomass_data[which(biomass_data$woody ==????? 1), 2]))
>>> ?? Data: biomass_data[which(biomass_data$woody == 1), ]
>>> ?? AIC?? BIC logLik deviance REMLdev
>>> ?588.6 619.6 -288.3??? 576.6???? 583
>>> Random effects:
>>> ?Groups???????????????????????????????????????????????????? Name
>>> ? ? ? ? ? ? ?? ? ??????? Variance?? Std.Dev.?? Corr
>>> ?as.factor(biomass_data[which(biomass_data$woody == 1), 2]) (Intercept)
>>> 1.7568529? 1.325463
>>> ??????????????????????????????????????????????????????????? log(BM_roots)
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? 0.0071313? 0.084447? -0.393
>>> ?Residual
>>> 0.0809467 0.284511
>>> Number of obs: 1282, groups: as.factor(biomass_data[which(biomass_data$woody
>>> == 1), 2]), 22
>>>
>>> Fixed effects:
>>> ????????????? Estimate Std. Error t value
>>> (Intercept)??? 1.33062??? 0.29669??? 4.48
>>> log(BM_roots)? 0.93182??? 0.02441?? 38.17
>>>
>>> Correlation of Fixed Effects:
>>> ??????????? (Intr)
>>> log(BM_rts) -0.446
>>>
>>>
>>
>>
>>
>> --
>> Time flies like an arrow, fruit flies like bananas.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> ? ? ?_________________________________________________________
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>



-- 
Time flies like an arrow, fruit flies like bananas.



From bolker at UFL.EDU  Mon Aug  3 14:58:54 2009
From: bolker at UFL.EDU (Bolker,Benjamin Michael)
Date: Mon, 3 Aug 2009 08:58:54 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <19062.46739.997974.752682@lynne.math.ethz.ch>
References: <4A7210E9.8050602@ufl.edu>
	<19058.44590.672088.932344@lynne.math.ethz.ch>	<4A733528.4020107@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
	<4A74811C.7080004@ufl.edu>
	<aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>
	<4A749392.8030307@ufl.edu>,
	<19062.46739.997974.752682@lynne.math.ethz.ch>
Message-ID: <2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE25@UFEXCH-MBXCL03.ad.ufl.edu>


   Another request to others out there to try to replicate -- perhaps if
we can see where it works and where it doesn't that will help narrow down
the problem (and understand why Martin can't replicate)?

  So far we have it with 2.9.1, Matrix_0.999375-30, and lme4
lme4_0.999375-{30,31,32} (I think), on a MacBook and on Ubuntu 9.04?

  Ben

________________________________________
From: Martin Maechler [maechler at stat.math.ethz.ch]
Sent: Monday, August 03, 2009 6:06 AM
To: Bolker,Benjamin Michael
Cc: Reinhold Kliegl; R Mixed Models; Martin Maechler
Subject: Re: [R-sig-ME] current r-forge version fails R CMD check ... ?

    BB>   Does this suggest a memory/pointer reference problem
    BB> (the only way I can think of getting non-deterministic
    BB> behavior of this type) ... ? ugh, ugh, ugh.


    BB>   Tried running with valgrind, but nothing pops up.

You could try
    gctorture()
as well.  But beware, that needs a lot of patience.

    BB>   After running the example below to create D, I can get
    BB> two different results from the *same* lmer call ...

    >> table(replicate(40,ranef(lmer(y~(x1+x2)|ff,data=D))$ff[1,1]))

    BB> 8.35055995996088 8.48042553563304 17 23

aha.  This at least seems "logical" to me, given the  identical()
problems mentioned earlier.
Since, I've said all the time,  the two ways really must give
identical results, and using all.equal() instead is really the
wrong test for the purpose ...


    BB>   I am also worried (without much justification) that
    BB> the problem might lie in Matrix, which is even Deeper
    BB> Magic to me than lme4 ...

:-)

If I only found a way to reproduce your findings on one of my
Linux platforms,...
then I could start digging...

Martin



    BB> Reinhold Kliegl wrote:
    >> When I run Martin's example several times, using
    >> "set.seed(1)" before each run, I get all possible
    >> outcomes: (a) Error for m0 vs. m1, (b) Error for m2 vs
    >> m3, and (c) no error.
    >>
    >> Reinhold
    >>
    >> other attached packages: [1] lme4_0.999375-32
    >> Matrix_0.999375-30 lattice_0.17-25
    >>
    >>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m2), ranef(m3)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
> + cat("Ok\n")
> Ok
>> ##------------------------------------------
>> # Maechler 01-08-09
>> set.seed(1)
>> ##----------------------------------------------------
>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
> +                  x1=rnorm(20,3), x2=rnorm(20,7),
> +                  x3=rnorm(20,1))
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
> +           identical(ranef(m2), ranef(m3)))
>> cat("Ok\n")
> Ok
>> ##------------------------------------------
>
>
> On Sat, Aug 1, 2009 at 7:53 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>  Thanks, Reinhold, I'm glad I'm not completely nuts.  With Doug Bates
>> (quite reasonably) occupied with other things, it strikes me it might be
>> a little hard to dig deep enough into the guts to see what's going on
>> ...  I will see how far I can get, but this is the kind of problem where
>> **if** we understood what was going on and it looked hard to fix, it
>> would seem reasonable to replace the "must be identical" criterion with
>> "abs(difference)<1e-7" or some such in the tests ...
>>
>>  Ben
>>
>> Reinhold Kliegl wrote:
>>> Just updated to Matrix_0.999375-30. The previous problem persists and
>>> now it also reports:
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>>
>>> Reinhold
>>>
>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>> +          identical(deviance(om2), deviance(om3)))
>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>> +    stop("offset does not change the fixed effects")
>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>> Time elapsed:  13.588 0.399 14.297 0 0
>>>> sessionInfo()
>>> R version 2.9.1 (2009-06-26)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods
>>> [7] base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25
>>>
>>>
>>> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
>>> Kliegl<reinhold.kliegl at gmail.com> wrote:
>>>> Ben's problem shows up with my implementation, too. Info below.
>>>>
>>>> Reinhold
>>>>
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>> +          identical(ranef(m2), ranef(m3)),
>>>> +          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>> function(e)e),"error"))
>>>> CHOLMOD error: xG? L?R
>>>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>>>> Zus?tzlich: Warnmeldung:
>>>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>>>> +
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>> +          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>> +    stop("offset does not change the fixed effects")
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>> Time elapsed:  11.608 0.369 12.353 0 0
>>>>> sessionInfo()
>>>> R version 2.9.1 (2009-06-26)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods
>>>> [7] base
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-31   Matrix_0.999375-29 lattice_0.17-25
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.9.1
>>>>
>>>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>  I don't mind it being public.
>>>>>
>>>>>  I got similar results with the CRAN lme4 (0.999375-31),
>>>>> with Matrix ...-30.  BATCH fails on m2 != m3 (consistently);
>>>>> source() fails on m0 != m1.
>>>>>
>>>>>  I'm probably doing something really really dumb, would appreciate
>>>>> anyone else who can try this on their systems ...
>>>>>
>>>>>  If you don't feel like downloading or running all of lmer-1.R, the
>>>>> following code chunk should demonstrate the problem ...
>>>>>
>>>>> =================
>>>>> library(lme4)
>>>>>
>>>>> set.seed(1)
>>>>> ## Wrong formula gave a seg.fault at times:
>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>                 x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>                 x3=rnorm(20,1))
>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>          identical(ranef(m2), ranef(m3)),
>>>>>          inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>>> function(e)e),
>>>>>                   "error"))
>>>>>
>>>>> ## Check the use of offset
>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>>>          identical(deviance(om2), deviance(om3)))
>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>>>    stop("offset does not change the fixed effects")
>>>>>
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>>
>>>>>
>>>>> Martin Maechler wrote:
>>>>>> Hi Ben,
>>>>>> as you took this "private", I'd like at least Doug Bates
>>>>>> to be in the CC ..
>>>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>>>> rather than privately...  I'll be pretty offline from now till Monday
>>>>>> in any case
>>>>>>
>>>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>>> Martin Maechler wrote:
>>>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>>>     on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>>>     BB> When I use the latest r-forge version of lme4
>>>>>>>>     BB> (  0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>>>     BB> numerical mismatch of two objects that are supposed
>>>>>>>>     BB> (??) to be identical (I also
>>>>>>>>     BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>>>     BB> comes from somewhere within Matrix ...)
>>>>>>>>
>>>>>>>> yes, and those should be gone with the version of Matrix
>>>>>>>> (0.999375-30) of two days ago.
>>>>>>>>
>>>>>>>>     BB> can anyone confirm?
>>>>>>>>
>>>>>>>> No.  To the contrary.
>>>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>>>> ready to be committed for a while, but that's only trivial
>>>>>>>> changes.
>>>>>>>>
>>>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>>>> a current version of R and packages ...
>>>>>>>> hmm ...
>>>>>>>>
>>>>>>>> Regards,
>>>>>>>> Martin
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> can anyone confirm? any ideas for a fix?
>>>>>>>>
>>>>>>>>
>>>>>>>>     BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>>>     BB> is very small ...
>>>>>>>>
>>>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>>>> message below is between  m0 and m1,  ...
>>>>>>>  hmmm indeed.  Maybe I was already hacking things.  I have
>>>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>>>> sessionInfo() says
>>>>>>>
>>>>>>>  lme4_0.999375-32   Matrix_0.999375-30
>>>>>>>
>>>>>>> in ../tests, I do
>>>>>>>
>>>>>>> R --vanilla
>>>>>>> library(lme4)
>>>>>>> source("lmer-1.R",echo=TRUE)
>>>>>>>
>>>>>>> or
>>>>>>>
>>>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>>>
>>>>>>>  oddly, the second (BATCH) always fails on m0/m1; the
>>>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>>>> I just can't understand how that *can* happen.
>>>>>> It would mean that the algorithms used were slightly "random",  or
>>>>>> e.g. using slightly different precision depending on memory
>>>>>> allocation, or ??,
>>>>>> ???
>>>>>>
>>>>>> As I said i the first e-mail: The slightly different formula should
>>>>>> produce absolutely identical matrices and vectors which define the
>>>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>>>
>>>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>>>> which has exactly the same tests/lmer-1.R  ?
>>>>>> ....
>>>>>> the phenomenon looks so illogical,  I even start to wonder if it's a
>>>>>> bug in your computer (hardware-low-level software combination)?
>>>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>>>
>>>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>>>> ``regular R-forge package''  called  'lme4a'
>>>>>>>  yes.
>>>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>>>
>>>>>>>>     >> getwd()
>>>>>>>>     BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>>>
>>>>>>>>     >> source("lmer-1.R",echo=TRUE)
>>>>>>>>
>>>>>>>>     BB> ...
>>>>>>>>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>     BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>     BB> x3=rnorm(20,1))
>>>>>>>>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>>
>>>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>>>> that a slightly different use of formulas would lead to the
>>>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>>>> parametrizations,
>>>>>>>> so I wonder how your version of lme4 could give different
>>>>>>>> results here....
>>>>>>>>
>>>>>>>>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>     BB> +           identical(ranef(m2), ranef(m3)),
>>>>>>>>     BB> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>>>     BB> [TRUNCATED]
>>>>>>>>     BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>>>     BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>>>     BB> In addition: Warning message:
>>>>>>>>     BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>>>
>>>>>>>> Note that the cholmod error and warning is from the
>>>>>>>>    lmer(y ~ x2|ff + x1, data = D)
>>>>>>>> part {which is wrapped in  tryCatch(...)}.
>>>>>>>>
>>>>>>>> Also, if I execute
>>>>>>>>
>>>>>>>> ##----------------------------------------------------
>>>>>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>                  x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>                  x3=rnorm(20,1))
>>>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>           identical(ranef(m2), ranef(m3)))
>>>>>>>> cat("Ok\n")
>>>>>>>> ##----------------------------------------------------
>>>>>>>>
>>>>>>>> many times, I never see a problem.
>>>>>>>>
>>>>>>>> Are you sure you are not using your already-hacked version of
>>>>>>>> lme4 ???
>>>>>>>>
>>>>>>>> Martin Maechler, ETH Zurich
>>>>>>>>
>>>>>>>  I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>>>
>>>>>>>  Ben
>>>>>>>
>>>>>>>
>>>>> --
>>>>> Ben Bolker
>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>


--
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From reinhold.kliegl at gmail.com  Mon Aug  3 15:44:02 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 3 Aug 2009 15:44:02 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE25@UFEXCH-MBXCL03.ad.ufl.edu>
References: <4A7210E9.8050602@ufl.edu>
	<3f1d2410908010217n5837e3b8ofa51879c9b8e9848@mail.gmail.com>
	<4A746DE3.3000704@ufl.edu>
	<aefe4d0a0908011037r3fd10898w7faa91570c7dd150@mail.gmail.com>
	<aefe4d0a0908011050j7cc76257t1d9f358ab5188a17@mail.gmail.com>
	<4A74811C.7080004@ufl.edu>
	<aefe4d0a0908011157t3a50872fwfefda70fe2b38a30@mail.gmail.com>
	<4A749392.8030307@ufl.edu>
	<19062.46739.997974.752682@lynne.math.ethz.ch>
	<2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE25@UFEXCH-MBXCL03.ad.ufl.edu>
Message-ID: <aefe4d0a0908030644m51f646cdud06a72f72e5535f6@mail.gmail.com>

Make this: MacBook Pro and MacBook Air
Reinhold


On Mon, Aug 3, 2009 at 2:58 PM, Bolker,Benjamin Michael<bolker at ufl.edu> wrote:
>
> ? Another request to others out there to try to replicate -- perhaps if
> we can see where it works and where it doesn't that will help narrow down
> the problem (and understand why Martin can't replicate)?
>
> ?So far we have it with 2.9.1, Matrix_0.999375-30, and lme4
> lme4_0.999375-{30,31,32} (I think), on a MacBook and on Ubuntu 9.04?
>
> ?Ben
>
> ________________________________________
> From: Martin Maechler [maechler at stat.math.ethz.ch]
> Sent: Monday, August 03, 2009 6:06 AM
> To: Bolker,Benjamin Michael
> Cc: Reinhold Kliegl; R Mixed Models; Martin Maechler
> Subject: Re: [R-sig-ME] current r-forge version fails R CMD check ... ?
>
> ? ?BB> ? Does this suggest a memory/pointer reference problem
> ? ?BB> (the only way I can think of getting non-deterministic
> ? ?BB> behavior of this type) ... ? ugh, ugh, ugh.
>
>
> ? ?BB> ? Tried running with valgrind, but nothing pops up.
>
> You could try
> ? ?gctorture()
> as well. ?But beware, that needs a lot of patience.
>
> ? ?BB> ? After running the example below to create D, I can get
> ? ?BB> two different results from the *same* lmer call ...
>
> ? ?>> table(replicate(40,ranef(lmer(y~(x1+x2)|ff,data=D))$ff[1,1]))
>
> ? ?BB> 8.35055995996088 8.48042553563304 17 23
>
> aha. ?This at least seems "logical" to me, given the ?identical()
> problems mentioned earlier.
> Since, I've said all the time, ?the two ways really must give
> identical results, and using all.equal() instead is really the
> wrong test for the purpose ...
>
>
> ? ?BB> ? I am also worried (without much justification) that
> ? ?BB> the problem might lie in Matrix, which is even Deeper
> ? ?BB> Magic to me than lme4 ...
>
> :-)
>
> If I only found a way to reproduce your findings on one of my
> Linux platforms,...
> then I could start digging...
>
> Martin
>
>
>
> ? ?BB> Reinhold Kliegl wrote:
> ? ?>> When I run Martin's example several times, using
> ? ?>> "set.seed(1)" before each run, I get all possible
> ? ?>> outcomes: (a) Error for m0 vs. m1, (b) Error for m2 vs
> ? ?>> m3, and (c) no error.
> ? ?>>
> ? ?>> Reinhold
> ? ?>>
> ? ?>> other attached packages: [1] lme4_0.999375-32
> ? ?>> Matrix_0.999375-30 lattice_0.17-25
> ? ?>>
> ? ?>>> ##------------------------------------------
>>> # Maechler 01-08-09
>>> set.seed(1)
>>> ##----------------------------------------------------
>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>> + ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>> + ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>> + ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>> Fehler: identical(ranef(m2), ranef(m3)) is not TRUE
>> + cat("Ok\n")
>> Ok
>>> ##------------------------------------------
>>> # Maechler 01-08-09
>>> set.seed(1)
>>> ##----------------------------------------------------
>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>> + ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>> + ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>> + ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>> + cat("Ok\n")
>> Ok
>>> ##------------------------------------------
>>> # Maechler 01-08-09
>>> set.seed(1)
>>> ##----------------------------------------------------
>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>> + ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>> + ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>> stopifnot(identical(ranef(m0), ranef(m1)),
>> + ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>>> cat("Ok\n")
>> Ok
>>> ##------------------------------------------
>>
>>
>> On Sat, Aug 1, 2009 at 7:53 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>> ?Thanks, Reinhold, I'm glad I'm not completely nuts. ?With Doug Bates
>>> (quite reasonably) occupied with other things, it strikes me it might be
>>> a little hard to dig deep enough into the guts to see what's going on
>>> ... ?I will see how far I can get, but this is the kind of problem where
>>> **if** we understood what was going on and it looked hard to fix, it
>>> would seem reasonable to replace the "must be identical" criterion with
>>> "abs(difference)<1e-7" or some such in the tests ...
>>>
>>> ?Ben
>>>
>>> Reinhold Kliegl wrote:
>>>> Just updated to Matrix_0.999375-30. The previous problem persists and
>>>> now it also reports:
>>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>>>
>>>> Reinhold
>>>>
>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>> + ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>>>> Fehler: identical(ranef(om2), ranef(om3)) is not TRUE
>>>> + if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>> + ? ?stop("offset does not change the fixed effects")
>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>> Time elapsed: ?13.588 0.399 14.297 0 0
>>>>> sessionInfo()
>>>> R version 2.9.1 (2009-06-26)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>>>> [7] base
>>>>
>>>> other attached packages:
>>>> [1] lme4_0.999375-31 ? Matrix_0.999375-30 lattice_0.17-25
>>>>
>>>>
>>>> On Sat, Aug 1, 2009 at 7:37 PM, Reinhold
>>>> Kliegl<reinhold.kliegl at gmail.com> wrote:
>>>>> Ben's problem shows up with my implementation, too. Info below.
>>>>>
>>>>> Reinhold
>>>>>
>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>> + ? ? ? ? ?identical(ranef(m2), ranef(m3)),
>>>>> + ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>>> function(e)e),"error"))
>>>>> CHOLMOD error: xG? L?R
>>>>> Fehler: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>> Zus?tzlich: Warnmeldung:
>>>>> In Ops.factor(ff, x1) : + nicht sinnvoll f?r Faktoren
>>>>> +
>>>>>> ## Check the use of offset
>>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>>
>>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>>> + ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>>> + ? ?stop("offset does not change the fixed effects")
>>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>> Time elapsed: ?11.608 0.369 12.353 0 0
>>>>>> sessionInfo()
>>>>> R version 2.9.1 (2009-06-26)
>>>>> i386-apple-darwin8.11.1
>>>>>
>>>>> locale:
>>>>> de_DE.UTF-8/en_US.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>>>>>
>>>>> attached base packages:
>>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
>>>>> [7] base
>>>>>
>>>>> other attached packages:
>>>>> [1] lme4_0.999375-31 ? Matrix_0.999375-29 lattice_0.17-25
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] grid_2.9.1
>>>>>
>>>>> On Sat, Aug 1, 2009 at 6:31 PM, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>> ?I don't mind it being public.
>>>>>>
>>>>>> ?I got similar results with the CRAN lme4 (0.999375-31),
>>>>>> with Matrix ...-30. ?BATCH fails on m2 != m3 (consistently);
>>>>>> source() fails on m0 != m1.
>>>>>>
>>>>>> ?I'm probably doing something really really dumb, would appreciate
>>>>>> anyone else who can try this on their systems ...
>>>>>>
>>>>>> ?If you don't feel like downloading or running all of lmer-1.R, the
>>>>>> following code chunk should demonstrate the problem ...
>>>>>>
>>>>>> =================
>>>>>> library(lme4)
>>>>>>
>>>>>> set.seed(1)
>>>>>> ## Wrong formula gave a seg.fault at times:
>>>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>> ? ? ? ? ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>> ? ? ? ? ? ? ? ? x3=rnorm(20,1))
>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>> ? ? ? ? ?identical(ranef(m2), ranef(m3)),
>>>>>> ? ? ? ? ?inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>>>>> function(e)e),
>>>>>> ? ? ? ? ? ? ? ? ? "error"))
>>>>>>
>>>>>> ## Check the use of offset
>>>>>> om2 <- lmer(y ~ x1 + (x2|ff), data = D, offset = x3)
>>>>>> om3 <- lmer(y ~ x1 + (x2|ff) + offset(x3), data = D)
>>>>>>
>>>>>> stopifnot(identical(ranef(om2), ranef(om3)),
>>>>>> ? ? ? ? ?identical(deviance(om2), deviance(om3)))
>>>>>> if (identical(TRUE, all.equal(fixef(m2), fixef(om2))))
>>>>>> ? ?stop("offset does not change the fixed effects")
>>>>>>
>>>>>> cat('Time elapsed: ', proc.time(),'\n') # for ``statistical reasons''
>>>>>>
>>>>>>
>>>>>> Martin Maechler wrote:
>>>>>>> Hi Ben,
>>>>>>> as you took this "private", I'd like at least Doug Bates
>>>>>>> to be in the CC ..
>>>>>>> Personally I would prefer to have this continue in the R-SIG-ME list
>>>>>>> rather than privately... ?I'll be pretty offline from now till Monday
>>>>>>> in any case
>>>>>>>
>>>>>>> On Fri, Jul 31, 2009 at 20:17, Ben Bolker<bolker at ufl.edu> wrote:
>>>>>>>> Martin Maechler wrote:
>>>>>>>>>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>>>>>>>>> ? ? on Thu, 30 Jul 2009 17:30:17 -0400 writes:
>>>>>>>>> ? ? BB> When I use the latest r-forge version of lme4
>>>>>>>>> ? ? BB> ( ?0.999375-32 ) it seems to fail R CMD check on a tiny
>>>>>>>>> ? ? BB> numerical mismatch of two objects that are supposed
>>>>>>>>> ? ? BB> (??) to be identical (I also
>>>>>>>>> ? ? BB> get a mangled CHOLMOD error message, but I suspect that
>>>>>>>>> ? ? BB> comes from somewhere within Matrix ...)
>>>>>>>>>
>>>>>>>>> yes, and those should be gone with the version of Matrix
>>>>>>>>> (0.999375-30) of two days ago.
>>>>>>>>>
>>>>>>>>> ? ? BB> can anyone confirm?
>>>>>>>>>
>>>>>>>>> No. ?To the contrary.
>>>>>>>>> I have had a slightly updated version of tests/lmer-1.Rout.save
>>>>>>>>> ready to be committed for a while, but that's only trivial
>>>>>>>>> changes.
>>>>>>>>>
>>>>>>>>> and below, from your sessionInfo(), it looks like you are using
>>>>>>>>> a current version of R and packages ...
>>>>>>>>> hmm ...
>>>>>>>>>
>>>>>>>>> Regards,
>>>>>>>>> Martin
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ? ? BB> can anyone confirm? any ideas for a fix?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ? ? BB> The offending mismatch between ranef(m2) and ranef(m3)
>>>>>>>>> ? ? BB> is very small ...
>>>>>>>>>
>>>>>>>>> well; it's interesting that the offending mismatch in the error
>>>>>>>>> message below is between ?m0 and m1, ?...
>>>>>>>> ?hmmm indeed. ?Maybe I was already hacking things. ?I have
>>>>>>>> (1) updated Matrix, (2) installed lme4 directly from r-forge.
>>>>>>>> sessionInfo() says
>>>>>>>>
>>>>>>>> ?lme4_0.999375-32 ? Matrix_0.999375-30
>>>>>>>>
>>>>>>>> in ../tests, I do
>>>>>>>>
>>>>>>>> R --vanilla
>>>>>>>> library(lme4)
>>>>>>>> source("lmer-1.R",echo=TRUE)
>>>>>>>>
>>>>>>>> or
>>>>>>>>
>>>>>>>> R CMD BATCH --vanilla lmer-1.R
>>>>>>>>
>>>>>>>> ?oddly, the second (BATCH) always fails on m0/m1; the
>>>>>>>> first (source) fails at different comparisons (sometimes m0/m1;
>>>>>>>> sometimes m2/m3; sometimes om2/om3 in the next section ... ???
>>>>>>> I just can't understand how that *can* happen.
>>>>>>> It would mean that the algorithms used were slightly "random", ?or
>>>>>>> e.g. using slightly different precision depending on memory
>>>>>>> allocation, or ??,
>>>>>>> ???
>>>>>>>
>>>>>>> As I said i the first e-mail: The slightly different formula should
>>>>>>> produce absolutely identical matrices and vectors which define the
>>>>>>> loglikelihood (or RE-LogLik.) and then the minimization really should
>>>>>>> be 100% reproducible on a given R+Platform+Installed-Packages setup.
>>>>>>>
>>>>>>> I assume you have tried the same with the CRAN-version of lme4 ...
>>>>>>> which has exactly the same tests/lmer-1.R ??
>>>>>>> ....
>>>>>>> the phenomenon looks so illogical, ?I even start to wonder if it's a
>>>>>>> bug in your computer (hardware-low-level software combination)?
>>>>>>> Maybe you could ask again on R-SIg-ME if others could reproduce?
>>>>>>>
>>>>>>>>> BTW: Have you noticed that we (Doug Bates and I, when at the
>>>>>>>>> useR/DSC meetings) have moved the former 'allcoef' branch into a
>>>>>>>>> ``regular R-forge package'' ?called ?'lme4a'
>>>>>>>> ?yes.
>>>>>>>>> But yes, that definitely does not pass 'CMD check at the moment'.
>>>>>>>>>
>>>>>>>>> ? ? >> getwd()
>>>>>>>>> ? ? BB> [1] "/home/ben/lib/R/pkgs/lme4/pkg/lme4/tests"
>>>>>>>>>
>>>>>>>>> ? ? >> source("lmer-1.R",echo=TRUE)
>>>>>>>>>
>>>>>>>>> ? ? BB> ...
>>>>>>>>> ? ? >> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>> ? ? BB> x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>> ? ? BB> x3=rnorm(20,1))
>>>>>>>>> ? ? >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>>> ? ? >> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>>>>>
>>>>>>>>> We had added these checks exactly *because* we wanted to be sure
>>>>>>>>> that a slightly different use of formulas would lead to the
>>>>>>>>> identical 'X', 'Z', .... matrices, and L(theta)
>>>>>>>>> parametrizations,
>>>>>>>>> so I wonder how your version of lme4 could give different
>>>>>>>>> results here....
>>>>>>>>>
>>>>>>>>> ? ? >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>>> ? ? >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>>> ? ? >> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>> ? ? BB> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
>>>>>>>>> ? ? BB> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D) ....
>>>>>>>>> ? ? BB> [TRUNCATED]
>>>>>>>>> ? ? BB> CHOLMOD error: =*?1????@???T??o????
>>>>>>>>> ? ? BB> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>>>>>>>> ? ? BB> In addition: Warning message:
>>>>>>>>> ? ? BB> In Ops.factor(ff, x1) : + not meaningful for factors
>>>>>>>>>
>>>>>>>>> Note that the cholmod error and warning is from the
>>>>>>>>> ? ?lmer(y ~ x2|ff + x1, data = D)
>>>>>>>>> part {which is wrapped in ?tryCatch(...)}.
>>>>>>>>>
>>>>>>>>> Also, if I execute
>>>>>>>>>
>>>>>>>>> ##----------------------------------------------------
>>>>>>>>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>>>>>>>>> ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
>>>>>>>>> ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>>>>>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>>>>>>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>>>>>>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>>>>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>>>>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>>>>>>>> ? ? ? ? ? identical(ranef(m2), ranef(m3)))
>>>>>>>>> cat("Ok\n")
>>>>>>>>> ##----------------------------------------------------
>>>>>>>>>
>>>>>>>>> many times, I never see a problem.
>>>>>>>>>
>>>>>>>>> Are you sure you are not using your already-hacked version of
>>>>>>>>> lme4 ???
>>>>>>>>>
>>>>>>>>> Martin Maechler, ETH Zurich
>>>>>>>>>
>>>>>>>> ?I'm not 100.0000% sure, but I don't see how I could be ...
>>>>>>>>
>>>>>>>> ?Ben
>>>>>>>>
>>>>>>>>
>>>>>> --
>>>>>> Ben Bolker
>>>>>> Associate professor, Biology Dep't, Univ. of Florida
>>>>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>>>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>
>>> --
>>> Ben Bolker
>>> Associate professor, Biology Dep't, Univ. of Florida
>>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Fabian.Scheipl at stat.uni-muenchen.de  Mon Aug  3 16:36:24 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Mon, 3 Aug 2009 16:36:24 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
Message-ID: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090803/35db7cde/attachment.pl>

From maechler at stat.math.ethz.ch  Mon Aug  3 16:57:34 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Aug 2009 16:57:34 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>
References: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>
Message-ID: <19062.64222.169440.480313@lynne.math.ethz.ch>

>>>>> "FS" == Fabian Scheipl <Fabian.Scheipl at stat.uni-muenchen.de>
>>>>>     on Mon, 3 Aug 2009 16:36:24 +0200 writes:

    FS> Comparison of m2 and m3 works for me.  I use R-2.9.0
    FS> with lme4_0.999375-31, Matrix_0.999375-30 on Windoze XP
    FS> Professional SP2.

    FS> Code is below.

    FS> Best, Fabian

Thank you, Fabian (and Reinhold and Ben).

I think the version of Matrix and lme4 do not matter here,
really, but rather the compilers and libraries used to build
*and* run R.

Notably I have small suspicion that the case which show the
buggy behavior are linked to an optimized version of BLAS and
LAPACK, and these might be the culprit.
My (self-compiled) versions of R always use the R-builtin
non-optimized BLAS+LAPACK, so that would fit the picture that I
never see the problem.
Also, AFAIK, the Mac versions *do* use optimized libraries, and
Ubuntu often does too (because Debian does).

Martin
      
    >> sessionInfo()
    FS> R version 2.9.0 (2009-04-17) i386-pc-mingw32

    FS> locale:
    FS> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252

    FS> attached base packages: [1] stats graphics grDevices
    FS> utils datasets methods base

    FS> other attached packages: [1] lme4_0.999375-31
    FS> Matrix_0.999375-30 lattice_0.17-25

    FS> loaded via a namespace (and not attached): [1]
    FS> grid_2.9.0 tools_2.4.1

    >> all(replicate(50, {
    FS> + set.seed(1) + D <- data.frame(y= rnorm(20,10), ff =
    FS> gl(4,5), + x1=rnorm(20,3), x2=rnorm(20,7), +
    FS> x3=rnorm(20,1)) + m2 <- lmer(y ~ x1 + (x2|ff), data = D)
    FS> + m3 <- lmer(y ~ (x2|ff) + x1, data = D) + +
    FS> identical(ranef(m2), ranef(m3)) + })) [1] TRUE

    >> set.seed(1) all(replicate(50, {
    FS> + D <- data.frame(y= rnorm(20,10), ff = gl(4,5), +
    FS> x1=rnorm(20,3), x2=rnorm(20,7), + x3=rnorm(20,1)) + m2
    FS> <- lmer(y ~ x1 + (x2|ff), data = D) + m3 <- lmer(y ~
    FS> (x2|ff) + x1, data = D) + + identical(ranef(m2),
    FS> ranef(m3)) + })) [1] TRUE

    FS> 	[[alternative HTML version deleted]]

    FS> _______________________________________________
    FS> R-sig-mixed-models at r-project.org mailing list
    FS> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From reinhold.kliegl at gmail.com  Mon Aug  3 16:59:13 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 3 Aug 2009 16:59:13 +0200
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>
References: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>
Message-ID: <aefe4d0a0908030759m7e6ff082ob6d3d537654d6385@mail.gmail.com>

Not sure this helps, but I was told once that the following should hold:

model at ST  # Check on proper convergence: no zeros on diagonal

The dataframe D clearly violates this expectation. I seem to recall
that I have seen different solutions for degenerated data before;
context was a comparison between SAS and lmer.

I do NOT get  different results across runs for various models that
are well behaved with respect to the above criterion.

Reinhold

On Mon, Aug 3, 2009 at 4:36 PM, Fabian
Scheipl<Fabian.Scheipl at stat.uni-muenchen.de> wrote:
> Comparison of m2 and m3 works for me.
>
> I use R-2.9.0 with lme4_0.999375-31, ?Matrix_0.999375-30 on Windoze XP
> Professional SP2.
>
> Code is below.
>
> Best,
> Fabian
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-31 ? Matrix_0.999375-30 lattice_0.17-25
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0 ?tools_2.4.1
>
>> all(replicate(50, {
> + set.seed(1)
> + D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
> + ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
> + ? ? ? ? x3=rnorm(20,1))
> + m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> + m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> +
> + identical(ranef(m2), ranef(m3))
> + }))
> [1] TRUE
>
>> set.seed(1)
>> all(replicate(50, {
> + D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
> + ? ? ? ? x1=rnorm(20,3), x2=rnorm(20,7),
> + ? ? ? ? x3=rnorm(20,1))
> + m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> + m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> +
> + identical(ranef(m2), ranef(m3))
> + }))
> [1] TRUE
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From j.Perez-Barberia at macaulay.ac.uk  Mon Aug  3 17:00:12 2009
From: j.Perez-Barberia at macaulay.ac.uk (Javier Perez-Barberia)
Date: Mon, 03 Aug 2009 16:00:12 +0100
Subject: [R-sig-ME] conversion of random effects from lme( ) into lmer( )
Message-ID: <4A77098D020000690003FB37@macaulay.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090803/877ff294/attachment.pl>

From j.hadfield at ed.ac.uk  Mon Aug  3 18:09:00 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 3 Aug 2009 17:09:00 +0100
Subject: [R-sig-ME] lmer (lme4): % total variance explained by random
	effect
In-Reply-To: <dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
	<dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
Message-ID: <F3A5213A-7DD2-4055-9E0D-5C6DA298AE23@ed.ac.uk>

Hi Katharina,

The difficulty with random intercept-slope models is that they  
(usually) give rise to a non-constant variance across the range of the  
covariate. This means that the percentage of variance explained will  
depend on which value of the covariate you evaluate.

If you extract the (co)variance matrix for the intercept-slopes:

V<-VarCorr(name_of_model)$name_of_random_effect

and then set up a design matrix with ones in the first column, and a  
set of covariate values in the second:

Z<-cbind(rep(1,100), seq(-1,1,length=100))

then

M<-diag(Z%*%V%*%t(Z))

is equal to the variance explained by the random effect for each value  
of the covariate.  If there are no other effects M/(M+Ve) gives you  
the proportion explained where Ve is the residual variance.

Hope this helps,

Jarrod

On 2 Aug 2009, at 16:23, Katharina May wrote:

> Hi,
>
> just out of curiosity because nobody is answering:
> is it not not possible to calculate the variance described by a random
> effect on slope and intercept as percentage of the total variance
> (variance of random effect + unexplained variance)?
>
> Would be more than happy if somebody can help me...
>
> Thanks,
>
>       Katharina
>
>
> 2009/7/24 Katharina May <may.katharina at googlemail.com>:
>> Hello,
>>
>> just to say sorry if this questions may be somewhat  
>> "inappropriate": I'm a
>> bachelor student,
>> recently started with R and with trying to understand mixed models,  
>> but I'm
>> somewhat stuck with
>> the following problem and hope somebody might be able to help me  
>> finding a
>> solution:
>>
>> How can I get the variance (in % of the total variance) which is  
>> explained
>> by the random effect (both on slope
>> and intercept together)?
>> My aim is to say something like xx% of the variance is explained by  
>> the
>> random effect...
>>
>> As I'm not sure how to deal with this I would be more than happy  
>> for any
>> hints...
>>
>> Thank you very much and With Best Wishes from Freising/Germany,
>>
>>                         Katharina
>>
>>
>>
>> here an example output of a mixed model I use with 1 random effect  
>> on both
>> slope and intercept,
>> fitted with method=ML:
>>
>>
>> Linear mixed model fit by maximum likelihood
>> Formula: log(AGB) ~ log(BM_roots) + (log(BM_roots) |
>> as.factor(biomass_data[which(biomass_data$woody ==      1), 2]))
>>    Data: biomass_data[which(biomass_data$woody == 1), ]
>>    AIC   BIC logLik deviance REMLdev
>>  588.6 619.6 -288.3    576.6     583
>> Random effects:
>>  Groups                                                     Name
>>                          Variance   Std.Dev.   Corr
>>  as.factor(biomass_data[which(biomass_data$woody == 1), 2])  
>> (Intercept)
>> 1.7568529  1.325463
>>                                                              
>> log(BM_roots)
>>                           0.0071313  0.084447  -0.393
>>  Residual
>> 0.0809467 0.284511
>> Number of obs: 1282, groups:  
>> as.factor(biomass_data[which(biomass_data$woody
>> == 1), 2]), 22
>>
>> Fixed effects:
>>               Estimate Std. Error t value
>> (Intercept)    1.33062    0.29669    4.48
>> log(BM_roots)  0.93182    0.02441   38.17
>>
>> Correlation of Fixed Effects:
>>             (Intr)
>> log(BM_rts) -0.446
>>
>>
>
>
>
> -- 
> Time flies like an arrow, fruit flies like bananas.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bolker at ufl.edu  Mon Aug  3 20:41:23 2009
From: bolker at ufl.edu (Bolker,Benjamin Michael)
Date: Mon, 3 Aug 2009 14:41:23 -0400
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <19062.64222.169440.480313@lynne.math.ethz.ch>
References: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>,
	<19062.64222.169440.480313@lynne.math.ethz.ch>
Message-ID: <2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE33@UFEXCH-MBXCL03.ad.ufl.edu>


  Is there a simple way to determine the BLAS/LAPACK versions in use?
  I believe at the moment I have the Debian binary installed, I can build
a different version locally (although I'm not sure which BLAS/LAPACK versions
it will pick up from my system).

  Is this going to be fixable/workable-around?

  cheers
    Ben
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Martin Maechler [maechler at stat.math.ethz.ch]
Sent: Monday, August 03, 2009 10:57 AM
To: Fabian Scheipl
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] current r-forge version fails R CMD check ... ?

>>>>> "FS" == Fabian Scheipl <Fabian.Scheipl at stat.uni-muenchen.de>
>>>>>     on Mon, 3 Aug 2009 16:36:24 +0200 writes:

    FS> Comparison of m2 and m3 works for me.  I use R-2.9.0
    FS> with lme4_0.999375-31, Matrix_0.999375-30 on Windoze XP
    FS> Professional SP2.

    FS> Code is below.

    FS> Best, Fabian

Thank you, Fabian (and Reinhold and Ben).

I think the version of Matrix and lme4 do not matter here,
really, but rather the compilers and libraries used to build
*and* run R.

Notably I have small suspicion that the case which show the
buggy behavior are linked to an optimized version of BLAS and
LAPACK, and these might be the culprit.
My (self-compiled) versions of R always use the R-builtin
non-optimized BLAS+LAPACK, so that would fit the picture that I
never see the problem.
Also, AFAIK, the Mac versions *do* use optimized libraries, and
Ubuntu often does too (because Debian does).

Martin

    >> sessionInfo()
    FS> R version 2.9.0 (2009-04-17) i386-pc-mingw32

    FS> locale:
    FS> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252

    FS> attached base packages: [1] stats graphics grDevices
    FS> utils datasets methods base

    FS> other attached packages: [1] lme4_0.999375-31
    FS> Matrix_0.999375-30 lattice_0.17-25

    FS> loaded via a namespace (and not attached): [1]
    FS> grid_2.9.0 tools_2.4.1

    >> all(replicate(50, {
    FS> + set.seed(1) + D <- data.frame(y= rnorm(20,10), ff =
    FS> gl(4,5), + x1=rnorm(20,3), x2=rnorm(20,7), +
    FS> x3=rnorm(20,1)) + m2 <- lmer(y ~ x1 + (x2|ff), data = D)
    FS> + m3 <- lmer(y ~ (x2|ff) + x1, data = D) + +
    FS> identical(ranef(m2), ranef(m3)) + })) [1] TRUE

    >> set.seed(1) all(replicate(50, {
    FS> + D <- data.frame(y= rnorm(20,10), ff = gl(4,5), +
    FS> x1=rnorm(20,3), x2=rnorm(20,7), + x3=rnorm(20,1)) + m2
    FS> <- lmer(y ~ x1 + (x2|ff), data = D) + m3 <- lmer(y ~
    FS> (x2|ff) + x1, data = D) + + identical(ranef(m2),
    FS> ranef(m3)) + })) [1] TRUE

    FS>         [[alternative HTML version deleted]]

    FS> _______________________________________________
    FS> R-sig-mixed-models at r-project.org mailing list
    FS> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Mon Aug  3 21:43:44 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 3 Aug 2009 14:43:44 -0500
Subject: [R-sig-ME] Lme4 query
In-Reply-To: <263BA63009B97B4CB8A65660DAD3D7D0518639D9B2@UOS-CL-EX7-L2.soton.ac.uk>
References: <AcoUUw+nk5h++5EiTX+yrONDUxyCXw==>
	<263BA63009B97B4CB8A65660DAD3D7D0518639D9B2@UOS-CL-EX7-L2.soton.ac.uk>
Message-ID: <40e66e0b0908031243m3d80e058w4c35f93dac25c300@mail.gmail.com>

On Mon, Aug 3, 2009 at 10:57 AM, D'Arrigo J.<J.DArrigo at soton.ac.uk> wrote:
> Dear Douglas and Martin,

> I am using the 'lmer' function to fit a random-effect model for a binary outcome. I aim to use the estimated random effects (ranef) from the model to make some weight adjustments. However, I am first interested in understanding how your function in R compute these random effects estimates. I have been trying to find some literature but unsuccessful. I would appreciate your help here.

Technically the values returned by ranef are not parameter estimates
because the random effects are not parameters.  They are an unobserved
set of random variables and the values returned by ranef are the
conditional modes of these random variables given the observed data
and the estimated values of the parameters in the model.

I'm not sure of what to suggest as a reference for this.  Perhaps you
could send a message to the R-SIG-Mixed-Models at R-project.org mailing
list, which I have cc:d on this reply, to see if someone reading that
list is able to provide a reference.



From bates at stat.wisc.edu  Mon Aug  3 21:59:15 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 3 Aug 2009 14:59:15 -0500
Subject: [R-sig-ME] current r-forge version fails R CMD check ... ?
In-Reply-To: <2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE33@UFEXCH-MBXCL03.ad.ufl.edu>
References: <4836bc6a0908030736j58fba7eex6b866976dbb15bf4@mail.gmail.com>
	<19062.64222.169440.480313@lynne.math.ethz.ch>
	<2180B808CDA3404B8FF30C1EA0AC09EE01E8FFEE33@UFEXCH-MBXCL03.ad.ufl.edu>
Message-ID: <40e66e0b0908031259w4bb8e022vf76013f3e5e9594b@mail.gmail.com>

First, I apologize for my prolonged absence from the mailing list.  I
managed to get a bad cold at the end of my stay in Europe and still
had it when, shortly after returning home, we moved to a new home.  At
present I don't have internet access unless I go to the public library
or a coffee shop downstairs from where I now live.  Between unpacking
at the new home and fixing up our old home to get it ready to put on
the market, I have gone on hiatus from reading email.  I hope to have
an Internet connection by the end of this week, after which I can
start responding again.

On Mon, Aug 3, 2009 at 1:41 PM, Bolker,Benjamin Michael<bolker at ufl.edu> wrote:

> ?Is there a simple way to determine the BLAS/LAPACK versions in use?
> ?I believe at the moment I have the Debian binary installed, I can build
> a different version locally (although I'm not sure which BLAS/LAPACK versions
> it will pick up from my system).

I'll leave that to others to answer.  My netbook running Ubuntu is
upstairs and if I were to write out the instructions without checking
on the system I would likely get them wrong.

> ?Is this going to be fixable/workable-around?

> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Martin Maechler [maechler at stat.math.ethz.ch]
> Sent: Monday, August 03, 2009 10:57 AM
> To: Fabian Scheipl
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] current r-forge version fails R CMD check ... ?
>
>>>>>> "FS" == Fabian Scheipl <Fabian.Scheipl at stat.uni-muenchen.de>
>>>>>> ? ? on Mon, 3 Aug 2009 16:36:24 +0200 writes:
>
> ? ?FS> Comparison of m2 and m3 works for me. ?I use R-2.9.0
> ? ?FS> with lme4_0.999375-31, Matrix_0.999375-30 on Windoze XP
> ? ?FS> Professional SP2.
>
> ? ?FS> Code is below.
>
> ? ?FS> Best, Fabian
>
> Thank you, Fabian (and Reinhold and Ben).
>
> I think the version of Matrix and lme4 do not matter here,
> really, but rather the compilers and libraries used to build
> *and* run R.
>
> Notably I have small suspicion that the case which show the
> buggy behavior are linked to an optimized version of BLAS and
> LAPACK, and these might be the culprit.
> My (self-compiled) versions of R always use the R-builtin
> non-optimized BLAS+LAPACK, so that would fit the picture that I
> never see the problem.
> Also, AFAIK, the Mac versions *do* use optimized libraries, and
> Ubuntu often does too (because Debian does).
>
> Martin
>
> ? ?>> sessionInfo()
> ? ?FS> R version 2.9.0 (2009-04-17) i386-pc-mingw32
>
> ? ?FS> locale:
> ? ?FS> LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252
>
> ? ?FS> attached base packages: [1] stats graphics grDevices
> ? ?FS> utils datasets methods base
>
> ? ?FS> other attached packages: [1] lme4_0.999375-31
> ? ?FS> Matrix_0.999375-30 lattice_0.17-25
>
> ? ?FS> loaded via a namespace (and not attached): [1]
> ? ?FS> grid_2.9.0 tools_2.4.1
>
> ? ?>> all(replicate(50, {
> ? ?FS> + set.seed(1) + D <- data.frame(y= rnorm(20,10), ff =
> ? ?FS> gl(4,5), + x1=rnorm(20,3), x2=rnorm(20,7), +
> ? ?FS> x3=rnorm(20,1)) + m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> ? ?FS> + m3 <- lmer(y ~ (x2|ff) + x1, data = D) + +
> ? ?FS> identical(ranef(m2), ranef(m3)) + })) [1] TRUE
>
> ? ?>> set.seed(1) all(replicate(50, {
> ? ?FS> + D <- data.frame(y= rnorm(20,10), ff = gl(4,5), +
> ? ?FS> x1=rnorm(20,3), x2=rnorm(20,7), + x3=rnorm(20,1)) + m2
> ? ?FS> <- lmer(y ~ x1 + (x2|ff), data = D) + m3 <- lmer(y ~
> ? ?FS> (x2|ff) + x1, data = D) + + identical(ranef(m2),
> ? ?FS> ranef(m3)) + })) [1] TRUE
>
> ? ?FS> ? ? ? ? [[alternative HTML version deleted]]
>
> ? ?FS> _______________________________________________
> ? ?FS> R-sig-mixed-models at r-project.org mailing list
> ? ?FS> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pogola at Princeton.EDU  Tue Aug  4 01:17:58 2009
From: pogola at Princeton.EDU (Patrick Onyango)
Date: Mon, 3 Aug 2009 19:17:58 -0400
Subject: [R-sig-ME] pvals.fnc for lme4
Message-ID: <9C914705-BE17-44FB-BE9A-94DBB0B6AD36@Princeton.EDU>

Hello everyone,
I am trying to employ the pvals.fnc function associated with Monte  
Carlo simulation but can't seem to get it to run. I tried R help, ? 
pvals.fnc, but couldn't find its description in R.

I will appreciate your help.

Patrick



From kubovy at virginia.edu  Tue Aug  4 06:19:20 2009
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 4 Aug 2009 00:19:20 -0400
Subject: [R-sig-ME] pvals.fnc for lme4
In-Reply-To: <9C914705-BE17-44FB-BE9A-94DBB0B6AD36@Princeton.EDU>
References: <9C914705-BE17-44FB-BE9A-94DBB0B6AD36@Princeton.EDU>
Message-ID: <084DC8E0-1D99-46FB-BEC3-E590A24B04F1@virginia.edu>

You need to install the package languageR.

On Aug 3, 2009, at 7:17 PM, Patrick Onyango wrote:

> Hello everyone,
> I am trying to employ the pvals.fnc function associated with Monte  
> Carlo simulation but can't seem to get it to run. I tried R help, ? 
> pvals.fnc, but couldn't find its description in R.
>
> I will appreciate your help.
>
> Patrick
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From juliet.hannah at gmail.com  Tue Aug  4 16:24:52 2009
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Tue, 4 Aug 2009 10:24:52 -0400
Subject: [R-sig-ME] examples in Raudenbush and Bryk
Message-ID: <93d6f2a80908040724w4bafb9c3y34c24081e9e982ea@mail.gmail.com>

Hi List,

Does anyone know if nlme or lme4 code is available for the examples in
RB 2002 (specifically
Chapter 8, but other chapters also if available).

Thanks,

Juliet



From charlotte.klank at env.ethz.ch  Tue Aug  4 16:55:07 2009
From: charlotte.klank at env.ethz.ch (Klank  Charlotte)
Date: Tue, 4 Aug 2009 16:55:07 +0200
Subject: [R-sig-ME] Question re: MCMCglmm with zipoisson family
Message-ID: <8D43C73F278C20459CF6691B5202334902001630@EX6.d.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090804/6623fee0/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Aug  4 18:57:59 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 4 Aug 2009 17:57:59 +0100
Subject: [R-sig-ME] Question re: MCMCglmm with zipoisson family
In-Reply-To: <8D43C73F278C20459CF6691B5202334902001630@EX6.d.ethz.ch>
References: <8D43C73F278C20459CF6691B5202334902001630@EX6.d.ethz.ch>
Message-ID: <1CD9BB27-A155-4E54-833B-7EDE438CB4DB@ed.ac.uk>

Dear Charlotte,

The structure of the model looks valid, although you may be able to  
simplify it more and get the same level of fit.

Initially, I would work with a reparameterisation of your model:

abund3.mcmc <-
MCMCglmm(abund~trait+trait:fl+trait:mps+trait:elev+trait:distance 
+trait:dens-1,
random=~idh(trait):YEAR 
+idh(trait):pop,rcov=~idh(trait):units,data=flyden
s,family="zipoisson",prior=priorD)

This fits the same model, but the interpretation is probably easier in  
this case.

The first fixed term will be the intercept of the Poisson process and  
the second fixed term will be the intercept of the zero-inflation. The  
remaining terms are trait (Poisson and Zero-inflation) specific  
contrasts from the intercept.

You may also want to fix the zero inflation as a constant across all  
levels (both in the fixed and random terms). For example,

priorB <- list(R=list(V=diag(2),n=2,fix=2),
G=list(G1=list(V=diag(c(1, 1e-6)),n=2, fix=2),G2=list(V=diag(c(1,  
1e-6)),n=2, fix=2)))

fixes the random effect variances of the zero-inflation to zero, which  
may be OK.  However, having 1 as your prior variance for the Poisson  
process should not be used by default, and you should make sure your  
conclusions don't depend on it.

Also, you may not want zero-inflation to vary across your fixed effect  
terms (e.g. fl).  All your fixed terms look continuous, so your  
parameters (using the above parameterisation) should be of the form:

1) poisson intercept
2) zi intercept
3) effect of fl on poisson process
4) effect of fl on zi process
5) effect of elev on poisson process
6) effect of elev on zi process

and so on...

you could set effects 4,6,8.... to zero by fixing them  at zero in the  
prior specification:


priorC <- list(B=list(mu=matrix(0, nterms, 1),  V=diag(nterms)*1e+6),  
R=list(V=diag(2),n=2,fix=2),
G=list(G1=list(V=diag(c(1, 1e-6)),n=2, fix=2),G2=list(V=diag(c(1,  
1e-6)),n=2, fix=2)))

# this sets up a diffuse prior around zero on the fixed effects, where  
nterms is the number of fixed effects your fitting

diag(priorC$B$V)[seq(4, nterms, 2)]<-1e-6

# this sets the variance around the zero inflation terms (except the  
intercept) to be very small, essentially fixing them to zero.


One potential problem you may have with diffuse priors on logit-binary  
outcomes is when the probability is extreme. In this  case the logit  
probability can be very large or very small and huge changes in the  
logit probability actually translate into very small differences on  
the probability scale. For example,

 > inv.logit(5)
[1] 0.9933071
 > inv.logit(10)
[1] 0.9999546

In this case it may make more sense to put an informative prior on the  
zi fixed effects. I often use a variance of pi^2/3 because this is  
approximately uniform on the probability scale:

hist(inv.logit(rnorm(10000, 0, sqrt(pi^2/3))))

but there are probably better options when there are random effects.  
Andrew Gelman has written something on this.

Cheers,

Jarrod



On 4 Aug 2009, at 15:55, Klank Charlotte wrote:

> Dear list,
>
>
>
> I am currently working on a data set on the fly abundance in flowers  
> of
> Trollius europaeus in 20 populations, recorded over three years.
>
>
>
> I am interested in the of effect of several explanatory variables such
> as plant population size, mean plant size, plant density, elevation  
> and
> distance to next sampled population on the fly abundance in a
> population.
>
>
>
> As I think that my data is zero-inflated (it contains 87% zero  
> values),
> I would like to use a zero-inflated model, which also allows me to fit
> fixed effects as well as random effects to account for the populations
> being repeatedly measured over three years.
>
>
>
> I therefore tried to fit the MCMCglmm with a zipoisson family and am
> wondering if any of you could give me some advice on the coding, as  
> I am
> not really sure if I have done things correctly.
>
>
>
> I have checked the MCMCglmm documentation as well as previous posts
> regarding MCMCglmm with a zipoisson family, but still have some  
> problems
> with how to code and if my priors are ok.
>
>
>
> So I would greatly appreciate it if you could have a look at the code
> below and let me know if it is ok and/or point me at the right reading
> material.
>
>
>
> ---
>
> Data set:
>
> n= 16867
>
> counts done in 2006,2007 and 2008
>
> 9 populations were sampled in 2006, all 20 in 2007 & 2008
>
>
>
> response:
>
> abund -  number of flies per flower, ranging from 0 - 7
>
>
>
> variables:
>
> YEAR -  year of sampling (factor)
>
> pop - name of the sampled population (factor)
>
> fl - population size (as No. of flowers) (int)
>
> elev - elevation (int)
>
> mps - mean plant size (average No. of flowers per individual) (num)
>
> dens -  plant population density (num)
>
> distance - distance to closest sampled population (num)
>
>
>
>
>
> MODEL CODE:
>
>
>
> priorA <- list(R=list(V=diag(2),n=2,fix=2),
> G=list(G1=list(V=diag(2),n=2),G2=list(V=diag(2),n=2)))
>
>
>
> abund3.mcmc <-
> MCMCglmm(abund~trait:fl+trait:mps+trait:elev+trait:distance 
> +trait:dens,r
> andom=~idh(trait):YEAR 
> +idh(trait):pop,rcov=~idh(trait):units,data=flyden
> s,family="zipoisson",prior=priorD)
>
>
>
> ----
>
>
>
> Thanks already for the help :>
>
>
>
> Regards,
>
>
>
> Charlotte
>
>
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bates at stat.wisc.edu  Tue Aug  4 20:33:23 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 4 Aug 2009 13:33:23 -0500
Subject: [R-sig-ME] examples in Raudenbush and Bryk
In-Reply-To: <93d6f2a80908040724w4bafb9c3y34c24081e9e982ea@mail.gmail.com>
References: <93d6f2a80908040724w4bafb9c3y34c24081e9e982ea@mail.gmail.com>
Message-ID: <40e66e0b0908041133k231a38dfyef4fb2f37a40f4d2@mail.gmail.com>

On Tue, Aug 4, 2009 at 9:24 AM, Juliet Hannah<juliet.hannah at gmail.com> wrote:
> Hi List,

> Does anyone know if nlme or lme4 code is available for the examples in
> RB 2002 (specifically
> Chapter 8, but other chapters also if available).

It would not be difficult to code up those examples in lme or lmer if
we could get access to the data sets.  Are the data sets available,
perhaps with the HLM software?



From tahirajamil at yahoo.com  Tue Aug  4 21:22:05 2009
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Tue, 4 Aug 2009 12:22:05 -0700 (PDT)
Subject: [R-sig-ME] Patterned Variance-Covariance matrices for the random
	effect
Message-ID: <592029.43211.qm@web50807.mail.re2.yahoo.com>

Hi everyone
I am wondering How can I assign special patteren / form e.g. compound symmetry structure , block diagonal etc to variance-covariace matrices to mer calss.
As in nlme library we have pdMat classes to specify patterened variance-covariance matrices for the random effects.
Hope to have some help from group members.

Tahira 
Ph.D student Biometrics 
Wageningen University Wageningen



From bates at stat.wisc.edu  Tue Aug  4 21:59:15 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 4 Aug 2009 14:59:15 -0500
Subject: [R-sig-ME] Patterned Variance-Covariance matrices for the
	random effect
In-Reply-To: <592029.43211.qm@web50807.mail.re2.yahoo.com>
References: <592029.43211.qm@web50807.mail.re2.yahoo.com>
Message-ID: <40e66e0b0908041259o684a85b0l83a63db7fd8bda78@mail.gmail.com>

On Tue, Aug 4, 2009 at 2:22 PM, Tahira Jamil<tahirajamil at yahoo.com> wrote:
> Hi everyone

> I am wondering How can I assign special patteren / form e.g. compound symmetry structure , block diagonal etc to variance-covariace matrices to mer calss.

> As in nlme library we have pdMat classes to specify patterened variance-covariance matrices for the random effects.
> Hope to have some help from group members.

The functions in the lme4 package do not allow for arbitrary
specification of the variance-covariance matrix for the random
effects.  Generally you specify random effects terms in the model
formula and the variance-covariance matrix of the random effects is
derived from the rules

random effects have a multivariate Gaussian distribution with mean zero
random effects associated with different terms in the formula are independent
random effects associated with different levels of the grouping factor
in a given term are independent
random effects associated with the same level of the grouping factor
in a given term have a general positive semidefinite
variance-covariance structure that is common to all levels.



From tobias.verbeke at gmail.com  Tue Aug  4 22:23:03 2009
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Tue, 04 Aug 2009 22:23:03 +0200
Subject: [R-sig-ME] examples in Raudenbush and Bryk
In-Reply-To: <40e66e0b0908041133k231a38dfyef4fb2f37a40f4d2@mail.gmail.com>
References: <93d6f2a80908040724w4bafb9c3y34c24081e9e982ea@mail.gmail.com>
	<40e66e0b0908041133k231a38dfyef4fb2f37a40f4d2@mail.gmail.com>
Message-ID: <4A7898A7.5020901@telenet.be>

Douglas Bates wrote:
> On Tue, Aug 4, 2009 at 9:24 AM, Juliet Hannah<juliet.hannah at gmail.com> wrote:
>> Hi List,
> 
>> Does anyone know if nlme or lme4 code is available for the examples in
>> RB 2002 (specifically
>> Chapter 8, but other chapters also if available).
> 
> It would not be difficult to code up those examples in lme or lmer if
> we could get access to the data sets.  Are the data sets available,
> perhaps with the HLM software?

I found this:

ftp://ftp.lisrel.com/hlm/unix/hlm5exs.tar.Z

According to the readme

ftp://ftp.lisrel.com/hlm/unix/readme

the datasets accompany the HLM5 manual,
but some (HSB1 from appendixa/ e.g.) are
reported elsewhere as being analyzed in
Raudenbush and Bryk (2002). I don't have
a copy so cannot help in identifying the
data from Chapter 8 (if present).

HTH,
Tobias



From bates at stat.wisc.edu  Wed Aug  5 01:27:59 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 4 Aug 2009 18:27:59 -0500
Subject: [R-sig-ME] examples in Raudenbush and Bryk
In-Reply-To: <4A7898A7.5020901@telenet.be>
References: <93d6f2a80908040724w4bafb9c3y34c24081e9e982ea@mail.gmail.com>
	<40e66e0b0908041133k231a38dfyef4fb2f37a40f4d2@mail.gmail.com>
	<4A7898A7.5020901@telenet.be>
Message-ID: <40e66e0b0908041627h6f4addedt445e0a92f75ea888@mail.gmail.com>

On Tue, Aug 4, 2009 at 3:23 PM, Tobias Verbeke<tobias.verbeke at gmail.com> wrote:
> Douglas Bates wrote:
>>
>> On Tue, Aug 4, 2009 at 9:24 AM, Juliet Hannah<juliet.hannah at gmail.com>
>> wrote:
>>>
>>> Hi List,
>>
>>> Does anyone know if nlme or lme4 code is available for the examples in
>>> RB 2002 (specifically
>>> Chapter 8, but other chapters also if available).
>>
>> It would not be difficult to code up those examples in lme or lmer if
>> we could get access to the data sets. ?Are the data sets available,
>> perhaps with the HLM software?
>
> I found this:
>
> ftp://ftp.lisrel.com/hlm/unix/hlm5exs.tar.Z
>
> According to the readme
>
> ftp://ftp.lisrel.com/hlm/unix/readme
>
> the datasets accompany the HLM5 manual,
> but some (HSB1 from appendixa/ e.g.) are
> reported elsewhere as being analyzed in
> Raudenbush and Bryk (2002). I don't have
> a copy so cannot help in identifying the
> data from Chapter 8 (if present).

Thanks for checking on that, Tobias.  As far as I can see that tar
file contains the data from the High School and Beyond study (HSB) in
appendix a, the EG data set in appendix b and the THAI data set in
appendix c.  These are the ones available in an ASCII format.  Other
data sets are only available in a SAS format for a VM/CMS machine
(interesting concept of "portable data format").

One can convert these to R data sets.  The EG data are already
available as egsingle in the mlmRev package and a truncated version of
the HSB data are available as Hsb82 in the same package.  The THAI
data can be converted as shown in the enclosed.


>
> HTH,
> Tobias
>
>

From j.hadfield at ed.ac.uk  Wed Aug  5 14:10:33 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 5 Aug 2009 13:10:33 +0100
Subject: [R-sig-ME] Over-dispersed models
Message-ID: <1925F143-B009-4A00-9081-2D1F9568B465@ed.ac.uk>

Hi,

I am having trouble obtaining the variance component estimates I  
expect when using quasi GLMM models with lmer.   My first thought is  
that I am misinterpreting how lmer handles over-dispersion. For  
example, I thought a quasi Poisson model with log-link would  have the  
form:

mu = exp(Xb+Zu+e)

where mu is the Poisson rate parameter and e is a vector of residuals,  
the variance of which is estimated (the "Residual" term in the model  
summary).  However, if I use simulated data (see below) the estimates  
do not correspond. I f I simulate data  with Xb=0, and var(u)=var(e)=1  
(with a well replicated balanced design), the mean estimate is  
var(u)=3.4 and var(e)= 2.62, instead of 1.

If I fit a quasibinomial model with the linear predictor of the same  
form

Pr = inverse.logit(Xb+Zu+e)

where Pr is the probability of success, then I get var(u)=0.038 and  
var(e)= 0.042,  instead of 1.

I guess the most likely explanation is that lmer is using some other  
model for over-dispersion (multiplicative?), but if someone could  
verify that it would be great. The other odd thing is that the  
likelihood does not seem to change between the standard and quasi  
models on the same data.

Any help would be appreciated,

Jarrod

I am using version 0.999375-31 on a MacBook Pro and Linux Fedora Core8.

library(gtools)

quasipoisson=FALSE
nsim<-100
VGhat<-1:nsim
VRhat<-1:nsim
fac<-gl(250,4)

for(i in 1:nsim){
	
   fac<-gl(250,4)
   l<-rnorm(250, 0, sqrt(1))[fac]+rnorm(1000, 0, sqrt(1))

   if(quasipoisson){
     y<-rpois(1000, exp(l))
     m1<-glmer(y~1+(1|fac), family="quasipoisson")
   }else{
     y2succ<-rbinom(1000, 10, inv.logit(l))
     y2fail<-10-y2succ
     m1<-glmer(cbind(y2succ, y2fail)~1+(1|fac), family="quasibinomial")
   }

   VGhat[i]<-VarCorr(m1)$fac[1]
   VRhat[i]<-attr(VarCorr(m1), "sc")^2
}



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090805/6a7f1384/attachment.pl>

From grant.mcdonald08 at imperial.ac.uk  Wed Aug  5 15:36:05 2009
From: grant.mcdonald08 at imperial.ac.uk (Mcdonald, Grant)
Date: Wed, 5 Aug 2009 14:36:05 +0100
Subject: [R-sig-ME] mixed effect model query
Message-ID: <5D1820C78E313F42AF9CD1C3DA84628205E7A7D613@ICEXM5.ic.ac.uk>

Dear sir/Madam,

I have a designed experiment where females insects were either allocted an old or young male insect and allowed 30 minutes in which to mate.

My response is there for a 1(success) or 0(failure to mate), 
and my explanotory variables are therefore, age of male, the ratio between male and female size, and index of male and female  activity level, and the time it took within the 30monute mating trial to start a mating attempt in the first place.

I also have though information on which mass rearing tubs the insects were grown,   two tubs for females and two tubs for young males and two tubs for old males (the tubs for female and youg males are the same).  I wanted to add these in as random effects.  All combinations between tubs were represented almost equally in a 2x4 experimental design (2 female tubs and 4 male tubs)


my model would look like this, 

  model1<-lmer(successful~maleage*relweight*malemobtrue*femmobtrue*timetoattemptsecs+(1|maletub/femtub),family=binomial)

does this seem correct as i feel i cant used aov due to the non normal error structure and glm will not allow me to use tub as a random effect



Kind  Regards 
Grant McDonald
Imperial college London

P.S. I apologise if this message is in poor format as I have not emailed before and i am unsure as to how to go about it.



From dmca at ucla.edu  Wed Aug  5 18:40:23 2009
From: dmca at ucla.edu (dmca at ucla.edu)
Date: Wed, 05 Aug 2009 09:40:23 -0700
Subject: [R-sig-ME] mixed models with time as an ordered factor
Message-ID: <20090805094023.213619vqrm3hg10k@mail.ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090805/c23363c0/attachment.pl>

From burkea at nwrel.org  Wed Aug  5 21:04:33 2009
From: burkea at nwrel.org (Arthur Burke)
Date: Wed, 5 Aug 2009 12:04:33 -0700
Subject: [R-sig-ME] examples in Raudenbush and Bryk
In-Reply-To: <mailman.5.1249466402.13942.r-sig-mixed-models@r-project.org>
References: <mailman.5.1249466402.13942.r-sig-mixed-models@r-project.org>
Message-ID: <CF736B65E2E03F42A197473E43E074A20529DF04@w23-7928.nwrel.org>

For the HSB data set ...
 
HSB<-read.table("http://www.hlm-online.com/software/hsbdataset.txt",
header=T)

For MLM examples (and data) using R and other software ...

http://www.ats.ucla.edu/stat/hlm/examples/default.htm

Art
Art Burke
Northwest Regional Educational Laboratory
101 SW Main St, Suite 500
Portland, OR 97204-3213


-----Original Message-----
From: r-sig-mixed-models-request at r-project.org
[mailto:r-sig-mixed-models-request at r-project.org] 
Date: Tue, 4 Aug 2009 18:27:59 -0500
From: Douglas Bates <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] examples in Raudenbush and Bryk
To: Tobias Verbeke <tobias.verbeke at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
	<40e66e0b0908041627h6f4addedt445e0a92f75ea888 at mail.gmail.com>
Content-Type: text/plain; charset="iso-8859-1"

On Tue, Aug 4, 2009 at 3:23 PM, Tobias Verbeke<tobias.verbeke at gmail.com>
wrote:
> Douglas Bates wrote:
>>
>> On Tue, Aug 4, 2009 at 9:24 AM, Juliet 
>> Hannah<juliet.hannah at gmail.com>
>> wrote:
>>>
>>> Hi List,
>>
>>> Does anyone know if nlme or lme4 code is available for the examples 
>>> in RB 2002 (specifically Chapter 8, but other chapters also if 
>>> available).
>>
>> It would not be difficult to code up those examples in lme or lmer if

>> we could get access to the data sets. ?Are the data sets available, 
>> perhaps with the HLM software?
>
> I found this:
>
> ftp://ftp.lisrel.com/hlm/unix/hlm5exs.tar.Z
>
> According to the readme
>
> ftp://ftp.lisrel.com/hlm/unix/readme
>
> the datasets accompany the HLM5 manual, but some (HSB1 from appendixa/

> e.g.) are reported elsewhere as being analyzed in Raudenbush and Bryk 
> (2002). I don't have a copy so cannot help in identifying the data 
> from Chapter 8 (if present).

Thanks for checking on that, Tobias.  As far as I can see that tar file
contains the data from the High School and Beyond study (HSB) in
appendix a, the EG data set in appendix b and the THAI data set in
appendix c.  These are the ones available in an ASCII format.  Other
data sets are only available in a SAS format for a VM/CMS machine
(interesting concept of "portable data format").

One can convert these to R data sets.  The EG data are already available
as egsingle in the mlmRev package and a truncated version of the HSB
data are available as Hsb82 in the same package.  The THAI data can be
converted as shown in the enclosed.


>
> HTH,
> Tobias
>
>

------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 32, Issue 11



From emm.charpentier at free.fr  Wed Aug  5 18:02:07 2009
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Wed, 05 Aug 2009 18:02:07 +0200
Subject: [R-sig-ME] mixed effect model query
In-Reply-To: <5D1820C78E313F42AF9CD1C3DA84628205E7A7D613@ICEXM5.ic.ac.uk>
References: <5D1820C78E313F42AF9CD1C3DA84628205E7A7D613@ICEXM5.ic.ac.uk>
Message-ID: <1249488127.3976.23.camel@PortableToshiba>

Fresh out of my limbic system : isn't searching to adjust  odel with
fifth-order interaction begging for trouble ? Even with a $#!+load of
data ? Especially wit very few levels of the random effects ?

Also, I do not think that  the "tube" effect for females has any reason
to be corelated to the "same tube" effect for males (in fact, your
"tube" effect should be sex:tube).  

Other than that, lmer should be able to fit such a model. I'd probably
start with a first-level interaction model, wtching out for evidence of
overdispersion (and reverting to a quasi- model if necessary) :

model1<-lmer(successful~(maleage+relweight+malemobtrue+femmobtrue
+timetoattemptsecs)^2+(1|maletub)+(1[femtub),family=binomial)

HTH,
					Emmanuel Charpentier

Le mercredi 05 ao?t 2009 ? 14:36 +0100, Mcdonald, Grant a ?crit :
> Dear sir/Madam,
> 
> I have a designed experiment where females insects were either allocted an old or young male insect and allowed 30 minutes in which to mate.
> 
> My response is there for a 1(success) or 0(failure to mate), 
> and my explanotory variables are therefore, age of male, the ratio between male and female size, and index of male and female  activity level, and the time it took within the 30monute mating trial to start a mating attempt in the first place.
> 
> I also have though information on which mass rearing tubs the insects were grown,   two tubs for females and two tubs for young males and two tubs for old males (the tubs for female and youg males are the same).  I wanted to add these in as random effects.  All combinations between tubs were represented almost equally in a 2x4 experimental design (2 female tubs and 4 male tubs)
> 
> 
> my model would look like this, 
> 
>   model1<-lmer(successful~maleage*relweight*malemobtrue*femmobtrue*timetoattemptsecs+(1|maletub/femtub),family=binomial)
> 
> does this seem correct as i feel i cant used aov due to the non normal error structure and glm will not allow me to use tub as a random effect
> 
> 
> 
> Kind  Regards 
> Grant McDonald
> Imperial college London
> 
> P.S. I apologise if this message is in poor format as I have not emailed before and i am unsure as to how to go about it.
> 



From Thierry.ONKELINX at inbo.be  Thu Aug  6 10:19:24 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 6 Aug 2009 10:19:24 +0200
Subject: [R-sig-ME] mixed effect model query
In-Reply-To: <5D1820C78E313F42AF9CD1C3DA84628205E7A7D613@ICEXM5.ic.ac.uk>
References: <5D1820C78E313F42AF9CD1C3DA84628205E7A7D613@ICEXM5.ic.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A10406A3C3D3@inboexch.inbo.be>

Dear Grant,

You have not enough levels to use random effects. You have only 2 and 4
levels whereas you need at least 6 to get a decent variance estimate. So
I would suggest to use the tubs as fixed effects. Hence your model
simplifies to a logistic regression.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Mcdonald, Grant
Verzonden: woensdag 5 augustus 2009 15:36
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] mixed effect model query

Dear sir/Madam,

I have a designed experiment where females insects were either allocted
an old or young male insect and allowed 30 minutes in which to mate.

My response is there for a 1(success) or 0(failure to mate), and my
explanotory variables are therefore, age of male, the ratio between male
and female size, and index of male and female  activity level, and the
time it took within the 30monute mating trial to start a mating attempt
in the first place.

I also have though information on which mass rearing tubs the insects
were grown,   two tubs for females and two tubs for young males and two
tubs for old males (the tubs for female and youg males are the same).  I
wanted to add these in as random effects.  All combinations between tubs
were represented almost equally in a 2x4 experimental design (2 female
tubs and 4 male tubs)


my model would look like this, 


model1<-lmer(successful~maleage*relweight*malemobtrue*femmobtrue*timetoa
ttemptsecs+(1|maletub/femtub),family=binomial)

does this seem correct as i feel i cant used aov due to the non normal
error structure and glm will not allow me to use tub as a random effect



Kind  Regards
Grant McDonald
Imperial college London

P.S. I apologise if this message is in poor format as I have not emailed
before and i am unsure as to how to go about it.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From kw.stat at gmail.com  Thu Aug  6 20:56:43 2009
From: kw.stat at gmail.com (Kevin W)
Date: Thu, 6 Aug 2009 13:56:43 -0500
Subject: [R-sig-ME] Too big for lmer?
Message-ID: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090806/c933f190/attachment.pl>

From Thierry.ONKELINX at inbo.be  Fri Aug  7 10:32:16 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 7 Aug 2009 10:32:16 +0200
Subject: [R-sig-ME] Too big for lmer?
In-Reply-To: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
References: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406A3C561@inboexch.inbo.be>

Dear Kevin,

This is probably due to the huge number of levels in L which you put in
the fixed effects. lmer() calculates the correlation between all fixed
effects. That requires a huge matrix in this case.

Since you have far less random effects than fixed effects, it seems to
me more appropriate to interchange them. 

m0 <- lmer(y~H + (1|L), data = dat)

Anonther option it to use them both as crossed random effects.

m1 <- lmer(y~(1|H)+(1|L), data=dat)

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Kevin W
Verzonden: donderdag 6 augustus 2009 20:57
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Too big for lmer?

I have a simple model that appears to be too big for lmer (using 2GB of
memory).  I _can_ fit the model with asreml, but I would like to make a
comparison with lmer. Simulated data is used below, but I have real data
this causing the same problem.

set.seed(496789)
dat <- data.frame(H=sample(1:51, 24000, replace=TRUE),
                  L=sample(1:6101, 24000, replace=TRUE)) Heff <-
rnorm(51, sd=sqrt(40)) Leff <- rnorm(6101, sd=sqrt(1200)) err <-
rnorm(24000, sd=10) dat$y <- 100+Heff[dat$H] + Leff[dat$L] + err dat <-
transform(dat, H=factor(H), L=factor(L))
str(dat)
bwplot(y~H, dat)  # Looks right

Using asreml recovers the variance components almost exactly:

m1 <- asreml(y~1, data=dat, sparse=~L, random=~H)

summary(m1)$varcomp
           component std.error   z.ratio constraint
H           50.96058 10.249266  4.972121   Positive
R!variance 100.07324  1.056039 94.762853   Positive

Now try lmer:

m0 <- lmer(y~1+L+(1|H), data=dat)

Error: cannot allocate vector of size 1.1 Gb In addition: Warning
messages:
1: In model.matrix.default(mt, mf, contrasts) :
  Reached total allocation of 1535Mb: see help(memory.size)

Am I pushing lmer past its limits (given the 2GB of memory) or is there
a way to make this fit?


Kevin Wright

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From ken at kjbeath.com.au  Fri Aug  7 10:44:37 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Fri, 7 Aug 2009 18:44:37 +1000
Subject: [R-sig-ME] Too big for lmer?
In-Reply-To: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
References: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
Message-ID: <46CBB2C1-3214-4691-88AE-7673F97099EB@kjbeath.com.au>

This will fit using a 64bit version of R, but unless there is more  
than the 4GB of memory I have it will run slowly.

Like Thierry I wonder if you really want a 6000 level fixed effect.

Ken

On 07/08/2009, at 4:56 AM, Kevin W wrote:

> I have a simple model that appears to be too big for lmer (using 2GB  
> of
> memory).  I _can_ fit the model with asreml, but I would like to  
> make a
> comparison with lmer. Simulated data is used below, but I have real  
> data
> this causing the same problem.
>
> set.seed(496789)
> dat <- data.frame(H=sample(1:51, 24000, replace=TRUE),
>                  L=sample(1:6101, 24000, replace=TRUE))
> Heff <- rnorm(51, sd=sqrt(40))
> Leff <- rnorm(6101, sd=sqrt(1200))
> err <- rnorm(24000, sd=10)
> dat$y <- 100+Heff[dat$H] + Leff[dat$L] + err
> dat <- transform(dat, H=factor(H), L=factor(L))
> str(dat)
> bwplot(y~H, dat)  # Looks right
>
> Using asreml recovers the variance components almost exactly:
>
> m1 <- asreml(y~1, data=dat, sparse=~L, random=~H)
>
> summary(m1)$varcomp
>           component std.error   z.ratio constraint
> H           50.96058 10.249266  4.972121   Positive
> R!variance 100.07324  1.056039 94.762853   Positive
>
> Now try lmer:
>
> m0 <- lmer(y~1+L+(1|H), data=dat)
>
> Error: cannot allocate vector of size 1.1 Gb
> In addition: Warning messages:
> 1: In model.matrix.default(mt, mf, contrasts) :
>  Reached total allocation of 1535Mb: see help(memory.size)
>
> Am I pushing lmer past its limits (given the 2GB of memory) or is  
> there a
> way to make this fit?
>
>
> Kevin Wright
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From maechler at stat.math.ethz.ch  Fri Aug  7 11:40:05 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 Aug 2009 11:40:05 +0200
Subject: [R-sig-ME] Too big for lmer?
In-Reply-To: <46CBB2C1-3214-4691-88AE-7673F97099EB@kjbeath.com.au>
References: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
	<46CBB2C1-3214-4691-88AE-7673F97099EB@kjbeath.com.au>
Message-ID: <19067.63093.954002.338389@stat.math.ethz.ch>

>>>>> "KB" == Ken Beath <ken at kjbeath.com.au>
>>>>>     on Fri, 7 Aug 2009 18:44:37 +1000 writes:

    KB> This will fit using a 64bit version of R, but unless there is more  
    KB> than the 4GB of memory I have it will run slowly.

    KB> Like Thierry I wonder if you really want a 6000 level fixed effect.

yes, indeed.

Note however that Doug Bates and I gave talks at useR! 2009 in
Rennes and  DSC 2009 in Kopenhagen, 
  --> http://matrix.r-forge.r-project.org/slides/
where
-  we have mentioned that working with sparse model matrices
  has become much easier;
  --> indeed the latest (*-30) version of Matrix now provides a
  function
	sparse.model.matrix()
 
	  [ in the future hopefully to be deprecated by a base R
    	    model.matrix(.....,  sparse=TRUE)         option ]

 which allows to directly produce a sparse design matrix from a
 formula and model.frame / data.frame

- we used a somewhat interesting case  with n ~ 70'000
  of non-perfectly nested  students / teachers  data with
  student random effect (~ 3000 levels) but 
  teacher fixed effect (1128 levels),  
  something which is IIRC too large for ca. 1 GB RAM,  but
  just barely works with 2 GB or so.
 
  Anyway, here we've used the new lmer2(...., sparseX = TRUE) 
  code in the not-released,  but Rforge-available  "lme4a" package
  ("a" : was formerly called "allcoef"-branch of lme4).
  which did allow to circumvent memory problems, as now, 
  both X (fixed effects) and  Z (random effects)  where sparse
  matrices.
  Note the very last slide of the Kopenhagen talk has a nice
  plot of  fixed  vs  random effects for teachers  which shows
  that
  1) yes, the random effects are "just" shrinked version of the f.eff.
  2) but: the ordering *is* changed to some extent, and if you
           want to *rank* the teachers, this can be of
    considerable "political" importance.

Best regards,
Martin Maechler,  ETH Zurich



    KB> Ken

    KB> On 07/08/2009, at 4:56 AM, Kevin W wrote:

    >> I have a simple model that appears to be too big for lmer (using 2GB  
    >> of
    >> memory).  I _can_ fit the model with asreml, but I would like to  
    >> make a
    >> comparison with lmer. Simulated data is used below, but I have real  
    >> data
    >> this causing the same problem.
    >> 
    >> set.seed(496789)
    >> dat <- data.frame(H=sample(1:51, 24000, replace=TRUE),
    >> L=sample(1:6101, 24000, replace=TRUE))
    >> Heff <- rnorm(51, sd=sqrt(40))
    >> Leff <- rnorm(6101, sd=sqrt(1200))
    >> err <- rnorm(24000, sd=10)
    >> dat$y <- 100+Heff[dat$H] + Leff[dat$L] + err
    >> dat <- transform(dat, H=factor(H), L=factor(L))
    >> str(dat)
    >> bwplot(y~H, dat)  # Looks right
    >> 
    >> Using asreml recovers the variance components almost exactly:
    >> 
    >> m1 <- asreml(y~1, data=dat, sparse=~L, random=~H)
    >> 
    >> summary(m1)$varcomp
    >> component std.error   z.ratio constraint
    >> H           50.96058 10.249266  4.972121   Positive
    >> R!variance 100.07324  1.056039 94.762853   Positive
    >> 
    >> Now try lmer:
    >> 
    >> m0 <- lmer(y~1+L+(1|H), data=dat)
    >> 
    >> Error: cannot allocate vector of size 1.1 Gb
    >> In addition: Warning messages:
    >> 1: In model.matrix.default(mt, mf, contrasts) :
    >> Reached total allocation of 1535Mb: see help(memory.size)
    >> 
    >> Am I pushing lmer past its limits (given the 2GB of memory) or is  
    >> there a
    >> way to make this fit?
    >> 
    >> 
    >> Kevin Wright
    >> 
    >> [[alternative HTML version deleted]]



From eliswanson at gmail.com  Fri Aug  7 18:17:06 2009
From: eliswanson at gmail.com (Eli Swanson)
Date: Fri, 7 Aug 2009 12:17:06 -0400
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
Message-ID: <257b6eb00908070917n6afaa500m268f316a3a600698@mail.gmail.com>

Hi all,



I'm working on an analyzing some data right now that's causing me some
difficulties.  I have 2 questions, and would really appreciate any
advice that people can offer.  I don't post data because there are
over 2000 cases.  sessionInfo() is posted at the end of my post.



The data was collected during focal animal surveys (FAS).  The
response variable is the number of minutes a cub was observed nursing
(Nurse.min).  The fixed predictors are 1) the number of minutes the
mother was present during the FAS (Mom.min), 2) the mother's social
rank (Mom.rank), and 3)sex of cub(Sex).  The random effects are 1)
Identity of mom, and 2) identity of cub, as there are a large number
of observations for every mother, and most of the cubs.  Cub is nested
within mom, and when I include sex in the model, my understanding is
that I have to nest it within cub.

Question the first:
I try to create the following model, leaving out sex for the moment,
because my understanding is that with only two cases, sex complicates
matters:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))

Is this model correctly specified?  I receive a CHOLMOD warning, as follows:

   11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
CHOLMOD warning: 7u?e_
Error in mer_finalize(ans) :
  Cholmod error `not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432

When I try to include Sex as a fixed effect, I'm even less sure I'm
specifying the model correctly but my model looks like this:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))

And my output:
  0:     11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
-0.244655 -0.683584
CHOLMOD warning: 7u?e_
Error in mer_finalize(ans) :
  Cholmod error `not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432

The model works if I specify it as follows, but I can't get it to work
with sex, and I think I'm specifying the random effects incorrectly
here:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)

summary(ger)
Generalized linear mixed model fit by the Laplace approximation
Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
   Data: data
   AIC   BIC logLik deviance
 11381 11404  -5687    11373
Random effects:
 Groups  Name        Variance Std.Dev.
 Mom:Cub (Intercept) 2.1313   1.4599
Number of obs: 2234, groups: Mom:Cub, 70

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.4669098  0.1962970   -7.47 7.84e-14 ***
Mom.min      0.0688668  0.0007541   91.32  < 2e-16 ***
Mom.rank     0.0676121  0.0069510    9.73  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr) Mom.mn
Mom.min  -0.134
Mom.rank -0.332  0.115



So, am I specifying these models correctly?  What could be the
problem?  I only have 1 observation for some of the cubs, and I
thought this might be the problem, but when I remove these cubs, the
error remains.







  I'm not sure if it makes a difference, but I do have slightly
overdispersed data (its 0-inflated i think, but not hugely so), hence
my second question:

When I use the quasipoisson family to estimate the model like so
(specifying the model the only way i could get it to work, even though
this may be incorrect)
:
 ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))

Then, by my understanding, estimate the degree of overdispersion:

lme4:::sigma(ger)
 sigmaML
1.233926

How badly overdispersed is this?  I tried using MCMCglmm with a
"zipoisson", but its giving me strange results (in fact, estimates for
the fixed effects that appear to have an opposite sign of those I find
with lmer).  As I'm not an expert in Bayesian methods, I assume I'm
specifying something wrong there and would prefer to stick with lmer
for now if possible.  Can I just continue to use quasipoisson?  I know
that the standard errors are inflated, but if im not worried about
that does this mean that parameters are correctly estimated?





sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-28   Matrix_0.999375-24 lattice_0.17-22

loaded via a namespace (and not attached):
[1] grid_2.9.0





i would appreciate any help that people can offer,
Thank you very much,
Eli



-- 
Eli Swanson
Department of Zoology
Ecology, Evolutionary Biology, and Behavior Program
Michigan State University



From lborger at uoguelph.ca  Fri Aug  7 20:31:11 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 7 Aug 2009 14:31:11 -0400 (EDT)
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
 effects
In-Reply-To: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

a quick reply to get this started (you may get more expert feedback by other members of the list).

1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).

2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).


Thus I'd try something like:


ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))


If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.

Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).


HTH



Cheers,


Luca


----- Messaggio originale -----
Da: "Eli Swanson" <eliswanson at gmail.com>
A: r-sig-mixed-models at r-project.org
Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects

Hi all,



I'm working on an analyzing some data right now that's causing me some
difficulties.  I have 2 questions, and would really appreciate any
advice that people can offer.  I don't post data because there are
over 2000 cases.  sessionInfo() is posted at the end of my post.



The data was collected during focal animal surveys (FAS).  The
response variable is the number of minutes a cub was observed nursing
(Nurse.min).  The fixed predictors are 1) the number of minutes the
mother was present during the FAS (Mom.min), 2) the mother's social
rank (Mom.rank), and 3)sex of cub(Sex).  The random effects are 1)
Identity of mom, and 2) identity of cub, as there are a large number
of observations for every mother, and most of the cubs.  Cub is nested
within mom, and when I include sex in the model, my understanding is
that I have to nest it within cub.

Question the first:
I try to create the following model, leaving out sex for the moment,
because my understanding is that with only two cases, sex complicates
matters:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))

Is this model correctly specified?  I receive a CHOLMOD warning, as follows:

   11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
CHOLMOD warning: 7u?e_
Error in mer_finalize(ans) :
  Cholmod error `not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432

When I try to include Sex as a fixed effect, I'm even less sure I'm
specifying the model correctly but my model looks like this:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))

And my output:
  0:     11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
-0.244655 -0.683584
CHOLMOD warning: 7u?e_
Error in mer_finalize(ans) :
  Cholmod error `not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432

The model works if I specify it as follows, but I can't get it to work
with sex, and I think I'm specifying the random effects incorrectly
here:

ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)

summary(ger)
Generalized linear mixed model fit by the Laplace approximation
Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
   Data: data
   AIC   BIC logLik deviance
 11381 11404  -5687    11373
Random effects:
 Groups  Name        Variance Std.Dev.
 Mom:Cub (Intercept) 2.1313   1.4599
Number of obs: 2234, groups: Mom:Cub, 70

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.4669098  0.1962970   -7.47 7.84e-14 ***
Mom.min      0.0688668  0.0007541   91.32  < 2e-16 ***
Mom.rank     0.0676121  0.0069510    9.73  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr) Mom.mn
Mom.min  -0.134
Mom.rank -0.332  0.115



So, am I specifying these models correctly?  What could be the
problem?  I only have 1 observation for some of the cubs, and I
thought this might be the problem, but when I remove these cubs, the
error remains.







  I'm not sure if it makes a difference, but I do have slightly
overdispersed data (its 0-inflated i think, but not hugely so), hence
my second question:

When I use the quasipoisson family to estimate the model like so
(specifying the model the only way i could get it to work, even though
this may be incorrect)
:
 ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))

Then, by my understanding, estimate the degree of overdispersion:

lme4:::sigma(ger)
 sigmaML
1.233926

How badly overdispersed is this?  I tried using MCMCglmm with a
"zipoisson", but its giving me strange results (in fact, estimates for
the fixed effects that appear to have an opposite sign of those I find
with lmer).  As I'm not an expert in Bayesian methods, I assume I'm
specifying something wrong there and would prefer to stick with lmer
for now if possible.  Can I just continue to use quasipoisson?  I know
that the standard errors are inflated, but if im not worried about
that does this mean that parameters are correctly estimated?





sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-28   Matrix_0.999375-24 lattice_0.17-22

loaded via a namespace (and not attached):
[1] grid_2.9.0





i would appreciate any help that people can offer,
Thank you very much,
Eli



-- 
Eli Swanson
Department of Zoology
Ecology, Evolutionary Biology, and Behavior Program
Michigan State University

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From eliswanson at gmail.com  Fri Aug  7 21:44:06 2009
From: eliswanson at gmail.com (Eli Swanson)
Date: Fri, 7 Aug 2009 15:44:06 -0400
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
	effects
In-Reply-To: <788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>
References: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
	<788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com>

Hi,
Thanks Luca, number 1 certainly makes sense to me- i only had sex
nested within cub like that as a random effect due to something i'd
read in a previous post.

Your answer number 2 was really helpful, I did not know that.  I do in
fact already have a unique ID for both each individual mom and each
individual cub.  Recoding this did not instantly solve my problem, but
mean centering and standardizing instantly fixed it.  My new model:
ger<-lmer(Nurse.min~Mom.mins+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=quasipoisson)

Is mean centering and standardizing totally valid in this case?  I
dont know why it wouldnt be, it just seems, i dont know, a very simple
fix for an ongoing problem ive been having.

I have tried to read all the old posts about overdispersion, and in
fact have calculated other values that have been suggested, as Doug
said that sigma probably wasn't valid, ie.
ger at deviance["pwrss"]/ger at dims["n"]
   pwrss
6.933783

But, I can't find anywhere what the meaning is of deviance/n .  Is it
an estimate of the scale parameter?  In that case my data is clearly
overdispersed, but I don't have a meaningful scale on which to think
about this that I know is accurate.  I may have missed some of the
info however, so I'll go back and read through the old posts again.

Thanks again!
Eli

On Fri, Aug 7, 2009 at 2:31 PM, Luca Borger<lborger at uoguelph.ca> wrote:
> Hello,
>
> a quick reply to get this started (you may get more expert feedback by other members of the list).
>
> 1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).
>
> 2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).
>
>
> Thus I'd try something like:
>
>
> ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>
>
> If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.
>
> Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).
>
>
> HTH
>
>
>
> Cheers,
>
>
> Luca
>
>
> ----- Messaggio originale -----
> Da: "Eli Swanson" <eliswanson at gmail.com>
> A: r-sig-mixed-models at r-project.org
> Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
> Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
>
> Hi all,
>
>
>
> I'm working on an analyzing some data right now that's causing me some
> difficulties. ?I have 2 questions, and would really appreciate any
> advice that people can offer. ?I don't post data because there are
> over 2000 cases. ?sessionInfo() is posted at the end of my post.
>
>
>
> The data was collected during focal animal surveys (FAS). ?The
> response variable is the number of minutes a cub was observed nursing
> (Nurse.min). ?The fixed predictors are 1) the number of minutes the
> mother was present during the FAS (Mom.min), 2) the mother's social
> rank (Mom.rank), and 3)sex of cub(Sex). ?The random effects are 1)
> Identity of mom, and 2) identity of cub, as there are a large number
> of observations for every mother, and most of the cubs. ?Cub is nested
> within mom, and when I include sex in the model, my understanding is
> that I have to nest it within cub.
>
> Question the first:
> I try to create the following model, leaving out sex for the moment,
> because my understanding is that with only two cases, sex complicates
> matters:
>
> ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>
> Is this model correctly specified? ?I receive a CHOLMOD warning, as follows:
>
> ? 11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
> CHOLMOD warning: 7u?e_
> Error in mer_finalize(ans) :
> ?Cholmod error `not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
>
> When I try to include Sex as a fixed effect, I'm even less sure I'm
> specifying the model correctly but my model looks like this:
>
> ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>
> And my output:
> ?0: ? ? 11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
> -0.244655 -0.683584
> CHOLMOD warning: 7u?e_
> Error in mer_finalize(ans) :
> ?Cholmod error `not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
>
> The model works if I specify it as follows, but I can't get it to work
> with sex, and I think I'm specifying the random effects incorrectly
> here:
>
> ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)
>
> summary(ger)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
> ? Data: data
> ? AIC ? BIC logLik deviance
> ?11381 11404 ?-5687 ? ?11373
> Random effects:
> ?Groups ?Name ? ? ? ?Variance Std.Dev.
> ?Mom:Cub (Intercept) 2.1313 ? 1.4599
> Number of obs: 2234, groups: Mom:Cub, 70
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.4669098 ?0.1962970 ? -7.47 7.84e-14 ***
> Mom.min ? ? ?0.0688668 ?0.0007541 ? 91.32 ?< 2e-16 ***
> Mom.rank ? ? 0.0676121 ?0.0069510 ? ?9.73 ?< 2e-16 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> ? ? ? ? (Intr) Mom.mn
> Mom.min ?-0.134
> Mom.rank -0.332 ?0.115
>
>
>
> So, am I specifying these models correctly? ?What could be the
> problem? ?I only have 1 observation for some of the cubs, and I
> thought this might be the problem, but when I remove these cubs, the
> error remains.
>
>
>
>
>
>
>
> ?I'm not sure if it makes a difference, but I do have slightly
> overdispersed data (its 0-inflated i think, but not hugely so), hence
> my second question:
>
> When I use the quasipoisson family to estimate the model like so
> (specifying the model the only way i could get it to work, even though
> this may be incorrect)
> :
> ?ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))
>
> Then, by my understanding, estimate the degree of overdispersion:
>
> lme4:::sigma(ger)
> ?sigmaML
> 1.233926
>
> How badly overdispersed is this? ?I tried using MCMCglmm with a
> "zipoisson", but its giving me strange results (in fact, estimates for
> the fixed effects that appear to have an opposite sign of those I find
> with lmer). ?As I'm not an expert in Bayesian methods, I assume I'm
> specifying something wrong there and would prefer to stick with lmer
> for now if possible. ?Can I just continue to use quasipoisson? ?I know
> that the standard errors are inflated, but if im not worried about
> that does this mean that parameters are correctly estimated?
>
>
>
>
>
> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-28 ? Matrix_0.999375-24 lattice_0.17-22
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0
>
>
>
>
>
> i would appreciate any help that people can offer,
> Thank you very much,
> Eli
>
>
>
> --
> Eli Swanson
> Department of Zoology
> Ecology, Evolutionary Biology, and Behavior Program
> Michigan State University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Eli Swanson
Department of Zoology
Ecology, Evolutionary Biology, and Behavior Program
Michigan State University



From kw.stat at gmail.com  Sat Aug  8 00:30:10 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 7 Aug 2009 17:30:10 -0500
Subject: [R-sig-ME] Too big for lmer?
In-Reply-To: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
References: <5c62e0070908061156v733a3effv58c8bb5ac4066ae2@mail.gmail.com>
Message-ID: <5c62e0070908071530r4a380cefo5078d6e2cfb0f4f3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090807/e4e12d19/attachment.pl>

From petemeyer at google.com  Sat Aug  8 00:43:45 2009
From: petemeyer at google.com (Pete Meyer)
Date: Fri, 7 Aug 2009 15:43:45 -0700
Subject: [R-sig-ME]  Too big for lmer?
Message-ID: <50e00a40908071543s6adae8b8p75961bc4b390d230@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090807/a03de0fd/attachment.pl>

From may.katharina at googlemail.com  Sun Aug  9 22:53:51 2009
From: may.katharina at googlemail.com (Katharina May)
Date: Sun, 9 Aug 2009 22:53:51 +0200
Subject: [R-sig-ME] lmer (lme4): % total variance explained by random
	effect
In-Reply-To: <F3A5213A-7DD2-4055-9E0D-5C6DA298AE23@ed.ac.uk>
References: <dd40a8b0907240751q5b1d72b8n6e88668d8ba1388@mail.gmail.com>
	<dd40a8b0908020823h62830f1o82379a17fd4b2943@mail.gmail.com>
	<F3A5213A-7DD2-4055-9E0D-5C6DA298AE23@ed.ac.uk>
Message-ID: <dd40a8b0908091353s7f1a8d6fid503cff1fe0a0ec2@mail.gmail.com>

Oh yes, now I get the picture, thanks a lot!
as the variance explained by the random effect for each value of the
covariate is (luckely) more or less similar within my data, I will
take the mean to have an approximation..

Thank you very much,

               -Katharina

2009/8/3 Jarrod Hadfield <j.hadfield at ed.ac.uk>:
> Hi Katharina,
>
> The difficulty with random intercept-slope models is that they (usually)
> give rise to a non-constant variance across the range of the covariate. This
> means that the percentage of variance explained will depend on which value
> of the covariate you evaluate.
>
> If you extract the (co)variance matrix for the intercept-slopes:
>
> V<-VarCorr(name_of_model)$name_of_random_effect
>
> and then set up a design matrix with ones in the first column, and a set of
> covariate values in the second:
>
> Z<-cbind(rep(1,100), seq(-1,1,length=100))
>
> then
>
> M<-diag(Z%*%V%*%t(Z))
>
> is equal to the variance explained by the random effect for each value of
> the covariate. ?If there are no other effects M/(M+Ve) gives you the
> proportion explained where Ve is the residual variance.
>
> Hope this helps,
>
> Jarrod
>
> On 2 Aug 2009, at 16:23, Katharina May wrote:
>
>> Hi,
>>
>> just out of curiosity because nobody is answering:
>> is it not not possible to calculate the variance described by a random
>> effect on slope and intercept as percentage of the total variance
>> (variance of random effect + unexplained variance)?
>>
>> Would be more than happy if somebody can help me...
>>
>> Thanks,
>>
>> ? ? ?Katharina
>>
>>
>> 2009/7/24 Katharina May <may.katharina at googlemail.com>:
>>>
>>> Hello,
>>>
>>> just to say sorry if this questions may be somewhat "inappropriate": I'm
>>> a
>>> bachelor student,
>>> recently started with R and with trying to understand mixed models, but
>>> I'm
>>> somewhat stuck with
>>> the following problem and hope somebody might be able to help me finding
>>> a
>>> solution:
>>>
>>> How can I get the variance (in % of the total variance) which is
>>> explained
>>> by the random effect (both on slope
>>> and intercept together)?
>>> My aim is to say something like xx% of the variance is explained by the
>>> random effect...
>>>
>>> As I'm not sure how to deal with this I would be more than happy for any
>>> hints...
>>>
>>> Thank you very much and With Best Wishes from Freising/Germany,
>>>
>>> ? ? ? ? ? ? ? ? ? ? ? ?Katharina
>>>
>>>
>>>
>>> here an example output of a mixed model I use with 1 random effect on
>>> both
>>> slope and intercept,
>>> fitted with method=ML:
>>>
>>>
>>> Linear mixed model fit by maximum likelihood
>>> Formula: log(AGB) ~ log(BM_roots) + (log(BM_roots) |
>>> as.factor(biomass_data[which(biomass_data$woody == ? ? ?1), 2]))
>>> ? Data: biomass_data[which(biomass_data$woody == 1), ]
>>> ? AIC ? BIC logLik deviance REMLdev
>>> ?588.6 619.6 -288.3 ? ?576.6 ? ? 583
>>> Random effects:
>>> ?Groups ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Name
>>> ? ? ? ? ? ? ? ? ? ? ? ? Variance ? Std.Dev. ? Corr
>>> ?as.factor(biomass_data[which(biomass_data$woody == 1), 2]) (Intercept)
>>> 1.7568529 ?1.325463
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?log(BM_roots)
>>> ? ? ? ? ? ? ? ? ? ? ? ? ?0.0071313 ?0.084447 ?-0.393
>>> ?Residual
>>> 0.0809467 0.284511
>>> Number of obs: 1282, groups:
>>> as.factor(biomass_data[which(biomass_data$woody
>>> == 1), 2]), 22
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? ?1.33062 ? ?0.29669 ? ?4.48
>>> log(BM_roots) ?0.93182 ? ?0.02441 ? 38.17
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ? ? ? ?(Intr)
>>> log(BM_rts) -0.446
>>>
>>>
>>
>>
>>
>> --
>> Time flies like an arrow, fruit flies like bananas.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>



-- 
Time flies like an arrow, fruit flies like bananas.



From charpent at bacbuc.dyndns.org  Mon Aug 10 09:51:14 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Mon, 10 Aug 2009 09:51:14 +0200
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
	effects
In-Reply-To: <257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com>
References: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
	<788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>
	<257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com>
Message-ID: <1249890674.12568.33.camel@PortableToshiba>

Dear Luca, dear list,

Sorry for buttin' in after the fact, but I wonder why you want to use a
(quasi-)Poisson model ? Unless I misunderstand your problem, your
dependent variable is, in essence, continuous, even if discretized by
the measurement process : when you record, for example, 5 minutes, that
means that the time (in mins) is some *real* value t in [4.5 5.5). Using
a model based on a discrete distribution does not make sense to me ;
ditto for "overdispersion".

Of course, your data may have a non-normal residuals' distribution
and/or heteroscedasticity. That means that you may have to use a
variable transformation such as log, or something more sophisticated
such as Box & Cox or logtrans transformation : see V&R4, for example.
MASS has a couple of functions for determination of the "optimal" Box &
Cox or logtrans parameter of the dependent variable transformation in
fixed effect models ; ISTR that the car package has something more
sophisticate, proposing transformation of the dependent and independent
variables ; ISTR also that there exist a couple of packages on CRAN
dedicated to this class of problems.

However, as far as I know, all these functions are written for
fixed-effects models. You may have to adapt them to random effects
models and/or find the optimal transformations on analogous fixed
effects models. You may also have to settle for a "reasonable"
transformation on general principles and check a posteriori that your
residuals are not (wildly)non-normal or heteroscedastic (ditto for the
random effects) ... and remember that the linear model is somewhat
robust to (small) deviations from these preconditions.

Last resort : bootstrap and permutation tests, but this is
non-trivial... Maybe a look at the "coin" package may be useful.

Hope this helps (even a bit late),

					Emmanuel Charpentier

Le vendredi 07 ao?t 2009 ? 15:44 -0400, Eli Swanson a ?crit :
> Hi,
> Thanks Luca, number 1 certainly makes sense to me- i only had sex
> nested within cub like that as a random effect due to something i'd
> read in a previous post.
> 
> Your answer number 2 was really helpful, I did not know that.  I do in
> fact already have a unique ID for both each individual mom and each
> individual cub.  Recoding this did not instantly solve my problem, but
> mean centering and standardizing instantly fixed it.  My new model:
> ger<-lmer(Nurse.min~Mom.mins+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=quasipoisson)
> 
> Is mean centering and standardizing totally valid in this case?  I
> dont know why it wouldnt be, it just seems, i dont know, a very simple
> fix for an ongoing problem ive been having.
> 
> I have tried to read all the old posts about overdispersion, and in
> fact have calculated other values that have been suggested, as Doug
> said that sigma probably wasn't valid, ie.
> ger at deviance["pwrss"]/ger at dims["n"]
>    pwrss
> 6.933783
> 
> But, I can't find anywhere what the meaning is of deviance/n .  Is it
> an estimate of the scale parameter?  In that case my data is clearly
> overdispersed, but I don't have a meaningful scale on which to think
> about this that I know is accurate.  I may have missed some of the
> info however, so I'll go back and read through the old posts again.
> 
> Thanks again!
> Eli
> 
> On Fri, Aug 7, 2009 at 2:31 PM, Luca Borger<lborger at uoguelph.ca> wrote:
> > Hello,
> >
> > a quick reply to get this started (you may get more expert feedback by other members of the list).
> >
> > 1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).
> >
> > 2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).
> >
> >
> > Thus I'd try something like:
> >
> >
> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >
> >
> > If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.
> >
> > Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).
> >
> >
> > HTH
> >
> >
> >
> > Cheers,
> >
> >
> > Luca
> >
> >
> > ----- Messaggio originale -----
> > Da: "Eli Swanson" <eliswanson at gmail.com>
> > A: r-sig-mixed-models at r-project.org
> > Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
> > Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
> >
> > Hi all,
> >
> >
> >
> > I'm working on an analyzing some data right now that's causing me some
> > difficulties.  I have 2 questions, and would really appreciate any
> > advice that people can offer.  I don't post data because there are
> > over 2000 cases.  sessionInfo() is posted at the end of my post.
> >
> >
> >
> > The data was collected during focal animal surveys (FAS).  The
> > response variable is the number of minutes a cub was observed nursing
> > (Nurse.min).  The fixed predictors are 1) the number of minutes the
> > mother was present during the FAS (Mom.min), 2) the mother's social
> > rank (Mom.rank), and 3)sex of cub(Sex).  The random effects are 1)
> > Identity of mom, and 2) identity of cub, as there are a large number
> > of observations for every mother, and most of the cubs.  Cub is nested
> > within mom, and when I include sex in the model, my understanding is
> > that I have to nest it within cub.
> >
> > Question the first:
> > I try to create the following model, leaving out sex for the moment,
> > because my understanding is that with only two cases, sex complicates
> > matters:
> >
> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >
> > Is this model correctly specified?  I receive a CHOLMOD warning, as follows:
> >
> >   11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
> > CHOLMOD warning: 7u?e_
> > Error in mer_finalize(ans) :
> >  Cholmod error `not positive definite' at
> > file:../Cholesky/t_cholmod_rowfac.c, line 432
> >
> > When I try to include Sex as a fixed effect, I'm even less sure I'm
> > specifying the model correctly but my model looks like this:
> >
> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >
> > And my output:
> >  0:     11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
> > -0.244655 -0.683584
> > CHOLMOD warning: 7u?e_
> > Error in mer_finalize(ans) :
> >  Cholmod error `not positive definite' at
> > file:../Cholesky/t_cholmod_rowfac.c, line 432
> >
> > The model works if I specify it as follows, but I can't get it to work
> > with sex, and I think I'm specifying the random effects incorrectly
> > here:
> >
> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)
> >
> > summary(ger)
> > Generalized linear mixed model fit by the Laplace approximation
> > Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
> >   Data: data
> >   AIC   BIC logLik deviance
> >  11381 11404  -5687    11373
> > Random effects:
> >  Groups  Name        Variance Std.Dev.
> >  Mom:Cub (Intercept) 2.1313   1.4599
> > Number of obs: 2234, groups: Mom:Cub, 70
> >
> > Fixed effects:
> >              Estimate Std. Error z value Pr(>|z|)
> > (Intercept) -1.4669098  0.1962970   -7.47 7.84e-14 ***
> > Mom.min      0.0688668  0.0007541   91.32  < 2e-16 ***
> > Mom.rank     0.0676121  0.0069510    9.73  < 2e-16 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >         (Intr) Mom.mn
> > Mom.min  -0.134
> > Mom.rank -0.332  0.115
> >
> >
> >
> > So, am I specifying these models correctly?  What could be the
> > problem?  I only have 1 observation for some of the cubs, and I
> > thought this might be the problem, but when I remove these cubs, the
> > error remains.
> >
> >
> >
> >
> >
> >
> >
> >  I'm not sure if it makes a difference, but I do have slightly
> > overdispersed data (its 0-inflated i think, but not hugely so), hence
> > my second question:
> >
> > When I use the quasipoisson family to estimate the model like so
> > (specifying the model the only way i could get it to work, even though
> > this may be incorrect)
> > :
> >  ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))
> >
> > Then, by my understanding, estimate the degree of overdispersion:
> >
> > lme4:::sigma(ger)
> >  sigmaML
> > 1.233926
> >
> > How badly overdispersed is this?  I tried using MCMCglmm with a
> > "zipoisson", but its giving me strange results (in fact, estimates for
> > the fixed effects that appear to have an opposite sign of those I find
> > with lmer).  As I'm not an expert in Bayesian methods, I assume I'm
> > specifying something wrong there and would prefer to stick with lmer
> > for now if possible.  Can I just continue to use quasipoisson?  I know
> > that the standard errors are inflated, but if im not worried about
> > that does this mean that parameters are correctly estimated?
> >
> >
> >
> >
> >
> > sessionInfo()
> > R version 2.9.0 (2009-04-17)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] lme4_0.999375-28   Matrix_0.999375-24 lattice_0.17-22
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.9.0
> >
> >
> >
> >
> >
> > i would appreciate any help that people can offer,
> > Thank you very much,
> > Eli
> >
> >
> >
> > --
> > Eli Swanson
> > Department of Zoology
> > Ecology, Evolutionary Biology, and Behavior Program
> > Michigan State University
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> 
> -- 
> Eli Swanson
> Department of Zoology
> Ecology, Evolutionary Biology, and Behavior Program
> Michigan State University
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From eliswanson at gmail.com  Mon Aug 10 16:28:20 2009
From: eliswanson at gmail.com (Eli Swanson)
Date: Mon, 10 Aug 2009 10:28:20 -0400
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
	effects
In-Reply-To: <1249890674.12568.33.camel@PortableToshiba>
References: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
	<788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca> 
	<257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com> 
	<1249890674.12568.33.camel@PortableToshiba>
Message-ID: <257b6eb00908100728t4b6e3807n1ec7c995568c3819@mail.gmail.com>

Hi Emmanuel,

    Ok, point very well taken, all my values are integers, but you are
correct that they were discretized by the measurement process.

    In that case, is there any input on what the current state of
negative binomial distributions is?  My understanding is that one can
use lmer as long as you specify a theta value, or use glmmADMB.  Are
these approaches still valid?  The conversations I found on the boards
were a couple years old.  Do you think I would I be better off using
one of the transformations you suggest?

Thanks!
Eli




-- 
Eli Swanson
Department of Zoology
Ecology, Evolutionary Biology, and Behavior Program
Michigan State University


On Mon, Aug 10, 2009 at 3:51 AM, Emmanuel
Charpentier<charpent at bacbuc.dyndns.org> wrote:
>
>
> Dear Luca, dear list,
>
> Sorry for buttin' in after the fact, but I wonder why you want to use a
> (quasi-)Poisson model ? Unless I misunderstand your problem, your
> dependent variable is, in essence, continuous, even if discretized by
> the measurement process : when you record, for example, 5 minutes, that
> means that the time (in mins) is some *real* value t in [4.5 5.5). Using
> a model based on a discrete distribution does not make sense to me ;
> ditto for "overdispersion".
>
> Of course, your data may have a non-normal residuals' distribution
> and/or heteroscedasticity. That means that you may have to use a
> variable transformation such as log, or something more sophisticated
> such as Box & Cox or logtrans transformation : see V&R4, for example.
> MASS has a couple of functions for determination of the "optimal" Box &
> Cox or logtrans parameter of the dependent variable transformation in
> fixed effect models ; ISTR that the car package has something more
> sophisticate, proposing transformation of the dependent and independent
> variables ; ISTR also that there exist a couple of packages on CRAN
> dedicated to this class of problems.
>
> However, as far as I know, all these functions are written for
> fixed-effects models. You may have to adapt them to random effects
> models and/or find the optimal transformations on analogous fixed
> effects models. You may also have to settle for a "reasonable"
> transformation on general principles and check a posteriori that your
> residuals are not (wildly)non-normal or heteroscedastic (ditto for the
> random effects) ... and remember that the linear model is somewhat
> robust to (small) deviations from these preconditions.
>
> Last resort : bootstrap and permutation tests, but this is
> non-trivial... Maybe a look at the "coin" package may be useful.
>
> Hope this helps (even a bit late),
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Emmanuel Charpentier
>
> Le vendredi 07 ao?t 2009 ? 15:44 -0400, Eli Swanson a ?crit :
>> Hi,
>> Thanks Luca, number 1 certainly makes sense to me- i only had sex
>> nested within cub like that as a random effect due to something i'd
>> read in a previous post.
>>
>> Your answer number 2 was really helpful, I did not know that. ?I do in
>> fact already have a unique ID for both each individual mom and each
>> individual cub. ?Recoding this did not instantly solve my problem, but
>> mean centering and standardizing instantly fixed it. ?My new model:
>> ger<-lmer(Nurse.min~Mom.mins+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=quasipoisson)
>>
>> Is mean centering and standardizing totally valid in this case? ?I
>> dont know why it wouldnt be, it just seems, i dont know, a very simple
>> fix for an ongoing problem ive been having.
>>
>> I have tried to read all the old posts about overdispersion, and in
>> fact have calculated other values that have been suggested, as Doug
>> said that sigma probably wasn't valid, ie.
>> ger at deviance["pwrss"]/ger at dims["n"]
>> ? ?pwrss
>> 6.933783
>>
>> But, I can't find anywhere what the meaning is of deviance/n . ?Is it
>> an estimate of the scale parameter? ?In that case my data is clearly
>> overdispersed, but I don't have a meaningful scale on which to think
>> about this that I know is accurate. ?I may have missed some of the
>> info however, so I'll go back and read through the old posts again.
>>
>> Thanks again!
>> Eli
>>
>> On Fri, Aug 7, 2009 at 2:31 PM, Luca Borger<lborger at uoguelph.ca> wrote:
>> > Hello,
>> >
>> > a quick reply to get this started (you may get more expert feedback by other members of the list).
>> >
>> > 1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).
>> >
>> > 2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).
>> >
>> >
>> > Thus I'd try something like:
>> >
>> >
>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>> >
>> >
>> > If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.
>> >
>> > Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).
>> >
>> >
>> > HTH
>> >
>> >
>> >
>> > Cheers,
>> >
>> >
>> > Luca
>> >
>> >
>> > ----- Messaggio originale -----
>> > Da: "Eli Swanson" <eliswanson at gmail.com>
>> > A: r-sig-mixed-models at r-project.org
>> > Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
>> > Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
>> >
>> > Hi all,
>> >
>> >
>> >
>> > I'm working on an analyzing some data right now that's causing me some
>> > difficulties. ?I have 2 questions, and would really appreciate any
>> > advice that people can offer. ?I don't post data because there are
>> > over 2000 cases. ?sessionInfo() is posted at the end of my post.
>> >
>> >
>> >
>> > The data was collected during focal animal surveys (FAS). ?The
>> > response variable is the number of minutes a cub was observed nursing
>> > (Nurse.min). ?The fixed predictors are 1) the number of minutes the
>> > mother was present during the FAS (Mom.min), 2) the mother's social
>> > rank (Mom.rank), and 3)sex of cub(Sex). ?The random effects are 1)
>> > Identity of mom, and 2) identity of cub, as there are a large number
>> > of observations for every mother, and most of the cubs. ?Cub is nested
>> > within mom, and when I include sex in the model, my understanding is
>> > that I have to nest it within cub.
>> >
>> > Question the first:
>> > I try to create the following model, leaving out sex for the moment,
>> > because my understanding is that with only two cases, sex complicates
>> > matters:
>> >
>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>> >
>> > Is this model correctly specified? ?I receive a CHOLMOD warning, as follows:
>> >
>> > ? 11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
>> > CHOLMOD warning: 7u?e_
>> > Error in mer_finalize(ans) :
>> > ?Cholmod error `not positive definite' at
>> > file:../Cholesky/t_cholmod_rowfac.c, line 432
>> >
>> > When I try to include Sex as a fixed effect, I'm even less sure I'm
>> > specifying the model correctly but my model looks like this:
>> >
>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>> >
>> > And my output:
>> > ?0: ? ? 11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
>> > -0.244655 -0.683584
>> > CHOLMOD warning: 7u?e_
>> > Error in mer_finalize(ans) :
>> > ?Cholmod error `not positive definite' at
>> > file:../Cholesky/t_cholmod_rowfac.c, line 432
>> >
>> > The model works if I specify it as follows, but I can't get it to work
>> > with sex, and I think I'm specifying the random effects incorrectly
>> > here:
>> >
>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)
>> >
>> > summary(ger)
>> > Generalized linear mixed model fit by the Laplace approximation
>> > Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
>> > ? Data: data
>> > ? AIC ? BIC logLik deviance
>> > ?11381 11404 ?-5687 ? ?11373
>> > Random effects:
>> > ?Groups ?Name ? ? ? ?Variance Std.Dev.
>> > ?Mom:Cub (Intercept) 2.1313 ? 1.4599
>> > Number of obs: 2234, groups: Mom:Cub, 70
>> >
>> > Fixed effects:
>> > ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> > (Intercept) -1.4669098 ?0.1962970 ? -7.47 7.84e-14 ***
>> > Mom.min ? ? ?0.0688668 ?0.0007541 ? 91.32 ?< 2e-16 ***
>> > Mom.rank ? ? 0.0676121 ?0.0069510 ? ?9.73 ?< 2e-16 ***
>> > ---
>> > Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Correlation of Fixed Effects:
>> > ? ? ? ? (Intr) Mom.mn
>> > Mom.min ?-0.134
>> > Mom.rank -0.332 ?0.115
>> >
>> >
>> >
>> > So, am I specifying these models correctly? ?What could be the
>> > problem? ?I only have 1 observation for some of the cubs, and I
>> > thought this might be the problem, but when I remove these cubs, the
>> > error remains.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ?I'm not sure if it makes a difference, but I do have slightly
>> > overdispersed data (its 0-inflated i think, but not hugely so), hence
>> > my second question:
>> >
>> > When I use the quasipoisson family to estimate the model like so
>> > (specifying the model the only way i could get it to work, even though
>> > this may be incorrect)
>> > :
>> > ?ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))
>> >
>> > Then, by my understanding, estimate the degree of overdispersion:
>> >
>> > lme4:::sigma(ger)
>> > ?sigmaML
>> > 1.233926
>> >
>> > How badly overdispersed is this? ?I tried using MCMCglmm with a
>> > "zipoisson", but its giving me strange results (in fact, estimates for
>> > the fixed effects that appear to have an opposite sign of those I find
>> > with lmer). ?As I'm not an expert in Bayesian methods, I assume I'm
>> > specifying something wrong there and would prefer to stick with lmer
>> > for now if possible. ?Can I just continue to use quasipoisson? ?I know
>> > that the standard errors are inflated, but if im not worried about
>> > that does this mean that parameters are correctly estimated?
>> >
>> >
>> >
>> >
>> >
>> > sessionInfo()
>> > R version 2.9.0 (2009-04-17)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> > States.1252;LC_MONETARY=English_United
>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>> >
>> > attached base packages:
>> > [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-28 ? Matrix_0.999375-24 lattice_0.17-22
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.9.0
>> >
>> >
>> >
>> >
>> >
>> > i would appreciate any help that people can offer,
>> > Thank you very much,
>> > Eli
>> >
>> >
>> >
>> > --
>> > Eli Swanson
>> > Department of Zoology
>> > Ecology, Evolutionary Biology, and Behavior Program
>> > Michigan State University
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
>>
>> --
>> Eli Swanson
>> Department of Zoology
>> Ecology, Evolutionary Biology, and Behavior Program
>> Michigan State University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>



From dlmcarthur at post.harvard.edu  Mon Aug 10 04:32:54 2009
From: dlmcarthur at post.harvard.edu (dlmcarthur at post.harvard.edu)
Date: Sun, 09 Aug 2009 19:32:54 -0700
Subject: [R-sig-ME] mixed models with time as an ordered factor
Message-ID: <200908100233.n7A2Wlmt027715@mail.ucla.edu>

Reposting from Wed Aug 5 (since original text got scrubbed):

For examining the shape of repeated responses over time, if time is 
specified as an ordered factor then can at least the lower orders 
(linear, quadratic, cubic...) and their interactions that emerge from 
the mixed model analysis be interpreted directly?

What to make of the differences in AIC, BIC, and random effect 
variance, from the model that does not declare time as an ordered factor?

How best to think about those degrees of freedom?

Or is there some preferred alternate strategy?

dF <- as.data.frame(cbind(rep(1:50,rep(5,50)), rep(1:2,rep(5,2)), 
rnorm(1:250), rep(1:5,50)))
names(dF) <- c('respondent', 'group', 'measure', 'time')
m.time_not_ordered <- lme(measure~group*time, random=~1|respondent, 
data=dF, method='ML')
m.time_ordered <- lme(measure~group*ordered(factor(time)), 
random=~1|respondent, data=dF, method='ML')

Many thanks - Dave McArthur



From bates at stat.wisc.edu  Mon Aug 10 17:35:17 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 10 Aug 2009 10:35:17 -0500
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
	effects
In-Reply-To: <257b6eb00908100728t4b6e3807n1ec7c995568c3819@mail.gmail.com>
References: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
	<788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>
	<257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com>
	<1249890674.12568.33.camel@PortableToshiba>
	<257b6eb00908100728t4b6e3807n1ec7c995568c3819@mail.gmail.com>
Message-ID: <40e66e0b0908100835wa6f3f46t74ae3eebef51238d@mail.gmail.com>

On Mon, Aug 10, 2009 at 9:28 AM, Eli Swanson<eliswanson at gmail.com> wrote:
> Hi Emmanuel,
>
> ? ?Ok, point very well taken, all my values are integers, but you are
> correct that they were discretized by the measurement process.
>
> ? ?In that case, is there any input on what the current state of
> negative binomial distributions is? ?My understanding is that one can
> use lmer as long as you specify a theta value, or use glmmADMB. ?Are
> these approaches still valid? ?The conversations I found on the boards
> were a couple years old.

Using the negative binomial family with a fixed theta is not yet
available in glmer but it is on the "To Do" list.

> Do you think I would I be better off using
> one of the transformations you suggest?
>
> Thanks!
> Eli
>
>
>
>
> --
> Eli Swanson
> Department of Zoology
> Ecology, Evolutionary Biology, and Behavior Program
> Michigan State University
>
>
> On Mon, Aug 10, 2009 at 3:51 AM, Emmanuel
> Charpentier<charpent at bacbuc.dyndns.org> wrote:
>>
>>
>> Dear Luca, dear list,
>>
>> Sorry for buttin' in after the fact, but I wonder why you want to use a
>> (quasi-)Poisson model ? Unless I misunderstand your problem, your
>> dependent variable is, in essence, continuous, even if discretized by
>> the measurement process : when you record, for example, 5 minutes, that
>> means that the time (in mins) is some *real* value t in [4.5 5.5). Using
>> a model based on a discrete distribution does not make sense to me ;
>> ditto for "overdispersion".
>>
>> Of course, your data may have a non-normal residuals' distribution
>> and/or heteroscedasticity. That means that you may have to use a
>> variable transformation such as log, or something more sophisticated
>> such as Box & Cox or logtrans transformation : see V&R4, for example.
>> MASS has a couple of functions for determination of the "optimal" Box &
>> Cox or logtrans parameter of the dependent variable transformation in
>> fixed effect models ; ISTR that the car package has something more
>> sophisticate, proposing transformation of the dependent and independent
>> variables ; ISTR also that there exist a couple of packages on CRAN
>> dedicated to this class of problems.
>>
>> However, as far as I know, all these functions are written for
>> fixed-effects models. You may have to adapt them to random effects
>> models and/or find the optimal transformations on analogous fixed
>> effects models. You may also have to settle for a "reasonable"
>> transformation on general principles and check a posteriori that your
>> residuals are not (wildly)non-normal or heteroscedastic (ditto for the
>> random effects) ... and remember that the linear model is somewhat
>> robust to (small) deviations from these preconditions.
>>
>> Last resort : bootstrap and permutation tests, but this is
>> non-trivial... Maybe a look at the "coin" package may be useful.
>>
>> Hope this helps (even a bit late),
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Emmanuel Charpentier
>>
>> Le vendredi 07 ao?t 2009 ? 15:44 -0400, Eli Swanson a ?crit :
>>> Hi,
>>> Thanks Luca, number 1 certainly makes sense to me- i only had sex
>>> nested within cub like that as a random effect due to something i'd
>>> read in a previous post.
>>>
>>> Your answer number 2 was really helpful, I did not know that. ?I do in
>>> fact already have a unique ID for both each individual mom and each
>>> individual cub. ?Recoding this did not instantly solve my problem, but
>>> mean centering and standardizing instantly fixed it. ?My new model:
>>> ger<-lmer(Nurse.min~Mom.mins+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=quasipoisson)
>>>
>>> Is mean centering and standardizing totally valid in this case? ?I
>>> dont know why it wouldnt be, it just seems, i dont know, a very simple
>>> fix for an ongoing problem ive been having.
>>>
>>> I have tried to read all the old posts about overdispersion, and in
>>> fact have calculated other values that have been suggested, as Doug
>>> said that sigma probably wasn't valid, ie.
>>> ger at deviance["pwrss"]/ger at dims["n"]
>>> ? ?pwrss
>>> 6.933783
>>>
>>> But, I can't find anywhere what the meaning is of deviance/n . ?Is it
>>> an estimate of the scale parameter? ?In that case my data is clearly
>>> overdispersed, but I don't have a meaningful scale on which to think
>>> about this that I know is accurate. ?I may have missed some of the
>>> info however, so I'll go back and read through the old posts again.
>>>
>>> Thanks again!
>>> Eli
>>>
>>> On Fri, Aug 7, 2009 at 2:31 PM, Luca Borger<lborger at uoguelph.ca> wrote:
>>> > Hello,
>>> >
>>> > a quick reply to get this started (you may get more expert feedback by other members of the list).
>>> >
>>> > 1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).
>>> >
>>> > 2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).
>>> >
>>> >
>>> > Thus I'd try something like:
>>> >
>>> >
>>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>>> >
>>> >
>>> > If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.
>>> >
>>> > Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).
>>> >
>>> >
>>> > HTH
>>> >
>>> >
>>> >
>>> > Cheers,
>>> >
>>> >
>>> > Luca
>>> >
>>> >
>>> > ----- Messaggio originale -----
>>> > Da: "Eli Swanson" <eliswanson at gmail.com>
>>> > A: r-sig-mixed-models at r-project.org
>>> > Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
>>> > Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
>>> >
>>> > Hi all,
>>> >
>>> >
>>> >
>>> > I'm working on an analyzing some data right now that's causing me some
>>> > difficulties. ?I have 2 questions, and would really appreciate any
>>> > advice that people can offer. ?I don't post data because there are
>>> > over 2000 cases. ?sessionInfo() is posted at the end of my post.
>>> >
>>> >
>>> >
>>> > The data was collected during focal animal surveys (FAS). ?The
>>> > response variable is the number of minutes a cub was observed nursing
>>> > (Nurse.min). ?The fixed predictors are 1) the number of minutes the
>>> > mother was present during the FAS (Mom.min), 2) the mother's social
>>> > rank (Mom.rank), and 3)sex of cub(Sex). ?The random effects are 1)
>>> > Identity of mom, and 2) identity of cub, as there are a large number
>>> > of observations for every mother, and most of the cubs. ?Cub is nested
>>> > within mom, and when I include sex in the model, my understanding is
>>> > that I have to nest it within cub.
>>> >
>>> > Question the first:
>>> > I try to create the following model, leaving out sex for the moment,
>>> > because my understanding is that with only two cases, sex complicates
>>> > matters:
>>> >
>>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>>> >
>>> > Is this model correctly specified? ?I receive a CHOLMOD warning, as follows:
>>> >
>>> > ? 11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
>>> > CHOLMOD warning: 7u?e_
>>> > Error in mer_finalize(ans) :
>>> > ?Cholmod error `not positive definite' at
>>> > file:../Cholesky/t_cholmod_rowfac.c, line 432
>>> >
>>> > When I try to include Sex as a fixed effect, I'm even less sure I'm
>>> > specifying the model correctly but my model looks like this:
>>> >
>>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
>>> >
>>> > And my output:
>>> > ?0: ? ? 11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
>>> > -0.244655 -0.683584
>>> > CHOLMOD warning: 7u?e_
>>> > Error in mer_finalize(ans) :
>>> > ?Cholmod error `not positive definite' at
>>> > file:../Cholesky/t_cholmod_rowfac.c, line 432
>>> >
>>> > The model works if I specify it as follows, but I can't get it to work
>>> > with sex, and I think I'm specifying the random effects incorrectly
>>> > here:
>>> >
>>> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)
>>> >
>>> > summary(ger)
>>> > Generalized linear mixed model fit by the Laplace approximation
>>> > Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
>>> > ? Data: data
>>> > ? AIC ? BIC logLik deviance
>>> > ?11381 11404 ?-5687 ? ?11373
>>> > Random effects:
>>> > ?Groups ?Name ? ? ? ?Variance Std.Dev.
>>> > ?Mom:Cub (Intercept) 2.1313 ? 1.4599
>>> > Number of obs: 2234, groups: Mom:Cub, 70
>>> >
>>> > Fixed effects:
>>> > ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>>> > (Intercept) -1.4669098 ?0.1962970 ? -7.47 7.84e-14 ***
>>> > Mom.min ? ? ?0.0688668 ?0.0007541 ? 91.32 ?< 2e-16 ***
>>> > Mom.rank ? ? 0.0676121 ?0.0069510 ? ?9.73 ?< 2e-16 ***
>>> > ---
>>> > Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> >
>>> > Correlation of Fixed Effects:
>>> > ? ? ? ? (Intr) Mom.mn
>>> > Mom.min ?-0.134
>>> > Mom.rank -0.332 ?0.115
>>> >
>>> >
>>> >
>>> > So, am I specifying these models correctly? ?What could be the
>>> > problem? ?I only have 1 observation for some of the cubs, and I
>>> > thought this might be the problem, but when I remove these cubs, the
>>> > error remains.
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > ?I'm not sure if it makes a difference, but I do have slightly
>>> > overdispersed data (its 0-inflated i think, but not hugely so), hence
>>> > my second question:
>>> >
>>> > When I use the quasipoisson family to estimate the model like so
>>> > (specifying the model the only way i could get it to work, even though
>>> > this may be incorrect)
>>> > :
>>> > ?ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))
>>> >
>>> > Then, by my understanding, estimate the degree of overdispersion:
>>> >
>>> > lme4:::sigma(ger)
>>> > ?sigmaML
>>> > 1.233926
>>> >
>>> > How badly overdispersed is this? ?I tried using MCMCglmm with a
>>> > "zipoisson", but its giving me strange results (in fact, estimates for
>>> > the fixed effects that appear to have an opposite sign of those I find
>>> > with lmer). ?As I'm not an expert in Bayesian methods, I assume I'm
>>> > specifying something wrong there and would prefer to stick with lmer
>>> > for now if possible. ?Can I just continue to use quasipoisson? ?I know
>>> > that the standard errors are inflated, but if im not worried about
>>> > that does this mean that parameters are correctly estimated?
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > sessionInfo()
>>> > R version 2.9.0 (2009-04-17)
>>> > i386-pc-mingw32
>>> >
>>> > locale:
>>> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> > States.1252;LC_MONETARY=English_United
>>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>> >
>>> > attached base packages:
>>> > [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>> >
>>> > other attached packages:
>>> > [1] lme4_0.999375-28 ? Matrix_0.999375-24 lattice_0.17-22
>>> >
>>> > loaded via a namespace (and not attached):
>>> > [1] grid_2.9.0
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > i would appreciate any help that people can offer,
>>> > Thank you very much,
>>> > Eli
>>> >
>>> >
>>> >
>>> > --
>>> > Eli Swanson
>>> > Department of Zoology
>>> > Ecology, Evolutionary Biology, and Behavior Program
>>> > Michigan State University
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>
>>>
>>> --
>>> Eli Swanson
>>> Department of Zoology
>>> Ecology, Evolutionary Biology, and Behavior Program
>>> Michigan State University
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Wolfgang.Viechtbauer at stat.unimaas.nl  Mon Aug 10 18:06:24 2009
From: Wolfgang.Viechtbauer at stat.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 10 Aug 2009 18:06:24 +0200
Subject: [R-sig-ME] mixed models with time as an ordered factor
In-Reply-To: <200908100233.n7A2Wlmt027715@mail.ucla.edu>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730FF114F5@UM-MAIL4112.unimaas.nl>

Well, first of all, the m.time_ordered model essentially gives a separate parameter for each group and each time point (2 * 5 = 10 fixed effects parameters). So, this is a saturated model, where the observed means per group and time point will be equal to the fitted means. The fit of that model will be exactly the same as using time as an unordered factor:

m.time_factor <- lme(measure~group*factor(time), random=~1|respondent, data=dF, method='ML')

The m.time_not_ordered is different, in that is assumes a linear relationship over time (that is allowed to differ in intercept and slope for the two groups).

By using time as an ordered factor, we get polynomial contrasts. So, the linear term and the linear by group interaction essentially reflect the same effects as the time and time by group interaction in the m.time_not_ordered model. However, due to the presence of the higher order terms, the results will be (slightly) different.

And, not surprisingly, the AIC, BIC, and intercept variance will also be different. Especially the AIC and BIC, which are strongly affected by the number of parameters in the model, will change noticeably.

Not sure if that helps.

Best,

--
Wolfgang Viechtbauer
 Department of Methodology and Statistics
 School for Public Health and Primary Care
 University of Maastricht, The Netherlands
 http://www.wvbauer.com/



----Original Message----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
dlmcarthur at post.harvard.edu Sent: Monday, August 10, 2009 04:33 To:
r-sig-mixed-models at r-project.org Subject: [R-sig-ME] mixed models with time
as an ordered factor

> Reposting from Wed Aug 5 (since original text got scrubbed):
>
> For examining the shape of repeated responses over time, if time is
> specified as an ordered factor then can at least the lower orders
> (linear, quadratic, cubic...) and their interactions that emerge from
> the mixed model analysis be interpreted directly?
>
> What to make of the differences in AIC, BIC, and random effect
> variance, from the model that does not declare time as an ordered factor?
>
> How best to think about those degrees of freedom?
>
> Or is there some preferred alternate strategy?
>
> dF <- as.data.frame(cbind(rep(1:50,rep(5,50)), rep(1:2,rep(5,2)),
> rnorm(1:250), rep(1:5,50)))
> names(dF) <- c('respondent', 'group', 'measure', 'time')
> m.time_not_ordered <- lme(measure~group*time, random=~1|respondent,
> data=dF, method='ML')
> m.time_ordered <- lme(measure~group*ordered(factor(time)),
> random=~1|respondent, data=dF, method='ML')
>
> Many thanks - Dave McArthur
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From reinhold.kliegl at gmail.com  Mon Aug 10 18:25:16 2009
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 10 Aug 2009 18:25:16 +0200
Subject: [R-sig-ME] mixed models with time as an ordered factor
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730FF114F5@UM-MAIL4112.unimaas.nl>
References: <200908100233.n7A2Wlmt027715@mail.ucla.edu>
	<077E31A57DA26E46AB0D493C9966AC730FF114F5@UM-MAIL4112.unimaas.nl>
Message-ID: <aefe4d0a0908100925x2c5b28dbj3af8ebd561de9575@mail.gmail.com>

Fits will be the same for ordered(factor(dF$time)) and
factor(dF$time), but the fixed-effect estimates will differ because
they assume different default contrast specifications.

> contrasts(ordered(factor(dF$time)))
          .L         .Q            .C         ^4
1 -0.6324555  0.5345225 -3.162278e-01  0.1195229
2 -0.3162278 -0.2672612  6.324555e-01 -0.4780914
3  0.0000000 -0.5345225 -4.095972e-16  0.7171372
4  0.3162278 -0.2672612 -6.324555e-01 -0.4780914
5  0.6324555  0.5345225  3.162278e-01  0.1195229

> contrasts(factor(dF$time))
  2 3 4 5
1 0 0 0 0
2 1 0 0 0
3 0 1 0 0
4 0 0 1 0
5 0 0 0 1

Of course, other contrast specfications are possible. Group
differences will be tested for each of the coefficients. Thus, by
choosing a contrast specification in line with your differential
growth expectation, you can test very specific hypotheses.

Reinhold Kliegl


On Mon, Aug 10, 2009 at 6:06 PM, Viechtbauer Wolfgang
(STAT)<Wolfgang.Viechtbauer at stat.unimaas.nl> wrote:
> Well, first of all, the m.time_ordered model essentially gives a separate parameter for each group and each time point (2 * 5 = 10 fixed effects parameters). So, this is a saturated model, where the observed means per group and time point will be equal to the fitted means. The fit of that model will be exactly the same as using time as an unordered factor:
>
> m.time_factor <- lme(measure~group*factor(time), random=~1|respondent, data=dF, method='ML')
>
> The m.time_not_ordered is different, in that is assumes a linear relationship over time (that is allowed to differ in intercept and slope for the two groups).
>
> By using time as an ordered factor, we get polynomial contrasts. So, the linear term and the linear by group interaction essentially reflect the same effects as the time and time by group interaction in the m.time_not_ordered model. However, due to the presence of the higher order terms, the results will be (slightly) different.
>
> And, not surprisingly, the AIC, BIC, and intercept variance will also be different. Especially the AIC and BIC, which are strongly affected by the number of parameters in the model, will change noticeably.
>
> Not sure if that helps.
>
> Best,
>
> --
> Wolfgang Viechtbauer
> ?Department of Methodology and Statistics
> ?School for Public Health and Primary Care
> ?University of Maastricht, The Netherlands
> ?http://www.wvbauer.com/
>
>
>
> ----Original Message----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> dlmcarthur at post.harvard.edu Sent: Monday, August 10, 2009 04:33 To:
> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] mixed models with time
> as an ordered factor
>
>> Reposting from Wed Aug 5 (since original text got scrubbed):
>>
>> For examining the shape of repeated responses over time, if time is
>> specified as an ordered factor then can at least the lower orders
>> (linear, quadratic, cubic...) and their interactions that emerge from
>> the mixed model analysis be interpreted directly?
>>
>> What to make of the differences in AIC, BIC, and random effect
>> variance, from the model that does not declare time as an ordered factor?
>>
>> How best to think about those degrees of freedom?
>>
>> Or is there some preferred alternate strategy?
>>
>> dF <- as.data.frame(cbind(rep(1:50,rep(5,50)), rep(1:2,rep(5,2)),
>> rnorm(1:250), rep(1:5,50)))
>> names(dF) <- c('respondent', 'group', 'measure', 'time')
>> m.time_not_ordered <- lme(measure~group*time, random=~1|respondent,
>> data=dF, method='ML')
>> m.time_ordered <- lme(measure~group*ordered(factor(time)),
>> random=~1|respondent, data=dF, method='ML')
>>
>> Many thanks - Dave McArthur
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From joelbried at yahoo.com  Mon Aug 10 21:32:52 2009
From: joelbried at yahoo.com (Joel Bried)
Date: Mon, 10 Aug 2009 19:32:52 +0000 (GMT)
Subject: [R-sig-ME] logistic regression for repeated measures
Message-ID: <76931.41182.qm@web24208.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090810/c3d59073/attachment.pl>

From David.Duffy at qimr.edu.au  Tue Aug 11 00:19:52 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 11 Aug 2009 08:19:52 +1000 (EST)
Subject: [R-sig-ME] logistic regression for repeated measures
In-Reply-To: <76931.41182.qm@web24208.mail.ird.yahoo.com>
References: <76931.41182.qm@web24208.mail.ird.yahoo.com>
Message-ID: <Pine.LNX.4.64.0908110813270.4299@orpheus.qimr.edu.au>

On Mon, 10 Aug 2009, Joel Bried wrote:

> I am working on paternity in a monogamous bird species and I 
> am performing analyses to check whether the probability for a male to be 
> cuckolded (binary variable) depends on his body size, the body size of 
> his female, the degree of genetic relatedness to his female and nest 
> density around his own nest (all continuous variables). Since I have 
> data for two years (2002 and 2003), I think that the best solution is to 
> conduct a logistic regression for repeated measures.
>
> However, I am a bit worried to use my entire data set. Indeed, a few 
> individuals changed partner between 2002 and 2003 (they divorced or 
> became widowed). For some other pairs, I have data for one year only 
> (the birds did not attempt to breed the other year).
>  Shall I use my whole data set?
[SNIP]

Surely you will want to use all your data, given you don't have that many 
pairs.  Why not first look at GEE models, ignoring most of the 
complications, and see if there are any interesting effects.  Then 
decide if more complex random effects models are worthwhile.

David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From charpent at bacbuc.dyndns.org  Tue Aug 11 00:35:51 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Tue, 11 Aug 2009 00:35:51 +0200
Subject: [R-sig-ME] CHOLMOD error in lmer-specifying nested random
	effects
In-Reply-To: <257b6eb00908100728t4b6e3807n1ec7c995568c3819@mail.gmail.com>
References: <1918948228.11050781249669608140.JavaMail.root@huron.cs.uoguelph.ca>
	<788937522.11054001249669871175.JavaMail.root@huron.cs.uoguelph.ca>
	<257b6eb00908071244q7086b259mf8bcf48953ce71a5@mail.gmail.com>
	<1249890674.12568.33.camel@PortableToshiba>
	<257b6eb00908100728t4b6e3807n1ec7c995568c3819@mail.gmail.com>
Message-ID: <1249943747.12613.52.camel@PortableToshiba>

Le lundi 10 ao?t 2009 ? 10:28 -0400, Eli Swanson a ?crit :
> Hi Emmanuel,
> 
>     Ok, point very well taken, all my values are integers, but you are
> correct that they were discretized by the measurement process.
> 
>     In that case, is there any input on what the current state of
> negative binomial distributions is?  My understanding is that one can
> use lmer as long as you specify a theta value, or use glmmADMB.  Are
> these approaches still valid?  The conversations I found on the boards
> were a couple years old.  Do you think I would I be better off using
> one of the transformations you suggest?

My objection to Poisson also applies to negative binomial (a discrete
distribution, last time I looked).

As to the transformation to use, I rummaged your previous posts and came
with  possible alternative :

The difficulty is that your observation is indeed a proportion, but not,
strictly speaking, a counting process. In your original posting, you
stated : "The response variable is the number of minutes a cub was
observed nursing (Nurse.min).", which I'm tempted to rewrite as "The
response variable is the *duration* a cub was observed nursing
(Nurse.t)." This duration is bound *twice* : on the left by 0, on the
right by the *total duration* of your observation (say, Obs.t).

I *think* that your variable of interest might be better expressed as
Nurse.frac=Nurse.t/Obs.t, which is bound by 0 nd 1, like a proportion.
Here, the sins of my past return to haunt me and sorely tempt me to
treat it a bit like a logistic regression problem :

What happens when you study log(Nurse.frac/(1-Nurse.frac)) in a *linear*
(mixed) model ?

Note, however, you *cannot* treat it as a "real" logistic regression
problem : the variance of this fraction is *not* a simple function of
Nurse.frac and Obs.t (your notional "sample size") ; here you have *one*
observation per unit, not Obs.mins. (To "see" it better, think of the
different results you would get when expressing your times in minutes
and in seconds...). Whereas in Poisson or logistic regression you have
to asses only one parameter (\pi or \lambda), here, you have two : \mu
and \sigma, the later being a "nuisance" parameter (which can indeed be
real nuisance : look out for heteroscedasticity).

Therefore, use lmer(..., family=gaussian) (or maybe lme(), which would
allow you to model heteroscedasticity), rather than lmer(...,
family=binomial).

Hope this helps,

						Emmanuel Charpentier

> Thanks!
> Eli
> 
> 
> 
> 
> -- 
> Eli Swanson
> Department of Zoology
> Ecology, Evolutionary Biology, and Behavior Program
> Michigan State University
> 
> 
> On Mon, Aug 10, 2009 at 3:51 AM, Emmanuel
> Charpentier<charpent at bacbuc.dyndns.org> wrote:
> >
> >
> > Dear Luca, dear list,
> >
> > Sorry for buttin' in after the fact, but I wonder why you want to use a
> > (quasi-)Poisson model ? Unless I misunderstand your problem, your
> > dependent variable is, in essence, continuous, even if discretized by
> > the measurement process : when you record, for example, 5 minutes, that
> > means that the time (in mins) is some *real* value t in [4.5 5.5). Using
> > a model based on a discrete distribution does not make sense to me ;
> > ditto for "overdispersion".
> >
> > Of course, your data may have a non-normal residuals' distribution
> > and/or heteroscedasticity. That means that you may have to use a
> > variable transformation such as log, or something more sophisticated
> > such as Box & Cox or logtrans transformation : see V&R4, for example.
> > MASS has a couple of functions for determination of the "optimal" Box &
> > Cox or logtrans parameter of the dependent variable transformation in
> > fixed effect models ; ISTR that the car package has something more
> > sophisticate, proposing transformation of the dependent and independent
> > variables ; ISTR also that there exist a couple of packages on CRAN
> > dedicated to this class of problems.
> >
> > However, as far as I know, all these functions are written for
> > fixed-effects models. You may have to adapt them to random effects
> > models and/or find the optimal transformations on analogous fixed
> > effects models. You may also have to settle for a "reasonable"
> > transformation on general principles and check a posteriori that your
> > residuals are not (wildly)non-normal or heteroscedastic (ditto for the
> > random effects) ... and remember that the linear model is somewhat
> > robust to (small) deviations from these preconditions.
> >
> > Last resort : bootstrap and permutation tests, but this is
> > non-trivial... Maybe a look at the "coin" package may be useful.
> >
> > Hope this helps (even a bit late),
> >
> >                                        Emmanuel Charpentier
> >
> > Le vendredi 07 ao?t 2009 ? 15:44 -0400, Eli Swanson a ?crit :
> >> Hi,
> >> Thanks Luca, number 1 certainly makes sense to me- i only had sex
> >> nested within cub like that as a random effect due to something i'd
> >> read in a previous post.
> >>
> >> Your answer number 2 was really helpful, I did not know that.  I do in
> >> fact already have a unique ID for both each individual mom and each
> >> individual cub.  Recoding this did not instantly solve my problem, but
> >> mean centering and standardizing instantly fixed it.  My new model:
> >> ger<-lmer(Nurse.min~Mom.mins+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=quasipoisson)
> >>
> >> Is mean centering and standardizing totally valid in this case?  I
> >> dont know why it wouldnt be, it just seems, i dont know, a very simple
> >> fix for an ongoing problem ive been having.
> >>
> >> I have tried to read all the old posts about overdispersion, and in
> >> fact have calculated other values that have been suggested, as Doug
> >> said that sigma probably wasn't valid, ie.
> >> ger at deviance["pwrss"]/ger at dims["n"]
> >>    pwrss
> >> 6.933783
> >>
> >> But, I can't find anywhere what the meaning is of deviance/n .  Is it
> >> an estimate of the scale parameter?  In that case my data is clearly
> >> overdispersed, but I don't have a meaningful scale on which to think
> >> about this that I know is accurate.  I may have missed some of the
> >> info however, so I'll go back and read through the old posts again.
> >>
> >> Thanks again!
> >> Eli
> >>
> >> On Fri, Aug 7, 2009 at 2:31 PM, Luca Borger<lborger at uoguelph.ca> wrote:
> >> > Hello,
> >> >
> >> > a quick reply to get this started (you may get more expert feedback by other members of the list).
> >> >
> >> > 1. I'd expect sex to have an effect on nursing time (longer time for males?). Sex is definitively a fixed effect (see also the mailing list archives).
> >> >
> >> > 2. Specify a unique ID code for each cub and for each mother, then lmer will work out the nesting without the need to specify it explicitly (see posts by Doug Bates on this issue).
> >> >
> >> >
> >> > Thus I'd try something like:
> >> >
> >> >
> >> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >> >
> >> >
> >> > If you don't have multiple cubs for each mother it might be that a model with only cubID might be more appropriate (but am guessing here). If the warning persists try also centrering/standardizing Mom.min.
> >> >
> >> > Re the overdispersion issue have a look at the mailing list archive (e.g. postings by Ben Bolker).
> >> >
> >> >
> >> > HTH
> >> >
> >> >
> >> >
> >> > Cheers,
> >> >
> >> >
> >> > Luca
> >> >
> >> >
> >> > ----- Messaggio originale -----
> >> > Da: "Eli Swanson" <eliswanson at gmail.com>
> >> > A: r-sig-mixed-models at r-project.org
> >> > Inviato: Venerd?, 7 agosto 2009 18:17:06 GMT +01:00 Amsterdam/Berlino/Berna/Roma/Stoccolma/Vienna
> >> > Oggetto: [R-sig-ME] CHOLMOD error in lmer-specifying nested random effects
> >> >
> >> > Hi all,
> >> >
> >> >
> >> >
> >> > I'm working on an analyzing some data right now that's causing me some
> >> > difficulties.  I have 2 questions, and would really appreciate any
> >> > advice that people can offer.  I don't post data because there are
> >> > over 2000 cases.  sessionInfo() is posted at the end of my post.
> >> >
> >> >
> >> >
> >> > The data was collected during focal animal surveys (FAS).  The
> >> > response variable is the number of minutes a cub was observed nursing
> >> > (Nurse.min).  The fixed predictors are 1) the number of minutes the
> >> > mother was present during the FAS (Mom.min), 2) the mother's social
> >> > rank (Mom.rank), and 3)sex of cub(Sex).  The random effects are 1)
> >> > Identity of mom, and 2) identity of cub, as there are a large number
> >> > of observations for every mother, and most of the cubs.  Cub is nested
> >> > within mom, and when I include sex in the model, my understanding is
> >> > that I have to nest it within cub.
> >> >
> >> > Question the first:
> >> > I try to create the following model, leaving out sex for the moment,
> >> > because my understanding is that with only two cases, sex complicates
> >> > matters:
> >> >
> >> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >> >
> >> > Is this model correctly specified?  I receive a CHOLMOD warning, as follows:
> >> >
> >> >   11918.870: 0.289063 0.172748 -0.0419576 0.0575048 0.00979307
> >> > CHOLMOD warning: 7u?e_
> >> > Error in mer_finalize(ans) :
> >> >  Cholmod error `not positive definite' at
> >> > file:../Cholesky/t_cholmod_rowfac.c, line 432
> >> >
> >> > When I try to include Sex as a fixed effect, I'm even less sure I'm
> >> > specifying the model correctly but my model looks like this:
> >> >
> >> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+Sex+(1|Mom:Cub:Sex)+(1|Mom),data=data,family=poisson,control=list(msVerbose=T))
> >> >
> >> > And my output:
> >> >  0:     11926.160: 0.289063 0.172748 0.172336 0.0572882 0.00311534
> >> > -0.244655 -0.683584
> >> > CHOLMOD warning: 7u?e_
> >> > Error in mer_finalize(ans) :
> >> >  Cholmod error `not positive definite' at
> >> > file:../Cholesky/t_cholmod_rowfac.c, line 432
> >> >
> >> > The model works if I specify it as follows, but I can't get it to work
> >> > with sex, and I think I'm specifying the random effects incorrectly
> >> > here:
> >> >
> >> > ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=poisson)
> >> >
> >> > summary(ger)
> >> > Generalized linear mixed model fit by the Laplace approximation
> >> > Formula: Nurse.min ~ Mom.min + Mom.rank + (1 | Mom:Cub)
> >> >   Data: data
> >> >   AIC   BIC logLik deviance
> >> >  11381 11404  -5687    11373
> >> > Random effects:
> >> >  Groups  Name        Variance Std.Dev.
> >> >  Mom:Cub (Intercept) 2.1313   1.4599
> >> > Number of obs: 2234, groups: Mom:Cub, 70
> >> >
> >> > Fixed effects:
> >> >              Estimate Std. Error z value Pr(>|z|)
> >> > (Intercept) -1.4669098  0.1962970   -7.47 7.84e-14 ***
> >> > Mom.min      0.0688668  0.0007541   91.32  < 2e-16 ***
> >> > Mom.rank     0.0676121  0.0069510    9.73  < 2e-16 ***
> >> > ---
> >> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> >
> >> > Correlation of Fixed Effects:
> >> >         (Intr) Mom.mn
> >> > Mom.min  -0.134
> >> > Mom.rank -0.332  0.115
> >> >
> >> >
> >> >
> >> > So, am I specifying these models correctly?  What could be the
> >> > problem?  I only have 1 observation for some of the cubs, and I
> >> > thought this might be the problem, but when I remove these cubs, the
> >> > error remains.
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >  I'm not sure if it makes a difference, but I do have slightly
> >> > overdispersed data (its 0-inflated i think, but not hugely so), hence
> >> > my second question:
> >> >
> >> > When I use the quasipoisson family to estimate the model like so
> >> > (specifying the model the only way i could get it to work, even though
> >> > this may be incorrect)
> >> > :
> >> >  ger<-lmer(Nurse.min~Mom.min+Mom.rank+(1|Mom:Cub),data=data,family=quasipoisson,control=list(msVerbose=T))
> >> >
> >> > Then, by my understanding, estimate the degree of overdispersion:
> >> >
> >> > lme4:::sigma(ger)
> >> >  sigmaML
> >> > 1.233926
> >> >
> >> > How badly overdispersed is this?  I tried using MCMCglmm with a
> >> > "zipoisson", but its giving me strange results (in fact, estimates for
> >> > the fixed effects that appear to have an opposite sign of those I find
> >> > with lmer).  As I'm not an expert in Bayesian methods, I assume I'm
> >> > specifying something wrong there and would prefer to stick with lmer
> >> > for now if possible.  Can I just continue to use quasipoisson?  I know
> >> > that the standard errors are inflated, but if im not worried about
> >> > that does this mean that parameters are correctly estimated?
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > sessionInfo()
> >> > R version 2.9.0 (2009-04-17)
> >> > i386-pc-mingw32
> >> >
> >> > locale:
> >> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> >> > States.1252;LC_MONETARY=English_United
> >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >> >
> >> > attached base packages:
> >> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >> >
> >> > other attached packages:
> >> > [1] lme4_0.999375-28   Matrix_0.999375-24 lattice_0.17-22
> >> >
> >> > loaded via a namespace (and not attached):
> >> > [1] grid_2.9.0
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > i would appreciate any help that people can offer,
> >> > Thank you very much,
> >> > Eli
> >> >
> >> >
> >> >
> >> > --
> >> > Eli Swanson
> >> > Department of Zoology
> >> > Ecology, Evolutionary Biology, and Behavior Program
> >> > Michigan State University
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >>
> >>
> >>
> >> --
> >> Eli Swanson
> >> Department of Zoology
> >> Ecology, Evolutionary Biology, and Behavior Program
> >> Michigan State University
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pmilin at ff.uns.ac.rs  Wed Aug 12 19:27:56 2009
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Wed, 12 Aug 2009 19:27:56 +0200
Subject: [R-sig-ME] mcmcsamp error message...
Message-ID: <4A82FB9C.7020805@ff.uns.ac.rs>

Hello!
I am puzzled with an error message that mcmcsamp for models with random 
correlation parameters is not implemented yet. However, this would be 
the case only with the model:
lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
(1+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
And same with:
lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
(1|subject) + (0+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item), 
data=dat)

If I run just:
lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
(1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
mcmcsamp ends fine.

I guess that the problem is in the fact that subjects were assigned 
(randomly) to only one level of the FACTOR1. Am I right?

I think, previously, mcmcsamp handled this kind of nesting, but I might 
be wrong.

What is strange to me that much more complex model (like the one where I 
got significant interaction between non-linear covariate and 
random-effect of participants -- subject) worked perfectly fine. Also, 
leaving only (0+COVARIATE3|item) is okay with mcmcsamp.

Best,
Petar Milin



From ebszolocsucsor at freemail.hu  Wed Aug 12 20:31:46 2009
From: ebszolocsucsor at freemail.hu (=?ISO-8859-2?Q?Bal=E1zs_Lest=E1r?=)
Date: Wed, 12 Aug 2009 20:31:46 +0200 (CEST)
Subject: [R-sig-ME] AIC
Message-ID: <freemail.20090712203146.76539@fm26.freemail.hu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090812/efda23fe/attachment.pl>

From andydolman at gmail.com  Wed Aug 12 22:37:41 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 12 Aug 2009 22:37:41 +0200
Subject: [R-sig-ME] AIC
In-Reply-To: <freemail.20090712203146.76539@fm26.freemail.hu>
References: <freemail.20090712203146.76539@fm26.freemail.hu>
Message-ID: <951234ac0908121337h26a13f72nde815e81814749f7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090812/f1429830/attachment.pl>

From bates at stat.wisc.edu  Fri Aug 14 15:38:34 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 14 Aug 2009 08:38:34 -0500
Subject: [R-sig-ME] mcmcsamp error message...
In-Reply-To: <4A82FB9C.7020805@ff.uns.ac.rs>
References: <4A82FB9C.7020805@ff.uns.ac.rs>
Message-ID: <40e66e0b0908140638s69e2fca1u6d56ee525edcf7d0@mail.gmail.com>

On Wed, Aug 12, 2009 at 12:27 PM, Petar Milin<pmilin at ff.uns.ac.rs> wrote:
> Hello!
> I am puzzled with an error message that mcmcsamp for models with random
> correlation parameters is not implemented yet. However, this would be the
> case only with the model:
> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
> (1+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
> And same with:
> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
> (1|subject) + (0+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item),
> data=dat)

> If I run just:
> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
> (1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
> mcmcsamp ends fine.

> I guess that the problem is in the fact that subjects were assigned
> (randomly) to only one level of the FACTOR1. Am I right?

I'm not sure what you mean by "the problem".  If FACTOR1 is a
non-trivial factor (i.e. it has more than one level) then the
random-effects terms (1 + FACTOR1|subject) and (0+FACTOR1|subject)
generate correlated random effects and currently mcmcsamp does not
handle models with correlated random effects.

If, as you say, each subject is assigned to only one level of FACTOR1
then neither of the terms above make sense.  You can't expect to
estimate an interaction of FACTOR1 and subject when FACTOR1:subject is
equivalent to subject.

> I think, previously, mcmcsamp handled this kind of nesting, but I might be
> wrong.
>
> What is strange to me that much more complex model (like the one where I got
> significant interaction between non-linear covariate and random-effect of
> participants -- subject) worked perfectly fine. Also, leaving only
> (0+COVARIATE3|item) is okay with mcmcsamp.
>
> Best,
> Petar Milin
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From pmilin at ff.uns.ac.rs  Fri Aug 14 20:15:53 2009
From: pmilin at ff.uns.ac.rs (Petar Milin)
Date: Fri, 14 Aug 2009 20:15:53 +0200
Subject: [R-sig-ME] mcmcsamp error message...
In-Reply-To: <40e66e0b0908140638s69e2fca1u6d56ee525edcf7d0@mail.gmail.com>
References: <4A82FB9C.7020805@ff.uns.ac.rs>
	<40e66e0b0908140638s69e2fca1u6d56ee525edcf7d0@mail.gmail.com>
Message-ID: <4A85A9D9.4060109@ff.uns.ac.rs>



Douglas Bates wrote:
> On Wed, Aug 12, 2009 at 12:27 PM, Petar Milin<pmilin at ff.uns.ac.rs> wrote:
>> Hello!
>> I am puzzled with an error message that mcmcsamp for models with random
>> correlation parameters is not implemented yet. However, this would be the
>> case only with the model:
>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>> (1+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
>> And same with:
>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>> (1|subject) + (0+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item),
>> data=dat)
> 
>> If I run just:
>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>> (1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
>> mcmcsamp ends fine.
> 
>> I guess that the problem is in the fact that subjects were assigned
>> (randomly) to only one level of the FACTOR1. Am I right?
> 
> I'm not sure what you mean by "the problem".  If FACTOR1 is a
> non-trivial factor (i.e. it has more than one level) then the
> random-effects terms (1 + FACTOR1|subject) and (0+FACTOR1|subject)
> generate correlated random effects and currently mcmcsamp does not
> handle models with correlated random effects.
> 
> If, as you say, each subject is assigned to only one level of FACTOR1
> then neither of the terms above make sense.  You can't expect to
> estimate an interaction of FACTOR1 and subject when FACTOR1:subject is
> equivalent to subject.

Sorry, I meant SOME subjects, but not all of them. And FACTOR1 has two 
levels, exactly. Hence, my question could be rephrased: if only 
subsample repeated levels of FACTOR1, could that be treated as a case of 
correlated random effects, in principle? Thus, in future, with the 
implementation solved, that could be handled as a regular/proper case?

>> I think, previously, mcmcsamp handled this kind of nesting, but I might be
>> wrong.

It is weird structure, anyway. (I am just trying to help a colleague.)

Thanks for the answer.
Best,
PM



From bates at stat.wisc.edu  Mon Aug 17 19:04:53 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 17 Aug 2009 12:04:53 -0500
Subject: [R-sig-ME] mcmcsamp error message...
In-Reply-To: <4A85A9D9.4060109@ff.uns.ac.rs>
References: <4A82FB9C.7020805@ff.uns.ac.rs>
	<40e66e0b0908140638s69e2fca1u6d56ee525edcf7d0@mail.gmail.com>
	<4A85A9D9.4060109@ff.uns.ac.rs>
Message-ID: <40e66e0b0908171004x14cb5b5cwb308c3a493363c0f@mail.gmail.com>

On Fri, Aug 14, 2009 at 1:15 PM, Petar Milin<pmilin at ff.uns.ac.rs> wrote:
>
>
> Douglas Bates wrote:
>>
>> On Wed, Aug 12, 2009 at 12:27 PM, Petar Milin<pmilin at ff.uns.ac.rs> wrote:
>>>
>>> Hello!
>>> I am puzzled with an error message that mcmcsamp for models with random
>>> correlation parameters is not implemented yet. However, this would be the
>>> case only with the model:
>>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>>> (1+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
>>> And same with:
>>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>>> (1|subject) + (0+FACTOR1|subject) + (1|item) + (0+COVARIATE3|item),
>>> data=dat)
>>
>>> If I run just:
>>> lmer(rt ~ FACTOR1 + COVARIATE1 + COVARIATE2 + COVARIATE3 +
>>> (1|subject) + (1|item) + (0+COVARIATE3|item), data=dat)
>>> mcmcsamp ends fine.
>>
>>> I guess that the problem is in the fact that subjects were assigned
>>> (randomly) to only one level of the FACTOR1. Am I right?
>>
>> I'm not sure what you mean by "the problem". ?If FACTOR1 is a
>> non-trivial factor (i.e. it has more than one level) then the
>> random-effects terms (1 + FACTOR1|subject) and (0+FACTOR1|subject)
>> generate correlated random effects and currently mcmcsamp does not
>> handle models with correlated random effects.
>>
>> If, as you say, each subject is assigned to only one level of FACTOR1
>> then neither of the terms above make sense. ?You can't expect to
>> estimate an interaction of FACTOR1 and subject when FACTOR1:subject is
>> equivalent to subject.
>
> Sorry, I meant SOME subjects, but not all of them. And FACTOR1 has two
> levels, exactly. Hence, my question could be rephrased: if only subsample
> repeated levels of FACTOR1, could that be treated as a case of correlated
> random effects, in principle?

Yes.

> Thus, in future, with the implementation
> solved, that could be handled as a regular/proper case?

Yes.

>>> I think, previously, mcmcsamp handled this kind of nesting, but I might
>>> be
>>> wrong.
>
> It is weird structure, anyway. (I am just trying to help a colleague.)
>
> Thanks for the answer.
> Best,
> PM
>



From Fabian.Mollet at wur.nl  Tue Aug 18 13:14:59 2009
From: Fabian.Mollet at wur.nl (Mollet, Fabian)
Date: Tue, 18 Aug 2009 13:14:59 +0200
Subject: [R-sig-ME] weighting nlme and multivariate outcomes
Message-ID: <2DF51316D2ACEF4891856424912C454E8A0B08@scomp0040.wurnet.nl>

Dear nlme expert

 

We need two pieces of information about the fitting of a nlme model which we cannot extract from the R help files and would be most grateful if you could help us. We fit an energy allocation growth model with 4 parameters to individual growth curves using the nlme routine. We thus have repeated age and size measurements of individuals and therefore allow for random individual effects (i.e. the data is grouped by individual). 

 

1)      Because the sampling of these individuals was size stratified we have to account for the representation of the individual in the true size distribution by statistical weighting. The statistical weight would thus differ across individuals but be the same over the repeated measurements of each individual (to which the random effects apply) and should be somehow multiplied by the residuals of the repeated measurements of each individual. We guess we need to use the varClasses argument but it does not seem clear in the R help files to which level the statistical weights would apply. Could you please tell us how to define the statistical weights on the level of the random effects, i.e. on the level of the individual? varIdent?

2)      We furthermore want to analyze the results of the 4 estimated parameters over time using the lme routine and have thus now 1 row per individual (comprising of the 4 parameters, a time variable and others). Because the 4 parameters are correlated we intend to analyze this multivariate outcome by "flagging" the response by using a dummy coding for the 4 parameters and the time variable as is e.g. described in Doran and Lockwood (2006) p. 223-225 (resulting in 16 rows per individual). Since we want to follow the evolution of the correlation between the 4 parameters over time we would like to make no assumptions on the correlation structure of the errors. We guess we therefore have to use the correlation=corSymm argument. However, the same weighting would apply as in 1) above to the individual and we are therefore not sure again how to define the statistical weights in this case and what this would imply for the error correlation structure. Could you give us a guidance?

 

Your help is most appreciated and we thank you very much in advance!

 

Kind regards

 

Fabian Mollet

 

 

Doran, H. C. and Lockwood, J. R. 2006. Fitting value-added models in R. - Journal of Educational and Behavioral Statistics 31: 205-230.

 



From F.DUYME at arvalisinstitutduvegetal.fr  Tue Aug 18 17:41:59 2009
From: F.DUYME at arvalisinstitutduvegetal.fr (DUYME Florent)
Date: Tue, 18 Aug 2009 17:41:59 +0200
Subject: [R-sig-ME] nested random effect with lmer
Message-ID: <674BC74273529E40A236CE2FB772DE093505871D6D@srv-exch-bgn.arvalis-fr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090818/a74dab04/attachment.pl>

From kw.stat at gmail.com  Tue Aug 18 19:11:14 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 18 Aug 2009 12:11:14 -0500
Subject: [R-sig-ME] nested random effect with lmer
In-Reply-To: <674BC74273529E40A236CE2FB772DE093505871D6D@srv-exch-bgn.arvalis-fr.com>
References: <674BC74273529E40A236CE2FB772DE093505871D6D@srv-exch-bgn.arvalis-fr.com>
Message-ID: <5c62e0070908181011v5a56eee9oc47f20195a54f482@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090818/0ee784c7/attachment.pl>

From DAfshartous at med.miami.edu  Wed Aug 19 16:29:08 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Wed, 19 Aug 2009 10:29:08 -0400
Subject: [R-sig-ME] weighting nlme and multivariate outcomes
In-Reply-To: <2DF51316D2ACEF4891856424912C454E8A0B08@scomp0040.wurnet.nl>
Message-ID: <C6B18474.B383%dafshartous@med.miami.edu>


Fabian,

RE defining weights, see section 5.2.1 in Pinheiro & Bates (Mixed Effects Models in S and S-Plus).
RE correlation structures, see section 5.3.3.   While these sections are with respect to the univariate mixed model, note that the multivariate mixed model is analogous to the univariate mixed model that is stratified per some grouping such as say gender.  For instance, as far as the data structure goes, there is no difference if we have 2 variables on 10 subjects over time versus  1 variable on 10 subjects over time for males and females.   Of course, the different scenarios will most likely lead to different model assumptions.

While I haven't used the corrrelation = corSymm for a multivariate mixed model in nlme, I have used varIdent to specify different error variances for the different response variables in the multivariate setting.  Just set up your model as specified in the Doran & Lockwood reference below, and include weights = varIdent(form ~ weights = Ind), where Ind is an indicator variable that identifies each separate response variable. What I would like to do is have the error variances also correlated across the different response variables, but only when they are both measured at the same time point.  I'll check this out again and let you know if this and your structure is possible.

Although it's respect to SAS, a good reference that provides insight into the various assumptions in the multivariate mixed model and the resulting structure of the covariance matrices is:
On the use of PROC MIXED to Estimate Correlation in the Presence of Repeated Measures by Hamlett, Ryan, and Wolfinger (comes up via google)

Cheers,
David



On 8/18/09 7:14 AM, "Mollet, Fabian" <Fabian.Mollet at wur.nl> wrote:

Dear nlme expert



We need two pieces of information about the fitting of a nlme model which we cannot extract from the R help files and would be most grateful if you could help us. We fit an energy allocation growth model with 4 parameters to individual growth curves using the nlme routine. We thus have repeated age and size measurements of individuals and therefore allow for random individual effects (i.e. the data is grouped by individual).



1)      Because the sampling of these individuals was size stratified we have to account for the representation of the individual in the true size distribution by statistical weighting. The statistical weight would thus differ across individuals but be the same over the repeated measurements of each individual (to which the random effects apply) and should be somehow multiplied by the residuals of the repeated measurements of each individual. We guess we need to use the varClasses argument but it does not seem clear in the R help files to which level the statistical weights would apply. Could you please tell us how to define the statistical weights on the level of the random effects, i.e. on the level of the individual? varIdent?

2)      We furthermore want to analyze the results of the 4 estimated parameters over time using the lme routine and have thus now 1 row per individual (comprising of the 4 parameters, a time variable and others). Because the 4 parameters are correlated we intend to analyze this multivariate outcome by "flagging" the response by using a dummy coding for the 4 parameters and the time variable as is e.g. described in Doran and Lockwood (2006) p. 223-225 (resulting in 16 rows per individual). Since we want to follow the evolution of the correlation between the 4 parameters over time we would like to make no assumptions on the correlation structure of the errors. We guess we therefore have to use the correlation=corSymm argument. However, the same weighting would apply as in 1) above to the individual and we are therefore not sure again how to define the statistical weights in this case and what this would imply for the error correlation structure. Could you give us a guidance?



Your help is most appreciated and we thank you very much in advance!



Kind regards



Fabian Mollet





Doran, H. C. and Lockwood, J. R. 2006. Fitting value-added models in R. - Journal of Educational and Behavioral Statistics 31: 205-230.



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From evans at u707.jussieu.fr  Wed Aug 19 17:03:12 2009
From: evans at u707.jussieu.fr (David Evans)
Date: Wed, 19 Aug 2009 17:03:12 +0200
Subject: [R-sig-ME] Unable to fit glmer with family=binomial(link=identity)
Message-ID: <4A8C1430.8080907@u707.jussieu.fr>

Fellow R-users,

I need to estimate the "risk difference" (in epidemiological 
terminology) for a neighbourhood-level exposure (e.g. presence of parks) 
with a binary outcome adjusted on 5 or so covariables. Study 
participants are clusted by neighbourhood .  I was hoping to use a 
generalized linear mixed model with the code:

mod  <-  glmer(outcome ~ exposure + (1 | neighbourhood), 
family=binomial(link=identity), data=rec)

but the identity link is not available for the binomial family with 
glmer (or for glmmPQL).  Is there any way to do this with lme4 or is 
there another package in R which could fix my problem?

I'd be very grateful for any help.

David.

-- 
David Evans
UMR-S 707 Inserm - Universit? Pierre et Marie Curie - Paris 6
Facult? de M?decine Saint-Antoine
27, rue Chaligny
75571 Paris cedex 12



From davidwevans at hotmail.com  Wed Aug 19 17:55:47 2009
From: davidwevans at hotmail.com (david evans)
Date: Wed, 19 Aug 2009 15:55:47 +0000
Subject: [R-sig-ME] Unable to fit glmer with family=binomial(link=identity)
Message-ID: <COL119-W51F348F82D5A52DD33941FA9FE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090819/8319cccb/attachment.pl>

From HDoran at air.org  Wed Aug 19 17:58:50 2009
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Aug 2009 11:58:50 -0400
Subject: [R-sig-ME] Unable to fit glmer with
	family=binomial(link=identity)
In-Reply-To: <4A8C1430.8080907@u707.jussieu.fr>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE0202D775@DC1EXCL01.air.org>

I may be missing something here, but why are you using an identity link with binomial outcomes? If there is a reason why, you might as well just use lmer since the identity link is for a normal distribution and that is the distributional assumption used for the errors in that function.

 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of David Evans
> Sent: Wednesday, August 19, 2009 11:03 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Unable to fit glmer with 
> family=binomial(link=identity)
> 
> Fellow R-users,
> 
> I need to estimate the "risk difference" (in epidemiological
> terminology) for a neighbourhood-level exposure (e.g. 
> presence of parks) with a binary outcome adjusted on 5 or so 
> covariables. Study participants are clusted by neighbourhood 
> .  I was hoping to use a generalized linear mixed model with the code:
> 
> mod  <-  glmer(outcome ~ exposure + (1 | neighbourhood), 
> family=binomial(link=identity), data=rec)
> 
> but the identity link is not available for the binomial 
> family with glmer (or for glmmPQL).  Is there any way to do 
> this with lme4 or is there another package in R which could 
> fix my problem?
> 
> I'd be very grateful for any help.
> 
> David.
> 
> --
> David Evans
> UMR-S 707 Inserm - Universit? Pierre et Marie Curie - Paris 6 
> Facult? de M?decine Saint-Antoine 27, rue Chaligny
> 75571 Paris cedex 12
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From HDoran at air.org  Wed Aug 19 18:09:23 2009
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Aug 2009 12:09:23 -0400
Subject: [R-sig-ME] Unable to fit glmer
	withfamily=binomial(link=identity)
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE0202D775@DC1EXCL01.air.org>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE0202D777@DC1EXCL01.air.org>

Should have added this to offer an example. What you want is possible, but I don't think this is what you really want. But, I've been wrong before.

> (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), family = gaussian, data = cbpp)) 
Linear mixed model fit by REML 
Formula: cbind(incidence, size - incidence) ~ period + (1 | herd) 
   Data: cbpp 
   AIC   BIC logLik deviance REMLdev
 255.1 267.3 -121.5    246.3   243.1
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.0000   0.0000  
 Residual             5.1254   2.2639  
Number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.0667     0.5845   6.957
period2      -2.8524     0.8413  -3.390
period3      -3.0667     0.8413  -3.645
period4      -3.5282     0.8579  -4.113

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.695              
period3 -0.695  0.483       
period4 -0.681  0.473  0.473

> (gm2 <- lmer(cbind(incidence, size - incidence) ~ period + (1 | herd), data = cbpp)) 
Linear mixed model fit by REML 
Formula: cbind(incidence, size - incidence) ~ period + (1 | herd) 
   Data: cbpp 
   AIC   BIC logLik deviance REMLdev
 255.1 267.3 -121.5    246.3   243.1
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.0000   0.0000  
 Residual             5.1254   2.2639  
Number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.0667     0.5845   6.957
period2      -2.8524     0.8413  -3.390
period3      -3.0667     0.8413  -3.645
period4      -3.5282     0.8579  -4.113

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.695              
period3 -0.695  0.483       
period4 -0.681  0.473  0.473 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Doran, Harold
> Sent: Wednesday, August 19, 2009 11:59 AM
> To: David Evans; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Unable to fit glmer 
> withfamily=binomial(link=identity)
> 
> I may be missing something here, but why are you using an 
> identity link with binomial outcomes? If there is a reason 
> why, you might as well just use lmer since the identity link 
> is for a normal distribution and that is the distributional 
> assumption used for the errors in that function.
> 
>  
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of David 
> > Evans
> > Sent: Wednesday, August 19, 2009 11:03 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Unable to fit glmer with
> > family=binomial(link=identity)
> > 
> > Fellow R-users,
> > 
> > I need to estimate the "risk difference" (in epidemiological
> > terminology) for a neighbourhood-level exposure (e.g. 
> > presence of parks) with a binary outcome adjusted on 5 or so 
> > covariables. Study participants are clusted by 
> neighbourhood .  I was 
> > hoping to use a generalized linear mixed model with the code:
> > 
> > mod  <-  glmer(outcome ~ exposure + (1 | neighbourhood), 
> > family=binomial(link=identity), data=rec)
> > 
> > but the identity link is not available for the binomial family with 
> > glmer (or for glmmPQL).  Is there any way to do this with 
> lme4 or is 
> > there another package in R which could fix my problem?
> > 
> > I'd be very grateful for any help.
> > 
> > David.
> > 
> > --
> > David Evans
> > UMR-S 707 Inserm - Universit? Pierre et Marie Curie - Paris 
> 6 Facult? 
> > de M?decine Saint-Antoine 27, rue Chaligny
> > 75571 Paris cedex 12
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From DAfshartous at med.miami.edu  Wed Aug 19 20:29:54 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Wed, 19 Aug 2009 14:29:54 -0400
Subject: [R-sig-ME] corSymm, nlme issue
Message-ID: <C6B1BCE2.B399%dafshartous@med.miami.edu>


All,

In the course of investigating yesterday's post by Fabian Mollet ([R-sig-ME]
weighting nlme and multivariate outcomes), I've noticed an issue with
corSymm. I am getting the error message below even for identical commands
used from Pinheiro & Bates (p.235).  Perhaps there was a discussion on this
previously but I didn't see anything in the archives.

Cheers,
David



> sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> library("nlme")
> cs1Symm = corSymm(value = c(.2, .1, -.1, 0, .2, 0), form = ~ 1 | Subject)
> cs1Symm = initialize(cs1Symm, data = Orthodont)
Error in getClass(Class) :
  c("\"corSymm\" is not a defined class", "\"corStruct\" is not a defined
class")
In addition: Warning message:
In if (!is.na(match(Class, .BasicClasses))) return(newBasic(Class,  :
  the condition has length > 1 and only the first element will be used



From ken at kjbeath.com.au  Wed Aug 19 23:52:16 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 20 Aug 2009 07:52:16 +1000
Subject: [R-sig-ME] Unable to fit glmer with
	family=binomial(link=identity)
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE0202D775@DC1EXCL01.air.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE0202D775@DC1EXCL01.air.org>
Message-ID: <73BE9C42-4471-40B3-AC4A-A67AB4F119E6@kjbeath.com.au>

On 20/08/2009, at 1:58 AM, Doran, Harold wrote:

> I may be missing something here, but why are you using an identity  
> link with binomial outcomes? If there is a reason why, you might as  
> well just use lmer since the identity link is for a normal  
> distribution and that is the distributional assumption used for the  
> errors in that function.
>

There are good reasons, as mentioned it results in relative risks  
rather than odds ratios. It can be made to work for fixed effects  
models, the main problem is that the linear predictor must always  
remain within 0 and 1 or the algorithm fails. For random effects  
models this is impossible, as the linear predictor plus a normally  
distributed random effect must always include points outside this  
range, so it is sensibly not allowed by the software.

Ken



>
>
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>> Of David Evans
>> Sent: Wednesday, August 19, 2009 11:03 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Unable to fit glmer with
>> family=binomial(link=identity)
>>
>> Fellow R-users,
>>
>> I need to estimate the "risk difference" (in epidemiological
>> terminology) for a neighbourhood-level exposure (e.g.
>> presence of parks) with a binary outcome adjusted on 5 or so
>> covariables. Study participants are clusted by neighbourhood
>> .  I was hoping to use a generalized linear mixed model with the  
>> code:
>>
>> mod  <-  glmer(outcome ~ exposure + (1 | neighbourhood),
>> family=binomial(link=identity), data=rec)
>>
>> but the identity link is not available for the binomial
>> family with glmer (or for glmmPQL).  Is there any way to do
>> this with lme4 or is there another package in R which could
>> fix my problem?
>>
>> I'd be very grateful for any help.
>>
>> David.
>>
>> --
>> David Evans
>> UMR-S 707 Inserm - Universit? Pierre et Marie Curie - Paris 6
>> Facult? de M?decine Saint-Antoine 27, rue Chaligny
>> 75571 Paris cedex 12
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From David.Duffy at qimr.edu.au  Thu Aug 20 05:24:15 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 20 Aug 2009 13:24:15 +1000 (EST)
Subject: [R-sig-ME] Unable to fit glmer with
	family=binomial(link=identity)
In-Reply-To: <73BE9C42-4471-40B3-AC4A-A67AB4F119E6@kjbeath.com.au>
References: <ED7B522EE00C9A4FA515AA71724D61EE0202D775@DC1EXCL01.air.org>
	<73BE9C42-4471-40B3-AC4A-A67AB4F119E6@kjbeath.com.au>
Message-ID: <Pine.LNX.4.64.0908201314560.26308@orpheus.qimr.edu.au>

On Thu, 20 Aug 2009, Ken Beath wrote:

> On 20/08/2009, at 1:58 AM, Doran, Harold wrote:
>
>> I may be missing something here, but why are you using an identity link 
>> with binomial outcomes? If there is a reason why, you might as well just 
>> use lmer since the identity link is for a normal distribution and that is 
>> the distributional assumption used for the errors in that function.
>> 
>
> There are good reasons, as mentioned it results in relative risks rather than 
> odds ratios. It can be made to work for fixed effects models, the main 
> problem is that the linear predictor must always remain within 0 and 1 or the 
> algorithm fails. For random effects models this is impossible, as the linear 
> predictor plus a normally distributed random effect must always include 
> points outside this range, so it is sensibly not allowed by the software.
>
> Ken

I do have (fortran) MCMC code for this model -- it rejects proposals 
leading to any predicted probabilities falling outside 0-1 at that 
iteration.  In R, perhaps MCMCglmm could be used.  Alternatively, if a 
point estimate is sufficient, then it could be produced from the logit 
link model fitted values from glmer, or I guess a Poisson model.  Finally, 
there is some literature suggesting that the Gaussian LMM for binary data 
might not be too bad, especially if the probabilities are all >0.05.

2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From jeroenooms at gmail.com  Wed Aug 19 21:08:07 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 19 Aug 2009 21:08:07 +0200
Subject: [R-sig-ME] Detecting duplicate random effects
Message-ID: <673e1b980908191208r45307c9dt951bc84d16020170@mail.gmail.com>

I was running into a problem in parsing lme4 output, and it turned out
that it was my own mistake (of course :) However, I think it was a
mistate that could have been detected. I accidentally inserted a
duplicate random effect term into the model. For example a user could
try:

(fm2 <- lmer(Reaction ~ Days + (1|Subject) + (Days|Subject), sleepstudy))

This does not result in an error, lme4 will fit twice a random
intercept for the Subject group. I cannot think of a situation in
which this would be useful. Would it be an idea to throw an error in
this situation? It can easily be detected by inspecting ranef(fm2),
and noticing the (intercept) term exists twice in the $Subject group.



From DAfshartous at med.miami.edu  Thu Aug 20 22:12:35 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Thu, 20 Aug 2009 16:12:35 -0400
Subject: [R-sig-ME] weighting nlme and multivariate outcomes
In-Reply-To: <C6B18474.B383%dafshartous@med.miami.edu>
Message-ID: <C6B32673.B3E0%dafshartous@med.miami.edu>


Dear Fabian and interested others,

I thought some more about the use of corSymm to accomplish your goal, as this is a question I was also thinking about myself awhile back.  The model below is close but one problem still needs to be worked out it seems.  Any other input much appreciated.  Summary below:

Consider the case where we have n1 subjects and two variables U and V, each measured at n2 time points.   Assume each variable arises from a random-intercept, random-slope model, with all random effects correlated.  Thus, the random-effects covariance matrix is 4x4.

Regarding the residual error term, for illustration suppose there are n2=2 time points.  Then for a given subject the response vector Y_i = (U_i', V_i')'  and residual error vector (e_i, d_i')' are both 4x1.  The covariance matrix of the residual error vector will thus be 4x4: the upper 2x2 being the covariance matrix of e_i, the lower 2x2 being the covariance matrix of d_i, and the off-diagonal 2x2 being the covariance matrix of e_i and d_i.  For instance, the two diagonal elements of this last 2x2 represent the covariance of the error terms of the different variables at time 1 and time 2 (the corresponding off-diagonal elements represent the covariance when each variable is measured at a _different_ time point).

Now, here are various ways to fit models to these data under different assumptions for the random-effects; the residual errors are fit with different variances per variable, and are initially assumed independent within and between variables (first copy and past the code block at the end of this e-mail that simulates the data) .

# all random-effects correlated; different residuial error variance per variable
mv1.lme = lme(y ~ -1 + U.ind + U.time + V.ind + V.time, random = ~ -1 + U.ind + U.time + V.ind + V.time | subject,
            data = data.mv.grp, control=nlmeControl(msMaxIter = 1000), weights = varIdent(form = ~ 1 | U.ind))
# all random-effects independent; need to have data as grouped-data object for pdDiag to work below
mv2.lme = lme(y ~ -1 + U.ind + U.time + V.ind + V.time, random = pdDiag(~ -1 +  U.ind + V.ind + V.time + U.time  ),
            data = data.mv.grp, control=nlmeControl(msMaxIter = 1000), weights = varIdent(form = ~ 1 | U.ind))
# random effects not correlated across variables
mv3.lme = update(mv2.lme, random = list(subject = pdBlocked(list(pdSymm(~ -1 +  U.ind + U.time),
             pdSymm(~ -1 + V.ind + V.time)))))

To relax the assumption of independence of residual errors across variables, it seems that corSymm should be sufficient.  Below I initialize the values for corSymm to correspond to the values used in the simulation, which are:

> Sig.corr
     [,1] [,2] [,3] [,4]
[1,]  1.0  0.0  0.1  0.0
[2,]  0.0  1.0  0.0  0.1
[3,]  0.1  0.0  1.0  0.0
[4,]  0.0  0.1  0.0  1.0

Thus,

value.star = offdiag.to.vector(Sig.corr)[[1]]  ## use initial values as actual values form simulation
cs1Symm = corSymm(value = value.star, form = ~ 1 | subject)
cs1Symm = Initialize(cs1Symm, data = data.mv)

However, regardless of which model above is used, adding correlation = cs1Symm introduces convergence problems:

mv3.lme = update(mv1.lme, correlation = cs1Symm, control=nlmeControl(msMaxIter = 1000))
Error in lme.formula(fixed = y ~ -1 + U.ind + U.time + V.ind + V.time,  :
  nlminb problem, convergence error code = 1
  message = false convergence (8)

It would seem that we need to perhaps fix some of the values of the correlation matrix to 0, viz., all off-diagonal elements of each of the 2x2 blocks mentioned earlier, but I do not see a way to do that based on the description in P&B (p.235).  It seems like this exists for varFunc but not for corStruct.  Does anyone know a way around this to reduce the number of parameters that are being estimated for the residual error accordingly?

Perhaps the design values of my simulation are part of the problem but I played around with them and didn't have much success.  If this last issue with corSymm can be solved it seems that a wide class of multivariate models will be able to be fit with lme.

Cheers,
David


##############

library("MASS"); library("nlme"); library("lattice")
set.seed(100); n1 = 50; n2 = 4
# U: random-intercept b1, random-slope b2
sigma.b1.sq = 3; sigma.b2.sq = 8;
# V: random-intercept c1, random-slope c2
sigma.c1.sq = 6; sigma.c2.sq = 12;
# correlations between random-effects
corr.b1.c1 = .1; sigma.b1.c1 = corr.b1.c1*(sqrt(sigma.b1.sq)*(sqrt(sigma.c1.sq)))
corr.b1.b2 = .2; sigma.b1.b2 = corr.b1.b2*(sqrt(sigma.b1.sq)*(sqrt(sigma.b2.sq)))
corr.c1.c2 = .2; sigma.c1.c2 = corr.c1.c2*(sqrt(sigma.c1.sq)*(sqrt(sigma.c2.sq)))
corr.b1.c2 = .05; sigma.b1.c2 = corr.b1.c2*(sqrt(sigma.b1.sq)*(sqrt(sigma.c2.sq)))
corr.b2.c1 = .05; sigma.b2.c1 = corr.b2.c1*(sqrt(sigma.b2.sq)*(sqrt(sigma.c1.sq)))
corr.b2.c2 = .35; sigma.b2.c2 = corr.b2.c1*(sqrt(sigma.b2.sq)*(sqrt(sigma.c2.sq)))
# residual error term:
sigma.u.sq = 14; sigma.v.sq = 25
corr.u.v = .1; sigma.u.v = corr.u.v*sqrt(sigma.u.sq)*sqrt(sigma.v.sq)
# simulate multivariate longitudinal profile
U = V = matrix(0, n2, n1)
for (i in 1:n1) {
    b.i = mvrnorm(n = 1, mu = c(0,0,0,0), Sigma = matrix(c(
            sigma.b1.sq, sigma.b1.b2, sigma.b1.c1,  sigma.b1.c2,
            sigma.b1.b2, sigma.b2.sq, sigma.b2.c1,  sigma.b2.c2,
            sigma.b1.c1, sigma.b2.c1, sigma.c1.sq,  sigma.c1.c2,
            sigma.b1.c2, sigma.b2.c2, sigma.c1.c2,  sigma.c2.sq), nrow = 4, ncol = 4)) # correlated random effects
    for (j in 1:n2) {
        eps =  mvrnorm(n = 1, mu = c(0,0), Sigma = matrix(c(sigma.u.sq, sigma.u.v, sigma.u.v, sigma.v.sq), nrow=2,ncol=2))
        U[j,i] = 75 + (13 + b.i[2]) * j + b.i[1] + eps[1]
        V[j,i] = 50 + (2 + b.i[4]) * j + b.i[3] + eps[2]  ## fixed intercept and sloped effects + random-interecept + random-slope
        }
    }
data.mv = data.frame(subject = rep(seq(1,n1), each = n2, 2), y = c(as.vector(U), as.vector(V)),
            U.ind = rep( c(1,0), each = n1*n2), V.ind = rep( c(0,1), each = n1*n2), U.time = c(rep(seq(1:n2), n1), rep(0, n1*n2)), V.time = c(rep(0, n1*n2), rep(seq(1,n2), n1)))
data.mv$time = data.mv$U.time + data.mv$V.time
data.mv.grp = groupedData(y ~ time | subject, data = data.mv)

Sig.upper.left = sigma.u.sq*diag(n2); Sig.lower.right = sigma.v.sq*diag(n2)
Sig.off.diag = diag(n2)*sigma.u.v
Sig = rbind(cbind(Sig.upper.left, Sig.off.diag), cbind(Sig.off.diag, Sig.lower.right))
Sig.corr = cov2cor(Sig)

offdiag.to.vector = function(matrix) {
     n = nrow(matrix)
     vec = rep(0, (n - 1) * n / 2)
     pos = matrix(0, (n-1) * n / 2, 2)
     ind = 1
     for (i in (1:(n-1))) {
       for (j in ((i+1):n)) {
         vec[ind] = matrix[i, j]
         pos[ind, ] = c(i, j)
         ind = ind + 1
       }
     }
     list(vector = vec, position.mat = pos)
   }


On 8/19/09 10:29 AM, "Afshartous, David" <DAfshartous at med.miami.edu> wrote:



Fabian,

RE defining weights, see section 5.2.1 in Pinheiro & Bates (Mixed Effects Models in S and S-Plus).
RE correlation structures, see section 5.3.3.   While these sections are with respect to the univariate mixed model, note that the multivariate mixed model is analogous to the univariate mixed model that is stratified per some grouping such as say gender.  For instance, as far as the data structure goes, there is no difference if we have 2 variables on 10 subjects over time versus  1 variable on 10 subjects over time for males and females.   Of course, the different scenarios will most likely lead to different model assumptions.

While I haven't used the corrrelation = corSymm for a multivariate mixed model in nlme, I have used varIdent to specify different error variances for the different response variables in the multivariate setting.  Just set up your model as specified in the Doran & Lockwood reference below, and include weights = varIdent(form ~ weights = Ind), where Ind is an indicator variable that identifies each separate response variable. What I would like to do is have the error variances also correlated across the different response variables, but only when they are both measured at the same time point.  I'll check this out again and let you know if this and your structure is possible.

Although it's respect to SAS, a good reference that provides insight into the various assumptions in the multivariate mixed model and the resulting structure of the covariance matrices is:
On the use of PROC MIXED to Estimate Correlation in the Presence of Repeated Measures by Hamlett, Ryan, and Wolfinger (comes up via google)

Cheers,
David



On 8/18/09 7:14 AM, "Mollet, Fabian" <Fabian.Mollet at wur.nl> wrote:

Dear nlme expert



We need two pieces of information about the fitting of a nlme model which we cannot extract from the R help files and would be most grateful if you could help us. We fit an energy allocation growth model with 4 parameters to individual growth curves using the nlme routine. We thus have repeated age and size measurements of individuals and therefore allow for random individual effects (i.e. the data is grouped by individual).



1)      Because the sampling of these individuals was size stratified we have to account for the representation of the individual in the true size distribution by statistical weighting. The statistical weight would thus differ across individuals but be the same over the repeated measurements of each individual (to which the random effects apply) and should be somehow multiplied by the residuals of the repeated measurements of each individual. We guess we need to use the varClasses argument but it does not seem clear in the R help files to which level the statistical weights would apply. Could you please tell us how to define the statistical weights on the level of the random effects, i.e. on the level of the individual? varIdent?

2)      We furthermore want to analyze the results of the 4 estimated parameters over time using the lme routine and have thus now 1 row per individual (comprising of the 4 parameters, a time variable and others). Because the 4 parameters are correlated we intend to analyze this multivariate outcome by "flagging" the response by using a dummy coding for the 4 parameters and the time variable as is e.g. described in Doran and Lockwood (2006) p. 223-225 (resulting in 16 rows per individual). Since we want to follow the evolution of the correlation between the 4 parameters over time we would like to make no assumptions on the correlation structure of the errors. We guess we therefore have to use the correlation=corSymm argument. However, the same weighting would apply as in 1) above to the individual and we are therefore not sure again how to define the statistical weights in this case and what this would imply for the error correlation structure. Could you give us a guidance?



Your help is most appreciated and we thank you very much in advance!



Kind regards



Fabian Mollet





Doran, H. C. and Lockwood, J. R. 2006. Fitting value-added models in R. - Journal of Educational and Behavioral Statistics 31: 205-230.



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Aug 21 15:40:53 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Aug 2009 08:40:53 -0500
Subject: [R-sig-ME] Detecting duplicate random effects
In-Reply-To: <673e1b980908191208r45307c9dt951bc84d16020170@mail.gmail.com>
References: <673e1b980908191208r45307c9dt951bc84d16020170@mail.gmail.com>
Message-ID: <40e66e0b0908210640m34e6365ege0e926b0750b77a9@mail.gmail.com>

On Wed, Aug 19, 2009 at 2:08 PM, Jeroen Ooms<jeroenooms at gmail.com> wrote:
> I was running into a problem in parsing lme4 output, and it turned out
> that it was my own mistake (of course :) However, I think it was a
> mistate that could have been detected. I accidentally inserted a
> duplicate random effect term into the model. For example a user could
> try:
>
> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (Days|Subject), sleepstudy))
>
> This does not result in an error, lme4 will fit twice a random
> intercept for the Subject group. I cannot think of a situation in
> which this would be useful. Would it be an idea to throw an error in
> this situation?

> It can easily be detected by inspecting ranef(fm2),
> and noticing the (intercept) term exists twice in the $Subject group.

I can see the desirability of doing this but "easily" may be a bit of
an overstatement here.  It would definitely add a lot of code to the
functions that parse the random effects terms and generate the model
matrices, etc.  I can add it to the list of feature requests but I
doubt I will get to it soon.

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jeroenooms at gmail.com  Fri Aug 21 15:44:39 2009
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Fri, 21 Aug 2009 15:44:39 +0200
Subject: [R-sig-ME] Detecting duplicate random effects
In-Reply-To: <40e66e0b0908210640m34e6365ege0e926b0750b77a9@mail.gmail.com>
References: <673e1b980908191208r45307c9dt951bc84d16020170@mail.gmail.com> 
	<40e66e0b0908210640m34e6365ege0e926b0750b77a9@mail.gmail.com>
Message-ID: <673e1b980908210644x517987c5q8e2550d71fc2a1d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090821/ec6f7cff/attachment.pl>

From bates at stat.wisc.edu  Fri Aug 21 17:18:36 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Aug 2009 10:18:36 -0500
Subject: [R-sig-ME] corSymm, nlme issue
In-Reply-To: <C6B1BCE2.B399%dafshartous@med.miami.edu>
References: <C6B1BCE2.B399%dafshartous@med.miami.edu>
Message-ID: <40e66e0b0908210818u42d82b47i62a7f83005cb34cb@mail.gmail.com>

On Wed, Aug 19, 2009 at 1:29 PM, Afshartous,
David<DAfshartous at med.miami.edu> wrote:

> All,

> In the course of investigating yesterday's post by Fabian Mollet ([R-sig-ME]
> weighting nlme and multivariate outcomes), I've noticed an issue with
> corSymm. I am getting the error message below even for identical commands
> used from Pinheiro & Bates (p.235). ?Perhaps there was a discussion on this
> previously but I didn't see anything in the archives.

This is an issue of long standing in the nlme package.  In S and
S-PLUS we could define a generic function "initialize".  In R that
name is overridden in the methods package and redefining it would
break a lot of code (possibly not now that there are namespaces but we
didn't have namespaces at the time that nlme was ported to R).  For R
the name was changed to Initialize

>> sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-apple-darwin8.11.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> library("nlme")
>> cs1Symm = corSymm(value = c(.2, .1, -.1, 0, .2, 0), form = ~ 1 | Subject)
>> cs1Symm = initialize(cs1Symm, data = Orthodont)
> Error in getClass(Class) :
> ?c("\"corSymm\" is not a defined class", "\"corStruct\" is not a defined
> class")
> In addition: Warning message:
> In if (!is.na(match(Class, .BasicClasses))) return(newBasic(Class, ?:
> ?the condition has length > 1 and only the first element will be used
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tuteson at yahoo.com  Fri Aug 21 21:22:49 2009
From: tuteson at yahoo.com (Rafael Diaz)
Date: Fri, 21 Aug 2009 12:22:49 -0700 (PDT)
Subject: [R-sig-ME] data layout for crossed factors w/interaction in linear
	mix models
Message-ID: <517512.78957.qm@web50510.mail.re2.yahoo.com>

Dear All,

I am trying to fit a simple linear mixed model (see below
this paragraph) arising from a crossed factorial design with
2 factors and ubalanced number of replicates (from two to
five) in each cell, but I keep getting an error message (see
bottom of message).? The model is:
 
yijk = intercept + ai + bj + abij + ejik, where:
 
"intercept" is fixed, and the crosss factors, ai, i =
1,..,10, and bj, j= 1,..,10, are random.? I am
interested in estimating the variance components of these
factors AND their interaction.? I have tried:
 
fm1 <- lmer(formula = V1~1 + (1|V2) + (1|V3) + (1|V4),
data = 'datos') using two types of data layout for "datos":
 
1) using a matrix with 3 columns:

y     intercept   ai's  bj's  abij's 
y111  1           1     1     1 (1x1)
y112  1           1     1     " 
y121  1           1     2     2 (1x2)
y122  1           1     2     "
y123  1           1     2     "
y131  1           1     3     3 (1x3)
.     .           .     .     .
.     .           .     .     .
 


2) using the design matrix from? Y = XBeta +Zb.?
That is, using the same first two columns as above, but
substituting 1020 columns (10 for ai's, 10 for bj's and 100
for abij's) for the last three columns.
 
I get the message: "Error in eval(predvars, data, env) :
invalid envir argument"
 
Is my data layout mispecified? Do I need to input initial
values for the random components in order to get the REML
estimates?? I lmer valid for unbalanced designs?? Any help would be greatly appreciated.

Rafael Diaz
California State University Sacramento
Math and Stats
 
> 
> ? ? ? 
>







From bates at stat.wisc.edu  Fri Aug 21 23:01:58 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Aug 2009 16:01:58 -0500
Subject: [R-sig-ME] data layout for crossed factors w/interaction in
	linear mix models
In-Reply-To: <517512.78957.qm@web50510.mail.re2.yahoo.com>
References: <517512.78957.qm@web50510.mail.re2.yahoo.com>
Message-ID: <40e66e0b0908211401ka56876fme2877412a5a08ef6@mail.gmail.com>

On Fri, Aug 21, 2009 at 2:22 PM, Rafael Diaz<tuteson at yahoo.com> wrote:
> Dear All,

> I am trying to fit a simple linear mixed model (see below
> this paragraph) arising from a crossed factorial design with
> 2 factors and ubalanced number of replicates (from two to
> five) in each cell, but I keep getting an error message (see
> bottom of message).? The model is:

> yijk = intercept + ai + bj + abij + ejik, where:

> "intercept" is fixed, and the crosss factors, ai, i =
> 1,..,10, and bj, j= 1,..,10, are random.? I am
> interested in estimating the variance components of these
> factors AND their interaction.? I have tried:

> fm1 <- lmer(formula = V1~1 + (1|V2) + (1|V3) + (1|V4),
> data = 'datos') using two types of data layout for "

We will need more information before we can help you.  It is best if
you can make the data available in some form.  Otherwise, please
include the results of

library(lme4)
sessionInfo()
str(datos)
summary(datos)
fm1 <- lmer(V1 ~ 1 + (1|V2) + (1|V3) + (1|V4), datos)

and, if the error still occurs,

traceback()

> 1) using a matrix with 3 columns:
>
> y ? ? intercept ? ai's ?bj's ?abij's
> y111 ?1 ? ? ? ? ? 1 ? ? 1 ? ? 1 (1x1)
> y112 ?1 ? ? ? ? ? 1 ? ? 1 ? ? "
> y121 ?1 ? ? ? ? ? 1 ? ? 2 ? ? 2 (1x2)
> y122 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
> y123 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
> y131 ?1 ? ? ? ? ? 1 ? ? 3 ? ? 3 (1x3)
> . ? ? . ? ? ? ? ? . ? ? . ? ? .
> . ? ? . ? ? ? ? ? . ? ? . ? ? .
>
>
>
> 2) using the design matrix from? Y = XBeta +Zb.
> That is, using the same first two columns as above, but
> substituting 1020 columns (10 for ai's, 10 for bj's and 100
> for abij's) for the last three columns.
>
> I get the message: "Error in eval(predvars, data, env) :
> invalid envir argument"
>
> Is my data layout mispecified? Do I need to input initial
> values for the random components in order to get the REML
> estimates?? I lmer valid for unbalanced designs?? Any help would be greatly appreciated.
>
> Rafael Diaz
> California State University Sacramento
> Math and Stats
>
>>
>>
>>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From tuteson at yahoo.com  Fri Aug 21 23:59:15 2009
From: tuteson at yahoo.com (Rafael Diaz)
Date: Fri, 21 Aug 2009 14:59:15 -0700 (PDT)
Subject: [R-sig-ME] data layout for crossed factors w/interaction in
	linear mix models
Message-ID: <887077.71123.qm@web50501.mail.re2.yahoo.com>

Please find attached data files "datos1" and "datos2" containing the data layout as described in 1) and 2), respectively, in original email below.

Note: when opening "datos2" with Notepad, the columns get scrambled (this doesn't happen with "datos1"; however, both files open nicely in Wordpad. 

Thank you very much again,

Rafael Diaz 

--- On Fri, 8/21/09, Douglas Bates <bates at stat.wisc.edu> wrote:

> From: Douglas Bates <bates at stat.wisc.edu>
> Subject: Re: [R-sig-ME] data layout for crossed factors w/interaction in  linear mix models
> To: "Rafael Diaz" <tuteson at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Friday, August 21, 2009, 2:01 PM
> On Fri, Aug 21, 2009 at 2:22 PM,
> Rafael Diaz<tuteson at yahoo.com>
> wrote:
> > Dear All,
> 
> > I am trying to fit a simple linear mixed model (see
> below
> > this paragraph) arising from a crossed factorial
> design with
> > 2 factors and ubalanced number of replicates (from two
> to
> > five) in each cell, but I keep getting an error
> message (see
> > bottom of message).? The model is:
> 
> > yijk = intercept + ai + bj + abij + ejik, where:
> 
> > "intercept" is fixed, and the crosss factors, ai, i =
> > 1,..,10, and bj, j= 1,..,10, are random.? I am
> > interested in estimating the variance components of
> these
> > factors AND their interaction.? I have tried:
> 
> > fm1 <- lmer(formula = V1~1 + (1|V2) + (1|V3) +
> (1|V4),
> > data = 'datos') using two types of data layout for "
> 
> We will need more information before we can help you.?
> It is best if
> you can make the data available in some form.?
> Otherwise, please
> include the results of
> 
> library(lme4)
> sessionInfo()
> str(datos)
> summary(datos)
> fm1 <- lmer(V1 ~ 1 + (1|V2) + (1|V3) + (1|V4), datos)
> 
> and, if the error still occurs,
> 
> traceback()
> 
> > 1) using a matrix with 3 columns:
> >
> > y ? ? intercept ? ai's ?bj's ?abij's
> > y111 ?1 ? ? ? ? ? 1 ? ? 1 ? ? 1 (1x1)
> > y112 ?1 ? ? ? ? ? 1 ? ? 1 ? ? "
> > y121 ?1 ? ? ? ? ? 1 ? ? 2 ? ? 2 (1x2)
> > y122 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
> > y123 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
> > y131 ?1 ? ? ? ? ? 1 ? ? 3 ? ? 3 (1x3)
> > . ? ? . ? ? ? ? ? . ? ? . ? ? .
> > . ? ? . ? ? ? ? ? . ? ? . ? ? .
> >
> >
> >
> > 2) using the design matrix from? Y = XBeta +Zb.
> > That is, using the same first two columns as above,
> but
> > substituting 120 columns (10 for ai's, 10 for bj's
> and 100
> > for abij's) for the last three columns.
> >
> > I get the message: "Error in eval(predvars, data, env)
> :
> > invalid envir argument"
> >
> > Is my data layout mispecified? Do I need to input
> initial
> > values for the random components in order to get the
> REML
> > estimates?? I lmer valid for unbalanced designs??
> Any help would be greatly appreciated.
> >
> > Rafael Diaz
> > California State University Sacramento
> > Math and Stats
> >
> >>
> >>
> >>
> >
> >
> >
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: datos1.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090821/9c86f6cf/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: datos2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090821/9c86f6cf/attachment-0001.txt>

From bates at stat.wisc.edu  Sat Aug 22 15:45:05 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 22 Aug 2009 08:45:05 -0500
Subject: [R-sig-ME] data layout for crossed factors w/interaction in
	linear mix models
In-Reply-To: <887077.71123.qm@web50501.mail.re2.yahoo.com>
References: <887077.71123.qm@web50501.mail.re2.yahoo.com>
Message-ID: <40e66e0b0908220645p325a6a8etc1ac68747e35680f@mail.gmail.com>

On Fri, Aug 21, 2009 at 4:59 PM, Rafael Diaz<tuteson at yahoo.com> wrote:
> Please find attached data files "datos1" and "datos2" containing the data layout as described in 1) and 2), respectively, in original email below.

Thank you for sending the data.  I should have mentioned that only the
first form, "datos1", is needed.

> Note: when opening "datos2" with Notepad, the columns get scrambled (this doesn't happen with "datos1"; however, both files open nicely in Wordpad.

Thanks for the warning.  It happens that I never use Windows so it is
not an issue for me.

I did not have any problem with fitting the model.  I enclose a
modified form of the data as a csv file (suitable for reading with
read.csv) and a transcript of fitting the model.

> Thank you very much again,
>
> Rafael Diaz
>
> --- On Fri, 8/21/09, Douglas Bates <bates at stat.wisc.edu> wrote:
>
>> From: Douglas Bates <bates at stat.wisc.edu>
>> Subject: Re: [R-sig-ME] data layout for crossed factors w/interaction in ?linear mix models
>> To: "Rafael Diaz" <tuteson at yahoo.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Date: Friday, August 21, 2009, 2:01 PM
>> On Fri, Aug 21, 2009 at 2:22 PM,
>> Rafael Diaz<tuteson at yahoo.com>
>> wrote:
>> > Dear All,
>>
>> > I am trying to fit a simple linear mixed model (see
>> below
>> > this paragraph) arising from a crossed factorial
>> design with
>> > 2 factors and ubalanced number of replicates (from two
>> to
>> > five) in each cell, but I keep getting an error
>> message (see
>> > bottom of message).? The model is:
>>
>> > yijk = intercept + ai + bj + abij + ejik, where:
>>
>> > "intercept" is fixed, and the crosss factors, ai, i =
>> > 1,..,10, and bj, j= 1,..,10, are random.? I am
>> > interested in estimating the variance components of
>> these
>> > factors AND their interaction.? I have tried:
>>
>> > fm1 <- lmer(formula = V1~1 + (1|V2) + (1|V3) +
>> (1|V4),
>> > data = 'datos') using two types of data layout for "
>>
>> We will need more information before we can help you.
>> It is best if
>> you can make the data available in some form.
>> Otherwise, please
>> include the results of
>>
>> library(lme4)
>> sessionInfo()
>> str(datos)
>> summary(datos)
>> fm1 <- lmer(V1 ~ 1 + (1|V2) + (1|V3) + (1|V4), datos)
>>
>> and, if the error still occurs,
>>
>> traceback()
>>
>> > 1) using a matrix with 3 columns:
>> >
>> > y ? ? intercept ? ai's ?bj's ?abij's
>> > y111 ?1 ? ? ? ? ? 1 ? ? 1 ? ? 1 (1x1)
>> > y112 ?1 ? ? ? ? ? 1 ? ? 1 ? ? "
>> > y121 ?1 ? ? ? ? ? 1 ? ? 2 ? ? 2 (1x2)
>> > y122 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
>> > y123 ?1 ? ? ? ? ? 1 ? ? 2 ? ? "
>> > y131 ?1 ? ? ? ? ? 1 ? ? 3 ? ? 3 (1x3)
>> > . ? ? . ? ? ? ? ? . ? ? . ? ? .
>> > . ? ? . ? ? ? ? ? . ? ? . ? ? .
>> >
>> >
>> >
>> > 2) using the design matrix from? Y = XBeta +Zb.
>> > That is, using the same first two columns as above,
>> but
>> > substituting 120 columns (10 for ai's, 10 for bj's
>> and 100
>> > for abij's) for the last three columns.
>> >
>> > I get the message: "Error in eval(predvars, data, env)
>> :
>> > invalid envir argument"
>> >
>> > Is my data layout mispecified? Do I need to input
>> initial
>> > values for the random components in order to get the
>> REML
>> > estimates?? I lmer valid for unbalanced designs?
>> Any help would be greatly appreciated.
>> >
>> > Rafael Diaz
>> > California State University Sacramento
>> > Math and Stats
>> >
>> >>
>> >>
>> >>
>> >
>> >
>> >
>> >
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org
>> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>
>
>
-------------- next part --------------
options(show.signif.stars = FALSE)
library(lme4)
sessionInfo()
datos <- within(read.table("~/Desktop/datos1.txt",
                           col.names = c("y", "one", "A", "B", "AB")),
            {
                A <- factor(A)
                B <- factor(B)
                AB <- factor(A:B)
            })
str(datos)
summary(datos)
datos$one <- NULL
xtabs(~ A + B, datos)
print(fm1 <- lmer(y ~ (1|A) + (1|B) + (1|AB), datos))
-------------- next part --------------

R version 2.9.1 (2009-06-26)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> options(show.signif.stars = FALSE)
> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 contr.helmert,
	 contr.poly,
	 contr.SAS,
	 contr.sum,
	 contr.treatment,
	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

> sessionInfo()
R version 2.9.1 (2009-06-26) 
i486-pc-linux-gnu 

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-30 lattice_0.17-25   

loaded via a namespace (and not attached):
[1] grid_2.9.1
> datos <- within(read.table("~/Desktop/datos1.txt",
+                            col.names = c("y", "one", "A", "B", "AB")),
+             {
+                 A <- factor(A)
+                 B <- factor(B)
+                 AB <- factor(A:B)
+             })
> str(datos)
'data.frame':	301 obs. of  5 variables:
 $ y  : num  -0.324 -0.468 -0.152 -1.341 -0.79 ...
 $ one: num  1 1 1 1 1 1 1 1 1 1 ...
 $ A  : Factor w/ 10 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ B  : Factor w/ 10 levels "1","2","3","4",..: 1 1 1 2 2 3 3 3 4 4 ...
 $ AB : Factor w/ 100 levels "1:1","1:2","1:3",..: 1 1 1 2 2 3 3 3 4 4 ...
> summary(datos)
       y                one          A             B             AB     
 Min.   :-5.2603   Min.   :1   2      : 35   5      : 34   2:1    :  7  
 1st Qu.:-1.1330   1st Qu.:1   3      : 35   1      : 33   3:10   :  6  
 Median : 0.2585   Median :1   4      : 32   7      : 32   4:7    :  6  
 Mean   : 0.4048   Mean   :1   8      : 32   8      : 32   6:4    :  5  
 3rd Qu.: 1.9831   3rd Qu.:1   7      : 31   4      : 30   7:5    :  5  
 Max.   : 5.9446   Max.   :1   9      : 31   10     : 30   9:5    :  5  
                               (Other):105   (Other):110   (Other):267  
> datos$one <- NULL
> xtabs(~ A + B, datos)
    B
A    1 2 3 4 5 6 7 8 9 10
  1  3 2 3 3 4 2 3 2 2  3
  2  7 2 2 3 3 4 4 3 3  4
  3  3 2 4 2 4 3 3 4 4  6
  4  3 3 2 3 2 3 6 4 4  2
  5  2 3 3 3 2 4 4 2 2  2
  6  2 2 4 5 2 2 2 2 3  2
  7  3 2 2 4 5 2 3 4 2  4
  8  2 3 4 2 4 4 3 4 3  3
  9  4 3 3 3 5 2 2 5 2  2
  10 4 2 2 2 3 3 2 2 3  2
> print(fm1 <- lmer(y ~ (1|A) + (1|B) + (1|AB), datos))
Linear mixed model fit by REML 
Formula: y ~ (1 | A) + (1 | B) + (1 | AB) 
   Data: datos 
  AIC  BIC logLik deviance REMLdev
 1039 1058 -514.7     1030    1029
Random effects:
 Groups   Name        Variance Std.Dev.
 AB       (Intercept) 1.56560  1.25124 
 B        (Intercept) 1.69080  1.30031 
 A        (Intercept) 0.57243  0.75659 
 Residual             0.87333  0.93452 
Number of obs: 301, groups: AB, 100; B, 10; A, 10

Fixed effects:
            Estimate Std. Error t value
(Intercept)   0.4284     0.4951  0.8653
> 
> proc.time()
   user  system elapsed 
 11.268   0.108  11.448 

From davidwevans at hotmail.com  Sun Aug 23 02:19:25 2009
From: davidwevans at hotmail.com (David Evans)
Date: Sun, 23 Aug 2009 02:19:25 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 32, Issue 24
In-Reply-To: <mailman.7.1250762402.26281.r-sig-mixed-models@r-project.org>
References: <mailman.7.1250762402.26281.r-sig-mixed-models@r-project.org>
Message-ID: <COL0-DAV28D1C4E17109E56D501736A9FA0@phx.gbl>

Thanks for the help so far.  I'll look at mcmcglmm--a good idea, even  
though I was hoping to use R for my "quick" exploratory models before  
moving to WinBUGS.  "Quickly exploring" with mcmc makes me nervous.

David, would it be possible to help me with some references on using  
Gaussian errors for binary data which you mention below.  I've read  
the Paper by Cheung, A modified least-squares regression approach to  
the estimation of risk difference, AJE 2007, 166:1337-1344 but was  
hoping to find some more on this.  In particular, any references which  
say Gaussian errors are acceptable in mixed models would be most  
appreciated (I have an outcome prevalence in the 0.2's).

Thanks again.

David.

P.S. Judging by the responses I've received, I can see Australia is  
not on holidays at the moment, unlike the Northern Hemisphere!

Le 20 ao?t 09 ? 12:00, r-sig-mixed-models-request at r-project.org a  
?crit :

> Finally,
> there is some literature suggesting that the Gaussian LMM for binary  
> data
> might not be too bad, especially if the probabilities are all >0.05.



From julie.bertrand at inserm.fr  Sun Aug 23 11:41:32 2009
From: julie.bertrand at inserm.fr (Julie Bertrand)
Date: Sun, 23 Aug 2009 11:41:32 +0200
Subject: [R-sig-ME] trouble using the lmer function
Message-ID: <4A910ECC.9030505@inserm.fr>

Dear All,

I meet trouble using the lmer function on a data set simulated with a 
gamma Emax Model.

I use the following code, where initial conditions are set to the true 
values :
GammaEmaxmodel<-function(D,lE0,lE50,lEmax,lHill)exp(lE0)+exp(lEmax)*D^exp(lHill)/(exp(lE50)^exp(lHill)+D^exp(lHill))
grMod <- deriv(body(GammaEmaxmodel), namevec = 
c("lE0","lE50","lEmax","lHill"), func = GammaEmaxmodel)

fit.lme4<-nlmer(DV~grMod(DOSE,lE0,lE50,lEmax,lHill)~(lE0+lEmax+lE50)|ID,#
        donnees,
        start = c(lE0=log(5),lE50=log(500),lEmax=log(30),lHill=log(2))
        )
and obtain the error message : "Erreur dans asMethod(object) : matrix is 
not symmetric [1,2]"

I am on Windows XP, with R version 2.9.1 (2009-06-26) and lme4_0.999375-31.
 
When I do not try to estimate the Hill parameter I obtain no error message :
 > 
GammaEmaxmodel<-function(D,lE0,lE50,lEmax)exp(lE0)+exp(lEmax)*D/(exp(lE50)+D)
 > grMod <- deriv(body(GammaEmaxmodel), namevec = 
c("lE0","lE50","lEmax"), func = GammaEmaxmodel)
 >
 >
 > fit.lme4<-nlmer(DV~grMod(DOSE,lE0,lE50,lEmax)~(lE0+lEmax+lE50)|ID,#
+ donnees,
+ start = c(lE0=log(5),lE50=log(500),lEmax=log(30))
+ )
 > fit.lme4
Nonlinear mixed model fit by the Laplace approximation
Formula: DV ~ grMod(DOSE, lE0, lE50, lEmax) ~ (lE0 + lEmax + lE50) | ID
   Data: donnees
  AIC  BIC logLik deviance
 2235 2273  -1107     2215
Random effects:
 Groups   Name  Variance Std.Dev. Corr         
 ID       lE0    1.7172  1.3104                
          lEmax 18.8214  4.3384   -0.171       
          lE50  27.4499  5.2393   -0.128  0.954
 Residual        4.2807  2.0690                
Number of obs: 324, groups: ID, 81

Fixed effects:
      Estimate Std. Error t value
lE0     1.2769     0.1591   8.024
lE50    7.9102     0.6817  11.603
lEmax   4.6933     0.5867   7.999

Correlation of Fixed Effects:
      lE0    lE50 
lE50  -0.058      
lEmax -0.098  0.962

Further, I succeed in estimating the Hill parameter using the nlme 
function (nlme_3.1-93) :

 > fit.nlme2<-nlme(DV~GammaEmaxmodel(DOSE,lE0,lE50,lEmax,lHill),
+ data=dat,
+ fixed=lE0+lEmax+lE50+lHill~1,
+ random=lE0+lEmax+lE50~1,
+             start = 
c(lE0=log(5),lE50=log(500),lEmax=log(30),lHill=log(2)),
+ weights=NULL
+      )
 > fit.nlme2
Nonlinear mixed-effects model fit by maximum likelihood
  Model: DV ~ GammaEmaxmodel(DOSE, lE0, lE50, lEmax, lHill)
  Data: dat
  Log-likelihood: -1007.409
  Fixed: lE0 + lEmax + lE50 + lHill ~ 1
      lE0     lEmax      lE50     lHill
1.4964002 3.2601144 6.0436652 0.4885341

Random effects:
 Formula: list(lE0 ~ 1, lEmax ~ 1, lE50 ~ 1)
 Level: ID
 Structure: General positive-definite, Log-Cholesky parametrization
         StdDev       Corr     
lE0      7.642895e-02 lE0  lEmax
lEmax    5.686393e-01 1.00     
lE50     3.690756e-05 0.01 0.01
Residual 3.906402e+00          

Number of Observations: 324
Number of Groups: 81

The data are simulated with Hill=2, please find enclose the data set 
that leads to these outputs (simdat.txt).
I also simulated a correlation between the lEmax and lE50 parameters 
however I coul not figure out how to code such a random effects matrix 
in lmer.

The first error message is due to lmer trouble in estimating the Hill 
parameter on this data set, or must I change something in my code or 
data set ?

Thank you in advance.

Julie Bertrand

-- 
UMR 738, INSERM, Universit? Paris Diderot



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: simdat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090823/606ca783/attachment.txt>

From ken at kjbeath.com.au  Mon Aug 24 02:00:49 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Mon, 24 Aug 2009 00:00:49 -0000 (GMT)
Subject: [R-sig-ME] trouble using the lmer function
In-Reply-To: <4A910ECC.9030505@inserm.fr>
References: <4A910ECC.9030505@inserm.fr>
Message-ID: <1893.137.111.57.71.1251072049.squirrel@65.99.229.10>

The problem is in the calculation of the derivatives, this

grMod(donnees$DOSE,log(5),log(500),log(30),log(2))

will show that some are NaN. It probably means that underflow has resulted
in a 0/0 in the gradient formula.

Ken

On Sun, August 23, 2009 9:41 am, Julie Bertrand wrote:
> Dear All,
>
> I meet trouble using the lmer function on a data set simulated with a
> gamma Emax Model.
>
> I use the following code, where initial conditions are set to the true
> values :
> GammaEmaxmodel<-function(D,lE0,lE50,lEmax,lHill)exp(lE0)+exp(lEmax)*D^exp(lHill)/(exp(lE50)^exp(lHill)+D^exp(lHill))
> grMod <- deriv(body(GammaEmaxmodel), namevec =
> c("lE0","lE50","lEmax","lHill"), func = GammaEmaxmodel)
>
> fit.lme4<-nlmer(DV~grMod(DOSE,lE0,lE50,lEmax,lHill)~(lE0+lEmax+lE50)|ID,#
>         donnees,
>         start = c(lE0=log(5),lE50=log(500),lEmax=log(30),lHill=log(2))
>         )
> and obtain the error message : "Erreur dans asMethod(object) : matrix is
> not symmetric [1,2]"
>
> I am on Windows XP, with R version 2.9.1 (2009-06-26) and
> lme4_0.999375-31.
>
> When I do not try to estimate the Hill parameter I obtain no error message
> :
>  >
> GammaEmaxmodel<-function(D,lE0,lE50,lEmax)exp(lE0)+exp(lEmax)*D/(exp(lE50)+D)
>  > grMod <- deriv(body(GammaEmaxmodel), namevec =
> c("lE0","lE50","lEmax"), func = GammaEmaxmodel)
>  >
>  >
>  > fit.lme4<-nlmer(DV~grMod(DOSE,lE0,lE50,lEmax)~(lE0+lEmax+lE50)|ID,#
> + donnees,
> + start = c(lE0=log(5),lE50=log(500),lEmax=log(30))
> + )
>  > fit.lme4
> Nonlinear mixed model fit by the Laplace approximation
> Formula: DV ~ grMod(DOSE, lE0, lE50, lEmax) ~ (lE0 + lEmax + lE50) | ID
>    Data: donnees
>   AIC  BIC logLik deviance
>  2235 2273  -1107     2215
> Random effects:
>  Groups   Name  Variance Std.Dev. Corr
>  ID       lE0    1.7172  1.3104
>           lEmax 18.8214  4.3384   -0.171
>           lE50  27.4499  5.2393   -0.128  0.954
>  Residual        4.2807  2.0690
> Number of obs: 324, groups: ID, 81
>
> Fixed effects:
>       Estimate Std. Error t value
> lE0     1.2769     0.1591   8.024
> lE50    7.9102     0.6817  11.603
> lEmax   4.6933     0.5867   7.999
>
> Correlation of Fixed Effects:
>       lE0    lE50
> lE50  -0.058
> lEmax -0.098  0.962
>
> Further, I succeed in estimating the Hill parameter using the nlme
> function (nlme_3.1-93) :
>
>  > fit.nlme2<-nlme(DV~GammaEmaxmodel(DOSE,lE0,lE50,lEmax,lHill),
> + data=dat,
> + fixed=lE0+lEmax+lE50+lHill~1,
> + random=lE0+lEmax+lE50~1,
> +             start =
> c(lE0=log(5),lE50=log(500),lEmax=log(30),lHill=log(2)),
> + weights=NULL
> +      )
>  > fit.nlme2
> Nonlinear mixed-effects model fit by maximum likelihood
>   Model: DV ~ GammaEmaxmodel(DOSE, lE0, lE50, lEmax, lHill)
>   Data: dat
>   Log-likelihood: -1007.409
>   Fixed: lE0 + lEmax + lE50 + lHill ~ 1
>       lE0     lEmax      lE50     lHill
> 1.4964002 3.2601144 6.0436652 0.4885341
>
> Random effects:
>  Formula: list(lE0 ~ 1, lEmax ~ 1, lE50 ~ 1)
>  Level: ID
>  Structure: General positive-definite, Log-Cholesky parametrization
>          StdDev       Corr
> lE0      7.642895e-02 lE0  lEmax
> lEmax    5.686393e-01 1.00
> lE50     3.690756e-05 0.01 0.01
> Residual 3.906402e+00
>
> Number of Observations: 324
> Number of Groups: 81
>
> The data are simulated with Hill=2, please find enclose the data set
> that leads to these outputs (simdat.txt).
> I also simulated a correlation between the lEmax and lE50 parameters
> however I coul not figure out how to code such a random effects matrix
> in lmer.
>
> The first error message is due to lmer trouble in estimating the Hill
> parameter on this data set, or must I change something in my code or
> data set ?
>
> Thank you in advance.
>
> Julie Bertrand
>
> --
> UMR 738, INSERM, Universit? Paris Diderot
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From m.fairbrother at bristol.ac.uk  Mon Aug 24 14:03:54 2009
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 24 Aug 2009 13:03:54 +0100
Subject: [R-sig-ME] Correlation of Fixed Effects in repeated cross-sectional
	data
Message-ID: <9A41737C-D00E-41B4-A77D-490D5B9E91A7@bristol.ac.uk>

Dear mixed modellers,

I am trying to use lmer to estimate a model with binary individual  
responses (N=27899, from repeated cross-sectional data) nested within  
state-years (N=748), in turn nested in states (N=49)--and potentially  
also in years (N=20). My independent variable of greatest interest  
("stateyearX") varies both across states and within them over time,  
and for most states it is trending upward over the period of study.

My issue is the value I'm getting for the correlation between the  
stateyearX and Intercept Fixed Effects (see below). This holds true  
irrespective of whether or not I interact stateyearX with time,  
whether or not I include year as an additional level, and whether or  
not I add other covariates (at various levels).

This value seems alarmingly high... and I'm not really sure how to  
interpret it. Can anyone advise me on whether I'm doing something  
wrong and/or what to do instead? What is this value telling me about  
the relationship between the overall (not random?) Intercept and the  
estimate I'm getting for stateyearX?

Sorry if this is ignorant. This is my first ever post here--thanks  
very much for the package, and for all the great information already  
in the archives.

Any help on this gratefully received.
- Malcolm


Malcolm Fairbrother
School of Geographical Sciences
University of Bristol



 > (wm96k <- lmer(Y ~ stateyearX + time + (1 | stateyear) + (1 |  
state), family=binomial(link="logit"), data=tdat))
Generalized linear mixed model fit by the Laplace approximation
Formula: Y ~ stateyearX + time + (1 | stateyear) + (1 | state)
    Data: tdat
    AIC   BIC logLik deviance
  36650 36691 -18320    36640
Random effects:
  Groups    Name        Variance Std.Dev.
  stateyear (Intercept) 0.043609 0.20883
  state     (Intercept) 0.132090 0.36344
Number of obs: 27899, groups: stateyear, 748; state, 49

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)  0.773340   0.461232   1.677   0.0936 .
stateyearX  -2.661767   1.287316  -2.068   0.0387 *
time        -0.008745   0.003642  -2.401   0.0163 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) sttyrX
stateyearX -0.990
time        0.832 -0.871


 > sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-31   Matrix_0.999375-30 lattice_0.17-25     
foreign_0.8-37

loaded via a namespace (and not attached):
[1] grid_2.9.1  tools_2.9.1


From David.Duffy at qimr.edu.au  Tue Aug 25 10:06:19 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 25 Aug 2009 18:06:19 +1000 (EST)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 32, Issue 24
In-Reply-To: <COL0-DAV28D1C4E17109E56D501736A9FA0@phx.gbl>
References: <mailman.7.1250762402.26281.r-sig-mixed-models@r-project.org>
	<COL0-DAV28D1C4E17109E56D501736A9FA0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0908251621310.11914@orpheus.qimr.edu.au>

On Sun, 23 Aug 2009, David Evans wrote:

>
> David, would it be possible to help me with some references on using 
> Gaussian errors for binary data which you mention below.  I've read the 
> Paper by Cheung, A modified least-squares regression approach to the 
> estimation of risk difference, AJE 2007, 166:1337-1344 but was hoping to 
> find some more on this.  In particular, any references which say 
> Gaussian errors are acceptable in mixed models would be most appreciated 
> (I have an outcome prevalence in the 0.2's).
>

A couple of reviews defending the general idea ;):

Harvey WR (1982). Least-squares analysis of discrete data. J Anim Sci 
54:1067-1071

http://jas.fass.org/cgi/reprint/54/5/1067

And also

Ch 17 in Gianola and Hammond Advances in Statistical Methods for
Genetic Improvement of Livestock.

The latter suggests:

V. Guiard, G. Herrend ??rfer, A. Tuchscherer (1985).  Variance Component
Estimation for Dichotomous Characters and Its Use for Estimating
Heritability. Biometric J 27: 653-658.

The heritability is the proportion of variance due to genetic random
effects.

A couple of genetics example I am aware of, where simulation finds that
the linear model gives similar answers to a GLMM or similar:

Visscher PM, Haley CS, Knott SA (1996). Mapping QTLs for binary traits
in backcross and F2 populations. Genetical Research 68(1):55-63.

http://genepi.qimr.edu.au/contents/p/staff/CVPV020.pdf

Zeegers MP, Rice JP, Rijsdijk FV, Abecasis GR and Sham PC (2003).
Regression-based sib pair linkage analysis for binary traits.
Hum Hered 55:125-31


There are many other applications of the approach in the animal 
breeding literature for heritability estimation.

But I'm afraid these merely support the approach in general - they
haven't usually applied a standard program like lme()/lmer(), but I
think one can argue that the same analysis of variance machinery is
being used.  The literature on binary intraclass/interclass correlations
in cluster sampling etc (Landis and Koch onwards) is also relevant.

Maybe also:

Lunney GH (2005).  Using analysis of variance with a dichotomous
dependent variable: an empirical study. J Educ Meas 7:263-269.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From DAfshartous at med.miami.edu  Thu Aug 27 16:44:50 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Thu, 27 Aug 2009 10:44:50 -0400
Subject: [R-sig-ME] VarIdent, extracting delta value
Message-ID: <C6BC1422.B4C2%dafshartous@med.miami.edu>


All, 

When using varIdent to specify different residual error variance per strata,
one obtains the ratio between the standard deviations of the strata (see P&B
p.211), and this is included in the summary output.  However, perhaps I'm
missing something extremely basic but I don't see where this is within
str((summary(m1)) for a given model and hence cannot extract it. A
workaround is below, but if anyone knows the direct method please advise.

Cheers,
David


Library("nlme")
 m1 = lme(distance ~ age, random = ~ 1 | Subject, weights = varIdent(form =
~ 1 | Sex), data = Orthodont)
summary(m1)
## shows that delta = 0.4533690
##
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | Sex 
 Parameter estimates:
     Male    Female
1.0000000 0.4533690

## 
str(summary(m1)) 

## workaround:
 1/attr(m1$modelStruct[[2]], "weights")[100]
   Female 
0.4533690 





######################################################
> sessionInfo()
R version 2.9.1 (2009-06-26)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-92     lattice_0.17-25

loaded via a namespace (and not attached):
[1] grid_2.9.1         lme4_0.999375-31   Matrix_0.999375-29
> 



From P.Dalgaard at biostat.ku.dk  Thu Aug 27 17:02:30 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 27 Aug 2009 17:02:30 +0200
Subject: [R-sig-ME] VarIdent, extracting delta value
In-Reply-To: <C6BC1422.B4C2%dafshartous@med.miami.edu>
References: <C6BC1422.B4C2%dafshartous@med.miami.edu>
Message-ID: <4A96A006.30808@biostat.ku.dk>

Afshartous, David wrote:
> All, 
> 
> When using varIdent to specify different residual error variance per strata,
> one obtains the ratio between the standard deviations of the strata (see P&B
> p.211), and this is included in the summary output.  However, perhaps I'm
> missing something extremely basic but I don't see where this is within
> str((summary(m1)) for a given model and hence cannot extract it. A
> workaround is below, but if anyone knows the direct method please advise.
> 
> Cheers,
> David
> 
> 
> Library("nlme")
>  m1 = lme(distance ~ age, random = ~ 1 | Subject, weights = varIdent(form =
> ~ 1 | Sex), data = Orthodont)
> summary(m1)
> ## shows that delta = 0.4533690
> ##
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | Sex 
>  Parameter estimates:
>      Male    Female
> 1.0000000 0.4533690
> 
> ## 
> str(summary(m1)) 
> 
> ## workaround:
>  1/attr(m1$modelStruct[[2]], "weights")[100]
>    Female 
> 0.4533690 
>

I think the canonical way is

> exp(c(summary(m1)$modelStruct$varStruct))
[1] 0.4533690

or

> coef(m1$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
     Male    Female
1.0000000 0.4533690

I'm not really sure that there is not a neater way of drilling down to

m1$modelStruct$varStruct

or summary(m1)$...


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From raterwil at gmail.com  Fri Aug 28 21:26:33 2009
From: raterwil at gmail.com (Robert Terwilliger)
Date: Fri, 28 Aug 2009 15:26:33 -0400
Subject: [R-sig-ME] longitudinal analysis using lmer?
Message-ID: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>

Dear R mixed effects gurus,

I have the following data below. Attached is a png graphic
representing the data.

I would like to run the following analysis:

signal ~ age | subject.

For your information (not statically relevant), the "signal" variable
is from a functional MRI experiment.

At issue is whether this analysis is valid using "lme". From the graph
(and the table below), one can see that there are five subjects.
However, each subject begins at a different age. Subject 1 begins at 8
and goes to 12, while subject 5 begins at 14. From my study of
longitudinal analysis, usually each subject begins at the same
starting point, while these data have subjects beginning at different
starting points (different ages).

Any insight is appreciated.

subject	age	signal
1	8	0.108
1	9	0.139
1      10    NA
1	11	0.151
1	12	0.148
2	10	0.127
2      11    NA
2	12	0.135
2	13	0.146
3	9	0.105
3	10	0.123
3	11	0.134
3	12	0.151
3	13	0.145
4	12	0.130
4	13	0.169
4	14	0.146
4	15	0.174
5	14	0.158
5	15	0.141
5	16	0.178
5      17    NA
5	18	0.172

Regards,

--
Robert Terwilliger
Physicist
Laboratory of Neurocognitive Development
Western Psychiatric Institute and Clinic
University of Pittsburgh Medical Center
Loeffler Building
121 Meyran Avenue ?#114
Pittsburgh, PA 15213
412.383.8174 ?- Office
412.383.8179 - Fax
em: raterwil at gmail.com
http://www.wpic.pitt.edu/research/lncd/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: longitudinal_graph.png
Type: image/png
Size: 88580 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090828/34edcc11/attachment.png>

From raterwil at gmail.com  Fri Aug 28 22:07:59 2009
From: raterwil at gmail.com (Robert Terwilliger)
Date: Fri, 28 Aug 2009 16:07:59 -0400
Subject: [R-sig-ME] longitudinal analysis using lmer?
In-Reply-To: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>
References: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>
Message-ID: <e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>

One more thing........

What i sent was only a small sample of the data, just for the purpose
of showing what kind of set we have.

We have about 150 subjects, with starting ages between 8 and 21, with
3-5 data points (yearly visits) per subject.

Thanks,

--
Robert Terwilliger
Physicist
Laboratory of Neurocognitive Development
Western Psychiatric Institute and Clinic
University of Pittsburgh Medical Center
Loeffler Building
121 Meyran Avenue  #114
Pittsburgh, PA 15213
412.383.8174  - Office
412.383.8179 - Fax
em: raterwil at gmail.com
http://www.wpic.pitt.edu/research/lncd/

*******************************************************
Dear R mixed effects gurus,

I have the following data below. Attached is a png graphic
representing the data.

I would like to run the following analysis:

signal ~ age | subject.

For your information (not statically relevant), the "signal" variable
is from a functional MRI experiment.

At issue is whether this analysis is valid using "lme". From the graph
(and the table below), one can see that there are five subjects.
However, each subject begins at a different age. Subject 1 begins at 8
and goes to 12, while subject 5 begins at 14. From my study of
longitudinal analysis, usually each subject begins at the same
starting point, while these data have subjects beginning at different
starting points (different ages).

Any insight is appreciated.

subject age     signal
1       8       0.108
1       9       0.139
1      10    NA
1       11      0.151
1       12      0.148
2       10      0.127
2      11    NA
2       12      0.135
2       13      0.146
3       9       0.105
3       10      0.123
3       11      0.134
3       12      0.151
3       13      0.145
4       12      0.130
4       13      0.169
4       14      0.146
4       15      0.174
5       14      0.158
5       15      0.141
5       16      0.178
5      17    NA
5       18      0.172



From highstat at highstat.com  Fri Aug 28 22:12:38 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Fri, 28 Aug 2009 22:12:38 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 32, Issue 32
In-Reply-To: <mailman.588.1251487614.4323.r-sig-mixed-models@r-project.org>
References: <mailman.588.1251487614.4323.r-sig-mixed-models@r-project.org>
Message-ID: <4A983A36.70805@highstat.com>

r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. longitudinal analysis using lmer? (Robert Terwilliger)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 28 Aug 2009 15:26:33 -0400
> From: Robert Terwilliger <raterwil at gmail.com>
> Subject: [R-sig-ME] longitudinal analysis using lmer?
> To: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<e837fef90908281226j6e7dd590p9c5249a58156429e at mail.gmail.com>
> Content-Type: text/plain; charset="iso-8859-1"
>
> Dear R mixed effects gurus,
>
> I have the following data below. Attached is a png graphic
> representing the data.
>
> I would like to run the following analysis:
>
> signal ~ age | subject.
>
> For your information (not statically relevant), the "signal" variable
> is from a functional MRI experiment.
>
> At issue is whether this analysis is valid using "lme". From the graph
> (and the table below), one can see that there are five subjects.
> However, each subject begins at a different age. Subject 1 begins at 8
> and goes to 12, while subject 5 begins at 14. From my study of
> longitudinal analysis, usually each subject begins at the same
> starting point, while these data have subjects beginning at different
> starting points (different ages).
>   

Robert..
What exactly do you have in mind with "valid using lme"? I assume age as 
covariate and subject as random intercept? Using subject as random 
effect would impose the compound correlation structure, and starting 
time is irrelevant in that case. But you would basically assume that the 
correlation  between observations of age 8-12 is the same as between 
12-18. Unless you mess around with random intercept and slope models. 
The other thing is that 5 subjects is on the low side, especially for 
random intercept and slope models. Better get more subjects!

Alain

>
>   


-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From ken at kjbeath.com.au  Sat Aug 29 01:07:53 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Sat, 29 Aug 2009 09:07:53 +1000
Subject: [R-sig-ME] longitudinal analysis using lmer?
In-Reply-To: <e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>
References: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>
	<e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>
Message-ID: <A8B693D3-9C3A-41FB-8A1A-B71D18A86E3B@kjbeath.com.au>

On 29/08/2009, at 6:07 AM, Robert Terwilliger wrote:

> One more thing........
>
> What i sent was only a small sample of the data, just for the purpose
> of showing what kind of set we have.
>
> We have about 150 subjects, with starting ages between 8 and 21, with
> 3-5 data points (yearly visits) per subject.
>

This will be fine, although it isn't as good as having a smaller  
number of complete series. One point is that they don't look  
completely linear, so a polynomial (maybe quadratic) or regression  
spline may be a better option. Judging by the scatter the random  
effect variance will probably be close to zero.

Ken




> Thanks,
>
> --
> Robert Terwilliger
> Physicist
> Laboratory of Neurocognitive Development
> Western Psychiatric Institute and Clinic
> University of Pittsburgh Medical Center
> Loeffler Building
> 121 Meyran Avenue  #114
> Pittsburgh, PA 15213
> 412.383.8174  - Office
> 412.383.8179 - Fax
> em: raterwil at gmail.com
> http://www.wpic.pitt.edu/research/lncd/
>
> *******************************************************
> Dear R mixed effects gurus,
>
> I have the following data below. Attached is a png graphic
> representing the data.
>
> I would like to run the following analysis:
>
> signal ~ age | subject.
>
> For your information (not statically relevant), the "signal" variable
> is from a functional MRI experiment.
>
> At issue is whether this analysis is valid using "lme". From the graph
> (and the table below), one can see that there are five subjects.
> However, each subject begins at a different age. Subject 1 begins at 8
> and goes to 12, while subject 5 begins at 14. From my study of
> longitudinal analysis, usually each subject begins at the same
> starting point, while these data have subjects beginning at different
> starting points (different ages).
>
> Any insight is appreciated.
>
> subject age     signal
> 1       8       0.108
> 1       9       0.139
> 1      10    NA
> 1       11      0.151
> 1       12      0.148
> 2       10      0.127
> 2      11    NA
> 2       12      0.135
> 2       13      0.146
> 3       9       0.105
> 3       10      0.123
> 3       11      0.134
> 3       12      0.151
> 3       13      0.145
> 4       12      0.130
> 4       13      0.169
> 4       14      0.146
> 4       15      0.174
> 5       14      0.158
> 5       15      0.141
> 5       16      0.178
> 5      17    NA
> 5       18      0.172
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From grahamleask at btinternet.com  Sat Aug 29 14:33:06 2009
From: grahamleask at btinternet.com (Graham Leask)
Date: Sat, 29 Aug 2009 13:33:06 +0100
Subject: [R-sig-ME] How many groups is enough?
Message-ID: <000001ca28a4$dff56770$9fe03650$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090829/1fc18371/attachment.pl>

From highstat at highstat.com  Sun Aug 30 13:53:27 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Sun, 30 Aug 2009 12:53:27 +0100
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
Message-ID: <4A9A6837.8030104@highstat.com>


>
> Alain Zuur's response to a recent posting raises an interesting question. To
> use a random effects model what number
>
> of groups is actually sufficient?
>
>  
>
> I have heard talk of a minimum of 20 groups but have seen numerous examples
> in books and published papers with
>
> much less than this. Is there a definitive reference on this?
>
>   

Graham,

Actually..it turned out that the data set for which the question was 
asked, had about 350 subjects I believe.

But anyway....that is not your question. In general you see the magic 
"5" in some textbooks.....but for what it is worth...I recently had to 
program a ZIP for 2-way nested data in RBugs..and in order to do this, I 
started with 1-way and 2-way GLMMs (just to build up the code). And to 
check whether my code was "correct", I compared the results with that of 
3-4 R packages (e.g. glmmPQL, lmer, glmml).  The data set consisted of 
multiple observations per animal, for 5-30 animals per colony, and 9 
colonies. I noticed that the estimated values for the variance for the 
random intercept colony differed a lot between these packages. But all 
came with similar estimates for the animal-within-colony random intercept.

Not that it tells you that much (all packages giving the same result 
doesn't mean it is correct)....but it is a bit worrying. Perhaps a 
simulation study gives you a better answer. The data I use(d) are highly 
unbalanced..so that may have played a role as well.

Alain





-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From kingsfordjones at gmail.com  Mon Aug 31 00:00:34 2009
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Sun, 30 Aug 2009 16:00:34 -0600
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <4A9A6837.8030104@highstat.com>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
	<4A9A6837.8030104@highstat.com>
Message-ID: <2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>

Here are some thoughts, which are just conjecture (caveat emptor).
I'd be interested in hearing contrary facts or opinion.

Because of the flexibility of mixed models I think it's hard to come
up with rules of thumb here. To examine the various scenarios,
simulations would need to look at effects of number of groups, number
of observations within groups and the balance of those observations
between groups, error variance, group variance, ratio of error and
group variances, number of levels, types of random slopes, random
effects covariance structure, error covariance structure, fixed
effects structure, etc...  Clearly permutations of the above could
lead to an awful lot of simulations, not to mention what happens when
you move away from normal errors and work with GLMMs.

My guess is that in general, for small numbers of groups (or just
small between group variance?) the sampling distribution of the
between group variance will have a long right tail and large spread.
Because the REML estimates are unbiased this would imply that when you
have few groups the majority (and perhaps a large majority) of the
estimates will be low, while some will be very high.

So the question remains: "what is a 'small' number of groups?".  I'm
not sure but the following may be suggestive, at least of the symmetry
of the sampling distribution (i.e. chi sq w/ df = # groups - 1):

ngroups <- c(4, 6, 10, 15, 20)
plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
for (i in ngroups) {
  plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
}


Also, googling turned up the paper below, which for a sub-class of
mixed models suggests that >=50 groups is sufficient to get
group-level variances and standard errors that are unbiased (but not
necessarily low-variance, AFAICS).

@article{maas2005sufficient,
  title={{Sufficient sample sizes for multilevel modeling}},
  author={Maas, C.J.M. and Hox, J.J.},
  journal={Methodology},
  volume={1},
  number={3},
  pages={86--92},
  year={2005}
  abstract={An important problem in multilevel modeling is what
constitutes a sufficient sample size for accurate estimation. In
multilevel analysis, the major restriction is often the higher-level
sample size. In this paper, a simulation study is used to determine
the influence of different sample sizes at the group level on the
accuracy of the estimates (regression coefficients and variances)
and their standard errors. In addition, the influence of other
factors, such as the lowest-level sample size and different variance
distributions between the levels (different intraclass correlations),
is examined. The results show that only a small sample size
at level two (meaning a sample of 50 or less) leads to biased
estimates of the second-level standard errors. In all of the other
simulated conditions the estimates of the regression coefficients, the
variance components, and the standard errors are unbiased
and accurate.}
}


hth,

Kingsford Jones




On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
Ltd.<highstat at highstat.com> wrote:
>
>>
>> Alain Zuur's response to a recent posting raises an interesting question.
>> To
>> use a random effects model what number
>>
>> of groups is actually sufficient?
>>
>>
>> I have heard talk of a minimum of 20 groups but have seen numerous
>> examples
>> in books and published papers with
>>
>> much less than this. Is there a definitive reference on this?
>>
>>
>
> Graham,
>
> Actually..it turned out that the data set for which the question was asked,
> had about 350 subjects I believe.
>
> But anyway....that is not your question. In general you see the magic "5" in
> some textbooks.....but for what it is worth...I recently had to program a
> ZIP for 2-way nested data in RBugs..and in order to do this, I started with
> 1-way and 2-way GLMMs (just to build up the code). And to check whether my
> code was "correct", I compared the results with that of 3-4 R packages (e.g.
> glmmPQL, lmer, glmml). ?The data set consisted of multiple observations per
> animal, for 5-30 animals per colony, and 9 colonies. I noticed that the
> estimated values for the variance for the random intercept colony differed a
> lot between these packages. But all came with similar estimates for the
> animal-within-colony random intercept.
>
> Not that it tells you that much (all packages giving the same result doesn't
> mean it is correct)....but it is a bit worrying. Perhaps a simulation study
> gives you a better answer. The data I use(d) are highly unbalanced..so that
> may have played a role as well.
>
> Alain
>
>
>
>
>
> --
>
>
> Dr. Alain F. Zuur
> First author of:
>
> 1. Analysing Ecological Data (2007).
> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> URL: www.springer.com/0-387-45967-7
>
>
> 2. Mixed effects models and extensions in ecology with R. (2009).
> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>
>
> 3. A Beginner's Guide to R (2009).
> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>
>
> Other books: http://www.highstat.com/books.htm
>
>
> Statistical consultancy, courses, data analysis and software
> Highland Statistics Ltd.
> 6 Laverock road
> UK - AB41 6FN Newburgh
> Tel: 0044 1358 788177
> Email: highstat at highstat.com
> URL: www.highstat.com
> URL: www.brodgar.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ken at kjbeath.com.au  Mon Aug 31 10:25:27 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Mon, 31 Aug 2009 18:25:27 +1000
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
	<4A9A6837.8030104@highstat.com>
	<2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>
Message-ID: <2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>

On 31/08/2009, at 8:00 AM, Kingsford Jones wrote:

> Here are some thoughts, which are just conjecture (caveat emptor).
> I'd be interested in hearing contrary facts or opinion.
>
> Because of the flexibility of mixed models I think it's hard to come
> up with rules of thumb here. To examine the various scenarios,
> simulations would need to look at effects of number of groups, number
> of observations within groups and the balance of those observations
> between groups, error variance, group variance, ratio of error and
> group variances, number of levels, types of random slopes, random
> effects covariance structure, error covariance structure, fixed
> effects structure, etc...  Clearly permutations of the above could
> lead to an awful lot of simulations, not to mention what happens when
> you move away from normal errors and work with GLMMs.
>
> My guess is that in general, for small numbers of groups (or just
> small between group variance?) the sampling distribution of the
> between group variance will have a long right tail and large spread.
> Because the REML estimates are unbiased this would imply that when you
> have few groups the majority (and perhaps a large majority) of the
> estimates will be low, while some will be very high.
>

One point, is that for most analyses we are not interested in  
estimates of the random effect variances. My impression is that other  
parameter estimates are fairly robust to the random effects variance,  
so if the models fit sensibly then it seems a reasonable approach. One  
problem with a small number of groups may be the use of Empirical  
Bayes, as it ignores the estimate uncertainty. I assume somebody has  
written a paper on this, advocating full Bayesian analysis. People  
seem happy to do random effects meta-analysis with only a few trials.


Ken

> So the question remains: "what is a 'small' number of groups?".  I'm
> not sure but the following may be suggestive, at least of the symmetry
> of the sampling distribution (i.e. chi sq w/ df = # groups - 1):
>
> ngroups <- c(4, 6, 10, 15, 20)
> plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
> for (i in ngroups) {
>  plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
> }
>
>
> Also, googling turned up the paper below, which for a sub-class of
> mixed models suggests that >=50 groups is sufficient to get
> group-level variances and standard errors that are unbiased (but not
> necessarily low-variance, AFAICS).
>
> @article{maas2005sufficient,
>  title={{Sufficient sample sizes for multilevel modeling}},
>  author={Maas, C.J.M. and Hox, J.J.},
>  journal={Methodology},
>  volume={1},
>  number={3},
>  pages={86--92},
>  year={2005}
>  abstract={An important problem in multilevel modeling is what
> constitutes a sufficient sample size for accurate estimation. In
> multilevel analysis, the major restriction is often the higher-level
> sample size. In this paper, a simulation study is used to determine
> the influence of different sample sizes at the group level on the
> accuracy of the estimates (regression coefficients and variances)
> and their standard errors. In addition, the influence of other
> factors, such as the lowest-level sample size and different variance
> distributions between the levels (different intraclass correlations),
> is examined. The results show that only a small sample size
> at level two (meaning a sample of 50 or less) leads to biased
> estimates of the second-level standard errors. In all of the other
> simulated conditions the estimates of the regression coefficients, the
> variance components, and the standard errors are unbiased
> and accurate.}
> }
>
>
> hth,
>
> Kingsford Jones
>
>
>
>
> On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
> Ltd.<highstat at highstat.com> wrote:
>>
>>>
>>> Alain Zuur's response to a recent posting raises an interesting  
>>> question.
>>> To
>>> use a random effects model what number
>>>
>>> of groups is actually sufficient?
>>>
>>>
>>> I have heard talk of a minimum of 20 groups but have seen numerous
>>> examples
>>> in books and published papers with
>>>
>>> much less than this. Is there a definitive reference on this?
>>>
>>>
>>
>> Graham,
>>
>> Actually..it turned out that the data set for which the question  
>> was asked,
>> had about 350 subjects I believe.
>>
>> But anyway....that is not your question. In general you see the  
>> magic "5" in
>> some textbooks.....but for what it is worth...I recently had to  
>> program a
>> ZIP for 2-way nested data in RBugs..and in order to do this, I  
>> started with
>> 1-way and 2-way GLMMs (just to build up the code). And to check  
>> whether my
>> code was "correct", I compared the results with that of 3-4 R  
>> packages (e.g.
>> glmmPQL, lmer, glmml).  The data set consisted of multiple  
>> observations per
>> animal, for 5-30 animals per colony, and 9 colonies. I noticed that  
>> the
>> estimated values for the variance for the random intercept colony  
>> differed a
>> lot between these packages. But all came with similar estimates for  
>> the
>> animal-within-colony random intercept.
>>
>> Not that it tells you that much (all packages giving the same  
>> result doesn't
>> mean it is correct)....but it is a bit worrying. Perhaps a  
>> simulation study
>> gives you a better answer. The data I use(d) are highly  
>> unbalanced..so that
>> may have played a role as well.
>>
>> Alain
>>
>>
>>
>>
>>
>> --
>>
>>
>> Dr. Alain F. Zuur
>> First author of:
>>
>> 1. Analysing Ecological Data (2007).
>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
>> URL: www.springer.com/0-387-45967-7
>>
>>
>> 2. Mixed effects models and extensions in ecology with R. (2009).
>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>>
>>
>> 3. A Beginner's Guide to R (2009).
>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>>
>>
>> Other books: http://www.highstat.com/books.htm
>>
>>
>> Statistical consultancy, courses, data analysis and software
>> Highland Statistics Ltd.
>> 6 Laverock road
>> UK - AB41 6FN Newburgh
>> Tel: 0044 1358 788177
>> Email: highstat at highstat.com
>> URL: www.highstat.com
>> URL: www.brodgar.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Aug 31 14:33:05 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 31 Aug 2009 07:33:05 -0500
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
	<4A9A6837.8030104@highstat.com>
	<2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>
	<2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>
Message-ID: <40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>

On Mon, Aug 31, 2009 at 3:25 AM, Ken Beath<ken at kjbeath.com.au> wrote:
> On 31/08/2009, at 8:00 AM, Kingsford Jones wrote:
>
>> Here are some thoughts, which are just conjecture (caveat emptor).
>> I'd be interested in hearing contrary facts or opinion.
>>
>> Because of the flexibility of mixed models I think it's hard to come
>> up with rules of thumb here. To examine the various scenarios,
>> simulations would need to look at effects of number of groups, number
>> of observations within groups and the balance of those observations
>> between groups, error variance, group variance, ratio of error and
>> group variances, number of levels, types of random slopes, random
>> effects covariance structure, error covariance structure, fixed
>> effects structure, etc... ?Clearly permutations of the above could
>> lead to an awful lot of simulations, not to mention what happens when
>> you move away from normal errors and work with GLMMs.
>>
>> My guess is that in general, for small numbers of groups (or just
>> small between group variance?) the sampling distribution of the
>> between group variance will have a long right tail and large spread.
>> Because the REML estimates are unbiased this would imply that when you
>> have few groups the majority (and perhaps a large majority) of the
>> estimates will be low, while some will be very high.
>>
>
> One point, is that for most analyses we are not interested in estimates of
> the random effect variances. My impression is that other parameter estimates
> are fairly robust to the random effects variance, so if the models fit
> sensibly then it seems a reasonable approach. One problem with a small
> number of groups may be the use of Empirical Bayes, as it ignores the
> estimate uncertainty. I assume somebody has written a paper on this,
> advocating full Bayesian analysis. People seem happy to do random effects
> meta-analysis with only a few trials.

I agree that the precision of estimates of the variance components can
be poor and that this is not that much of a problem when one is
primarily interested in the estimates of the fixed-effects parameters.
 (By the way, the statement that "REML estimates are unbiased" is not
true in general.  Even in the simple, balanced cases where they are
unbiased, I don't think it is an important property because the
distribution of the estimator is so skewed that characterizing the
distribution by its mean is unrealistic.).

I produced some plots of the profiled likelihood of the variance
components for a simple, balanced example with 6 groups (a model for
the Dyestuff data).  They are rather sobering although one should
expect highly skewed patterns for a variance estimate (think of the
simplest case of the estimate of a variance from the mythical i.i.d.
Gaussian sample).  The plots are available in
http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf

>
> Ken
>
>> So the question remains: "what is a 'small' number of groups?". ?I'm
>> not sure but the following may be suggestive, at least of the symmetry
>> of the sampling distribution (i.e. chi sq w/ df = # groups - 1):
>>
>> ngroups <- c(4, 6, 10, 15, 20)
>> plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
>> for (i in ngroups) {
>> ?plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
>> }
>>
>>
>> Also, googling turned up the paper below, which for a sub-class of
>> mixed models suggests that >=50 groups is sufficient to get
>> group-level variances and standard errors that are unbiased (but not
>> necessarily low-variance, AFAICS).
>>
>> @article{maas2005sufficient,
>> ?title={{Sufficient sample sizes for multilevel modeling}},
>> ?author={Maas, C.J.M. and Hox, J.J.},
>> ?journal={Methodology},
>> ?volume={1},
>> ?number={3},
>> ?pages={86--92},
>> ?year={2005}
>> ?abstract={An important problem in multilevel modeling is what
>> constitutes a sufficient sample size for accurate estimation. In
>> multilevel analysis, the major restriction is often the higher-level
>> sample size. In this paper, a simulation study is used to determine
>> the influence of different sample sizes at the group level on the
>> accuracy of the estimates (regression coefficients and variances)
>> and their standard errors. In addition, the influence of other
>> factors, such as the lowest-level sample size and different variance
>> distributions between the levels (different intraclass correlations),
>> is examined. The results show that only a small sample size
>> at level two (meaning a sample of 50 or less) leads to biased
>> estimates of the second-level standard errors. In all of the other
>> simulated conditions the estimates of the regression coefficients, the
>> variance components, and the standard errors are unbiased
>> and accurate.}
>> }
>>
>>
>> hth,
>>
>> Kingsford Jones
>>
>>
>>
>>
>> On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
>> Ltd.<highstat at highstat.com> wrote:
>>>
>>>>
>>>> Alain Zuur's response to a recent posting raises an interesting
>>>> question.
>>>> To
>>>> use a random effects model what number
>>>>
>>>> of groups is actually sufficient?
>>>>
>>>>
>>>> I have heard talk of a minimum of 20 groups but have seen numerous
>>>> examples
>>>> in books and published papers with
>>>>
>>>> much less than this. Is there a definitive reference on this?
>>>>
>>>>
>>>
>>> Graham,
>>>
>>> Actually..it turned out that the data set for which the question was
>>> asked,
>>> had about 350 subjects I believe.
>>>
>>> But anyway....that is not your question. In general you see the magic "5"
>>> in
>>> some textbooks.....but for what it is worth...I recently had to program a
>>> ZIP for 2-way nested data in RBugs..and in order to do this, I started
>>> with
>>> 1-way and 2-way GLMMs (just to build up the code). And to check whether
>>> my
>>> code was "correct", I compared the results with that of 3-4 R packages
>>> (e.g.
>>> glmmPQL, lmer, glmml). ?The data set consisted of multiple observations
>>> per
>>> animal, for 5-30 animals per colony, and 9 colonies. I noticed that the
>>> estimated values for the variance for the random intercept colony
>>> differed a
>>> lot between these packages. But all came with similar estimates for the
>>> animal-within-colony random intercept.
>>>
>>> Not that it tells you that much (all packages giving the same result
>>> doesn't
>>> mean it is correct)....but it is a bit worrying. Perhaps a simulation
>>> study
>>> gives you a better answer. The data I use(d) are highly unbalanced..so
>>> that
>>> may have played a role as well.
>>>
>>> Alain
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>>
>>> Dr. Alain F. Zuur
>>> First author of:
>>>
>>> 1. Analysing Ecological Data (2007).
>>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
>>> URL: www.springer.com/0-387-45967-7
>>>
>>>
>>> 2. Mixed effects models and extensions in ecology with R. (2009).
>>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
>>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>>>
>>>
>>> 3. A Beginner's Guide to R (2009).
>>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
>>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>>>
>>>
>>> Other books: http://www.highstat.com/books.htm
>>>
>>>
>>> Statistical consultancy, courses, data analysis and software
>>> Highland Statistics Ltd.
>>> 6 Laverock road
>>> UK - AB41 6FN Newburgh
>>> Tel: 0044 1358 788177
>>> Email: highstat at highstat.com
>>> URL: www.highstat.com
>>> URL: www.brodgar.com
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From highstat at highstat.com  Mon Aug 31 15:11:40 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Mon, 31 Aug 2009 14:11:40 +0100
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>	
	<4A9A6837.8030104@highstat.com>	
	<2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>	
	<2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>
	<40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>
Message-ID: <4A9BCC0C.5080402@highstat.com>


>> One point, is that for most analyses we are not interested in estimates of
>> the random effect variances.
Unless you stick the estimated variances in these nice power analysis 
equations (e.g. in Snijders and Bosker, 1999 if I remember well) that 
calculate the intraclass correlation, and tell you how many observations 
to take next time.

Alain


>>  My impression is that other parameter estimates
>> are fairly robust to the random effects variance, so if the models fit
>> sensibly then it seems a reasonable approach. One problem with a small
>> number of groups may be the use of Empirical Bayes, as it ignores the
>> estimate uncertainty. I assume somebody has written a paper on this,
>> advocating full Bayesian analysis. People seem happy to do random effects
>> meta-analysis with only a few trials.
>>     
>
> I agree that the precision of estimates of the variance components can
> be poor and that this is not that much of a problem when one is
> primarily interested in the estimates of the fixed-effects parameters.
>  (By the way, the statement that "REML estimates are unbiased" is not
> true in general.  Even in the simple, balanced cases where they are
> unbiased, I don't think it is an important property because the
> distribution of the estimator is so skewed that characterizing the
> distribution by its mean is unrealistic.).
>
> I produced some plots of the profiled likelihood of the variance
> components for a simple, balanced example with 6 groups (a model for
> the Dyestuff data).  They are rather sobering although one should
> expect highly skewed patterns for a variance estimate (think of the
> simplest case of the estimate of a variance from the mythical i.i.d.
> Gaussian sample).  The plots are available in
> http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf
>
>   
>> Ken
>>
>>     
>>> So the question remains: "what is a 'small' number of groups?".  I'm
>>> not sure but the following may be suggestive, at least of the symmetry
>>> of the sampling distribution (i.e. chi sq w/ df = # groups - 1):
>>>
>>> ngroups <- c(4, 6, 10, 15, 20)
>>> plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
>>> for (i in ngroups) {
>>>  plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
>>> }
>>>
>>>
>>> Also, googling turned up the paper below, which for a sub-class of
>>> mixed models suggests that >=50 groups is sufficient to get
>>> group-level variances and standard errors that are unbiased (but not
>>> necessarily low-variance, AFAICS).
>>>
>>> @article{maas2005sufficient,
>>>  title={{Sufficient sample sizes for multilevel modeling}},
>>>  author={Maas, C.J.M. and Hox, J.J.},
>>>  journal={Methodology},
>>>  volume={1},
>>>  number={3},
>>>  pages={86--92},
>>>  year={2005}
>>>  abstract={An important problem in multilevel modeling is what
>>> constitutes a sufficient sample size for accurate estimation. In
>>> multilevel analysis, the major restriction is often the higher-level
>>> sample size. In this paper, a simulation study is used to determine
>>> the influence of different sample sizes at the group level on the
>>> accuracy of the estimates (regression coefficients and variances)
>>> and their standard errors. In addition, the influence of other
>>> factors, such as the lowest-level sample size and different variance
>>> distributions between the levels (different intraclass correlations),
>>> is examined. The results show that only a small sample size
>>> at level two (meaning a sample of 50 or less) leads to biased
>>> estimates of the second-level standard errors. In all of the other
>>> simulated conditions the estimates of the regression coefficients, the
>>> variance components, and the standard errors are unbiased
>>> and accurate.}
>>> }
>>>
>>>
>>> hth,
>>>
>>> Kingsford Jones
>>>
>>>
>>>
>>>
>>> On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
>>> Ltd.<highstat at highstat.com> wrote:
>>>       
>>>>> Alain Zuur's response to a recent posting raises an interesting
>>>>> question.
>>>>> To
>>>>> use a random effects model what number
>>>>>
>>>>> of groups is actually sufficient?
>>>>>
>>>>>
>>>>> I have heard talk of a minimum of 20 groups but have seen numerous
>>>>> examples
>>>>> in books and published papers with
>>>>>
>>>>> much less than this. Is there a definitive reference on this?
>>>>>
>>>>>
>>>>>           
>>>> Graham,
>>>>
>>>> Actually..it turned out that the data set for which the question was
>>>> asked,
>>>> had about 350 subjects I believe.
>>>>
>>>> But anyway....that is not your question. In general you see the magic "5"
>>>> in
>>>> some textbooks.....but for what it is worth...I recently had to program a
>>>> ZIP for 2-way nested data in RBugs..and in order to do this, I started
>>>> with
>>>> 1-way and 2-way GLMMs (just to build up the code). And to check whether
>>>> my
>>>> code was "correct", I compared the results with that of 3-4 R packages
>>>> (e.g.
>>>> glmmPQL, lmer, glmml).  The data set consisted of multiple observations
>>>> per
>>>> animal, for 5-30 animals per colony, and 9 colonies. I noticed that the
>>>> estimated values for the variance for the random intercept colony
>>>> differed a
>>>> lot between these packages. But all came with similar estimates for the
>>>> animal-within-colony random intercept.
>>>>
>>>> Not that it tells you that much (all packages giving the same result
>>>> doesn't
>>>> mean it is correct)....but it is a bit worrying. Perhaps a simulation
>>>> study
>>>> gives you a better answer. The data I use(d) are highly unbalanced..so
>>>> that
>>>> may have played a role as well.
>>>>
>>>> Alain
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>>
>>>>
>>>> Dr. Alain F. Zuur
>>>> First author of:
>>>>
>>>> 1. Analysing Ecological Data (2007).
>>>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
>>>> URL: www.springer.com/0-387-45967-7
>>>>
>>>>
>>>> 2. Mixed effects models and extensions in ecology with R. (2009).
>>>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
>>>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>>>>
>>>>
>>>> 3. A Beginner's Guide to R (2009).
>>>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
>>>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>>>>
>>>>
>>>> Other books: http://www.highstat.com/books.htm
>>>>
>>>>
>>>> Statistical consultancy, courses, data analysis and software
>>>> Highland Statistics Ltd.
>>>> 6 Laverock road
>>>> UK - AB41 6FN Newburgh
>>>> Tel: 0044 1358 788177
>>>> Email: highstat at highstat.com
>>>> URL: www.highstat.com
>>>> URL: www.brodgar.com
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>         
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>       
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>     
>
>   


-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From raterwil at gmail.com  Mon Aug 31 18:53:35 2009
From: raterwil at gmail.com (Robert Terwilliger)
Date: Mon, 31 Aug 2009 12:53:35 -0400
Subject: [R-sig-ME] longitudinal analysis using lmer?
In-Reply-To: <A8B693D3-9C3A-41FB-8A1A-B71D18A86E3B@kjbeath.com.au>
References: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>
	<e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>
	<A8B693D3-9C3A-41FB-8A1A-B71D18A86E3B@kjbeath.com.au>
Message-ID: <e837fef90908310953l234f885ard183182b8e5f62f@mail.gmail.com>

Thanks everyone for all the advice.

One question I have (maybe there will be more...... :-P ):
Should I exclude subjects that have only 1 or 2 data points?

On Fri, Aug 28, 2009 at 7:07 PM, Ken Beath<ken at kjbeath.com.au> wrote:
> On 29/08/2009, at 6:07 AM, Robert Terwilliger wrote:
>
>> One more thing........
>>
>> What i sent was only a small sample of the data, just for the purpose
>> of showing what kind of set we have.
>>
>> We have about 150 subjects, with starting ages between 8 and 21, with
>> 3-5 data points (yearly visits) per subject.
>>
>
> This will be fine, although it isn't as good as having a smaller number of
> complete series. One point is that they don't look completely linear, so a
> polynomial (maybe quadratic) or regression spline may be a better option.
> Judging by the scatter the random effect variance will probably be close to
> zero.
>
> Ken
>
>
>
>
>> Thanks,
>>
>> --
>> Robert Terwilliger
>> Physicist
>> Laboratory of Neurocognitive Development
>> Western Psychiatric Institute and Clinic
>> University of Pittsburgh Medical Center
>> Loeffler Building
>> 121 Meyran Avenue ?#114
>> Pittsburgh, PA 15213
>> 412.383.8174 ?- Office
>> 412.383.8179 - Fax
>> em: raterwil at gmail.com
>> http://www.wpic.pitt.edu/research/lncd/
>>
>> *******************************************************
>> Dear R mixed effects gurus,
>>
>> I have the following data below. Attached is a png graphic
>> representing the data.
>>
>> I would like to run the following analysis:
>>
>> signal ~ age | subject.
>>
>> For your information (not statically relevant), the "signal" variable
>> is from a functional MRI experiment.
>>
>> At issue is whether this analysis is valid using "lme". From the graph
>> (and the table below), one can see that there are five subjects.
>> However, each subject begins at a different age. Subject 1 begins at 8
>> and goes to 12, while subject 5 begins at 14. From my study of
>> longitudinal analysis, usually each subject begins at the same
>> starting point, while these data have subjects beginning at different
>> starting points (different ages).
>>
>> Any insight is appreciated.
>>
>> subject age ? ? signal
>> 1 ? ? ? 8 ? ? ? 0.108
>> 1 ? ? ? 9 ? ? ? 0.139
>> 1 ? ? ?10 ? ?NA
>> 1 ? ? ? 11 ? ? ?0.151
>> 1 ? ? ? 12 ? ? ?0.148
>> 2 ? ? ? 10 ? ? ?0.127
>> 2 ? ? ?11 ? ?NA
>> 2 ? ? ? 12 ? ? ?0.135
>> 2 ? ? ? 13 ? ? ?0.146
>> 3 ? ? ? 9 ? ? ? 0.105
>> 3 ? ? ? 10 ? ? ?0.123
>> 3 ? ? ? 11 ? ? ?0.134
>> 3 ? ? ? 12 ? ? ?0.151
>> 3 ? ? ? 13 ? ? ?0.145
>> 4 ? ? ? 12 ? ? ?0.130
>> 4 ? ? ? 13 ? ? ?0.169
>> 4 ? ? ? 14 ? ? ?0.146
>> 4 ? ? ? 15 ? ? ?0.174
>> 5 ? ? ? 14 ? ? ?0.158
>> 5 ? ? ? 15 ? ? ?0.141
>> 5 ? ? ? 16 ? ? ?0.178
>> 5 ? ? ?17 ? ?NA
>> 5 ? ? ? 18 ? ? ?0.172
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



-- 
Robert Terwilliger
Physicist
Laboratory of Neurocognitive Development
Western Psychiatric Institute and Clinic
University of Pittsburgh Medical Center
Loeffler Building
121 Meyran Avenue  #114
Pittsburgh, PA 15213
412.383.8174  - Office
412.383.8179 - Fax
em: raterwil at gmail.com
http://www.wpic.pitt.edu/research/lncd/



From ral at lcfltd.com  Mon Aug 31 20:13:23 2009
From: ral at lcfltd.com (Robert A LaBudde)
Date: Mon, 31 Aug 2009 14:13:23 -0400
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.co m>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
	<4A9A6837.8030104@highstat.com>
	<2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>
	<2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>
	<40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>
Message-ID: <0KP900KRV6MNMUX0@vms173019.mailsrvcs.net>

This may be overly simplistic, but when I had to answer this question 
I considered estimating a variance for a normally distributed variate 
and then looked at the width of the chi-square-based confidence 
interval on standard deviance. A plot vs degrees of freedom indicates 
that you need about 6-8 elements to get to the knee of the curve. 
This appears consistent with the advice to not use a random effect 
instead of a fixed effect if you have fewer than 6 levels.


At 08:33 AM 8/31/2009, Douglas Bates wrote:
>On Mon, Aug 31, 2009 at 3:25 AM, Ken Beath<ken at kjbeath.com.au> wrote:
> > On 31/08/2009, at 8:00 AM, Kingsford Jones wrote:
> >
> >> Here are some thoughts, which are just conjecture (caveat emptor).
> >> I'd be interested in hearing contrary facts or opinion.
> >>
> >> Because of the flexibility of mixed models I think it's hard to come
> >> up with rules of thumb here. To examine the various scenarios,
> >> simulations would need to look at effects of number of groups, number
> >> of observations within groups and the balance of those observations
> >> between groups, error variance, group variance, ratio of error and
> >> group variances, number of levels, types of random slopes, random
> >> effects covariance structure, error covariance structure, fixed
> >> effects structure, etc...  Clearly permutations of the above could
> >> lead to an awful lot of simulations, not to mention what happens when
> >> you move away from normal errors and work with GLMMs.
> >>
> >> My guess is that in general, for small numbers of groups (or just
> >> small between group variance?) the sampling distribution of the
> >> between group variance will have a long right tail and large spread.
> >> Because the REML estimates are unbiased this would imply that when you
> >> have few groups the majority (and perhaps a large majority) of the
> >> estimates will be low, while some will be very high.
> >>
> >
> > One point, is that for most analyses we are not interested in estimates of
> > the random effect variances. My impression is that other 
> parameter estimates
> > are fairly robust to the random effects variance, so if the models fit
> > sensibly then it seems a reasonable approach. One problem with a small
> > number of groups may be the use of Empirical Bayes, as it ignores the
> > estimate uncertainty. I assume somebody has written a paper on this,
> > advocating full Bayesian analysis. People seem happy to do random effects
> > meta-analysis with only a few trials.
>
>I agree that the precision of estimates of the variance components can
>be poor and that this is not that much of a problem when one is
>primarily interested in the estimates of the fixed-effects parameters.
>  (By the way, the statement that "REML estimates are unbiased" is not
>true in general.  Even in the simple, balanced cases where they are
>unbiased, I don't think it is an important property because the
>distribution of the estimator is so skewed that characterizing the
>distribution by its mean is unrealistic.).
>
>I produced some plots of the profiled likelihood of the variance
>components for a simple, balanced example with 6 groups (a model for
>the Dyestuff data).  They are rather sobering although one should
>expect highly skewed patterns for a variance estimate (think of the
>simplest case of the estimate of a variance from the mythical i.i.d.
>Gaussian sample).  The plots are available in
>http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf
>
> >
> > Ken
> >
> >> So the question remains: "what is a 'small' number of groups?".  I'm
> >> not sure but the following may be suggestive, at least of the symmetry
> >> of the sampling distribution (i.e. chi sq w/ df = # groups - 1):
> >>
> >> ngroups <- c(4, 6, 10, 15, 20)
> >> plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
> >> for (i in ngroups) {
> >>  plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
> >> }
> >>
> >>
> >> Also, googling turned up the paper below, which for a sub-class of
> >> mixed models suggests that >=50 groups is sufficient to get
> >> group-level variances and standard errors that are unbiased (but not
> >> necessarily low-variance, AFAICS).
> >>
> >> @article{maas2005sufficient,
> >>  title={{Sufficient sample sizes for multilevel modeling}},
> >>  author={Maas, C.J.M. and Hox, J.J.},
> >>  journal={Methodology},
> >>  volume={1},
> >>  number={3},
> >>  pages={86--92},
> >>  year={2005}
> >>  abstract={An important problem in multilevel modeling is what
> >> constitutes a sufficient sample size for accurate estimation. In
> >> multilevel analysis, the major restriction is often the higher-level
> >> sample size. In this paper, a simulation study is used to determine
> >> the influence of different sample sizes at the group level on the
> >> accuracy of the estimates (regression coefficients and variances)
> >> and their standard errors. In addition, the influence of other
> >> factors, such as the lowest-level sample size and different variance
> >> distributions between the levels (different intraclass correlations),
> >> is examined. The results show that only a small sample size
> >> at level two (meaning a sample of 50 or less) leads to biased
> >> estimates of the second-level standard errors. In all of the other
> >> simulated conditions the estimates of the regression coefficients, the
> >> variance components, and the standard errors are unbiased
> >> and accurate.}
> >> }
> >>
> >>
> >> hth,
> >>
> >> Kingsford Jones
> >>
> >>
> >>
> >>
> >> On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
> >> Ltd.<highstat at highstat.com> wrote:
> >>>
> >>>>
> >>>> Alain Zuur's response to a recent posting raises an interesting
> >>>> question.
> >>>> To
> >>>> use a random effects model what number
> >>>>
> >>>> of groups is actually sufficient?
> >>>>
> >>>>
> >>>> I have heard talk of a minimum of 20 groups but have seen numerous
> >>>> examples
> >>>> in books and published papers with
> >>>>
> >>>> much less than this. Is there a definitive reference on this?
> >>>>
> >>>>
> >>>
> >>> Graham,
> >>>
> >>> Actually..it turned out that the data set for which the question was
> >>> asked,
> >>> had about 350 subjects I believe.
> >>>
> >>> But anyway....that is not your question. In general you see the magic "5"
> >>> in
> >>> some textbooks.....but for what it is worth...I recently had to program a
> >>> ZIP for 2-way nested data in RBugs..and in order to do this, I started
> >>> with
> >>> 1-way and 2-way GLMMs (just to build up the code). And to check whether
> >>> my
> >>> code was "correct", I compared the results with that of 3-4 R packages
> >>> (e.g.
> >>> glmmPQL, lmer, glmml).  The data set consisted of multiple observations
> >>> per
> >>> animal, for 5-30 animals per colony, and 9 colonies. I noticed that the
> >>> estimated values for the variance for the random intercept colony
> >>> differed a
> >>> lot between these packages. But all came with similar estimates for the
> >>> animal-within-colony random intercept.
> >>>
> >>> Not that it tells you that much (all packages giving the same result
> >>> doesn't
> >>> mean it is correct)....but it is a bit worrying. Perhaps a simulation
> >>> study
> >>> gives you a better answer. The data I use(d) are highly unbalanced..so
> >>> that
> >>> may have played a role as well.
> >>>
> >>> Alain
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>>
> >>>
> >>> Dr. Alain F. Zuur
> >>> First author of:
> >>>
> >>> 1. Analysing Ecological Data (2007).
> >>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> >>> URL: www.springer.com/0-387-45967-7
> >>>
> >>>
> >>> 2. Mixed effects models and extensions in ecology with R. (2009).
> >>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> >>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
> >>>
> >>>
> >>> 3. A Beginner's Guide to R (2009).
> >>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> >>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
> >>>
> >>>
> >>> Other books: http://www.highstat.com/books.htm
> >>>
> >>>
> >>> Statistical consultancy, courses, data analysis and software
> >>> Highland Statistics Ltd.
> >>> 6 Laverock road
> >>> UK - AB41 6FN Newburgh
> >>> Tel: 0044 1358 788177
> >>> Email: highstat at highstat.com
> >>> URL: www.highstat.com
> >>> URL: www.brodgar.com
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"



From emm.charpentier at free.fr  Mon Aug 31 23:19:11 2009
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Mon, 31 Aug 2009 23:19:11 +0200
Subject: [R-sig-ME] longitudinal analysis using lmer?
In-Reply-To: <e837fef90908310953l234f885ard183182b8e5f62f@mail.gmail.com>
References: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>
	<e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>
	<A8B693D3-9C3A-41FB-8A1A-B71D18A86E3B@kjbeath.com.au>
	<e837fef90908310953l234f885ard183182b8e5f62f@mail.gmail.com>
Message-ID: <1251753551.2202.6.camel@PortableToshiba>

Le lundi 31 ao?t 2009 ? 12:53 -0400, Robert Terwilliger a ?crit :
> Thanks everyone for all the advice.
> 
> One question I have (maybe there will be more...... :-P ):
> Should I exclude subjects that have only 1 or 2 data points?

The question you shuld try to answer is "*Why* do they have only 1 or 2
points ?".

HTH,

					Emmanuel Charpentier


> On Fri, Aug 28, 2009 at 7:07 PM, Ken Beath<ken-PJqznCQlsrTvnOemgxGiVw at public.gmane.org> wrote:
> > On 29/08/2009, at 6:07 AM, Robert Terwilliger wrote:
> >
> >> One more thing........
> >>
> >> What i sent was only a small sample of the data, just for the purpose
> >> of showing what kind of set we have.
> >>
> >> We have about 150 subjects, with starting ages between 8 and 21, with
> >> 3-5 data points (yearly visits) per subject.
> >>
> >
> > This will be fine, although it isn't as good as having a smaller number of
> > complete series. One point is that they don't look completely linear, so a
> > polynomial (maybe quadratic) or regression spline may be a better option.
> > Judging by the scatter the random effect variance will probably be close to
> > zero.
> >
> > Ken
> >
> >
> >
> >
> >> Thanks,
> >>
> >> --
> >> Robert Terwilliger
> >> Physicist
> >> Laboratory of Neurocognitive Development
> >> Western Psychiatric Institute and Clinic
> >> University of Pittsburgh Medical Center
> >> Loeffler Building
> >> 121 Meyran Avenue  #114
> >> Pittsburgh, PA 15213
> >> 412.383.8174  - Office
> >> 412.383.8179 - Fax
> >> em: raterwil at gmail.com
> >> http://www.wpic.pitt.edu/research/lncd/
> >>
> >> *******************************************************
> >> Dear R mixed effects gurus,
> >>
> >> I have the following data below. Attached is a png graphic
> >> representing the data.
> >>
> >> I would like to run the following analysis:
> >>
> >> signal ~ age | subject.
> >>
> >> For your information (not statically relevant), the "signal" variable
> >> is from a functional MRI experiment.
> >>
> >> At issue is whether this analysis is valid using "lme". From the graph
> >> (and the table below), one can see that there are five subjects.
> >> However, each subject begins at a different age. Subject 1 begins at 8
> >> and goes to 12, while subject 5 begins at 14. From my study of
> >> longitudinal analysis, usually each subject begins at the same
> >> starting point, while these data have subjects beginning at different
> >> starting points (different ages).
> >>
> >> Any insight is appreciated.
> >>
> >> subject age     signal
> >> 1       8       0.108
> >> 1       9       0.139
> >> 1      10    NA
> >> 1       11      0.151
> >> 1       12      0.148
> >> 2       10      0.127
> >> 2      11    NA
> >> 2       12      0.135
> >> 2       13      0.146
> >> 3       9       0.105
> >> 3       10      0.123
> >> 3       11      0.134
> >> 3       12      0.151
> >> 3       13      0.145
> >> 4       12      0.130
> >> 4       13      0.169
> >> 4       14      0.146
> >> 4       15      0.174
> >> 5       14      0.158
> >> 5       15      0.141
> >> 5       16      0.178
> >> 5      17    NA
> >> 5       18      0.172
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> 
> 
> 



From emm.charpentier at free.fr  Mon Aug 31 23:47:58 2009
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Mon, 31 Aug 2009 23:47:58 +0200
Subject: [R-sig-ME] How many groups is enough?
In-Reply-To: <40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>
References: <mailman.1.1251626402.14690.r-sig-mixed-models@r-project.org>
	<4A9A6837.8030104@highstat.com>
	<2ad0cc110908301500k66b6561dk2afdb125d551c299@mail.gmail.com>
	<2EA4BCAA-B67F-4DA9-857F-CB24F03D1FB1@kjbeath.com.au>
	<40e66e0b0908310533y1172853em886510f14fba87e8@mail.gmail.com>
Message-ID: <1251755277.2202.33.camel@PortableToshiba>

Le lundi 31 ao?t 2009 ? 07:33 -0500, Douglas Bates a ?crit :
> On Mon, Aug 31, 2009 at 3:25 AM, Ken Beath<ken at kjbeath.com.au> wrote:
> > On 31/08/2009, at 8:00 AM, Kingsford Jones wrote:
> >
> >> Here are some thoughts, which are just conjecture (caveat emptor).
> >> I'd be interested in hearing contrary facts or opinion.
> >>
> >> Because of the flexibility of mixed models I think it's hard to come
> >> up with rules of thumb here. To examine the various scenarios,
> >> simulations would need to look at effects of number of groups, number
> >> of observations within groups and the balance of those observations
> >> between groups, error variance, group variance, ratio of error and
> >> group variances, number of levels, types of random slopes, random
> >> effects covariance structure, error covariance structure, fixed
> >> effects structure, etc...  Clearly permutations of the above could
> >> lead to an awful lot of simulations, not to mention what happens when
> >> you move away from normal errors and work with GLMMs.
> >>
> >> My guess is that in general, for small numbers of groups (or just
> >> small between group variance?) the sampling distribution of the
> >> between group variance will have a long right tail and large spread.
> >> Because the REML estimates are unbiased this would imply that when you
> >> have few groups the majority (and perhaps a large majority) of the
> >> estimates will be low, while some will be very high.
> >>
> >
> > One point, is that for most analyses we are not interested in estimates of
> > the random effect variances. My impression is that other parameter estimates
> > are fairly robust to the random effects variance, so if the models fit
> > sensibly then it seems a reasonable approach. One problem with a small
> > number of groups may be the use of Empirical Bayes, as it ignores the
> > estimate uncertainty. I assume somebody has written a paper on this,
> > advocating full Bayesian analysis. People seem happy to do random effects
> > meta-analysis with only a few trials.
> 
> I agree that the precision of estimates of the variance components can
> be poor and that this is not that much of a problem when one is
> primarily interested in the estimates of the fixed-effects parameters.
>  (By the way, the statement that "REML estimates are unbiased" is not
> true in general.  Even in the simple, balanced cases where they are
> unbiased, I don't think it is an important property because the
> distribution of the estimator is so skewed that characterizing the
> distribution by its mean is unrealistic.).

This almost sounds as a plea for full Bayesian analysis (aiming at
assessing the posterior distribution of a parameter, rather than
gambling on a constant-but-forever-unknown value), possibly using
low-information conjugate priors. In his small but interesting textbook,
Jim Alberts illustrates the difficulty of assessing inter-groups
variance (or variance-like) parameters. By totally different wys, you
reach the same conclusions...

> I produced some plots of the profiled likelihood of the variance
> components for a simple, balanced example with 6 groups (a model for
> the Dyestuff data).  They are rather sobering although one should
> expect highly skewed patterns for a variance estimate (think of the
> simplest case of the estimate of a variance from the mythical i.i.d.
> Gaussian sample).  The plots are available in
> http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf

May I suggest that further releases of lmer (and possibly nlme) contain
at least a vignette pointing to this (and possibly your previous
presentations, that I found quite useful for explaining the intricacies
of mixed-model to non-statisticians) ? Of course, a full book should be
preferable (and I understand that this is one of your goals), but in the
interim, these slides should avoid you lot of similar questions on the
list.

Another suggestion : give in a vignette the current state of confidence
one should put in various parts of the lmer pckage ; for example, I
understand that you have had doubts about the mcmc algorithms : are
these doubts confirmed ? infirmed ? still lingering ? Can we use them
"safely" to get confidence intervals on fixed effects coefficients ? for
random effects variances ? or (heavens ...) feeding p-values to journal
editors that crave them (BTW : wht about "mcmcpavlues" in package
"languageR" ?) ? If not, what can be done to answer those basic
questions ?

Respectfully yours,

					Emmanuel Charpentier

> >
> > Ken
> >
> >> So the question remains: "what is a 'small' number of groups?".  I'm
> >> not sure but the following may be suggestive, at least of the symmetry
> >> of the sampling distribution (i.e. chi sq w/ df = # groups - 1):
> >>
> >> ngroups <- c(4, 6, 10, 15, 20)
> >> plot(0, type='n', xlim=c(0, 30), ylim=c(0, .3))
> >> for (i in ngroups) {
> >>  plot(function(x) dchisq(x, i - 1), 0, 60, add=TRUE)
> >> }
> >>
> >>
> >> Also, googling turned up the paper below, which for a sub-class of
> >> mixed models suggests that >=50 groups is sufficient to get
> >> group-level variances and standard errors that are unbiased (but not
> >> necessarily low-variance, AFAICS).
> >>
> >> @article{maas2005sufficient,
> >>  title={{Sufficient sample sizes for multilevel modeling}},
> >>  author={Maas, C.J.M. and Hox, J.J.},
> >>  journal={Methodology},
> >>  volume={1},
> >>  number={3},
> >>  pages={86--92},
> >>  year={2005}
> >>  abstract={An important problem in multilevel modeling is what
> >> constitutes a sufficient sample size for accurate estimation. In
> >> multilevel analysis, the major restriction is often the higher-level
> >> sample size. In this paper, a simulation study is used to determine
> >> the influence of different sample sizes at the group level on the
> >> accuracy of the estimates (regression coefficients and variances)
> >> and their standard errors. In addition, the influence of other
> >> factors, such as the lowest-level sample size and different variance
> >> distributions between the levels (different intraclass correlations),
> >> is examined. The results show that only a small sample size
> >> at level two (meaning a sample of 50 or less) leads to biased
> >> estimates of the second-level standard errors. In all of the other
> >> simulated conditions the estimates of the regression coefficients, the
> >> variance components, and the standard errors are unbiased
> >> and accurate.}
> >> }
> >>
> >>
> >> hth,
> >>
> >> Kingsford Jones
> >>
> >>
> >>
> >>
> >> On Sun, Aug 30, 2009 at 5:53 AM, Highland Statistics
> >> Ltd.<highstat at highstat.com> wrote:
> >>>
> >>>>
> >>>> Alain Zuur's response to a recent posting raises an interesting
> >>>> question.
> >>>> To
> >>>> use a random effects model what number
> >>>>
> >>>> of groups is actually sufficient?
> >>>>
> >>>>
> >>>> I have heard talk of a minimum of 20 groups but have seen numerous
> >>>> examples
> >>>> in books and published papers with
> >>>>
> >>>> much less than this. Is there a definitive reference on this?
> >>>>
> >>>>
> >>>
> >>> Graham,
> >>>
> >>> Actually..it turned out that the data set for which the question was
> >>> asked,
> >>> had about 350 subjects I believe.
> >>>
> >>> But anyway....that is not your question. In general you see the magic "5"
> >>> in
> >>> some textbooks.....but for what it is worth...I recently had to program a
> >>> ZIP for 2-way nested data in RBugs..and in order to do this, I started
> >>> with
> >>> 1-way and 2-way GLMMs (just to build up the code). And to check whether
> >>> my
> >>> code was "correct", I compared the results with that of 3-4 R packages
> >>> (e.g.
> >>> glmmPQL, lmer, glmml).  The data set consisted of multiple observations
> >>> per
> >>> animal, for 5-30 animals per colony, and 9 colonies. I noticed that the
> >>> estimated values for the variance for the random intercept colony
> >>> differed a
> >>> lot between these packages. But all came with similar estimates for the
> >>> animal-within-colony random intercept.
> >>>
> >>> Not that it tells you that much (all packages giving the same result
> >>> doesn't
> >>> mean it is correct)....but it is a bit worrying. Perhaps a simulation
> >>> study
> >>> gives you a better answer. The data I use(d) are highly unbalanced..so
> >>> that
> >>> may have played a role as well.
> >>>
> >>> Alain
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> --
> >>>
> >>>
> >>> Dr. Alain F. Zuur
> >>> First author of:
> >>>
> >>> 1. Analysing Ecological Data (2007).
> >>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> >>> URL: www.springer.com/0-387-45967-7
> >>>
> >>>
> >>> 2. Mixed effects models and extensions in ecology with R. (2009).
> >>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> >>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
> >>>
> >>>
> >>> 3. A Beginner's Guide to R (2009).
> >>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> >>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
> >>>
> >>>
> >>> Other books: http://www.highstat.com/books.htm
> >>>
> >>>
> >>> Statistical consultancy, courses, data analysis and software
> >>> Highland Statistics Ltd.
> >>> 6 Laverock road
> >>> UK - AB41 6FN Newburgh
> >>> Tel: 0044 1358 788177
> >>> Email: highstat at highstat.com
> >>> URL: www.highstat.com
> >>> URL: www.brodgar.com
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>



From maj at stats.waikato.ac.nz  Tue Sep  1 04:14:28 2009
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 01 Sep 2009 14:14:28 +1200
Subject: [R-sig-ME] longitudinal analysis using lmer?
In-Reply-To: <1251753551.2202.6.camel@PortableToshiba>
References: <e837fef90908281226j6e7dd590p9c5249a58156429e@mail.gmail.com>	<e837fef90908281307q5203ce0an4be6795bca07eb71@mail.gmail.com>	<A8B693D3-9C3A-41FB-8A1A-B71D18A86E3B@kjbeath.com.au>	<e837fef90908310953l234f885ard183182b8e5f62f@mail.gmail.com>
	<1251753551.2202.6.camel@PortableToshiba>
Message-ID: <4A9C8384.4090306@stats.waikato.ac.nz>

Andrew Gelman at least seems to glory in the ability of random effects
models to cope with cases having meagre data. See the discussion in the
Gelman/Hell book on the Radon data and Lac Qui Parle County.

Murray Jorgensen

Emmanuel Charpentier wrote:
> Le lundi 31 ao?t 2009 ? 12:53 -0400, Robert Terwilliger a ?crit :
>> Thanks everyone for all the advice.
>>
>> One question I have (maybe there will be more...... :-P ):
>> Should I exclude subjects that have only 1 or 2 data points?
> 
> The question you shuld try to answer is "*Why* do they have only 1 or 2
> points ?".
> 
> HTH,
> 
> 					Emmanuel Charpentier
> 
> 
>> On Fri, Aug 28, 2009 at 7:07 PM, Ken Beath<ken-PJqznCQlsrTvnOemgxGiVw at public.gmane.org> wrote:
>>> On 29/08/2009, at 6:07 AM, Robert Terwilliger wrote:
>>>
>>>> One more thing........
>>>>
>>>> What i sent was only a small sample of the data, just for the purpose
>>>> of showing what kind of set we have.
>>>>
>>>> We have about 150 subjects, with starting ages between 8 and 21, with
>>>> 3-5 data points (yearly visits) per subject.
>>>>
>>> This will be fine, although it isn't as good as having a smaller number of
>>> complete series. One point is that they don't look completely linear, so a
>>> polynomial (maybe quadratic) or regression spline may be a better option.
>>> Judging by the scatter the random effect variance will probably be close to
>>> zero.
>>>
>>> Ken
>>>
>>>
>>>
>>>
>>>> Thanks,
>>>>
>>>> --
>>>> Robert Terwilliger
>>>> Physicist
>>>> Laboratory of Neurocognitive Development
>>>> Western Psychiatric Institute and Clinic
>>>> University of Pittsburgh Medical Center
>>>> Loeffler Building
>>>> 121 Meyran Avenue  #114
>>>> Pittsburgh, PA 15213
>>>> 412.383.8174  - Office
>>>> 412.383.8179 - Fax
>>>> em: raterwil at gmail.com
>>>> http://www.wpic.pitt.edu/research/lncd/
>>>>
>>>> *******************************************************
>>>> Dear R mixed effects gurus,
>>>>
>>>> I have the following data below. Attached is a png graphic
>>>> representing the data.
>>>>
>>>> I would like to run the following analysis:
>>>>
>>>> signal ~ age | subject.
>>>>
>>>> For your information (not statically relevant), the "signal" variable
>>>> is from a functional MRI experiment.
>>>>
>>>> At issue is whether this analysis is valid using "lme". From the graph
>>>> (and the table below), one can see that there are five subjects.
>>>> However, each subject begins at a different age. Subject 1 begins at 8
>>>> and goes to 12, while subject 5 begins at 14. From my study of
>>>> longitudinal analysis, usually each subject begins at the same
>>>> starting point, while these data have subjects beginning at different
>>>> starting points (different ages).
>>>>
>>>> Any insight is appreciated.
>>>>
>>>> subject age     signal
>>>> 1       8       0.108
>>>> 1       9       0.139
>>>> 1      10    NA
>>>> 1       11      0.151
>>>> 1       12      0.148
>>>> 2       10      0.127
>>>> 2      11    NA
>>>> 2       12      0.135
>>>> 2       13      0.146
>>>> 3       9       0.105
>>>> 3       10      0.123
>>>> 3       11      0.134
>>>> 3       12      0.151
>>>> 3       13      0.145
>>>> 4       12      0.130
>>>> 4       13      0.169
>>>> 4       14      0.146
>>>> 4       15      0.174
>>>> 5       14      0.158
>>>> 5       15      0.141
>>>> 5       16      0.178
>>>> 5      17    NA
>>>> 5       18      0.172
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From Fabian.Scheipl at stat.uni-muenchen.de  Tue Sep  1 12:15:20 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Tue, 1 Sep 2009 12:15:20 +0200
Subject: [R-sig-ME] amer: generalized additive mixed models with lme4
Message-ID: <4836bc6a0909010315q74b07dcfyf730e9df06ed004c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090901/6c602412/attachment.pl>

From grahamleask at btinternet.com  Tue Sep  1 13:59:44 2009
From: grahamleask at btinternet.com (Graham Leask)
Date: Tue, 1 Sep 2009 12:59:44 +0100
Subject: [R-sig-ME] How many groups is enough
Message-ID: <000001ca2afb$b7bee7a0$273cb6e0$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090901/5ec931ad/attachment.pl>

From m.fairbrother at bristol.ac.uk  Wed Sep  2 04:00:21 2009
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 2 Sep 2009 03:00:21 +0100
Subject: [R-sig-ME] fitted values for logit models using glmer
In-Reply-To: <mailman.5.1251453601.29552.r-sig-mixed-models@r-project.org>
References: <mailman.5.1251453601.29552.r-sig-mixed-models@r-project.org>
Message-ID: <2A9B0387-FD94-4558-8296-49D0D72BD8E4@bristol.ac.uk>

Dear all,

I have been trying to determine what I get with "fitted(model)" when  
the model in question is a logit, fitted using glmer. After some  
investigation, my current impression is that I get predicted  
probabilities. However, I've found at least three suggestions to the  
contrary scattered around the web:

http://psy-ed.wikidot.com/glm
http://clic.cimec.unitn.it/methods/R/lectures/regression3-ho.pdf  
(second last page)
http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6209.html

Can anyone please tell me whether I'm right or they're right? I'm  
quite happy to be wrong, but I'd like to know for sure. Was there  
perhaps a change made to the package in this regard at some point?

Many thanks,

Malcolm Fairbrother

School of Geographical Sciences
University of Bristol



From kagba2006 at yahoo.com  Thu Sep  3 18:39:14 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 3 Sep 2009 09:39:14 -0700 (PDT)
Subject: [R-sig-ME] correlation structure with AR(1)
Message-ID: <216154.80628.qm@web38303.mail.mud.yahoo.com>

Dear All,

Could someone please advice me the difference between lme function with correlation structure of the residual from AR(1) process and? without this correlation structure. I found from the help menu shown below that if we do not declare?any value in corAR1, by default, the function will assume there is no autocorrelation i.e. 0. 

Does this meant we can just simply ignore the correlation structure in the model and just use a simple command in lme without including corAR1? Please correct me if i'm wrong. 

###################################################################################
Usage
corAR1(value, form, fixed)

Arguments
value the value of the lag 1 autocorrelation, which must be between -1 and 1. Defaults to 0 (no autocorrelation). 
###################################################################################



Let see on few examples from the help menu. I noticed that these two examples?yield different results?in term of the?fixed and random effects parameters. From what i understand, we should get the same results as the second object, fm2Ovar.lme? does not have any autocorrelation in its AR(1) correlation structure as the default value is?used. 

Could someone please advice on the reason of these?differences?


###################################################################################
# Pinheiro and Bates, p. 240
fm1Ovar.lme <- lme(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), data = Ovary, random = pdDiag(~sin(2*pi*Time)))
fm2Ovar.lme <- update(fm1Ovar.lme, correlation = corAR1())
###################################################################################



Thank you
Fir







From bolker at ufl.edu  Thu Sep  3 18:54:58 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 03 Sep 2009 12:54:58 -0400
Subject: [R-sig-ME] correlation structure with AR(1)
In-Reply-To: <216154.80628.qm@web38303.mail.mud.yahoo.com>
References: <216154.80628.qm@web38303.mail.mud.yahoo.com>
Message-ID: <4A9FF4E2.5060802@ufl.edu>

FMH wrote:
> Dear All,
> 
> Could someone please advice me the difference between lme function
> with correlation structure of the residual from AR(1) process and
> without this correlation structure. I found from the help menu shown
> below that if we do not declare any value in corAR1, by default, the
> function will assume there is no autocorrelation i.e. 0.
> 
> Does this meant we can just simply ignore the correlation structure
> in the model and just use a simple command in lme without including
> corAR1? Please correct me if i'm wrong.
> 
> ###################################################################################
>  Usage corAR1(value, form, fixed)
> 
> Arguments value the value of the lag 1 autocorrelation, which must be
> between -1 and 1. Defaults to 0 (no autocorrelation). 
> ###################################################################################
> 

  You're a little confused.  What the help page means is that if you
simply define a "corAR1" object, it will have its autocorrelation
parameter set to zero:

corAR1()

However, when you pass corAR1 to the lme function, it fits the
autocorrelation parameter (changing it to something other than zero).
If you wanted to specify a starting value other than zero for phi, then
you can specify a value.

  Ben Bolker



From bolker at ufl.edu  Fri Sep  4 14:19:34 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 04 Sep 2009 08:19:34 -0400
Subject: [R-sig-ME] correlation structure with AR(1)
In-Reply-To: <170845.77356.qm@web38306.mail.mud.yahoo.com>
References: <216154.80628.qm@web38303.mail.mud.yahoo.com>
	<4A9FF4E2.5060802@ufl.edu>
	<170845.77356.qm@web38306.mail.mud.yahoo.com>
Message-ID: <4AA105D6.4010307@ufl.edu>

FMH wrote:
> Hi,
> 
> Thank you for the advice. In an example from the help menu shown
> below, fm3Dial.gls specify the first value of the autocorrelation
> i.e. 0.771, but after running the script, the new phi occurred which
> was 0.7526038.
> 
> ####################################################################################
> Pinheiro and Bates, pp. 255-258:  use in gls fm1Dial.gls <-  gls(rate
> ~(pressure + I(pressure^2) + I(pressure^3) + I(pressure^4))*QB,
> Dialyzer) fm2Dial.gls <- update(fm1Dial.gls,   weights =
> varPower(form = ~ pressure)) fm3Dial.gls <- update(fm2Dial.gls,
> corr = corAR1(0.771, form = ~ 1 | Subject)) 
> ###################################################################################
> 
> 
> 
> Could you please advice me on the reason of this difference phi?
> 
> Thank you Fir
> 

  Sure.  gls found that the best-fitting phi was 0.752, rather than
0.771.  If you want to keep phi fixed at 0.771  I think you need
... corAR1(0.771,form=~1|Subject,fixed=TRUE) ... See ?corAR1


> ----- Original Message ---- From: Ben Bolker <bolker at ufl.edu> To: FMH
> <kagba2006 at yahoo.com> Cc: "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org> Sent: Thursday, September 3, 2009
> 5:54:58 PM Subject: Re: [R-sig-ME] correlation structure with AR(1)
> 
> FMH wrote:
>> Dear All,
>> 
>> Could someone please advice me the difference between lme function 
>> with correlation structure of the residual from AR(1) process and 
>> without this correlation structure. I found from the help menu
>> shown below that if we do not declare any value in corAR1, by
>> default, the function will assume there is no autocorrelation i.e.
>> 0.
>> 
>> Does this meant we can just simply ignore the correlation structure
>>  in the model and just use a simple command in lme without
>> including corAR1? Please correct me if i'm wrong.
>> 
>> ###################################################################################
>>  Usage corAR1(value, form, fixed)
>> 
>> Arguments value the value of the lag 1 autocorrelation, which must
>> be between -1 and 1. Defaults to 0 (no autocorrelation). 
>> ###################################################################################
>> 
>> 
> 
> You're a little confused.  What the help page means is that if you 
> simply define a "corAR1" object, it will have its autocorrelation 
> parameter set to zero:
> 
> corAR1()
> 
> However, when you pass corAR1 to the lme function, it fits the 
> autocorrelation parameter (changing it to something other than zero).
>  If you wanted to specify a starting value other than zero for phi,
> then you can specify a value.
> 
> Ben Bolker
> 
> 
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Tue Sep  8 09:46:29 2009
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 8 Sep 2009 09:46:29 +0200
Subject: [R-sig-ME] REML and LRT
Message-ID: <077E31A57DA26E46AB0D493C9966AC730FF1153C@UM-MAIL4112.unimaas.nl>

Hello All,

A discussion on r-help got me to think about the following issue.

Suppose we want to conduct a LRT to compare the fit of two nested mixed-effects models differing in their fixed effects. We know that the restricted likelihoods of the two models cannot be directly compared then, so the typical recommendation in the literature is to use ML estimation to fit both models.

However, using REML estimation simply means that the variance components are estimated based on the restricted likelihood (which does not involve any fixed effects) and then plugging the REML estimates of the variance components into the variance-covariance matrix of the observations and using the equation for the ML estimators for the fixed effects (which is just GLS) to estimate those fixed effects.

So, if we look at ML vs REML simply as two different ways of estimating the variance components, then couldn't we simply consider the regular likelihoods of the two models to carry out the LRT even if the variance components have been estimated with REML?

In fact, it was suggested that this is how the anova() function works in lme4. I have not checked this, but I am curious what people think about this issue in general.

Best,

--
Wolfgang Viechtbauer
 Department of Methodology and Statistics
 School for Public Health and Primary Care
 University of Maastricht, The Netherlands
 http://www.wvbauer.com/



From erickson at ucr.edu  Tue Sep  8 17:36:59 2009
From: erickson at ucr.edu (Michael Erickson)
Date: Tue, 8 Sep 2009 08:36:59 -0700
Subject: [R-sig-ME] lme4 mcmcsamp workaround?
Message-ID: <48dc38d30909080836u245cefb7ha9159204bc9556b2@mail.gmail.com>

I have tried searching the archives to find an answer to this
question, but I'm not having much luck.? What I think I have
discovered is that since the release of lme4_0.999375, mcmcsamp() has
not worked for correlated random effects.

I looked at the r-forge site and it seems like this is bug [#68]
"mcmcsamp is broken."  The last update on it was 2008-06-23, and it
did not sound promising.

What are people doing now without mcmcsamp()?  Are they not getting
HPDintervals for correlated random effects?  Are they only using
models with uncorrelated random effects? Have they reverted to a
version that works in some cases, but not when values of a variance
component are near 0?

What I am wondering, is whether or not my life is better not being
able to do this or whether I can use some sort a workaround.  If there
is a workaround, can someone tell me what it is?  I am currently using
lme4_0.999375-31 (and R version 2.9.2, 2009-08-24).  Is there a way to
install an old package that still works?

Thanks!

Michael



From kagba2006 at yahoo.com  Wed Sep  9 14:16:44 2009
From: kagba2006 at yahoo.com (FMH)
Date: Wed, 9 Sep 2009 05:16:44 -0700 (PDT)
Subject: [R-sig-ME] Error message with lme
Message-ID: <356243.24695.qm@web38302.mail.mud.yahoo.com>

Dear All,

I tried to run an R scipt on a set of data with lmList function and it worked fine, but as i tried to run with lme function, the program suddently give a message error. Both script and message error are? shown below

#################################################################################
> dp <- rep(rev(1:11), 261)
> sub1 <- data.frame(sub1, dp, or)
> tmp <- groupedData(Temp ~ dp? | or, data = sub1, FUN = mean, order.groups = TRUE, labels = list(x = "Depth", y = ??? ??? 
??? "Temperature"),? units = list(y = "(0C)"))
> lm.lis1 <- lmList(tmp)
> lm.lme1 <- lme(lm.lis1)

Error in lme.formula(fixed = Temp ~ dp, data = tmp, random = list(or = c(2.45530618001172,? : 
? nlminb problem, convergence error code = 1
? message = iteration limit reached without convergence (9)
#################################################################################

Could?someone advice me the?way to tackle on this problem?

Thank you
Fir






From bates at stat.wisc.edu  Wed Sep  9 15:08:10 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Sep 2009 08:08:10 -0500
Subject: [R-sig-ME] Error message with lme
In-Reply-To: <356243.24695.qm@web38302.mail.mud.yahoo.com>
References: <356243.24695.qm@web38302.mail.mud.yahoo.com>
Message-ID: <40e66e0b0909090608g7cba6a3dr311a44f30f2c1fd9@mail.gmail.com>

On Wed, Sep 9, 2009 at 7:16 AM, FMH <kagba2006 at yahoo.com> wrote:
> Dear All,
>
> I tried to run an R scipt on a set of data with lmList function and it worked fine, but as i tried to run with lme function, the program suddently give a message error. Both script and message error are? shown below
>
> #################################################################################
>> dp <- rep(rev(1:11), 261)
>> sub1 <- data.frame(sub1, dp, or)
>> tmp <- groupedData(Temp ~ dp? | or, data = sub1, FUN = mean, order.groups = TRUE, labels = list(x = "Depth", y =
> ??? "Temperature"),? units = list(y = "(0C)"))
>> lm.lis1 <- lmList(tmp)
>> lm.lme1 <- lme(lm.lis1)
>
> Error in lme.formula(fixed = Temp ~ dp, data = tmp, random = list(or = c(2.45530618001172,? :
> ? nlminb problem, convergence error code = 1
> ? message = iteration limit reached without convergence (9)
> #################################################################################
>
> Could?someone advice me the?way to tackle on this problem?

The first thing to do is to request verbose output to see what the
optimization is doing.  Use control = list(msVerbose = 1) in the call
to lme.

You may meet with more success using lmer from the lme4 package.  The
lmer function is a later design that takes advantage of further
research into linear mixed-effects models.  In particular, if the
problem you are encountering is due to a singular variance-covariance
matrix it will be handled much more effectively in lmer than in lme.



From ledonret at email.unc.edu  Wed Sep  9 16:20:24 2009
From: ledonret at email.unc.edu (ledonret at email.unc.edu)
Date: Wed, 09 Sep 2009 10:20:24 -0400
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and
	bootstrapping	downstream statistics
Message-ID: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>

Dear List,

I have been using R for a couple of years now, but I am very new to the 
lme4 package. I am currently trying to use lmer to analyze a mixed 
model, and also trying to bootstrap some downstream statistics that 
utilize the variance components I am obtaining from this model. 
However, I'm not sure that I am specifying the model correctly, and 
while I have written a function that works with the boot package for 
iterations of up to about 30, it will not work for greater iterations. 
I was hoping you or others could shed some light on these issues!

*I am using lme4 version 0.99375-28 with Mac OS X version 10.5.7

My design is this: I created 9 Families, and I treated these families 
with two diets. Each family by diet combination was replicated 9 times 
(randomized and interspersed). In my model, I am treating Family as a 
random effect, and Diet as a fixed effect. I am mostly concerned with 
determining the variance of the Family by Diet interaction. From 
previous queries, I gathered that the correct specification would be 
this (disregarding replicate)

lmer(SVL ~ Treatment + (1|Family) + (1|Family:Treatment), dataset)

or equivalently

lmer(SVL ~ Treatment + (1|Family/Treatment), dataset)

where "SVL" is my trait. It's a little confusing to me, because in the 
second formula it appears that Treatment is nested in Family, instead 
of being completely crossed with family, but I tried both ways and they 
gave me the same answer, so I was satisfied. However, I'd also like to 
add replicate (Box1) as a nested factor. The way I'd intuitively write 
that,

lmer(SVL ~ Treatment + (1|Family/Treatment/Box1), dataset)

should mean that replicate is completely cross with Family, instead of 
being nested within. The way I tried to deal with this was to make sure 
each replicate had a unique identity... is that sufficient?

My second issue concerned bootstrapping and some errors that I receive 
when trying to use this with an R>30. The function that I am attempting 
to use is a function that I wrote to calculate heritability (I am 
trying to bootstrap my estimate of the heritability of the Diet by 
Treatment interaction).

#The function
> fun<-function(data,i){
+ d<-data[i,]
+ M<-lmer(SVL~Treatment+(1|Family/Box1/Family),d)
+ Mv<-VarCorr(M)
+ varcomps<-c(unlist(lapply(Mv,diag))) #Variance of random factors
+ resid<-(attr(Mv,"sc")^2) #Residual Variance
+ VarTot<-sum(varcomps,resid) #Total variance
+ VarFamTrt<-Mv$`Treatment:Family`[1,1] #Variance for Family by Treatment
+ return((2*VarFamTrt)/VarTot)} #Heritability
#bootstrapping
> Fam.boot<-boot(data,statistic=fun,R=10)
This will work up to about R=30, but beyond that, I get this error message,

Warning message:
In mer_finalize(ans) : singular convergence (7)

I realize this is probably a problem that isn't specific to lmer, but 
it is the first time that I have run into it, so I'm at a loss for what 
to do.

Thank you so much in advance, for any insight you can provide!

Best, Cristina Ledon-Rettig
UNC-Chapel Hill



From andydolman at gmail.com  Wed Sep  9 16:58:21 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 9 Sep 2009 16:58:21 +0200
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and
	bootstrapping downstream statistics
In-Reply-To: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>
References: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>
Message-ID: <951234ac0909090758o23503049nb744dcadd8385a44@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090909/55b68fa4/attachment.pl>

From andydolman at gmail.com  Wed Sep  9 17:17:39 2009
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 9 Sep 2009 17:17:39 +0200
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and
	bootstrapping downstream statistics
In-Reply-To: <20090909110347.apl3ogt5dcs440wc@webmail5.isis.unc.edu>
References: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>
	<951234ac0909090758o23503049nb744dcadd8385a44@mail.gmail.com>
	<20090909110347.apl3ogt5dcs440wc@webmail5.isis.unc.edu>
Message-ID: <951234ac0909090817n2fdbe984ld171c826f3e39c35@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090909/14591690/attachment.pl>

From ledonret at email.unc.edu  Wed Sep  9 17:08:39 2009
From: ledonret at email.unc.edu (ledonret at email.unc.edu)
Date: Wed, 09 Sep 2009 11:08:39 -0400
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and
	bootstrapping	downstream statistics
Message-ID: <20090909110839.6a05ijykz4oss804@webmail5.isis.unc.edu>

I just wanted to correct something in my earlier post,

The function that I used was actually,
#The function
> fun<-function(data,i){
+ d<-data[i,]
+ M<-lmer(SVL~Treatment+(1|Family/Treatment/Box1),d)
+ Mv<-VarCorr(M)
+ varcomps<-c(unlist(lapply(Mv,diag))) #Variance of random factors
+ resid<-(attr(Mv,"sc")^2) #Residual Variance
+ VarTot<-sum(varcomps,resid) #Total variance
+ VarFamTrt<-Mv$`Treatment:Family`[1,1] #Variance for Family by Treatment
+ return((2*VarFamTrt)/VarTot)} #Heritability
#bootstrapping
> Fam.boot<-boot(data,statistic=fun,R=10)

Which still gives me the error message
In mer_finalize(ans) : singular convergence (7)

Sorry about the typo!

Dear List,

I have been using R for a couple of years now, but I am very new to the 
lme4 package. I am currently trying to use lmer to analyze a mixed 
model, and also trying to bootstrap some downstream statistics that 
utilize the variance components I am obtaining from this model. 
However, I'm not sure that I am specifying the model correctly, and 
while I have written a function that works with the boot package for 
iterations of up to about 30, it will not work for greater iterations. 
I was hoping you or others could shed some light on these issues!

*I am using lme4 version 0.99375-28 with Mac OS X version 10.5.7

My design is this: I created 9 Families, and I treated these families 
with two diets. Each family by diet combination was replicated 9 times 
(randomized and interspersed). In my model, I am treating Family as a 
random effect, and Diet as a fixed effect. I am mostly concerned with 
determining the variance of the Family by Diet interaction. From 
previous queries, I gathered that the correct specification would be 
this (disregarding replicate)

lmer(SVL ~ Treatment + (1|Family) + (1|Family:Treatment), dataset)

or equivalently

lmer(SVL ~ Treatment + (1|Family/Treatment), dataset)

where "SVL" is my trait. It's a little confusing to me, because in the 
second formula it appears that Treatment is nested in Family, instead 
of being completely crossed with family, but I tried both ways and they 
gave me the same answer, so I was satisfied. However, I'd also like to 
add replicate (Box1) as a nested factor. The way I'd intuitively write 
that,

lmer(SVL ~ Treatment + (1|Family/Treatment/Box1), dataset)

should mean that replicate is completely cross with Family, instead of 
being nested within. The way I tried to deal with this was to make sure 
each replicate had a unique identity... is that sufficient?

My second issue concerned bootstrapping and some errors that I receive 
when trying to use this with an R>30. The function that I am attempting 
to use is a function that I wrote to calculate heritability (I am 
trying to bootstrap my estimate of the heritability of the Diet by 
Treatment interaction).

#The function
> fun<-function(data,i){
+ d<-data[i,]
+ M<-lmer(SVL~Treatment+(1|Family/Box1/Family),d)
+ Mv<-VarCorr(M)
+ varcomps<-c(unlist(lapply(Mv,diag))) #Variance of random factors
+ resid<-(attr(Mv,"sc")^2) #Residual Variance
+ VarTot<-sum(varcomps,resid) #Total variance
+ VarFamTrt<-Mv$`Treatment:Family`[1,1] #Variance for Family by Treatment
+ return((2*VarFamTrt)/VarTot)} #Heritability
#bootstrapping
> Fam.boot<-boot(data,statistic=fun,R=10)
This will work up to about R=30, but beyond that, I get this error message,

Warning message:
In mer_finalize(ans) : singular convergence (7)

I realize this is probably a problem that isn't specific to lmer, but 
it is the first time that I have run into it, so I'm at a loss for what 
to do.

Thank you so much in advance, for any insight you can provide!

Best, Cristina Ledon-Rettig
UNC-Chapel Hill



From bates at stat.wisc.edu  Wed Sep  9 20:36:04 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Sep 2009 13:36:04 -0500
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and
	bootstrapping downstream statistics
In-Reply-To: <951234ac0909090758o23503049nb744dcadd8385a44@mail.gmail.com>
References: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>
	<951234ac0909090758o23503049nb744dcadd8385a44@mail.gmail.com>
Message-ID: <40e66e0b0909091136p7716e164y7bd526e16967f3f6@mail.gmail.com>

On Wed, Sep 9, 2009 at 9:58 AM, Andrew Dolman <andydolman at gmail.com> wrote:
> andydolman at gmail.com
>
>
> 2009/9/9 <ledonret at email.unc.edu>
>
>> Dear List,
>>
>> I have been using R for a couple of years now, but I am very new to the
>> lme4 package. I am currently trying to use lmer to analyze a mixed model,
>> and also trying to bootstrap some downstream statistics that utilize the
>> variance components I am obtaining from this model. However, I'm not sure
>> that I am specifying the model correctly, and while I have written a
>> function that works with the boot package for iterations of up to about 30,
>> it will not work for greater iterations. I was hoping you or others could
>> shed some light on these issues!
>>
>> *I am using lme4 version 0.99375-28 with Mac OS X version 10.5.7
>>
>> My design is this: I created 9 Families, and I treated these families with
>> two diets. Each family by diet combination was replicated 9 times
>> (randomized and interspersed). In my model, I am treating Family as a random
>> effect, and Diet as a fixed effect. I am mostly concerned with determining
>> the variance of the Family by Diet interaction. From previous queries, I
>> gathered that the correct specification would be this (disregarding
>> replicate)
>>
>> lmer(SVL ~ Treatment + (1|Family) + (1|Family:Treatment), dataset)
>>
>> or equivalently
>>
>> lmer(SVL ~ Treatment + (1|Family/Treatment), dataset)
>>
>> where "SVL" is my trait. It's a little confusing to me, because in the
>> second formula it appears that Treatment is nested in Family, instead of
>> being completely crossed with family, but I tried both ways and they gave me
>> the same answer, so I was satisfied.
>
>
>
> Both these specifications are for nested models, for crossed you want
>
> lmer(SVL ~ Treatment + (1|Family) + (1|Treatment), dataset)
>
>
> But you've only got 2 levels of Treatment so it's probably not suitable to
> treat it as random, particularly as you want to use the variance components.
>
>
>
>
>> However, I'd also like to add replicate (Box1) as a nested factor. The way
>> I'd intuitively write that,
>>
>> lmer(SVL ~ Treatment + (1|Family/Treatment/Box1), dataset)
>>
>> should mean that replicate is completely cross with Family, instead of
>> being nested within. The way I tried to deal with this was to make sure each
>> replicate had a unique identity... is that sufficient?
>>
>>
>
> To nest Box in e.g. Treatment you'd do
>
> lmer(SVL ~ Treatment + (1|Family) + (1|Treatment/Box1), dataset)
>
> if that's what you want to do.

Actually it would be

lmer(SVL ~ Treatment + (1|Family) + (1|Treatment:Box1), dataset)

so that you don't try to model Treatment as both a fixed effect and a
random effect.  A term like (1|Treatment/Box1) expands to
(1|Treatment) + (1|Treatment:Box1)

In fact, if the levels of Box1 are defined so that they are distinct
both within and between treatments you can write the model as

lmer(SVL ~ Treatment + (1|Family) + (1|Box1), dataset)

The nesting of Box1 within Treatment can be discovered from the data
as long as the levels of Box1 are defined as described above.

>
>
>
>
>
>> My second issue concerned bootstrapping and some errors that I receive when
>> trying to use this with an R>30. The function that I am attempting to use is
>> a function that I wrote to calculate heritability (I am trying to bootstrap
>> my estimate of the heritability of the Diet by Treatment interaction).
>>
>> #The function
>>
>>> fun<-function(data,i){
>>>
>> + d<-data[i,]
>> + M<-lmer(SVL~Treatment+(1|Family/Box1/Family),d)
>>
>
> family is nested in family here - probably not at all what you want
>
>
>
>
>> + Mv<-VarCorr(M)
>> + varcomps<-c(unlist(lapply(Mv,diag))) #Variance of random factors
>> + resid<-(attr(Mv,"sc")^2) #Residual Variance
>> + VarTot<-sum(varcomps,resid) #Total variance
>> + VarFamTrt<-Mv$`Treatment:Family`[1,1] #Variance for Family by Treatment
>> + return((2*VarFamTrt)/VarTot)} #Heritability
>> #bootstrapping
>>
>>> Fam.boot<-boot(data,statistic=fun,R=10)
>>>
>> This will work up to about R=30, but beyond that, I get this error message,
>>
>> Warning message:
>> In mer_finalize(ans) : singular convergence (7)
>>
>> I realize this is probably a problem that isn't specific to lmer, but it is
>> the first time that I have run into it, so I'm at a loss for what to do.
>>
>> Thank you so much in advance, for any insight you can provide!
>>
>> Best, Cristina Ledon-Rettig
>> UNC-Chapel Hill
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ledonret at email.unc.edu  Thu Sep 10 01:20:44 2009
From: ledonret at email.unc.edu (ledonret at email.unc.edu)
Date: Wed, 09 Sep 2009 19:20:44 -0400
Subject: [R-sig-ME] Specifying Crossed vs. Nested Factors with Lmer and	
	bootstrapping downstream statistics
In-Reply-To: <40e66e0b0909091136p7716e164y7bd526e16967f3f6@mail.gmail.com>
References: <20090909102024.anm4whs0g0ww80cw@webmail5.isis.unc.edu>
	<951234ac0909090758o23503049nb744dcadd8385a44@mail.gmail.com>
	<40e66e0b0909091136p7716e164y7bd526e16967f3f6@mail.gmail.com>
Message-ID: <20090909192044.so2gyiu9gcck448k@webmail5.isis.unc.edu>

Quoting Douglas Bates <bates at stat.wisc.edu>:

> On Wed, Sep 9, 2009 at 9:58 AM, Andrew Dolman <andydolman at gmail.com> wrote:
>> andydolman at gmail.com
>>
>>
>> 2009/9/9 <ledonret at email.unc.edu>
>>
>>> Dear List,
>>>
>>> I have been using R for a couple of years now, but I am very new to the
>>> lme4 package. I am currently trying to use lmer to analyze a mixed model,
>>> and also trying to bootstrap some downstream statistics that utilize the
>>> variance components I am obtaining from this model. However, I'm not sure
>>> that I am specifying the model correctly, and while I have written a
>>> function that works with the boot package for iterations of up to about 30,
>>> it will not work for greater iterations. I was hoping you or others could
>>> shed some light on these issues!
>>>
>>> *I am using lme4 version 0.99375-28 with Mac OS X version 10.5.7
>>>
>>> My design is this: I created 9 Families, and I treated these families with
>>> two diets. Each family by diet combination was replicated 9 times
>>> (randomized and interspersed). In my model, I am treating Family as 
>>> a random
>>> effect, and Diet as a fixed effect. I am mostly concerned with determining
>>> the variance of the Family by Diet interaction. From previous queries, I
>>> gathered that the correct specification would be this (disregarding
>>> replicate)
>>>
>>> lmer(SVL ~ Treatment + (1|Family) + (1|Family:Treatment), dataset)
>>>
>>> or equivalently
>>>
>>> lmer(SVL ~ Treatment + (1|Family/Treatment), dataset)
>>>
>>> where "SVL" is my trait. It's a little confusing to me, because in the
>>> second formula it appears that Treatment is nested in Family, instead of
>>> being completely crossed with family, but I tried both ways and 
>>> they gave me
>>> the same answer, so I was satisfied.
>>
>>
>>
>> Both these specifications are for nested models, for crossed you want
>>
>> lmer(SVL ~ Treatment + (1|Family) + (1|Treatment), dataset)
>>
>>
>> But you've only got 2 levels of Treatment so it's probably not suitable to
>> treat it as random, particularly as you want to use the variance components.
>>
>>
>>
>>
>>> However, I'd also like to add replicate (Box1) as a nested factor. The way
>>> I'd intuitively write that,
>>>
>>> lmer(SVL ~ Treatment + (1|Family/Treatment/Box1), dataset)
>>>
>>> should mean that replicate is completely cross with Family, instead of
>>> being nested within. The way I tried to deal with this was to make 
>>> sure each
>>> replicate had a unique identity... is that sufficient?
>>>
>>>
>>
>> To nest Box in e.g. Treatment you'd do
>>
>> lmer(SVL ~ Treatment + (1|Family) + (1|Treatment/Box1), dataset)
>>
>> if that's what you want to do.
>
> Actually it would be
>
> lmer(SVL ~ Treatment + (1|Family) + (1|Treatment:Box1), dataset)
>
> so that you don't try to model Treatment as both a fixed effect and a
> random effect.  A term like (1|Treatment/Box1) expands to
> (1|Treatment) + (1|Treatment:Box1)
>
> In fact, if the levels of Box1 are defined so that they are distinct
> both within and between treatments you can write the model as
>
> lmer(SVL ~ Treatment + (1|Family) + (1|Box1), dataset)
>
> The nesting of Box1 within Treatment can be discovered from the data
> as long as the levels of Box1 are defined as described above.

Thank you for your reply, Dr. Bates.

I think I understand now - my replicates (Box1) are distinct both 
within and between treatments, so in order to have a model that 
includes Treatment as a fixed effect, family as a random effect, and 
the family by treatment interaction as a random effect, I would use,

lmer(SVL ~ Treatment + (1|Family/Treatment)+(1|Box1), dataset)

which expands to

lmer(SVL ~ Treatment + (1|Family) + (1|Family:Treatment) + (1|Box1), dataset)

Cris

>
>>
>>
>>
>>
>>
>>> My second issue concerned bootstrapping and some errors that I receive when
>>> trying to use this with an R>30. The function that I am attempting 
>>> to use is
>>> a function that I wrote to calculate heritability (I am trying to bootstrap
>>> my estimate of the heritability of the Diet by Treatment interaction).
>>>
>>> #The function
>>>
>>>> fun<-function(data,i){
>>>>
>>> + d<-data[i,]
>>> + M<-lmer(SVL~Treatment+(1|Family/Box1/Family),d)
>>>
>>
>> family is nested in family here - probably not at all what you want
>>
>>
>>
>>
>>> + Mv<-VarCorr(M)
>>> + varcomps<-c(unlist(lapply(Mv,diag))) #Variance of random factors
>>> + resid<-(attr(Mv,"sc")^2) #Residual Variance
>>> + VarTot<-sum(varcomps,resid) #Total variance
>>> + VarFamTrt<-Mv$`Treatment:Family`[1,1] #Variance for Family by Treatment
>>> + return((2*VarFamTrt)/VarTot)} #Heritability
>>> #bootstrapping
>>>
>>>> Fam.boot<-boot(data,statistic=fun,R=10)
>>>>
>>> This will work up to about R=30, but beyond that, I get this error message,
>>>
>>> Warning message:
>>> In mer_finalize(ans) : singular convergence (7)
>>>
>>> I realize this is probably a problem that isn't specific to lmer, but it is
>>> the first time that I have run into it, so I'm at a loss for what to do.
>>>
>>> Thank you so much in advance, for any insight you can provide!
>>>
>>> Best, Cristina Ledon-Rettig
>>> UNC-Chapel Hill
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From tobias.verbeke at gmail.com  Thu Sep 10 12:20:12 2009
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Thu, 10 Sep 2009 12:20:12 +0200
Subject: [R-sig-ME] lme vs. lm subset argument behaviour
Message-ID: <f00f59370909100320g4920f35ycd86a16682c450ea@mail.gmail.com>

Dear list,

I came across a difference in how lme and lm respond
to the subset argument.

I must be overlooking something obvious. Any idea ?

Many thanks in advance,
Tobias

### plain statements
library(nlme)
lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1)
keepValues <- rep(TRUE, nrow(Orthodont))
keepValues[32] <- FALSE
lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1,
subset = keepValues)
# no Error

### inside function
lmeTest <- function(x, keepValues = NULL){
  keepV <- if (is.null(keepValues)) rep(TRUE, nrow(x)) else keepValues
  lme(fixed = distance ~ age + Sex, data = x, random = ~1, subset = keepV)
}

lmeTest(x = Orthodont)
# Error in eval(expr, envir, enclos) : object 'keepV' not found

### same scenario using lm instead of lme
retainValues <- rep(TRUE, nrow(cars))
retainValues[5] <- FALSE
lm(dist ~ speed, cars, subset = retainValues)

testLm <- function(x, retainValues = NULL){
  retainV <- if (is.null(retainValues)) rep(TRUE, nrow(x)) else retainValues
  lm(speed ~ dist, data = cars,  subset = retainV)
}

testLm(x = cars) # no Error
testLm(x = cars, retainValues = retainValues) # no Error

sessionInfo()
# R version 2.9.2 (2009-08-24)
# x86_64-pc-linux-gnu
#
# locale:
# en_US.UTF-8
#
# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base
#
# other attached packages:
# [1] nlme_3.1-94
#
# loaded via a namespace (and not attached):
# [1] grid_2.9.2      lattice_0.17-25



From tobias.verbeke at gmail.com  Thu Sep 10 12:26:52 2009
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Thu, 10 Sep 2009 12:26:52 +0200
Subject: [R-sig-ME] lme vs. lm subset argument behaviour
In-Reply-To: <f00f59370909100320g4920f35ycd86a16682c450ea@mail.gmail.com>
References: <f00f59370909100320g4920f35ycd86a16682c450ea@mail.gmail.com>
Message-ID: <f00f59370909100326o43dc5edfib39718017b5483ee@mail.gmail.com>

There is a small error in my code below,
but it seems not to affect the difference
in behaviour observed.

On Thu, Sep 10, 2009 at 12:20 PM, Tobias Verbeke
<tobias.verbeke at gmail.com> wrote:
> Dear list,
>
> I came across a difference in how lme and lm respond
> to the subset argument.
>
> I must be overlooking something obvious. Any idea ?
>
> Many thanks in advance,
> Tobias
>
> ### plain statements
> library(nlme)
> lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1)
> keepValues <- rep(TRUE, nrow(Orthodont))
> keepValues[32] <- FALSE
> lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1,
> subset = keepValues)
> # no Error
>
> ### inside function
> lmeTest <- function(x, keepValues = NULL){
> ?keepV <- if (is.null(keepValues)) rep(TRUE, nrow(x)) else keepValues
> ?lme(fixed = distance ~ age + Sex, data = x, random = ~1, subset = keepV)
> }
>
> lmeTest(x = Orthodont)
> # Error in eval(expr, envir, enclos) : object 'keepV' not found
>
> ### same scenario using lm instead of lme
> retainValues <- rep(TRUE, nrow(cars))
> retainValues[5] <- FALSE
> lm(dist ~ speed, cars, subset = retainValues)
>
> testLm <- function(x, retainValues = NULL){
> ?retainV <- if (is.null(retainValues)) rep(TRUE, nrow(x)) else retainValues
> ?lm(speed ~ dist, data = cars, ?subset = retainV)
> }

testLm <- function(x, retainValues = NULL){
  retainV <- if (is.null(retainValues)) rep(TRUE, nrow(x)) else retainValues
  lm(speed ~ dist, data = x,  subset = retainV)   # <--- x not cars
}

Best,
Tobias

> testLm(x = cars) # no Error
> testLm(x = cars, retainValues = retainValues) # no Error
>
> sessionInfo()
> # R version 2.9.2 (2009-08-24)
> # x86_64-pc-linux-gnu
> #
> # locale:
> # en_US.UTF-8
> #
> # attached base packages:
> # [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
> #
> # other attached packages:
> # [1] nlme_3.1-94
> #
> # loaded via a namespace (and not attached):
> # [1] grid_2.9.2 ? ? ?lattice_0.17-25
>



From bates at stat.wisc.edu  Sat Sep 12 00:03:46 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 11 Sep 2009 17:03:46 -0500
Subject: [R-sig-ME] lme vs. lm subset argument behaviour
In-Reply-To: <f00f59370909100326o43dc5edfib39718017b5483ee@mail.gmail.com>
References: <f00f59370909100320g4920f35ycd86a16682c450ea@mail.gmail.com>
	<f00f59370909100326o43dc5edfib39718017b5483ee@mail.gmail.com>
Message-ID: <40e66e0b0909111503i7757b5e0kc73cd44d5c43a554@mail.gmail.com>

It's a known problem caused by the fact that we didn't know what
Thomas Lumley calls "the standard non-standard evaluation" used by the
model.frame function.  The initial version of the nlme package was
written for S and the evaluation model in S and S-PLUS is different
from that in R.  Most model-fitting functions in R evaluate the model
frame by re-writing the call to the function itself as a call to
model.frame and evaluating it the parent environment.  That is how you
can get all the weird combinations of arguments to work.  The lme and
nlme functions do not do this, in part because there can be multiple
formulas to evaluate (this was one reason that the design of lmer uses
just one formula).

I would suggest using lmer if you can, rather than lme, if you are
going to do something tricky on having a call to lme generated within
another function.

On Thu, Sep 10, 2009 at 5:26 AM, Tobias Verbeke
<tobias.verbeke at gmail.com> wrote:
> There is a small error in my code below,
> but it seems not to affect the difference
> in behaviour observed.
>
> On Thu, Sep 10, 2009 at 12:20 PM, Tobias Verbeke
> <tobias.verbeke at gmail.com> wrote:
>> Dear list,
>>
>> I came across a difference in how lme and lm respond
>> to the subset argument.
>>
>> I must be overlooking something obvious. Any idea ?
>>
>> Many thanks in advance,
>> Tobias
>>
>> ### plain statements
>> library(nlme)
>> lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1)
>> keepValues <- rep(TRUE, nrow(Orthodont))
>> keepValues[32] <- FALSE
>> lme(fixed = distance ~ age + Sex, data = Orthodont, random = ~1,
>> subset = keepValues)
>> # no Error
>>
>> ### inside function
>> lmeTest <- function(x, keepValues = NULL){
>> ?keepV <- if (is.null(keepValues)) rep(TRUE, nrow(x)) else keepValues
>> ?lme(fixed = distance ~ age + Sex, data = x, random = ~1, subset = keepV)
>> }
>>
>> lmeTest(x = Orthodont)
>> # Error in eval(expr, envir, enclos) : object 'keepV' not found
>>
>> ### same scenario using lm instead of lme
>> retainValues <- rep(TRUE, nrow(cars))
>> retainValues[5] <- FALSE
>> lm(dist ~ speed, cars, subset = retainValues)
>>
>> testLm <- function(x, retainValues = NULL){
>> ?retainV <- if (is.null(retainValues)) rep(TRUE, nrow(x)) else retainValues
>> ?lm(speed ~ dist, data = cars, ?subset = retainV)
>> }
>
> testLm <- function(x, retainValues = NULL){
> ?retainV <- if (is.null(retainValues)) rep(TRUE, nrow(x)) else retainValues
> ?lm(speed ~ dist, data = x, ?subset = retainV) ? # <--- x not cars
> }
>
> Best,
> Tobias
>
>> testLm(x = cars) # no Error
>> testLm(x = cars, retainValues = retainValues) # no Error
>>
>> sessionInfo()
>> # R version 2.9.2 (2009-08-24)
>> # x86_64-pc-linux-gnu
>> #
>> # locale:
>> # en_US.UTF-8
>> #
>> # attached base packages:
>> # [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> #
>> # other attached packages:
>> # [1] nlme_3.1-94
>> #
>> # loaded via a namespace (and not attached):
>> # [1] grid_2.9.2 ? ? ?lattice_0.17-25
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From juliet.hannah at gmail.com  Sat Sep 12 05:25:15 2009
From: juliet.hannah at gmail.com (Juliet Hannah)
Date: Fri, 11 Sep 2009 23:25:15 -0400
Subject: [R-sig-ME] literature suggestions regarding residuals in mixed
	models
Message-ID: <93d6f2a80909112025r6071fb2dubeb91b12b1d9eae8@mail.gmail.com>

Hi List,

I have a general question regarding mixed models.

Consider ordinary regression.

If we have a model y ~ x1 + x2. We can fit this in stages
by regressing y on x1, and x1 on x2, and then regressing
the first residuals on the second.

And if x1 is unrelated to other covariates, we can approximate
the regression by removing the effects of all covariates, and then
regressing the residuals on x1.

My question is, I would like to understand what I
can remove in the mixed model setting (as an approximation) --
any fixed or random effects?

Does anyone know of any specific references? I haven't had any
luck in my search.

Thanks for your time.

Regards,

Juliet



From raldo.kruger at gmail.com  Sun Sep 13 13:55:55 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Sun, 13 Sep 2009 13:55:55 +0200
Subject: [R-sig-ME] Help with glmer {lme4} function: how to return F or t
	statistics instead of z statistics?
Message-ID: <30406dd0909130455r700d6debw4eac4ad0e935dd93@mail.gmail.com>

Hi,

I'm new to R and GLMMs, and I've been unable to find the answers to my
questions by trawling through the R help archives. I'm hoping someone
here can help me.
I'm running an analysis on Seedling survival (count data=Poisson
distribution) on restoration sites, and my main interest is in
determining whether the Nutrients (N) and water absorbing polymer Gel
(G) additions to the soil substrate contribute positively to the
survival of the seedlings, over a 3 year time period (for simplicity
I'm just using 3 time periods, each in the same season for the 3
successive years).
Fixed factors: Nutrients (0 and 1), Gel (0 and 1)
Random factors: Site (4 non replicate sites), Year (3 time periods)
Response variable: Seedling numbers (counts) / 0.25m2 plot

According to the decision tree on page 131 in Bolker et al. (2008, in
TREE; thanks, very useful paper!), most of my data sets should be
analysed with Laplace or GHQ model with Wald t or F statistic (since
it is non-normal, can?t be transformed to normality, has a mean <  5,
has less than 3 random effects, and is overdispersed). I?m using the
glmer {lme4} function, since it allows for Laplace or GHQ, as well as
more than one random factor (glmmML {glmmML) and glmPQL {MASS}
apparently does not), as follows:
> m1<-glmer(Seedlings~N*G*(1|Year)*(1|Site), data=ex5m, family=poisson(link="log"))

My questions are:
1)      The model returns Z values, and I?m unable to find an argument in
the function where this can be changed to return a t or F value (as
Bolker et al. suggests I should use for my data).
2)      I?m unsure what the AIC or QAIC value means, other than knowing
that it should be as low as possible. Is there a rule of thumb of what
is a good AIC value? Mine are in the region of 2230.
3)      The default in glmer {lme4) for the argument  nAGQ = 1, which uses
the Laplace approximation. When nAGQ >1, it uses the GHQ method, but
I?m unsure how to determine the correct number of Gauss-Hermite points
to enter in the argument when using this method.  How is this
determined?
4)      Some of my data sets have means >5, and are also overdispersed, and
according to Bolker et al. should be analysed using a GLMM with PQL
and a Wald t or F. However, the glmmPQL {glmmPQL} does not accept more
than one random factor, and I have two, so how do I deal with that?
5) Lastly, what does the "1" imply in the random factor term, e.g.
(1|Site), and how does this affect the analysis?

Many thanks,
Raldo Kruger
MSc Student
Unversity of Cape Town
South Africa



From wkmor1 at gmail.com  Mon Sep 14 03:57:46 2009
From: wkmor1 at gmail.com (Will Morris)
Date: Mon, 14 Sep 2009 11:57:46 +1000
Subject: [R-sig-ME] Help with glmer {lme4} function: how to return F or
	t statistics instead of z statistics?
In-Reply-To: <30406dd0909130455r700d6debw4eac4ad0e935dd93@mail.gmail.com>
References: <30406dd0909130455r700d6debw4eac4ad0e935dd93@mail.gmail.com>
Message-ID: <a5dabfa60909131857g647aaald2198ad646f3acc2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090914/28e6c609/attachment.pl>

From bolker at ufl.edu  Mon Sep 14 04:09:24 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 13 Sep 2009 22:09:24 -0400
Subject: [R-sig-ME] Help with glmer {lme4} function: how to return F or
 t	statistics instead of z statistics?
In-Reply-To: <30406dd0909130455r700d6debw4eac4ad0e935dd93@mail.gmail.com>
References: <30406dd0909130455r700d6debw4eac4ad0e935dd93@mail.gmail.com>
Message-ID: <4AADA5D4.6030904@ufl.edu>

Raldo Kruger wrote:
> Hi,
> 
> I'm new to R and GLMMs, and I've been unable to find the answers to my
> questions by trawling through the R help archives. I'm hoping someone
> here can help me.
> I'm running an analysis on Seedling survival (count data=Poisson
> distribution) on restoration sites, and my main interest is in
> determining whether the Nutrients (N) and water absorbing polymer Gel
> (G) additions to the soil substrate contribute positively to the
> survival of the seedlings, over a 3 year time period (for simplicity
> I'm just using 3 time periods, each in the same season for the 3
> successive years).
> Fixed factors: Nutrients (0 and 1), Gel (0 and 1)
> Random factors: Site (4 non replicate sites), Year (3 time periods)
> Response variable: Seedling numbers (counts) / 0.25m2 plot
> 
> According to the decision tree on page 131 in Bolker et al. (2008, in
> TREE; thanks, very useful paper!), most of my data sets should be
> analysed with Laplace or GHQ model with Wald t or F statistic (since
> it is non-normal, can?t be transformed to normality, has a mean <  5,
> has less than 3 random effects, and is overdispersed). I?m using the
> glmer {lme4} function, since it allows for Laplace or GHQ, as well as
> more than one random factor (glmmML {glmmML) and glmPQL {MASS}
> apparently does not), as follows:
>> m1<-glmer(Seedlings~N*G*(1|Year)*(1|Site), data=ex5m, family=poisson(link="log"))
> 
> My questions are:
> 1)      The model returns Z values, and I?m unable to find an argument in
> the function where this can be changed to return a t or F value (as
> Bolker et al. suggests I should use for my data).

   The "t statistic" and the "Z statistic" are the same (coefficient
divided by [the estimate of] its standard error) ... the difference is
whether you test the null hypothesis with dnorm or dt ...

> 2)      I?m unsure what the AIC or QAIC value means, other than knowing
> that it should be as low as possible. Is there a rule of thumb of what
> is a good AIC value? Mine are in the region of 2230.

  see the other answer in this thread.

> 3)      The default in glmer {lme4) for the argument  nAGQ = 1, which uses
> the Laplace approximation. When nAGQ >1, it uses the GHQ method, but
> I?m unsure how to determine the correct number of Gauss-Hermite points
> to enter in the argument when using this method.  How is this
> determined?

   Try increasing it until the answers don't change much.  I have often
found that nAGQ=5 is sufficient, but if you've got noisy data and fairly
wide confidence intervals even the difference between Laplace and GHQ
may be swamped by the noise in your data.


> 4)      Some of my data sets have means >5, and are also overdispersed, and
> according to Bolker et al. should be analysed using a GLMM with PQL
> and a Wald t or F. However, the glmmPQL {glmmPQL} does not accept more
> than one random factor, and I have two, so how do I deal with that?

   Laplace/AGQ are probably *better* than GLMM/PQL in any case -- it's
just "acceptable" to use GLMM/PQL (and makes some things easier --
GLMM/PQL is much more flexible, faster, etc.) in the means>5 case.

> 5) Lastly, what does the "1" imply in the random factor term, e.g.
> (1|Site), and how does this affect the analysis?
> 
> Many thanks,
> Raldo Kruger
> MSc Student
> Unversity of Cape Town
> South Africa
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From kagba2006 at yahoo.com  Mon Sep 14 12:19:38 2009
From: kagba2006 at yahoo.com (FMH)
Date: Mon, 14 Sep 2009 03:19:38 -0700 (PDT)
Subject: [R-sig-ME] Error message with lme
In-Reply-To: <40e66e0b0909090608g7cba6a3dr311a44f30f2c1fd9@mail.gmail.com>
References: <356243.24695.qm@web38302.mail.mud.yahoo.com>
	<40e66e0b0909090608g7cba6a3dr311a44f30f2c1fd9@mail.gmail.com>
Message-ID: <223436.79045.qm@web38307.mail.mud.yahoo.com>

Thank you



----- Original Message ----
From: Douglas Bates <bates at stat.wisc.edu>
To: FMH <kagba2006 at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Wednesday, September 9, 2009 2:08:10 PM
Subject: Re: [R-sig-ME] Error message with lme

On Wed, Sep 9, 2009 at 7:16 AM, FMH <kagba2006 at yahoo.com> wrote:
> Dear All,
>
> I tried to run an R scipt on a set of data with lmList function and it worked fine, but as i tried to run with lme function, the program suddently give a message error. Both script and message error are? shown below
>
> #################################################################################
>> dp <- rep(rev(1:11), 261)
>> sub1 <- data.frame(sub1, dp, or)
>> tmp <- groupedData(Temp ~ dp? | or, data = sub1, FUN = mean, order.groups = TRUE, labels = list(x = "Depth", y =
> ??? "Temperature"),? units = list(y = "(0C)"))
>> lm.lis1 <- lmList(tmp)
>> lm.lme1 <- lme(lm.lis1)
>
> Error in lme.formula(fixed = Temp ~ dp, data = tmp, random = list(or = c(2.45530618001172,? :
> ? nlminb problem, convergence error code = 1
> ? message = iteration limit reached without convergence (9)
> #################################################################################
>
> Could?someone advice me the?way to tackle on this problem?

The first thing to do is to request verbose output to see what the
optimization is doing.? Use control = list(msVerbose = 1) in the call
to lme.

You may meet with more success using lmer from the lme4 package.? The
lmer function is a later design that takes advantage of further
research into linear mixed-effects models.? In particular, if the
problem you are encountering is due to a singular variance-covariance
matrix it will be handled much more effectively in lmer than in lme.







From kubovy at virginia.edu  Tue Sep 15 05:30:35 2009
From: kubovy at virginia.edu (Michael Kubovy)
Date: Mon, 14 Sep 2009 23:30:35 -0400
Subject: [R-sig-ME] lme4 under 64 bit (Snow Leopard)
Message-ID: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>

Here is my session:

R version 2.9.2 Patched (2009-09-05 r49613)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.28 (5399) x86_64-apple-darwin9.8.0]

Error in library.dynam(lib, package, package.lib) :
   shared library 'lme4' not found
[Workspace restored from /.RData]

trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/ 
lme4_0.999375-31.tar.gz'
Content type 'application/x-gzip' length 839548 bytes (819 Kb)
opened URL
==================================================
downloaded 819 Kb

* Installing *source* package ?lme4? ...
** libs
** arch - i386
sh: make: command not found
ERROR: compilation failed for package ?lme4?
* Removing ?/Library/Frameworks/R.framework/Versions/2.9/Resources/ 
library/lme4?
* Restoring previous ?/Library/Frameworks/R.framework/Versions/2.9/ 
Resources/library/lme4?

The downloaded packages are in
	?/private/var/folders/TG/TG6nWu2pHYCI-BdWWiyMxU+++TI/-Tmp-/Rtmprhnu6K/ 
downloaded_packages?
 > require(lme4)
Loading required package: lme4
Error: package 'lme4' is not installed for 'arch=x86_64'
In addition: Warning message:
In install.packages(c("lme4"), lib = "/Library/Frameworks/R.framework/ 
Resources/library/",  :
   installation of package 'lme4' had non-zero exit status



From t.bishop at usyd.edu.au  Tue Sep 15 05:57:12 2009
From: t.bishop at usyd.edu.au (Thomas Bishop)
Date: Tue, 15 Sep 2009 13:57:12 +1000
Subject: [R-sig-ME] Fitting a fixed effect model while modelling correlation
	in the residuals in 2 directions
Message-ID: <54C44B5E31101D4B8D2B32179CBE49778B41CC@EXPRSV03.mcs.usyd.edu.au>



Dear R users,

I have recently started to use the nlme and lme4 packages for fitting
mixed effects models.  Previously I used Genstat for doing this.
Current I am struggling with analysing an experiment while modelling the
correlation in the residual term in two directions, along rows and down
columns.  

The data is below.  It is an agricultural experiment with variety as a
fixed effect and yield as the response.  The experiment was laid out as
a lattice square design but I wish to ignore this blocking structure and
model the spatial correlation in the residuals.  The layout is 10 rows
by 15 columns of plots, each planted with a different variety.  I wish
to model the correlation with an AR(1) model.

I have below example code based on the nlme package.

I can model correlation in 1 direction and get the same results as I do
with Genstat.

slate.ar1 <- gls(Yield~as.factor(Variety),corr = corAR1(form = ~
1|FieldRow),data=Slate)

summary(slate.ar1)

#Generalized least squares fit by REML
#  Model: Yield ~ as.factor(Variety) 
#  Data: Slate 
#       AIC     BIC    logLik
#  552.6045 628.969 -249.3022
#
#Correlation Structure: AR(1)
# Formula: ~1 | FieldRow 
# Parameter estimate(s):
#      Phi 
#0.7325946 

But to model spatial correlation in 2 directions along rows (FieldRow)
and down columns (Field Column) I get an error message.  

slate.ar1*ar1 <- gls(Yield~as.factor(Variety),corr = corAR1(form = ~
1|(FieldRow+FieldColumn),data=Slate))

#Error in corAR1(form = ~1 | (FieldRow + FieldColumn), data = Slate) : 
#  unused argument(s) (data = Slate)

Thank you for any advice you can give.

Tom



Data:

Variety	Yield	FieldRow	FieldColumn
1	10.03	1	1
2	13.56	1	2
4	14.12	1	3
3	12.39	1	4
5	15.08	1	5
19	19.67	1	6
23	15.72	1	7
2	19.69	1	8
6	17.47	1	9
15	15.98	1	10
18	16.3	1	11
25	16.33	1	12
9	12.55	1	13
11	12.77	1	14
2	15.72	1	15
6	15.31	2	1
7	15.4	2	2
9	12.5	2	3
8	16.58	2	4
10	11.85	2	5
8	16.05	2	6
12	15.5	2	7
16	15	2	8
25	16.42	2	9
4	15.04	2	10
5	16.8	2	11
7	15.26	2	12
16	14.52	2	13
23	14.8	2	14
14	14.82	2	15
21	11.26	3	1
22	14	3	2
24	13.29	3	3
23	12.87	3	4
25	15.55	3	5
11	13.95	3	6
20	16.96	3	7
24	15.7	3	8
3	14.04	3	9
7	12.85	3	10
6	14.73	3	11
13	17.61	3	12
22	16.95	3	13
4	13.64	3	14
20	17.9	3	15
11	12.61	4	1
12	14.23	4	2
14	11.1	4	3
13	17.35	4	4
15	16.17	4	5
22	18.2	4	6
1	13.51	4	7
10	12.97	4	8
14	14.12	4	9
18	15.06	4	10
24	15.12	4	11
1	13.55	4	12
15	15.24	4	13
17	14.78	4	14
8	13.71	4	15
16	14.58	5	1
17	20.36	5	2
19	21.19	5	3
18	19.12	5	4
20	18.93	5	5
5	17.48	5	6
9	14.5	5	7
13	17.4	5	8
17	14.5	5	9
21	15.23	5	10
12	13.64	5	11
19	16.9	5	12
3	13.34	5	13
10	12.39	5	14
21	15.57	5	15
3	16.23	6	1
18	18.62	6	2
8	16.45	6	3
13	18.88	6	4
23	15.27	6	5
16	16.06	6	6
24	18.42	6	7
10	11.86	6	8
13	14.62	6	9
2	12.42	6	10
10	10.82	6	11
4	13.04	6	12
17	12.67	6	13
11	12.66	6	14
23	12	6	15
1	13.31	7	1
16	14.17	7	2
6	16.11	7	3
11	14.54	7	4
21	17.9	7	5
12	17.67	7	6
20	19.17	7	7
1	12.64	7	8
9	10.6	7	9
23	9.51	7	10
12	11.3	7	11
6	12.66	7	12
24	12.89	7	13
18	12.6	7	14
5	11.74	7	15
5	12.11	8	1
20	14.11	8	2
10	11.83	8	3
15	15.5	8	4
25	16.6	8	5
4	15.26	8	6
7	16.81	8	7
18	15.45	8	8
21	12.9	8	9
15	9.76	8	10
19	12.4	8	11
13	11.81	8	12
1	9.17	8	13
25	12.87	8	14
7	9.75	8	15
2	13.88	9	1
17	14.53	9	2
7	13.84	9	3
12	16.69	9	4
22	17.38	9	5
25	18.45	9	6
3	17	9	7
14	15.28	9	8
17	13.73	9	9
6	12.4	9	10
21	12.52	9	11
20	15.91	9	12
8	14.28	9	13
2	15.09	9	14
14	12.73	9	15
4	14.43	10	1
19	16.67	10	2
9	15.49	10	3
14	14.59	10	4
24	17.22	10	5
8	15.83	10	6
11	14.9	10	7
22	16.07	10	8
5	13.15	10	9
19	11.74	10	10
3	14.43	10	11
22	16.49	10	12
15	14.07	10	13
9	13.15	10	14
16	13.18	10	15



From adik at ilovebacon.org  Tue Sep 15 06:22:04 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 14 Sep 2009 21:22:04 -0700 (PDT)
Subject: [R-sig-ME] Fitting a fixed effect model while modelling
 correlation in the residuals in 2 directions
In-Reply-To: <54C44B5E31101D4B8D2B32179CBE49778B41CC@EXPRSV03.mcs.usyd.edu.au>
References: <54C44B5E31101D4B8D2B32179CBE49778B41CC@EXPRSV03.mcs.usyd.edu.au>
Message-ID: <Pine.LNX.4.64.0909142121040.8722@parser.ilovebacon.org>



On Tue, 15 Sep 2009, Thomas Bishop wrote:

> slate.ar1*ar1 <- gls(Yield~as.factor(Variety),corr = corAR1(form = ~
> 1|(FieldRow+FieldColumn),data=Slate))

...data=Slate is one paren too deep. Should be ...+FieldColumn)),data=Slate)

:)

--Adam



From wkmor1 at gmail.com  Tue Sep 15 06:58:52 2009
From: wkmor1 at gmail.com (Will Morris)
Date: Tue, 15 Sep 2009 14:58:52 +1000
Subject: [R-sig-ME] lme4 under 64 bit (Snow Leopard)
In-Reply-To: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
References: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
Message-ID: <a5dabfa60909142158r94e0f17r36f35f42a17db273@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090915/52dbb127/attachment.pl>

From p.dalgaard at biostat.ku.dk  Tue Sep 15 09:50:51 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 15 Sep 2009 09:50:51 +0200
Subject: [R-sig-ME] lme4 under 64 bit (Snow Leopard)
In-Reply-To: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
References: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
Message-ID: <4AAF475B.5050501@biostat.ku.dk>

Michael Kubovy wrote:
> Here is my session:

And the problem is? (Sounds like you are referring to an ealier post, 
but I don't see any.)

You have a generic package install problem. That's more of an R-sig-mac 
issue than -ME. Do you need to install from source? If you do, you need 
a compile toolchain in place, and you obviously haven't.

	-pd

> 
> R version 2.9.2 Patched (2009-09-05 r49613)
> Copyright (C) 2009 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [R.app GUI 1.28 (5399) x86_64-apple-darwin9.8.0]
> 
> Error in library.dynam(lib, package, package.lib) :
>   shared library 'lme4' not found
> [Workspace restored from /.RData]
> 
> trying URL 
> 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/lme4_0.999375-31.tar.gz'
> Content type 'application/x-gzip' length 839548 bytes (819 Kb)
> opened URL
> ==================================================
> downloaded 819 Kb
> 
> * Installing *source* package ?lme4? ...
> ** libs
> ** arch - i386
> sh: make: command not found
> ERROR: compilation failed for package ?lme4?
> * Removing 
> ?/Library/Frameworks/R.framework/Versions/2.9/Resources/library/lme4?
> * Restoring previous 
> ?/Library/Frameworks/R.framework/Versions/2.9/Resources/library/lme4?
> 
> The downloaded packages are in
>     ?/private/var/folders/TG/TG6nWu2pHYCI-BdWWiyMxU+++TI/-Tmp-/Rtmprhnu6K/downloaded_packages? 
> 
>  > require(lme4)
> Loading required package: lme4
> Error: package 'lme4' is not installed for 'arch=x86_64'
> In addition: Warning message:
> In install.packages(c("lme4"), lib = 
> "/Library/Frameworks/R.framework/Resources/library/",  :
>   installation of package 'lme4' had non-zero exit status
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From Christine.Griffiths at bristol.ac.uk  Tue Sep 15 12:05:58 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Tue, 15 Sep 2009 11:05:58 +0100
Subject: [R-sig-ME] interpreting Std. error from glmer output
Message-ID: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk>

I want to plot my predictions from a model and use the standard error 
output as a measure of dispersion as I am unable to calculate confidence 
intervals with mcmcsamp as I have a binomial distribution.

I know that the estimates are deviations from the intercept.
Fixed effects below:
                           Estimate Std. Error z value Pr(>|z|)
(Intercept)                 2.90836    0.34041   8.544  < 2e-16 ***
treatment2      		   -0.73507    0.12986  -5.660 1.51e-08 ***
treatment3                 -1.20052    0.12371  -9.705  < 2e-16 ***

So the estimate for treatment 2 is 2.9 + -0.73. Are standard errors also 
deviations from the intercept? i.e. 0.34 + 0.13 for treatment 2?

Many thanks
Christine



From kagba2006 at yahoo.com  Tue Sep 15 12:57:56 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 15 Sep 2009 03:57:56 -0700 (PDT)
Subject: [R-sig-ME] Error message with lme function
Message-ID: <564933.24053.qm@web38308.mail.mud.yahoo.com>

Dear All,

I have a set of data which consist of 261 groups with 11 temperature values?in each group. This temperature is recorded across 11 different depths of the sea. The variables involve?in the R script are:

############################
#group : 1-261
#dp: 11 different depths for each group
#sub1: Data set 1
#set: Data set 2
############################

I tried to fit a linear mixed model with fixed efffect on slope and intercept, and random effect on slope and intercept too with lme function, but sadly the program gave an error message. 

#################################################
dp<- rep(rev(seq(1,51, by = 5)),261)
group?<- rep(1:261, each = 11)
set <- data.frame(sub1, dp, group)
(lm.lme2 <- lme(Temp ~ dp| group, data = set, random = ~ dp| group))

Error in MEEM(object, conLin, control$niterEM) :?
?Singularity in backsolve at level 0, block 1
#################################################

Could someone please advice me the meaning of this error and the way to sort it out?

Thank you
Fir






From Thierry.ONKELINX at inbo.be  Tue Sep 15 13:23:06 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 15 Sep 2009 13:23:06 +0200
Subject: [R-sig-ME] Error message with lme function
In-Reply-To: <564933.24053.qm@web38308.mail.mud.yahoo.com>
References: <564933.24053.qm@web38308.mail.mud.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B4868E@inboexch.inbo.be>

Dear Fir,

Remove the |group from the fixed effects. The grouping is defined in the random effects.

HTH,

Thierry

PS Your example was not reproducible because sub1 was missing 


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens FMH
Verzonden: dinsdag 15 september 2009 12:58
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Error message with lme function

Dear All,

I have a set of data which consist of 261 groups with 11 temperature values?in each group. This temperature is recorded across 11 different depths of the sea. The variables involve?in the R script are:

############################
#group : 1-261
#dp: 11 different depths for each group
#sub1: Data set 1
#set: Data set 2
############################

I tried to fit a linear mixed model with fixed efffect on slope and intercept, and random effect on slope and intercept too with lme function, but sadly the program gave an error message. 

#################################################
dp<- rep(rev(seq(1,51, by = 5)),261)
group?<- rep(1:261, each = 11)
set <- data.frame(sub1, dp, group)
(lm.lme2 <- lme(Temp ~ dp| group, data = set, random = ~ dp| group))

Error in MEEM(object, conLin, control$niterEM) :
?Singularity in backsolve at level 0, block 1 #################################################

Could someone please advice me the meaning of this error and the way to sort it out?

Thank you
Fir




_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From wkmor1 at gmail.com  Tue Sep 15 13:38:09 2009
From: wkmor1 at gmail.com (Will Morris)
Date: Tue, 15 Sep 2009 21:38:09 +1000
Subject: [R-sig-ME] interpreting Std. error from glmer output
In-Reply-To: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk>
References: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk>
Message-ID: <a5dabfa60909150438h72c9c5abge21f666183a9857e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090915/6be989c3/attachment.pl>

From kagba2006 at yahoo.com  Tue Sep 15 13:52:06 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 15 Sep 2009 04:52:06 -0700 (PDT)
Subject: [R-sig-ME] How to define the fixed and random effects in lmer
Message-ID: <321761.66698.qm@web38304.mail.mud.yahoo.com>

Dear All,

I was running lme function on my data as shown below, in which the variables involved are:

########################################
#Pre : Precipitation
#t : time
#group : Group of precipitation
#prec: data set

lme(Pre ~ t| group, data = prec, random = ~ t| group)
#########################################

How could i write the scripts?with lmer function with :
1. fixed effects for the intercept and slope and only random effect for the intercept is included
2. fixed effects for the intercept and slope, and?random effects for the intercept and slope are included
3. only fixed effect for the intercept and only random effect for the intercept is included
4. only fixed effects for the slope, and?random effects for the intercept and slope are included?

Thank you
Fir






From bolker at ufl.edu  Tue Sep 15 14:48:54 2009
From: bolker at ufl.edu (Bolker,Benjamin Michael)
Date: Tue, 15 Sep 2009 08:48:54 -0400
Subject: [R-sig-ME] How to define the fixed and random effects in lmer
In-Reply-To: <321761.66698.qm@web38304.mail.mud.yahoo.com>
References: <321761.66698.qm@web38304.mail.mud.yahoo.com>
Message-ID: <AC6F23A2BA13C347A59BDCBCFF41E27B5E032D99D5@UFEXCH-MBXCL03.ad.ufl.edu>


I was running lme function on my data as shown below, in which the variables involved are:

########################################
#Pre : Precipitation
#t : time
#group : Group of precipitation
#prec: data set

lme(Pre ~ t| group, data = prec, random = ~ t| group)
#########################################

  I'm surprised this works (does it?) -- I didn't think |group was meaningful in a fixed-effects formula
specification

How could i write the scripts with lmer function with :
1. fixed effects for the intercept and slope and only random effect for the intercept is included

     lme(Pre~t, random=~1|group, data= prec)

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


     lme(Pre~t, random=~t|group, data= prec)

3. only fixed effect for the intercept and only random effect for the intercept is included

     lme(Pre~1, random=~1|group, data= prec)

4. only fixed effects for the slope, and random effects for the intercept and slope are included

  lme(Pre~t-1, random=~1|group, data= prec)


  (I think. See if those work as expected)


From bolker at ufl.edu  Tue Sep 15 14:53:05 2009
From: bolker at ufl.edu (Bolker,Benjamin Michael)
Date: Tue, 15 Sep 2009 08:53:05 -0400
Subject: [R-sig-ME] Fitting a fixed effect model while modelling
 correlation in the residuals in 2 directions
In-Reply-To: <Pine.LNX.4.64.0909142121040.8722@parser.ilovebacon.org>
References: <54C44B5E31101D4B8D2B32179CBE49778B41CC@EXPRSV03.mcs.usyd.edu.au>,
	<Pine.LNX.4.64.0909142121040.8722@parser.ilovebacon.org>
Message-ID: <AC6F23A2BA13C347A59BDCBCFF41E27B5E032D99D6@UFEXCH-MBXCL03.ad.ufl.edu>


________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Adam D. I. Kramer [adik at ilovebacon.org]
Sent: Tuesday, September 15, 2009 12:22 AM
To: Thomas Bishop
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Fitting a fixed effect model while modelling correlation in the residuals in 2 directions

On Tue, 15 Sep 2009, Thomas Bishop wrote:

> slate.ar1*ar1 <- gls(Yield~as.factor(Variety),corr = corAR1(form = ~
> 1|(FieldRow+FieldColumn),data=Slate))

...data=Slate is one paren too deep. Should be ...+FieldColumn)),data=Slate)


   Does corAR1 really work for spatial problems?  I would have thought the definition would have been slightly different ...



From mailinglist.honeypot at gmail.com  Tue Sep 15 05:58:23 2009
From: mailinglist.honeypot at gmail.com (Steve Lianoglou)
Date: Mon, 14 Sep 2009 23:58:23 -0400
Subject: [R-sig-ME] [R-SIG-Mac] lme4 under 64 bit (Snow Leopard)
In-Reply-To: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
References: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
Message-ID: <bbdc7ed00909142058s2ca13c54p7d12d184af102b2a@mail.gmail.com>

Hi,

On Mon, Sep 14, 2009 at 11:30 PM, Michael Kubovy <kubovy at virginia.edu> wrote:

> Error in library.dynam(lib, package, package.lib) :
>  shared library 'lme4' not found
> [Workspace restored from /.RData]

Assuming you mean to autoload the .Rdata file ...

> trying URL
> 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/lme4_0.999375-31.tar.gz'
> Content type 'application/x-gzip' length 839548 bytes (819 Kb)
> opened URL
> ==================================================
> downloaded 819 Kb
>
> * Installing *source* package ?lme4? ...
> ** libs
> ** arch - i386
> sh: make: command not found
> ERROR: compilation failed for package ?lme4?

Did you install XCode after upgrading to Snow Leopard? It looks like
it can't find the "make" tool.

...

> Error: package 'lme4' is not installed for 'arch=x86_64'

Being that you just installed 64 bit version of R, this makes sense.

Just install the new XCode and install a source package:

R> install.packages('lme4', type='source')

It should work out fine.

-steve

-- 
Steve Lianoglou
Graduate Student: Computational Systems Biology
 | Memorial Sloan-Kettering Cancer Center
 | Weill Medical College of Cornell University
Contact Info: http://cbio.mskcc.org/~lianos/contact



From Bruno.Ernande at ifremer.fr  Tue Sep 15 14:42:00 2009
From: Bruno.Ernande at ifremer.fr (Bruno ERNANDE)
Date: Tue, 15 Sep 2009 14:42:00 +0200
Subject: [R-sig-ME] Within-group correlation matrix in nlme
Message-ID: <4AAF8B98.50806@ifremer.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090915/40b7c143/attachment.pl>

From jeroen at yeroon.net  Mon Sep 14 13:02:54 2009
From: jeroen at yeroon.net (Jeroen)
Date: Mon, 14 Sep 2009 13:02:54 +0200
Subject: [R-sig-ME] lme4 web application
Message-ID: <673e1b980909140402k3a6bda62g792477242a0fc6ed@mail.gmail.com>

Dear lme4 users,

inspired by useR! 2009,?yeroon.net?is a new project developing
statistical web applications to make popular R packages easier
available. A first version of the lme4 web interface is available at
http://yeroon.net/lme4/. It implements most lme4 features and some
more.

A short 2minute how-to demo video that illustrates how to use the
application is available on youtube:
http://www.youtube.com/watch?v=_OHps7z3Pqc&hd=1. More information and
details are available on my website
http://www.jeroenooms.com/lme4.html

We hope you will give it a try, and that you like it. Any
feedback/suggestions/bugreports are welcome of course.

Jeroen Ooms



From dwinsemius at comcast.net  Tue Sep 15 15:14:45 2009
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 15 Sep 2009 09:14:45 -0400
Subject: [R-sig-ME] [R-SIG-Mac]  lme4 under 64 bit (Snow Leopard)
In-Reply-To: <a5dabfa60909142158r94e0f17r36f35f42a17db273@mail.gmail.com>
References: <5FC335DF-D234-4629-AC01-D09C7E87479A@virginia.edu>
	<a5dabfa60909142158r94e0f17r36f35f42a17db273@mail.gmail.com>
Message-ID: <7F82C069-D178-4DE7-AFCC-087ED513BA6C@comcast.net>


On Sep 15, 2009, at 12:58 AM, Will Morris wrote:

> When you run the 64bit version of R on OSX you need to compile all  
> packages
> from source as 64bit too, rather than simply downloading the  
> binaries which
> are all 32bit.

That is not my experience, although it was true in the past. Most of  
the CRAN binaries now work fine under 64 bit. I do not have Snow  
Leopard so this experience is only from MacOSX 10.5.8.

-- 
David Winsemius
>
> To compile R packages from source you need to have installed the Xcode
> package from apple. It can be installed from your OSX discs or  
> downloaded
> from the Apple Developer Network site which is is free to join.
>
> On Tue, Sep 15, 2009 at 1:30 PM, Michael Kubovy  
> <kubovy at virginia.edu> wrote:
>
>> Here is my session:
>>
>> R version 2.9.2 Patched (2009-09-05 r49613)
>> Copyright (C) 2009 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [R.app GUI 1.28 (5399) x86_64-apple-darwin9.8.0]
>>
>> Error in library.dynam(lib, package, package.lib) :
>> shared library 'lme4' not found
>> [Workspace restored from /.RData]
>>
>> trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/
>> lme4_0.999375-31.tar.gz'
>> Content type 'application/x-gzip' length 839548 bytes (819 Kb)
>> opened URL
>> ==================================================
>> downloaded 819 Kb
>>
>> * Installing *source* package ?lme4? ...
>> ** libs
>> ** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4?
>> * Removing
>> ?/Library/Frameworks/R.framework/Versions/2.9/Resources/library/lme4?
>> * Restoring previous
>> ?/Library/Frameworks/R.framework/Versions/2.9/Resources/library/lme4?
>>
>> The downloaded packages are in
>>
>> ?/private/var/folders/TG/TG6nWu2pHYCI-BdWWiyMxU+++TI/-Tmp-/ 
>> Rtmprhnu6K/downloaded_packages?
>>> require(lme4)
>> Loading required package: lme4
>> Error: package 'lme4' is not installed for 'arch=x86_64'
>> In addition: Warning message:
>> In install.packages(c("lme4"), lib =
>> "/Library/Frameworks/R.framework/Resources/library/",  :
>> installation of package 'lme4' had non-zero exit status
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> -- 
> Will Morris
> Masters of Philosophy candidate
> Vesk Plant Ecology Lab
> The School of Botany
> The University of Melbourne
> Australia
> Phone: +61 3 8344 0120
> http://www.botany.unimelb.edu.au/vesk/
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac

David Winsemius, MD
Heritage Laboratories
West Hartford, CT



From wkmor1 at gmail.com  Tue Sep 15 15:32:49 2009
From: wkmor1 at gmail.com (William Morris)
Date: Tue, 15 Sep 2009 23:32:49 +1000
Subject: [R-sig-ME] interpreting Std. error from glmer output
In-Reply-To: <AD19E73BB7523EF4907EA217@bio-mammal026.bio.bris.ac.uk>
References: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk>
	<a5dabfa60909150438h72c9c5abge21f666183a9857e@mail.gmail.com>
	<AD19E73BB7523EF4907EA217@bio-mammal026.bio.bris.ac.uk>
Message-ID: <F1AB641C-313A-4189-BABA-291ABA007AF2@gmail.com>

Well, it depends.

It depends on what you mean by deviance, you should clarify this (here  
is a start http://en.wikipedia.org/wiki/Deviance_%28statistics%29). In  
general, deviance is used as a measure of model fit and usually  
encountered as a component of Information criteria.

Do you need to take the uncertainty (SE) in model estimates into  
account? It is probably a good idea if you are going to make  
predictions based on model estimates to also calculate predictions at  
the 95CI limits.

On 15/09/2009, at 10:26 PM, Christine Griffiths wrote:

> Thank you. So to clarify, I do not need to calculate the deviance of  
> the standard error from the intercept standard error, in the way  
> that I would do for the estimate?
>
> Cheers
> Christine
>
> --On 15 September 2009 21:38 +1000 Will Morris <wkmor1 at gmail.com>  
> wrote:
>
>> The SE is a measure of the models uncertainty about the parameter
>> estimates, it takes into account your sample size as well as sample
>> variance.  +_2*SE is usually a good estimate of the 95% confidence
>> interval.  In other words your treatment effect for treatment2 is
>> probably somewhere between -.6 and -.86.
>>
>>
>> On Tue, Sep 15, 2009 at 8:05 PM, Christine Griffiths
>> <Christine.Griffiths at bristol.ac.uk> wrote:
>>
>> I want to plot my predictions from a model and use the standard error
>> output as a measure of dispersion as I am unable to calculate  
>> confidence
>> intervals with mcmcsamp as I have a binomial distribution.
>>
>> I know that the estimates are deviations from the intercept.
>> Fixed effects below:
>>                          Estimate Std. Error z value Pr(>|z|)
>> (Intercept)                 2.90836    0.34041   8.544  < 2e-16 ***
>> treatment2                         -0.73507    0.12986  -5.660  
>> 1.51e-08
>> ***
>> treatment3                 -1.20052    0.12371  -9.705  < 2e-16 ***
>>
>> So the estimate for treatment 2 is 2.9 + -0.73. Are standard errors  
>> also
>> deviations from the intercept? i.e. 0.34 + 0.13 for treatment 2?
>>
>> Many thanks
>> Christine
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Will Morris
>> Masters of Philosophy candidate
>> Vesk Plant Ecology Lab
>> The School of Botany
>> The University of Melbourne
>> Australia
>> Phone: +61 3 8344 0120
>> http://www.botany.unimelb.edu.au/vesk/
>
>
>
> ----------------------
> Christine Griffiths
> PhD student
> School of Biological Sciences
> University of Bristol
> Woodland Road
> Bristol BS8 1UG
> Tel: 0117 9287593
> Fax 0117 3317985
> Christine.Griffiths at bristol.ac.uk
> http://www.bio.bris.ac.uk/research/mammal/tortoises.html



Will Morris
Masters of Philosophy candidate
Vesk Plant Ecology Lab
The School of Botany
The University of Melbourne
Australia
Phone: +61 3 8344 0120
http://www.botany.unimelb.edu.au/vesk/



From Christine.Griffiths at bristol.ac.uk  Tue Sep 15 18:28:30 2009
From: Christine.Griffiths at bristol.ac.uk (Christine Griffiths)
Date: Tue, 15 Sep 2009 17:28:30 +0100
Subject: [R-sig-ME] interpreting Std. error from glmer output
In-Reply-To: <F1AB641C-313A-4189-BABA-291ABA007AF2@gmail.com>
References: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk>
	<a5dabfa60909150438h72c9c5abge21f666183a9857e@mail.gmail.com>
	<AD19E73BB7523EF4907EA217@bio-mammal026.bio.bris.ac.uk>
	<F1AB641C-313A-4189-BABA-291ABA007AF2@gmail.com>
Message-ID: <425029F194D4150C06572211@bio-mammal026.bio.bris.ac.uk>

Thank you for your help. Because I am using glmer with Binomial family I 
cannot calculate 95% CIs using the mcmcsamp function and have not been able 
to find a way to do this. Hence my reason to look at the SE.

I probably didn't explain myself clearly enough. What I meant is, is the SE 
for a fixed effect the difference from the intercept, just as the mean for 
a fixed effect needs to be calculated as a difference from the intercept?
Your definition earlier seemed to support that it is a difference and so I 
need to calculate the SE by summing the value given with the intercept.

--On 15 September 2009 23:32 +1000 William Morris <wkmor1 at gmail.com> wrote:

> Well, it depends.
>
> It depends on what you mean by deviance, you should clarify this (here
> is a start http://en.wikipedia.org/wiki/Deviance_%28statistics%29). In
> general, deviance is used as a measure of model fit and usually
> encountered as a component of Information criteria.
>
> Do you need to take the uncertainty (SE) in model estimates into
> account? It is probably a good idea if you are going to make  predictions
> based on model estimates to also calculate predictions at  the 95CI
> limits.
>
> On 15/09/2009, at 10:26 PM, Christine Griffiths wrote:
>
>> Thank you. So to clarify, I do not need to calculate the deviance of
>> the standard error from the intercept standard error, in the way
>> that I would do for the estimate?
>>
>> Cheers
>> Christine
>>
>> --On 15 September 2009 21:38 +1000 Will Morris <wkmor1 at gmail.com>
>> wrote:
>>
>>> The SE is a measure of the models uncertainty about the parameter
>>> estimates, it takes into account your sample size as well as sample
>>> variance.  +_2*SE is usually a good estimate of the 95% confidence
>>> interval.  In other words your treatment effect for treatment2 is
>>> probably somewhere between -.6 and -.86.
>>>
>>>
>>> On Tue, Sep 15, 2009 at 8:05 PM, Christine Griffiths
>>> <Christine.Griffiths at bristol.ac.uk> wrote:
>>>
>>> I want to plot my predictions from a model and use the standard error
>>> output as a measure of dispersion as I am unable to calculate
>>> confidence
>>> intervals with mcmcsamp as I have a binomial distribution.
>>>
>>> I know that the estimates are deviations from the intercept.
>>> Fixed effects below:
>>>                          Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)                 2.90836    0.34041   8.544  < 2e-16 ***
>>> treatment2                         -0.73507    0.12986  -5.660
>>> 1.51e-08
>>> ***
>>> treatment3                 -1.20052    0.12371  -9.705  < 2e-16 ***
>>>
>>> So the estimate for treatment 2 is 2.9 + -0.73. Are standard errors
>>> also
>>> deviations from the intercept? i.e. 0.34 + 0.13 for treatment 2?
>>>
>>> Many thanks
>>> Christine
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>
>>> --
>>> Will Morris
>>> Masters of Philosophy candidate
>>> Vesk Plant Ecology Lab
>>> The School of Botany
>>> The University of Melbourne
>>> Australia
>>> Phone: +61 3 8344 0120
>>> http://www.botany.unimelb.edu.au/vesk/
>>
>>
>>
>> ----------------------
>> Christine Griffiths
>> PhD student
>> School of Biological Sciences
>> University of Bristol
>> Woodland Road
>> Bristol BS8 1UG
>> Tel: 0117 9287593
>> Fax 0117 3317985
>> Christine.Griffiths at bristol.ac.uk
>> http://www.bio.bris.ac.uk/research/mammal/tortoises.html
>
>
>
> Will Morris
> Masters of Philosophy candidate
> Vesk Plant Ecology Lab
> The School of Botany
> The University of Melbourne
> Australia
> Phone: +61 3 8344 0120
> http://www.botany.unimelb.edu.au/vesk/



----------------------
Christine Griffiths
PhD student
School of Biological Sciences
University of Bristol
Woodland Road
Bristol BS8 1UG
Tel: 0117 9287593
Fax 0117 3317985
Christine.Griffiths at bristol.ac.uk
http://www.bio.bris.ac.uk/research/mammal/tortoises.html



From kagba2006 at yahoo.com  Tue Sep 15 19:30:25 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 15 Sep 2009 10:30:25 -0700 (PDT)
Subject: [R-sig-ME] How to define the fixed and random effects in lmer
In-Reply-To: <AC6F23A2BA13C347A59BDCBCFF41E27B5E032D99D5@UFEXCH-MBXCL03.ad.ufl.edu>
References: <321761.66698.qm@web38304.mail.mud.yahoo.com>
	<AC6F23A2BA13C347A59BDCBCFF41E27B5E032D99D5@UFEXCH-MBXCL03.ad.ufl.edu>
Message-ID: <95660.62236.qm@web38305.mail.mud.yahoo.com>

Thank you for your advice, but actually i'm looking for the scripts via lmer function?in lme4 package.

Cheers
Fir



----- Original Message ----
From: "Bolker,Benjamin Michael" <bolker at ufl.edu>
To: FMH <kagba2006 at yahoo.com>; "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Sent: Tuesday, September 15, 2009 1:48:54 PM
Subject: RE: [R-sig-ME] How to define the fixed and random effects in lmer


I was running lme function on my data as shown below, in which the variables involved are:

########################################
#Pre : Precipitation
#t : time
#group : Group of precipitation
#prec: data set

lme(Pre ~ t| group, data = prec, random = ~ t| group)
#########################################

? I'm surprised this works (does it?) -- I didn't think |group was meaningful in a fixed-effects formula
specification

How could i write the scripts with lmer function with :
1. fixed effects for the intercept and slope and only random effect for the intercept is included

? ? lme(Pre~t, random=~1|group, data= prec)

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


? ? lme(Pre~t, random=~t|group, data= prec)

3. only fixed effect for the intercept and only random effect for the intercept is included

? ? lme(Pre~1, random=~1|group, data= prec)

4. only fixed effects for the slope, and random effects for the intercept and slope are included

? lme(Pre~t-1, random=~1|group, data= prec)


? (I think. See if those work as expected)






From lborger at uoguelph.ca  Tue Sep 15 19:42:17 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Tue, 15 Sep 2009 13:42:17 -0400 (EDT)
Subject: [R-sig-ME] How to define the fixed and random effects in lmer
In-Reply-To: <95660.62236.qm@web38305.mail.mud.yahoo.com>
Message-ID: <2000402205.7525861253036537385.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

that should be fairly easy to do, instead of "random =..." you use brackets to specify the random effects. For example:

1. fixed effects for the intercept and slope and only random effect for the intercept is included

    lmer(Pre~t +(1|group), data= prec)



or

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


    lmer(Pre~t + (t|group), data= prec)




HTH


Cheers,


Luca


----- Messaggio originale -----
Da: "FMH" <kagba2006 at yahoo.com>
A: "Benjamin Michael Bolker" <bolker at ufl.edu>, r-sig-mixed-models at r-project.org
Inviato: Marted?, 15 settembre 2009 13:30:25 GMT -05:00 U.S.A./Canada, stati orientali
Oggetto: Re: [R-sig-ME] How to define the fixed and random effects in lmer

Thank you for your advice, but actually i'm looking for the scripts via lmer function?in lme4 package.

Cheers
Fir



----- Original Message ----
From: "Bolker,Benjamin Michael" <bolker at ufl.edu>
To: FMH <kagba2006 at yahoo.com>; "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Sent: Tuesday, September 15, 2009 1:48:54 PM
Subject: RE: [R-sig-ME] How to define the fixed and random effects in lmer


I was running lme function on my data as shown below, in which the variables involved are:

########################################
#Pre : Precipitation
#t : time
#group : Group of precipitation
#prec: data set

lme(Pre ~ t| group, data = prec, random = ~ t| group)
#########################################

? I'm surprised this works (does it?) -- I didn't think |group was meaningful in a fixed-effects formula
specification

How could i write the scripts with lmer function with :
1. fixed effects for the intercept and slope and only random effect for the intercept is included

? ? lme(Pre~t, random=~1|group, data= prec)

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


? ? lme(Pre~t, random=~t|group, data= prec)

3. only fixed effect for the intercept and only random effect for the intercept is included

? ? lme(Pre~1, random=~1|group, data= prec)

4. only fixed effects for the slope, and random effects for the intercept and slope are included

? lme(Pre~t-1, random=~1|group, data= prec)


? (I think. See if those work as expected)




_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Thierry.ONKELINX at inbo.be  Wed Sep 16 10:38:29 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 Sep 2009 10:38:29 +0200
Subject: [R-sig-ME] interpreting Std. error from glmer output
In-Reply-To: <425029F194D4150C06572211@bio-mammal026.bio.bris.ac.uk>
References: <A3D3758F07CC42861059F48F@bio-mammal026.bio.bris.ac.uk><a5dabfa60909150438h72c9c5abge21f666183a9857e@mail.gmail.com><AD19E73BB7523EF4907EA217@bio-mammal026.bio.bris.ac.uk><F1AB641C-313A-4189-BABA-291ABA007AF2@gmail.com>
	<425029F194D4150C06572211@bio-mammal026.bio.bris.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A10406B4884F@inboexch.inbo.be>

Dear Christine,

Be carefull about that. The SE of a sum is NOT the sums of the SE! But
the variance of a sum is the sum of the variances minus the covariance.

The easiest option would be to refit the model without intercept if you
want the 'total' SE for each treatment.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Christine
Griffiths
Verzonden: dinsdag 15 september 2009 18:29
Aan: William Morris
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] interpreting Std. error from glmer output

Thank you for your help. Because I am using glmer with Binomial family I
cannot calculate 95% CIs using the mcmcsamp function and have not been
able to find a way to do this. Hence my reason to look at the SE.

I probably didn't explain myself clearly enough. What I meant is, is the
SE for a fixed effect the difference from the intercept, just as the
mean for a fixed effect needs to be calculated as a difference from the
intercept?
Your definition earlier seemed to support that it is a difference and so
I need to calculate the SE by summing the value given with the
intercept.

--On 15 September 2009 23:32 +1000 William Morris <wkmor1 at gmail.com>
wrote:

> Well, it depends.
>
> It depends on what you mean by deviance, you should clarify this (here

> is a start http://en.wikipedia.org/wiki/Deviance_%28statistics%29). In

> general, deviance is used as a measure of model fit and usually 
> encountered as a component of Information criteria.
>
> Do you need to take the uncertainty (SE) in model estimates into 
> account? It is probably a good idea if you are going to make  
> predictions based on model estimates to also calculate predictions at

> the 95CI limits.
>
> On 15/09/2009, at 10:26 PM, Christine Griffiths wrote:
>
>> Thank you. So to clarify, I do not need to calculate the deviance of 
>> the standard error from the intercept standard error, in the way that

>> I would do for the estimate?
>>
>> Cheers
>> Christine
>>
>> --On 15 September 2009 21:38 +1000 Will Morris <wkmor1 at gmail.com>
>> wrote:
>>
>>> The SE is a measure of the models uncertainty about the parameter 
>>> estimates, it takes into account your sample size as well as sample 
>>> variance.  +_2*SE is usually a good estimate of the 95% confidence 
>>> interval.  In other words your treatment effect for treatment2 is 
>>> probably somewhere between -.6 and -.86.
>>>
>>>
>>> On Tue, Sep 15, 2009 at 8:05 PM, Christine Griffiths 
>>> <Christine.Griffiths at bristol.ac.uk> wrote:
>>>
>>> I want to plot my predictions from a model and use the standard 
>>> error output as a measure of dispersion as I am unable to calculate 
>>> confidence intervals with mcmcsamp as I have a binomial 
>>> distribution.
>>>
>>> I know that the estimates are deviations from the intercept.
>>> Fixed effects below:
>>>                          Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)                 2.90836    0.34041   8.544  < 2e-16 ***
>>> treatment2                         -0.73507    0.12986  -5.660
>>> 1.51e-08
>>> ***
>>> treatment3                 -1.20052    0.12371  -9.705  < 2e-16 ***
>>>
>>> So the estimate for treatment 2 is 2.9 + -0.73. Are standard errors 
>>> also deviations from the intercept? i.e. 0.34 + 0.13 for treatment 
>>> 2?
>>>
>>> Many thanks
>>> Christine
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>
>>> --
>>> Will Morris
>>> Masters of Philosophy candidate
>>> Vesk Plant Ecology Lab
>>> The School of Botany
>>> The University of Melbourne
>>> Australia
>>> Phone: +61 3 8344 0120
>>> http://www.botany.unimelb.edu.au/vesk/
>>
>>
>>
>> ----------------------
>> Christine Griffiths
>> PhD student
>> School of Biological Sciences
>> University of Bristol
>> Woodland Road
>> Bristol BS8 1UG
>> Tel: 0117 9287593
>> Fax 0117 3317985
>> Christine.Griffiths at bristol.ac.uk
>> http://www.bio.bris.ac.uk/research/mammal/tortoises.html
>
>
>
> Will Morris
> Masters of Philosophy candidate
> Vesk Plant Ecology Lab
> The School of Botany
> The University of Melbourne
> Australia
> Phone: +61 3 8344 0120
> http://www.botany.unimelb.edu.au/vesk/



----------------------
Christine Griffiths
PhD student
School of Biological Sciences
University of Bristol
Woodland Road
Bristol BS8 1UG
Tel: 0117 9287593
Fax 0117 3317985
Christine.Griffiths at bristol.ac.uk
http://www.bio.bris.ac.uk/research/mammal/tortoises.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From kagba2006 at yahoo.com  Wed Sep 16 12:17:28 2009
From: kagba2006 at yahoo.com (FMH)
Date: Wed, 16 Sep 2009 03:17:28 -0700 (PDT)
Subject: [R-sig-ME] Warning message with lmer function
Message-ID: <686354.86388.qm@web38307.mail.mud.yahoo.com>

Dear All,

I have a set of data which consist of?1575 groups with 11 temperature values?in each group. This temperature is recorded across 11 different depths of the sea. The?R script are shown below:

############################################################
#Temp : Temperature
#dp1, dp2, dp3 : covariate with respect to linear, quadratic and cubic terms
#group : 1575 groups in which there are 11 observations in each group
#sub3 : Data set 1
#set3 : Data set 2

dp1 <- rep(rev(seq(1,51, by = 5)),1575)
dp2 <- dp1^2
dp3 <- dp1^3
group <- rep(1:1575, each = 11)
set3 <- data.frame(sub3, dp1, dp2, dp3)
(lm.lme3 <- lmer(Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3|group), data = set3))
############################################################


I tried to fit a linear mixed model via lmer function, with all the fixed and random effects are included, but there is a 'Warning' message given after the output, as shown below.


##############################################
Linear mixed model fit by REML 
Formula: Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3 | group) 
?? Data: set3 
?? AIC?? BIC logLik deviance REMLdev
?65627 65743 -32799??? 65539?? 65597
Random effects:
?Groups?? Name??????? Variance?? Std.Dev.?? Corr?????????????????
?group??? (Intercept) 4.8336e-01 6.9524e-01????????????????????? 
????????? dp1???????? 5.2199e-04 2.2847e-02? 0.000?????????????? 
????????? dp2???????? 3.0528e-07 5.5252e-04? 0.000? 0.000??????? 
????????? dp3???????? 7.8888e-11 8.8819e-06 -0.966? 0.000? 0.000 
?Residual???????????? 1.9939e+00 1.4120e+00????????????????????? 
Number of obs: 17325, groups: group, 1575
Fixed effects:
????????????? Estimate Std. Error t value
(Intercept)? 1.363e+01? 4.043e-02?? 337.1
dp1???????? -2.930e-01? 6.328e-03?? -46.3
dp2????????? 3.924e-03? 2.870e-04??? 13.7
dp3???????? -1.900e-05? 3.628e-06??? -5.2
Correlation of Fixed Effects:
??? (Intr) dp1??? dp2?? 
dp1 -0.739????????????? 
dp2? 0.616 -0.959?????? 
dp3 -0.563? 0.904 -0.982

Warning message:
In mer_finalize(ans) : false convergence (8)
#############################################


Does the output given is valid? Could someone please advice on this message.

Thank you
Fir


    


From ken at kjbeath.com.au  Wed Sep 16 12:35:04 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Wed, 16 Sep 2009 20:35:04 +1000
Subject: [R-sig-ME] Warning message with lmer function
In-Reply-To: <686354.86388.qm@web38307.mail.mud.yahoo.com>
References: <686354.86388.qm@web38307.mail.mud.yahoo.com>
Message-ID: <094F4AD5-BBF9-46FD-ADD6-7B26EB5F1CEC@kjbeath.com.au>

The random effects variances are close to zero, which will cause lots  
of problems.

This is possibly a numerical problem, as the values of the fixed  
effect estimates are small. Maybe you could try scaling the covariate  
before creating the polynomial terms.

Ken

On 16/09/2009, at 8:17 PM, FMH wrote:

> Dear All,
>
> I have a set of data which consist of 1575 groups with 11  
> temperature values in each group. This temperature is recorded  
> across 11 different depths of the sea. The R script are shown below:
>
> ############################################################
> #Temp : Temperature
> #dp1, dp2, dp3 : covariate with respect to linear, quadratic and  
> cubic terms
> #group : 1575 groups in which there are 11 observations in each group
> #sub3 : Data set 1
> #set3 : Data set 2
>
> dp1 <- rep(rev(seq(1,51, by = 5)),1575)
> dp2 <- dp1^2
> dp3 <- dp1^3
> group <- rep(1:1575, each = 11)
> set3 <- data.frame(sub3, dp1, dp2, dp3)
> (lm.lme3 <- lmer(Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3|group),  
> data = set3))
> ############################################################
>
>
> I tried to fit a linear mixed model via lmer function, with all the  
> fixed and random effects are included, but there is a 'Warning'  
> message given after the output, as shown below.
>
>
> ##############################################
> Linear mixed model fit by REML
> Formula: Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3 | group)
>    Data: set3
>    AIC   BIC logLik deviance REMLdev
>  65627 65743 -32799    65539   65597
> Random effects:
>  Groups   Name        Variance   Std.Dev.   Corr
>  group    (Intercept) 4.8336e-01 6.9524e-01
>           dp1         5.2199e-04 2.2847e-02  0.000
>           dp2         3.0528e-07 5.5252e-04  0.000  0.000
>           dp3         7.8888e-11 8.8819e-06 -0.966  0.000  0.000
>  Residual             1.9939e+00 1.4120e+00
> Number of obs: 17325, groups: group, 1575
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept)  1.363e+01  4.043e-02   337.1
> dp1         -2.930e-01  6.328e-03   -46.3
> dp2          3.924e-03  2.870e-04    13.7
> dp3         -1.900e-05  3.628e-06    -5.2
> Correlation of Fixed Effects:
>     (Intr) dp1    dp2
> dp1 -0.739
> dp2  0.616 -0.959
> dp3 -0.563  0.904 -0.982
>
> Warning message:
> In mer_finalize(ans) : false convergence (8)
> #############################################
>
>
> Does the output given is valid? Could someone please advice on this  
> message.
>
> Thank you
> Fir
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Thierry.ONKELINX at inbo.be  Wed Sep 16 13:01:35 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 Sep 2009 13:01:35 +0200
Subject: [R-sig-ME] Warning message with lmer function
In-Reply-To: <094F4AD5-BBF9-46FD-ADD6-7B26EB5F1CEC@kjbeath.com.au>
References: <686354.86388.qm@web38307.mail.mud.yahoo.com>
	<094F4AD5-BBF9-46FD-ADD6-7B26EB5F1CEC@kjbeath.com.au>
Message-ID: <2E9C414912813E4EB981326983E0A10406B488D9@inboexch.inbo.be>

Use poly() instead of calculating the polynomials by hand. 

And note that your current random effect requires 10 parameters. And you
have only 11 data point within each group. Therefore I would simplify it
to the model below.

lmer(Temp ~ poly(dp1, 3) + (poly(dp1, 1)|group) data = set3)

HTH,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ken Beath
Verzonden: woensdag 16 september 2009 12:35
Aan: FMH
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Warning message with lmer function

The random effects variances are close to zero, which will cause lots of
problems.

This is possibly a numerical problem, as the values of the fixed effect
estimates are small. Maybe you could try scaling the covariate before
creating the polynomial terms.

Ken

On 16/09/2009, at 8:17 PM, FMH wrote:

> Dear All,
>
> I have a set of data which consist of 1575 groups with 11  
> temperature values in each group. This temperature is recorded  
> across 11 different depths of the sea. The R script are shown below:
>
> ############################################################
> #Temp : Temperature
> #dp1, dp2, dp3 : covariate with respect to linear, quadratic and  
> cubic terms
> #group : 1575 groups in which there are 11 observations in each group
> #sub3 : Data set 1
> #set3 : Data set 2
>
> dp1 <- rep(rev(seq(1,51, by = 5)),1575)
> dp2 <- dp1^2
> dp3 <- dp1^3
> group <- rep(1:1575, each = 11)
> set3 <- data.frame(sub3, dp1, dp2, dp3)
> (lm.lme3 <- lmer(Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3|group),  
> data = set3))
> ############################################################
>
>
> I tried to fit a linear mixed model via lmer function, with all the  
> fixed and random effects are included, but there is a 'Warning'  
> message given after the output, as shown below.
>
>
> ##############################################
> Linear mixed model fit by REML
> Formula: Temp ~ dp1 + dp2 + dp3 + (dp1 + dp2 + dp3 | group)
>    Data: set3
>    AIC   BIC logLik deviance REMLdev
>  65627 65743 -32799    65539   65597
> Random effects:
>  Groups   Name        Variance   Std.Dev.   Corr
>  group    (Intercept) 4.8336e-01 6.9524e-01
>           dp1         5.2199e-04 2.2847e-02  0.000
>           dp2         3.0528e-07 5.5252e-04  0.000  0.000
>           dp3         7.8888e-11 8.8819e-06 -0.966  0.000  0.000
>  Residual             1.9939e+00 1.4120e+00
> Number of obs: 17325, groups: group, 1575
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept)  1.363e+01  4.043e-02   337.1
> dp1         -2.930e-01  6.328e-03   -46.3
> dp2          3.924e-03  2.870e-04    13.7
> dp3         -1.900e-05  3.628e-06    -5.2
> Correlation of Fixed Effects:
>     (Intr) dp1    dp2
> dp1 -0.739
> dp2  0.616 -0.959
> dp3 -0.563  0.904 -0.982
>
> Warning message:
> In mer_finalize(ans) : false convergence (8)
> #############################################
>
>
> Does the output given is valid? Could someone please advice on this  
> message.
>
> Thank you
> Fir
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From kagba2006 at yahoo.com  Wed Sep 16 14:59:40 2009
From: kagba2006 at yahoo.com (FMH)
Date: Wed, 16 Sep 2009 05:59:40 -0700 (PDT)
Subject: [R-sig-ME] How to define the fixed and random effects in lmer
In-Reply-To: <2000402205.7525861253036537385.JavaMail.root@huron.cs.uoguelph.ca>
References: <2000402205.7525861253036537385.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <910586.83357.qm@web38305.mail.mud.yahoo.com>

Thank you for the answer. How about a model with:

1. only fixed and random effects for the slope are included?


Cheers
Fir

?


----- Original Message ----
From: Luca Borger <lborger at uoguelph.ca>
To: FMH <kagba2006 at yahoo.com>
Cc: Benjamin Michael Bolker <bolker at ufl.edu>; r-sig-mixed-models at r-project.org
Sent: Tuesday, September 15, 2009 6:42:17 PM
Subject: Re: [R-sig-ME] How to define the fixed and random effects in lmer

Hello,

that should be fairly easy to do, instead of "random =..." you use brackets to specify the random effects. For example:

1. fixed effects for the intercept and slope and only random effect for the intercept is included

? ? lmer(Pre~t +(1|group), data= prec)



or

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


? ? lmer(Pre~t + (t|group), data= prec)




HTH


Cheers,


Luca


----- Messaggio originale -----
Da: "FMH" <kagba2006 at yahoo.com>
A: "Benjamin Michael Bolker" <bolker at ufl.edu>, r-sig-mixed-models at r-project.org
Inviato: Marted?, 15 settembre 2009 13:30:25 GMT -05:00 U.S.A./Canada, stati orientali
Oggetto: Re: [R-sig-ME] How to define the fixed and random effects in lmer

Thank you for your advice, but actually i'm looking for the scripts via lmer function?in lme4 package.

Cheers
Fir



----- Original Message ----
From: "Bolker,Benjamin Michael" <bolker at ufl.edu>
To: FMH <kagba2006 at yahoo.com>; "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Sent: Tuesday, September 15, 2009 1:48:54 PM
Subject: RE: [R-sig-ME] How to define the fixed and random effects in lmer


I was running lme function on my data as shown below, in which the variables involved are:

########################################
#Pre : Precipitation
#t : time
#group : Group of precipitation
#prec: data set

lme(Pre ~ t| group, data = prec, random = ~ t| group)
#########################################

? I'm surprised this works (does it?) -- I didn't think |group was meaningful in a fixed-effects formula
specification

How could i write the scripts with lmer function with :
1. fixed effects for the intercept and slope and only random effect for the intercept is included

? ? lme(Pre~t, random=~1|group, data= prec)

2. fixed effects for the intercept and slope, and random effects for the intercept and slope are included


? ? lme(Pre~t, random=~t|group, data= prec)

3. only fixed effect for the intercept and only random effect for the intercept is included

? ? lme(Pre~1, random=~1|group, data= prec)

4. only fixed effects for the slope, and random effects for the intercept and slope are included

? lme(Pre~t-1, random=~1|group, data= prec)


? (I think. See if those work as expected)




_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models







From Timothy_Handley at nps.gov  Wed Sep 16 16:38:01 2009
From: Timothy_Handley at nps.gov (Timothy_Handley at nps.gov)
Date: Wed, 16 Sep 2009 07:38:01 -0700
Subject: [R-sig-ME] odd numbers in output from gls
Message-ID: <OF978BFA71.8E9CA227-ON88257633.004F14F1-88257633.00506100@nps.gov>


A couple weeks ago I posted a message on this topic to r-help, the response
was that this seemed like odd behavior, and that I ought to post it to one
of the developer lists. This seemed like the appropriate list, so I'm
posting the issue here (1) FYI, in case it is an error in gls (2) For my
information, in case I have made an error, in the hope that one of you
folks might be able to correct me. Thanks in advance for your time.

The issue is in 2 parts.

(A) I've used gls to fit a model with two fixed effects and a corExp
object. By my count, this fitting process estimates 5 parameters:
(Intercept), l10area, newx, range, and nugget. With 118 total df, there
should be 118 - 5 = 113 residual df. However, the output from summary.gls
reports 115 residual degrees of freedom. Is this an error in summary or
gls, or is there an error in my count?

(B) Summary.gls reports logLik=-273.6. Using my count of 5 estimated
parameters, the AIC should be -2*(-273.6) + 2*5 = 557.2. However,
summary.gls reports an AIC of 559.2. If one works backwards from the
reported AIC of 559.2, it seems that gls believes it has estimated 6
parameters in the fitting process. Why the difference?

Copied from R terminal:

>
> summary(sppl.i.ex)
Generalized least squares fit by maximum likelihood
  Model: all.all.rch ~ l10area + newx
  Data: gtemp
      AIC      BIC    logLik
  559.167 575.7911 -273.5835

Correlation Structure: Exponential spatial correlation
 Formula: ~x + y | area
 Parameter estimate(s):
     range     nugget
15.4448835  0.3741476

Coefficients:
               Value Std.Error   t-value p-value
(Intercept) 7.621306 0.7648135  9.964921  0.0000
l10area     6.332931 0.5589199 11.330659  0.0000
newx        0.066535 0.0204417  3.254857  0.0015

 Correlation:
        (Intr) l10are
l10area -0.605
newx     0.358 -0.024

Standardized residuals:
       Min         Q1        Med         Q3        Max
-3.0035983 -0.5990432 -0.2226852  0.5113270  2.4444263

Residual standard error: 2.820337
Degrees of freedom: 118 total; 115 residual

Tim Handley
Fire Effects Monitor
Santa Monica Mountains National Recreation Area
401 W. Hillcrest Dr.
Thousand Oaks, CA 91360
805-370-2347



From mspinola10 at gmail.com  Thu Sep 17 02:29:37 2009
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Wed, 16 Sep 2009 18:29:37 -0600
Subject: [R-sig-ME] Repeated measures for unbalanced data in R
Message-ID: <4AB182F1.7070309@gmail.com>

Dear list members,

Sorry for crossposting but I posted the following message to the 
R-SIG-Ecology and I did not have many answers.

I would like to run a repeated measure model in R and I would like to 
have your advice on how to parameterize the model and which package and 
function should I use..

I have:

Response variable: Disease rate (number of cases x 1000 people)
County (16 counties, it would be the subject)
Year: from 2002 to 2007

My data set is unbalanced (the counties do not have information for all 
the years).
Thank you very much in advance.
Best,

Manuel Sp?nola

-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gamil.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From adik at ilovebacon.org  Thu Sep 17 03:06:59 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 16 Sep 2009 18:06:59 -0700 (PDT)
Subject: [R-sig-ME] Repeated measures for unbalanced data in R
In-Reply-To: <4AB182F1.7070309@gmail.com>
References: <4AB182F1.7070309@gmail.com>
Message-ID: <Pine.LNX.4.64.0909161758500.8722@parser.ilovebacon.org>

Hi Manuel,

 	It's not quite clear from your question whether you are asking for
help choosing a statistical model IN GENERAL (not really the purpose of this
list, but sometimes people help out anyway) or whether you have a specific
model in mind and are askig for help RUNNING IT (in which case, you should
tell us what the model is, and mention what you're tried).

 	Regarding the MODEL question, it is not clear whether COUNTRY is
random (you're not looking for differences among countries, rather, you're
sampling countries and trying to tell whether there's a trend over time, so
you probably want

lmer(rate ~ year + (1|country), data=?)

 	...) or if YEAR is random (you're trying to look at differences
among countries, so you probably want

lmer(rate ~ country + (1|year), data=?)

 	...), though you may be empirically underidentified in the latter case.

...or maybe you want something else entirely. In any case, being as precise
as you can be about what you want to do and what the question is (i.e.,
"model help" or "method help" or "function help"), you may get better
responses on R-help lists (ME and Ecology, though I only read ME).

--Adam

On Wed, 16 Sep 2009, Manuel Sp?nola wrote:

> Dear list members,
>
> Sorry for crossposting but I posted the following message to the 
> R-SIG-Ecology and I did not have many answers.
>
> I would like to run a repeated measure model in R and I would like to have 
> your advice on how to parameterize the model and which package and function 
> should I use..
>
> I have:
>
> Response variable: Disease rate (number of cases x 1000 people)
> County (16 counties, it would be the subject)
> Year: from 2002 to 2007
>
> My data set is unbalanced (the counties do not have information for all the 
> years).
> Thank you very much in advance.
> Best,
>
> Manuel Sp?nola
>
> -- 
> Manuel Sp?nola, Ph.D.
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.ac.cr
> mspinola10 at gamil.com
> Tel?fono: (506) 2277-3598
> Fax: (506) 2237-7036
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From kagba2006 at yahoo.com  Thu Sep 17 11:48:47 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 17 Sep 2009 02:48:47 -0700 (PDT)
Subject: [R-sig-ME] p-value for the fixed effect
Message-ID: <829181.71996.qm@web38306.mail.mud.yahoo.com>

Dear All,

Could someone advice me the way ?to extract the p-value for the fixed effect in? lme and lmer functions?

Thank you
Fir






From kagba2006 at yahoo.com  Thu Sep 17 11:51:11 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 17 Sep 2009 02:51:11 -0700 (PDT)
Subject: [R-sig-ME] Correlation structure in lmer function
Message-ID: <943626.96478.qm@web38308.mail.mud.yahoo.com>

Dear All,

Could someone?give some advice on the way to define the correlation structure in lmer function from the lme4 package?

Thank you
Fir






From Thierry.ONKELINX at inbo.be  Thu Sep 17 12:12:05 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 17 Sep 2009 12:12:05 +0200
Subject: [R-sig-ME] Correlation structure in lmer function
In-Reply-To: <943626.96478.qm@web38308.mail.mud.yahoo.com>
References: <943626.96478.qm@web38308.mail.mud.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B48A90@inboexch.inbo.be>

You can't. That is one of the (few) drawbacks of lme4.

HTH,

Thierry 


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens FMH
Verzonden: donderdag 17 september 2009 11:51
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Correlation structure in lmer function

Dear All,

Could someone?give some advice on the way to define the correlation structure in lmer function from the lme4 package?

Thank you
Fir




_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Thierry.ONKELINX at inbo.be  Thu Sep 17 12:20:10 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 17 Sep 2009 12:20:10 +0200
Subject: [R-sig-ME] p-value for the fixed effect
In-Reply-To: <829181.71996.qm@web38306.mail.mud.yahoo.com>
References: <829181.71996.qm@web38306.mail.mud.yahoo.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B48A96@inboexch.inbo.be>

Lmer does not provide p-values. That is FAQ 7.35. More details on https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html.

With lme() you can use summary(model)$tTable

HTH,

Thierry 


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens FMH
Verzonden: donderdag 17 september 2009 11:49
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] p-value for the fixed effect

Dear All,

Could someone advice me the way ?to extract the p-value for the fixed effect in? lme and lmer functions?

Thank you
Fir




_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From matthias_gralle at eva.mpg.de  Thu Sep 17 13:23:16 2009
From: matthias_gralle at eva.mpg.de (Matthias Gralle)
Date: Thu, 17 Sep 2009 13:23:16 +0200
Subject: [R-sig-ME] Problems with formula for highly pseudoreplicate
	mixed-effects system
Message-ID: <4AB21C24.40705@eva.mpg.de>

Hello everybody,

I have posted this request on r-help before, but as nobody has responded 
over there, and as I have now followed some of the threads on this 
group, I will reformulate my request here and hope it makes more sense 
this way.

I have been trying for some weeks to state the correct design of my 
experiment as a GLM formula, and have not been able to find something 
appropriate in Pinheiro & Bates 2000 or with any of the local R users, 
so I am posting it here and hope somebody can help me.

In each experimental condition, described by
1) gene (10 levels, fixed, because of high interest to me)
2) species (2 levels, fixed, because of high interest)
3) day (2 levels, random)
4) replicate (2 levels per day, random),

I have several thousand data points consisting of two variables:

5) FITC (level of transfection of a cell)
6) APC (antibody binding to the cell)

Because of intrinsic and uncontrollable cell-to-cell variation, FITC 
varies quite uniformly over a wide range, and APC correlates rather well 
with FITC. In some cases, I made the intrinsic nesting of day and 
replicate explicit by  pasting them together as day_repl.

In order to make the examples clearer, I am attaching a reduced version 
of my data with only two levels of gene and ca. 400 data points per 
experimental condition:

 > 
small<-read.csv("small.csv",colClasses=c("character",rep("integer",2),rep("factor",5)))

My biological question is the following:

Is there any gene (in my set of 10 genes) where the species makes a 
difference in the relation between FITC and APC ? If yes, in what gene 
does species have an effect ? And what is the effect of the species 
difference ?

My first attempt was the following: fit the data points of each 
experimental condition to a linear equation
APC=Intercept+Slope*FITC

and analyse the slopes :
 > lm(Slope~species*gene*day_repl)    # the data set is not included 
here, but rather trivial

This analysis shows clear differences between the genes, but no effect 
of species and no interaction gene:species.

The linear fit to the cells is reasonably good, but of course does not 
represent the data set completely, so I wanted to incorporate the 
complete data set. The comparison is between models containing resp. 
omitting the interaction gene:species.

Model ignoring pseudoreplication:

 > model1=lmer(APC~(FITC+species+gene)3+(1|day)+(1|repl),REML=F,data=small)
 > model2=lmer(APC~(FITC+species+gene)2+(1|day)+(1|repl),REML=F,data=small)
 > anova(model1,model2)

gives me a significant difference for this data set and a highly 
significant difference (p<10-16) for the original data set, but I don't 
trust these results because the analysis does not account for 
pseudoreplication, and with >200000 data points in the original data 
set, any interaction will be significant (I have tried out several 
reduced models). In fact, lme gives >2000 000 denominator dfs. I have 
followed the discussion on why lmer does not estimate denominator dfs. 
My version of lme4 (0.999375-27) does not contain hatTrace to estimate a 
similar parameter.

In fact, I suppose FITC should be nested in day and replicate:
 > model3=lmer(APC~species*gene+(1|day/day_repl/FITC),data=small)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In day_repl:day :
  numerical expression has 800 elements: only the first used
(and several similar ones)

Can I do nesting without incurring this kind of error ? Or should I 
truncate or sample the experimental conditions with more data points in 
order to have at the end the same number of data points in every 
experimental condition ?

Last attempt:
 > model4=lmer(APC~gene*species+(1|day) + (1|repl) + 
(1+(gene:species)|FITC),data=small)
 > model5=lmer(APC~gene+species+(1|day) + (1|repl) + (1|FITC),data=small)
 > anova(model4,model5)

works with this smaller data set, but fails to converge (after >3 days) 
with the original data set. I am unsure if this is the right kind of 
analysis for the data and there is only a problem of convergence, or if 
it is the wrong formula.

I would be very grateful for any advice.

Matthias Gralle


For your information: I am using R version 2.8.0 (2008-10-20) on Ubuntu 
8.04 on a linux 2.6.24-24-generic kernel on different Intel systems with 
lme4 0.999375-27, and the output of some commmands is given below.

 > library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs


        The following object(s) are masked from package:base :

         colMeans,
         colSums,
         rcond,
         rowMeans,
         rowSums

 > sessionInfo()
function (package = NULL)
{
    z <- list()
    z$R.version <- R.Version()
    z$locale <- Sys.getlocale()
    if (is.null(package)) {
        package <- grep("^package:", search(), value = TRUE)
        keep <- sapply(package, function(x) x == "package:base" ||
            !is.null(attr(as.environment(x), "path")))
        package <- sub("^package:", "", package[keep])
    }
    pkgDesc <- lapply(package, packageDescription)
    if (length(package) == 0)
        stop("no valid packages were specified")
    basePkgs <- sapply(pkgDesc, function(x) !is.null(x$Priority) &&
        x$Priority == "base")
    z$basePkgs <- package[basePkgs]
    if (any(!basePkgs)) {
        z$otherPkgs <- pkgDesc[!basePkgs]
        names(z$otherPkgs) <- package[!basePkgs]
    }
    loadedOnly <- loadedNamespaces()
    loadedOnly <- loadedOnly[!(loadedOnly %in% package)]
    if (length(loadedOnly)) {
        names(loadedOnly) <- loadedOnly
        pkgDesc <- c(pkgDesc, lapply(loadedOnly, packageDescription))
        z$loadedOnly <- pkgDesc[loadedOnly]
    }
    class(z) <- "sessionInfo"
    z
}
<environment: namespace:utils>

str(small)
'data.frame':   800 obs. of  8 variables:
 $ X       : int  10846 10946 11046 11146 11246 11346 11446 11546 11646 
11746 ...
 $ FITC    : int  740 503 576 554 698 601 752 726 523 524 ...
 $ APC     : int  678 495 505 393 657 607 722 693 571 572 ...
 $ gene    : Factor w/ 2 levels "NM_1039029","NM_12242": 1 1 1 1 1 1 1 1 
1 1 ...
 $ species : Factor w/ 2 levels "human","other": 1 1 1 1 1 1 1 1 1 1 ...
 $ day     : int  20090806 20090806 20090806 20090806 20090806 20090806 
20090806 20090806 20090806 20090806 ...
 $ repl    : Factor w/ 2 levels "a","b": 1 1 1 1 1 1 1 1 1 1 ...
 $ day_repl: Factor w/ 4 levels "20090806_a","20090806_b",..: 1 1 1 1 1 
1 1 1 1 1 ...
 > summary(small)
       X               FITC            APC                gene      species
 Min.   :     1   Min.   :417.0   Min.   :256.0   NM_1039029:400   human:400
 1st Qu.: 19921   1st Qu.:555.0   1st Qu.:478.0   NM_12242  :400   other:400
 Median : 93356   Median :634.5   Median :557.0
 Mean   : 88387   Mean   :646.7   Mean   :565.7
 3rd Qu.:155904   3rd Qu.:730.0   3rd Qu.:650.2
 Max.   :168337   Max.   :973.0   Max.   :844.0
      day           repl          day_repl
 Min.   :20090806   a:542   20090806_a:283
 1st Qu.:20090806   b:258   20090806_b:100
 Median :20090812           20090812_a:259
 Mean   :20090809           20090812_b:158
 3rd Qu.:20090812
 Max.   :20090812

-- 
Matthias Gralle, PhD
Dept. Evolutionary Genetics
Max Planck Institute for Evolutionary Anthropology
Deutscher Platz 6
04103 Leipzig, Germany
Tel +49 341 3550 519
Fax +49 341 3550 555


From David.Duffy at qimr.edu.au  Thu Sep 17 14:44:22 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 17 Sep 2009 22:44:22 +1000 (EST)
Subject: [R-sig-ME] Problems with formula for highly
 pseudoreplicatemixed-effects system
In-Reply-To: <4AB21C24.40705@eva.mpg.de>
References: <4AB21C24.40705@eva.mpg.de>
Message-ID: <Pine.LNX.4.64.0909172231050.31522@orpheus.qimr.edu.au>

On Thu, 17 Sep 2009, Matthias Gralle wrote:

>
> I have been trying for some weeks to state the correct design of my 
> experiment as a GLM formula, and have not been able to find something 
> appropriate in Pinheiro & Bates 2000 or with any of the local R users, so I 
> am posting it here and hope somebody can help me.
>
> In each experimental condition, described by
> 1) gene (10 levels, fixed, because of high interest to me)
> 2) species (2 levels, fixed, because of high interest)
> 3) day (2 levels, random)
> 4) replicate (2 levels per day, random),
>
> I have several thousand data points consisting of two variables:
>
> 5) FITC (level of transfection of a cell)
> 6) APC (antibody binding to the cell)
>
> ...pseudoreplication, and with 
> 200000 data points in the original data set, any interaction will be 
>
What do you mean by pseudoreplication -- repeated measures?  Don't you 
want something like APC ~ gene + FITC + (FITC|gene) + species + (1|day) + 
(1|replicate), where your interest is in the random regression FITC|gene?. 
Alternatively/equivalently, how about testing for homogeneity of the 
FITC-APC (partial) correlation coefficients across 10 gene strata (what do 
these look like?).  The latter is natural for a multigroup SEM.


I hope I understand what you are talking about

Cheers, David Duffy.



From pogola at Princeton.EDU  Thu Sep 17 15:41:31 2009
From: pogola at Princeton.EDU (Patrick Onyango)
Date: Thu, 17 Sep 2009 09:41:31 -0400
Subject: [R-sig-ME] p-value for the fixed effect
In-Reply-To: <829181.71996.qm@web38306.mail.mud.yahoo.com>
References: <829181.71996.qm@web38306.mail.mud.yahoo.com>
Message-ID: <58B922CF-0834-4CDF-BB1D-3331E102ACA0@princeton.edu>

Hi,
First, here are some texts on R that you might find useful:
1. Pinheiro & Bates, 2000. Mixed Effects Model inn S and S-PLUS
2. West et al., 2007. Linear Mixed Models: A Practical Guide USing  
Statistical Software.
3. Crawley 2005: The R Book.

These books are gems!!

Second, and briefly: There are 3 approaches known to me; they are as  
follows
1. Obtain conditional tests (t-test and F-tests) using summary ( ) or  
anova ( ). These tests have some drawbacks (see Pinheiro & Bates,  
2000; West et al, 2007; Baayen et al., 2008). Also, the F  test in R  
is a Type 1, which means from what I have gathered that p values  
obtained are sequential, dependent on the order of your fixed effects  
in the model. The t-test is not.

2. Likelihood ratios test using the anova( ) function, which you can  
use to compare two models that differ in either the random effects  
structure in which case you specify REML as method; or the fixed  
effects structure in which case you specify method as ML. Please see  
above refs for further details. Here the p value is based on a chi- 
square distribution, which has its own drawbacks.

3. In lmer, you can also us MCMC commands, which are in the package  
languageR. So you will need to load that library. I will let the  
experts tell you more about what it does; because I am still reading  
about it myself.


Good luck
Patrick






On Sep 17, 2009, at 5:48 AM, FMH wrote:

> Dear All,
>
> Could someone advice me the way  to extract the p-value for the  
> fixed effect in  lme and lmer functions?
>
> Thank you
> Fir
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From matthias_gralle at eva.mpg.de  Thu Sep 17 18:53:02 2009
From: matthias_gralle at eva.mpg.de (Matthias Gralle)
Date: Thu, 17 Sep 2009 18:53:02 +0200
Subject: [R-sig-ME] Problems with formula for highly
 pseudoreplicatemixed-effects system
In-Reply-To: <Pine.LNX.4.64.0909172231050.31522@orpheus.qimr.edu.au>
References: <4AB21C24.40705@eva.mpg.de>
	<Pine.LNX.4.64.0909172231050.31522@orpheus.qimr.edu.au>
Message-ID: <4AB2696E.9050603@eva.mpg.de>

Thank you, David!

I have tried out a variant of your formula (pasting first gene and 
species as gene_species):

 > duffymodel=lmer(APC ~ gene*species + FITC + (FITC|gene) + 
(FITC|gene_species) + (FITC|species) + (1|day) + (1|day_repl),data=small)
 > duffymodelred=lmer(APC ~ gene+species + FITC + (FITC|gene) + 
(FITC|species) + (1|day) + (1|day_repl),data=small)
 > anova(duffymodel,duffymodelred)
Data: small
Models:
duffymodelred: APC ~ gene + species + FITC + (FITC | gene) + (FITC | 
species) +
duffymodelred: (1 | day) + (1 | day_repl)
duffymodel: APC ~ gene * species + FITC + (FITC | gene) + (FITC | 
gene_species) +
duffymodel: (FITC | species) + (1 | day) + (1 | day_repl)
Df AIC BIC logLik Chisq Chi Df Pr(>Chisq)
duffymodelred 13 8625.3 8686.2 -4299.7
duffymodel 17 8562.3 8641.9 -4264.1 71.068 4 1.350e-14 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

At first sight, this would seem to mean that gene:species is indeed a 
highly significant interaction. Now, what I meant by pseudoreplication 
is that the several hundred (or in my full data set, several thousand) 
cells in each experimental condition are not independent. They were all 
treated in exactly the same way, but due to intrinsic variability they 
express widely varying amounts of protein. I see in my data that 
replicate experiments sometimes differ strongly in their slope APC~FITC, 
even though each replicate contains several thousand data points. My 
results seem to be much more reliable when I repeat the experiment 
several times with independent cell treatment than when I increase the 
number of cells measured in one experimental condition. That is why I 
don't know if I can trust "your" formula.

Put another way, when I delete either (1|day) or (1|day_repl) from the 
formula, the difference is also highly significant, but I don't trust this.

hatTrace would maybe give a clearer indication of what I mean: there are 
too many residual degrees of freedom.

I'm sorry I don't know anything about testing for homogeneity of the 
partial correlation coefficients. I can try to look it up, or can you 
give me a hint ?

Hope this makes sense.

Matthias

David Duffy wrote:
> On Thu, 17 Sep 2009, Matthias Gralle wrote:
>
>>
>> I have been trying for some weeks to state the correct design of my 
>> experiment as a GLM formula, and have not been able to find something 
>> appropriate in Pinheiro & Bates 2000 or with any of the local R 
>> users, so I am posting it here and hope somebody can help me.
>>
>> In each experimental condition, described by
>> 1) gene (10 levels, fixed, because of high interest to me)
>> 2) species (2 levels, fixed, because of high interest)
>> 3) day (2 levels, random)
>> 4) replicate (2 levels per day, random),
>>
>> I have several thousand data points consisting of two variables:
>>
>> 5) FITC (level of transfection of a cell)
>> 6) APC (antibody binding to the cell)
>>
>> ...pseudoreplication, and with 200000 data points in the original 
>> data set, any interaction will be
> What do you mean by pseudoreplication -- repeated measures? Don't you 
> want something like APC ~ gene + FITC + (FITC|gene) + species + 
> (1|day) + (1|replicate), where your interest is in the random 
> regression FITC|gene?. Alternatively/equivalently, how about testing 
> for homogeneity of the FITC-APC (partial) correlation coefficients 
> across 10 gene strata (what do these look like?). The latter is 
> natural for a multigroup SEM.
>
>
> I hope I understand what you are talking about
>
> Cheers, David Duffy.
>
>
>
>
>


-- 
Matthias Gralle, PhD
Dept. Evolutionary Genetics
Max Planck Institute for Evolutionary Anthropology
Deutscher Platz 6
04103 Leipzig, Germany
Tel +49 341 3550 519
Fax +49 341 3550 555



From pauljohn32 at gmail.com  Thu Sep 17 21:34:54 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 17 Sep 2009 14:34:54 -0500
Subject: [R-sig-ME] question about lmer versus lme and evaluation of
	estimates of random parameters
Message-ID: <13e802630909171234m5d1903fau44d7d3d1ac42d8e4@mail.gmail.com>

Greetings!  I'm back for my once-a-semester adventure in mixed model
user support.

I'm asked to help a student with a problem involving surveys done in
about 50 countries.  The dependent variable is a 7 category ordinal
scale, and I've searched the archives on this (and other lists) and
see many of you recommend we try to use the linear/gaussian model
(with diagnostics after).  That's the only feasible option in R, as
far as I can tell. There are some commercial packages that claim to
support mixed model fitting for ordinal outputs (HLM), but I don't
have them and don't know if they are good.

We need to estimate a random intercept at the country level and the
researcher also supposes that there are variations across countries in
the slopes for 3 input variables.  I've estimated that with the newest
version of lmer in lme4.

However, I noticed when I tried to run the mcmcsamp routines to study
the distributions of estimates I noticed that the help page for
mcmsamp does not offer quite so much detail about how it is supposed
to be used.  Backtracking into this list again, I find that mcmcsamp
is "not yet ready" for non-gaussian models. Maybe it never will be, I
can't tell from the commentary.

But it is still supposed to be useful for linear models, right?   I
can still run mcmcsamp, but don't understand how to interact with the
result--the old stuff we were using last year with coda and the
HPDinterval function don't work any more.

Anyway, while searching in this list, I see some of you pointing
people in my situation to use routines from nlme, rather than lme4.

Is that right?  Should I push for use of lme (nlme) rather than lmer (lme4)?

I gather one advantage of using lmer is that it would allow correlated
random effects. However, if we just stay with a vanilla
specification--country level random intercepts and uncorrelated random
country level slopes, is there any advantage to lmer compared to lme?

Is lme expected to be faster because its random effects structure is simpler?

In either of these models, how do we gauge the accuracy of estimated
standard deviations for random parameters?

Can you tell me how to use mcmcsamp in current lme4

or

show me how people make that assessment in nlme ?



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From wayne.dawson at ips.unibe.ch  Fri Sep 18 10:39:40 2009
From: wayne.dawson at ips.unibe.ch (Dawson Wayne)
Date: Fri, 18 Sep 2009 10:39:40 +0200
Subject: [R-sig-ME] Phylogenetic meta-analysis and setting animal variable
	in MCMCglmm
Message-ID: <20090918103940.25379f1kxpy2s958@mail.unibe.ch>

Dear R-Sig-Me and R-Sig-Phylo users,

I have recently started using MCMCglmm with the aim of conducting  
phylogenetic meta-analysis. I have managed to run a basic model using  
MCMCglmm(), with weak uninformative priors specified, but I am  
struggling to work out how to incorporate a phylogeny. In particular,  
I am having problems setting the animal variable.
So, here is my set-up:

I have 123 species (plants), and my response variable is mean relative  
growth rate (RGR_mean), with associated variances (RGR_meanVAR). I  
want to see if the growth rates are related to plant invasiveness,  
which is (for the moment) the number of references in the global  
compendium of weeds (gcwrefs). I constructed a tree ("tree")"using  
phylomatic, which has some polytomies, and it is non-ultrametric.

This was my session:

sessionInfo()
R version 2.9.1 (2009-06-26)
i386-pc-mingw32

locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United  
Kingdom.1252;LC_MONETARY=English_United  
Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] MCMCglmm_1.11      gtools_2.6.1       combinat_0.0-6      
orthopolynom_1.0-1
  [5] polynom_1.3-6      pscl_1.03          mvtnorm_0.9-7      coda_0.13-4
  [9] Matrix_0.999375-30 lattice_0.17-25    tensorA_0.31       corpcor_1.5.2
[13] MASS_7.2-48        ape_2.3-2

loaded via a namespace (and not attached):
[1] gee_4.13-14 grid_2.9.1  nlme_3.1-93

#reading the data file and the tree

rgrgrime<-read.table("rgr_grime.txt",header=T)
rgr2<-subset(rgrgrime,gcwrefs!="0")
attach(rgr2)

tree<-read.tree("rgr_testtree.txt")
tree2<-drop.tip(tree,c("Dryas_octopetala","Helianthemum_chamaecistus","Helictotrichon_pratense","Zerna_erecta","Picea_nigra","Pinus_sylvestris"))

Some species had to be removed before analysis, but the end no. was  
123, and the data-file was in the same order as the tree tips.

So, the basic meta-analysis was (with default for burnin and no. of  
simulations)-

prior = list (R = list (V = 1,n = 1, fix = 1),G = list (G1 = list ( V  
= 1, n = 1)))

(using a weak prior as in the vignette tutorial- I am uncertain as to  
how I might change the priors to something more appropriate to my  
data, any recommendations for further reading on this would be great)-

model<-MCMCglmm (RGR_mean ~ sqrt (gcwrefs), random = ~ species_name,  
mev = RGR_meanVAR, prior = prior, data = rgr2)

This model converges, I've checked the autocorr statistics, and the  
posterior distributions, and they seem ok.

Then I want to add phylogeny in the "pedigree=" argument, and need to  
define the animal variable. In the MCMCglmm vignette, Jarrod says the  
animal variable will always be associated with the id levels in the  
first column of the pedigree table. But what will they be associated  
with if you pass a phylogeny through the pedigree argument? Logically,  
I thought I would make animal equal the phylogeny tip names-

rgr2$animal<-tree2$tip

Then I tried the model-

model2<-MCMCglmm(RGR_mean ~sqrt(gcwrefs), random = ~animal, mev =  
RGR_meanVAR, pedigree = tree2, prior = prior, data = rgr2, scale=F)

But I get the following error message-

Error in `$<-.data.frame`(`*tmp*`, "MCMC_mev", value = c(0.223606797749979,  :
   replacement has 252 rows, data has 188
In addition: Warning message:
In MCMCglmm(RGR_mean ~ sqrt(gcwrefs), random = ~animal, mev = RGR_meanVAR,  :
   some combinations in animal do not exist and 64 missing records  
have been generated

So, has anyone got any idea what I'm doing wrong here? Apologies if  
I'm being dumb, but I did only start using MCMCglmm yesterday, and I  
can't find any messages relating to phylogeny in MCMCglmm in either  
email-list.

Many thanks in advance,

Wayne

-- 
Dr. Wayne Dawson
Institute of Plant Sciences
University of Bern
Altenbergrain 21
3013 Bern
Switzerland
+41 (0)31 631 49 25



From j.hadfield at ed.ac.uk  Fri Sep 18 11:28:53 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 18 Sep 2009 10:28:53 +0100
Subject: [R-sig-ME] Phylogenetic meta-analysis and setting animal
	variable in MCMCglmm
In-Reply-To: <20090918103940.25379f1kxpy2s958@mail.unibe.ch>
References: <20090918103940.25379f1kxpy2s958@mail.unibe.ch>
Message-ID: <CE9A838D-CA4B-418A-9884-97DC598C9233@ed.ac.uk>

Dear Wayne,

This is my fault. With phylogenies the ancestral nodes are treated as  
missing data and so I set their measurement error to an arbitrary  
value. The code for working out how many "new" measurement errors  
there are  was incorrect.

L98 of MCMCglmm.R should read

mev<-c(mev, rep(1, dim(missing.combinations)[1]))

not

mev<-c(mev, rep(1, length(missing.combinations)))

I'll change this is in the next version.  In the mean time there are  
two work arounds that should give exactly the same results:

A)

specify nodes="TIPS" in the MCMCglmm function. This avoids augmenting  
with internal nodes, but can be much slower because the correlation  
structure is no longer sparse. The mixing properties can be better.

B)



Include the random effect

idh(sqrt(mev)):units  or idh(sqrt(RGR_meanVAR)):units in your case.

and set the variance for this term to 1:

prior$G$G2<-list(V=1, n=0.002, fix=1)

  This is equivalent because the random design matrix Z is diagonal  
matrix with the standard errors on the diagonal.  vZZ' defines the  
expected covariance structure of the measurement errors, and since v=1  
this is equal to independent measurement errors with variance equal o  
mev.

Cheers,

Jarrod






On 18 Sep 2009, at 09:39, Dawson Wayne wrote:

> Dear R-Sig-Me and R-Sig-Phylo users,
>
> I have recently started using MCMCglmm with the aim of conducting  
> phylogenetic meta-analysis. I have managed to run a basic model  
> using MCMCglmm(), with weak uninformative priors specified, but I am  
> struggling to work out how to incorporate a phylogeny. In  
> particular, I am having problems setting the animal variable.
> So, here is my set-up:
>
> I have 123 species (plants), and my response variable is mean  
> relative growth rate (RGR_mean), with associated variances  
> (RGR_meanVAR). I want to see if the growth rates are related to  
> plant invasiveness, which is (for the moment) the number of  
> references in the global compendium of weeds (gcwrefs). I  
> constructed a tree ("tree")"using phylomatic, which has some  
> polytomies, and it is non-ultrametric.
>
> This was my session:
>
> sessionInfo()
> R version 2.9.1 (2009-06-26)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United  
> Kingdom.1252;LC_MONETARY=English_United Kingdom. 
> 1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] MCMCglmm_1.11      gtools_2.6.1       combinat_0.0-6      
> orthopolynom_1.0-1
> [5] polynom_1.3-6      pscl_1.03          mvtnorm_0.9-7       
> coda_0.13-4
> [9] Matrix_0.999375-30 lattice_0.17-25    tensorA_0.31        
> corpcor_1.5.2
> [13] MASS_7.2-48        ape_2.3-2
>
> loaded via a namespace (and not attached):
> [1] gee_4.13-14 grid_2.9.1  nlme_3.1-93
>
> #reading the data file and the tree
>
> rgrgrime<-read.table("rgr_grime.txt",header=T)
> rgr2<-subset(rgrgrime,gcwrefs!="0")
> attach(rgr2)
>
> tree<-read.tree("rgr_testtree.txt")
> tree2<- 
> drop 
> .tip 
> (tree 
> ,c 
> ("Dryas_octopetala 
> ","Helianthemum_chamaecistus 
> ","Helictotrichon_pratense 
> ","Zerna_erecta","Picea_nigra","Pinus_sylvestris"))
>
> Some species had to be removed before analysis, but the end no. was  
> 123, and the data-file was in the same order as the tree tips.
>
> So, the basic meta-analysis was (with default for burnin and no. of  
> simulations)-
>
> prior = list (R = list (V = 1,n = 1, fix = 1),G = list (G1 = list  
> ( V = 1, n = 1)))

>
>
> (using a weak prior as in the vignette tutorial- I am uncertain as  
> to how I might change the priors to something more appropriate to my  
> data, any recommendations for further reading on this would be great)-
>
> model<-MCMCglmm (RGR_mean ~ sqrt (gcwrefs), random = ~ species_name,  
> mev = RGR_meanVAR, prior = prior, data = rgr2)
>
> This model converges, I've checked the autocorr statistics, and the  
> posterior distributions, and they seem ok.
>
> Then I want to add phylogeny in the "pedigree=" argument, and need  
> to define the animal variable. In the MCMCglmm vignette, Jarrod says  
> the animal variable will always be associated with the id levels in  
> the first column of the pedigree table. But what will they be  
> associated with if you pass a phylogeny through the pedigree  
> argument? Logically, I thought I would make animal equal the  
> phylogeny tip names-
>
> rgr2$animal<-tree2$tip
>
> Then I tried the model-
>
> model2<-MCMCglmm(RGR_mean ~sqrt(gcwrefs), random = ~animal, mev =  
> RGR_meanVAR, pedigree = tree2, prior = prior, data = rgr2, scale=F)
>
> But I get the following error message-
>
> Error in `$<-.data.frame`(`*tmp*`, "MCMC_mev", value =  
> c(0.223606797749979,  :
>  replacement has 252 rows, data has 188
> In addition: Warning message:
> In MCMCglmm(RGR_mean ~ sqrt(gcwrefs), random = ~animal, mev =  
> RGR_meanVAR,  :
>  some combinations in animal do not exist and 64 missing records  
> have been generated
>
> So, has anyone got any idea what I'm doing wrong here? Apologies if  
> I'm being dumb, but I did only start using MCMCglmm yesterday, and I  
> can't find any messages relating to phylogeny in MCMCglmm in either  
> email-list.
>
> Many thanks in advance,
>
> Wayne
>
> -- 
> Dr. Wayne Dawson
> Institute of Plant Sciences
> University of Bern
> Altenbergrain 21
> 3013 Bern
> Switzerland
> +41 (0)31 631 49 25
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mark.Lyman at atk.com  Fri Sep 18 18:02:37 2009
From: Mark.Lyman at atk.com (Lyman, Mark)
Date: Fri, 18 Sep 2009 10:02:37 -0600
Subject: [R-sig-ME] Error in documentation of lmer?
In-Reply-To: <mailman.7.1253268002.400.r-sig-mixed-models@r-project.org>
References: <mailman.7.1253268002.400.r-sig-mixed-models@r-project.org>
Message-ID: <A6BB278845329C41A08CB3C52A0E2C1001D8FBD9@ut40se02.atk.com>

According to the documentation of lmer, the way to get the fitting
algorithm steps is by setting the control = list(msVerbose=TRUE). For
me, this seems to be ignored.

> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
control=list(msVerbose=TRUE)))
Linear mixed model fit by REML 
Formula: Reaction ~ Days + (Days | Subject) 
   Data: sleepstudy 
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 Subject  (Intercept) 612.092  24.7405        
          Days         35.072   5.9221  0.066 
 Residual             654.941  25.5918        
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138

However, after looking at the lmer function, it appears that by setting
verbose=TRUE, I can get the steps.

> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
verbose=TRUE))
  0:     1768.4124: 0.516398 0.0967302  0.00000
  1:     1761.9813: 0.571375 0.550876 0.167097
  2:     1755.4534: 0.790274 0.455893 0.215675
  3:     1745.0053: 0.812187 0.239613 0.105945
  4:     1744.2582: 0.817183 0.213879 0.0692586
  5:     1743.9764: 0.834405 0.230507 0.0310488
  6:     1743.8121: 0.877690 0.218240 0.0280506
  7:     1743.7121: 0.964311 0.243094 0.0246631
  8:     1743.6293: 0.970155 0.232066 0.0135558
  9:     1743.6284: 0.966654 0.230511 0.0163398
 10:     1743.6283: 0.966755 0.230912 0.0156969
 11:     1743.6283: 0.966734 0.230909 0.0156904
Linear mixed model fit by REML 
Formula: Reaction ~ Days + (Days | Subject) 
   Data: sleepstudy 
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 Subject  (Intercept) 612.092  24.7405        
          Days         35.072   5.9221  0.066 
 Residual             654.941  25.5918        
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138

Is this a mistake in the documentation? Or have I missed something. I
have seen this on R 2.9.1 on Windows XP and on R 2.9.0 on Linux with
lme4 0.999375-31

Mark Lyman



From bates at stat.wisc.edu  Fri Sep 18 18:59:57 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 18 Sep 2009 11:59:57 -0500
Subject: [R-sig-ME] Error in documentation of lmer?
In-Reply-To: <A6BB278845329C41A08CB3C52A0E2C1001D8FBD9@ut40se02.atk.com>
References: <mailman.7.1253268002.400.r-sig-mixed-models@r-project.org>
	<A6BB278845329C41A08CB3C52A0E2C1001D8FBD9@ut40se02.atk.com>
Message-ID: <40e66e0b0909180959t22dd702bm86a6d8b922217dc@mail.gmail.com>

Hmm, both control = list(msVerbose = TRUE) and verbose = TRUE should
result in verbose output from the optimization, although verbose =
TRUE is the preferred form now.

It looks as if at some point I got carried away with cleaning up the
code and removed the part of lmer that handles the control argument.
I have restored that and will issue a new version of the lme4 package.

Thanks for the report.

On Fri, Sep 18, 2009 at 11:02 AM, Lyman, Mark <Mark.Lyman at atk.com> wrote:
> According to the documentation of lmer, the way to get the fitting
> algorithm steps is by setting the control = list(msVerbose=TRUE). For
> me, this seems to be ignored.
>
>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> control=list(msVerbose=TRUE)))
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
> ? Data: sleepstudy
> ?AIC ?BIC logLik deviance REMLdev
> ?1756 1775 -871.8 ? ? 1752 ? ?1744
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?Subject ?(Intercept) 612.092 ?24.7405
> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>
> Correlation of Fixed Effects:
> ? ? (Intr)
> Days -0.138
>
> However, after looking at the lmer function, it appears that by setting
> verbose=TRUE, I can get the steps.
>
>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> verbose=TRUE))
> ?0: ? ? 1768.4124: 0.516398 0.0967302 ?0.00000
> ?1: ? ? 1761.9813: 0.571375 0.550876 0.167097
> ?2: ? ? 1755.4534: 0.790274 0.455893 0.215675
> ?3: ? ? 1745.0053: 0.812187 0.239613 0.105945
> ?4: ? ? 1744.2582: 0.817183 0.213879 0.0692586
> ?5: ? ? 1743.9764: 0.834405 0.230507 0.0310488
> ?6: ? ? 1743.8121: 0.877690 0.218240 0.0280506
> ?7: ? ? 1743.7121: 0.964311 0.243094 0.0246631
> ?8: ? ? 1743.6293: 0.970155 0.232066 0.0135558
> ?9: ? ? 1743.6284: 0.966654 0.230511 0.0163398
> ?10: ? ? 1743.6283: 0.966755 0.230912 0.0156969
> ?11: ? ? 1743.6283: 0.966734 0.230909 0.0156904
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
> ? Data: sleepstudy
> ?AIC ?BIC logLik deviance REMLdev
> ?1756 1775 -871.8 ? ? 1752 ? ?1744
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev. Corr
> ?Subject ?(Intercept) 612.092 ?24.7405
> ? ? ? ? ?Days ? ? ? ? 35.072 ? 5.9221 ?0.066
> ?Residual ? ? ? ? ? ? 654.941 ?25.5918
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?251.405 ? ? ?6.825 ? 36.84
> Days ? ? ? ? ?10.467 ? ? ?1.546 ? ?6.77
>
> Correlation of Fixed Effects:
> ? ? (Intr)
> Days -0.138
>
> Is this a mistake in the documentation? Or have I missed something. I
> have seen this on R 2.9.1 on Windows XP and on R 2.9.0 on Linux with
> lme4 0.999375-31
>
> Mark Lyman
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sun Sep 20 16:46:49 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 20 Sep 2009 09:46:49 -0500
Subject: [R-sig-ME] lmList in the nlme package [Was Re: Please reply me]
Message-ID: <40e66e0b0909200746n21855f2ah42c624760cc1694d@mail.gmail.com>

On Sun, Sep 20, 2009 at 8:06 AM, mino rezayi <mino.rezayi at yahoo.com> wrote:

> Hi Professor Bates,I am a M.S student in statistics and I need to study your book (Mixed Effect Models in S - Splus) to learn mixed effect model, but there is examples?just for simple models ?in your book, and in my data there is 5 covariates and 1response variable,I want to make a lmList but I can''t , and there is no example similier to my data , would you please help me?

I assume that you are using R, in which case it is probably more
productive to send your questions to the
R-SIG-Mixed-Models at R-project.org mailing list.  I have taken the
liberty of cc:ing the list on this reply.

The lmList function takes a formula like the formula for lm but with
an additional term of the form | grp at the end to describe the
grouping.  You would give the formula for your model and the data set.

Generally it is easier to help if you provide a reproducible example,
perhaps with generated data.

Also you should note that lmList does not fit a mixed-effects model.
It fits separate models to the data corresponding to each level of the
grouping factor.



From Thierry.ONKELINX at inbo.be  Mon Sep 21 11:50:51 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 21 Sep 2009 11:50:51 +0200
Subject: [R-sig-ME] [R-sig-eco] mixed effects model in lme
In-Reply-To: <ac10b4f30909181254h4990ead8r536b0f017c58bca7@mail.gmail.com>
References: <200909181425.JAA29822@gauss.stat.iastate.edu>
	<ac10b4f30909181254h4990ead8r536b0f017c58bca7@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B959F5@inboexch.inbo.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090921/acfce0dc/attachment.pl>

From mino.rezayi at yahoo.com  Sun Sep 20 17:55:09 2009
From: mino.rezayi at yahoo.com (mino rezayi)
Date: Sun, 20 Sep 2009 08:55:09 -0700 (PDT)
Subject: [R-sig-ME] please reply
Message-ID: <172099.26077.qm@web111912.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090920/b2dc5daa/attachment.pl>

From bates at stat.wisc.edu  Mon Sep 21 16:31:19 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 Sep 2009 09:31:19 -0500
Subject: [R-sig-ME] Fwd: please reply
In-Reply-To: <40e66e0b0909210729na130eabq2901347ce64e8629@mail.gmail.com>
References: <210899.81564.qm@web111917.mail.gq1.yahoo.com>
	<40e66e0b0909210729na130eabq2901347ce64e8629@mail.gmail.com>
Message-ID: <40e66e0b0909210731i293364f7g1afea2777539131d@mail.gmail.com>

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Mon, Sep 21, 2009 at 9:29 AM
Subject: Re: please reply
To: mino rezayi <mino.rezayi at yahoo.com>


On Mon, Sep 21, 2009 at 6:33 AM, mino rezayi <mino.rezayi at yahoo.com> wrote:

> Thanck you for your helping. But I did regression in s-plus with MLE and I want to use NLME becouse of improving ?my results, but in Mixed Effect Models in S-Splus book? there is examples just for 1 covariate datas?and used some espicial?models?such as ?biexponential model. but my data have 4covariates with 1 response variable, (Y~X1+X2+X3+X4|grouped) ,would you please help me what kind of?models I can use?.
> ?Best regard
> M.Rezayi

1. Please use the R-SIG-Mixed-Models at R-project.org mailing list for
questions like this

2. Please use an informative Subject:

3. Please include a reproducible example.



From jmyer19 at lsu.edu  Mon Sep 21 18:56:18 2009
From: jmyer19 at lsu.edu (Jonathan Myers)
Date: Mon, 21 Sep 2009 11:56:18 -0500
Subject: [R-sig-ME] [R-sig-eco] Problem with correlation structure in lme
Message-ID: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090921/5fb9da86/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Sep 22 10:00:08 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 22 Sep 2009 10:00:08 +0200
Subject: [R-sig-ME] [R-sig-eco] Problem with correlation structure in lme
In-Reply-To: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>
References: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B95B6E@inboexch.inbo.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090922/0dfdc939/attachment.pl>

From mdu at ceh.ac.uk  Tue Sep 22 12:31:08 2009
From: mdu at ceh.ac.uk (Dunbar, Michael)
Date: Tue, 22 Sep 2009 11:31:08 +0100
Subject: [R-sig-ME] ranef, plot and dotplot in lmer and lme
Message-ID: <9C29AFE27E3FBA4DB1742CC8E8F74ECD04682E346B@nerckwmb1.ad.nerc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090922/1f0945f3/attachment.pl>

From jmyer19 at lsu.edu  Tue Sep 22 15:55:59 2009
From: jmyer19 at lsu.edu (Jonathan Myers)
Date: Tue, 22 Sep 2009 08:55:59 -0500
Subject: [R-sig-ME] [R-sig-eco] Problem with correlation structure in lme
In-Reply-To: <2E9C414912813E4EB981326983E0A10406B95B6E@inboexch.inbo.be>
References: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10406B95B6E@inboexch.inbo.be>
Message-ID: <ac10b4f30909220655i4907ca78u3bf96ac64a2a22dd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090922/c88cbc7d/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Sep 22 16:29:22 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 22 Sep 2009 16:29:22 +0200
Subject: [R-sig-ME] [R-sig-eco] Problem with correlation structure in lme
In-Reply-To: <ac10b4f30909220655i4907ca78u3bf96ac64a2a22dd@mail.gmail.com>
References: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10406B95B6E@inboexch.inbo.be>
	<ac10b4f30909220655i4907ca78u3bf96ac64a2a22dd@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406B95CD6@inboexch.inbo.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090922/956ead97/attachment.pl>

From jmyer19 at lsu.edu  Tue Sep 22 19:26:44 2009
From: jmyer19 at lsu.edu (Jonathan Myers)
Date: Tue, 22 Sep 2009 12:26:44 -0500
Subject: [R-sig-ME] [R-sig-eco] Problem with correlation structure in lme
In-Reply-To: <2E9C414912813E4EB981326983E0A10406B95CD6@inboexch.inbo.be>
References: <ac10b4f30909210956r2834f93fn6f7cbe8e0f687627@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10406B95B6E@inboexch.inbo.be>
	<ac10b4f30909220655i4907ca78u3bf96ac64a2a22dd@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A10406B95CD6@inboexch.inbo.be>
Message-ID: <ac10b4f30909221026g23f6598at29ced023baa8753a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090922/bcc1901f/attachment.pl>

From lamprianou at yahoo.com  Tue Sep 22 21:55:25 2009
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 22 Sep 2009 12:55:25 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 33, Issue 23
In-Reply-To: <mailman.2392.1253629783.25490.r-sig-mixed-models@r-project.org>
Message-ID: <795547.99102.qm@web58903.mail.re1.yahoo.com>

Dear friends, 
 I am wondering if anyone has a reference, or could give us his/her own opinion, on whether the multilevel models (MLM) and Generalizability Theory (GT) should give the same results. In essence, the GT uses ANOVA techniques to compute the variance components. Therefore, I would expect the models to give slightly different results when our data design is heavily unbalanced. Anyone else with a more theoretical opinion on the issue? Also, can the GT considered to be a special case of a general MLM?
There is a relevant paper but is not very illuminative: 

Estimating reliability of school-level scores using multilevel and generalizability theory models, Asia Pacific Education Review, Volume 10, Number 2 / June, 2009, by Min-Jeong Jeon, Guemin Lee , Jeong-Won Hwang and Sang-Jin Kang


Thank you for your response

P.S. When I say MLM, I mean a generalized mixed effects model such the ones we run with lmer


Dr. Iasonas Lamprianou


Assistant Professor (Educational Research and Evaluation)
Department of Education Sciences
European University-Cyprus
P.O. Box 22006
1516 Nicosia
Cyprus 
Tel.: +357-22-713178
Fax: +357-22-590539


Honorary Research Fellow
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044  161 275 3485
iasonas.lamprianou at manchester.ac.uk


--- On Tue, 22/9/09, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:

> From: r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
> Subject: R-sig-mixed-models Digest, Vol 33, Issue 23
> To: r-sig-mixed-models at r-project.org
> Date: Tuesday, 22 September, 2009, 3:29 PM
> Send R-sig-mixed-models mailing list
> submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help'
> to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more
> specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ???1. ranef, plot and dotplot in lmer and
> lme (Dunbar, Michael)
> ???2. Re: [R-sig-eco] Problem with
> correlation structure in lme
> ? ? ? (Jonathan Myers)
> ???3. Re: [R-sig-eco] Problem with
> correlation structure in lme
> ? ? ? (ONKELINX, Thierry)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Tue, 22 Sep 2009 11:31:08 +0100
> From: "Dunbar, Michael" <mdu at ceh.ac.uk>
> Subject: [R-sig-ME] ranef, plot and dotplot in lmer and
> lme
> To: "r-sig-mixed-models at r-project.org"
> ??? <r-sig-mixed-models at r-project.org>
> Message-ID:
> ??? <9C29AFE27E3FBA4DB1742CC8E8F74ECD04682E346B at nerckwmb1.ad.nerc.ac.uk>
> Content-Type: text/plain
> 
> 
> I have a two level-model with a random intercept and two
> random slope components. I can fit this with lme and then do
> plot(ranef(model), layout=c(3,1,1)), and somewhere in the
> code, it recognises that the x-axis scales are different and
> does the plot accordingly, and as expected.
> 
> With lmer, things seem more complicated. I can do:
> 
> rr1 <- ranef(model, postVar=TRUE)
> dotplot(rr1,scales = list(x = list(relation = 'free'),
> layout=c(3,1,1)))[["groupingfactor"]]
> 
> However it seems like the explicit specification of
> relation=free then causes layout to be ignored, generally
> leading to a 2x2 panel plot, which causes too much bunching
> in the groups to be able to read them, and generally not
> using the space on the page in an optimal manner.
> 
> It is possible to go for
> dotplot(rr1 , layout=c(3,1,1)))[["groupingfactor"]]
> and get the layout right but the x-axis scales are then
> equal for each panel, which will force the random slopes to
> be plotted on the same scale as the random intercepts :-(
> 
> Has anyone else also had these problems, and perhaps found
> a solution?
> 
> regards
> 
> Mike Dunbar
> 
> 
> 
> 
> -- 
> This message (and any attachments) is for the recipient
> ...{{dropped:10}}
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Tue, 22 Sep 2009 08:55:59 -0500
> From: Jonathan Myers <jmyer19 at lsu.edu>
> Subject: Re: [R-sig-ME] [R-sig-eco] Problem with
> correlation structure
> ??? in lme
> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
> ??? <ac10b4f30909220655i4907ca78u3bf96ac64a2a22dd at mail.gmail.com>
> Content-Type: text/plain
> 
> Dear Thierry,
> Thanks very much for your reply. I changed year from a
> factor to an integer
> and that change seems to have fixed the problem, although
> it's not clear to
> me why lme accepts an integer as a fixed effect (perhaps
> lme treats numeric
> variables as factors when included as fixed effects?). I
> also added
> heterogeneous variance structure for one of the fixed
> effects (fire
> treatment):
> 
> model <- lme(x ~ (water+fire+seed+year)^3, random = ~1 |
> block/plot/subplot,
> data = spprich5, correlation = corAR1(form = ~year),
> weights = varIdent(form
> = ~1 | fire))
> 
> The output from this model looks appropriate: I now have 53
> denDF for
> whole-plot factors and interactions, 54 denDF for
> split-factors and
> interactions, 230 denDF for year, and 230 denDF for
> interactions including
> year; there are a total of 360 observations (120 subplots
> sampled per year x
> 3 years) in the data set. The correlation structure for the
> repeated
> measurements was:
> 
> Correlation Structure: AR(1)
>  Formula: ~year | block/plot/subplot
>  Parameter estimate(s):
> ? ? ? Phi
> 0.5232107
> 
> Thanks again for the help!
> 
> All the best,
> 
> Jonathan
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Jonathan A. Myers
> Department of Biological Sciences
> Division of Systematics, Ecology, and Evolution
> Louisiana State University
> Baton Rouge, LA 70803 USA
> 
> E-mail: jmyer19 at lsu.edu
> Telephone: 225-578-7567
> Fax: 225-578-2597
> 
> Website: http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> On Tue, Sep 22, 2009 at 3:00 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> > wrote:
> 
> >? Dear Jonathan,
> >
> > How is year coded? As a number or as a factor? I woudl
> expect is to be a
> > factor, since that would make sense in your fixed
> effects. corAR1() will
> > probably require a number.
> >
> > Hopefully that might do the trick.
> >
> > HTH,
> >
> > Thierry
> >
> >
> >
> ----------------------------------------------------------------------------
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research
> Institute for Nature and
> > Forest
> > Cel biometrie, methodologie en kwaliteitszorg /
> Section biometrics,
> > methodology and quality assurance
> > Gaverstraat 4
> > 9500 Geraardsbergen
> > Belgium
> > tel. + 32 54/436 185
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is
> done may be no more
> > than asking him to perform a post-mortem examination:
> he may be able to say
> > what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for
> an answer does not
> > ensure that a reasonable answer can be extracted from
> a given body of data.
> > ~ John Tukey
> >
> >
> >
> >? ------------------------------
> > *Van:* jonamyers at gmail.com
> [mailto:jonamyers at gmail.com]
> *Namens *Jonathan
> > Myers
> > *Verzonden:* maandag 21 september 2009 18:56
> > *Aan:* ONKELINX, Thierry
> > *CC:* r-sig-mixed-models at r-project.org
> > *Onderwerp:* Re: [R-sig-eco] Problem with correlation
> structure in lme
> >
> > Dear Thierry and List Members,
> > Thank you very much for the help. I think I'm very
> close to having an
> > appropriate model, but I cannot figure out why I get
> the following error
> > message:
> >
> > MODEL:
> >? lme(species.richness ~ (water+fuel+seed+year)^3,
> random = ~1 |
> > block/plot/subplot, correlation = corAR1(form =
> ~year))
> >
> >? ERROR MESSAGE:
> > Error in attributes(.Data) <- c(attributes(.Data),
> attrib) :
> >???'names' attribute [240] must be the
> same length as the vector [0]
> >
> > I would greatly appreciate advice on how to specify
> the correlation
> > structure properly. The model works fine when I remove
> the optional
> > correlation argument.
> >
> > My overall goal is to have a model that accounts for
> repeated measurements
> > of the subplots in each of the three years in the data
> set (i.e., to avoid
> > pseudoreplication). I've included a description of the
> experiment below.
> >
> > Thanks very much,
> >
> > Jonathan
> >
> > My experiment consists of three categorical treatments
> (fire, water, seed)
> > arranged in a split-plot design. The fire treatment (2
> levels) and water
> > treatment (3 levels) were assigned to plots, and the
> seed treatment (2
> > levels) was assigned to two subplots within each plot.
> There are 60 total
> > plots (120 total subplots), divided equally among two
> large blocks (30 plots
> > per block). I measured species richness in each
> subplot in three separate
> > years. I would like to test for main effects of the
> three treatments, a main
> > effect of year, and all 3-way interactions. To avoid
> pseudoreplication, I
> > would also like to account for repeated measurements
> of the subplots in each
> > of the three years.
> >
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > Jonathan A. Myers
> > Department of Biological Sciences
> > Division of Systematics, Ecology, and Evolution
> > Louisiana State University
> > Baton Rouge, LA 70803 USA
> >
> > E-mail: jmyer19 at lsu.edu
> > Telephone: 225-578-7567
> > Fax: 225-578-2597
> >
> > Website: http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >
> >
> >
> >
> > On Mon, Sep 21, 2009 at 4:50 AM, ONKELINX, Thierry
> <
> > Thierry.ONKELINX at inbo.be>
> wrote:
> >
> >>? Dear Jonathan,
> >>
> >> Since you have multiple measurements (from several
> years) in your
> >> subplots, it does makes sense to include that in
> the random effect.
> >>
> >> There are several things you can do with the
> information about the years.
> >> First you could assume that there is a different
> trend (random slope along
> >> year) in each plot and subpplot. Here is an
> example with some tay data.
> >>
> >>
> >> years *<-* rnorm(
> >> 3)
> >>
> >> sdPlot *<-* 2
> >>
> >> sdSubplot *<-*
> >> 1
> >>
> >> sdYear *<-*
> >> 0.5
> >>
> >> sdError *<-*
> >> 0.1
> >>
> >> dataset *<-* expand.grid(year =
> >> 1:3, plot = factor(LETTERS[1:26]), subplot =
> factor(letters[1:26]))
> >>
> >> dataset
> >> $Y *<-* with(dataset, years[year] +
> rnorm(length(unique(plot)), sd =
> >> sdPlot)[plot] + year * rnorm(length(unique(plot)),
> sd = sdYear)[plot] +rnorm(length(unique(subplot)), sd =
> sdSubplot)
> >> [subplot] + rnorm(nrow(dataset), sd = sdError))
> >>
> >> library(nlme)
> >>
> >> lme(Y
> >> ~ factor(year), random = ~year|plot/subplot, data
> = dataset)
> >>
> >> Or you can assume that the random slope is only at
> the plot level. Since
> >> you have only a few subplots per plot, that will
> be more reasonable.
> >>
> >> lme(Y
> >> ~ factor(year), random = list(plot = pdSymm(form =
> ~year), subplot =
> >> pdSymm(form = ~1)), data = dataset)
> >>
> >> lme(Y
> >> ~ factor(year), random = list(plot = pdDiag(form =
> ~year), subplot =
> >> pdSymm(form = ~1)), data = dataset)
> >>
> >> Another option is that you assume that the
> residuals are correlated in
> >> time (e.g. AR1 correlation).
> >>
> >> lme(Y
> >> ~ factor(year), random = ~1|plot/subplot, data =
> dataset, correlation =
> >> corAR1(form = ~year))
> >>
> >> And you can even combine both a random slope and a
> correlation structure.
> >>
> >> lme(Y
> >> ~ factor(year), random = list(plot = pdDiag(form =
> ~year), subplot =
> >> pdSymm(form = ~1)), data = dataset, correlation =
> corAR1(form = ~year))
> >>
> >>
> >>
> >> Note that in the SAS the correlation structure
> defines the correlation
> >> between the random effects. This is in nlme
> equivalent with the pdClasses
> >> (see ?pdClasses for more info). The correlation
> structures in in nlme work
> >> on the residuals. See ?corClasses
> >>
> >> HTH,
> >>
> >> Thierry
> >>
> >> PS. R-sig-mixed models is a better list for this
> kind of questions.
> >>
> >>
> >>
> ----------------------------------------------------------------------------
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research
> Institute for Nature and
> >> Forest
> >> Cel biometrie, methodologie en kwaliteitszorg /
> Section biometrics,
> >> methodology and quality assurance
> >> Gaverstraat 4
> >> 9500 Geraardsbergen
> >> Belgium
> >> tel. + 32 54/436 185
> >> Thierry.Onkelinx at inbo.be
> >> www.inbo.be
> >>
> >> To call in the statistician after the experiment
> is done may be no more
> >> than asking him to perform a post-mortem
> examination: he may be able to say
> >> what the experiment died of.
> >> ~ Sir Ronald Aylmer Fisher
> >>
> >> The plural of anecdote is not data.
> >> ~ Roger Brinner
> >>
> >> The combination of some data and an aching desire
> for an answer does not
> >> ensure that a reasonable answer can be extracted
> from a given body of data.
> >> ~ John Tukey
> >>
> >>
> >>
> >>? ------------------------------
> >> *Van:* jonamyers at gmail.com
> [mailto:jonamyers at gmail.com]
> *Namens *Jonathan
> >> Myers
> >> *Verzonden:* vrijdag 18 september 2009 21:55
> >> *Aan:* Philip Dixon
> >> *CC:* r-sig-ecology at r-project.org;
> ONKELINX, Thierry; mdu at ceh.ac.uk
> >> *Onderwerp:* Re: [R-sig-eco] mixed effects model
> in lme
> >>
> >>???Dear List Members,
> >> Thank you very much for your helpful replies and
> advice.
> >>
> >> I would greatly appreciate any additional advice
> on how to rewrite my lme
> >> model to account for repeated measurements of the
> subplots in each of the
> >> three years. I imagine this would involve
> modifying the random-effects
> >> component of the model and/or using the
> "CorStruct" function to specify the
> >> correlation structure (e.g., compound symmetry,
> autoregressive-moving
> >> average [AR1], etc.) for the repeated measures. My
> current model is:
> >>
> >> model = lme(species.richness ~
> (water+fuel+seed+year)^3, random = ~1 |
> >> block/plot)
> >>
> >> Note that the model now includes only 3-way
> interactions for the fixed
> >> effects (I removed the 4-way interaction).
> According to Crawley (2007, The R
> >> Book, pg. 632), it is not necessary to specify the
> smallest nested spatial
> >> scale (subplot) in the random-effects component of
> the model; i.e., "random
> >> = ~1 | block/plot" will produce results identical
> to "random = ~1 |
> >> block/plot/subplot."
> >>
> >> Can anyone provide advice for how to rewrite this
> model to account for
> >> repeated measurements of the subplots in the three
> years? Either code for R
> >> or code for SAS would be helpful at this point, as
> I may ultimately have to
> >> perform the analysis in SAS to figure out how to
> do it using lme in R.
> >>
> >> I've pasted my original message below that
> includes the description of the
> >> experiment.
> >>
> >> Thanks very much!
> >>
> >> Jonathan
> >>
> >>
> >> Original message:
> >>
> >>? Dear List Members,
> >>
> >> I am using a mixed-effects model in lme and would
> like to know whether I
> >> am using the proper structure for the
> random-effects component of the model.
> >> My experiment consists of three categorical
> treatments (fire, water, seed)
> >> arranged in a split-plot design. The fire
> treatment (2 levels) and water
> >> treatment (3 levels) were assigned to plots, and
> the seed treatment (2
> >> levels) was assigned to two subplots within each
> plot. There are 60 total
> >> plots (120 total subplots), divided equally among
> two large blocks (30 plots
> >> per block). I measured species richness in each
> subplot in three separate
> >> years. My goal is to test for main effects of the
> three treatments, a main
> >> effect of year, and all interactions. My current
> model consists of four
> >> factorial fixed effects (fire, water, seed, year)
> and 1 random effect
> >> (block), with plots nested within blocks (to
> account for the split-plot
> >> structure of the experiment):
> >>
> >> model = lme(species.richness ~
> water*fuel*seed*year, random = ~1 |
> >> block/plot)
> >>
> >> The ANOVA output includes two denominator degrees
> of freedom (denDF): 53
> >> denDF for plot factors (fire, water, fire x water
> interaction) and 270 denDF
> >> for split-plot factors (everything else).
> >>
> >> I would greatly appreciate feedback as to whether
> the random-effects
> >> component of the model looks appropriate, and if
> not, how it should be
> >> modified.
> >>
> >> Thanks very much!
> >>
> >> Cheers,
> >>
> >> Jonathan
> >>
> >> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >> Jonathan A. Myers
> >> Department of Biological Sciences
> >> Division of Systematics, Ecology, and Evolution
> >> Louisiana State University
> >> Baton Rouge, LA 70803 USA
> >> Telephone: 225-578-7567
> >> Fax: 225-578-2597
> >> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> On Fri, Sep 18, 2009 at 9:25 AM, Philip Dixon
> <pdixon at iastate.edu>
> wrote:
> >>
> >>> I believe you have three levels of variation:
> >>>
> >>> between plots assigned to the same fire/water
> treatment
> >>> between subplots assigned to the same
> fire/water/seed treatment
> >>> and between measurements
> (fire/water/seed/year)
> >>>
> >>> Your models (and the previous replies) appear
> to be ignoring the repeated
> >>> measurements on the same subplot.? You
> will probably need to explore
> >>> various
> >>> choices of correlation structure among years
> (e.g. Compound Symmetry =
> >>> split/split plot, ar(1), ...)
> >>>
> >>> One key is that tests of split plot factors
> have 270 error DF (denDF).
> >>>? You
> >>> only have 120 subplots.
> >>>
> >>> Also, I suggest you retain at least all the
> fire/water/seed interactions
> >>> in
> >>> the model.???Each combination
> of fire/water/seed represents a specific
> >>> "thing"
> >>> (some call it treatment, but treatment has
> many different meanings) done
> >>> to a
> >>> subplot.???The full model with
> all these interactions corresponds to a
> >>> cell
> >>> means model.? Marginal means (i.e. main
> effects) correspond to averages
> >>> of
> >>> cell means.? If you drop those
> interactions, you are assuming that the
> >>> true
> >>> interaction is zero, so those dropped
> interactions only inform you about
> >>> the
> >>> error variation.? I believe this is
> somewhat dangerous because tests of
> >>> interactions have low power (i.e. lower than
> tests of main effects).
> >>> I recognize that there are many other opinions
> here.
> >>>
> >>> The above argument does not apply to
> interactions with year because year
> >>> is
> >>> not randomly assigned to a subplot or
> plot.? Many different opinions.
> >>>
> >>> I prefer to fit models like this in SAS,
> because it is much easier to get
> >>> meaningful estimates (i.e. not just tests) in
> SAS than in lme.
> >>>
> >>> Best wishes,
> >>> Philip Dixon
> >>>
> >>>
> _______________________________________________
> >>> R-sig-ecology mailing list
> >>> R-sig-ecology at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-ecology
> >>>
> >>
> >>
> >>
> >> --
> >>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >> Jonathan A. Myers
> >> Department of Biological Sciences
> >> Division of Systematics, Ecology, and Evolution
> >> Louisiana State University
> >> Baton Rouge, LA 70803 USA
> >>
> >> E-mail: jmyer19 at lsu.edu
> >> Telephone: 225-578-7567
> >> Fax: 225-578-2597
> >>
> >> Website: http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> >>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >>
> >> Druk dit bericht a.u.b. niet onnodig af.
> >> Please do not print this message unnecessarily.
> >>
> >> Dit bericht en eventuele bijlagen geven enkel de
> visie van de schrijver weer
> >> en binden het INBO onder geen enkel beding, zolang
> dit bericht niet bevestigd is
> >> door een geldig ondertekend document. The views
> expressed in? this message
> >> and any annex are purely those of the writer and
> may not be regarded as stating
> >> an official position of INBO, as long as the
> message is not confirmed by a duly
> >> signed document.
> >>
> >>
> >
> >
> >
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > Jonathan A. Myers
> > Department of Biological Sciences
> > Division of Systematics, Ecology, and Evolution
> > Louisiana State University
> > Baton Rouge, LA 70803 USA
> >
> > E-mail: jmyer19 at lsu.edu
> > Telephone: 225-578-7567
> > Fax: 225-578-2597
> >
> > Website: http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> >
> > Druk dit bericht a.u.b. niet onnodig af.
> > Please do not print this message unnecessarily.
> >
> > Dit bericht en eventuele bijlagen geven enkel de visie
> van de schrijver weer
> > en binden het INBO onder geen enkel beding, zolang dit
> bericht niet bevestigd is
> > door een geldig ondertekend document. The views
> expressed in? this message
> > and any annex are purely those of the writer and may
> not be regarded as stating
> > an official position of INBO, as long as the message
> is not confirmed by a duly
> > signed document.
> >
> >
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Tue, 22 Sep 2009 16:29:22 +0200
> From: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Subject: Re: [R-sig-ME] [R-sig-eco] Problem with
> correlation structure
> ??? in lme
> To: <jmyer19 at lsu.edu>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
> ??? <2E9C414912813E4EB981326983E0A10406B95CD6 at inboexch.inbo.be>
> Content-Type: text/plain
> 
> Dear Jonathan,
>  
> Note that you can use year as a factor in your fixed
> effect. But it
> needs to be a number for the corAR1() structure. I would
> even recommend
> to include is as a factor in the fixed effects, unless you
> have sound
> evidence for a linear trend along year. 
>  
> You could something like this:
>  
> lme(x ~ (water+fire+seed+factor(year))^3 + block, random =
> ~1 |
> plot/subplot, data = spprich5, correlation = corAR1(form =
> ~year),
> weights = varIdent(form = ~1 | fire))
>  
> Or you could add year twice to the dataset. Once as a
> number and once as
> a factor. 
>  
> Note that I moved block to the fixed effects because you
> have only two
> levels. You won't get good variance estimates with only two
> levels.
>  
> HTH,
>  
> Thierry
>  
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute
> for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section
> biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done
> may be no more
> than asking him to perform a post-mortem examination: he
> may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an
> answer does not
> ensure that a reasonable answer can be extracted from a
> given body of
> data.
> ~ John Tukey
> ? 
> 
> 
> ________________________________
> 
> Van: jonamyers at gmail.com
> [mailto:jonamyers at gmail.com]
> Namens Jonathan
> Myers
> Verzonden: dinsdag 22 september 2009 15:56
> Aan: ONKELINX, Thierry
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-eco] Problem with correlation
> structure in lme
> 
> 
> Dear Thierry, 
> 
> Thanks very much for your reply. I changed year from a
> factor to an
> integer and that change seems to have fixed the problem,
> although it's
> not clear to me why lme accepts an integer as a fixed
> effect (perhaps
> lme treats numeric variables as factors when included as
> fixed
> effects?). I also added heterogeneous variance structure
> for one of the
> fixed effects (fire treatment):
> 
> model <- lme(x ~ (water+fire+seed+year)^3, random = ~1
> |
> block/plot/subplot, data = spprich5, correlation =
> corAR1(form = ~year),
> weights = varIdent(form = ~1 | fire))
> 
> The output from this model looks appropriate: I now have 53
> denDF for
> whole-plot factors and interactions, 54 denDF for
> split-factors and
> interactions, 230 denDF for year, and 230 denDF for
> interactions
> including year; there are a total of 360 observations (120
> subplots
> sampled per year x 3 years) in the data set. The
> correlation structure
> for the repeated measurements was:
> 
> Correlation Structure: AR(1)
>  Formula: ~year | block/plot/subplot 
>  Parameter estimate(s):
> ? ? ? Phi 
> 0.5232107
> 
> Thanks again for the help!
> 
> All the best,
> 
> Jonathan
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Jonathan A. Myers
> Department of Biological Sciences
> Division of Systematics, Ecology, and Evolution
> Louisiana State University
> Baton Rouge, LA 70803 USA
> 
> E-mail: jmyer19 at lsu.edu
> Telephone: 225-578-7567
> Fax: 225-578-2597
> 
> Website: http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~?
> ???
> 
> On Tue, Sep 22, 2009 at 3:00 AM, ONKELINX, Thierry
> <Thierry.ONKELINX at inbo.be>
> wrote:
> 
> 
> ??? Dear Jonathan,
> ?????
> ??? How is year coded? As a number or as a
> factor? I woudl expect is
> to be a factor, since that would make sense in your fixed
> effects.
> corAR1() will probably require a number.
> ?????
> ??? Hopefully that might do the trick.
> ?????
> ??? HTH,
> ?????
> ??? Thierry
> 
> ??? 
> ------------------------------------------------------------------------
> ----
> ??? ir. Thierry Onkelinx
> ??? Instituut voor natuur- en bosonderzoek /
> Research Institute for
> Nature and Forest
> ??? Cel biometrie, methodologie en
> kwaliteitszorg / Section
> biometrics, methodology and quality assurance
> ??? Gaverstraat 4
> ??? 9500 Geraardsbergen
> ??? Belgium
> ??? tel. + 32 54/436 185
> ??? Thierry.Onkelinx at inbo.be
> ??? www.inbo.be
> ??? 
> ??? To call in the statistician after the
> experiment is done may be
> no more than asking him to perform a post-mortem
> examination: he may be
> able to say what the experiment died of.
> ??? ~ Sir Ronald Aylmer Fisher
> ??? 
> ??? The plural of anecdote is not data.
> ??? ~ Roger Brinner
> ??? 
> ??? The combination of some data and an
> aching desire for an answer
> does not ensure that a reasonable answer can be extracted
> from a given
> body of data.
> ??? ~ John Tukey
> ??? ? 
> 
> ?????
> 
> ________________________________
> 
> ??? 
> ??? Van: jonamyers at gmail.com
> [mailto:jonamyers at gmail.com]
> Namens
> Jonathan Myers
> ??? 
> ??? Verzonden: maandag 21 september 2009
> 18:56
> ??? Aan: ONKELINX, Thierry
> ??? CC: r-sig-mixed-models at r-project.org
> ??? Onderwerp: Re: [R-sig-eco] Problem with
> correlation structure in
> lme
> ??? 
> ??? 
> ??? Dear Thierry and List Members, 
> 
> ??? Thank you very much for the help. I
> think I'm very close to
> having an appropriate model, but I cannot figure out why I
> get the
> following error message:
> 
> ??? MODEL:
> ??? lme(species.richness ~
> (water+fuel+seed+year)^3, random = ~1 |
> block/plot/subplot, correlation = corAR1(form = ~year))
> 
> ??? ERROR MESSAGE:
> ??? Error in attributes(.Data) <-
> c(attributes(.Data), attrib) : 
> ??? ? 'names' attribute [240] must be
> the same length as the vector
> [0]
> 
> ??? I would greatly appreciate advice on how
> to specify the
> correlation structure properly. The model works fine when I
> remove the
> optional correlation argument.
> 
> ??? My overall goal is to have a model that
> accounts for repeated
> measurements of the subplots in each of the three years in
> the data set
> (i.e., to avoid pseudoreplication). I've included a
> description of the
> experiment below.
> 
> ??? Thanks very much,
> 
> ??? Jonathan 
> ??? 
> ??? 
> ??? My experiment consists of three
> categorical treatments (fire,
> water, seed) arranged in a split-plot design. The fire
> treatment (2
> levels) and water treatment (3 levels) were assigned to
> plots, and the
> seed treatment (2 levels) was assigned to two subplots
> within each plot.
> There are 60 total plots (120 total subplots), divided
> equally among two
> large blocks (30 plots per block). I measured species
> richness in each
> subplot in three separate years. I would like to test for
> main effects
> of the three treatments, a main effect of year, and all
> 3-way
> interactions. To avoid pseudoreplication, I would also like
> to account
> for repeated measurements of the subplots in each of the
> three years. 
> 
> ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? Jonathan A. Myers
> ??? Department of Biological Sciences
> ??? Division of Systematics, Ecology, and
> Evolution
> ??? Louisiana State University
> ??? Baton Rouge, LA 70803 USA
> ??? 
> ??? E-mail: jmyer19 at lsu.edu
> ??? Telephone: 225-578-7567
> ??? Fax: 225-578-2597
> ??? 
> ??? Website:
> http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> ?????
> 
> 
> ??? On Mon, Sep 21, 2009 at 4:50 AM,
> ONKELINX, Thierry
> <Thierry.ONKELINX at inbo.be>
> wrote:
> ??? 
> 
> ??? ??? Dear Jonathan,
> ??? ?????
> ??? ??? Since you have
> multiple measurements (from several
> years) in your subplots, it does makes sense to include
> that in the
> random effect.
> ??? ?????
> ??? ??? There are several
> things you can do with the information
> about the years. First you could assume that there is a
> different trend
> (random slope along year) in each plot and subpplot. Here
> is an example
> with some tay data.
> ??? ?????
> ??? ??? years <- rnorm(
> 
> ??? ??? 3) 
> 
> ??? ??? sdPlot <- 2
> 
> ??? ??? sdSubplot <- 
> 
> ??? ??? 1 
> 
> ??? ??? sdYear <- 
> 
> ??? ??? 0.5 
> 
> ??? ??? sdError <- 
> 
> ??? ??? 0.1 
> 
> ??? ??? dataset <-
> expand.grid(year = 
> 
> ??? ??? 1:3, plot =
> factor(LETTERS[1:26]), subplot =
> factor(letters[1:26])) 
> 
> ??? ??? dataset
> 
> ??? ??? $Y <-
> with(dataset, years[year] +
> rnorm(length(unique(plot)), sd = sdPlot)[plot] + year *
> rnorm(length(unique(plot)), sd = sdYear)[plot] +
> rnorm(length(unique(subplot)), sd = sdSubplot)[subplot] +
> rnorm(nrow(dataset), sd = sdError)) 
> 
> ??? ??? library(nlme)
> 
> ??? ??? 
> 
> ??? ??? lme(Y 
> 
> ??? ??? ~ factor(year),
> random = ~year|plot/subplot, data =
> dataset) 
> 
> ??? ??? Or you can assume
> that the random slope is only at the
> plot level. Since you have only a few subplots per plot,
> that will be
> more reasonable.
> 
> ??? ??? lme(Y 
> 
> ??? ??? ~ factor(year),
> random = list(plot = pdSymm(form =
> ~year), subplot = pdSymm(form = ~1)), data = dataset) 
> 
> ??? ??? lme(Y 
> 
> ??? ??? ~ factor(year),
> random = list(plot = pdDiag(form =
> ~year), subplot = pdSymm(form = ~1)), data = dataset) 
> 
> ??? ??? Another option is
> that you assume that the residuals are
> correlated in time (e.g. AR1 correlation).
> 
> ??? ??? lme(Y 
> 
> ??? ??? ~ factor(year),
> random = ~1|plot/subplot, data =
> dataset, correlation = corAR1(form = ~year)) 
> 
> ??? ??? And you can even
> combine both a random slope and a
> correlation structure.
> 
> ??? ??? lme(Y 
> 
> ??? ??? ~ factor(year),
> random = list(plot = pdDiag(form =
> ~year), subplot = pdSymm(form = ~1)), data = dataset,
> correlation =
> corAR1(form = ~year)) 
> 
> ??? ?????
> 
> ??? ??? Note that in the SAS
> the correlation structure defines
> the correlation between the random effects. This is in nlme
> equivalent
> with the pdClasses (see ?pdClasses for more info). The
> correlation
> structures in in nlme work on the residuals. See
> ?corClasses
> 
> ??? ??? HTH,
> 
> ??? ??? Thierry
> 
> ??? ??? PS. R-sig-mixed
> models is a better list for this kind of
> questions.
> 
> ??? 
> ------------------------------------------------------------------------
> ----
> ??? ??? ir. Thierry Onkelinx
> ??? ??? Instituut voor
> natuur- en bosonderzoek / Research
> Institute for Nature and Forest
> ??? ??? Cel biometrie,
> methodologie en kwaliteitszorg / Section
> biometrics, methodology and quality assurance
> ??? ??? Gaverstraat 4
> ??? ??? 9500 Geraardsbergen
> ??? ??? Belgium
> ??? ??? tel. + 32 54/436 185
> ??? ??? Thierry.Onkelinx at inbo.be
> ??? ??? www.inbo.be
> ??? ??? 
> ??? ??? To call in the
> statistician after the experiment is done
> may be no more than asking him to perform a post-mortem
> examination: he
> may be able to say what the experiment died of.
> ??? ??? ~ Sir Ronald Aylmer
> Fisher
> ??? ??? 
> ??? ??? The plural of
> anecdote is not data.
> ??? ??? ~ Roger Brinner
> ??? ??? 
> ??? ??? The combination of
> some data and an aching desire for an
> answer does not ensure that a reasonable answer can be
> extracted from a
> given body of data.
> ??? ??? ~ John Tukey
> ??? ??? ? 
> 
> ??? ?????
> 
> ________________________________
> 
> ??? ??? Van: jonamyers at gmail.com
> [mailto:jonamyers at gmail.com]
> Namens Jonathan Myers
> ??? ??? Verzonden: vrijdag 18
> september 2009 21:55
> ??? ??? Aan: Philip Dixon
> ??? ??? CC: r-sig-ecology at r-project.org;
> ONKELINX, Thierry;
> mdu at ceh.ac.uk
> ??? ??? Onderwerp: Re:
> [R-sig-eco] mixed effects model in lme
> ??? ??? 
> ??? ??? 
> ??? ??? Dear List Members, 
> 
> ??? ??? Thank you very much
> for your helpful replies and advice.
> 
> ??? ??? I would greatly
> appreciate any additional advice on how
> to rewrite my lme model to account for repeated
> measurements of the
> subplots in each of the three years. I imagine this would
> involve
> modifying the random-effects component of the model and/or
> using the
> "CorStruct" function to specify the correlation structure
> (e.g.,
> compound symmetry, autoregressive-moving average [AR1],
> etc.) for the
> repeated measures. My current model is:
> 
> ??? ??? model =
> lme(species.richness ~ (water+fuel+seed+year)^3,
> random = ~1 | block/plot)
> 
> ??? ??? Note that the model
> now includes only 3-way interactions
> for the fixed effects (I removed the 4-way interaction).
> According to
> Crawley (2007, The R Book, pg. 632), it is not necessary to
> specify the
> smallest nested spatial scale (subplot) in the
> random-effects component
> of the model; i.e., "random = ~1 | block/plot" will produce
> results
> identical to "random = ~1 | block/plot/subplot."
> 
> ??? ??? Can anyone provide
> advice for how to rewrite this model
> to account for repeated measurements of the subplots in the
> three years?
> Either code for R or code for SAS would be helpful at this
> point, as I
> may ultimately have to perform the analysis in SAS to
> figure out how to
> do it using lme in R.? 
> 
> ??? ??? I've pasted my
> original message below that includes the
> description of the experiment.
> 
> ??? ??? Thanks very much!
> 
> ??? ???
> Jonathan???
> 
> 
> ??? ??? Original message:
> ??? ?????
> ??? ??? 
> ??? ??? Dear List Members,
> 
> ??? ??? I am using a
> mixed-effects model in lme and would like
> to know whether I am using the proper structure for the
> random-effects
> component of the model. My experiment consists of three
> categorical
> treatments (fire, water, seed) arranged in a split-plot
> design. The fire
> treatment (2 levels) and water treatment (3 levels) were
> assigned to
> plots, and the seed treatment (2 levels) was assigned to
> two subplots
> within each plot. There are 60 total plots (120 total
> subplots), divided
> equally among two large blocks (30 plots per block). I
> measured species
> richness in each subplot in three separate years. My goal
> is to test for
> main effects of the three treatments, a main effect of
> year, and all
> interactions. My current model consists of four factorial
> fixed effects
> (fire, water, seed, year) and 1 random effect (block), with
> plots nested
> within blocks (to account for the split-plot structure of
> the
> experiment):
> 
> ??? ??? model =
> lme(species.richness ~ water*fuel*seed*year,
> random = ~1 | block/plot)
> 
> ??? ??? The ANOVA output
> includes two denominator degrees of
> freedom (denDF): 53 denDF for plot factors (fire, water,
> fire x water
> interaction) and 270 denDF for split-plot factors
> (everything else).
> 
> ??? ??? I would greatly
> appreciate feedback as to whether the
> random-effects component of the model looks appropriate,
> and if not, how
> it should be modified.
> 
> ??? ??? Thanks very much!
> 
> ??? ??? Cheers,
> 
> ??? ??? Jonathan 
> 
> ??? ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? ??? Jonathan A. Myers
> ??? ??? Department of
> Biological Sciences
> ??? ??? Division of
> Systematics, Ecology, and Evolution
> ??? ??? Louisiana State
> University
> ??? ??? Baton Rouge, LA 70803
> USA
> ??? ??? Telephone:
> 225-578-7567
> ??? ??? Fax: 225-578-2597
> ??? ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? ??? ???
> 
> 
> 
> 
> ??? ?????
> 
> ??? ?????
> 
> 
> ??? ??? On Fri, Sep 18, 2009
> at 9:25 AM, Philip Dixon
> <pdixon at iastate.edu>
> wrote:
> ??? ??? 
> 
> ??? ??? ??? I
> believe you have three levels of variation:
> ??? ??? ??? 
> ??? ??? ???
> between plots assigned to the same fire/water
> treatment
> ??? ??? ???
> between subplots assigned to the same
> fire/water/seed treatment
> ??? ??? ???
> and between measurements (fire/water/seed/year)
> ??? ??? ??? 
> ??? ??? ???
> Your models (and the previous replies) appear to
> be ignoring the repeated
> ??? ??? ???
> measurements on the same subplot.? You will
> probably need to explore various
> ??? ??? ???
> choices of correlation structure among years
> (e.g. Compound Symmetry =
> ??? ??? ???
> split/split plot, ar(1), ...)
> ??? ??? ??? 
> ??? ??? ???
> One key is that tests of split plot factors have
> 270 error DF (denDF).? You
> ??? ??? ???
> only have 120 subplots.
> ??? ??? ??? 
> ??? ??? ???
> Also, I suggest you retain at least all the
> fire/water/seed interactions in
> ??? ??? ???
> the model.???Each combination of
> fire/water/seed
> represents a specific "thing"
> ??? ??? ???
> (some call it treatment, but treatment has many
> different meanings) done to a
> ??? ??? ???
> subplot.???The full model with all these
> interactions corresponds to a cell
> ??? ??? ???
> means model.? Marginal means (i.e. main effects)
> correspond to averages of
> ??? ??? ???
> cell means.? If you drop those interactions, you
> are assuming that the true
> ??? ??? ???
> interaction is zero, so those dropped
> interactions only inform you about the
> ??? ??? ???
> error variation.? I believe this is somewhat
> dangerous because tests of
> ??? ??? ???
> interactions have low power (i.e. lower than
> tests of main effects).
> ??? ??? ??? I
> recognize that there are many other opinions
> here.
> ??? ??? ??? 
> ??? ??? ???
> The above argument does not apply to
> interactions with year because year is
> ??? ??? ???
> not randomly assigned to a subplot or plot.
> Many different opinions.
> ??? ??? ??? 
> ??? ??? ??? I
> prefer to fit models like this in SAS, because
> it is much easier to get
> ??? ??? ???
> meaningful estimates (i.e. not just tests) in
> SAS than in lme.
> ??? ??? ??? 
> ??? ??? ???
> Best wishes,
> ??? ??? ???
> Philip Dixon
> ??? ??? ??? 
> ??? ??? ???
> _______________________________________________
> ??? ??? ???
> R-sig-ecology mailing list
> ??? ??? ??? R-sig-ecology at r-project.org
> ??? 
> https://stat.ethz.ch/mailman/listinfo/r-sig-ecology
> ??? ??? ??? 
> 
> 
> 
> 
> ??? ??? -- 
> ??? ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? ??? Jonathan A. Myers
> ??? ??? Department of
> Biological Sciences
> ??? ??? Division of
> Systematics, Ecology, and Evolution
> ??? ??? Louisiana State
> University
> ??? ??? Baton Rouge, LA 70803
> USA
> ??? ??? 
> ??? ??? E-mail: jmyer19 at lsu.edu
> ??? ??? Telephone:
> 225-578-7567
> ??? ??? Fax: 225-578-2597
> ??? ??? 
> ??? ??? Website:
> http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> ??? ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? ??? 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van
> de schrijver
> weer 
> en binden het INBO onder geen enkel beding, zolang dit
> bericht niet
> bevestigd is
> door een geldig ondertekend document. The views expressed
> in? this
> message 
> and any annex are purely those of the writer and may not be
> regarded as
> stating 
> an official position of INBO, as long as the message is not
> confirmed by
> a duly 
> signed document.
> 
> 
> 
> 
> ?????
> ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? Jonathan A. Myers
> ??? Department of Biological Sciences
> ??? Division of Systematics, Ecology, and
> Evolution
> ??? Louisiana State University
> ??? Baton Rouge, LA 70803 USA
> ??? 
> ??? E-mail: jmyer19 at lsu.edu
> ??? Telephone: 225-578-7567
> ??? Fax: 225-578-2597
> ??? 
> ??? Website:
> http://www.biology.lsu.edu/labpages/harmslab/jmyers/index.html
> ???
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ??? 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van
> de schrijver
> weer 
> en binden het INBO onder geen enkel beding, zolang dit
> bericht niet
> bevestigd is
> door een geldig ondertekend document. The views expressed
> in? this
> message 
> and any annex are purely those of the writer and may not be
> regarded as
> stating 
> an official position of INBO, as long as the message is not
> confirmed by
> a duly 
> signed document.
> 
> 
> 
> 
> 
> 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van
> de schrijver weer 
> en binden het INBO onder geen enkel beding, zolang dit
> bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed
> in? this message
> and any annex are purely those of the writer and may not be
> regarded as stating 
> an official position of INBO, as long as the message is not
> confirmed by a duly 
> signed document.
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 33, Issue 23
> **************************************************
> 






From pauljohn32 at gmail.com  Wed Sep 23 08:36:46 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 23 Sep 2009 01:36:46 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
Message-ID: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>

Sent this to r-sig-debian by mistake the first time.  Depressing.

1.  One general question for general discussion:

Is HLM6 faster than lmer? If so, why?

I'm always advocating R to students, but some faculty members are
skeptical.  A colleague compared the commercial HLM6 software to lmer.
 HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.

If you have HLM6 (I don't), can you tell me if you see similar differences?

My first thought was that LM6 uses PQL by default, and it would be
faster.  However, in the output, HLM6 says:

Method of estimation: restricted maximum likelihood

But that doesn't tell me what quadrature approach they use, does it?

Another explanation for the difference in time might be the way HLM6
saves the results of some matrix calculations and re-uses them behind
the scenes.  If every call to lmer is re-calculating some big matrix
results, I suppose that could explain it.

There are comparisons from 2006 here

http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml

that indicate that lme was much slower than HLM, but that doesn't help
me understand *why* there is a difference.

2. What does "stack imbalance in .Call" mean in lmer?

Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
to CRAN &  I checked this document:

http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf

I *think* these things are automatically generated.  The version
that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
full of the error message:

stack imbalance in .Call,

Were those always there?  I don't think so.   What do they mean?

3. In the HLM6 output, there is a message at the end of the variable list:

'%' - This level-1 predictor has been centered around its grand mean.
'$' - This level-2 predictor has been centered around its grand mean.

What effect does that have on the estimates?  I believe it should have
no effect on the fixed effect slope estimates, but it seems to me the
estimates of the variances of random parameters would be
changed.  In order to make the estimates from lmer as directly
comparable as possible, should I manually center all of the variables
before fitting the model?   I'm a little stumped on how to center a
multi-category factor before feeding it to lmer.  Know what I mean?

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From tobias.verbeke at gmail.com  Wed Sep 23 10:12:02 2009
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Wed, 23 Sep 2009 10:12:02 +0200
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
Message-ID: <4AB9D852.8090705@gmail.com>

Hi Paul,

I am not familiar at all with HLM6 (and do not plan to become),
but..

 > 1.  One general question for general discussion:
 >
 > Is HLM6 faster than lmer? If so, why?
 >
 > I'm always advocating R to students, but some faculty members are
 > skeptical.

Nowadays it is unethical not to expose students to R. You would
deny access to a goldmine of statistical algorithms and life-long 
pleasure for students that get interested beyond their courses.

 > A colleague compared the commercial HLM6 software to lmer.
 >  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.

I'm afraid there is no concrete example to investigate
(nor information related to versions), but whatever
the outcome may be (and I am 'skeptical' w.r.t. the reported
timings), I would not trust a fast blackbox compared to
software for which the algorithms are publicly available
as well as every single line of code that implements
them.

Some other questions that come to mind are:

Is HLM available on all platforms ?
Is HLM capable of fitting models to huge datasets ?
Can one easily share research results with colleagues in
a way that they can reproduce the results (using free
[in all senses] software ?
Does HLM provide graphics systems coming near to R's ?

 > If you have HLM6 (I don't), can you tell me if you see similar 
differences?

Apparently it is possible to download a trial version for 15 days

http://www.ssicentral.com/hlm/downloads.html

 > My first thought was that LM6 uses PQL by default, and it would be
 > faster.  However, in the output, HLM6 says:
 >
 > Method of estimation: restricted maximum likelihood
 >
 > But that doesn't tell me what quadrature approach they use, does it?
 >
 > Another explanation for the difference in time might be the way HLM6
 > saves the results of some matrix calculations and re-uses them behind
 > the scenes.  If every call to lmer is re-calculating some big matrix
 > results, I suppose that could explain it.
 >
 > There are comparisons from 2006 here
 >
 > 
http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
 >
 > that indicate that lme was much slower than HLM, but that doesn't help
 > me understand *why* there is a difference.

The knowledgeable may correct me, but lmer internals are entirely 
different from those of lme, so I don't think you can take these
results as a starting point.

Best,
Tobias

> 2. What does "stack imbalance in .Call" mean in lmer?
> 
> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
> to CRAN &  I checked this document:
> 
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
> 
> I *think* these things are automatically generated.  The version
> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
> full of the error message:
> 
> stack imbalance in .Call,
> 
> Were those always there?  I don't think so.   What do they mean?
> 
> 3. In the HLM6 output, there is a message at the end of the variable list:
> 
> '%' - This level-1 predictor has been centered around its grand mean.
> '$' - This level-2 predictor has been centered around its grand mean.
> 
> What effect does that have on the estimates?  I believe it should have
> no effect on the fixed effect slope estimates, but it seems to me the
> estimates of the variances of random parameters would be
> changed.  In order to make the estimates from lmer as directly
> comparable as possible, should I manually center all of the variables
> before fitting the model?   I'm a little stumped on how to center a
> multi-category factor before feeding it to lmer.  Know what I mean?
> 
> pj
>



From kw.stat at gmail.com  Wed Sep 23 15:54:32 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 23 Sep 2009 08:54:32 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
Message-ID: <5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>

Paul,

It appears to me that the published timings you reference are
comparing the __nlme__ package with other software.  So the answer is
yes, nlme really is that slow for some models.  You are probably aware
that the __lme4__ package has faster algorithms.

There are many ways to fit mixed models in R including nlme, lme4,
MCMCglmm, admb asreml, BUGS, etc.  If I was teaching a course, I would
try to expose students to at least two of those in some detail and
touch briefly on the others: nlme can fit a variety of complex
varaiance structures, lme4 has faster algorithms, asreml is the only
choice of animal/plant breeders and has commercial support, MCMCglmm
has some Bayesian aspects and can fit some heteroskedastic variance
structures, admb is used in Fish & Wildlife, etc.

Mixed model fitting in R is definitely not a case of "one size fits all".

Kevin Wright


On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>
> 1. ?One general question for general discussion:
>
> Is HLM6 faster than lmer? If so, why?
>
> I'm always advocating R to students, but some faculty members are
> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>
> If you have HLM6 (I don't), can you tell me if you see similar differences?
>
> My first thought was that LM6 uses PQL by default, and it would be
> faster. ?However, in the output, HLM6 says:
>
> Method of estimation: restricted maximum likelihood
>
> But that doesn't tell me what quadrature approach they use, does it?
>
> Another explanation for the difference in time might be the way HLM6
> saves the results of some matrix calculations and re-uses them behind
> the scenes. ?If every call to lmer is re-calculating some big matrix
> results, I suppose that could explain it.
>
> There are comparisons from 2006 here
>
> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>
> that indicate that lme was much slower than HLM, but that doesn't help
> me understand *why* there is a difference.
>
> 2. What does "stack imbalance in .Call" mean in lmer?
>
> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
> to CRAN & ?I checked this document:
>
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>
> I *think* these things are automatically generated. ?The version
> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
> full of the error message:
>
> stack imbalance in .Call,
>
> Were those always there? ?I don't think so. ? What do they mean?
>
> 3. In the HLM6 output, there is a message at the end of the variable list:
>
> '%' - This level-1 predictor has been centered around its grand mean.
> '$' - This level-2 predictor has been centered around its grand mean.
>
> What effect does that have on the estimates? ?I believe it should have
> no effect on the fixed effect slope estimates, but it seems to me the
> estimates of the variances of random parameters would be
> changed. ?In order to make the estimates from lmer as directly
> comparable as possible, should I manually center all of the variables
> before fitting the model? ? I'm a little stumped on how to center a
> multi-category factor before feeding it to lmer. ?Know what I mean?
>
> pj
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From alexandre.villers at cebc.cnrs.fr  Wed Sep 23 16:06:52 2009
From: alexandre.villers at cebc.cnrs.fr (Alexandre VILLERS)
Date: Wed, 23 Sep 2009 16:06:52 +0200
Subject: [R-sig-ME] zero inflated and spatial autocorrelation
Message-ID: <4ABA2B7C.4070407@cebc.cnrs.fr>

(sorry if the message was double posted...)

Good afternoon,

I currently try to estimate the relative contribution of habitat quality 
and a proxy of conspecific attraction for a bird species (3 years of 
data: 2000, 2004 and 2008) with a model of the form

Abundance (year t) ~ Abundance (year t-1) + Habitat_quality + Epsi

I would like being able to compare what happened between 2000-2004 to 
2004-2008
and would need some advices.

Problems are
1/ that the distribution of abundance (integer values) is zero inflated, 
with 80% of my grid cells "tagged" with 0
2/ I need to account for spatial autocorrelation (which is detectable 
below 10 km, my grid being 3 x 3 km in order to account for between 
years short dispersal).

I lack some skills in statistics to fully handle this on my own (even if 
I try to make up for lost time)
Shall I run straight ahead with a gamm model which is the only one, to 
my knowledge, that can account for both the spatial autocorrelation 
structure (with for example correlation=corSpher(form=~(X+Y))) and the 
zero inflated distribution (with family= negbin) ?
Or is there a way to relax some constraints on the distribution in order 
to handle overdispersion (induced by the ZI distribution) and thus trust 
the run of a glmmPQL with quasipoisson ?
 >From what I read, glmm and gamm are at the edge of statistics and need 
to be examined cautiously... so if I can avoid inserting irrelevant 
information in it...

Thanks for any help or link
Best regards


Alex


Tiebreaker: my observation window has an irregular shape, meaning that 
cells at the edge are truncated. If it is the correct solution to manage 
this, how do I properly specify weights=...  with the area of cells as 
argument.
Do I need to transform the value of areas ?
Or would it also be correct to exclude those piece of cells (which are 
mainly zeros --> 0 would then represent "only" 68% of observations, 
392/577 )?

-- 
Alexandre Villers
PhD Student
Team "Biodiversity"
Centre d'Etudes Biologiques de Chiz?-CNRS UPR1934
79360 Beauvoir sur Niort

Phone +33 (0)5 49 09 96 13
Fax   +33 (0)5 49 09 65 26




__________ Information from ESET Mail Security, version of virus signature database 4450 (20090923) __________

The message was checked by ESET Mail Security.
http://www.eset.com



From HDoran at air.org  Wed Sep 23 18:12:25 2009
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Sep 2009 12:12:25 -0400
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is
	a"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE0202D928@DC1EXCL01.air.org>

> 1.  One general question for general discussion:
> 
> Is HLM6 faster than lmer? If so, why?
> 
> I'm always advocating R to students, but some faculty members 
> are skeptical.  A colleague compared the commercial HLM6 
> software to lmer.
>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
> 
> If you have HLM6 (I don't), can you tell me if you see 
> similar differences?

Whether or not this is true on the data used for the example is not too
interesting to me. What *is* interesting to me is that HLM cannot for
sure to handle large models with complex random effects. In other words,
you might find small toy examples where HLM is faster than the lmer
function. However, with large data sets and complex structures for the
marginal variance/covarianc matrix, HLM can't even compete. 

> My first thought was that LM6 uses PQL by default, and it 
> would be faster.  

You suspect that PQL would be faster than what? 

However, in the output, HLM6 says:
> 
> Method of estimation: restricted maximum likelihood
> 
> But that doesn't tell me what quadrature approach they use, does it?

I don't think we can answer your question in a meaningful way w/o you
providing more information. REML is also the default in lmer and it is
essentially like integrating out the fixed effects with a uniform prior.
But, are you estimating linear or generalized mixed models?

> 
> Another explanation for the difference in time might be the 
> way HLM6 saves the results of some matrix calculations and 
> re-uses them behind the scenes.  If every call to lmer is 
> re-calculating some big matrix results, I suppose that could 
> explain it.

What matrices are saved at each iteration in HLM? I'm curious. Of
course, the model matrices don't change, but others do. 

> 
> There are comparisons from 2006 here
> 
> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-so
ftware/tables.shtml

I looked very briefly at the materials on this link. They evaluate a
very old version of the mixed model functions in R (using R 1.5.1) and
we are now on R version 2.9.2. The older function, nlme, was a bit slow,
and I do recall it being slower than HLM (the software).

The nwer functions of lmer are very different than the days of old. I
think you will find, if you do some comparisons yourself, that the R
functions are extremely fast, and most likely I suspect would be faster
than HLM.

> that indicate that lme was much slower than HLM, but that 
> doesn't help me understand *why* there is a difference.
> 
> 2. What does "stack imbalance in .Call" mean in lmer?
> 
> Here's why I ask.  Searching for comparisons of lmer and HLM, 
>  I went to CRAN &  I checked this document:
> 
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
> 
> I *think* these things are automatically generated.  The 
> version that's up there at this moment  (mlmRev edition 
> 0.99875-1)  has pages full of the error message:
> 
> stack imbalance in .Call,
> 
> Were those always there?  I don't think so.   What do they mean?
> 
> 3. In the HLM6 output, there is a message at the end of the 
> variable list:
> 
> '%' - This level-1 predictor has been centered around its grand mean.
> '$' - This level-2 predictor has been centered around its grand mean.
> 
> What effect does that have on the estimates?  I believe it 
> should have no effect on the fixed effect slope estimates, 
> but it seems to me the estimates of the variances of random 
> parameters would be changed.  In order to make the estimates 
> from lmer as directly comparable as possible, should I 
> manually center all of the variables
> before fitting the model?   I'm a little stumped on how to center a
> multi-category factor before feeding it to lmer.  Know what I mean?

Centering will change some of the estimates. But, without providing more
details on what your model is, how your centering there is no way to
answer your question. For example, you say it won't affect slope. Slope
of what? 

> 
> pj
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bates at stat.wisc.edu  Wed Sep 23 18:31:37 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 11:31:37 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
Message-ID: <40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>

Got to disagree with you, Kevin.  admb and asreml are not part of R,
even in the general sense of R packages.  R is Open Source - they are
not. Tacking on an R interface to proprietary software and saying it
is available in R is misleading and dishonest.

On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Paul,
>
> It appears to me that the published timings you reference are
> comparing the __nlme__ package with other software. ?So the answer is
> yes, nlme really is that slow for some models. ?You are probably aware
> that the __lme4__ package has faster algorithms.
>
> There are many ways to fit mixed models in R including nlme, lme4,
> MCMCglmm, admb asreml, BUGS, etc. ?If I was teaching a course, I would
> try to expose students to at least two of those in some detail and
> touch briefly on the others: nlme can fit a variety of complex
> varaiance structures, lme4 has faster algorithms, asreml is the only
> choice of animal/plant breeders and has commercial support, MCMCglmm
> has some Bayesian aspects and can fit some heteroskedastic variance
> structures, admb is used in Fish & Wildlife, etc.
>
> Mixed model fitting in R is definitely not a case of "one size fits all".
>
> Kevin Wright
>
>
> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>>
>> 1. ?One general question for general discussion:
>>
>> Is HLM6 faster than lmer? If so, why?
>>
>> I'm always advocating R to students, but some faculty members are
>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>
>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>
>> My first thought was that LM6 uses PQL by default, and it would be
>> faster. ?However, in the output, HLM6 says:
>>
>> Method of estimation: restricted maximum likelihood
>>
>> But that doesn't tell me what quadrature approach they use, does it?
>>
>> Another explanation for the difference in time might be the way HLM6
>> saves the results of some matrix calculations and re-uses them behind
>> the scenes. ?If every call to lmer is re-calculating some big matrix
>> results, I suppose that could explain it.
>>
>> There are comparisons from 2006 here
>>
>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>
>> that indicate that lme was much slower than HLM, but that doesn't help
>> me understand *why* there is a difference.
>>
>> 2. What does "stack imbalance in .Call" mean in lmer?
>>
>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>> to CRAN & ?I checked this document:
>>
>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>
>> I *think* these things are automatically generated. ?The version
>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>> full of the error message:
>>
>> stack imbalance in .Call,
>>
>> Were those always there? ?I don't think so. ? What do they mean?
>>
>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>
>> '%' - This level-1 predictor has been centered around its grand mean.
>> '$' - This level-2 predictor has been centered around its grand mean.
>>
>> What effect does that have on the estimates? ?I believe it should have
>> no effect on the fixed effect slope estimates, but it seems to me the
>> estimates of the variances of random parameters would be
>> changed. ?In order to make the estimates from lmer as directly
>> comparable as possible, should I manually center all of the variables
>> before fitting the model? ? I'm a little stumped on how to center a
>> multi-category factor before feeding it to lmer. ?Know what I mean?
>>
>> pj
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science
>> 1541 Lilac Lane, Room 504
>> University of Kansas
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Sep 23 18:34:52 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 11:34:52 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>
Message-ID: <40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>

I forgot to cc: the list on this reply.

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Wed, Sep 23, 2009 at 11:29 AM
Subject: Re: [R-sig-ME] More naive questions: Speed comparisons? what
is a "stack imbalance" in lmer? does lmer center variables?
To: Paul Johnson <pauljohn32 at gmail.com>



On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Sent this to r-sig-debian by mistake the first time. ?Depressing.

> 1. ?One general question for general discussion:

> Is HLM6 faster than lmer? If so, why?

> I'm always advocating R to students, but some faculty members are
> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.

> If you have HLM6 (I don't), can you tell me if you see similar differences?

Honestly, Paul, I don't see a point in discussing vague generalities
and rumors. ?If your colleague can make the data (or even simuiated
data with a similar structure) available and describe the model being
fit then we can see why lmer appears to be so much slower on it. ?But
do bear in mind that the folks marketing HLM6 have the ability -
indeed they have the right - to run lmer on their test cases and to
examine every single line of code in lmer so they can determine
exactly what it is doing. ?They have the right to do that because
everyone has the right to do that. ?If we want to find out how HLM6
performs on a test case we are reduced to your approach of asking if
someone has a copy of the software (on one of or perhaps the only
operating system under which it runs) and all that can be done is to
quote the results. ?The internal details of HLM6 are proprietary.

I can tell you my goals in developing the lme4 package are:
?1. Provide the ability to fit general forms of mixed-effects models.
?2. To the best of my ability, provide reliable estimates.
?3. Allow for models to be fit to very large data sets.
?4. Take advantage of the R environment to allow for straightforward
model specification and for very general data manipulation and
graphical capabilities.
?5. Subject to objectives 1-4 provide the fastest software that I can

> My first thought was that LM6 uses PQL by default, and it would be
> faster. ?However, in the output, HLM6 says:

> Method of estimation: restricted maximum likelihood

> But that doesn't tell me what quadrature approach they use, does it?

To me this is very confusing. ?In my world REML is only meaningful for
linear mixed models. ?(I know, at one time Mary Lindstrom and I wrote
about REML estimates for nonlinear mixed models but, as I have said
before, I consider that a youthful indiscretion.) ?For linear mixed
models there is no need to use PQL or to discuss quadrature because
the evaluation of the profiled deviance or the profiled REML criterion
is a direct calculation.

Again, without a more complete description of the data and the model
to be fit it is impossible to discuss these issues meaningfully.

> Another explanation for the difference in time might be the way HLM6
> saves the results of some matrix calculations and re-uses them behind
> the scenes. ?If every call to lmer is re-calculating some big matrix
> results, I suppose that could explain it.

But you don't need to speculate about what lmer does. ?It is Open
Source so you can check for yourself.

However, this does bring up another point which is the need to compare
apples with apples when you are benchmarking software. ?If the data
import and model specification stages in HLM6 create the necessary
matrix structures for performing the iterative fit then does the time
to fit the model consist solely of the optimization and summary
stages? ?Using an expression like

system.time(fm1 <- lmer(...))

is assessing the time to take the original data, which could be in a
very general form, create all those internal structures and perform
the optimization.

You should bear in mind that a lot of that construction of the model
structures is written in R exactly so that it is capable of fitting
very general model specifications. ?The code in HLM6 is, I imagine,
compiled code, which is possible because it targets a very specific
task, and compiled code is always going to be much faster than
interpreted code.

> There are comparisons from 2006 here

> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml

> that indicate that lme was much slower than HLM, but that doesn't help
> me understand *why* there is a difference.

I believe that those examples are available for testing with lmer in
the mlmRev package for R. ?However, the results can't be compared
meaningfully to the tabled results because today's hardware is so
different from what was used for those comparisons.

Besides, none of those examples is really challenging. ?I was just
doing some timing tests on a model fit to 1.7 million observations
with 750,000 random effects associated with four different, non-nested
grouping factors and 40 fixed-effects parameters. ?To me that is a
meaningful test because it took from 1 to 2 hours to fit on a fast
server computer. ?Unfortunately, I can't make that data available
because of confidentiality restrictions but, even if I could, I don't
think the model could be fit in HLM6 or MLWin or SAS PROC MIXED or
Stata because there are 750,000 random effects in a non-nested
configuration.

I can make a similar but smaller test case available using the star
(Student-Teacher Achievement Ratio) data from the mlmRev package. ?One
model could be

> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
? user ?system elapsed
?9.885 ? 0.044 ?10.508
> print(fm1, corr = FALSE)
Linear mixed model fit by REML
Formula: math ~ gr + cltype + sx + eth + (1 | id) + (1 | tch) + (1 | sch)
? Data: star
? ?AIC ? ?BIC ?logLik deviance REMLdev
?239236 239365 -119602 ? 239245 ?239204
Random effects:
?Groups ? Name ? ? ? ?Variance Std.Dev.
?id ? ? ? (Intercept) 1001.60 ?31.648
?tch ? ? ?(Intercept) ?295.03 ?17.176
?sch ? ? ?(Intercept) ?104.78 ?10.236
?Residual ? ? ? ? ? ? ?397.32 ?19.933
Number of obs: 24578, groups: id, 10732; tch, 1374; sch, 80

Fixed effects:
? ? ? ? ? ?Estimate Std. Error t value
(Intercept) 560.8868 ? ? 1.5745 ? 356.2
gr.L ? ? ? ? 95.6126 ? ? 1.0080 ? ?94.9
gr.Q ? ? ? ? -4.6783 ? ? 0.9857 ? ?-4.7
gr.C ? ? ? ? -3.2320 ? ? 0.9729 ? ?-3.3
cltypereg ? ?-7.7943 ? ? 1.3322 ? ?-5.9
cltypereg+A ?-7.0055 ? ? 1.3265 ? ?-5.3
sxF ? ? ? ? ? 2.8766 ? ? 0.6836 ? ? 4.2
ethB ? ? ? ?-21.9197 ? ? 1.2219 ? -17.9
ethA ? ? ? ? ?3.1940 ? ? 6.7037 ? ? 0.5
ethH ? ? ? ? ?4.5411 ? ? 9.6653 ? ? 0.5
ethI ? ? ? ?-28.1618 ? ?13.5359 ? ?-2.1
ethO ? ? ? ? ?3.4356 ? ? 8.3133 ? ? 0.4

Unfortunately, because that model is based on only 25000 observations
and 11000 random effects it is difficult to get a meaningful timing.
Timings under 10 seconds, like this, are subject to too much
variability.

Nevertheless you can take that data and try to fit that model in any
of the other software systems. ?Note that student (the "id" factor) is
not nested within teacher ("tch") or school, as will almost always
happen when fitting longitudinal data so the random effects are
partially crossed. ?In other words, they are not nested so the
structure is not hierarchical or multi-level in the sense of HLM or
MLWin. ?I would invite those who have access to such software to fit
the model using lme4 and to fit an equivalent model in other systems
and tell us how they compare. ?I can't do that because I choose not to
use proprietary software.

> 2. What does "stack imbalance in .Call" mean in lmer?

It is a sign of a bug in the C code underlying the lme4 package. ?It
should be reported as a bug if it occurred in the currently released
version of lme4.

> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
> to CRAN & ?I checked this document:
>
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>
> I *think* these things are automatically generated. ?The version
> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
> full of the error message:
>
> stack imbalance in .Call,
>
> Were those always there? ?I don't think so. ? What do they mean?

No they shouldn't be there. ?I'll update the mlmRev package.

> 3. In the HLM6 output, there is a message at the end of the variable list:
>
> '%' - This level-1 predictor has been centered around its grand mean.
> '$' - This level-2 predictor has been centered around its grand mean.
>
> What effect does that have on the estimates? ?I believe it should have
> no effect on the fixed effect slope estimates, but it seems to me the
> estimates of the variances of random parameters would be
> changed. ?In order to make the estimates from lmer as directly
> comparable as possible, should I manually center all of the variables
> before fitting the model? ? I'm a little stumped on how to center a
> multi-category factor before feeding it to lmer. ?Know what I mean?



From bolker at ufl.edu  Wed Sep 23 18:51:19 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 23 Sep 2009 12:51:19 -0400
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
Message-ID: <4ABA5207.9020805@ufl.edu>

   As of sometime last year (? I think ?), ADMB is
free/gratis/libre/open source (BSD licensed).  Even before that,
glmmADMB (which was an R package with a binary component, available for
download) was "free as in beer". In its current status, I think of ADMB
in the same category as WinBUGS -- a powerful, albeit sometimes
unwieldy, tool that can be used through an R interface to solve general
problems by writing model descriptions in a non-R language.
  I have to agree with Kevin that the diversity of mixed model software
tools is a good thing.

  cheers
    Ben Bolker

Douglas Bates wrote:
> Got to disagree with you, Kevin.  admb and asreml are not part of R,
> even in the general sense of R packages.  R is Open Source - they are
> not. Tacking on an R interface to proprietary software and saying it
> is available in R is misleading and dishonest.
> 
> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>> Paul,
>>
>> It appears to me that the published timings you reference are
>> comparing the __nlme__ package with other software.  So the answer is
>> yes, nlme really is that slow for some models.  You are probably aware
>> that the __lme4__ package has faster algorithms.
>>
>> There are many ways to fit mixed models in R including nlme, lme4,
>> MCMCglmm, admb asreml, BUGS, etc.  If I was teaching a course, I would
>> try to expose students to at least two of those in some detail and
>> touch briefly on the others: nlme can fit a variety of complex
>> varaiance structures, lme4 has faster algorithms, asreml is the only
>> choice of animal/plant breeders and has commercial support, MCMCglmm
>> has some Bayesian aspects and can fit some heteroskedastic variance
>> structures, admb is used in Fish & Wildlife, etc.
>>
>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>
>> Kevin Wright
>>
>>
>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>> Sent this to r-sig-debian by mistake the first time.  Depressing.
>>>
>>> 1.  One general question for general discussion:
>>>
>>> Is HLM6 faster than lmer? If so, why?
>>>
>>> I'm always advocating R to students, but some faculty members are
>>> skeptical.  A colleague compared the commercial HLM6 software to lmer.
>>>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>
>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>
>>> My first thought was that LM6 uses PQL by default, and it would be
>>> faster.  However, in the output, HLM6 says:
>>>
>>> Method of estimation: restricted maximum likelihood
>>>
>>> But that doesn't tell me what quadrature approach they use, does it?
>>>
>>> Another explanation for the difference in time might be the way HLM6
>>> saves the results of some matrix calculations and re-uses them behind
>>> the scenes.  If every call to lmer is re-calculating some big matrix
>>> results, I suppose that could explain it.
>>>
>>> There are comparisons from 2006 here
>>>
>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>
>>> that indicate that lme was much slower than HLM, but that doesn't help
>>> me understand *why* there is a difference.
>>>
>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>
>>> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
>>> to CRAN &  I checked this document:
>>>
>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>
>>> I *think* these things are automatically generated.  The version
>>> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
>>> full of the error message:
>>>
>>> stack imbalance in .Call,
>>>
>>> Were those always there?  I don't think so.   What do they mean?
>>>
>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>
>>> '%' - This level-1 predictor has been centered around its grand mean.
>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>
>>> What effect does that have on the estimates?  I believe it should have
>>> no effect on the fixed effect slope estimates, but it seems to me the
>>> estimates of the variances of random parameters would be
>>> changed.  In order to make the estimates from lmer as directly
>>> comparable as possible, should I manually center all of the variables
>>> before fitting the model?   I'm a little stumped on how to center a
>>> multi-category factor before feeding it to lmer.  Know what I mean?
>>>
>>> pj
>>>
>>> --
>>> Paul E. Johnson
>>> Professor, Political Science
>>> 1541 Lilac Lane, Room 504
>>> University of Kansas
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From highstat at highstat.com  Wed Sep 23 19:08:19 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Wed, 23 Sep 2009 18:08:19 +0100
Subject: [R-sig-ME] zero inflated and spatial autocorrelation
In-Reply-To: <mailman.2663.1253723719.25490.r-sig-mixed-models@r-project.org>
References: <mailman.2663.1253723719.25490.r-sig-mixed-models@r-project.org>
Message-ID: <4ABA5603.40703@highstat.com>


> (sorry if the message was double posted...)
>
> Good afternoon,
>
> I currently try to estimate the relative contribution of habitat quality 
> and a proxy of conspecific attraction for a bird species (3 years of 
> data: 2000, 2004 and 2008) with a model of the form
>
> Abundance (year t) ~ Abundance (year t-1) + Habitat_quality + Epsi
>
> I would like being able to compare what happened between 2000-2004 to 
> 2004-2008
> and would need some advices.
>
> Problems are
> 1/ that the distribution of abundance (integer values) is zero inflated, 
> with 80% of my grid cells "tagged" with 0
>   

The negative binomial can cope with some degree of zeros....but 80% is a 
lot. I guess a zero inflated distribution would be better. Besides...I 
can't remember wether gamm in mgcv is estimating the theta, or whether 
it uses a fixed value.


Have a look how these guys fitted their models....it is similar:

http://www.unavarra.es/metma3/Papers/Invited/VerHoef.pdf

The first author published a couple of similar papers. But I don't think 
that this is going to be a simple call to a gamm function.

> 2/ I need to account for spatial autocorrelation (which is detectable 
> below 10 km, my grid being 3 x 3 km in order to account for between 
> years short dispersal).
>
> I lack some skills in statistics to fully handle this on my own 
>   
This is not easy..:-)


> Shall I run straight ahead with a gamm model which is the only one, to 
> my knowledge, that can account for both the spatial autocorrelation 
> structure (with for example correlation=corSpher(form=~(X+Y))) and the 
> zero inflated distribution (with family= negbin) ?
> Or is there a way to relax some constraints on the distribution in order 
> to handle overdispersion (induced by the ZI distribution) and thus trust 
> the run of a glmmPQL with quasipoisson ?
>   

Have a look at the VGAM package. Perhaps it can do this type of stuff by 
now. If I remember well it can do smoothing with zero inflation. Not 
sure if it can do correlation. As a quick-and-dirty approach you could 
include s(X,Y) and capture the spatial pattern with such a 2-d smoother. 
But that may be more for larger scale patterns? However....it may cause 
trouble if your habitat stuff is collinear with spatial positions.

Have fun....this is not easy...but shit happens.

Alain

>  >From what I read, glmm and gamm are at the edge of statistics and need 
> to be examined cautiously... so if I can avoid inserting irrelevant 
> information in it...
>
> Thanks for any help or link
> Best regards
>
>
> Alex
>
>
> Tiebreaker: my observation window has an irregular shape, meaning that 
> cells at the edge are truncated. If it is the correct solution to manage 
> this, how do I properly specify weights=...  with the area of cells as 
> argument.
> Do I need to transform the value of areas ?
> Or would it also be correct to exclude those piece of cells (which are 
> mainly zeros --> 0 would then represent "only" 68% of observations, 
> 392/577 )?
>
>   


-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From p.dalgaard at biostat.ku.dk  Wed Sep 23 19:22:26 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 23 Sep 2009 19:22:26 +0200
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <4ABA5207.9020805@ufl.edu>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<4ABA5207.9020805@ufl.edu>
Message-ID: <4ABA5952.7000808@biostat.ku.dk>

Ben Bolker wrote:
>    As of sometime last year (? I think ?), ADMB is
> free/gratis/libre/open source (BSD licensed). 

As of _next_ year is more like it. Their downloads are still 
binary-only. BSD does not imply Open Source when you don't have the 
sources, and "open source project" in this case means a project to make 
the software open source. The intention appears to be honourable, though.

  Even before that,
> glmmADMB (which was an R package with a binary component, available for
> download) was "free as in beer". In its current status, I think of ADMB
> in the same category as WinBUGS -- a powerful, albeit sometimes
> unwieldy, tool that can be used through an R interface to solve general
> problems by writing model descriptions in a non-R language.
>   I have to agree with Kevin that the diversity of mixed model software
> tools is a good thing.
> 
>   cheers
>     Ben Bolker
> 
> Douglas Bates wrote:
>> Got to disagree with you, Kevin.  admb and asreml are not part of R,
>> even in the general sense of R packages.  R is Open Source - they are
>> not. Tacking on an R interface to proprietary software and saying it
>> is available in R is misleading and dishonest.
>>
>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>> Paul,
>>>
>>> It appears to me that the published timings you reference are
>>> comparing the __nlme__ package with other software.  So the answer is
>>> yes, nlme really is that slow for some models.  You are probably aware
>>> that the __lme4__ package has faster algorithms.
>>>
>>> There are many ways to fit mixed models in R including nlme, lme4,
>>> MCMCglmm, admb asreml, BUGS, etc.  If I was teaching a course, I would
>>> try to expose students to at least two of those in some detail and
>>> touch briefly on the others: nlme can fit a variety of complex
>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>> structures, admb is used in Fish & Wildlife, etc.
>>>
>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>
>>> Kevin Wright
>>>
>>>
>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>> Sent this to r-sig-debian by mistake the first time.  Depressing.
>>>>
>>>> 1.  One general question for general discussion:
>>>>
>>>> Is HLM6 faster than lmer? If so, why?
>>>>
>>>> I'm always advocating R to students, but some faculty members are
>>>> skeptical.  A colleague compared the commercial HLM6 software to lmer.
>>>>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>
>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>
>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>> faster.  However, in the output, HLM6 says:
>>>>
>>>> Method of estimation: restricted maximum likelihood
>>>>
>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>
>>>> Another explanation for the difference in time might be the way HLM6
>>>> saves the results of some matrix calculations and re-uses them behind
>>>> the scenes.  If every call to lmer is re-calculating some big matrix
>>>> results, I suppose that could explain it.
>>>>
>>>> There are comparisons from 2006 here
>>>>
>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>
>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>> me understand *why* there is a difference.
>>>>
>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>
>>>> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
>>>> to CRAN &  I checked this document:
>>>>
>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>
>>>> I *think* these things are automatically generated.  The version
>>>> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
>>>> full of the error message:
>>>>
>>>> stack imbalance in .Call,
>>>>
>>>> Were those always there?  I don't think so.   What do they mean?
>>>>
>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>
>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>
>>>> What effect does that have on the estimates?  I believe it should have
>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>> estimates of the variances of random parameters would be
>>>> changed.  In order to make the estimates from lmer as directly
>>>> comparable as possible, should I manually center all of the variables
>>>> before fitting the model?   I'm a little stumped on how to center a
>>>> multi-category factor before feeding it to lmer.  Know what I mean?
>>>>
>>>> pj
>>>>
>>>> --
>>>> Paul E. Johnson
>>>> Professor, Political Science
>>>> 1541 Lilac Lane, Room 504
>>>> University of Kansas
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From bolker at ufl.edu  Wed Sep 23 19:21:54 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 23 Sep 2009 13:21:54 -0400
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <4ABA5952.7000808@biostat.ku.dk>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<4ABA5207.9020805@ufl.edu> <4ABA5952.7000808@biostat.ku.dk>
Message-ID: <4ABA5932.80807@ufl.edu>

  Source *is* available:


Peter Dalgaard wrote:
> Ben Bolker wrote:
>>    As of sometime last year (? I think ?), ADMB is
>> free/gratis/libre/open source (BSD licensed). 
> 
> As of _next_ year is more like it. Their downloads are still 
> binary-only. BSD does not imply Open Source when you don't have the 
> sources, and "open source project" in this case means a project to make 
> the software open source. The intention appears to be honourable, though.
> 
>   Even before that,
>> glmmADMB (which was an R package with a binary component, available for
>> download) was "free as in beer". In its current status, I think of ADMB
>> in the same category as WinBUGS -- a powerful, albeit sometimes
>> unwieldy, tool that can be used through an R interface to solve general
>> problems by writing model descriptions in a non-R language.
>>   I have to agree with Kevin that the diversity of mixed model software
>> tools is a good thing.
>>
>>   cheers
>>     Ben Bolker
>>
>> Douglas Bates wrote:
>>> Got to disagree with you, Kevin.  admb and asreml are not part of R,
>>> even in the general sense of R packages.  R is Open Source - they are
>>> not. Tacking on an R interface to proprietary software and saying it
>>> is available in R is misleading and dishonest.
>>>
>>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>> Paul,
>>>>
>>>> It appears to me that the published timings you reference are
>>>> comparing the __nlme__ package with other software.  So the answer is
>>>> yes, nlme really is that slow for some models.  You are probably aware
>>>> that the __lme4__ package has faster algorithms.
>>>>
>>>> There are many ways to fit mixed models in R including nlme, lme4,
>>>> MCMCglmm, admb asreml, BUGS, etc.  If I was teaching a course, I would
>>>> try to expose students to at least two of those in some detail and
>>>> touch briefly on the others: nlme can fit a variety of complex
>>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>>> structures, admb is used in Fish & Wildlife, etc.
>>>>
>>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>>
>>>> Kevin Wright
>>>>
>>>>
>>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>>> Sent this to r-sig-debian by mistake the first time.  Depressing.
>>>>>
>>>>> 1.  One general question for general discussion:
>>>>>
>>>>> Is HLM6 faster than lmer? If so, why?
>>>>>
>>>>> I'm always advocating R to students, but some faculty members are
>>>>> skeptical.  A colleague compared the commercial HLM6 software to lmer.
>>>>>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>>
>>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>>
>>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>>> faster.  However, in the output, HLM6 says:
>>>>>
>>>>> Method of estimation: restricted maximum likelihood
>>>>>
>>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>>
>>>>> Another explanation for the difference in time might be the way HLM6
>>>>> saves the results of some matrix calculations and re-uses them behind
>>>>> the scenes.  If every call to lmer is re-calculating some big matrix
>>>>> results, I suppose that could explain it.
>>>>>
>>>>> There are comparisons from 2006 here
>>>>>
>>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>>
>>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>>> me understand *why* there is a difference.
>>>>>
>>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>>
>>>>> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
>>>>> to CRAN &  I checked this document:
>>>>>
>>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>>
>>>>> I *think* these things are automatically generated.  The version
>>>>> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
>>>>> full of the error message:
>>>>>
>>>>> stack imbalance in .Call,
>>>>>
>>>>> Were those always there?  I don't think so.   What do they mean?
>>>>>
>>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>>
>>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>>
>>>>> What effect does that have on the estimates?  I believe it should have
>>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>>> estimates of the variances of random parameters would be
>>>>> changed.  In order to make the estimates from lmer as directly
>>>>> comparable as possible, should I manually center all of the variables
>>>>> before fitting the model?   I'm a little stumped on how to center a
>>>>> multi-category factor before feeding it to lmer.  Know what I mean?
>>>>>
>>>>> pj
>>>>>
>>>>> --
>>>>> Paul E. Johnson
>>>>> Professor, Political Science
>>>>> 1541 Lilac Lane, Room 504
>>>>> University of Kansas
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From p.dalgaard at biostat.ku.dk  Wed Sep 23 19:31:05 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 23 Sep 2009 19:31:05 +0200
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <4ABA5932.80807@ufl.edu>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<4ABA5207.9020805@ufl.edu> <4ABA5952.7000808@biostat.ku.dk>
	<4ABA5932.80807@ufl.edu>
Message-ID: <4ABA5B59.2060705@biostat.ku.dk>

Ben Bolker wrote:
>   Source *is* available:
> 

Oops, you're right. I overlooked the SVN checkout. It's just that there 
is no source tarball among

http://code.google.com/p/admb-project/downloads/list

but there is a "Source" tab.


> Peter Dalgaard wrote:
>> Ben Bolker wrote:
>>>    As of sometime last year (? I think ?), ADMB is
>>> free/gratis/libre/open source (BSD licensed). 
>> As of _next_ year is more like it. Their downloads are still 
>> binary-only. BSD does not imply Open Source when you don't have the 
>> sources, and "open source project" in this case means a project to make 
>> the software open source. The intention appears to be honourable, though.
>>
>>   Even before that,
>>> glmmADMB (which was an R package with a binary component, available for
>>> download) was "free as in beer". In its current status, I think of ADMB
>>> in the same category as WinBUGS -- a powerful, albeit sometimes
>>> unwieldy, tool that can be used through an R interface to solve general
>>> problems by writing model descriptions in a non-R language.
>>>   I have to agree with Kevin that the diversity of mixed model software
>>> tools is a good thing.
>>>
>>>   cheers
>>>     Ben Bolker
>>>
>>> Douglas Bates wrote:
>>>> Got to disagree with you, Kevin.  admb and asreml are not part of R,
>>>> even in the general sense of R packages.  R is Open Source - they are
>>>> not. Tacking on an R interface to proprietary software and saying it
>>>> is available in R is misleading and dishonest.
>>>>
>>>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>>> Paul,
>>>>>
>>>>> It appears to me that the published timings you reference are
>>>>> comparing the __nlme__ package with other software.  So the answer is
>>>>> yes, nlme really is that slow for some models.  You are probably aware
>>>>> that the __lme4__ package has faster algorithms.
>>>>>
>>>>> There are many ways to fit mixed models in R including nlme, lme4,
>>>>> MCMCglmm, admb asreml, BUGS, etc.  If I was teaching a course, I would
>>>>> try to expose students to at least two of those in some detail and
>>>>> touch briefly on the others: nlme can fit a variety of complex
>>>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>>>> structures, admb is used in Fish & Wildlife, etc.
>>>>>
>>>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>>>
>>>>> Kevin Wright
>>>>>
>>>>>
>>>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>>>> Sent this to r-sig-debian by mistake the first time.  Depressing.
>>>>>>
>>>>>> 1.  One general question for general discussion:
>>>>>>
>>>>>> Is HLM6 faster than lmer? If so, why?
>>>>>>
>>>>>> I'm always advocating R to students, but some faculty members are
>>>>>> skeptical.  A colleague compared the commercial HLM6 software to lmer.
>>>>>>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>>>
>>>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>>>
>>>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>>>> faster.  However, in the output, HLM6 says:
>>>>>>
>>>>>> Method of estimation: restricted maximum likelihood
>>>>>>
>>>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>>>
>>>>>> Another explanation for the difference in time might be the way HLM6
>>>>>> saves the results of some matrix calculations and re-uses them behind
>>>>>> the scenes.  If every call to lmer is re-calculating some big matrix
>>>>>> results, I suppose that could explain it.
>>>>>>
>>>>>> There are comparisons from 2006 here
>>>>>>
>>>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>>>
>>>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>>>> me understand *why* there is a difference.
>>>>>>
>>>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>>>
>>>>>> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
>>>>>> to CRAN &  I checked this document:
>>>>>>
>>>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>>>
>>>>>> I *think* these things are automatically generated.  The version
>>>>>> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
>>>>>> full of the error message:
>>>>>>
>>>>>> stack imbalance in .Call,
>>>>>>
>>>>>> Were those always there?  I don't think so.   What do they mean?
>>>>>>
>>>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>>>
>>>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>>>
>>>>>> What effect does that have on the estimates?  I believe it should have
>>>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>>>> estimates of the variances of random parameters would be
>>>>>> changed.  In order to make the estimates from lmer as directly
>>>>>> comparable as possible, should I manually center all of the variables
>>>>>> before fitting the model?   I'm a little stumped on how to center a
>>>>>> multi-category factor before feeding it to lmer.  Know what I mean?
>>>>>>
>>>>>> pj
>>>>>>
>>>>>> --
>>>>>> Paul E. Johnson
>>>>>> Professor, Political Science
>>>>>> 1541 Lilac Lane, Room 504
>>>>>> University of Kansas
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From bates at stat.wisc.edu  Wed Sep 23 19:37:15 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 12:37:15 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <4ABA5932.80807@ufl.edu>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<4ABA5207.9020805@ufl.edu> <4ABA5952.7000808@biostat.ku.dk>
	<4ABA5932.80807@ufl.edu>
Message-ID: <40e66e0b0909231037if1c9530xf20bd2197c082ebc@mail.gmail.com>

On Wed, Sep 23, 2009 at 12:21 PM, Ben Bolker <bolker at ufl.edu> wrote:
> ?Source *is* available:

Thanks for the correction, Ben.  I withdraw my comments about ADMB and
welcome it to the Open Source software arena.

> Peter Dalgaard wrote:
>> Ben Bolker wrote:
>>> ? ?As of sometime last year (? I think ?), ADMB is
>>> free/gratis/libre/open source (BSD licensed).
>>
>> As of _next_ year is more like it. Their downloads are still
>> binary-only. BSD does not imply Open Source when you don't have the
>> sources, and "open source project" in this case means a project to make
>> the software open source. The intention appears to be honourable, though.
>>
>> ? Even before that,
>>> glmmADMB (which was an R package with a binary component, available for
>>> download) was "free as in beer". In its current status, I think of ADMB
>>> in the same category as WinBUGS -- a powerful, albeit sometimes
>>> unwieldy, tool that can be used through an R interface to solve general
>>> problems by writing model descriptions in a non-R language.
>>> ? I have to agree with Kevin that the diversity of mixed model software
>>> tools is a good thing.
>>>
>>> ? cheers
>>> ? ? Ben Bolker
>>>
>>> Douglas Bates wrote:
>>>> Got to disagree with you, Kevin. ?admb and asreml are not part of R,
>>>> even in the general sense of R packages. ?R is Open Source - they are
>>>> not. Tacking on an R interface to proprietary software and saying it
>>>> is available in R is misleading and dishonest.
>>>>
>>>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>>> Paul,
>>>>>
>>>>> It appears to me that the published timings you reference are
>>>>> comparing the __nlme__ package with other software. ?So the answer is
>>>>> yes, nlme really is that slow for some models. ?You are probably aware
>>>>> that the __lme4__ package has faster algorithms.
>>>>>
>>>>> There are many ways to fit mixed models in R including nlme, lme4,
>>>>> MCMCglmm, admb asreml, BUGS, etc. ?If I was teaching a course, I would
>>>>> try to expose students to at least two of those in some detail and
>>>>> touch briefly on the others: nlme can fit a variety of complex
>>>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>>>> structures, admb is used in Fish & Wildlife, etc.
>>>>>
>>>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>>>
>>>>> Kevin Wright
>>>>>
>>>>>
>>>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>>>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>>>>>>
>>>>>> 1. ?One general question for general discussion:
>>>>>>
>>>>>> Is HLM6 faster than lmer? If so, why?
>>>>>>
>>>>>> I'm always advocating R to students, but some faculty members are
>>>>>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>>>>>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>>>
>>>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>>>
>>>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>>>> faster. ?However, in the output, HLM6 says:
>>>>>>
>>>>>> Method of estimation: restricted maximum likelihood
>>>>>>
>>>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>>>
>>>>>> Another explanation for the difference in time might be the way HLM6
>>>>>> saves the results of some matrix calculations and re-uses them behind
>>>>>> the scenes. ?If every call to lmer is re-calculating some big matrix
>>>>>> results, I suppose that could explain it.
>>>>>>
>>>>>> There are comparisons from 2006 here
>>>>>>
>>>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>>>
>>>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>>>> me understand *why* there is a difference.
>>>>>>
>>>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>>>
>>>>>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>>>>>> to CRAN & ?I checked this document:
>>>>>>
>>>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>>>
>>>>>> I *think* these things are automatically generated. ?The version
>>>>>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>>>>>> full of the error message:
>>>>>>
>>>>>> stack imbalance in .Call,
>>>>>>
>>>>>> Were those always there? ?I don't think so. ? What do they mean?
>>>>>>
>>>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>>>
>>>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>>>
>>>>>> What effect does that have on the estimates? ?I believe it should have
>>>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>>>> estimates of the variances of random parameters would be
>>>>>> changed. ?In order to make the estimates from lmer as directly
>>>>>> comparable as possible, should I manually center all of the variables
>>>>>> before fitting the model? ? I'm a little stumped on how to center a
>>>>>> multi-category factor before feeding it to lmer. ?Know what I mean?
>>>>>>
>>>>>> pj
>>>>>>
>>>>>> --
>>>>>> Paul E. Johnson
>>>>>> Professor, Political Science
>>>>>> 1541 Lilac Lane, Room 504
>>>>>> University of Kansas
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Sep 23 20:08:43 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 13:08:43 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909231037if1c9530xf20bd2197c082ebc@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<4ABA5207.9020805@ufl.edu> <4ABA5952.7000808@biostat.ku.dk>
	<4ABA5932.80807@ufl.edu>
	<40e66e0b0909231037if1c9530xf20bd2197c082ebc@mail.gmail.com>
Message-ID: <40e66e0b0909231108s9e5fa5cof2c3f9ce4c73bc56@mail.gmail.com>

On Wed, Sep 23, 2009 at 12:37 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Sep 23, 2009 at 12:21 PM, Ben Bolker <bolker at ufl.edu> wrote:
>> ?Source *is* available:
>
> Thanks for the correction, Ben. ?I withdraw my comments about ADMB and
> welcome it to the Open Source software arena.

I have also exchanged email off-list with Kevin Wright and would like
to clarify that I was not labeling Kevin as dishonest in my response
and I sincerely regret my poor phrasing if I left that impression.

I am not quite Stallmanesque in my approach to open-source software
(for example, I will use the phrase "open-source") but I am somewhat
of a purist.  I do essentially all of my computing on Linux systems,
by choice.  I know of the thousands of hours of work, probably
hundreds of thousands by now, done by members of R-Core and many, many
others to make R what it is today. I also know of the importance of
licenses on open-source software.  In a very real sense the licenses
are what makes the whole open-source software movement work.  They may
not be important to casual useRs but they should be important to
developeRs.

This is why it pains me when software that is not open source is said
to be available through R because an interface has been written.
First it is unlikely that I would even be able to use it.  Most of the
time the binary is a Windows binary and not of use to me.  Secondly,
if I am going to devote many hours of my time to producing software
and make it all freely available, including the sources, I don't want
others to say that their wonderful software has similar status when
they can see what I do but I can't see what they do.

It turns out that I was wrong when I characterized ADMB as
proprietary.  It was proprietary but it is now open source and I think
that is great.  I offer my apologies if I have offended anyone with my
inaccurate and poorly considered statements.

>> Peter Dalgaard wrote:
>>> Ben Bolker wrote:
>>>> ? ?As of sometime last year (? I think ?), ADMB is
>>>> free/gratis/libre/open source (BSD licensed).
>>>
>>> As of _next_ year is more like it. Their downloads are still
>>> binary-only. BSD does not imply Open Source when you don't have the
>>> sources, and "open source project" in this case means a project to make
>>> the software open source. The intention appears to be honourable, though.
>>>
>>> ? Even before that,
>>>> glmmADMB (which was an R package with a binary component, available for
>>>> download) was "free as in beer". In its current status, I think of ADMB
>>>> in the same category as WinBUGS -- a powerful, albeit sometimes
>>>> unwieldy, tool that can be used through an R interface to solve general
>>>> problems by writing model descriptions in a non-R language.
>>>> ? I have to agree with Kevin that the diversity of mixed model software
>>>> tools is a good thing.
>>>>
>>>> ? cheers
>>>> ? ? Ben Bolker
>>>>
>>>> Douglas Bates wrote:
>>>>> Got to disagree with you, Kevin. ?admb and asreml are not part of R,
>>>>> even in the general sense of R packages. ?R is Open Source - they are
>>>>> not. Tacking on an R interface to proprietary software and saying it
>>>>> is available in R is misleading and dishonest.
>>>>>
>>>>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>>>>> Paul,
>>>>>>
>>>>>> It appears to me that the published timings you reference are
>>>>>> comparing the __nlme__ package with other software. ?So the answer is
>>>>>> yes, nlme really is that slow for some models. ?You are probably aware
>>>>>> that the __lme4__ package has faster algorithms.
>>>>>>
>>>>>> There are many ways to fit mixed models in R including nlme, lme4,
>>>>>> MCMCglmm, admb asreml, BUGS, etc. ?If I was teaching a course, I would
>>>>>> try to expose students to at least two of those in some detail and
>>>>>> touch briefly on the others: nlme can fit a variety of complex
>>>>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>>>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>>>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>>>>> structures, admb is used in Fish & Wildlife, etc.
>>>>>>
>>>>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>>>>
>>>>>> Kevin Wright
>>>>>>
>>>>>>
>>>>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>>>>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>>>>>>>
>>>>>>> 1. ?One general question for general discussion:
>>>>>>>
>>>>>>> Is HLM6 faster than lmer? If so, why?
>>>>>>>
>>>>>>> I'm always advocating R to students, but some faculty members are
>>>>>>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>>>>>>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>>>>
>>>>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>>>>
>>>>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>>>>> faster. ?However, in the output, HLM6 says:
>>>>>>>
>>>>>>> Method of estimation: restricted maximum likelihood
>>>>>>>
>>>>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>>>>
>>>>>>> Another explanation for the difference in time might be the way HLM6
>>>>>>> saves the results of some matrix calculations and re-uses them behind
>>>>>>> the scenes. ?If every call to lmer is re-calculating some big matrix
>>>>>>> results, I suppose that could explain it.
>>>>>>>
>>>>>>> There are comparisons from 2006 here
>>>>>>>
>>>>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>>>>
>>>>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>>>>> me understand *why* there is a difference.
>>>>>>>
>>>>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>>>>
>>>>>>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>>>>>>> to CRAN & ?I checked this document:
>>>>>>>
>>>>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>>>>
>>>>>>> I *think* these things are automatically generated. ?The version
>>>>>>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>>>>>>> full of the error message:
>>>>>>>
>>>>>>> stack imbalance in .Call,
>>>>>>>
>>>>>>> Were those always there? ?I don't think so. ? What do they mean?
>>>>>>>
>>>>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>>>>
>>>>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>>>>
>>>>>>> What effect does that have on the estimates? ?I believe it should have
>>>>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>>>>> estimates of the variances of random parameters would be
>>>>>>> changed. ?In order to make the estimates from lmer as directly
>>>>>>> comparable as possible, should I manually center all of the variables
>>>>>>> before fitting the model? ? I'm a little stumped on how to center a
>>>>>>> multi-category factor before feeding it to lmer. ?Know what I mean?
>>>>>>>
>>>>>>> pj
>>>>>>>
>>>>>>> --
>>>>>>> Paul E. Johnson
>>>>>>> Professor, Political Science
>>>>>>> 1541 Lilac Lane, Room 504
>>>>>>> University of Kansas
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>>
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From kw.stat at gmail.com  Wed Sep 23 20:46:47 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 23 Sep 2009 13:46:47 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
Message-ID: <5c62e0070909231146w5ba0a2d9r1b7ad405fe6f52a@mail.gmail.com>

Of course asreml is "not part of R", but it is certainly available in
R.  R's license allows for closed-source packages, just not on CRAN.
To call this "dishonest" is most peculiar.  Is REvolutionR acting
dishonestly with some of their offerings?

I'm a strong believer in collaborative development and open source,
but I believe there's room for closed development models too.  More
than that, I would even argue that it is *helpful* to R.  Remember
that MASS, Design, Hmisc, nlme, and survival all started with S-Plus.
Without the existence of S-Plus we probably would be using
xlisp-stat-nlme and have to deal with even more parentheses!  I'm sure
Doug could enlighten us with some interesting stories about how nlme
started as part of S-Plus.

>From the perspective of developing personal skills that are portable
to different platforms or careers or whatever, I wish I could use an
open source mixed models package, but neither nlme nor lme4 nor
MCMCglmm can fit models to large data sets with a variety of complex
variance structures, so I use asreml.

On a lighter note, I propose that the members of this list create the
"Doug Bates foundation" and establish funding for Doug to quit his day
job and spend his life finishing lme4.

Kevin Wright


On Wed, Sep 23, 2009 at 11:31 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Got to disagree with you, Kevin. ?admb and asreml are not part of R,
> even in the general sense of R packages. ?R is Open Source - they are
> not. Tacking on an R interface to proprietary software and saying it
> is available in R is misleading and dishonest.
>
> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>> Paul,
>>
>> It appears to me that the published timings you reference are
>> comparing the __nlme__ package with other software. ?So the answer is
>> yes, nlme really is that slow for some models. ?You are probably aware
>> that the __lme4__ package has faster algorithms.
>>
>> There are many ways to fit mixed models in R including nlme, lme4,
>> MCMCglmm, admb asreml, BUGS, etc. ?If I was teaching a course, I would
>> try to expose students to at least two of those in some detail and
>> touch briefly on the others: nlme can fit a variety of complex
>> varaiance structures, lme4 has faster algorithms, asreml is the only
>> choice of animal/plant breeders and has commercial support, MCMCglmm
>> has some Bayesian aspects and can fit some heteroskedastic variance
>> structures, admb is used in Fish & Wildlife, etc.
>>
>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>
>> Kevin Wright
>>
>>
>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>>>
>>> 1. ?One general question for general discussion:
>>>
>>> Is HLM6 faster than lmer? If so, why?
>>>
>>> I'm always advocating R to students, but some faculty members are
>>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>
>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>
>>> My first thought was that LM6 uses PQL by default, and it would be
>>> faster. ?However, in the output, HLM6 says:
>>>
>>> Method of estimation: restricted maximum likelihood
>>>
>>> But that doesn't tell me what quadrature approach they use, does it?
>>>
>>> Another explanation for the difference in time might be the way HLM6
>>> saves the results of some matrix calculations and re-uses them behind
>>> the scenes. ?If every call to lmer is re-calculating some big matrix
>>> results, I suppose that could explain it.
>>>
>>> There are comparisons from 2006 here
>>>
>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>
>>> that indicate that lme was much slower than HLM, but that doesn't help
>>> me understand *why* there is a difference.
>>>
>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>
>>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>>> to CRAN & ?I checked this document:
>>>
>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>
>>> I *think* these things are automatically generated. ?The version
>>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>>> full of the error message:
>>>
>>> stack imbalance in .Call,
>>>
>>> Were those always there? ?I don't think so. ? What do they mean?
>>>
>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>
>>> '%' - This level-1 predictor has been centered around its grand mean.
>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>
>>> What effect does that have on the estimates? ?I believe it should have
>>> no effect on the fixed effect slope estimates, but it seems to me the
>>> estimates of the variances of random parameters would be
>>> changed. ?In order to make the estimates from lmer as directly
>>> comparable as possible, should I manually center all of the variables
>>> before fitting the model? ? I'm a little stumped on how to center a
>>> multi-category factor before feeding it to lmer. ?Know what I mean?
>>>
>>> pj
>>>
>>> --
>>> Paul E. Johnson
>>> Professor, Political Science
>>> 1541 Lilac Lane, Room 504
>>> University of Kansas
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bates at stat.wisc.edu  Wed Sep 23 21:37:24 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 14:37:24 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <5c62e0070909231146w5ba0a2d9r1b7ad405fe6f52a@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<5c62e0070909231146w5ba0a2d9r1b7ad405fe6f52a@mail.gmail.com>
Message-ID: <40e66e0b0909231237s6b3f6550kfcbd1ef4ffdcbe7b@mail.gmail.com>

On Wed, Sep 23, 2009 at 1:46 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> Of course asreml is "not part of R", but it is certainly available in
> R. ?R's license allows for closed-source packages, just not on CRAN.
> To call this "dishonest" is most peculiar. ?Is REvolutionR acting
> dishonestly with some of their offerings?

> I'm a strong believer in collaborative development and open source,
> but I believe there's room for closed development models too. ?More
> than that, I would even argue that it is *helpful* to R. ?Remember
> that MASS, Design, Hmisc, nlme, and survival all started with S-Plus.
> Without the existence of S-Plus we probably would be using
> xlisp-stat-nlme and have to deal with even more parentheses! ?I'm sure
> Doug could enlighten us with some interesting stories about how nlme
> started as part of S-Plus.

The nlme package was always open source.  It was S-PLUS that was
closed source.  But we didn't develop nlme in S-PLUS, we developed it
in S from Bell Labs.  I rarely used S-PLUS at all.  Our book was
originally titled "Mixed-effects Models in S".  It was Springer who
lobbied for tacking the "and S-PLUS" on the end.

> From the perspective of developing personal skills that are portable
> to different platforms or careers or whatever, I wish I could use an
> open source mixed models package, but neither nlme nor lme4 nor
> MCMCglmm can fit models to large data sets with a variety of complex
> variance structures, so I use asreml.
>
> On a lighter note, I propose that the members of this list create the
> "Doug Bates foundation" and establish funding for Doug to quit his day
> job and spend his life finishing lme4.

Well, actually, Doug likes his day job (for the most part - about two
hours into a typical faculty meeting he may be open to offers of other
ways to spend his time).  This is the whole point of open-source
software development - it is part of my job.  For all intents and
purposes, the cost of open source software is the cost of the first
copy - creating and distributing subsequent copies is essentially free
relative to the cost of developing the first copy, especially when the
infrastructure for that distribution is available from other
open-source projects such as Apache, Linux, ...  My employer has no
problems with my spending my time developing that first copy.  It's
called "research" and they expect that I will spend at least some of
my time doing that. It happens that the University of Wisconsin has a
very strong tradition of openness with regard to research and freedom
of expression (look up the phrase "sifting and winnowing" on
www.wisc.edu) and is quite supportive of my making software freely
available.

>From time to time it is suggested that it would speed development of R
if money were used to hire "professional programmers" as opposed to
the amateurs who work on it now.  But that really isn't the case.
R-Core is a meritocracy and its members have to believe that anyone
admitted to R-Core is really, really good and unlikely to botch things
up with careless commits.  It is unlikely that an ad for a programmer
on a job-search site is going to get you the next John Chambers or
Brian Ripley or Luke Tierney or ...  These are the top people in the
field and they aren't working on R as a job.  They are doing it
because of the freedom to create the software that they want to make
available, not what the marketing folks think should be done.  Do you
think that the marketing folks would have tolerated a system without a
GUI for this length of time?  If R was driven by marketing
considerations it would be Excel.

People are often taken aback when comparisons of software quality show
that well-established open-source projects are better quality code
than commercial software.  For example, the evaluation of cdf's,
quantile functions and densities or probability functions in R is at
least as good as in commercial software and often much better.  Why?
Well, writing such code is a job for someone as SAS Institute.  For
Martin Maechler, writing code to evaluate these functions accurately
under the widest possible range of arguments is a passion.

The other part of the economics of open-source software versus
commercial software that escapes the usual analysis is that
development is only a small part of the cost of commercial software.
Most of the cost of doing business for software companies is in
marketing and support and support for R is contributed through mailing
lists like this.

>
> Kevin Wright
>
>
> On Wed, Sep 23, 2009 at 11:31 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> Got to disagree with you, Kevin. ?admb and asreml are not part of R,
>> even in the general sense of R packages. ?R is Open Source - they are
>> not. Tacking on an R interface to proprietary software and saying it
>> is available in R is misleading and dishonest.
>>
>> On Wed, Sep 23, 2009 at 8:54 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>>> Paul,
>>>
>>> It appears to me that the published timings you reference are
>>> comparing the __nlme__ package with other software. ?So the answer is
>>> yes, nlme really is that slow for some models. ?You are probably aware
>>> that the __lme4__ package has faster algorithms.
>>>
>>> There are many ways to fit mixed models in R including nlme, lme4,
>>> MCMCglmm, admb asreml, BUGS, etc. ?If I was teaching a course, I would
>>> try to expose students to at least two of those in some detail and
>>> touch briefly on the others: nlme can fit a variety of complex
>>> varaiance structures, lme4 has faster algorithms, asreml is the only
>>> choice of animal/plant breeders and has commercial support, MCMCglmm
>>> has some Bayesian aspects and can fit some heteroskedastic variance
>>> structures, admb is used in Fish & Wildlife, etc.
>>>
>>> Mixed model fitting in R is definitely not a case of "one size fits all".
>>>
>>> Kevin Wright
>>>
>>>
>>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>>>>
>>>> 1. ?One general question for general discussion:
>>>>
>>>> Is HLM6 faster than lmer? If so, why?
>>>>
>>>> I'm always advocating R to students, but some faculty members are
>>>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>>>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>>>
>>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>>>>
>>>> My first thought was that LM6 uses PQL by default, and it would be
>>>> faster. ?However, in the output, HLM6 says:
>>>>
>>>> Method of estimation: restricted maximum likelihood
>>>>
>>>> But that doesn't tell me what quadrature approach they use, does it?
>>>>
>>>> Another explanation for the difference in time might be the way HLM6
>>>> saves the results of some matrix calculations and re-uses them behind
>>>> the scenes. ?If every call to lmer is re-calculating some big matrix
>>>> results, I suppose that could explain it.
>>>>
>>>> There are comparisons from 2006 here
>>>>
>>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>>>
>>>> that indicate that lme was much slower than HLM, but that doesn't help
>>>> me understand *why* there is a difference.
>>>>
>>>> 2. What does "stack imbalance in .Call" mean in lmer?
>>>>
>>>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>>>> to CRAN & ?I checked this document:
>>>>
>>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>>
>>>> I *think* these things are automatically generated. ?The version
>>>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>>>> full of the error message:
>>>>
>>>> stack imbalance in .Call,
>>>>
>>>> Were those always there? ?I don't think so. ? What do they mean?
>>>>
>>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>>
>>>> '%' - This level-1 predictor has been centered around its grand mean.
>>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>>
>>>> What effect does that have on the estimates? ?I believe it should have
>>>> no effect on the fixed effect slope estimates, but it seems to me the
>>>> estimates of the variances of random parameters would be
>>>> changed. ?In order to make the estimates from lmer as directly
>>>> comparable as possible, should I manually center all of the variables
>>>> before fitting the model? ? I'm a little stumped on how to center a
>>>> multi-category factor before feeding it to lmer. ?Know what I mean?
>>>>
>>>> pj
>>>>
>>>> --
>>>> Paul E. Johnson
>>>> Professor, Political Science
>>>> 1541 Lilac Lane, Room 504
>>>> University of Kansas
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



From adik at ilovebacon.org  Wed Sep 23 23:19:15 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 23 Sep 2009 14:19:15 -0700 (PDT)
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>
	<40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>

Dear collagues,

 	Questions of speed, especially comparative speed between R and some
proprietary program, come up with some frequency.  Perhaps we should add a
FAQ that covers this?  Here is my first attempt at such a contribution.

Section: R Speed. I have {heard,seen,shown} that R is {a bit,a lot,eons}
faster than [other program].  Is this true?

0) We assume that the "benchmark" data sets adequately represent the sorts
of tasks you might use the software for, and that it includes the whole
process (including data import/transformation to prepare the model to run).

1) Proprietary software produces unverifiable statistical results: You
cannot deduce or detect when, whether, or how your results are wrong, unless
you compare the results to a trustworthy algorithm.  It is always faster to
use one method (e.g., the trustworthy one) than two.

2) Paying skilled programmers to write, optimize, and compile statistical
algorthims optimizes for speed.  Letting skilled statisticians who know how
to code and are personally motivated to implement an algorithm optimizes for
correctness and robustness of a model and its results.

3) The extensible nature of R algorithms may require more processing time,
which is likely less than the time required to export, import, reformat, and
re-tidy a data set for several programs (HLM6, SPSS, SAS, etc.), much like
it is faster to visit a large department store to buy a frying pan, perfume,
and a suit than it is to drive across three times to specific stores.

4) The speed of R changes based on several factors, including the version of
R you use and in some cases the BLAS against which you link.  If you believe
R is much slower than it should be, be sure you have upgraded to the latest
version and are using the appropriate version for your hardware and software
(e.g., 64-bit R for Snow Leopard).

5) R's code is written to treat arbitrarily-large data sets; many "very
fast" algorithms that other programs could use may well make assumptions
about data size that are intractible for large data sets, leading to
crashes, errors, or results that seem correct but are not.

Further:

6) R is more than a one-trick pony, and the ability to do nearly everything
comes at the expense of microoptimization.  Human triatheletes also do not
and cannot bike, run, or swim as quickly as single-focus bicyclists,
runners, or swimmers.

7) It is probably unreasonable to even expect open-source interpreted code
to be as fast as code written by people whose full-time job is to write and
optimize code. The fact that R's speed is of the same order of magnitude as
"some other program" is itself remarkable.

...in sum, it is possible that a proprietary software system may produce a
result of the form you expect faster than R does, but it is unlikely to be
MUCH faster when you consider the entire data analysis process, and there
are several strong arguments for waiting the few extra seconds.

--Adam

On Wed, 23 Sep 2009, Douglas Bates wrote:

> I forgot to cc: the list on this reply.
>
> ---------- Forwarded message ----------
> From: Douglas Bates <bates at stat.wisc.edu>
> Date: Wed, Sep 23, 2009 at 11:29 AM
> Subject: Re: [R-sig-ME] More naive questions: Speed comparisons? what
> is a "stack imbalance" in lmer? does lmer center variables?
> To: Paul Johnson <pauljohn32 at gmail.com>
>
>
>
> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>
>> 1. ?One general question for general discussion:
>
>> Is HLM6 faster than lmer? If so, why?
>
>> I'm always advocating R to students, but some faculty members are
>> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
>> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>
>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>
> Honestly, Paul, I don't see a point in discussing vague generalities
> and rumors. ?If your colleague can make the data (or even simuiated
> data with a similar structure) available and describe the model being
> fit then we can see why lmer appears to be so much slower on it. ?But
> do bear in mind that the folks marketing HLM6 have the ability -
> indeed they have the right - to run lmer on their test cases and to
> examine every single line of code in lmer so they can determine
> exactly what it is doing. ?They have the right to do that because
> everyone has the right to do that. ?If we want to find out how HLM6
> performs on a test case we are reduced to your approach of asking if
> someone has a copy of the software (on one of or perhaps the only
> operating system under which it runs) and all that can be done is to
> quote the results. ?The internal details of HLM6 are proprietary.
>
> I can tell you my goals in developing the lme4 package are:
> ?1. Provide the ability to fit general forms of mixed-effects models.
> ?2. To the best of my ability, provide reliable estimates.
> ?3. Allow for models to be fit to very large data sets.
> ?4. Take advantage of the R environment to allow for straightforward
> model specification and for very general data manipulation and
> graphical capabilities.
> ?5. Subject to objectives 1-4 provide the fastest software that I can
>
>> My first thought was that LM6 uses PQL by default, and it would be
>> faster. ?However, in the output, HLM6 says:
>
>> Method of estimation: restricted maximum likelihood
>
>> But that doesn't tell me what quadrature approach they use, does it?
>
> To me this is very confusing. ?In my world REML is only meaningful for
> linear mixed models. ?(I know, at one time Mary Lindstrom and I wrote
> about REML estimates for nonlinear mixed models but, as I have said
> before, I consider that a youthful indiscretion.) ?For linear mixed
> models there is no need to use PQL or to discuss quadrature because
> the evaluation of the profiled deviance or the profiled REML criterion
> is a direct calculation.
>
> Again, without a more complete description of the data and the model
> to be fit it is impossible to discuss these issues meaningfully.
>
>> Another explanation for the difference in time might be the way HLM6
>> saves the results of some matrix calculations and re-uses them behind
>> the scenes. ?If every call to lmer is re-calculating some big matrix
>> results, I suppose that could explain it.
>
> But you don't need to speculate about what lmer does. ?It is Open
> Source so you can check for yourself.
>
> However, this does bring up another point which is the need to compare
> apples with apples when you are benchmarking software. ?If the data
> import and model specification stages in HLM6 create the necessary
> matrix structures for performing the iterative fit then does the time
> to fit the model consist solely of the optimization and summary
> stages? ?Using an expression like
>
> system.time(fm1 <- lmer(...))
>
> is assessing the time to take the original data, which could be in a
> very general form, create all those internal structures and perform
> the optimization.
>
> You should bear in mind that a lot of that construction of the model
> structures is written in R exactly so that it is capable of fitting
> very general model specifications. ?The code in HLM6 is, I imagine,
> compiled code, which is possible because it targets a very specific
> task, and compiled code is always going to be much faster than
> interpreted code.
>
>> There are comparisons from 2006 here
>
>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>
>> that indicate that lme was much slower than HLM, but that doesn't help
>> me understand *why* there is a difference.
>
> I believe that those examples are available for testing with lmer in
> the mlmRev package for R. ?However, the results can't be compared
> meaningfully to the tabled results because today's hardware is so
> different from what was used for those comparisons.
>
> Besides, none of those examples is really challenging. ?I was just
> doing some timing tests on a model fit to 1.7 million observations
> with 750,000 random effects associated with four different, non-nested
> grouping factors and 40 fixed-effects parameters. ?To me that is a
> meaningful test because it took from 1 to 2 hours to fit on a fast
> server computer. ?Unfortunately, I can't make that data available
> because of confidentiality restrictions but, even if I could, I don't
> think the model could be fit in HLM6 or MLWin or SAS PROC MIXED or
> Stata because there are 750,000 random effects in a non-nested
> configuration.
>
> I can make a similar but smaller test case available using the star
> (Student-Teacher Achievement Ratio) data from the mlmRev package. ?One
> model could be
>
>> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
> ? user ?system elapsed
> ?9.885 ? 0.044 ?10.508
>> print(fm1, corr = FALSE)
> Linear mixed model fit by REML
> Formula: math ~ gr + cltype + sx + eth + (1 | id) + (1 | tch) + (1 | sch)
> ? Data: star
> ? ?AIC ? ?BIC ?logLik deviance REMLdev
> ?239236 239365 -119602 ? 239245 ?239204
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?id ? ? ? (Intercept) 1001.60 ?31.648
> ?tch ? ? ?(Intercept) ?295.03 ?17.176
> ?sch ? ? ?(Intercept) ?104.78 ?10.236
> ?Residual ? ? ? ? ? ? ?397.32 ?19.933
> Number of obs: 24578, groups: id, 10732; tch, 1374; sch, 80
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) 560.8868 ? ? 1.5745 ? 356.2
> gr.L ? ? ? ? 95.6126 ? ? 1.0080 ? ?94.9
> gr.Q ? ? ? ? -4.6783 ? ? 0.9857 ? ?-4.7
> gr.C ? ? ? ? -3.2320 ? ? 0.9729 ? ?-3.3
> cltypereg ? ?-7.7943 ? ? 1.3322 ? ?-5.9
> cltypereg+A ?-7.0055 ? ? 1.3265 ? ?-5.3
> sxF ? ? ? ? ? 2.8766 ? ? 0.6836 ? ? 4.2
> ethB ? ? ? ?-21.9197 ? ? 1.2219 ? -17.9
> ethA ? ? ? ? ?3.1940 ? ? 6.7037 ? ? 0.5
> ethH ? ? ? ? ?4.5411 ? ? 9.6653 ? ? 0.5
> ethI ? ? ? ?-28.1618 ? ?13.5359 ? ?-2.1
> ethO ? ? ? ? ?3.4356 ? ? 8.3133 ? ? 0.4
>
> Unfortunately, because that model is based on only 25000 observations
> and 11000 random effects it is difficult to get a meaningful timing.
> Timings under 10 seconds, like this, are subject to too much
> variability.
>
> Nevertheless you can take that data and try to fit that model in any
> of the other software systems. ?Note that student (the "id" factor) is
> not nested within teacher ("tch") or school, as will almost always
> happen when fitting longitudinal data so the random effects are
> partially crossed. ?In other words, they are not nested so the
> structure is not hierarchical or multi-level in the sense of HLM or
> MLWin. ?I would invite those who have access to such software to fit
> the model using lme4 and to fit an equivalent model in other systems
> and tell us how they compare. ?I can't do that because I choose not to
> use proprietary software.
>
>> 2. What does "stack imbalance in .Call" mean in lmer?
>
> It is a sign of a bug in the C code underlying the lme4 package. ?It
> should be reported as a bug if it occurred in the currently released
> version of lme4.
>
>> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
>> to CRAN & ?I checked this document:
>>
>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>
>> I *think* these things are automatically generated. ?The version
>> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
>> full of the error message:
>>
>> stack imbalance in .Call,
>>
>> Were those always there? ?I don't think so. ? What do they mean?
>
> No they shouldn't be there. ?I'll update the mlmRev package.
>
>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>
>> '%' - This level-1 predictor has been centered around its grand mean.
>> '$' - This level-2 predictor has been centered around its grand mean.
>>
>> What effect does that have on the estimates? ?I believe it should have
>> no effect on the fixed effect slope estimates, but it seems to me the
>> estimates of the variances of random parameters would be
>> changed. ?In order to make the estimates from lmer as directly
>> comparable as possible, should I manually center all of the variables
>> before fitting the model? ? I'm a little stumped on how to center a
>> multi-category factor before feeding it to lmer. ?Know what I mean?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

From kw.stat at gmail.com  Thu Sep 24 00:52:56 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 23 Sep 2009 17:52:56 -0500
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>
	<40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>
	<Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
Message-ID: <5c62e0070909231552y5814f8case92c5c0840b7ff2e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090923/579aadf8/attachment.pl>

From ggrothendieck at gmail.com  Thu Sep 24 01:12:45 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 23 Sep 2009 19:12:45 -0400
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
	"stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
Message-ID: <971536df0909231612y547c519eoe95b9034876d1889@mail.gmail.com>

Even if the commercial software is faster is this really material or
just theoretical?
If most practical problems take 1 second on one and 10 seconds on the
other is it really important?

One person, not a user -- just interested in benchmarking, noted that
for particular cases he could write R software that was orders of
magnitude faster than strapply in gsubfn.  I asked the user of that
software who I suspected of using the largest datasets whether the
speed was a problem and he said NO!     I sped it up by an order of
magnitude anyways but even if I had not it probably would not have had
any practical significance.

On Wed, Sep 23, 2009 at 2:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Sent this to r-sig-debian by mistake the first time. ?Depressing.
>
> 1. ?One general question for general discussion:
>
> Is HLM6 faster than lmer? If so, why?
>
> I'm always advocating R to students, but some faculty members are
> skeptical. ?A colleague compared the commercial HLM6 software to lmer.
> ?HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>
> If you have HLM6 (I don't), can you tell me if you see similar differences?
>
> My first thought was that LM6 uses PQL by default, and it would be
> faster. ?However, in the output, HLM6 says:
>
> Method of estimation: restricted maximum likelihood
>
> But that doesn't tell me what quadrature approach they use, does it?
>
> Another explanation for the difference in time might be the way HLM6
> saves the results of some matrix calculations and re-uses them behind
> the scenes. ?If every call to lmer is re-calculating some big matrix
> results, I suppose that could explain it.
>
> There are comparisons from 2006 here
>
> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>
> that indicate that lme was much slower than HLM, but that doesn't help
> me understand *why* there is a difference.
>
> 2. What does "stack imbalance in .Call" mean in lmer?
>
> Here's why I ask. ?Searching for comparisons of lmer and HLM, ?I went
> to CRAN & ?I checked this document:
>
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>
> I *think* these things are automatically generated. ?The version
> that's up there at this moment ?(mlmRev edition 0.99875-1) ?has pages
> full of the error message:
>
> stack imbalance in .Call,
>
> Were those always there? ?I don't think so. ? What do they mean?
>
> 3. In the HLM6 output, there is a message at the end of the variable list:
>
> '%' - This level-1 predictor has been centered around its grand mean.
> '$' - This level-2 predictor has been centered around its grand mean.
>
> What effect does that have on the estimates? ?I believe it should have
> no effect on the fixed effect slope estimates, but it seems to me the
> estimates of the variances of random parameters would be
> changed. ?In order to make the estimates from lmer as directly
> comparable as possible, should I manually center all of the variables
> before fitting the model? ? I'm a little stumped on how to center a
> multi-category factor before feeding it to lmer. ?Know what I mean?
>
> pj
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Thu Sep 24 02:11:47 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 23 Sep 2009 20:11:47 -0400
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>	<40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>	<40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>
	<Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
Message-ID: <4ABAB943.3040504@ufl.edu>

   I think this reasonable and interesting, but it reads more like an
apology (in the technical sense, not indicating any sense of shame) for
R rather than a measured pros and cons.  I could quibble with almost any
of these statements ... probably should just stop there, but I'll
continue below.

Adam D. I. Kramer wrote:
> Dear collagues,
> 
>         Questions of speed, especially comparative speed between R and some
> proprietary program, come up with some frequency.  Perhaps we should add a
> FAQ that covers this?  Here is my first attempt at such a contribution.
> 
> Section: R Speed. I have {heard,seen,shown} that R is {a bit,a lot,eons}
> faster than [other program].  Is this true?
> 
> 0) We assume that the "benchmark" data sets adequately represent the sorts
> of tasks you might use the software for, and that it includes the whole
> process (including data import/transformation to prepare the model to run).

  Good point.
> 
> 1) Proprietary software produces unverifiable statistical results: You
> cannot deduce or detect when, whether, or how your results are wrong, unless
> you compare the results to a trustworthy algorithm.  It is always faster to
> use one method (e.g., the trustworthy one) than two.

   I don't think that simply having the access to the code guarantees
"verification". It sure helps though! My personal criteria for trust in
a piece of software would also include [in no particular order] (1)
trust in the credentials, skill, and attention to detail of the author;
(2) comparisons against benchmark cases where analytical results or
carefully hand-worked results are available; (3) comparisons against
other software.

> 
> 2) Paying skilled programmers to write, optimize, and compile statistical
> algorthims optimizes for speed.  Letting skilled statisticians who know how
> to code and are personally motivated to implement an algorithm optimizes for
> correctness and robustness of a model and its results.

  Yes, but ... where open source tends to fall down is in implementing
features (and I mean real features, not questionable "features") that
are outside the focus of the developers.  There are plenty of "wish
list" items that people would happily pay for that don't get done
because no-one with the skills feels like doing it. I've thought before
of trying to set up a bounty system for R, but even that is too far down
on my list to get to ...
> 
> 3) The extensible nature of R algorithms may require more processing time,
> which is likely less than the time required to export, import, reformat, and
> re-tidy a data set for several programs (HLM6, SPSS, SAS, etc.), much like
> it is faster to visit a large department store to buy a frying pan, perfume,
> and a suit than it is to drive across three times to specific stores.

  Analogy alert!
  Agreed that it is nice to use a single tool for all jobs, but that's
not necessarily the best idea.  I agree that all software should make it
easy to EXPORT data to other formats (or to interchange formats), and
open source software is often better at this.  (Should we really try to
re-implement GIS systems, relational databases, etc. within R? no.)

> 
> 4) The speed of R changes based on several factors, including the version of
> R you use and in some cases the BLAS against which you link.  If you believe
> R is much slower than it should be, be sure you have upgraded to the latest
> version and are using the appropriate version for your hardware and software
> (e.g., 64-bit R for Snow Leopard).

  yes.
> 
> 5) R's code is written to treat arbitrarily-large data sets; many "very
> fast" algorithms that other programs could use may well make assumptions
> about data size that are intractible for large data sets, leading to
> crashes, errors, or results that seem correct but are not.

   Certainly not always true.  (See Kevin Wright's post.)

> 
> Further:
> 
> 6) R is more than a one-trick pony, and the ability to do nearly everything
> comes at the expense of microoptimization.  Human triatheletes also do not
> and cannot bike, run, or swim as quickly as single-focus bicyclists,
> runners, or swimmers.

  Yeah, so?
  The "Unix philosophy" of tools suggests instead that one should
instead write sets of tools, each of which does one thing well, and have
them talk to each other.  Just saying that there are arguments for
different levels of modularity, specialization, etc..

> 
> 7) It is probably unreasonable to even expect open-source interpreted code
> to be as fast as code written by people whose full-time job is to write and
> optimize code. The fact that R's speed is of the same order of magnitude as
> "some other program" is itself remarkable.

  So?
> 
> ...in sum, it is possible that a proprietary software system may produce a
> result of the form you expect faster than R does, but it is unlikely to be
> MUCH faster when you consider the entire data analysis process, and there
> are several strong arguments for waiting the few extra seconds.

  "It depends."
> 
> --Adam
> 
> On Wed, 23 Sep 2009, Douglas Bates wrote:
> 
>> I forgot to cc: the list on this reply.
>>
>> ---------- Forwarded message ----------
>> From: Douglas Bates <bates at stat.wisc.edu>
>> Date: Wed, Sep 23, 2009 at 11:29 AM
>> Subject: Re: [R-sig-ME] More naive questions: Speed comparisons? what
>> is a "stack imbalance" in lmer? does lmer center variables?
>> To: Paul Johnson <pauljohn32 at gmail.com>
>>
>>
>>
>> On Wed, Sep 23, 2009 at 1:36 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>> Sent this to r-sig-debian by mistake the first time.  Depressing.
>>> 1.  One general question for general discussion:
>>> Is HLM6 faster than lmer? If so, why?
>>> I'm always advocating R to students, but some faculty members are
>>> skeptical.  A colleague compared the commercial HLM6 software to lmer.
>>>  HLM6 seems to fit the model in 1 second, but lmer takes 60 seconds.
>>> If you have HLM6 (I don't), can you tell me if you see similar differences?
>> Honestly, Paul, I don't see a point in discussing vague generalities
>> and rumors.  If your colleague can make the data (or even simuiated
>> data with a similar structure) available and describe the model being
>> fit then we can see why lmer appears to be so much slower on it.  But
>> do bear in mind that the folks marketing HLM6 have the ability -
>> indeed they have the right - to run lmer on their test cases and to
>> examine every single line of code in lmer so they can determine
>> exactly what it is doing.  They have the right to do that because
>> everyone has the right to do that.  If we want to find out how HLM6
>> performs on a test case we are reduced to your approach of asking if
>> someone has a copy of the software (on one of or perhaps the only
>> operating system under which it runs) and all that can be done is to
>> quote the results.  The internal details of HLM6 are proprietary.
>>
>> I can tell you my goals in developing the lme4 package are:
>>  1. Provide the ability to fit general forms of mixed-effects models.
>>  2. To the best of my ability, provide reliable estimates.
>>  3. Allow for models to be fit to very large data sets.
>>  4. Take advantage of the R environment to allow for straightforward
>> model specification and for very general data manipulation and
>> graphical capabilities.
>>  5. Subject to objectives 1-4 provide the fastest software that I can
>>
>>> My first thought was that LM6 uses PQL by default, and it would be
>>> faster.  However, in the output, HLM6 says:
>>> Method of estimation: restricted maximum likelihood
>>> But that doesn't tell me what quadrature approach they use, does it?
>> To me this is very confusing.  In my world REML is only meaningful for
>> linear mixed models.  (I know, at one time Mary Lindstrom and I wrote
>> about REML estimates for nonlinear mixed models but, as I have said
>> before, I consider that a youthful indiscretion.)  For linear mixed
>> models there is no need to use PQL or to discuss quadrature because
>> the evaluation of the profiled deviance or the profiled REML criterion
>> is a direct calculation.
>>
>> Again, without a more complete description of the data and the model
>> to be fit it is impossible to discuss these issues meaningfully.
>>
>>> Another explanation for the difference in time might be the way HLM6
>>> saves the results of some matrix calculations and re-uses them behind
>>> the scenes.  If every call to lmer is re-calculating some big matrix
>>> results, I suppose that could explain it.
>> But you don't need to speculate about what lmer does.  It is Open
>> Source so you can check for yourself.
>>
>> However, this does bring up another point which is the need to compare
>> apples with apples when you are benchmarking software.  If the data
>> import and model specification stages in HLM6 create the necessary
>> matrix structures for performing the iterative fit then does the time
>> to fit the model consist solely of the optimization and summary
>> stages?  Using an expression like
>>
>> system.time(fm1 <- lmer(...))
>>
>> is assessing the time to take the original data, which could be in a
>> very general form, create all those internal structures and perform
>> the optimization.
>>
>> You should bear in mind that a lot of that construction of the model
>> structures is written in R exactly so that it is capable of fitting
>> very general model specifications.  The code in HLM6 is, I imagine,
>> compiled code, which is possible because it targets a very specific
>> task, and compiled code is always going to be much faster than
>> interpreted code.
>>
>>> There are comparisons from 2006 here
>>> http://www.cmm.bristol.ac.uk/learning-training/multilevel-m-software/tables.shtml
>>> that indicate that lme was much slower than HLM, but that doesn't help
>>> me understand *why* there is a difference.
>> I believe that those examples are available for testing with lmer in
>> the mlmRev package for R.  However, the results can't be compared
>> meaningfully to the tabled results because today's hardware is so
>> different from what was used for those comparisons.
>>
>> Besides, none of those examples is really challenging.  I was just
>> doing some timing tests on a model fit to 1.7 million observations
>> with 750,000 random effects associated with four different, non-nested
>> grouping factors and 40 fixed-effects parameters.  To me that is a
>> meaningful test because it took from 1 to 2 hours to fit on a fast
>> server computer.  Unfortunately, I can't make that data available
>> because of confidentiality restrictions but, even if I could, I don't
>> think the model could be fit in HLM6 or MLWin or SAS PROC MIXED or
>> Stata because there are 750,000 random effects in a non-nested
>> configuration.
>>
>> I can make a similar but smaller test case available using the star
>> (Student-Teacher Achievement Ratio) data from the mlmRev package.  One
>> model could be
>>
>>> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
>>   user  system elapsed
>>  9.885   0.044  10.508
>>> print(fm1, corr = FALSE)
>> Linear mixed model fit by REML
>> Formula: math ~ gr + cltype + sx + eth + (1 | id) + (1 | tch) + (1 | sch)
>>   Data: star
>>    AIC    BIC  logLik deviance REMLdev
>>  239236 239365 -119602   239245  239204
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  id       (Intercept) 1001.60  31.648
>>  tch      (Intercept)  295.03  17.176
>>  sch      (Intercept)  104.78  10.236
>>  Residual              397.32  19.933
>> Number of obs: 24578, groups: id, 10732; tch, 1374; sch, 80
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept) 560.8868     1.5745   356.2
>> gr.L         95.6126     1.0080    94.9
>> gr.Q         -4.6783     0.9857    -4.7
>> gr.C         -3.2320     0.9729    -3.3
>> cltypereg    -7.7943     1.3322    -5.9
>> cltypereg+A  -7.0055     1.3265    -5.3
>> sxF           2.8766     0.6836     4.2
>> ethB        -21.9197     1.2219   -17.9
>> ethA          3.1940     6.7037     0.5
>> ethH          4.5411     9.6653     0.5
>> ethI        -28.1618    13.5359    -2.1
>> ethO          3.4356     8.3133     0.4
>>
>> Unfortunately, because that model is based on only 25000 observations
>> and 11000 random effects it is difficult to get a meaningful timing.
>> Timings under 10 seconds, like this, are subject to too much
>> variability.
>>
>> Nevertheless you can take that data and try to fit that model in any
>> of the other software systems.  Note that student (the "id" factor) is
>> not nested within teacher ("tch") or school, as will almost always
>> happen when fitting longitudinal data so the random effects are
>> partially crossed.  In other words, they are not nested so the
>> structure is not hierarchical or multi-level in the sense of HLM or
>> MLWin.  I would invite those who have access to such software to fit
>> the model using lme4 and to fit an equivalent model in other systems
>> and tell us how they compare.  I can't do that because I choose not to
>> use proprietary software.
>>
>>> 2. What does "stack imbalance in .Call" mean in lmer?
>> It is a sign of a bug in the C code underlying the lme4 package.  It
>> should be reported as a bug if it occurred in the currently released
>> version of lme4.
>>
>>> Here's why I ask.  Searching for comparisons of lmer and HLM,  I went
>>> to CRAN &  I checked this document:
>>>
>>> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>>>
>>> I *think* these things are automatically generated.  The version
>>> that's up there at this moment  (mlmRev edition 0.99875-1)  has pages
>>> full of the error message:
>>>
>>> stack imbalance in .Call,
>>>
>>> Were those always there?  I don't think so.   What do they mean?
>> No they shouldn't be there.  I'll update the mlmRev package.
>>
>>> 3. In the HLM6 output, there is a message at the end of the variable list:
>>>
>>> '%' - This level-1 predictor has been centered around its grand mean.
>>> '$' - This level-2 predictor has been centered around its grand mean.
>>>
>>> What effect does that have on the estimates?  I believe it should have
>>> no effect on the fixed effect slope estimates, but it seems to me the
>>> estimates of the variances of random parameters would be
>>> changed.  In order to make the estimates from lmer as directly
>>> comparable as possible, should I manually center all of the variables
>>> before fitting the model?   I'm a little stumped on how to center a
>>> multi-category factor before feeding it to lmer.  Know what I mean?
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From pauljohn32 at gmail.com  Thu Sep 24 03:42:42 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 23 Sep 2009 20:42:42 -0500
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
Message-ID: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>

I'm sorry I made Doug mad and I'm sorry to have led the discussion off
into such a strange, disagreeable place.

Now that I understand your answers, I believe I can ask the question
in a non-naive way.  I believe this version should not provoke some of
the harsh words that I triggered in my awkward question.

New Non-Naive version of the Speed Question

Do you have a copy of HLM6 on your system?  Maybe you could help me by
running the same model in R (with any of the packages such as lme4,
nlme, or whatever) and HLM6 and let us all know if you get similar
estimates and how long it takes to run each one.

Here's why I ask.

My colleague has HLM6 on Windows XP and he compared a two-level linear
mixed effects model fitted with lmer from lme4 against HLM6.  He
surprised my by claiming that the HLM6 model estimation was completed
in about 1.5 seconds and the lmer estimation took 50 seconds.  That
did not seem right to me.  I looked a bit at his example and made a
few mental notes so I could ask you what to look for when I go back to
dig into this.  There are 27000 cases in his datasets and he has about
25 variables at the lower level of observation and 4 or 5 variables at
the higher level, which I think is the county of survey respondents.
He is fitting a random intercept (random across counties) and several
random slopes for the higher level variables.

He pointed out that the mlWin website reported speed differences in
2006 that were about the same.  Of course, you and I know that R and
all of the mixed effects packages have improved significantly since
then. That is why the speed gap on the one Windows XP system surprised
me.

Can you tell me if you see a difference between the two programs (if
you have HLM6).  If you see a difference on the same magnitude, it may
mean we are not mistaken in our conclusion.  But if you see no
difference, then it will mean I'm getting it wrong and I should
investigate more. If I can't solve it, I should provide a reproducible
example for your inspection.  I will ask permission to release the
private data to  you in that case.

Perhaps you think there are good reasons why R estimation takes longer.  E.g.:
1. HLM programmers have full access to benefit from optimizations in
lmer and other open programs, but they don't share their optimizations
in return.
2. lmer and other R routines are making calculations in a better way,
a more accurate way, so we should not worry that they take longer.
   That was my first guess, in the original mail I said I thought that
HLM was using PQL whereas lmer is using Laplace or Adaptive Gaussian
Quadrature.  But Doug's comment indicated that I was mistaken to
expect a difference there because REML is the default in lmer and it
is also what HLM is doing, and there's no involvement of quadrature or
integral approximation in a mixed linear model (gaussian dependent
variable).

On the other hand, perhaps you are (like me) surprised by this
difference and you want to help me figure out the cause of the
differences.  If you have ideas about that, maybe we can work together
(I don't suck at C!). I have pretty much experience profiling programs
in C and did some optimization help on a big-ish C++ based R package
this summer.

So far, I have a simple observer's interest in this question.   I
advise people whether it is beneficial for them to spend their scarce
resources on a commercial package like HLM6 and one of the factors
that is important to them is how "fast" the programs are.   I
personally don't see an urgent reason to buy HLM because it can
estimate a model in 1 second and an open source approach requires 50
seconds.  But I'm not the one making the decision. If I can make the R
version run almost as fast as HLM6, or provide reasons why people
might benefit from using a program that takes longer, then I can do my
job of advising the users.

I am sorry if this question appears impertinent or insulting. I do not
mean it as a criticism.

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From charpent at bacbuc.dyndns.org  Thu Sep 24 00:43:05 2009
From: charpent at bacbuc.dyndns.org (Emmanuel Charpentier)
Date: Thu, 24 Sep 2009 00:43:05 +0200
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <40e66e0b0909231237s6b3f6550kfcbd1ef4ffdcbe7b@mail.gmail.com>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<5c62e0070909230654k7a6b97beof29342f851ecc5d7@mail.gmail.com>
	<40e66e0b0909230931i4e9ce53fw9fae03005723854f@mail.gmail.com>
	<5c62e0070909231146w5ba0a2d9r1b7ad405fe6f52a@mail.gmail.com>
	<40e66e0b0909231237s6b3f6550kfcbd1ef4ffdcbe7b@mail.gmail.com>
Message-ID: <1253745784.11745.93.camel@PortableToshiba>

Ahem...

Le mercredi 23 septembre 2009 ? 14:37 -0500, Douglas Bates a ?crit, in a
very interesting thread :

[ Snip (for bandwidth's sake) ... ]

> [ ... ] If R was driven by marketing
> considerations it would be Excel.

With apologies to Pr Douglas M. Bates, I hereby take the liberty to
nominate this last sentence for immortalization as a fortune() data
point :-). (Hence the Cc to Achim Zeileis, which maintains the relevant
package).

[ another Snip... ]

Now, to get back to the subject matter :

I'd like to "push" a bit the JAGS Gibbs sampler as a good example of
both the good and discutable points of free software development.

JAGS is essentially  reimplementation of the BUGS language, able to run
(almost) all of the $#!+load of tutorial/pedagogic material written for
WinBUGS. It does it independently of the original Object Pascal (?)
implementation of WinBUGS.

One of its strong points is the use of C++ as  source language, making
it compilable on any platform with  gcc-compatible C++ compiler, whereas
WinBUGS is still tied, glued, bolted, riveted and weld to Windows and
the curious Pascal compiler and toolbox (the attempts to create a Linux
or Mac OS/X version of OpenBUGS seem to be (currently) a  failure), thus
forcing its potential users on these "other" platforms to use either a
more or less shaky and incomplete reimplementation of the necessary
parts of the Windows libraries (i. e. Wine) or a virtual machine. In
this sense, JAGS is *practically* "freer" than WinBUGS, the restrictions
to the use of the latter coming not from its license (David
Spiegelhalter and his team did "the Right Thing" here) but from its
implementation.

However, this "platform independence" came also at the cost of losing
the GUI. While I'm not quite fond of it (I tried it on a Windows
platform, found its objets incompatible with almost everything else in
common use on this platform (including graphics) and a distraction for
most of my work), I can understand that this GUI may be an useful ladder
while climbing (the first levels of) the learning curve of
Bayesian/multilevel/hierarchical modeling in R, which can be damnably
steep... A platform-specific reimplementation of such a GUI is probably
doable, a portable one is probably out of question.

Furthermore, Martyn Plummer, for good reasons (as far as I can tell),
did not implement some BUGS "features" (e.g. the I(,) introduced a
couple or two of small incompatibilities, which he duly flagged in a
section of the JAGS reference manual. Some limitations of the program
exist (e. g., you can have only as much parallel simulation chains as
there is random number generators).

Most of these incompatibilities are not a serious problem : for example,
if I needed a new random number generator, I could (if my C++ was not as
rusty as it is...) implement one and link it to the current
implementation of JAGS without too much difficulty.

However, some other (subtle) incompatibilities (probably) lie at the
root of the JAGS engine, and might be much more difficult to root out
(if possible at all). An example from the manual (sect 7.0.6 (sic...)) :

"Directed cycles are forbidden in JAGS. There are two important
instances where directed
cycles are used in BUGS.
. Defining autoregressive priors
. Defining ordered priors
For the first case, the GeoBUGS extension to WinBUGS provides some
convenient ways of defining autoregressive priors. These should be
available in a future version of JAGS."

Practically, this means that it is possible to write a model that will
run in WinBUGS but not in JAGS (and probably vice-versa...). I am not
competent enough to judge "which is Right", but I think that thes
incompatibilities might become a problem.

So, the freedom to reimplement comes with a (possibly not trivial)
price.

While my vote goes mostly to JAGS, mostly due to its *effective*
freedom, I see points in the "more closed" approach of WinBUGS.

This issue is, IMHO, different of the free/proprietary issue so hotly
(ng lengthily... debated in various places, this thread excluded :-) : I
see it not as free vs proprietary, but as "which is the "right" use of
the freedom we buy by using/contributing to free software" ?

So my points are :
	1) JAGS should be mentioned as an alternative implementation of the
BUGS language, "somewhat freer" than WinBUGS, wherever Gibbs sampling
via this tool is mentioned ;
	2) Martyn Plummer should be commended for taking the pain of offering
this alternative (and much needed) implementation ;
	3)  care should be taken to point the incompatibilities between these
two dialects of the same language ;
	4) more generally, care should be given not only to *moral* freedom,
but also to *practical* freedom issues... 

(Aside note : I'm not really sure that the two underlying models are
indeed the same, i. e. describing the same set of fittable models. Any
lights ?).

Sincerely,

					Emmanuel Charpentier
					(Mistypist...)



From emm.charpentier at free.fr  Thu Sep 24 00:51:09 2009
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Thu, 24 Sep 2009 00:51:09 +0200
Subject: [R-sig-ME] More naive questions: Speed comparisons? what is a
 "stack imbalance" in lmer? does lmer center variables?
In-Reply-To: <Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
References: <13e802630909222336p17148614kf601e85c69f5299f@mail.gmail.com>
	<40e66e0b0909230929n65458ddbxdbb8ff0dc3016d52@mail.gmail.com>
	<40e66e0b0909230934y2e697d5ev4e851e355fc5cd3e@mail.gmail.com>
	<Pine.LNX.4.64.0909231306540.8722@parser.ilovebacon.org>
Message-ID: <1253746269.11745.99.camel@PortableToshiba>

Le mercredi 23 septembre 2009 ? 14:19 -0700, Adam D. I. Kramer a ?crit :
> Dear collagues,
> 
>  	Questions of speed, especially comparative speed between R and some
> proprietary program, come up with some frequency.  Perhaps we should add a
> FAQ that covers this?  Here is my first attempt at such a contribution.
> 
> Section: R Speed. I have {heard,seen,shown} that R is {a bit,a lot,eons}
> faster than [other program].  Is this true?
  ^^|^^^
    +------- Didn't you mean "slower" (as implied by your proposed
answers) ? If so, nice lapsus calami... You barely miss a fortunes()
nomination (I already posted one tonight on this very list...:-).

[ Snip (bandwidth savings) of a proposal that seems sound to me ... ]

					Emmanuel Charpentier



From smckinney at bccrc.ca  Thu Sep 24 04:31:21 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 23 Sep 2009 19:31:21 -0700
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
In-Reply-To: <19527_1253756584_1253756584_13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
References: <19527_1253756584_1253756584_13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0249B5FF@crcmail4.BCCRC.CA>



Hi Paul,

Comments on speed in-line below


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Paul Johnson
> Sent: Wednesday, September 23, 2009 6:43 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about
> speed
> 
> I'm sorry I made Doug mad and I'm sorry to have led the discussion off
> into such a strange, disagreeable place.
> 
> Now that I understand your answers, I believe I can ask the question
> in a non-naive way.  I believe this version should not provoke some of
> the harsh words that I triggered in my awkward question.
> 
> New Non-Naive version of the Speed Question
> 
> Do you have a copy of HLM6 on your system?  Maybe you could help me by
> running the same model in R (with any of the packages such as lme4,
> nlme, or whatever) and HLM6 and let us all know if you get similar
> estimates and how long it takes to run each one.
> 
> Here's why I ask.
...
> 
> Perhaps you think there are good reasons why R estimation takes longer.
> E.g.:
> 1. HLM programmers have full access to benefit from optimizations in
> lmer and other open programs, but they don't share their optimizations
> in return.
> 2. lmer and other R routines are making calculations in a better way,
> a more accurate way, so we should not worry that they take longer.
>    That was my first guess, in the original mail I said I thought that
> HLM was using PQL whereas lmer is using Laplace or Adaptive Gaussian
> Quadrature.  But Doug's comment indicated that I was mistaken to
> expect a difference there because REML is the default in lmer and it
> is also what HLM is doing, and there's no involvement of quadrature or
> integral approximation in a mixed linear model (gaussian dependent
> variable).

Here's Doug's comment:
<Doug Bates>
But you don't need to speculate about what lmer does.  It is Open
Source so you can check for yourself.

However, this does bring up another point which is the need to compare
apples with apples when you are benchmarking software.  If the data
import and model specification stages in HLM6 create the necessary
matrix structures for performing the iterative fit then does the time
to fit the model consist solely of the optimization and summary
stages?  Using an expression like

system.time(fm1 <- lmer(...))

is assessing the time to take the original data, which could be in a
very general form, create all those internal structures and perform
the optimization.

You should bear in mind that a lot of that construction of the model
structures is written in R exactly so that it is capable of fitting
very general model specifications.  The code in HLM6 is, I imagine,
compiled code, which is possible because it targets a very specific
task, and compiled code is always going to be much faster than
interpreted code.
<\Doug Bates>

So part of the speed difference will be that R is an interpreted
language, whereas HLM6 is compiled.  

The other part is the construction and handling of the model matrix, 
which is a tough one to compare, as lmer() can handle more general models.  

Will your colleague only be fitting models that are within the 
specifications of HLM6, or will your colleague have some datasets with 
structure that HLM6 can not handle, and so will need to shoe-horn the data 
into HLM6 and make compromises that would not need to be made in lmer()?

If the former, then some clever programming (potentially both in R and
in C) can yield a specialized version of lmer() that will be comparable
in speed to HLM6 (I've done such modifications to several functions
over the years so have stopped believing that compiled code is always
faster than R - after all much of R is compiled C).  

If the latter, then the flexibility of the interpreted language version, 
and the implementation speed (i.e versus recoding and recompiling a 
specialized C program to fit new scenarios) generally beats the compiled 
language version.

> 
> On the other hand, perhaps you are (like me) surprised by this
> difference and you want to help me figure out the cause of the
> differences.  If you have ideas about that, maybe we can work together
> (I don't suck at C!). I have pretty much experience profiling programs
> in C and did some optimization help on a big-ish C++ based R package
> this summer.
> 
> So far, I have a simple observer's interest in this question.   I
> advise people whether it is beneficial for them to spend their scarce
> resources on a commercial package like HLM6 and one of the factors
> that is important to them is how "fast" the programs are.   I
> personally don't see an urgent reason to buy HLM because it can
> estimate a model in 1 second and an open source approach requires 50
> seconds.  


When I need to fit hundreds or thousands of models, I overcome the
speed deficit of the interpreted language by using a compute cluster,
far cheaper than the cost of my or other programmers' time that would
be involved to code and compile some specialty software in an effort
to handle the great variety of problems that the interpreted language
can handle.


All that said, the learning curve for the S language is somewhat
steep and a bit long.  If you just have to stuff some data into
something right away and get some numbers out, the $500 or so to
purchase HLM6 may be cheaper than learning R.  But if you're in it
for the long haul, learning how to drive this Race caR is sweet.


Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney -at-  bccrc +dot+ ca
tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3

Canada

> But I'm not the one making the decision. If I can make the R
> version run almost as fast as HLM6, or provide reasons why people
> might benefit from using a program that takes longer, then I can do my
> job of advising the users.
> 
> I am sorry if this question appears impertinent or insulting. I do not
> mean it as a criticism.
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken at kjbeath.com.au  Thu Sep 24 04:34:13 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 24 Sep 2009 02:34:13 -0000 (GMT)
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
In-Reply-To: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
References: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
Message-ID: <3509.137.111.57.71.1253759653.squirrel@65.99.229.10>

On Thu, September 24, 2009 1:42 am, Paul Johnson wrote:
> Do you have a copy of HLM6 on your system?  Maybe you could help me by
> running the same model in R (with any of the packages such as lme4,
> nlme, or whatever) and HLM6 and let us all know if you get similar
> estimates and how long it takes to run each one.
>

There is a time-limited trial version of HLM
http://www.ssicentral.com/hlm/downloads.html

I haven't tried it, but I expect that I wont like it. I expect it will
have a philosophy that every model is special, rather than providing a
general model specification as in R.

>
> My colleague has HLM6 on Windows XP and he compared a two-level linear
> mixed effects model fitted with lmer from lme4 against HLM6.  He
> surprised my by claiming that the HLM6 model estimation was completed
> in about 1.5 seconds and the lmer estimation took 50 seconds.  That
> did not seem right to me.  I looked a bit at his example and made a
> few mental notes so I could ask you what to look for when I go back to
> dig into this.  There are 27000 cases in his datasets and he has about
> 25 variables at the lower level of observation and 4 or 5 variables at
> the higher level, which I think is the county of survey respondents.
> He is fitting a random intercept (random across counties) and several
> random slopes for the higher level variables.
>
> He pointed out that the mlWin website reported speed differences in
> 2006 that were about the same.  Of course, you and I know that R and
> all of the mixed effects packages have improved significantly since
> then. That is why the speed gap on the one Windows XP system surprised
> me.
>
> Can you tell me if you see a difference between the two programs (if
> you have HLM6).  If you see a difference on the same magnitude, it may
> mean we are not mistaken in our conclusion.  But if you see no
> difference, then it will mean I'm getting it wrong and I should
> investigate more. If I can't solve it, I should provide a reproducible
> example for your inspection.  I will ask permission to release the
> private data to  you in that case.
>
> Perhaps you think there are good reasons why R estimation takes longer.
> E.g.:
> 1. HLM programmers have full access to benefit from optimizations in
> lmer and other open programs, but they don't share their optimizations
> in return.
> 2. lmer and other R routines are making calculations in a better way,
> a more accurate way, so we should not worry that they take longer.

I don't know what HLM use. lme used an EM algorithm which is one of the
slower ways, but with excellent properties, and I assume lmer uses the
same. It may be that Doug has set some of the convergence criteria so that
it will work with very complex models and these could be relaxed at the
users peril.  I would prefer slower.  R can also take a lot of time to do
some things, and the only way around this is to rewrite everything in C or
Fortran.

To me R has the advantage that I can set up a large number of complex
analyses with graphs, and just run the lot. If time became a concern
because it was preventing other use of my computer then I would set up a
linux server and run everything remotely.

>    That was my first guess, in the original mail I said I thought that
> HLM was using PQL whereas lmer is using Laplace or Adaptive Gaussian
> Quadrature.  But Doug's comment indicated that I was mistaken to
> expect a difference there because REML is the default in lmer and it
> is also what HLM is doing, and there's no involvement of quadrature or
> integral approximation in a mixed linear model (gaussian dependent
> variable).
>
> On the other hand, perhaps you are (like me) surprised by this
> difference and you want to help me figure out the cause of the
> differences.  If you have ideas about that, maybe we can work together
> (I don't suck at C!). I have pretty much experience profiling programs
> in C and did some optimization help on a big-ish C++ based R package
> this summer.
>
> So far, I have a simple observer's interest in this question.   I
> advise people whether it is beneficial for them to spend their scarce
> resources on a commercial package like HLM6 and one of the factors
> that is important to them is how "fast" the programs are.   I
> personally don't see an urgent reason to buy HLM because it can
> estimate a model in 1 second and an open source approach requires 50
> seconds.  But I'm not the one making the decision. If I can make the R
> version run almost as fast as HLM6, or provide reasons why people
> might benefit from using a program that takes longer, then I can do my
> job of advising the users.
>
> I am sorry if this question appears impertinent or insulting. I do not
> mean it as a criticism.
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Sep 24 05:44:36 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 23 Sep 2009 22:44:36 -0500
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
In-Reply-To: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
References: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
Message-ID: <40e66e0b0909232044o79435305q2eaa9606b2960a7b@mail.gmail.com>

Thanks for rephrasing your question, Paul.

On Wed, Sep 23, 2009 at 8:42 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> I'm sorry I made Doug mad and I'm sorry to have led the discussion off
> into such a strange, disagreeable place.
>
> Now that I understand your answers, I believe I can ask the question
> in a non-naive way. ?I believe this version should not provoke some of
> the harsh words that I triggered in my awkward question.
>
> New Non-Naive version of the Speed Question
>
> Do you have a copy of HLM6 on your system? ?Maybe you could help me by
> running the same model in R (with any of the packages such as lme4,
> nlme, or whatever) and HLM6 and let us all know if you get similar
> estimates and how long it takes to run each one.

I still claim it would help to have a reproducible example with known
data and a known model to fit.
> Here's why I ask.
>
> My colleague has HLM6 on Windows XP and he compared a two-level linear
> mixed effects model fitted with lmer from lme4 against HLM6. ?He
> surprised my by claiming that the HLM6 model estimation was completed
> in about 1.5 seconds and the lmer estimation took 50 seconds. ?That
> did not seem right to me. ?I looked a bit at his example and made a
> few mental notes so I could ask you what to look for when I go back to
> dig into this. ?There are 27000 cases in his datasets and he has about
> 25 variables at the lower level of observation and 4 or 5 variables at
> the higher level, which I think is the county of survey respondents.
> He is fitting a random intercept (random across counties) and several
> random slopes for the higher level variables.
>
> He pointed out that the mlWin website reported speed differences in
> 2006 that were about the same. ?Of course, you and I know that R and
> all of the mixed effects packages have improved significantly since
> then. That is why the speed gap on the one Windows XP system surprised
> me.
>
> Can you tell me if you see a difference between the two programs (if
> you have HLM6). ?If you see a difference on the same magnitude, it may
> mean we are not mistaken in our conclusion. ?But if you see no
> difference, then it will mean I'm getting it wrong and I should
> investigate more. If I can't solve it, I should provide a reproducible
> example for your inspection. ?I will ask permission to release the
> private data to ?you in that case.
>
> Perhaps you think there are good reasons why R estimation takes longer. ?E.g.:
> 1. HLM programmers have full access to benefit from optimizations in
> lmer and other open programs, but they don't share their optimizations
> in return.
> 2. lmer and other R routines are making calculations in a better way,
> a more accurate way, so we should not worry that they take longer.
> ? That was my first guess, in the original mail I said I thought that
> HLM was using PQL whereas lmer is using Laplace or Adaptive Gaussian
> Quadrature. ?But Doug's comment indicated that I was mistaken to
> expect a difference there because REML is the default in lmer and it
> is also what HLM is doing, and there's no involvement of quadrature or
> integral approximation in a mixed linear model (gaussian dependent
> variable).
>
> On the other hand, perhaps you are (like me) surprised by this
> difference and you want to help me figure out the cause of the
> differences. ?If you have ideas about that, maybe we can work together
> (I don't suck at C!). I have pretty much experience profiling programs
> in C and did some optimization help on a big-ish C++ based R package
> this summer.
>
> So far, I have a simple observer's interest in this question. ? I
> advise people whether it is beneficial for them to spend their scarce
> resources on a commercial package like HLM6 and one of the factors
> that is important to them is how "fast" the programs are. ? I
> personally don't see an urgent reason to buy HLM because it can
> estimate a model in 1 second and an open source approach requires 50
> seconds. ?But I'm not the one making the decision. If I can make the R
> version run almost as fast as HLM6, or provide reasons why people
> might benefit from using a program that takes longer, then I can do my
> job of advising the users.
>
> I am sorry if this question appears impertinent or insulting. I do not
> mean it as a criticism.
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From raldo.kruger at gmail.com  Thu Sep 24 08:05:32 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Thu, 24 Sep 2009 08:05:32 +0200
Subject: [R-sig-ME] Calculating SE from GLMM results (using glmer{lme4})
Message-ID: <30406dd0909232305k3edcecedi396c9bb6e8655833@mail.gmail.com>

Dear R users,

Please excuse the basic questions, but I?m new to GLMMs and R!

I?m analyzing an experiment where Seedling numbers in plots where seed
has been sown on restoration sites is the response variable. I?m most
interested in determining whether the Nutrients (N) and water
absorbing polymer Gel (Ge) additions to the soil substrate contribute
positively to the survival of the seedlings, over a 3 year time period
(for simplicity I'm just using 3 time periods, each in the same season
for the 3
successive years).
Fixed factors: Nutrients (0 and 1), Gel (0 and 1)
Random factors: Site (4 non replicate sites), Year (3 time periods)
Response variable: Seedling numbers (counts) / 0.25m2 plot
The results are as follows:
	         Estimate	Std. Error	z value	 Pr(>|z|)	
(Intercept)	4.52982	0.24486	18.5	       <2.00E-16	***
N	       -0.07922	0.08415	-0.94	       0.346489	
Ge	         0.20766	0.08428	2.46	        0.013744	*
Year  	-1.62937	0.04672	-34.88	<2.00E-16	***
N:Ge 	-0.44213	0.11898	-3.72   	0.000202	***
N:Year	0.11705	0.06322	1.85   	0.064125	.
Ge:Year	-0.04861	0.0645	-0.75  	0.451132	
N:Ge:Year	0.11458	0.08917	1.28  	0.198821	

1)	So as I understand (from previous correspondence with R-users) the
number of seedlings in the control plots in year 0 is
        exp(4.53) = 92.7. Is the standard error calculated with
0.24486 (i.e. 92.7*0.24), or with 92.7*exp(0.24).
2)	And for the N:Ge treatment, the effect is exp(-0.08+0.21-0.44)
=0.73 (I.e. a 27% reduction compared to the control), right? So
        is the SE for the N:Ge effect calculated as the sum of the
SE?s too, i.e. 0.08+0.08+0.12, or is it just 0.12?
3)	Lastly, is it possible to fit two response variables in one GLMM?
E.g. seedling numbers and height.

Many thanks,
Raldo Kr?ger
Msc student
University of Cape Town


-- 
Raldo



From raldo.kruger at gmail.com  Thu Sep 24 08:22:45 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Thu, 24 Sep 2009 08:22:45 +0200
Subject: [R-sig-ME] Data sheet notation and model structure for GLMM with 3
	non-factorial factors
Message-ID: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>

Hi R users,

I have 3 factors in a non-factorial design (G, K and N), as well as
two time periods (Year) and a random factor (Site), with Plant numbers
as the response variable.

My 1st question relates to the the notation of the treatments in the
data frame. Is it appropriate to use an expanded treatment notation,
such as this, when using glmer{lme4}:

Site	Year	Plant	G	K	N
A	1	5	0	0	0
A	1	4	1	0	0
A	1	7	0	1	0
A	1	10	0	0	1
A	2	3	0	0	0
A	2	4	1	0	0
A	2	8	0	1	0
A	2	12	0	0	1
B	1	7	0	0	0
B	1	3	1	0	0
B	1	7	0	1	0
B	1	12	0	0	1
B	2	4	0	0	0
B	2	5	1	0	0
B	2	6	0	1	0
B	2	11	0	0	1

With the model

m1<-glmer(Plant~G+K+N+Year+(1|Site), ...)

Or is it better to use a single column for the treatments, like this:

Site	Year	Plant	Treatment
A	1	5	C
A	1	4	G
A	1	7	K
A	1	10	N
A	2	3	C
A	2	4	G
A	2	8	K
A	2	12	N
B	1	7	C
B	1	3	G
B	1	7	K
B	1	12	N
B	2	4	C
B	2	5	G
B	2	6	K
B	2	11	N

With the following model:
m1<-glmer(Plants~Treatment+Year+(1|Site), ...)

Many thanks,
-- 
Raldo Kruger
MSc student
University of Cape Town



From kagba2006 at yahoo.com  Thu Sep 24 12:28:34 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 24 Sep 2009 03:28:34 -0700 (PDT)
Subject: [R-sig-ME] standar error for the fixed effects
Message-ID: <947443.86505.qm@web38303.mail.mud.yahoo.com>

Dear All,

Herewith, is a sample?of?mixed model command from the help menu.
?
fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
fm1
?
I noticed that there is no standard error for the fixed effects. Could someone advice me the way to extract it?
?
Thank you
Fir






From ken at kjbeath.com.au  Thu Sep 24 12:52:31 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 24 Sep 2009 20:52:31 +1000
Subject: [R-sig-ME] standar error for the fixed effects
In-Reply-To: <947443.86505.qm@web38303.mail.mud.yahoo.com>
References: <947443.86505.qm@web38303.mail.mud.yahoo.com>
Message-ID: <B43B4F31-A96F-40D3-B5BC-70FCCAB7D493@kjbeath.com.au>

summary(fm1)

Obtaining a copy of Pinheiro and Bates is strongly recommended.

Ken

On 24/09/2009, at 8:28 PM, FMH wrote:

> Dear All,
>
> Herewith, is a sample of mixed model command from the help menu.
>
> fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
> fm1
>
> I noticed that there is no standard error for the fixed effects.  
> Could someone advice me the way to extract it?
>
> Thank you
> Fir
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kagba2006 at yahoo.com  Thu Sep 24 13:27:32 2009
From: kagba2006 at yahoo.com (FMH)
Date: Thu, 24 Sep 2009 04:27:32 -0700 (PDT)
Subject: [R-sig-ME] standar error for the fixed effects
In-Reply-To: <B43B4F31-A96F-40D3-B5BC-70FCCAB7D493@kjbeath.com.au>
References: <947443.86505.qm@web38303.mail.mud.yahoo.com>
	<B43B4F31-A96F-40D3-B5BC-70FCCAB7D493@kjbeath.com.au>
Message-ID: <398848.34503.qm@web38304.mail.mud.yahoo.com>

Thank you for the hint. I've even tried it but it?did not?give any standard error for the fixed effects.



----- Original Message ----
From: Ken Beath <ken at kjbeath.com.au>
To: FMH <kagba2006 at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Thursday, September 24, 2009 11:52:31 AM
Subject: Re: [R-sig-ME] standar error for the fixed effects

summary(fm1)

Obtaining a copy of Pinheiro and Bates is strongly recommended.

Ken

On 24/09/2009, at 8:28 PM, FMH wrote:

> Dear All,
>
> Herewith, is a sample of mixed model command from the help menu.
>
> fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
> fm1
>
> I noticed that there is no standard error for the fixed effects.? 
> Could someone advice me the way to extract it?
>
> Thank you
> Fir
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>






From ken at kjbeath.com.au  Thu Sep 24 13:43:52 2009
From: ken at kjbeath.com.au (Ken Beath)
Date: Thu, 24 Sep 2009 21:43:52 +1000
Subject: [R-sig-ME] standar error for the fixed effects
In-Reply-To: <398848.34503.qm@web38304.mail.mud.yahoo.com>
References: <947443.86505.qm@web38303.mail.mud.yahoo.com>
	<B43B4F31-A96F-40D3-B5BC-70FCCAB7D493@kjbeath.com.au>
	<398848.34503.qm@web38304.mail.mud.yahoo.com>
Message-ID: <548EAD97-E7A0-44E7-9EE5-8D1759C440A8@kjbeath.com.au>

On 24/09/2009, at 9:27 PM, FMH wrote:

> Thank you for the hint. I've even tried it but it did not give any  
> standard error for the fixed effects.
>

I'm not certain what you mean. They are clearly there after Value.

Ken

 > summary(fm1)
Linear mixed-effects model fit by REML
  Data: Orthodont
        AIC      BIC    logLik
   454.6367 470.6173 -221.3183

Random effects:
  Formula: ~age | Subject
  Structure: General positive-definite
             StdDev    Corr
(Intercept) 2.3270338 (Intr)
age         0.2264276 -0.609
Residual    1.3100399

Fixed effects: distance ~ age
                 Value Std.Error DF   t-value p-value
(Intercept) 16.761111 0.7752461 80 21.620375       0
age          0.660185 0.0712533 80  9.265334       0
  Correlation:
     (Intr)
age -0.848

Standardized Within-Group Residuals:
          Min           Q1          Med           Q3          Max
-3.223106065 -0.493760858  0.007316633  0.472151095  3.916032722

Number of Observations: 108
Number of Groups: 27
 >


>
> ----- Original Message ----
> From: Ken Beath <ken at kjbeath.com.au>
> To: FMH <kagba2006 at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Thursday, September 24, 2009 11:52:31 AM
> Subject: Re: [R-sig-ME] standar error for the fixed effects
>
> summary(fm1)
>
> Obtaining a copy of Pinheiro and Bates is strongly recommended.
>
> Ken
>
> On 24/09/2009, at 8:28 PM, FMH wrote:
>
>> Dear All,
>>
>> Herewith, is a sample of mixed model command from the help menu.
>>
>> fm1 <- lme(distance ~ age, data = Orthodont) # random is ~ age
>> fm1
>>
>> I noticed that there is no standard error for the fixed effects.
>> Could someone advice me the way to extract it?
>>
>> Thank you
>> Fir
>>
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
>



From bates at stat.wisc.edu  Thu Sep 24 14:10:44 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Sep 2009 07:10:44 -0500
Subject: [R-sig-ME] Data sheet notation and model structure for GLMM
	with 3 non-factorial factors
In-Reply-To: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>
References: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>
Message-ID: <40e66e0b0909240510l6cffc62chea7ea49f7be0c26f@mail.gmail.com>

On Thu, Sep 24, 2009 at 1:22 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Hi R users,
>
> I have 3 factors in a non-factorial design (G, K and N), as well as
> two time periods (Year) and a random factor (Site), with Plant numbers
> as the response variable.
>
> My 1st question relates to the the notation of the treatments in the
> data frame. Is it appropriate to use an expanded treatment notation,
> such as this, when using glmer{lme4}:
>
> Site ? ?Year ? ?Plant ? G ? ? ? K ? ? ? N
> A ? ? ? 1 ? ? ? 5 ? ? ? 0 ? ? ? 0 ? ? ? 0
> A ? ? ? 1 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
> A ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
> A ? ? ? 1 ? ? ? 10 ? ? ?0 ? ? ? 0 ? ? ? 1
> A ? ? ? 2 ? ? ? 3 ? ? ? 0 ? ? ? 0 ? ? ? 0
> A ? ? ? 2 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
> A ? ? ? 2 ? ? ? 8 ? ? ? 0 ? ? ? 1 ? ? ? 0
> A ? ? ? 2 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 0 ? ? ? 0
> B ? ? ? 1 ? ? ? 3 ? ? ? 1 ? ? ? 0 ? ? ? 0
> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
> B ? ? ? 1 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
> B ? ? ? 2 ? ? ? 4 ? ? ? 0 ? ? ? 0 ? ? ? 0
> B ? ? ? 2 ? ? ? 5 ? ? ? 1 ? ? ? 0 ? ? ? 0
> B ? ? ? 2 ? ? ? 6 ? ? ? 0 ? ? ? 1 ? ? ? 0
> B ? ? ? 2 ? ? ? 11 ? ? ?0 ? ? ? 0 ? ? ? 1
>
> With the model
>
> m1<-glmer(Plant~G+K+N+Year+(1|Site), ...)
>
> Or is it better to use a single column for the treatments, like this:
>
> Site ? ?Year ? ?Plant ? Treatment
> A ? ? ? 1 ? ? ? 5 ? ? ? C
> A ? ? ? 1 ? ? ? 4 ? ? ? G
> A ? ? ? 1 ? ? ? 7 ? ? ? K
> A ? ? ? 1 ? ? ? 10 ? ? ?N
> A ? ? ? 2 ? ? ? 3 ? ? ? C
> A ? ? ? 2 ? ? ? 4 ? ? ? G
> A ? ? ? 2 ? ? ? 8 ? ? ? K
> A ? ? ? 2 ? ? ? 12 ? ? ?N
> B ? ? ? 1 ? ? ? 7 ? ? ? C
> B ? ? ? 1 ? ? ? 3 ? ? ? G
> B ? ? ? 1 ? ? ? 7 ? ? ? K
> B ? ? ? 1 ? ? ? 12 ? ? ?N
> B ? ? ? 2 ? ? ? 4 ? ? ? C
> B ? ? ? 2 ? ? ? 5 ? ? ? G
> B ? ? ? 2 ? ? ? 6 ? ? ? K
> B ? ? ? 2 ? ? ? 11 ? ? ?N
>
> With the following model:
> m1<-glmer(Plants~Treatment+Year+(1|Site), ...)

The latter is preferred.  R will generate the indicator columns for
the levels of the Treatment factor (the 0/1 columns shown in the first
form) and, when appropriate, reduce them to a set of 2 "contrasts" in
the model.  (The reason for quoting the word "contrasts" is that there
is a formal mathematical definition of a contrast but the linear
combinations generated by R do not always satisfy this definition.
The method and results are correct, it is just the name that is
inaccurate.)

The reason that the latter is preferred is that it is easier to
maintain the data in a consistent form (factors maintain consistency
and are easy to check in the output from str() or summary(), whereas
indicator columns have inter-column dependencies that must be checked
separately) and the "when appropriate" clause above.  Determining a
useful parameterization of a linear model incorporating factors is
subtle and a lot of code in the R function model.matrix is devoted to
a symbolic analysis designed to get this right.  Also, you can, if you
wish, change the parameterization (see ?contrasts).



From bolker at ufl.edu  Thu Sep 24 15:21:15 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 24 Sep 2009 09:21:15 -0400
Subject: [R-sig-ME] Calculating SE from GLMM results (using glmer{lme4})
In-Reply-To: <30406dd0909232305k3edcecedi396c9bb6e8655833@mail.gmail.com>
References: <30406dd0909232305k3edcecedi396c9bb6e8655833@mail.gmail.com>
Message-ID: <4ABB724B.3080804@ufl.edu>

Raldo Kruger wrote:
> Dear R users,
> 
> Please excuse the basic questions, but I?m new to GLMMs and R!
> 
> I?m analyzing an experiment where Seedling numbers in plots where seed
> has been sown on restoration sites is the response variable. I?m most
> interested in determining whether the Nutrients (N) and water
> absorbing polymer Gel (Ge) additions to the soil substrate contribute
> positively to the survival of the seedlings, over a 3 year time period
> (for simplicity I'm just using 3 time periods, each in the same season
> for the 3
> successive years).
> Fixed factors: Nutrients (0 and 1), Gel (0 and 1)
> Random factors: Site (4 non replicate sites), Year (3 time periods)
> Response variable: Seedling numbers (counts) / 0.25m2 plot
> The results are as follows:
> 	         Estimate	Std. Error	z value	 Pr(>|z|)	
> (Intercept)	4.52982	0.24486	18.5	       <2.00E-16	***
> N	       -0.07922	0.08415	-0.94	       0.346489	
> Ge	         0.20766	0.08428	2.46	        0.013744	*
> Year  	-1.62937	0.04672	-34.88	<2.00E-16	***
> N:Ge 	-0.44213	0.11898	-3.72   	0.000202	***
> N:Year	0.11705	0.06322	1.85   	0.064125	.
> Ge:Year	-0.04861	0.0645	-0.75  	0.451132	
> N:Ge:Year	0.11458	0.08917	1.28  	0.198821	
> 

 Some comments:

*  It looks like you fitted year as a fixed effect rather than a random
effect (probably sensible, since you only have 3 levels / years), and
incorporated all fixed effect interactions (i.e. N*Ge*Year) ?  However,
it also looks like you fitted year as a continuous covariate, which
means that R is trying to fit a linear function of time -- is that
really what you want?  There's a very large negative year effect -- if
your year values are coded 1-3, then it suggests you have very few
seedlings left in year 3?

 It's also
worth considering whether you are really getting reliable answers based
on only 4 sites -- I would also try this with Site as a fixed effect
and see whether the answers differ considerably.  (I know that,
philosophically, Site and Year are both random effects, and you may
run into trouble with reviewers who are used to classical ANOVA
> 1)	So as I understand (from previous correspondence with R-users) the
> number of seedlings in the control plots in year 0 is
>         exp(4.53) = 92.7. Is the standard error calculated with
> 0.24486 (i.e. 92.7*0.24), or with 92.7*exp(0.24).

  The latter.
  So for example the approximate confidence intervals would be
exp(0.453 +/- 2*0.245)

> 2)	And for the N:Ge treatment, the effect is exp(-0.08+0.21-0.44)
> =0.73 (I.e. a 27% reduction compared to the control), right? So
>         is the SE for the N:Ge effect calculated as the sum of the
> SE?s too, i.e. 0.08+0.08+0.12, or is it just 0.12?

  The SE for combined effects is calculated as sqrt(se1^2 + se2^2 + se3^2)

> 3)	Lastly, is it possible to fit two response variables in one GLMM?
> E.g. seedling numbers and height.

  This would be hard -- you're talking about a multivariate response
with different measurement scales/error distributions for different
variables ...
> 
> Many thanks,
> Raldo Kr?ger
> Msc student
> University of Cape Town
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From HDoran at air.org  Thu Sep 24 18:29:59 2009
From: HDoran at air.org (Doran, Harold)
Date: Thu, 24 Sep 2009 12:29:59 -0400
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
In-Reply-To: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE0202D93C@DC1EXCL01.air.org>

> I'm sorry I made Doug mad and I'm sorry to have led the 
> discussion off into such a strange, disagreeable place.

I don't think you did. He invests a lot in the lmer function and matrix
pakage (with Martin) and likes to see it represented properly.

> Now that I understand your answers, I believe I can ask the 
> question in a non-naive way.  I believe this version should 
> not provoke some of the harsh words that I triggered in my 
> awkward question.
> 
> New Non-Naive version of the Speed Question
> 
> Do you have a copy of HLM6 on your system?  Maybe you could 
> help me by running the same model in R (with any of the 
> packages such as lme4, nlme, or whatever) and HLM6 and let us 
> all know if you get similar estimates and how long it takes 
> to run each one.

Yes, I do, and I have. But, I *think* you can only look at a wall clock
for HLM timings. Below is an example of a model that you can run in both
packages. Takes HLM a bit longer (by looking at a wall clock) on my
machine to run this same model. These data come freely with HLM called
EG1, EG2, and EG3

library(mlmRev)
> system.time(fm1 <- lmer(math ~ year + retained + black + hispanic +
size + lowinc + mobility +(year|schoolid) + (year|childid), egsingle))
   user  system elapsed 
   7.75    0.17    7.92 

> 
> Here's why I ask.
> 
> My colleague has HLM6 on Windows XP and he compared a 
> two-level linear mixed effects model fitted with lmer from 
> lme4 against HLM6.  He surprised my by claiming that the HLM6 
> model estimation was completed in about 1.5 seconds and the 
> lmer estimation took 50 seconds.  That did not seem right to 
> me.  I looked a bit at his example and made a few mental 
> notes so I could ask you what to look for when I go back to 
> dig into this.  There are 27000 cases in his datasets and he has about
> 25 variables at the lower level of observation and 4 or 5 
> variables at the higher level, which I think is the county of 
> survey respondents.
> He is fitting a random intercept (random across counties) and 
> several random slopes for the higher level variables.

Like I said yesterday, examples like this aren't too interesting. I
don't really care if one software can do something in 1.5 seconds
whereas another takes 50 seconds. Plus, this is a very simple model with
a nested design. There are many, many sofwtare programs for these kinds
of models. I think differences such as those are petty. What *is*
interesting is when the models become so complex, like those with many
levels of the random effects and complex covariance structures. At that
point you will find that HLM cannot even estimate those models. Doug and
I have recently estimated very large models where the dimensions of the
model matrix for the random effects was huge and run time was on the
order of a few hours. Now, take a model with crossed random effects for,
say 1 million students each of whom has three observations. Now, try and
run that model with random effects for students and their teachers in
each of those years in HLM and see what happens. 
> 
> He pointed out that the mlWin website reported speed differences in
> 2006 that were about the same.  Of course, you and I know 
> that R and all of the mixed effects packages have improved 
> significantly since then. That is why the speed gap on the 
> one Windows XP system surprised me.
> 
> Can you tell me if you see a difference between the two 
> programs (if you have HLM6).  If you see a difference on the 
> same magnitude, it may mean we are not mistaken in our 
> conclusion.  But if you see no difference, then it will mean 
> I'm getting it wrong and I should investigate more. If I 
> can't solve it, I should provide a reproducible example for 
> your inspection.  I will ask permission to release the 
> private data to  you in that case.

See above for the example. But, despite my better judgement, I gave the
example anyhow. I don't see differences in the order of a minute or so
interesting at all. The more meaningful differences are found when the
models become complex.

> 
> Perhaps you think there are good reasons why R estimation 
> takes longer.  E.g.:

But I don't think it does.

> 1. HLM programmers have full access to benefit from 
> optimizations in lmer and other open programs, but they don't 
> share their optimizations in return.

I believe Richard Congden and Steve Raudenbush to be very virtuous and
have published quite a bit on this topic. There may be some
computational details that remain unknown, but they have been very
transparent in their work.

> 2. lmer and other R routines are making calculations in a 
> better way, a more accurate way, so we should not worry that 
> they take longer.

While I am a big user of the lmer functions, I don't necessarily believe
this is accurate. Doug has taken great care to ensure lmer returns
reliable estimates. But, so have the HLM crew. I have routinely found
that HLM and lmer give the same estimates for models with nested random
effects. Since HLM cannot estimate large models with crossed random
effects, I cannot form any comparison. 

>    That was my first guess, in the original mail I said I 
> thought that HLM was using PQL whereas lmer is using Laplace 
> or Adaptive Gaussian Quadrature.  But Doug's comment 
> indicated that I was mistaken to expect a difference there 
> because REML is the default in lmer and it is also what HLM 
> is doing, and there's no involvement of quadrature or 
> integral approximation in a mixed linear model (gaussian 
> dependent variable).

I think you remain a little confused here. For generalized linear mixed
models, R and HLM have different ways for evaluating the
integral--although I have found that, with nested designs, both yield
results comparable out to multiple decimal points. But, with linear
mixed models that is not an issue. With linear mixed models, REML is the
default in both HLM and R. But, the HLM folks view the world as a GLS
problem and Doug views this as a PLS problem. 

> 
> On the other hand, perhaps you are (like me) surprised by 
> this difference and you want to help me figure out the cause 
> of the differences.  If you have ideas about that, maybe we 
> can work together (I don't suck at C!). I have pretty much 
> experience profiling programs in C and did some optimization 
> help on a big-ish C++ based R package this summer.
> 
> So far, I have a simple observer's interest in this question.   I
> advise people whether it is beneficial for them to spend 
> their scarce resources on a commercial package like HLM6 and 
> one of the factors
> that is important to them is how "fast" the programs are.   I
> personally don't see an urgent reason to buy HLM because it 
> can estimate a model in 1 second and an open source approach 
> requires 50 seconds.  But I'm not the one making the 
> decision. If I can make the R version run almost as fast as 
> HLM6, or provide reasons why people might benefit from using 
> a program that takes longer, then I can do my job of advising 
> the users.

Yes, "fast" is important when it comes to big problems. But, there are
many other issues to consider as well, and I would place those far above
the "fast" issue. For instance, what if you want to create an
interaction term in HLM? You must first, work with a stat package to
manually create the interaction variable, import those data into HLM and
then run the model. So, it takes two software programs to get the job
done. What if you want presentation-style visual displays of your data?
What if you want (close to) on-demand support from real statisticians on
your problem? 

Last, and IMHO the biggest factor, what if you want to modify the code
in some way to customize your analysis? I suppose all of this is to say
look beyond the fast issue for simple problems in your evaluation
criteria. I would suggest that you consider what your world would look
like if you needed any of the info I discuss in the preceding paragraph.

Just my .02 cents.



> 
> I am sorry if this question appears impertinent or insulting. 
> I do not mean it as a criticism.
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bates at stat.wisc.edu  Thu Sep 24 23:56:59 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Sep 2009 16:56:59 -0500
Subject: [R-sig-ME] Examples for speed comparisons in fitting linear
	mixed-effects models
Message-ID: <40e66e0b0909241456w3c8d97d7yb124c88814a4a95c@mail.gmail.com>

In some ways this is responding to the messages from Paul, Kevin,
Harold and others but it involves enough new material that I will
start a new thread.

I would very much appreciate examples of data sets and corresponding
models that can be used to assess the speed and reliability of fitting
linear mixed-effects models.  As both Harold and I mentioned in the
other thread it is difficult to get a meaningful timing on a model fit
when it only takes a few seconds.  I enclose output (star1_Rout.txt)
from fitting a model to the star data.  You will see that I timed the
fitting several times with results between 10.3 seconds and 4.3
seconds.  Some of the variability is due to garbage collection and the
amount of memory that is currently allocated but not in use.  That is
why later timings tend to be faster.  But there are many other sources
of variability in addition to memory allocation.

Besides the difficulty in reproducing fast timings, there is also the
"so what" factor.  I really don't care whether the model is fit in 5
seconds or in 10 seconds.

But notice that this is a model with 3 partially crossed (i.e.
non-nested) levels of random effects for a total of about 11000 random
effects, 25000 observations and 12 fixed-effects parameters.  That
used to be considered big and difficult but it isn't any more.  The
second set of timings (star2_Rout.txt) are from an experimental
version of lme4 (called lme4a for the time being) and two functions,
lmer and lmer2.  (The lmer2 name is going to change so don't pay too
much attention to it now.)  The lmer2 function produces an environment
with certain extractor functions, one of which, setPars, sets new
values of the parameters and causes re-evaluation of the deviance or
the REML criterion.  By default it also optimizes the criterion using
the nlminb optimizer.  Kate Mullen and others have an R-forge project
on optimization including a package called minqa that provides an
optimizer bobyqa (love those Fortran, 6-character names) which
outperforms nlminb on my examples.  One advantage of the lmer2
structure is that the optimization can be separated from the model
specification so you can switch optimizers.  With the bobyqa optimizer
and the lmer2 formulation this model can be fit in under 2 seconds.

I do have timings on a much larger and more difficult model fit but
the data are confidential.  This is a model with four, non-nested
levels of random effects (in this case student, school, district and
area) and 40 fixed-effects parameters in total.  The overall
dimensions are
> print(fm1, corr = FALSE)
Linear mixed model fit by REML
Formula: Rss ~ Yr * fgr + Sx * Ra + Dis + ELP + EC + (1 | id) + (1 |
   sch) + (1 | dist) + (1 | area)
   Data: dat
    REML
16917518

Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 1357.394 36.8428
 sch      (Intercept)   64.341  8.0213
 dist     (Intercept)   22.408  4.7337
 area     (Intercept)    6.220  2.4940
 Residual              498.701 22.3316
Number of obs: 1714674, groups: id, 735604; sch, 2409; dist, 445; area, 12

In this case it takes about a minute to set up the model structures
and each evaluation of the REML criterion takes about 8 seconds.
Again, bobyqa does much better than nlminb, about 1600 seconds
compared to 2500 seconds and both are much faster than the currently
released lme4.

I can't release these data.  I don't even want to post estimates of
the fixed-effects parameters.  I could, for the purposes of timing,
generate a dummy data set from model structure and parameter estimates
but I would prefer not to do that.  Also, I want to be able to test
the new formulation of lmer on real models fit to real data by real
useRs.

So if you have data to which you want to fit linear mixed-effects
models and they seem to be taking a long time then please send me your
data and model specification.  If the model could be fit by HLM6 or
MLWin or SAS PROC MIXED or Stata (I'm reasonably sure that even the
small example could not because of the partially crossed random
effects but I would be happy to hear otherwise) then we could compare
but right now I am mostly interested in the lme4a package methods and
the choice of optimizers bobyqa or nlminb.
-------------- next part --------------

R version 2.9.1 (2009-06-26)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 contr.SAS,
	 contr.helmert,
	 contr.poly,
	 contr.sum,
	 contr.treatment,
	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

> data(star, package = "mlmRev")
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
 10.303   0.050  10.824 
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  7.752   0.056   8.369 
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  4.311   0.005   4.777 
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  4.895   0.001   5.036 
> print(fm1, corr = FALSE)
Linear mixed model fit by REML 
Formula: math ~ gr + cltype + sx + eth + (1 | id) + (1 | tch) + (1 | sch) 
   Data: star 
    AIC    BIC  logLik deviance REMLdev
 239236 239365 -119602   239245  239204
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 1001.59  31.648  
 tch      (Intercept)  295.04  17.177  
 sch      (Intercept)  104.76  10.235  
 Residual              397.32  19.933  
Number of obs: 24578, groups: id, 10732; tch, 1374; sch, 80

Fixed effects:
            Estimate Std. Error t value
(Intercept) 560.8869     1.5742   356.3
gr.L         95.6128     1.0080    94.9
gr.Q         -4.6783     0.9858    -4.7
gr.C         -3.2320     0.9729    -3.3
cltypereg    -7.7943     1.3322    -5.9
cltypereg+A  -7.0055     1.3265    -5.3
sxF           2.8766     0.6836     4.2
ethB        -21.9199     1.2218   -17.9
ethA          3.1941     6.7036     0.5
ethH          4.5410     9.6650     0.5
ethI        -28.1621    13.5356    -2.1
ethO          3.4358     8.3131     0.4
> 
> 
> proc.time()
   user  system elapsed 
 45.579   0.322  48.042 
-------------- next part --------------

R version 2.9.1 (2009-06-26)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 contr.SAS,
	 contr.helmert,
	 contr.poly,
	 contr.sum,
	 contr.treatment,
	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

> sessionInfo()
R version 2.9.1 (2009-06-26) 
x86_64-unknown-linux-gnu 

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4a_0.999375-42  Matrix_0.999375-31 lattice_0.17-25   

loaded via a namespace (and not attached):
[1] grid_2.9.1
> data(star, package = "mlmRev")
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
 14.076   0.070  14.960 
Warning message:
In merFinalize(rho) : false convergence (8)
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  7.897   0.018   8.297 
Warning message:
In merFinalize(rho) : false convergence (8)
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  7.852   0.001   8.443 
Warning message:
In merFinalize(rho) : false convergence (8)
> system.time(fm1 <- lmer(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  8.619   0.007   9.208 
Warning message:
In merFinalize(rho) : false convergence (8)
> system.time(fm1 <- lmer2(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  2.555   0.002   2.565 
> system.time(fm1 <- lmer2(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  2.166   0.001   2.308 
> system.time(fm1 <- lmer2(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  2.207   0.001   2.224 
> system.time(fm1 <- lmer2(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star))
   user  system elapsed 
  2.936   0.000   2.960 
> print(fm1, corr = FALSE)
Linear mixed model fit by REML 
Formula: math ~ gr + cltype + sx + eth + (1 | id) + (1 | tch) + (1 | sch) 
   Data: star 
  REML 
239204 

Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 1001.60  31.648  
 tch      (Intercept)  295.04  17.177  
 sch      (Intercept)  104.76  10.235  
 Residual              397.31  19.933  
Number of obs: 24578, groups: id, 10732; tch, 1374; sch, 80

Fixed effects:
            Estimate Std. Error t value
(Intercept) 560.8868     1.5747   356.2
gr.L         95.6126     1.0080    94.9
gr.Q         -4.6782     0.9858    -4.7
gr.C         -3.2320     0.9729    -3.3
cltypereg    -7.7945     1.3322    -5.9
cltypereg+A  -7.0056     1.3265    -5.3
sxF           2.8766     0.6836     4.2
ethB        -21.9196     1.2219   -17.9
ethA          3.1940     6.7036     0.5
ethH          4.5413     9.6650     0.5
ethI        -28.1612    13.5356    -2.1
ethO          3.4357     8.3131     0.4
> ## time the setup phase only
> system.time(fm1 <- lmer2(math ~ gr + cltype + sx + eth + (1|id) + (1|tch) + (1|sch), star, doFit = FALSE))
   user  system elapsed 
  0.398   0.000   0.398 
> ## time the optimization using nlminb
> system.time(nlminb(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(trace = 1)))
  0:     240730.91:  1.00000  1.00000  1.00000
  1:     239648.32:  1.98282 0.816539 0.979744
  2:     239342.22:  1.75919  1.02726 0.914733
  3:     239259.59:  1.49223 0.865024 0.882315
  4:     239230.77:  1.65620 0.811277 0.619893
  5:     239225.00:  1.58040 0.894458 0.326679
  6:     239216.42:  1.55704 0.901629 0.639797
  7:     239207.82:  1.59249 0.869466 0.630141
  8:     239206.23:  1.58324 0.844715 0.589082
  9:     239204.54:  1.59280 0.873056 0.550491
 10:     239204.24:  1.59525 0.852259 0.506384
 11:     239203.77:  1.58797 0.859716 0.507220
 12:     239203.75:  1.58832 0.862046 0.517409
 13:     239203.74:  1.58797 0.862118 0.513037
 14:     239203.74:  1.58772 0.861717 0.513120
 15:     239203.74:  1.58773 0.861747 0.513507
 16:     239203.74:  1.58774 0.861740 0.513496
   user  system elapsed 
  2.400   0.001   2.582 
> system.time(nlminb(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(trace = 1)))
  0:     240730.91:  1.00000  1.00000  1.00000
  1:     239648.32:  1.98282 0.816539 0.979744
  2:     239342.22:  1.75919  1.02726 0.914733
  3:     239259.59:  1.49223 0.865024 0.882315
  4:     239230.77:  1.65620 0.811277 0.619893
  5:     239225.00:  1.58040 0.894458 0.326679
  6:     239216.42:  1.55704 0.901629 0.639797
  7:     239207.82:  1.59249 0.869466 0.630141
  8:     239206.23:  1.58324 0.844715 0.589082
  9:     239204.54:  1.59280 0.873056 0.550491
 10:     239204.24:  1.59525 0.852259 0.506384
 11:     239203.77:  1.58797 0.859716 0.507220
 12:     239203.75:  1.58832 0.862046 0.517409
 13:     239203.74:  1.58797 0.862118 0.513037
 14:     239203.74:  1.58772 0.861717 0.513120
 15:     239203.74:  1.58773 0.861747 0.513507
 16:     239203.74:  1.58774 0.861740 0.513496
   user  system elapsed 
  1.947   0.002   2.108 
> system.time(nlminb(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(trace = 1)))
  0:     240730.91:  1.00000  1.00000  1.00000
  1:     239648.32:  1.98282 0.816539 0.979744
  2:     239342.22:  1.75919  1.02726 0.914733
  3:     239259.59:  1.49223 0.865024 0.882315
  4:     239230.77:  1.65620 0.811277 0.619893
  5:     239225.00:  1.58040 0.894458 0.326679
  6:     239216.42:  1.55704 0.901629 0.639797
  7:     239207.82:  1.59249 0.869466 0.630141
  8:     239206.23:  1.58324 0.844715 0.589082
  9:     239204.54:  1.59280 0.873056 0.550491
 10:     239204.24:  1.59525 0.852259 0.506384
 11:     239203.77:  1.58797 0.859716 0.507220
 12:     239203.75:  1.58832 0.862046 0.517409
 13:     239203.74:  1.58797 0.862118 0.513037
 14:     239203.74:  1.58772 0.861717 0.513120
 15:     239203.74:  1.58773 0.861747 0.513507
 16:     239203.74:  1.58774 0.861740 0.513496
   user  system elapsed 
  2.015   0.000   2.016 
> system.time(nlminb(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(trace = 1)))
  0:     240730.91:  1.00000  1.00000  1.00000
  1:     239648.32:  1.98282 0.816539 0.979744
  2:     239342.22:  1.75919  1.02726 0.914733
  3:     239259.59:  1.49223 0.865024 0.882315
  4:     239230.77:  1.65620 0.811277 0.619893
  5:     239225.00:  1.58040 0.894458 0.326679
  6:     239216.42:  1.55704 0.901629 0.639797
  7:     239207.82:  1.59249 0.869466 0.630141
  8:     239206.23:  1.58324 0.844715 0.589082
  9:     239204.54:  1.59280 0.873056 0.550491
 10:     239204.24:  1.59525 0.852259 0.506384
 11:     239203.77:  1.58797 0.859716 0.507220
 12:     239203.75:  1.58832 0.862046 0.517409
 13:     239203.74:  1.58797 0.862118 0.513037
 14:     239203.74:  1.58772 0.861717 0.513120
 15:     239203.74:  1.58773 0.861747 0.513507
 16:     239203.74:  1.58774 0.861740 0.513496
   user  system elapsed 
  1.896   0.000   1.897 
> ## time the optimization using bobyqa
> library(minqa)
> system.time(bobyqa(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(iprint = 2)))
   user  system elapsed 
  1.674   0.000   1.795 
> system.time(bobyqa(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(iprint = 2)))
   user  system elapsed 
  1.577   0.000   1.578 
> system.time(bobyqa(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(iprint = 2)))
   user  system elapsed 
  1.488   0.000   1.488 
> system.time(bobyqa(c(1,1,1), fm1 at setPars, lower = c(0,0,0), control = list(iprint = 2)))
   user  system elapsed 
  1.490   0.000   1.602 
> 
> 
> 
> proc.time()
   user  system elapsed 
 82.897   0.339  87.485 

    New RHO = 1.0000D-01     Number of function values =     6
    Least value of F =  2.396525830667515D+05         The corresponding X is:
     2.000000D+00   1.000000D+00   1.000000D+00

    New RHO = 1.0000D-02     Number of function values =    16
    Least value of F =  2.392271194838589D+05         The corresponding X is:
     1.530990D+00   9.271466D-01   5.263914D-01

    New RHO = 1.0000D-03     Number of function values =    22
    Least value of F =  2.392039829385394D+05         The corresponding X is:
     1.586325D+00   8.555261D-01   5.344145D-01

    New RHO = 1.0000D-04     Number of function values =    38
    Least value of F =  2.392037396723067D+05         The corresponding X is:
     1.587629D+00   8.618595D-01   5.139103D-01

    New RHO = 1.0000D-05     Number of function values =    45
    Least value of F =  2.392037395221720D+05         The corresponding X is:
     1.587714D+00   8.617400D-01   5.134964D-01

    New RHO = 1.0000D-06     Number of function values =    51
    Least value of F =  2.392037395205490D+05         The corresponding X is:
     1.587737D+00   8.617412D-01   5.135009D-01

    At the return from BOBYQA     Number of function values =    58
    Least value of F =  2.392037395205379D+05         The corresponding X is:
     1.587738D+00   8.617422D-01   5.134982D-01

    New RHO = 1.0000D-01     Number of function values =     6
    Least value of F =  2.396525830667515D+05         The corresponding X is:
     2.000000D+00   1.000000D+00   1.000000D+00

    New RHO = 1.0000D-02     Number of function values =    16
    Least value of F =  2.392271194838589D+05         The corresponding X is:
     1.530990D+00   9.271466D-01   5.263914D-01

    New RHO = 1.0000D-03     Number of function values =    22
    Least value of F =  2.392039829385394D+05         The corresponding X is:
     1.586325D+00   8.555261D-01   5.344145D-01

    New RHO = 1.0000D-04     Number of function values =    38
    Least value of F =  2.392037396723067D+05         The corresponding X is:
     1.587629D+00   8.618595D-01   5.139103D-01

    New RHO = 1.0000D-05     Number of function values =    45
    Least value of F =  2.392037395221720D+05         The corresponding X is:
     1.587714D+00   8.617400D-01   5.134964D-01

    New RHO = 1.0000D-06     Number of function values =    51
    Least value of F =  2.392037395205490D+05         The corresponding X is:
     1.587737D+00   8.617412D-01   5.135009D-01

    At the return from BOBYQA     Number of function values =    58
    Least value of F =  2.392037395205379D+05         The corresponding X is:
     1.587738D+00   8.617422D-01   5.134982D-01

    New RHO = 1.0000D-01     Number of function values =     6
    Least value of F =  2.396525830667515D+05         The corresponding X is:
     2.000000D+00   1.000000D+00   1.000000D+00

    New RHO = 1.0000D-02     Number of function values =    16
    Least value of F =  2.392271194838589D+05         The corresponding X is:
     1.530990D+00   9.271466D-01   5.263914D-01

    New RHO = 1.0000D-03     Number of function values =    22
    Least value of F =  2.392039829385394D+05         The corresponding X is:
     1.586325D+00   8.555261D-01   5.344145D-01

    New RHO = 1.0000D-04     Number of function values =    38
    Least value of F =  2.392037396723067D+05         The corresponding X is:
     1.587629D+00   8.618595D-01   5.139103D-01

    New RHO = 1.0000D-05     Number of function values =    45
    Least value of F =  2.392037395221720D+05         The corresponding X is:
     1.587714D+00   8.617400D-01   5.134964D-01

    New RHO = 1.0000D-06     Number of function values =    51
    Least value of F =  2.392037395205490D+05         The corresponding X is:
     1.587737D+00   8.617412D-01   5.135009D-01

    At the return from BOBYQA     Number of function values =    58
    Least value of F =  2.392037395205379D+05         The corresponding X is:
     1.587738D+00   8.617422D-01   5.134982D-01

    New RHO = 1.0000D-01     Number of function values =     6
    Least value of F =  2.396525830667515D+05         The corresponding X is:
     2.000000D+00   1.000000D+00   1.000000D+00

    New RHO = 1.0000D-02     Number of function values =    16
    Least value of F =  2.392271194838589D+05         The corresponding X is:
     1.530990D+00   9.271466D-01   5.263914D-01

    New RHO = 1.0000D-03     Number of function values =    22
    Least value of F =  2.392039829385394D+05         The corresponding X is:
     1.586325D+00   8.555261D-01   5.344145D-01

    New RHO = 1.0000D-04     Number of function values =    38
    Least value of F =  2.392037396723067D+05         The corresponding X is:
     1.587629D+00   8.618595D-01   5.139103D-01

    New RHO = 1.0000D-05     Number of function values =    45
    Least value of F =  2.392037395221720D+05         The corresponding X is:
     1.587714D+00   8.617400D-01   5.134964D-01

    New RHO = 1.0000D-06     Number of function values =    51
    Least value of F =  2.392037395205490D+05         The corresponding X is:
     1.587737D+00   8.617412D-01   5.135009D-01

    At the return from BOBYQA     Number of function values =    58
    Least value of F =  2.392037395205379D+05         The corresponding X is:
     1.587738D+00   8.617422D-01   5.134982D-01

From bates at stat.wisc.edu  Fri Sep 25 04:46:48 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Sep 2009 21:46:48 -0500
Subject: [R-sig-ME] I'm sorry, and here is what I mean to ask about speed
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE0202D93C@DC1EXCL01.air.org>
References: <13e802630909231842jc9c001eic921337c43db20fb@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE0202D93C@DC1EXCL01.air.org>
Message-ID: <40e66e0b0909241946x51086c83uf3a7c5ad9d4fa579@mail.gmail.com>

On Thu, Sep 24, 2009 at 11:29 AM, Doran, Harold <HDoran at air.org> wrote:
>> I'm sorry I made Doug mad and I'm sorry to have led the
>> discussion off into such a strange, disagreeable place.
>
> I don't think you did. He invests a lot in the lmer function and matrix
> pakage (with Martin) and likes to see it represented properly.
>
>> Now that I understand your answers, I believe I can ask the
>> question in a non-naive way. ?I believe this version should
>> not provoke some of the harsh words that I triggered in my
>> awkward question.
>>
>> New Non-Naive version of the Speed Question
>>
>> Do you have a copy of HLM6 on your system? ?Maybe you could
>> help me by running the same model in R (with any of the
>> packages such as lme4, nlme, or whatever) and HLM6 and let us
>> all know if you get similar estimates and how long it takes
>> to run each one.
>
> Yes, I do, and I have. But, I *think* you can only look at a wall clock
> for HLM timings. Below is an example of a model that you can run in both
> packages. Takes HLM a bit longer (by looking at a wall clock) on my
> machine to run this same model. These data come freely with HLM called
> EG1, EG2, and EG3
>
> library(mlmRev)
>> system.time(fm1 <- lmer(math ~ year + retained + black + hispanic +
> size + lowinc + mobility +(year|schoolid) + (year|childid), egsingle))
> ? user ?system elapsed
> ? 7.75 ? ?0.17 ? ?7.92
>
>>
>> Here's why I ask.
>>
>> My colleague has HLM6 on Windows XP and he compared a
>> two-level linear mixed effects model fitted with lmer from
>> lme4 against HLM6. ?He surprised my by claiming that the HLM6
>> model estimation was completed in about 1.5 seconds and the
>> lmer estimation took 50 seconds. ?That did not seem right to
>> me. ?I looked a bit at his example and made a few mental
>> notes so I could ask you what to look for when I go back to
>> dig into this. ?There are 27000 cases in his datasets and he has about
>> 25 variables at the lower level of observation and 4 or 5
>> variables at the higher level, which I think is the county of
>> survey respondents.
>> He is fitting a random intercept (random across counties) and
>> several random slopes for the higher level variables.
>
> Like I said yesterday, examples like this aren't too interesting. I
> don't really care if one software can do something in 1.5 seconds
> whereas another takes 50 seconds. Plus, this is a very simple model with
> a nested design. There are many, many sofwtare programs for these kinds
> of models. I think differences such as those are petty. What *is*
> interesting is when the models become so complex, like those with many
> levels of the random effects and complex covariance structures. At that
> point you will find that HLM cannot even estimate those models. Doug and
> I have recently estimated very large models where the dimensions of the
> model matrix for the random effects was huge and run time was on the
> order of a few hours. Now, take a model with crossed random effects for,
> say 1 million students each of whom has three observations. Now, try and
> run that model with random effects for students and their teachers in
> each of those years in HLM and see what happens.
>>
>> He pointed out that the mlWin website reported speed differences in
>> 2006 that were about the same. ?Of course, you and I know
>> that R and all of the mixed effects packages have improved
>> significantly since then. That is why the speed gap on the
>> one Windows XP system surprised me.
>>
>> Can you tell me if you see a difference between the two
>> programs (if you have HLM6). ?If you see a difference on the
>> same magnitude, it may mean we are not mistaken in our
>> conclusion. ?But if you see no difference, then it will mean
>> I'm getting it wrong and I should investigate more. If I
>> can't solve it, I should provide a reproducible example for
>> your inspection. ?I will ask permission to release the
>> private data to ?you in that case.
>
> See above for the example. But, despite my better judgement, I gave the
> example anyhow. I don't see differences in the order of a minute or so
> interesting at all. The more meaningful differences are found when the
> models become complex.
>
>>
>> Perhaps you think there are good reasons why R estimation
>> takes longer. ?E.g.:
>
> But I don't think it does.
>
>> 1. HLM programmers have full access to benefit from
>> optimizations in lmer and other open programs, but they don't
>> share their optimizations in return.
>
> I believe Richard Congden and Steve Raudenbush to be very virtuous and
> have published quite a bit on this topic. There may be some
> computational details that remain unknown, but they have been very
> transparent in their work.
>
>> 2. lmer and other R routines are making calculations in a
>> better way, a more accurate way, so we should not worry that
>> they take longer.
>
> While I am a big user of the lmer functions, I don't necessarily believe
> this is accurate. Doug has taken great care to ensure lmer returns
> reliable estimates. But, so have the HLM crew. I have routinely found
> that HLM and lmer give the same estimates for models with nested random
> effects. Since HLM cannot estimate large models with crossed random
> effects, I cannot form any comparison.
>
>> ? ?That was my first guess, in the original mail I said I
>> thought that HLM was using PQL whereas lmer is using Laplace
>> or Adaptive Gaussian Quadrature. ?But Doug's comment
>> indicated that I was mistaken to expect a difference there
>> because REML is the default in lmer and it is also what HLM
>> is doing, and there's no involvement of quadrature or
>> integral approximation in a mixed linear model (gaussian
>> dependent variable).
>
> I think you remain a little confused here. For generalized linear mixed
> models, R and HLM have different ways for evaluating the
> integral--although I have found that, with nested designs, both yield
> results comparable out to multiple decimal points. But, with linear
> mixed models that is not an issue. With linear mixed models, REML is the
> default in both HLM and R. But, the HLM folks view the world as a GLS
> problem and Doug views this as a PLS problem.

That's true.  I think there are additional differences in the behavior
at the edge cases and in terms of the profiling of the objective
function (the deviance or the REML criterion).  The algorithm
implemented in lmer uses penalized least squares (PLS) instead of
Generalized least squares (GLS) as you mentioned.  In mathematical
terms these are "dual" problems; a GLS problem can be written as PLS
and a PLS problem can be written as GLS.  In a strictly hierarchical
model there is not a clear advantage one way or the other.  In a model
with non-nested random effects PLS is the winner big-time. You don't
want to contemplate GLS in those cases.

There is a second duality where the choice made in lmer is different
from the conventional choice.  If you have seen Henderson's
mixed-model equations (http://en.wikipedia.org/wiki/Mixed_model) the
conventional representation uses the precision matrix of the random
effects (G^{-1} in the Wikipedia entry - a precision matrix is the
inverse of a variance-covariance matrix).  That's fine except when G
becomes singular, as it can.  The representation in lmer incorporates
the effects of G into the model matrix, not the penalty.  A detailed
explanation is given in the slides from a presentation at DSC2009 and
available as http://matrix.r-forge.r-project.org/slides/2009-07-14-Copenhagen/BatesMaechlerD.pdf
These slides include an example from you, Harold.

>>
>> On the other hand, perhaps you are (like me) surprised by
>> this difference and you want to help me figure out the cause
>> of the differences. ?If you have ideas about that, maybe we
>> can work together (I don't suck at C!). I have pretty much
>> experience profiling programs in C and did some optimization
>> help on a big-ish C++ based R package this summer.
>>
>> So far, I have a simple observer's interest in this question. ? I
>> advise people whether it is beneficial for them to spend
>> their scarce resources on a commercial package like HLM6 and
>> one of the factors
>> that is important to them is how "fast" the programs are. ? I
>> personally don't see an urgent reason to buy HLM because it
>> can estimate a model in 1 second and an open source approach
>> requires 50 seconds. ?But I'm not the one making the
>> decision. If I can make the R version run almost as fast as
>> HLM6, or provide reasons why people might benefit from using
>> a program that takes longer, then I can do my job of advising
>> the users.
>
> Yes, "fast" is important when it comes to big problems. But, there are
> many other issues to consider as well, and I would place those far above
> the "fast" issue. For instance, what if you want to create an
> interaction term in HLM? You must first, work with a stat package to
> manually create the interaction variable, import those data into HLM and
> then run the model. So, it takes two software programs to get the job
> done. What if you want presentation-style visual displays of your data?
> What if you want (close to) on-demand support from real statisticians on
> your problem?

It is interesting that in Paul's original posting on this he described
the problematic example as having 40 first level "variables" and 5
second-level variables (or the other way around, I can never remember
if level-1 refers to the most specific grouping, usually an
individual, or the least specific grouping, such as district if the
data are grouped by student, class, school and district).  I'm willing
to bet that these aren't variables or covariates in the sense that I
would think of them.  If you had a race/ethnicity covariate with
(typically in the U.S.) five levels then that would count as 4
variables in HLM, I believe, but only 1 variable in R.  The formula
language in R creates the model matrix from the data and the terms in
the model.  Other systems require that you create the model matrix
which leads to people thinking that it is natural to use 0/1 encodings
for characteristics like sex.  For a binary classification that is not
too risky but when you have more than two levels you must create a set
of indicators and maintain consistency in them, and the implicit
"missing" indicator.  It is just much more awkward and yet, if you
started using that system, you find it to be the natural way of doing
things (sort of like people who grew up using the Imperial system of
weights and measures: feet, yards, furlongs, miles, etc. complaining
that the metric system is so difficult to understand).

> Last, and IMHO the biggest factor, what if you want to modify the code
> in some way to customize your analysis? I suppose all of this is to say
> look beyond the fast issue for simple problems in your evaluation
> criteria. I would suggest that you consider what your world would look
> like if you needed any of the info I discuss in the preceding paragraph.
>
> Just my .02 cents.
>
>
>
>>
>> I am sorry if this question appears impertinent or insulting.
>> I do not mean it as a criticism.
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science
>> 1541 Lilac Lane, Room 504
>> University of Kansas
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From raldo.kruger at gmail.com  Sat Sep 26 10:11:40 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Sat, 26 Sep 2009 10:11:40 +0200
Subject: [R-sig-ME] Data sheet notation and model structure for GLMM
	with 3 non-factorial factors
In-Reply-To: <40e66e0b0909240510l6cffc62chea7ea49f7be0c26f@mail.gmail.com>
References: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>
	<40e66e0b0909240510l6cffc62chea7ea49f7be0c26f@mail.gmail.com>
Message-ID: <30406dd0909260111u41efa321nfa4c1766f255eebf@mail.gmail.com>

Hi Douglas,

Many thanks for the input. I've run two analyses on the same dataset
using 1) indicator columns and the 2) a single 'factor / treatment'
column for the non-factorial design described in my previous e-mail,
and the results were identical (great!).

However, I did the same for a dataset with a factorial design (N, G,
N*G, i.e. there were plots with N, plots with G, and plots with both N
and G), and the results for the main effects are identical, but the
estimates for the interaction effects (N*G) are different between the
two analyses (see below). Could you help me make sense of that please
(i.e. which one is correct?) !

Thanks,
Raldo

With expanded treatment notation-
Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept)    2.92060    0.23834  12.254  < 2e-16 ***
N              0.03766    0.03486   1.080   0.2801
G              0.14929    0.03395   4.397 1.10e-05 ***
Yearthree     -2.85449    0.10664 -26.768  < 2e-16 ***
Yeartwo       -1.88175    0.06844 -27.494  < 2e-16 ***
N:G           -0.31633    0.04953  -6.386 1.70e-10 ***
N:Yearthree    0.15710    0.14428   1.089   0.2762
N:Yeartwo      0.14736    0.09305   1.584   0.1133
G:Yearthree   -0.25107    0.15430  -1.627   0.1037
G:Yeartwo      0.07550    0.09200   0.821   0.4118
N:G:Yearthree  0.36353    0.20810   1.747   0.0807 .
N:G:Yeartwo   -0.01158    0.12996  -0.089   0.9290

With single column treatment notation-
Fixed effects:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)         2.92057    0.23836  12.253  < 2e-16 ***
TreatG              0.14928    0.03395   4.397 1.10e-05 ***
TreatN              0.03767    0.03486   1.080 0.279928
TreatNG            -0.12938    0.03639  -3.556 0.000377 ***
Yearthree          -2.85448    0.10664 -26.768  < 2e-16 ***
Yeartwo            -1.88175    0.06844 -27.494  < 2e-16 ***
TreatG:Yearthree   -0.25109    0.15430  -1.627 0.103693
TreatN:Yearthree    0.15711    0.14428   1.089 0.276199
TreatNG :Yearthree  0.26959    0.14636   1.842 0.065483 .
TreatG:Yeartwo      0.07549    0.09200   0.820 0.411941
TreatN:Yeartwo      0.14735    0.09305   1.583 0.113308
TreatNG :Yeartwo    0.21118    0.09558   2.210 0.027139 *


On Thu, Sep 24, 2009 at 2:10 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Thu, Sep 24, 2009 at 1:22 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
>> Hi R users,
>>
>> I have 3 factors in a non-factorial design (G, K and N), as well as
>> two time periods (Year) and a random factor (Site), with Plant numbers
>> as the response variable.
>>
>> My 1st question relates to the the notation of the treatments in the
>> data frame. Is it appropriate to use an expanded treatment notation,
>> such as this, when using glmer{lme4}:
>>
>> Site ? ?Year ? ?Plant ? G ? ? ? K ? ? ? N
>> A ? ? ? 1 ? ? ? 5 ? ? ? 0 ? ? ? 0 ? ? ? 0
>> A ? ? ? 1 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>> A ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>> A ? ? ? 1 ? ? ? 10 ? ? ?0 ? ? ? 0 ? ? ? 1
>> A ? ? ? 2 ? ? ? 3 ? ? ? 0 ? ? ? 0 ? ? ? 0
>> A ? ? ? 2 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>> A ? ? ? 2 ? ? ? 8 ? ? ? 0 ? ? ? 1 ? ? ? 0
>> A ? ? ? 2 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 0 ? ? ? 0
>> B ? ? ? 1 ? ? ? 3 ? ? ? 1 ? ? ? 0 ? ? ? 0
>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>> B ? ? ? 1 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>> B ? ? ? 2 ? ? ? 4 ? ? ? 0 ? ? ? 0 ? ? ? 0
>> B ? ? ? 2 ? ? ? 5 ? ? ? 1 ? ? ? 0 ? ? ? 0
>> B ? ? ? 2 ? ? ? 6 ? ? ? 0 ? ? ? 1 ? ? ? 0
>> B ? ? ? 2 ? ? ? 11 ? ? ?0 ? ? ? 0 ? ? ? 1
>>
>> With the model
>>
>> m1<-glmer(Plant~G+K+N+Year+(1|Site), ...)
>>
>> Or is it better to use a single column for the treatments, like this:
>>
>> Site ? ?Year ? ?Plant ? Treatment
>> A ? ? ? 1 ? ? ? 5 ? ? ? C
>> A ? ? ? 1 ? ? ? 4 ? ? ? G
>> A ? ? ? 1 ? ? ? 7 ? ? ? K
>> A ? ? ? 1 ? ? ? 10 ? ? ?N
>> A ? ? ? 2 ? ? ? 3 ? ? ? C
>> A ? ? ? 2 ? ? ? 4 ? ? ? G
>> A ? ? ? 2 ? ? ? 8 ? ? ? K
>> A ? ? ? 2 ? ? ? 12 ? ? ?N
>> B ? ? ? 1 ? ? ? 7 ? ? ? C
>> B ? ? ? 1 ? ? ? 3 ? ? ? G
>> B ? ? ? 1 ? ? ? 7 ? ? ? K
>> B ? ? ? 1 ? ? ? 12 ? ? ?N
>> B ? ? ? 2 ? ? ? 4 ? ? ? C
>> B ? ? ? 2 ? ? ? 5 ? ? ? G
>> B ? ? ? 2 ? ? ? 6 ? ? ? K
>> B ? ? ? 2 ? ? ? 11 ? ? ?N
>>
>> With the following model:
>> m1<-glmer(Plants~Treatment+Year+(1|Site), ...)
>
> The latter is preferred. ?R will generate the indicator columns for
> the levels of the Treatment factor (the 0/1 columns shown in the first
> form) and, when appropriate, reduce them to a set of 2 "contrasts" in
> the model. ?(The reason for quoting the word "contrasts" is that there
> is a formal mathematical definition of a contrast but the linear
> combinations generated by R do not always satisfy this definition.
> The method and results are correct, it is just the name that is
> inaccurate.)
>
> The reason that the latter is preferred is that it is easier to
> maintain the data in a consistent form (factors maintain consistency
> and are easy to check in the output from str() or summary(), whereas
> indicator columns have inter-column dependencies that must be checked
> separately) and the "when appropriate" clause above. ?Determining a
> useful parameterization of a linear model incorporating factors is
> subtle and a lot of code in the R function model.matrix is devoted to
> a symbolic analysis designed to get this right. ?Also, you can, if you
> wish, change the parameterization (see ?contrasts).
>



-- 
Raldo



From raldo.kruger at gmail.com  Sat Sep 26 10:23:29 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Sat, 26 Sep 2009 10:23:29 +0200
Subject: [R-sig-ME] Calculating SE from GLMM results (using glmer{lme4})
In-Reply-To: <4ABB724B.3080804@ufl.edu>
References: <30406dd0909232305k3edcecedi396c9bb6e8655833@mail.gmail.com>
	<4ABB724B.3080804@ufl.edu>
Message-ID: <30406dd0909260123p70eae67ehcdf39687b56fb778@mail.gmail.com>

Hi Ben,

Thanks for your help. See my responses below (~~~).

Regards,
Raldo



On Thu, Sep 24, 2009 at 3:21 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Raldo Kruger wrote:
>> Dear R users,
>>
>> Please excuse the basic questions, but I?m new to GLMMs and R!
>>
>> I?m analyzing an experiment where Seedling numbers in plots where seed
>> has been sown on restoration sites is the response variable. I?m most
>> interested in determining whether the Nutrients (N) and water
>> absorbing polymer Gel (Ge) additions to the soil substrate contribute
>> positively to the survival of the seedlings, over a 3 year time period
>> (for simplicity I'm just using 3 time periods, each in the same season
>> for the 3
>> successive years).
>> Fixed factors: Nutrients (0 and 1), Gel (0 and 1)
>> Random factors: Site (4 non replicate sites), Year (3 time periods)
>> Response variable: Seedling numbers (counts) / 0.25m2 plot
>> The results are as follows:
>> ? ? ? ? ? ? ? ?Estimate ? ? ? Std. Error ? ? ?z value ?Pr(>|z|)
>> (Intercept) ? 4.52982 0.24486 18.5 ? ? ? ? ? <2.00E-16 ? ? ? ?***
>> N ? ? ? ? ? ?-0.07922 0.08415 -0.94 ? ? ? ? ?0.346489
>> Ge ? ? ? ? ? ? 0.20766 ? ? ? ?0.08428 2.46 ? ? ? ? ? ?0.013744 ? ? ? ?*
>> Year ? ? ? ? ?-1.62937 ? ? ? ?0.04672 -34.88 ?<2.00E-16 ? ? ? ***
>> N:Ge ?-0.44213 ? ? ? ?0.11898 -3.72 ? ? ? ? ? 0.000202 ? ? ? ?***
>> N:Year ? ? ? ?0.11705 0.06322 1.85 ? ?0.064125 ? ? ? ?.
>> Ge:Year ? ? ? -0.04861 ? ? ? ?0.0645 ?-0.75 ? 0.451132
>> N:Ge:Year ? ? 0.11458 0.08917 1.28 ? ?0.198821
>>
>
> ?Some comments:
>
> * ?It looks like you fitted year as a fixed effect rather than a random
> effect (probably sensible, since you only have 3 levels / years), and
> incorporated all fixed effect interactions (i.e. N*Ge*Year) ? ?However,
> it also looks like you fitted year as a continuous covariate, which
> means that R is trying to fit a linear function of time -- is that
> really what you want? ?There's a very large negative year effect -- if
> your year values are coded 1-3, then it suggests you have very few
> seedlings left in year 3?

~~~Yes, you're right - I have used Year as a continuous covariate,
partly because when I first ~~~tried it as a categorical predictor, I
didn't know how to make sense of the results. But ~~~you're right,
Time is not a linear function in this case, since there is a big drop
in ~~~seedling numbers from year 1 to 2, and a much smaller drop from
year 2 to 3. I've ~~~corrected it, and the results are much 'better'
(and i can now make sense of them!). ~~~Either way, there are very few
seedlings left in year 3 (which is what the observed data ~~~shows
too).


>
> ?It's also
> worth considering whether you are really getting reliable answers based
> on only 4 sites -- I would also try this with Site as a fixed effect
> and see whether the answers differ considerably. ?(I know that,
> philosophically, Site and Year are both random effects, and you may
> run into trouble with reviewers who are used to classical ANOVA

~~~ I've been using glmer, and it doesn't seem to accept a model with
no random factors. Is ~~~that true, and if not, how can i  write the
model without a random factor so that it is ~~~accepted by glmer?

>> 1) ? ?So as I understand (from previous correspondence with R-users) the
>> number of seedlings in the control plots in year 0 is
>> ? ? ? ? exp(4.53) = 92.7. Is the standard error calculated with
>> 0.24486 (i.e. 92.7*0.24), or with 92.7*exp(0.24).
>
> ?The latter.
> ?So for example the approximate confidence intervals would be
> exp(0.453 +/- 2*0.245)
>
>> 2) ? ?And for the N:Ge treatment, the effect is exp(-0.08+0.21-0.44)
>> =0.73 (I.e. a 27% reduction compared to the control), right? So
>> ? ? ? ? is the SE for the N:Ge effect calculated as the sum of the
>> SE?s too, i.e. 0.08+0.08+0.12, or is it just 0.12?
>
> ?The SE for combined effects is calculated as sqrt(se1^2 + se2^2 + se3^2)
>
>> 3) ? ?Lastly, is it possible to fit two response variables in one GLMM?
>> E.g. seedling numbers and height.
>
> ?This would be hard -- you're talking about a multivariate response
> with different measurement scales/error distributions for different
> variables ...
>>
>> Many thanks,
>> Raldo Kr?ger
>> Msc student
>> University of Cape Town
>>
>>
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>



-- 
Raldo



From bates at stat.wisc.edu  Sat Sep 26 14:43:04 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 26 Sep 2009 07:43:04 -0500
Subject: [R-sig-ME] Data sheet notation and model structure for GLMM
	with 3 non-factorial factors
In-Reply-To: <30406dd0909260111u41efa321nfa4c1766f255eebf@mail.gmail.com>
References: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>
	<40e66e0b0909240510l6cffc62chea7ea49f7be0c26f@mail.gmail.com>
	<30406dd0909260111u41efa321nfa4c1766f255eebf@mail.gmail.com>
Message-ID: <40e66e0b0909260543k6d7621a2o21eec5402ae8f10a@mail.gmail.com>

 Sat, Sep 26, 2009 at 3:11 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Hi Douglas,

> Many thanks for the input. I've run two analyses on the same dataset
> using 1) indicator columns and the 2) a single 'factor / treatment'
> column for the non-factorial design described in my previous e-mail,
> and the results were identical (great!).

> However, I did the same for a dataset with a factorial design (N, G,
> N*G, i.e. there were plots with N, plots with G, and plots with both N
> and G), and the results for the main effects are identical, but the
> estimates for the interaction effects (N*G) are different between the
> two analyses (see below). Could you help me make sense of that please
> (i.e. which one is correct?) !

Generally when you have the possibility of having N and G combined you
would treat the design as a two-factor two-level factorial.  That is,
one factor for presence or absence of G and another factor for
presence or absence of N.  You could treat it as a single factor with
four levels (neither, G only, N only and both N and G) but, as you
have seen you need to translate between the representations.

In the two-factor, two-level factorial design, let a be the estimate
of the main effect for G, b be the estimate of the main effect for N,
and c be the interaction estimate.  In your example a = 0.14929, b =
0.03766 and c = -0.31633.  Then the estimated cell mean for the NG
cell is a + b + c =
>  0.03766 + 0.14929 + (-0.31633)
[1] -0.12938

> Thanks,
> Raldo
>
> With expanded treatment notation-
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ?2.92060 ? ?0.23834 ?12.254 ?< 2e-16 ***
> N ? ? ? ? ? ? ?0.03766 ? ?0.03486 ? 1.080 ? 0.2801
> G ? ? ? ? ? ? ?0.14929 ? ?0.03395 ? 4.397 1.10e-05 ***
> Yearthree ? ? -2.85449 ? ?0.10664 -26.768 ?< 2e-16 ***
> Yeartwo ? ? ? -1.88175 ? ?0.06844 -27.494 ?< 2e-16 ***
> N:G ? ? ? ? ? -0.31633 ? ?0.04953 ?-6.386 1.70e-10 ***
> N:Yearthree ? ?0.15710 ? ?0.14428 ? 1.089 ? 0.2762
> N:Yeartwo ? ? ?0.14736 ? ?0.09305 ? 1.584 ? 0.1133
> G:Yearthree ? -0.25107 ? ?0.15430 ?-1.627 ? 0.1037
> G:Yeartwo ? ? ?0.07550 ? ?0.09200 ? 0.821 ? 0.4118
> N:G:Yearthree ?0.36353 ? ?0.20810 ? 1.747 ? 0.0807 .
> N:G:Yeartwo ? -0.01158 ? ?0.12996 ?-0.089 ? 0.9290
>
> With single column treatment notation-
> Fixed effects:
> ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? 2.92057 ? ?0.23836 ?12.253 ?< 2e-16 ***
> TreatG ? ? ? ? ? ? ?0.14928 ? ?0.03395 ? 4.397 1.10e-05 ***
> TreatN ? ? ? ? ? ? ?0.03767 ? ?0.03486 ? 1.080 0.279928
> TreatNG ? ? ? ? ? ?-0.12938 ? ?0.03639 ?-3.556 0.000377 ***
> Yearthree ? ? ? ? ?-2.85448 ? ?0.10664 -26.768 ?< 2e-16 ***
> Yeartwo ? ? ? ? ? ?-1.88175 ? ?0.06844 -27.494 ?< 2e-16 ***
> TreatG:Yearthree ? -0.25109 ? ?0.15430 ?-1.627 0.103693
> TreatN:Yearthree ? ?0.15711 ? ?0.14428 ? 1.089 0.276199
> TreatNG :Yearthree ?0.26959 ? ?0.14636 ? 1.842 0.065483 .
> TreatG:Yeartwo ? ? ?0.07549 ? ?0.09200 ? 0.820 0.411941
> TreatN:Yeartwo ? ? ?0.14735 ? ?0.09305 ? 1.583 0.113308
> TreatNG :Yeartwo ? ?0.21118 ? ?0.09558 ? 2.210 0.027139 *
>
>
> On Thu, Sep 24, 2009 at 2:10 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Thu, Sep 24, 2009 at 1:22 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
>>> Hi R users,
>>>
>>> I have 3 factors in a non-factorial design (G, K and N), as well as
>>> two time periods (Year) and a random factor (Site), with Plant numbers
>>> as the response variable.
>>>
>>> My 1st question relates to the the notation of the treatments in the
>>> data frame. Is it appropriate to use an expanded treatment notation,
>>> such as this, when using glmer{lme4}:
>>>
>>> Site ? ?Year ? ?Plant ? G ? ? ? K ? ? ? N
>>> A ? ? ? 1 ? ? ? 5 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>> A ? ? ? 1 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>> A ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>> A ? ? ? 1 ? ? ? 10 ? ? ?0 ? ? ? 0 ? ? ? 1
>>> A ? ? ? 2 ? ? ? 3 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>> A ? ? ? 2 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>> A ? ? ? 2 ? ? ? 8 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>> A ? ? ? 2 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>> B ? ? ? 1 ? ? ? 3 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>> B ? ? ? 1 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>>> B ? ? ? 2 ? ? ? 4 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>> B ? ? ? 2 ? ? ? 5 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>> B ? ? ? 2 ? ? ? 6 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>> B ? ? ? 2 ? ? ? 11 ? ? ?0 ? ? ? 0 ? ? ? 1
>>>
>>> With the model
>>>
>>> m1<-glmer(Plant~G+K+N+Year+(1|Site), ...)
>>>
>>> Or is it better to use a single column for the treatments, like this:
>>>
>>> Site ? ?Year ? ?Plant ? Treatment
>>> A ? ? ? 1 ? ? ? 5 ? ? ? C
>>> A ? ? ? 1 ? ? ? 4 ? ? ? G
>>> A ? ? ? 1 ? ? ? 7 ? ? ? K
>>> A ? ? ? 1 ? ? ? 10 ? ? ?N
>>> A ? ? ? 2 ? ? ? 3 ? ? ? C
>>> A ? ? ? 2 ? ? ? 4 ? ? ? G
>>> A ? ? ? 2 ? ? ? 8 ? ? ? K
>>> A ? ? ? 2 ? ? ? 12 ? ? ?N
>>> B ? ? ? 1 ? ? ? 7 ? ? ? C
>>> B ? ? ? 1 ? ? ? 3 ? ? ? G
>>> B ? ? ? 1 ? ? ? 7 ? ? ? K
>>> B ? ? ? 1 ? ? ? 12 ? ? ?N
>>> B ? ? ? 2 ? ? ? 4 ? ? ? C
>>> B ? ? ? 2 ? ? ? 5 ? ? ? G
>>> B ? ? ? 2 ? ? ? 6 ? ? ? K
>>> B ? ? ? 2 ? ? ? 11 ? ? ?N
>>>
>>> With the following model:
>>> m1<-glmer(Plants~Treatment+Year+(1|Site), ...)
>>
>> The latter is preferred. ?R will generate the indicator columns for
>> the levels of the Treatment factor (the 0/1 columns shown in the first
>> form) and, when appropriate, reduce them to a set of 2 "contrasts" in
>> the model. ?(The reason for quoting the word "contrasts" is that there
>> is a formal mathematical definition of a contrast but the linear
>> combinations generated by R do not always satisfy this definition.
>> The method and results are correct, it is just the name that is
>> inaccurate.)
>>
>> The reason that the latter is preferred is that it is easier to
>> maintain the data in a consistent form (factors maintain consistency
>> and are easy to check in the output from str() or summary(), whereas
>> indicator columns have inter-column dependencies that must be checked
>> separately) and the "when appropriate" clause above. ?Determining a
>> useful parameterization of a linear model incorporating factors is
>> subtle and a lot of code in the R function model.matrix is devoted to
>> a symbolic analysis designed to get this right. ?Also, you can, if you
>> wish, change the parameterization (see ?contrasts).
>>
>
>
>
> --
> Raldo
>



From atyre2 at unlnotes.unl.edu  Sat Sep 26 15:01:18 2009
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Sat, 26 Sep 2009 08:01:18 -0500
Subject: [R-sig-ME] year and site
Message-ID: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090926/eff7ec7f/attachment.pl>

From wkmor1 at gmail.com  Sat Sep 26 15:41:20 2009
From: wkmor1 at gmail.com (Will Morris)
Date: Sat, 26 Sep 2009 23:41:20 +1000
Subject: [R-sig-ME] year and site
In-Reply-To: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
Message-ID: <-2184813634866656385@unknownmsgid>

Gelman suggests that specifying a weakly informative half-Cauchy
distribution for the group level standard deviation can overcome the
difficulty in estimation experienced when there are few groups and
your using a uniform prior (and I presume using Maximum likelihood
too). See Gelman & Hill, 2007.

Will Morris
Masters of Philosophy candidate
Vesk Plant Ecology Lab
The School of Botany
The University of Melbourne
Australia
Phone: +61 3 8344 0120
http://www.botany.unimelb.edu.au/vesk/

On 26/09/2009, at 23:29, Andrew J Tyre <atyre2 at unlnotes.unl.edu> wrote:

> Hi all,
>
> in ecology year a study is done in, and the site it is done at, are
> obvious random effects. However, for most student projects, and
> indeed,
> even larger projects, having more than 2-3 years of data is unusual.
> Having more than 2-3 sites is more common, but even then the number is
> very limited. This means that estimating a random effect of year
> crossed
> with site is difficult. The solution that I've tried a couple times
> is to
> create a "siteyear" random effect, where each year at each site is a
> different level. This gives many more levels with which to estimate
> variances, and seems to work well. The only downside that I've been
> able
> to come up with is that if there are "site" effects that are
> consistent
> through time, or year effects consistent across space, then this
> approach
> misses separating them, at a minimum. What I'm concerned about is
> that it
> might lead to bias as well - I don't think it will, but I'd rather be
> certain!
>
> I have used the "fallback" of fitting year and/or site as a fixed
> effect,
> but I'm hearing some concern from reviewers who've been sold on the
> random
> effects idea convincingly enough to reject a paper that doesn't
> treat year
> or site as random without recognizing that it doesn't help when the
> number
> of levels is low. Also, if there is a continuous covariate whose
> effect
> varies by siteyear, the fixed effect interaction term gets ugly, fast.
>
> Any discussion or insights appreciated!
>
> thanks,
>
>
>
> Drew Tyre
>
> School of Natural Resources
> University of Nebraska-Lincoln
> 416 Hardin Hall, East Campus
> 3310 Holdrege Street
> Lincoln, NE 68583-0974
>
> phone: +1 402 472 4054
> fax: +1 402 472 2946
> email: atyre2 at unl.edu
> http://snr.unl.edu/tyre
> http://aminpractice.blogspot.com
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From h.wickham at gmail.com  Sat Sep 26 16:17:50 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 26 Sep 2009 09:17:50 -0500
Subject: [R-sig-ME] year and site
In-Reply-To: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
Message-ID: <f8e6ff050909260717k2e18cd32y5a0d4a478057b649@mail.gmail.com>

> in ecology year a study is done in, and the site it is done at, are
> obvious random effects.

You're picking the years at random? - that's a pretty impressive study design!

Hadley

-- 
http://had.co.nz/



From bates at stat.wisc.edu  Sat Sep 26 16:58:09 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 26 Sep 2009 09:58:09 -0500
Subject: [R-sig-ME] year and site
In-Reply-To: <f8e6ff050909260717k2e18cd32y5a0d4a478057b649@mail.gmail.com>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
	<f8e6ff050909260717k2e18cd32y5a0d4a478057b649@mail.gmail.com>
Message-ID: <40e66e0b0909260758k3d5de0b1k3133af6682afcc17@mail.gmail.com>

On Sat, Sep 26, 2009 at 9:17 AM, hadley wickham <h.wickham at gmail.com> wrote:
>> in ecology year a study is done in, and the site it is done at, are
>> obvious random effects.
>
> You're picking the years at random? - that's a pretty impressive study design!

As I'm sure you realize, Hadley, it is the effects that are random,
not the years.  If I have studied a particular location for the last
three years and I use a fixed-effect for the years in my model then I
can "predict" the response for any one of those three years that I
wish to.  But I have no information on which to base a prediction for
next year, which is usually what I want to do.  (I am assuming the
year is being modeled as a categorical variable rather than in terms
of trends.)

Using random effects for the year allows me to characterize the
variability between years and that does help me in characterizing the
variability for the next year.



From raldo.kruger at gmail.com  Sat Sep 26 19:31:51 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Sat, 26 Sep 2009 19:31:51 +0200
Subject: [R-sig-ME] Data sheet notation and model structure for GLMM
	with 3 non-factorial factors
In-Reply-To: <40e66e0b0909260543k6d7621a2o21eec5402ae8f10a@mail.gmail.com>
References: <30406dd0909232322v1caa06acja7f3cdcc10aa052c@mail.gmail.com>
	<40e66e0b0909240510l6cffc62chea7ea49f7be0c26f@mail.gmail.com>
	<30406dd0909260111u41efa321nfa4c1766f255eebf@mail.gmail.com>
	<40e66e0b0909260543k6d7621a2o21eec5402ae8f10a@mail.gmail.com>
Message-ID: <30406dd0909261031n1dfe192dr3e0f46688aec62c8@mail.gmail.com>

Thanks for the help!

On Sat, Sep 26, 2009 at 2:43 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> ?Sat, Sep 26, 2009 at 3:11 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
>> Hi Douglas,
>
>> Many thanks for the input. I've run two analyses on the same dataset
>> using 1) indicator columns and the 2) a single 'factor / treatment'
>> column for the non-factorial design described in my previous e-mail,
>> and the results were identical (great!).
>
>> However, I did the same for a dataset with a factorial design (N, G,
>> N*G, i.e. there were plots with N, plots with G, and plots with both N
>> and G), and the results for the main effects are identical, but the
>> estimates for the interaction effects (N*G) are different between the
>> two analyses (see below). Could you help me make sense of that please
>> (i.e. which one is correct?) !
>
> Generally when you have the possibility of having N and G combined you
> would treat the design as a two-factor two-level factorial. ?That is,
> one factor for presence or absence of G and another factor for
> presence or absence of N. ?You could treat it as a single factor with
> four levels (neither, G only, N only and both N and G) but, as you
> have seen you need to translate between the representations.
>
> In the two-factor, two-level factorial design, let a be the estimate
> of the main effect for G, b be the estimate of the main effect for N,
> and c be the interaction estimate. ?In your example a = 0.14929, b =
> 0.03766 and c = -0.31633. ?Then the estimated cell mean for the NG
> cell is a + b + c =
>> ?0.03766 + 0.14929 + (-0.31633)
> [1] -0.12938
>
>> Thanks,
>> Raldo
>>
>> With expanded treatment notation-
>> Fixed effects:
>> ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? ?2.92060 ? ?0.23834 ?12.254 ?< 2e-16 ***
>> N ? ? ? ? ? ? ?0.03766 ? ?0.03486 ? 1.080 ? 0.2801
>> G ? ? ? ? ? ? ?0.14929 ? ?0.03395 ? 4.397 1.10e-05 ***
>> Yearthree ? ? -2.85449 ? ?0.10664 -26.768 ?< 2e-16 ***
>> Yeartwo ? ? ? -1.88175 ? ?0.06844 -27.494 ?< 2e-16 ***
>> N:G ? ? ? ? ? -0.31633 ? ?0.04953 ?-6.386 1.70e-10 ***
>> N:Yearthree ? ?0.15710 ? ?0.14428 ? 1.089 ? 0.2762
>> N:Yeartwo ? ? ?0.14736 ? ?0.09305 ? 1.584 ? 0.1133
>> G:Yearthree ? -0.25107 ? ?0.15430 ?-1.627 ? 0.1037
>> G:Yeartwo ? ? ?0.07550 ? ?0.09200 ? 0.821 ? 0.4118
>> N:G:Yearthree ?0.36353 ? ?0.20810 ? 1.747 ? 0.0807 .
>> N:G:Yeartwo ? -0.01158 ? ?0.12996 ?-0.089 ? 0.9290
>>
>> With single column treatment notation-
>> Fixed effects:
>> ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? ? ? ? 2.92057 ? ?0.23836 ?12.253 ?< 2e-16 ***
>> TreatG ? ? ? ? ? ? ?0.14928 ? ?0.03395 ? 4.397 1.10e-05 ***
>> TreatN ? ? ? ? ? ? ?0.03767 ? ?0.03486 ? 1.080 0.279928
>> TreatNG ? ? ? ? ? ?-0.12938 ? ?0.03639 ?-3.556 0.000377 ***
>> Yearthree ? ? ? ? ?-2.85448 ? ?0.10664 -26.768 ?< 2e-16 ***
>> Yeartwo ? ? ? ? ? ?-1.88175 ? ?0.06844 -27.494 ?< 2e-16 ***
>> TreatG:Yearthree ? -0.25109 ? ?0.15430 ?-1.627 0.103693
>> TreatN:Yearthree ? ?0.15711 ? ?0.14428 ? 1.089 0.276199
>> TreatNG :Yearthree ?0.26959 ? ?0.14636 ? 1.842 0.065483 .
>> TreatG:Yeartwo ? ? ?0.07549 ? ?0.09200 ? 0.820 0.411941
>> TreatN:Yeartwo ? ? ?0.14735 ? ?0.09305 ? 1.583 0.113308
>> TreatNG :Yeartwo ? ?0.21118 ? ?0.09558 ? 2.210 0.027139 *
>>
>>
>> On Thu, Sep 24, 2009 at 2:10 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Thu, Sep 24, 2009 at 1:22 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
>>>> Hi R users,
>>>>
>>>> I have 3 factors in a non-factorial design (G, K and N), as well as
>>>> two time periods (Year) and a random factor (Site), with Plant numbers
>>>> as the response variable.
>>>>
>>>> My 1st question relates to the the notation of the treatments in the
>>>> data frame. Is it appropriate to use an expanded treatment notation,
>>>> such as this, when using glmer{lme4}:
>>>>
>>>> Site ? ?Year ? ?Plant ? G ? ? ? K ? ? ? N
>>>> A ? ? ? 1 ? ? ? 5 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>>> A ? ? ? 1 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>>> A ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>>> A ? ? ? 1 ? ? ? 10 ? ? ?0 ? ? ? 0 ? ? ? 1
>>>> A ? ? ? 2 ? ? ? 3 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>>> A ? ? ? 2 ? ? ? 4 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>>> A ? ? ? 2 ? ? ? 8 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>>> A ? ? ? 2 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>>>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>>> B ? ? ? 1 ? ? ? 3 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>>> B ? ? ? 1 ? ? ? 7 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>>> B ? ? ? 1 ? ? ? 12 ? ? ?0 ? ? ? 0 ? ? ? 1
>>>> B ? ? ? 2 ? ? ? 4 ? ? ? 0 ? ? ? 0 ? ? ? 0
>>>> B ? ? ? 2 ? ? ? 5 ? ? ? 1 ? ? ? 0 ? ? ? 0
>>>> B ? ? ? 2 ? ? ? 6 ? ? ? 0 ? ? ? 1 ? ? ? 0
>>>> B ? ? ? 2 ? ? ? 11 ? ? ?0 ? ? ? 0 ? ? ? 1
>>>>
>>>> With the model
>>>>
>>>> m1<-glmer(Plant~G+K+N+Year+(1|Site), ...)
>>>>
>>>> Or is it better to use a single column for the treatments, like this:
>>>>
>>>> Site ? ?Year ? ?Plant ? Treatment
>>>> A ? ? ? 1 ? ? ? 5 ? ? ? C
>>>> A ? ? ? 1 ? ? ? 4 ? ? ? G
>>>> A ? ? ? 1 ? ? ? 7 ? ? ? K
>>>> A ? ? ? 1 ? ? ? 10 ? ? ?N
>>>> A ? ? ? 2 ? ? ? 3 ? ? ? C
>>>> A ? ? ? 2 ? ? ? 4 ? ? ? G
>>>> A ? ? ? 2 ? ? ? 8 ? ? ? K
>>>> A ? ? ? 2 ? ? ? 12 ? ? ?N
>>>> B ? ? ? 1 ? ? ? 7 ? ? ? C
>>>> B ? ? ? 1 ? ? ? 3 ? ? ? G
>>>> B ? ? ? 1 ? ? ? 7 ? ? ? K
>>>> B ? ? ? 1 ? ? ? 12 ? ? ?N
>>>> B ? ? ? 2 ? ? ? 4 ? ? ? C
>>>> B ? ? ? 2 ? ? ? 5 ? ? ? G
>>>> B ? ? ? 2 ? ? ? 6 ? ? ? K
>>>> B ? ? ? 2 ? ? ? 11 ? ? ?N
>>>>
>>>> With the following model:
>>>> m1<-glmer(Plants~Treatment+Year+(1|Site), ...)
>>>
>>> The latter is preferred. ?R will generate the indicator columns for
>>> the levels of the Treatment factor (the 0/1 columns shown in the first
>>> form) and, when appropriate, reduce them to a set of 2 "contrasts" in
>>> the model. ?(The reason for quoting the word "contrasts" is that there
>>> is a formal mathematical definition of a contrast but the linear
>>> combinations generated by R do not always satisfy this definition.
>>> The method and results are correct, it is just the name that is
>>> inaccurate.)
>>>
>>> The reason that the latter is preferred is that it is easier to
>>> maintain the data in a consistent form (factors maintain consistency
>>> and are easy to check in the output from str() or summary(), whereas
>>> indicator columns have inter-column dependencies that must be checked
>>> separately) and the "when appropriate" clause above. ?Determining a
>>> useful parameterization of a linear model incorporating factors is
>>> subtle and a lot of code in the R function model.matrix is devoted to
>>> a symbolic analysis designed to get this right. ?Also, you can, if you
>>> wish, change the parameterization (see ?contrasts).
>>>
>>
>>
>>
>> --
>> Raldo
>>
>



-- 
Raldo



From h.wickham at gmail.com  Sat Sep 26 23:18:44 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 26 Sep 2009 16:18:44 -0500
Subject: [R-sig-ME] year and site
In-Reply-To: <40e66e0b0909260758k3d5de0b1k3133af6682afcc17@mail.gmail.com>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
	<f8e6ff050909260717k2e18cd32y5a0d4a478057b649@mail.gmail.com> 
	<40e66e0b0909260758k3d5de0b1k3133af6682afcc17@mail.gmail.com>
Message-ID: <f8e6ff050909261418sfaa88b8o7f2a2697502e0218@mail.gmail.com>

On Sat, Sep 26, 2009 at 9:58 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Sat, Sep 26, 2009 at 9:17 AM, hadley wickham <h.wickham at gmail.com> wrote:
>>> in ecology year a study is done in, and the site it is done at, are
>>> obvious random effects.
>>
>> You're picking the years at random? - that's a pretty impressive study design!
>
> As I'm sure you realize, Hadley, it is the effects that are random,
> not the years. ?If I have studied a particular location for the last
> three years and I use a fixed-effect for the years in my model then I
> can "predict" the response for any one of those three years that I
> wish to. ?But I have no information on which to base a prediction for
> next year, which is usually what I want to do. ?(I am assuming the
> year is being modeled as a categorical variable rather than in terms
> of trends.)
>
> Using random effects for the year allows me to characterize the
> variability between years and that does help me in characterizing the
> variability for the next year.

I forgot to add a ;) to my initial comment - I was really more poking
at "are obvious random effects". It is _useful_ to model year as a
random effect, but don't we need to limit the scope of our inference
to the scope of the experimental randomisation?  To extend the scope
of inference to all years we need to make some additional assumptions
- that these three years are representative (in some sense) and that
there is no long term trend (and probably some others).

While the locations are also unlikely to be picked at random, we often
make more of an effort to randomise their location within a study
area.  Until a time machine is invented, we are limited to a
convenience sample of years.

Hadley

-- 
http://had.co.nz/



From wkmor1 at gmail.com  Sun Sep 27 00:17:23 2009
From: wkmor1 at gmail.com (Will Morris)
Date: Sun, 27 Sep 2009 08:17:23 +1000
Subject: [R-sig-ME] year and site
In-Reply-To: <OF9BD01F8A.A2FD5AF0-ON8625763D.006DFCB8-8625763D.006E787D@unl.edu>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>
	<-2184813634866656385@unknownmsgid>
	<OF9BD01F8A.A2FD5AF0-ON8625763D.006DFCB8-8625763D.006E787D@unl.edu>
Message-ID: <a5dabfa60909261517h7bbec593j946f3babcdb78a8b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090927/ed7bc58b/attachment.pl>

From atyre2 at unlnotes.unl.edu  Sat Sep 26 22:01:08 2009
From: atyre2 at unlnotes.unl.edu (Andrew J Tyre)
Date: Sat, 26 Sep 2009 15:01:08 -0500
Subject: [R-sig-ME] year and site
In-Reply-To: <40e66e0b0909260758k3d5de0b1k3133af6682afcc17@mail.gmail.com>
References: <OF1A6C0974.35800B9A-ON8625763D.0046CD3E-8625763D.00478678@unl.edu>	<f8e6ff050909260717k2e18cd32y5a0d4a478057b649@mail.gmail.com>
	<40e66e0b0909260758k3d5de0b1k3133af6682afcc17@mail.gmail.com>
Message-ID: <OFDD6E9C38.F375CF3E-ON8625763D.006D8D70-8625763D.006DED74@unl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090926/478111de/attachment.pl>

From bolker at ufl.edu  Sun Sep 27 19:08:20 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 27 Sep 2009 13:08:20 -0400
Subject: [R-sig-ME] Calculating SE from GLMM results (using glmer{lme4})
In-Reply-To: <30406dd0909260123p70eae67ehcdf39687b56fb778@mail.gmail.com>
References: <30406dd0909232305k3edcecedi396c9bb6e8655833@mail.gmail.com>	
	<4ABB724B.3080804@ufl.edu>
	<30406dd0909260123p70eae67ehcdf39687b56fb778@mail.gmail.com>
Message-ID: <4ABF9C04.80600@ufl.edu>

Raldo Kruger wrote:
> Hi Ben,
> 
> Thanks for your help. See my responses below (~~~).
> 
> Regards,
> Raldo

[snip]
> 
>  
>>  It's also
>> worth considering whether you are really getting reliable answers based
>> on only 4 sites -- I would also try this with Site as a fixed effect
>> and see whether the answers differ considerably.  (I know that,
>> philosophically, Site and Year are both random effects, and you may
>> run into trouble with reviewers who are used to classical ANOVA
> 
> ~~~ I've been using glmer, and it doesn't seem to accept a model with
> no random factors. Is ~~~that true, and if not, how can i  write the
> model without a random factor so that it is ~~~accepted by glmer?

  If you have a model with no random factors, then glm() should work
fine (although be aware that the likelihoods/AIC values will not be
directly comparable between glm() and glmer())



From raldo.kruger at gmail.com  Tue Sep 29 15:09:15 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Tue, 29 Sep 2009 15:09:15 +0200
Subject: [R-sig-ME] p-value for glmer with quasipoisson family
Message-ID: <30406dd0909290609t1c32ec02w92706fc9eeb5f1e1@mail.gmail.com>

Hi all,

How come there is no p-value displayed in the summary of the results
of glmer when using the quasipoisson family? Is there a way of
extracting the p-values from the results?

Thanks,
Raldo

> summary(ex5m_r)
Generalized linear mixed model fit by the Laplace approximation
Formula: Plants ~ Treat + Year + (1 | Site)
   Data: ex5m
  AIC  BIC logLik deviance
 4685 4719  -2336     4671
Random effects:
 Groups   Name        Variance Std.Dev.
 Site     (Intercept)  3.550   1.8841
 Residual             12.957   3.5996
Number of obs: 928, groups: Site, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.02627    0.68130   1.506
TreatGr     -0.38019    0.17078  -2.226
TreatK      -0.84274    0.19838  -4.248
TreatN       0.04644    0.15215   0.305
Yeartwo      0.66848    0.12931   5.170

Correlation of Fixed Effects:
        (Intr) TretGr TreatK TreatN
TreatGr -0.102
TreatK  -0.088  0.350
TreatN  -0.114  0.456  0.392
Yeartwo -0.125  0.000  0.000  0.000



From Kate.Pressland at bristol.ac.uk  Tue Sep 29 15:52:38 2009
From: Kate.Pressland at bristol.ac.uk (CL Pressland)
Date: Tue, 29 Sep 2009 14:52:38 +0100
Subject: [R-sig-ME] p-value for glmer with quasipoisson family
In-Reply-To: <30406dd0909290609t1c32ec02w92706fc9eeb5f1e1@mail.gmail.com>
References: <30406dd0909290609t1c32ec02w92706fc9eeb5f1e1@mail.gmail.com>
Message-ID: <5D01C86D82FDF3D16638CA13@bio-mammal03.bio.bris.ac.uk>

Please check the archive - there is a lot written on here explaining why 
lme4 does not give p values, unless you're using a MCMC approach which is 
better able to estimate the parameters.

In particular see: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q3/002833.html

--On 29 September 2009 15:09 +0200 Raldo Kruger <raldo.kruger at gmail.com> 
wrote:

> Hi all,
>
> How come there is no p-value displayed in the summary of the results
> of glmer when using the quasipoisson family? Is there a way of
> extracting the p-values from the results?
>
> Thanks,
> Raldo
>
>> summary(ex5m_r)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Plants ~ Treat + Year + (1 | Site)
>    Data: ex5m
>   AIC  BIC logLik deviance
>  4685 4719  -2336     4671
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Site     (Intercept)  3.550   1.8841
>  Residual             12.957   3.5996
> Number of obs: 928, groups: Site, 8
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  1.02627    0.68130   1.506
> TreatGr     -0.38019    0.17078  -2.226
> TreatK      -0.84274    0.19838  -4.248
> TreatN       0.04644    0.15215   0.305
> Yeartwo      0.66848    0.12931   5.170
>
> Correlation of Fixed Effects:
>         (Intr) TretGr TreatK TreatN
> TreatGr -0.102
> TreatK  -0.088  0.350
> TreatN  -0.114  0.456  0.392
> Yeartwo -0.125  0.000  0.000  0.000
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From mjuanjorda at gmail.com  Tue Sep 29 17:00:24 2009
From: mjuanjorda at gmail.com (Maria Jose Juan Jorda)
Date: Tue, 29 Sep 2009 17:00:24 +0200
Subject: [R-sig-ME] Estimate confidence intervals for a linear combination
	of coefficients for a GLS model. Something similar to
	ESTIMABLE function from gmodels package??
Message-ID: <9bcbdf360909290800q6185e1a6k35ee19b4d08298ff@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090929/4e8f09cc/attachment.pl>

From zamani_hossain at yahoo.com  Tue Sep 29 17:04:59 2009
From: zamani_hossain at yahoo.com (hossain zamani)
Date: Tue, 29 Sep 2009 08:04:59 -0700 (PDT)
Subject: [R-sig-ME] need help in glm
Message-ID: <456079.40196.qm@web32703.mail.mud.yahoo.com>

Dear all,
I am a R using. I have a mixed Poisson regression. my function is:

?## P(N=k)=[(a+2)/a ](lambda^k)*[((a+2/a+1)+lambda)^(-k-1)-(a+2+lambda)^(-k-1)]; lambda=a0+a1*x1+a2*x2

?and I've attached in a pdf file also.This is a poisson mixed with a weighted exponential distribution in the case that E(theta)=1(theta=random.effect). in fact this model is?same as a Poisson-inverse gaussian or Poisson-lognormal regression.I want to estimate the parameters by fitting this model on my data and then compare with Poisson regression(glm).Which package in R can be used.
?with the best wishes
?Zamani.H




      
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mixed poisson.pdf
Type: application/pdf
Size: 55072 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090929/d6644c83/attachment.pdf>

From nikko at hailmail.net  Tue Sep 29 18:18:30 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Tue, 29 Sep 2009 09:18:30 -0700
Subject: [R-sig-ME]  need help in glm
In-Reply-To: <mailman.3634.1254240304.25490.r-sig-mixed-models@r-project.org>
References: <mailman.3634.1254240304.25490.r-sig-mixed-models@r-project.org>
Message-ID: <1254241110.26971.1337195593@webmail.messagingengine.com>

Hi,
You will have to create your own family function to fit 
using glm. look at family.glm in the stats package. You might also
check VGAM and gamlss.mx to see if this or something similar is already
implemented.

Nicholas
essage: 4
> Date: Tue, 29 Sep 2009 08:04:59 -0700 (PDT)
> From: hossain zamani <zamani_hossain at yahoo.com>
> Subject: [R-sig-ME] need help in glm
> To: R-SIG-Mixed-Models at R-project.org
> Message-ID: <456079.40196.qm at web32703.mail.mud.yahoo.com>
> Content-Type: text/plain; charset="iso-8859-1"
> 
> Dear all,
> I am a R using. I have a mixed Poisson regression. my function is:
> 
> ?## P(N=k)=[(a+2)/a
> ](lambda^k)*[((a+2/a+1)+lambda)^(-k-1)-(a+2+lambda)^(-k-1)];
> lambda=a0+a1*x1+a2*x2
> 
> ?and I've attached in a pdf file also.This is a poisson mixed with a
> weighted exponential distribution in the case that
> E(theta)=1(theta=random.effect). in fact this model is?same as a
> Poisson-inverse gaussian or Poisson-lognormal regression.I want to
> estimate the parameters by fitting this model on my data and then compare
> with Poisson regression(glm).Which package in R can be used.
> ?with the best wishes
> ?Zamani.H
> 
>



From desja004 at umn.edu  Tue Sep 29 19:55:57 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 29 Sep 2009 12:55:57 -0500
Subject: [R-sig-ME] lme vs. lmer
Message-ID: <4AC24A2D.2090606@umn.edu>

I've started working through Pinheiro & Bates, 2000 and noticed the use 
of lme from the nlme package. I am curious if lmer from lme4 has 
superseded lme or if lme still holds its own? The reason I ask is that I 
have taken a few classes where we've solely used lmer and just read 
about lme today. If both functions are on equal footing, can the 
p-values from lme be trusted?
Thanks!
Chris

-- 
Christopher David Desjardins, Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of Minnesota



From bolker at ufl.edu  Tue Sep 29 20:02:33 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 29 Sep 2009 14:02:33 -0400
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC24A2D.2090606@umn.edu>
References: <4AC24A2D.2090606@umn.edu>
Message-ID: <4AC24BB9.5000609@ufl.edu>


Christopher David Desjardins wrote:
> I've started working through Pinheiro & Bates, 2000 and noticed the use 
> of lme from the nlme package. I am curious if lmer from lme4 has 
> superseded lme or if lme still holds its own? The reason I ask is that I 
> have taken a few classes where we've solely used lmer and just read 
> about lme today. If both functions are on equal footing, can the 
> p-values from lme be trusted?
> Thanks!
> Chris
> 

  You should read the extended discussion of p-values, degrees of
freedom, etc. that is on the R wiki (I think) and referenced from the R
FAQ.  At least in my opinion, (n)lme is still fine (and indeed necessary
at this stage for fitting heteroscedastic and correlated models).  The
df/p-value estimates, however, are "use at your own risk" -- you'll have
to read the literature and decide for yourself.

  I still think there's room for someone to implement (at least)
Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
sake of comparison, but I'm not volunteering.

  cheers
    Ben Bolker

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From desja004 at umn.edu  Tue Sep 29 20:17:14 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 29 Sep 2009 13:17:14 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC24BB9.5000609@ufl.edu>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
Message-ID: <4AC24F2A.6010600@umn.edu>

Thanks Ben. I knew about the discussion with the dfs and p-values. I 
guess what I was really wondering was if lme was deprecated, which 
you've answered.
Chris

Ben Bolker wrote:
> Christopher David Desjardins wrote:
>   
>> I've started working through Pinheiro & Bates, 2000 and noticed the use 
>> of lme from the nlme package. I am curious if lmer from lme4 has 
>> superseded lme or if lme still holds its own? The reason I ask is that I 
>> have taken a few classes where we've solely used lmer and just read 
>> about lme today. If both functions are on equal footing, can the 
>> p-values from lme be trusted?
>> Thanks!
>> Chris
>>
>>     
>
>   You should read the extended discussion of p-values, degrees of
> freedom, etc. that is on the R wiki (I think) and referenced from the R
> FAQ.  At least in my opinion, (n)lme is still fine (and indeed necessary
> at this stage for fitting heteroscedastic and correlated models).  The
> df/p-value estimates, however, are "use at your own risk" -- you'll have
> to read the literature and decide for yourself.
>
>   I still think there's room for someone to implement (at least)
> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
> sake of comparison, but I'm not volunteering.
>
>   cheers
>     Ben Bolker
>
>   

-- 
Christopher David Desjardins, Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of Minnesota
http://cddesjardins.wordpress.com/



From bates at stat.wisc.edu  Tue Sep 29 20:32:16 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Sep 2009 13:32:16 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC24BB9.5000609@ufl.edu>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
Message-ID: <40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>

On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:

> Christopher David Desjardins wrote:
>> I've started working through Pinheiro & Bates, 2000 and noticed the use
>> of lme from the nlme package. I am curious if lmer from lme4 has
>> superseded lme or if lme still holds its own? The reason I ask is that I
>> have taken a few classes where we've solely used lmer and just read
>> about lme today. If both functions are on equal footing, can the
>> p-values from lme be trusted?
>> Thanks!
>> Chris

> ?You should read the extended discussion of p-values, degrees of
> freedom, etc. that is on the R wiki (I think) and referenced from the R
> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed necessary
> at this stage for fitting heteroscedastic and correlated models). ?The
> df/p-value estimates, however, are "use at your own risk" -- you'll have
> to read the literature and decide for yourself.

> ?I still think there's room for someone to implement (at least)
> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
> sake of comparison, but I'm not volunteering.

You may need to define them first.  Many of the formulas in the mixed
models literature assume a hierarchical structure in the random
effects - certainly we used such a formula for calculating the
denominator degrees of freedom in the nlme package. But lme4 allows
for fully or partially crossed random effects so you can't think in
terms of "levels" of random effects.

Referring to the "Satterthwaite and Kenward-Roger corrections" gives
the impression that these are well-known formulas and implementing
them would be a simple matter of writing a few lines of code.  I don't
think it is.  I would be very pleased to incorporate such code if it
could be written but, as I said, I don't even know if such things are
defined in the general case, let alone easy to calculate.

I am not trying to be argumentative (although of late I seem to have
succeeded in being that).  I'm just saying that I don't think this is
trivial. (It I wanted to be argumentative I would say that it is
difficult and, for the most part, irrelevant. :-)



From bates at stat.wisc.edu  Tue Sep 29 20:36:06 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Sep 2009 13:36:06 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC24F2A.6010600@umn.edu>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<4AC24F2A.6010600@umn.edu>
Message-ID: <40e66e0b0909291136j27bc3dbbi817bcfcc8ecc5d25@mail.gmail.com>

On Tue, Sep 29, 2009 at 1:17 PM, Christopher David Desjardins
<desja004 at umn.edu> wrote:
> Thanks Ben. I knew about the discussion with the dfs and p-values. I guess
> what I was really wondering was if lme was deprecated, which you've
> answered.
> Chris

As Ben said, lmer does not currently allow for parameterized
correlation structures or parameterized weight functions as lme does.
If you need those you should use lme.  For models that can be fit by
both I would use lmer.  It is more reliable and usually faster.

>
> Ben Bolker wrote:
>>
>> Christopher David Desjardins wrote:
>>
>>>
>>> I've started working through Pinheiro & Bates, 2000 and noticed the use
>>> of lme from the nlme package. I am curious if lmer from lme4 has superseded
>>> lme or if lme still holds its own? The reason I ask is that I have taken a
>>> few classes where we've solely used lmer and just read about lme today. If
>>> both functions are on equal footing, can the p-values from lme be trusted?
>>> Thanks!
>>> Chris
>>>
>>>
>>
>> ?You should read the extended discussion of p-values, degrees of
>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed necessary
>> at this stage for fitting heteroscedastic and correlated models). ?The
>> df/p-value estimates, however, are "use at your own risk" -- you'll have
>> to read the literature and decide for yourself.
>>
>> ?I still think there's room for someone to implement (at least)
>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
>> sake of comparison, but I'm not volunteering.
>>
>> ?cheers
>> ? ?Ben Bolker
>>
>>
>
> --
> Christopher David Desjardins, Ph.D. Student
> Quantitative Methods in Education
> Department of Educational Psychology
> University of Minnesota
> http://cddesjardins.wordpress.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Sep 29 20:45:34 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 29 Sep 2009 14:45:34 -0400
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
Message-ID: <4AC255CE.1090904@ufl.edu>

Douglas Bates wrote:
> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
> 
>> Christopher David Desjardins wrote:
>>> I've started working through Pinheiro & Bates, 2000 and noticed the use
>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>> superseded lme or if lme still holds its own? The reason I ask is that I
>>> have taken a few classes where we've solely used lmer and just read
>>> about lme today. If both functions are on equal footing, can the
>>> p-values from lme be trusted?
>>> Thanks!
>>> Chris
> 
>>  You should read the extended discussion of p-values, degrees of
>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>> FAQ.  At least in my opinion, (n)lme is still fine (and indeed necessary
>> at this stage for fitting heteroscedastic and correlated models).  The
>> df/p-value estimates, however, are "use at your own risk" -- you'll have
>> to read the literature and decide for yourself.
> 
>>  I still think there's room for someone to implement (at least)
>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
>> sake of comparison, but I'm not volunteering.
> 
> You may need to define them first.  Many of the formulas in the mixed
> models literature assume a hierarchical structure in the random
> effects - certainly we used such a formula for calculating the
> denominator degrees of freedom in the nlme package. But lme4 allows
> for fully or partially crossed random effects so you can't think in
> terms of "levels" of random effects.
> 
> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
> the impression that these are well-known formulas and implementing
> them would be a simple matter of writing a few lines of code.  I don't
> think it is.  I would be very pleased to incorporate such code if it
> could be written but, as I said, I don't even know if such things are
> defined in the general case, let alone easy to calculate.
> 
> I am not trying to be argumentative (although of late I seem to have
> succeeded in being that).  I'm just saying that I don't think this is
> trivial. (It I wanted to be argumentative I would say that it is
> difficult and, for the most part, irrelevant. :-)

  Fair enough. Actually, I'm not sure I meant implementing them in lmer
-- even implementing them in nlme would be useful (and perhaps more
straightforward, if not trivial). I also wouldn't impose the requirement
that they have to be feasible for huge data sets -- I'm just curious if
they can be implemented within lme in a relatively straightforward/
boneheaded way.
   But again, this is very far down my to-do list (and at the edge
of my abilities) and completely off yours, so unless someone else bites
it won't happen.

  cheers
    Ben Bolker



From p.dalgaard at biostat.ku.dk  Tue Sep 29 22:58:42 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 29 Sep 2009 22:58:42 +0200
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC255CE.1090904@ufl.edu>
References: <4AC24A2D.2090606@umn.edu>
	<4AC24BB9.5000609@ufl.edu>	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu>
Message-ID: <4AC27502.7070104@biostat.ku.dk>

Ben Bolker wrote:
> Douglas Bates wrote:
>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>
>>> Christopher David Desjardins wrote:
>>>> I've started working through Pinheiro & Bates, 2000 and noticed the use
>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>> superseded lme or if lme still holds its own? The reason I ask is that I
>>>> have taken a few classes where we've solely used lmer and just read
>>>> about lme today. If both functions are on equal footing, can the
>>>> p-values from lme be trusted?
>>>> Thanks!
>>>> Chris
>>>  You should read the extended discussion of p-values, degrees of
>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>>> FAQ.  At least in my opinion, (n)lme is still fine (and indeed necessary
>>> at this stage for fitting heteroscedastic and correlated models).  The
>>> df/p-value estimates, however, are "use at your own risk" -- you'll have
>>> to read the literature and decide for yourself.
>>>  I still think there's room for someone to implement (at least)
>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
>>> sake of comparison, but I'm not volunteering.
>> You may need to define them first.  Many of the formulas in the mixed
>> models literature assume a hierarchical structure in the random
>> effects - certainly we used such a formula for calculating the
>> denominator degrees of freedom in the nlme package. But lme4 allows
>> for fully or partially crossed random effects so you can't think in
>> terms of "levels" of random effects.
>>
>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>> the impression that these are well-known formulas and implementing
>> them would be a simple matter of writing a few lines of code.  I don't
>> think it is.  I would be very pleased to incorporate such code if it
>> could be written but, as I said, I don't even know if such things are
>> defined in the general case, let alone easy to calculate.
>>
>> I am not trying to be argumentative (although of late I seem to have
>> succeeded in being that).  I'm just saying that I don't think this is
>> trivial. (It I wanted to be argumentative I would say that it is
>> difficult and, for the most part, irrelevant. :-)
> 
>   Fair enough. Actually, I'm not sure I meant implementing them in lmer
> -- even implementing them in nlme would be useful (and perhaps more
> straightforward, if not trivial). I also wouldn't impose the requirement
> that they have to be feasible for huge data sets -- I'm just curious if
> they can be implemented within lme in a relatively straightforward/
> boneheaded way.
>    But again, this is very far down my to-do list (and at the edge
> of my abilities) and completely off yours, so unless someone else bites
> it won't happen.

I don't think (n)lme is all that easy either; you still need to sort out 
the connection between its multilevel formulation and the projection 
matrices in the K-R paper. In both nlme and lme4, an implementation is 
almost certainly possible, although probably complicated and perhaps at 
the expense of all computational efficiency.

One main problem is that even when they can be calculated, the 
corrections rely on a normal distribution assumption which is more than 
likely wrong in practice. This isn't any different from ordinary 
t-tests: once you get into the single-digit df regime, you really don't 
know what you are doing, and if there are more than 30 df, the normal 
approximation works well enough without the correction.

Accordingly, I tend to see low df more as a warning flag than as 
something that gives accurate p values, and I sometimes wonder whether 
there is a way to raise such a flag more expediently.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From bates at stat.wisc.edu  Tue Sep 29 23:50:43 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Sep 2009 16:50:43 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <4AC27502.7070104@biostat.ku.dk>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
Message-ID: <40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>

On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
<p.dalgaard at biostat.ku.dk> wrote:
> Ben Bolker wrote:
>>
>> Douglas Bates wrote:
>>>
>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>
>>>> Christopher David Desjardins wrote:
>>>>>
>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the use
>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>>> superseded lme or if lme still holds its own? The reason I ask is that
>>>>> I
>>>>> have taken a few classes where we've solely used lmer and just read
>>>>> about lme today. If both functions are on equal footing, can the
>>>>> p-values from lme be trusted?
>>>>> Thanks!
>>>>> Chris
>>>>
>>>> ?You should read the extended discussion of p-values, degrees of
>>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed necessary
>>>> at this stage for fitting heteroscedastic and correlated models). ?The
>>>> df/p-value estimates, however, are "use at your own risk" -- you'll have
>>>> to read the literature and decide for yourself.
>>>> ?I still think there's room for someone to implement (at least)
>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for the
>>>> sake of comparison, but I'm not volunteering.
>>>
>>> You may need to define them first. ?Many of the formulas in the mixed
>>> models literature assume a hierarchical structure in the random
>>> effects - certainly we used such a formula for calculating the
>>> denominator degrees of freedom in the nlme package. But lme4 allows
>>> for fully or partially crossed random effects so you can't think in
>>> terms of "levels" of random effects.
>>>
>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>>> the impression that these are well-known formulas and implementing
>>> them would be a simple matter of writing a few lines of code. ?I don't
>>> think it is. ?I would be very pleased to incorporate such code if it
>>> could be written but, as I said, I don't even know if such things are
>>> defined in the general case, let alone easy to calculate.
>>>
>>> I am not trying to be argumentative (although of late I seem to have
>>> succeeded in being that). ?I'm just saying that I don't think this is
>>> trivial. (It I wanted to be argumentative I would say that it is
>>> difficult and, for the most part, irrelevant. :-)
>>
>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
>> -- even implementing them in nlme would be useful (and perhaps more
>> straightforward, if not trivial). I also wouldn't impose the requirement
>> that they have to be feasible for huge data sets -- I'm just curious if
>> they can be implemented within lme in a relatively straightforward/
>> boneheaded way.
>> ? But again, this is very far down my to-do list (and at the edge
>> of my abilities) and completely off yours, so unless someone else bites
>> it won't happen.
>
> I don't think (n)lme is all that easy either; you still need to sort out the
> connection between its multilevel formulation and the projection matrices in
> the K-R paper. In both nlme and lme4, an implementation is almost certainly
> possible, although probably complicated and perhaps at the expense of all
> computational efficiency.
>
> One main problem is that even when they can be calculated, the corrections
> rely on a normal distribution assumption which is more than likely wrong in
> practice. This isn't any different from ordinary t-tests: once you get into
> the single-digit df regime, you really don't know what you are doing, and if
> there are more than 30 df, the normal approximation works well enough
> without the correction.
>
> Accordingly, I tend to see low df more as a warning flag than as something
> that gives accurate p values, and I sometimes wonder whether there is a way
> to raise such a flag more expediently.

I agree, wholeheartedly.

My general advice to those who are required to produce a p-value for a
particular fixed-effects term in a mixed-effects model is to use a
likelihood ratio test.  Fit the model including that term using
maximum likelihood (i.e. REML = FALSE), fit it again without the term
and compare the results using anova.

The likelihood ratio statistic will be compared to a chi-squared
distribution to get a p-value and this process is somewhat suspect
when the degrees of freedom would be small.  However, so many other
things could be going wrong when you are fitting complex models to few
observations that this may be the least of your worries.

I appreciate that for Ben and others in fields like ecology the need
to incorporate many different possible terms in models for
comparatively small data sets may be inevitable.  But it is also
inevitable that the precision of the information one can extract from
such small data sets is low.  Reducing such analysis to a set of
p-values for various terms and treating these p-values as if they were
precisely determined is an oversimplification, even when journal
editors insist on such an oversimplification.



From bolker at ufl.edu  Wed Sep 30 02:52:39 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 29 Sep 2009 20:52:39 -0400
Subject: [R-sig-ME] need help in glm
In-Reply-To: <456079.40196.qm@web32703.mail.mud.yahoo.com>
References: <456079.40196.qm@web32703.mail.mud.yahoo.com>
Message-ID: <4AC2ABD7.80304@ufl.edu>

  Since you have a closed-form expression for the likelihood, you can
use optim() [base package] directly, or use mle [stats4], or mle2 [bbmle].

hossain zamani wrote:
> Dear all, I am a R using. I have a mixed Poisson regression. my
> function is:
> 
> ## P(N=k)=[(a+2)/a
> ](lambda^k)*[((a+2/a+1)+lambda)^(-k-1)-(a+2+lambda)^(-k-1)];
> lambda=a0+a1*x1+a2*x2
> 
> and I've attached in a pdf file also.This is a poisson mixed with a
> weighted exponential distribution in the case that
> E(theta)=1(theta=random.effect). in fact this model is same as a
> Poisson-inverse gaussian or Poisson-lognormal regression.I want to
> estimate the parameters by fitting this model on my data and then
> compare with Poisson regression(glm).Which package in R can be used. 
> with the best wishes Zamani.H
> 
> 
> 
> 
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From robert.espesser at lpl-aix.fr  Wed Sep 30 10:09:50 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Wed, 30 Sep 2009 10:09:50 +0200
Subject: [R-sig-ME]  lme vs. lmer and contrasts
In-Reply-To: <40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu>
	<4AC24BB9.5000609@ufl.edu>	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>	<4AC255CE.1090904@ufl.edu>
	<4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
Message-ID: <4AC3124E.2030802@lpl-aix.fr>

In the last discussion about "lme vs. lmer"  (see below) , D. Bates 
adviced to
use anova between 2 mixed models to test a fixed effect.

1) Does it mean that mcmc pvalues have to be disregarded finally ?

2) When the fixed effect is a factor, anova returns the whole 
significance of the factor,
but no information about  the levels of the factor. How is it possible 
to get it  ?
(I am thinking about  contrast analysis for a factor with more than 2 
levels)

3) As a side question:
The mixed models are said to be robust to unbalanced data.
Let suppose a 4 levels factor, with a  number of measures which is 
different for
each level (or at least for one level). In what extend can I trust 
outputs of a mixed model with
typical contrasts (treatment, sdif, ordered) applied to such a factor ?

Thank you very much for your help

R. Espesser
Laboratoire Parole et Langage,
Universit? de Provence/CNRS,
5 av. Pasteur, Aix en provence (France)


Douglas Bates a ?crit :
>
> [...]
>
> My general advice to those who are required to produce a p-value for a
> particular fixed-effects term in a mixed-effects model is to use a
> likelihood ratio test.  Fit the model including that term using
> maximum likelihood (i.e. REML = FALSE), fit it again without the term
> and compare the results using anova.
>
> The likelihood ratio statistic will be compared to a chi-squared
> distribution to get a p-value and this process is somewhat suspect
> when the degrees of freedom would be small.  However, so many other
> things could be going wrong when you are fitting complex models to few
> observations that this may be the least of your worries.
>
>



From raldo.kruger at gmail.com  Wed Sep 30 11:45:00 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Wed, 30 Sep 2009 11:45:00 +0200
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
Message-ID: <30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>

Hi all, I've been following this thread since it's of interest to the
analyses i'm currenty doing.
My question is, how does one do model simplification with lmer (or
glmer in my case) if there are no p-values (since p-values are used to
determine which terms to drop, and the drop1 function does not work
for glmer)?

And Douglas, could you provide a working example of getting the
p-values as you described, preferably with glmer (glmer does not have
the REML=FALSE option)? I understand the 1st part of fitting two
models, one with and one without the term of interest... So does it
mean one has to do this for every term in order to get all the
p-values?

Many thanks, Raldo

On 9/29/09, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
> <p.dalgaard at biostat.ku.dk> wrote:
>> Ben Bolker wrote:
>>>
>>> Douglas Bates wrote:
>>>>
>>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>
>>>>> Christopher David Desjardins wrote:
>>>>>>
>>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the
>>>>>> use
>>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>>>> superseded lme or if lme still holds its own? The reason I ask is that
>>>>>> I
>>>>>> have taken a few classes where we've solely used lmer and just read
>>>>>> about lme today. If both functions are on equal footing, can the
>>>>>> p-values from lme be trusted?
>>>>>> Thanks!
>>>>>> Chris
>>>>>
>>>>> ?You should read the extended discussion of p-values, degrees of
>>>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed
>>>>> necessary
>>>>> at this stage for fitting heteroscedastic and correlated models). ?The
>>>>> df/p-value estimates, however, are "use at your own risk" -- you'll
>>>>> have
>>>>> to read the literature and decide for yourself.
>>>>> ?I still think there's room for someone to implement (at least)
>>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for
>>>>> the
>>>>> sake of comparison, but I'm not volunteering.
>>>>
>>>> You may need to define them first. ?Many of the formulas in the mixed
>>>> models literature assume a hierarchical structure in the random
>>>> effects - certainly we used such a formula for calculating the
>>>> denominator degrees of freedom in the nlme package. But lme4 allows
>>>> for fully or partially crossed random effects so you can't think in
>>>> terms of "levels" of random effects.
>>>>
>>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>>>> the impression that these are well-known formulas and implementing
>>>> them would be a simple matter of writing a few lines of code. ?I don't
>>>> think it is. ?I would be very pleased to incorporate such code if it
>>>> could be written but, as I said, I don't even know if such things are
>>>> defined in the general case, let alone easy to calculate.
>>>>
>>>> I am not trying to be argumentative (although of late I seem to have
>>>> succeeded in being that). ?I'm just saying that I don't think this is
>>>> trivial. (It I wanted to be argumentative I would say that it is
>>>> difficult and, for the most part, irrelevant. :-)
>>>
>>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
>>> -- even implementing them in nlme would be useful (and perhaps more
>>> straightforward, if not trivial). I also wouldn't impose the requirement
>>> that they have to be feasible for huge data sets -- I'm just curious if
>>> they can be implemented within lme in a relatively straightforward/
>>> boneheaded way.
>>> ? But again, this is very far down my to-do list (and at the edge
>>> of my abilities) and completely off yours, so unless someone else bites
>>> it won't happen.
>>
>> I don't think (n)lme is all that easy either; you still need to sort out
>> the
>> connection between its multilevel formulation and the projection matrices
>> in
>> the K-R paper. In both nlme and lme4, an implementation is almost
>> certainly
>> possible, although probably complicated and perhaps at the expense of all
>> computational efficiency.
>>
>> One main problem is that even when they can be calculated, the corrections
>> rely on a normal distribution assumption which is more than likely wrong
>> in
>> practice. This isn't any different from ordinary t-tests: once you get
>> into
>> the single-digit df regime, you really don't know what you are doing, and
>> if
>> there are more than 30 df, the normal approximation works well enough
>> without the correction.
>>
>> Accordingly, I tend to see low df more as a warning flag than as something
>> that gives accurate p values, and I sometimes wonder whether there is a
>> way
>> to raise such a flag more expediently.
>
> I agree, wholeheartedly.
>
> My general advice to those who are required to produce a p-value for a
> particular fixed-effects term in a mixed-effects model is to use a
> likelihood ratio test.  Fit the model including that term using
> maximum likelihood (i.e. REML = FALSE), fit it again without the term
> and compare the results using anova.
>
> The likelihood ratio statistic will be compared to a chi-squared
> distribution to get a p-value and this process is somewhat suspect
> when the degrees of freedom would be small.  However, so many other
> things could be going wrong when you are fitting complex models to few
> observations that this may be the least of your worries.
>
> I appreciate that for Ben and others in fields like ecology the need
> to incorporate many different possible terms in models for
> comparatively small data sets may be inevitable.  But it is also
> inevitable that the precision of the information one can extract from
> such small data sets is low.  Reducing such analysis to a set of
> p-values for various terms and treating these p-values as if they were
> precisely determined is an oversimplification, even when journal
> editors insist on such an oversimplification.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Sent from my mobile device

Raldo



From desja004 at umn.edu  Wed Sep 30 17:22:17 2009
From: desja004 at umn.edu (desja004 at umn.edu)
Date: 30 Sep 2009 10:22:17 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
Message-ID: <Gophermail.2.0.0909301022170.523@vs-a.tc.umn.edu>

Hi Raldo,
I think you have 3 options if you're looking for an empirically driven way 
to do model simplification and remove fixed effects. There of course may be 
others.

1) Likelihood ratio test using anova()
2) Model comparison with AIC
3) Model comparison with BIC

Pinheiro & Bates (2000) discuss their usage.

I am not sure which one is preferred but I do know that most people seem to 
be a little leery of BIC and favor using AIC over it. Personally, I would 
let theory dictate what terms to remove not p-values.

HTH,
Chris


On Sep 30 2009, Raldo Kruger wrote:

>Hi all, I've been following this thread since it's of interest to the
>analyses i'm currenty doing.
>My question is, how does one do model simplification with lmer (or
>glmer in my case) if there are no p-values (since p-values are used to
>determine which terms to drop, and the drop1 function does not work
>for glmer)?
>
>And Douglas, could you provide a working example of getting the
>p-values as you described, preferably with glmer (glmer does not have
>the REML=FALSE option)? I understand the 1st part of fitting two
>models, one with and one without the term of interest... So does it
>mean one has to do this for every term in order to get all the
>p-values?
>
>Many thanks, Raldo
>
>On 9/29/09, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
>> <p.dalgaard at biostat.ku.dk> wrote:
>>> Ben Bolker wrote:
>>>>
>>>> Douglas Bates wrote:
>>>>>
>>>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>>
>>>>>> Christopher David Desjardins wrote:
>>>>>>>
>>>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the
>>>>>>> use
>>>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>>>>> superseded lme or if lme still holds its own? The reason I ask is 
>>>>>>> that
>>>>>>> I
>>>>>>> have taken a few classes where we've solely used lmer and just read
>>>>>>> about lme today. If both functions are on equal footing, can the
>>>>>>> p-values from lme be trusted?
>>>>>>> Thanks!
>>>>>>> Chris
>>>>>>
>>>>>> ?You should read the extended discussion of p-values, degrees of
>>>>>> freedom, etc. that is on the R wiki (I think) and referenced from 
>>>>>> the R
>>>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed
>>>>>> necessary
>>>>>> at this stage for fitting heteroscedastic and correlated models). 
>>>>>> ?The
>>>>>> df/p-value estimates, however, are "use at your own risk" -- you'll
>>>>>> have
>>>>>> to read the literature and decide for yourself.
>>>>>> ?I still think there's room for someone to implement (at least)
>>>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for
>>>>>> the
>>>>>> sake of comparison, but I'm not volunteering.
>>>>>
>>>>> You may need to define them first. ?Many of the formulas in the mixed
>>>>> models literature assume a hierarchical structure in the random
>>>>> effects - certainly we used such a formula for calculating the
>>>>> denominator degrees of freedom in the nlme package. But lme4 allows
>>>>> for fully or partially crossed random effects so you can't think in
>>>>> terms of "levels" of random effects.
>>>>>
>>>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>>>>> the impression that these are well-known formulas and implementing
>>>>> them would be a simple matter of writing a few lines of code. ?I 
>>>>> don't
>>>>> think it is. ?I would be very pleased to incorporate such code if it
>>>>> could be written but, as I said, I don't even know if such things are
>>>>> defined in the general case, let alone easy to calculate.
>>>>>
>>>>> I am not trying to be argumentative (although of late I seem to have
>>>>> succeeded in being that). ?I'm just saying that I don't think this is
>>>>> trivial. (It I wanted to be argumentative I would say that it is
>>>>> difficult and, for the most part, irrelevant. :-)
>>>>
>>>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
>>>> -- even implementing them in nlme would be useful (and perhaps more
>>>> straightforward, if not trivial). I also wouldn't impose the 
>>>> requirement
>>>> that they have to be feasible for huge data sets -- I'm just curious if
>>>> they can be implemented within lme in a relatively straightforward/
>>>> boneheaded way.
>>>> ? But again, this is very far down my to-do list (and at the edge
>>>> of my abilities) and completely off yours, so unless someone else bites
>>>> it won't happen.
>>>
>>> I don't think (n)lme is all that easy either; you still need to sort out
>>> the
>>> connection between its multilevel formulation and the projection 
>>> matrices
>>> in
>>> the K-R paper. In both nlme and lme4, an implementation is almost
>>> certainly
>>> possible, although probably complicated and perhaps at the expense of 
>>> all
>>> computational efficiency.
>>>
>>> One main problem is that even when they can be calculated, the 
>>> corrections
>>> rely on a normal distribution assumption which is more than likely wrong
>>> in
>>> practice. This isn't any different from ordinary t-tests: once you get
>>> into
>>> the single-digit df regime, you really don't know what you are doing, 
>>> and
>>> if
>>> there are more than 30 df, the normal approximation works well enough
>>> without the correction.
>>>
>>> Accordingly, I tend to see low df more as a warning flag than as 
>>> something
>>> that gives accurate p values, and I sometimes wonder whether there is a
>>> way
>>> to raise such a flag more expediently.
>>
>> I agree, wholeheartedly.
>>
>> My general advice to those who are required to produce a p-value for a
>> particular fixed-effects term in a mixed-effects model is to use a
>> likelihood ratio test.  Fit the model including that term using
>> maximum likelihood (i.e. REML = FALSE), fit it again without the term
>> and compare the results using anova.
>>
>> The likelihood ratio statistic will be compared to a chi-squared
>> distribution to get a p-value and this process is somewhat suspect
>> when the degrees of freedom would be small.  However, so many other
>> things could be going wrong when you are fitting complex models to few
>> observations that this may be the least of your worries.
>>
>> I appreciate that for Ben and others in fields like ecology the need
>> to incorporate many different possible terms in models for
>> comparatively small data sets may be inevitable.  But it is also
>> inevitable that the precision of the information one can extract from
>> such small data sets is low.  Reducing such analysis to a set of
>> p-values for various terms and treating these p-values as if they were
>> precisely determined is an oversimplification, even when journal
>> editors insist on such an oversimplification.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



From nikko at hailmail.net  Wed Sep 30 17:39:17 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 30 Sep 2009 08:39:17 -0700
Subject: [R-sig-ME]   lme vs. lmer and contrasts
In-Reply-To: <mailman.3762.1254303915.25490.r-sig-mixed-models@r-project.org>
References: <mailman.3762.1254303915.25490.r-sig-mixed-models@r-project.org>
Message-ID: <1254325157.9455.1337380095@webmail.messagingengine.com>

Hi Robert, (and Raldo)
1) No, but when you have correlated random effects, mcmc is still not
working.
2) set up contrasts as in lm I believe the multcomp package works with
lme4, look at glht
3) About as much as the variability in your data, and whether or not
  it is a designed experiment, and whether you think the assumptions of
  the model hold,
  and if the effect size is meaningful and , ......

Which was the point of the whole discussion, and many others on this
list. 
Inference is hard (paraphrasing Barbie).
 <\begin Rant> P-values tend to sweep many important
factors about a model and interpreting them under the umbrella of
significance.
While unfortunately many journals still perpetuate the p-value, it is
possible to 
publish, write reports, and go about doing science without them. <\end
Rant>

for Raldo (from lme4 documentation, see cake)
str(cake)
print(fm1 <- lmer(angle ~ recipe * temperature + (1|recipe:replicate),
cake,
                  REML = FALSE), corr = FALSE)
print(fm2 <- lmer(angle ~ recipe + temperature + (1|recipe:replicate),
cake,
                  REML = FALSE), corr = FALSE)
print(fm3 <- lmer(angle ~ recipe + temp + (1|recipe:replicate), cake,
                  REML = FALSE), corr = FALSE)
anova(fm3, fm2, fm1)

Gives a p-value


Nicholas

> 
> ------------------------------
> 
> Message: 4
> Date: Wed, 30 Sep 2009 10:09:50 +0200
> From: espesser <robert.espesser at lpl-aix.fr>
> Subject: [R-sig-ME]  lme vs. lmer and contrasts
> To: "R-SIG-Mixed-Models at r-project.org"
> 	<R-SIG-Mixed-Models at r-project.org>
> Message-ID: <4AC3124E.2030802 at lpl-aix.fr>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> In the last discussion about "lme vs. lmer"  (see below) , D. Bates 
> adviced to
> use anova between 2 mixed models to test a fixed effect.
> 
> 1) Does it mean that mcmc pvalues have to be disregarded finally ?
> 
> 2) When the fixed effect is a factor, anova returns the whole 
> significance of the factor,
> but no information about  the levels of the factor. How is it possible 
> to get it  ?
> (I am thinking about  contrast analysis for a factor with more than 2 
> levels)
> 
> 3) As a side question:
> The mixed models are said to be robust to unbalanced data.
> Let suppose a 4 levels factor, with a  number of measures which is 
> different for
> each level (or at least for one level). In what extend can I trust 
> outputs of a mixed model with
> typical contrasts (treatment, sdif, ordered) applied to such a factor ?
> 
> Thank you very much for your help
> 
> R. Espesser
> Laboratoire Parole et Langage,
> Universit? de Provence/CNRS,
> 5 av. Pasteur, Aix en provence (France)
> 
> 
> Douglas Bates a ?crit :
> >
> > [...]
> >
> > My general advice to those who are required to produce a p-value for a
> > particular fixed-effects term in a mixed-effects model is to use a
> > likelihood ratio test.  Fit the model including that term using
> > maximum likelihood (i.e. REML = FALSE), fit it again without the term
> > and compare the results using anova.
> >
> > The likelihood ratio statistic will be compared to a chi-squared
> > distribution to get a p-value and this process is somewhat suspect
> > when the degrees of freedom would be small.  However, so many other
> > things could be going wrong when you are fitting complex models to few
> > observations that this may be the least of your worries.
> >
> >
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Wed, 30 Sep 2009 11:45:00 +0200
> From: Raldo Kruger <raldo.kruger at gmail.com>
> Subject: Re: [R-sig-ME] lme vs. lmer
> To: Douglas Bates <bates at stat.wisc.edu>,        Peter Dalgaard
> 	<p.dalgaard at biostat.ku.dk>,	"R-SIG-Mixed-Models at r-project.org"
> 	<R-SIG-Mixed-Models at r-project.org>
> Message-ID:
> 	<30406dd0909300245j78380cfesa28d4e056d99cd82 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Hi all, I've been following this thread since it's of interest to the
> analyses i'm currenty doing.
> My question is, how does one do model simplification with lmer (or
> glmer in my case) if there are no p-values (since p-values are used to
> determine which terms to drop, and the drop1 function does not work
> for glmer)?
> 
> And Douglas, could you provide a working example of getting the
> p-values as you described, preferably with glmer (glmer does not have
> the REML=FALSE option)? I understand the 1st part of fitting two
> models, one with and one without the term of interest... So does it
> mean one has to do this for every term in order to get all the
> p-values?
> 
> Many thanks, Raldo
> 
> On 9/29/09, Douglas Bates <bates at stat.wisc.edu> wrote:
> > On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
> > <p.dalgaard at biostat.ku.dk> wrote:
> >> Ben Bolker wrote:
> >>>
> >>> Douglas Bates wrote:
> >>>>
> >>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
> >>>>
> >>>>> Christopher David Desjardins wrote:
> >>>>>>
> >>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the
> >>>>>> use
> >>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
> >>>>>> superseded lme or if lme still holds its own? The reason I ask is that
> >>>>>> I
> >>>>>> have taken a few classes where we've solely used lmer and just read
> >>>>>> about lme today. If both functions are on equal footing, can the
> >>>>>> p-values from lme be trusted?
> >>>>>> Thanks!
> >>>>>> Chris
> >>>>>
> >>>>> ?You should read the extended discussion of p-values, degrees of
> >>>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
> >>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed
> >>>>> necessary
> >>>>> at this stage for fitting heteroscedastic and correlated models). ?The
> >>>>> df/p-value estimates, however, are "use at your own risk" -- you'll
> >>>>> have
> >>>>> to read the literature and decide for yourself.
> >>>>> ?I still think there's room for someone to implement (at least)
> >>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for
> >>>>> the
> >>>>> sake of comparison, but I'm not volunteering.
> >>>>
> >>>> You may need to define them first. ?Many of the formulas in the mixed
> >>>> models literature assume a hierarchical structure in the random
> >>>> effects - certainly we used such a formula for calculating the
> >>>> denominator degrees of freedom in the nlme package. But lme4 allows
> >>>> for fully or partially crossed random effects so you can't think in
> >>>> terms of "levels" of random effects.
> >>>>
> >>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
> >>>> the impression that these are well-known formulas and implementing
> >>>> them would be a simple matter of writing a few lines of code. ?I don't
> >>>> think it is. ?I would be very pleased to incorporate such code if it
> >>>> could be written but, as I said, I don't even know if such things are
> >>>> defined in the general case, let alone easy to calculate.
> >>>>
> >>>> I am not trying to be argumentative (although of late I seem to have
> >>>> succeeded in being that). ?I'm just saying that I don't think this is
> >>>> trivial. (It I wanted to be argumentative I would say that it is
> >>>> difficult and, for the most part, irrelevant. :-)
> >>>
> >>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
> >>> -- even implementing them in nlme would be useful (and perhaps more
> >>> straightforward, if not trivial). I also wouldn't impose the requirement
> >>> that they have to be feasible for huge data sets -- I'm just curious if
> >>> they can be implemented within lme in a relatively straightforward/
> >>> boneheaded way.
> >>> ? But again, this is very far down my to-do list (and at the edge
> >>> of my abilities) and completely off yours, so unless someone else bites
> >>> it won't happen.
> >>
> >> I don't think (n)lme is all that easy either; you still need to sort out
> >> the
> >> connection between its multilevel formulation and the projection matrices
> >> in
> >> the K-R paper. In both nlme and lme4, an implementation is almost
> >> certainly
> >> possible, although probably complicated and perhaps at the expense of all
> >> computational efficiency.
> >>
> >> One main problem is that even when they can be calculated, the corrections
> >> rely on a normal distribution assumption which is more than likely wrong
> >> in
> >> practice. This isn't any different from ordinary t-tests: once you get
> >> into
> >> the single-digit df regime, you really don't know what you are doing, and
> >> if
> >> there are more than 30 df, the normal approximation works well enough
> >> without the correction.
> >>
> >> Accordingly, I tend to see low df more as a warning flag than as something
> >> that gives accurate p values, and I sometimes wonder whether there is a
> >> way
> >> to raise such a flag more expediently.
> >
> > I agree, wholeheartedly.
> >
> > My general advice to those who are required to produce a p-value for a
> > particular fixed-effects term in a mixed-effects model is to use a
> > likelihood ratio test.  Fit the model including that term using
> > maximum likelihood (i.e. REML = FALSE), fit it again without the term
> > and compare the results using anova.
> >
> > The likelihood ratio statistic will be compared to a chi-squared
> > distribution to get a p-value and this process is somewhat suspect
> > when the degrees of freedom would be small.  However, so many other
> > things could be going wrong when you are fitting complex models to few
> > observations that this may be the least of your worries.
> >
> > I appreciate that for Ben and others in fields like ecology the need
> > to incorporate many different possible terms in models for
> > comparatively small data sets may be inevitable.  But it is also
> > inevitable that the precision of the information one can extract from
> > such small data sets is low.  Reducing such analysis to a set of
> > p-values for various terms and treating these p-values as if they were
> > precisely determined is an oversimplification, even when journal
> > editors insist on such an oversimplification.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> -- 
> Sent from my mobile device
> 
> Raldo
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 33, Issue 41
> **************************************************



From fouzia12001 at yahoo.com  Wed Sep 30 17:49:34 2009
From: fouzia12001 at yahoo.com (hello bye)
Date: Wed, 30 Sep 2009 08:49:34 -0700 (PDT)
Subject: [R-sig-ME] need help in R program
Message-ID: <377252.59231.qm@web53104.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20090930/39932ae3/attachment.pl>

From bates at stat.wisc.edu  Wed Sep 30 18:20:16 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 30 Sep 2009 11:20:16 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
Message-ID: <40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>

On Wed, Sep 30, 2009 at 4:45 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Hi all, I've been following this thread since it's of interest to the
> analyses i'm currenty doing.
> My question is, how does one do model simplification with lmer (or
> glmer in my case) if there are no p-values (since p-values are used to
> determine which terms to drop, and the drop1 function does not work
> for glmer)?

> And Douglas, could you provide a working example of getting the
> p-values as you described, preferably with glmer (glmer does not have
> the REML=FALSE option)? I understand the 1st part of fitting two
> models, one with and one without the term of interest... So does it
> mean one has to do this for every term in order to get all the
> p-values?

Got data? (I live in "the dairy state" in the United States and the
milk producers have an advertising campaign with the slogan "Got
milk?")

It would be easier, and probably more useful, if you could propose a
data set and model for illustration.

For a binary response the summary of a glmer fitted model actually
provides p-values for the coefficients.  Refitting the model without a
particular term and using a likelihood ratio test may be more
reasonable than using those p-values, simply because both models are
being fit to the data.  The "Wald test" statistics are based on an
inferred model fit for the simpler model, which may or may not be
reasonable.

> On 9/29/09, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
>> <p.dalgaard at biostat.ku.dk> wrote:
>>> Ben Bolker wrote:
>>>>
>>>> Douglas Bates wrote:
>>>>>
>>>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>>
>>>>>> Christopher David Desjardins wrote:
>>>>>>>
>>>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the
>>>>>>> use
>>>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>>>>> superseded lme or if lme still holds its own? The reason I ask is that
>>>>>>> I
>>>>>>> have taken a few classes where we've solely used lmer and just read
>>>>>>> about lme today. If both functions are on equal footing, can the
>>>>>>> p-values from lme be trusted?
>>>>>>> Thanks!
>>>>>>> Chris
>>>>>>
>>>>>> ?You should read the extended discussion of p-values, degrees of
>>>>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>>>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed
>>>>>> necessary
>>>>>> at this stage for fitting heteroscedastic and correlated models). ?The
>>>>>> df/p-value estimates, however, are "use at your own risk" -- you'll
>>>>>> have
>>>>>> to read the literature and decide for yourself.
>>>>>> ?I still think there's room for someone to implement (at least)
>>>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for
>>>>>> the
>>>>>> sake of comparison, but I'm not volunteering.
>>>>>
>>>>> You may need to define them first. ?Many of the formulas in the mixed
>>>>> models literature assume a hierarchical structure in the random
>>>>> effects - certainly we used such a formula for calculating the
>>>>> denominator degrees of freedom in the nlme package. But lme4 allows
>>>>> for fully or partially crossed random effects so you can't think in
>>>>> terms of "levels" of random effects.
>>>>>
>>>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>>>>> the impression that these are well-known formulas and implementing
>>>>> them would be a simple matter of writing a few lines of code. ?I don't
>>>>> think it is. ?I would be very pleased to incorporate such code if it
>>>>> could be written but, as I said, I don't even know if such things are
>>>>> defined in the general case, let alone easy to calculate.
>>>>>
>>>>> I am not trying to be argumentative (although of late I seem to have
>>>>> succeeded in being that). ?I'm just saying that I don't think this is
>>>>> trivial. (It I wanted to be argumentative I would say that it is
>>>>> difficult and, for the most part, irrelevant. :-)
>>>>
>>>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
>>>> -- even implementing them in nlme would be useful (and perhaps more
>>>> straightforward, if not trivial). I also wouldn't impose the requirement
>>>> that they have to be feasible for huge data sets -- I'm just curious if
>>>> they can be implemented within lme in a relatively straightforward/
>>>> boneheaded way.
>>>> ? But again, this is very far down my to-do list (and at the edge
>>>> of my abilities) and completely off yours, so unless someone else bites
>>>> it won't happen.
>>>
>>> I don't think (n)lme is all that easy either; you still need to sort out
>>> the
>>> connection between its multilevel formulation and the projection matrices
>>> in
>>> the K-R paper. In both nlme and lme4, an implementation is almost
>>> certainly
>>> possible, although probably complicated and perhaps at the expense of all
>>> computational efficiency.
>>>
>>> One main problem is that even when they can be calculated, the corrections
>>> rely on a normal distribution assumption which is more than likely wrong
>>> in
>>> practice. This isn't any different from ordinary t-tests: once you get
>>> into
>>> the single-digit df regime, you really don't know what you are doing, and
>>> if
>>> there are more than 30 df, the normal approximation works well enough
>>> without the correction.
>>>
>>> Accordingly, I tend to see low df more as a warning flag than as something
>>> that gives accurate p values, and I sometimes wonder whether there is a
>>> way
>>> to raise such a flag more expediently.
>>
>> I agree, wholeheartedly.
>>
>> My general advice to those who are required to produce a p-value for a
>> particular fixed-effects term in a mixed-effects model is to use a
>> likelihood ratio test. ?Fit the model including that term using
>> maximum likelihood (i.e. REML = FALSE), fit it again without the term
>> and compare the results using anova.
>>
>> The likelihood ratio statistic will be compared to a chi-squared
>> distribution to get a p-value and this process is somewhat suspect
>> when the degrees of freedom would be small. ?However, so many other
>> things could be going wrong when you are fitting complex models to few
>> observations that this may be the least of your worries.
>>
>> I appreciate that for Ben and others in fields like ecology the need
>> to incorporate many different possible terms in models for
>> comparatively small data sets may be inevitable. ?But it is also
>> inevitable that the precision of the information one can extract from
>> such small data sets is low. ?Reducing such analysis to a set of
>> p-values for various terms and treating these p-values as if they were
>> precisely determined is an oversimplification, even when journal
>> editors insist on such an oversimplification.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> --
> Sent from my mobile device
>
> Raldo
>



From raldo.kruger at gmail.com  Wed Sep 30 21:40:38 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Wed, 30 Sep 2009 21:40:38 +0200
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
	<40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>
Message-ID: <30406dd0909301240w456a19d9jd54966cd1c0fa43e@mail.gmail.com>

Chris,
Thanks for that - I should probably have mentioned that I'm using
family=quasipoisson  in glmer since my data has Poisson distribution
as well as being overdispersed. I'm unsure how one decides which term
to drop without being informed by p-values, and so don't quite
understand how the "Likelihood ratio test using anova()" , or the AIC
or BIC model comparison will work in this case (I thought one's
supposed to remove the term with the highest p-value from the model,
and compare it with the model with the term included to see if there's
a difference, not so?).

Douglas,
Yes I have data (see attached). The response variable ('Counts'
column) is the number of seedlings per plot. There are four sites that
are not the same (since these are previously mined sites and it's
impossible to get even two sites that are exactly the same, in terms
of age, soil properties etc). Each site has 20 reps of each treatment
- Control, G, N and NG, and the data was collected over three
consecutive years. Each set of treatments were grouped together in a
'Patch' (sort of a split plot design, although I've ignored this thus
far).

So the model using glmer looks like this (I'm not sure if the 'random'
factors are correct, or if it should just be '(1|Site)', and i've
ignore the split plot design...):

> ex4o_r2<-glmer(Counts~N+G+Year+N:Year+G:Year+N:G:Year+(Year|Site), data=ex4o, family=quasipoisson)
> ex4o_r2
Generalized linear mixed model fit by the Laplace approximation
Formula: Counts~ N + G + Year + N:Year + G:Year + N:G:Year + (Year |      Site)
   Data: ex4o
  AIC  BIC logLik deviance
 5731 5823  -2846     5693
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Site     (Intercept) 1.35594  1.1644
          Yearthree   3.53069  1.8790   0.752
          Yeartwo     0.88908  0.9429   0.169 0.777
 Residual             6.76955  2.6018
Number of obs: 936, groups: Site, 4

Fixed effects:
              Estimate Std. Error t value
(Intercept)    2.93093    0.58598   5.002
N              0.03767    0.09071   0.415
G              0.14927    0.08833   1.690
Yearthree     -3.22170    0.98325  -3.277
Yeartwo       -1.96111    0.50636  -3.873
N:Yearthree    0.15713    0.37544   0.419
N:Yeartwo      0.14736    0.24210   0.609
G:Yearthree   -0.25103    0.40152  -0.625
G:Yeartwo      0.07549    0.23937   0.315
N:G:Yearone   -0.31633    0.12888  -2.455
N:G:Yearthree  0.04722    0.52594   0.090
N:G:Yeartwo   -0.32787    0.31260  -1.049

Correlation of Fixed Effects:
            (Intr) N      G      Yerthr Yeartw N:Yrth N:Yrtw G:Yrth
G:Yrtw N:G:Yrn N:G:Yrth
N           -0.079
G           -0.081  0.523
Yearthree    0.706  0.047  0.048
Yeartwo      0.141  0.091  0.094  0.707
N:Yearthree  0.019 -0.242 -0.126 -0.209 -0.022
N:Yeartwo    0.030 -0.375 -0.196 -0.018 -0.259  0.091
G:Yearthree  0.018 -0.115 -0.220 -0.195 -0.021  0.511  0.043
G:Yeartwo    0.030 -0.193 -0.369 -0.018 -0.262  0.047  0.547  0.081
N:G:Yearone  0.056 -0.704 -0.685 -0.033 -0.064  0.170  0.264  0.151
0.253
N:G:Yearthr  0.000  0.000  0.000  0.141  0.000 -0.672  0.000 -0.726
0.000  0.000
N:G:Yeartwo  0.000  0.000  0.000  0.000  0.174  0.000 -0.666  0.000
-0.661  0.000   0.000

Hope you can work with that?
Thanks,
Raldo

On Wed, Sep 30, 2009 at 6:20 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Sep 30, 2009 at 4:45 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
>> Hi all, I've been following this thread since it's of interest to the
>> analyses i'm currenty doing.
>> My question is, how does one do model simplification with lmer (or
>> glmer in my case) if there are no p-values (since p-values are used to
>> determine which terms to drop, and the drop1 function does not work
>> for glmer)?
>
>> And Douglas, could you provide a working example of getting the
>> p-values as you described, preferably with glmer (glmer does not have
>> the REML=FALSE option)? I understand the 1st part of fitting two
>> models, one with and one without the term of interest... So does it
>> mean one has to do this for every term in order to get all the
>> p-values?
>
> Got data? (I live in "the dairy state" in the United States and the
> milk producers have an advertising campaign with the slogan "Got
> milk?")
>
> It would be easier, and probably more useful, if you could propose a
> data set and model for illustration.
>
> For a binary response the summary of a glmer fitted model actually
> provides p-values for the coefficients. ?Refitting the model without a
> particular term and using a likelihood ratio test may be more
> reasonable than using those p-values, simply because both models are
> being fit to the data. ?The "Wald test" statistics are based on an
> inferred model fit for the simpler model, which may or may not be
> reasonable.
>
>> On 9/29/09, Douglas Bates <bates at stat.wisc.edu> wrote:
>>> On Tue, Sep 29, 2009 at 3:58 PM, Peter Dalgaard
>>> <p.dalgaard at biostat.ku.dk> wrote:
>>>> Ben Bolker wrote:
>>>>>
>>>>> Douglas Bates wrote:
>>>>>>
>>>>>> On Tue, Sep 29, 2009 at 1:02 PM, Ben Bolker <bolker at ufl.edu> wrote:
>>>>>>
>>>>>>> Christopher David Desjardins wrote:
>>>>>>>>
>>>>>>>> I've started working through Pinheiro & Bates, 2000 and noticed the
>>>>>>>> use
>>>>>>>> of lme from the nlme package. I am curious if lmer from lme4 has
>>>>>>>> superseded lme or if lme still holds its own? The reason I ask is that
>>>>>>>> I
>>>>>>>> have taken a few classes where we've solely used lmer and just read
>>>>>>>> about lme today. If both functions are on equal footing, can the
>>>>>>>> p-values from lme be trusted?
>>>>>>>> Thanks!
>>>>>>>> Chris
>>>>>>>
>>>>>>> ?You should read the extended discussion of p-values, degrees of
>>>>>>> freedom, etc. that is on the R wiki (I think) and referenced from the R
>>>>>>> FAQ. ?At least in my opinion, (n)lme is still fine (and indeed
>>>>>>> necessary
>>>>>>> at this stage for fitting heteroscedastic and correlated models). ?The
>>>>>>> df/p-value estimates, however, are "use at your own risk" -- you'll
>>>>>>> have
>>>>>>> to read the literature and decide for yourself.
>>>>>>> ?I still think there's room for someone to implement (at least)
>>>>>>> Satterthwaite and (possibly) Kenward-Roger corrections, at least for
>>>>>>> the
>>>>>>> sake of comparison, but I'm not volunteering.
>>>>>>
>>>>>> You may need to define them first. ?Many of the formulas in the mixed
>>>>>> models literature assume a hierarchical structure in the random
>>>>>> effects - certainly we used such a formula for calculating the
>>>>>> denominator degrees of freedom in the nlme package. But lme4 allows
>>>>>> for fully or partially crossed random effects so you can't think in
>>>>>> terms of "levels" of random effects.
>>>>>>
>>>>>> Referring to the "Satterthwaite and Kenward-Roger corrections" gives
>>>>>> the impression that these are well-known formulas and implementing
>>>>>> them would be a simple matter of writing a few lines of code. ?I don't
>>>>>> think it is. ?I would be very pleased to incorporate such code if it
>>>>>> could be written but, as I said, I don't even know if such things are
>>>>>> defined in the general case, let alone easy to calculate.
>>>>>>
>>>>>> I am not trying to be argumentative (although of late I seem to have
>>>>>> succeeded in being that). ?I'm just saying that I don't think this is
>>>>>> trivial. (It I wanted to be argumentative I would say that it is
>>>>>> difficult and, for the most part, irrelevant. :-)
>>>>>
>>>>> ?Fair enough. Actually, I'm not sure I meant implementing them in lmer
>>>>> -- even implementing them in nlme would be useful (and perhaps more
>>>>> straightforward, if not trivial). I also wouldn't impose the requirement
>>>>> that they have to be feasible for huge data sets -- I'm just curious if
>>>>> they can be implemented within lme in a relatively straightforward/
>>>>> boneheaded way.
>>>>> ? But again, this is very far down my to-do list (and at the edge
>>>>> of my abilities) and completely off yours, so unless someone else bites
>>>>> it won't happen.
>>>>
>>>> I don't think (n)lme is all that easy either; you still need to sort out
>>>> the
>>>> connection between its multilevel formulation and the projection matrices
>>>> in
>>>> the K-R paper. In both nlme and lme4, an implementation is almost
>>>> certainly
>>>> possible, although probably complicated and perhaps at the expense of all
>>>> computational efficiency.
>>>>
>>>> One main problem is that even when they can be calculated, the corrections
>>>> rely on a normal distribution assumption which is more than likely wrong
>>>> in
>>>> practice. This isn't any different from ordinary t-tests: once you get
>>>> into
>>>> the single-digit df regime, you really don't know what you are doing, and
>>>> if
>>>> there are more than 30 df, the normal approximation works well enough
>>>> without the correction.
>>>>
>>>> Accordingly, I tend to see low df more as a warning flag than as something
>>>> that gives accurate p values, and I sometimes wonder whether there is a
>>>> way
>>>> to raise such a flag more expediently.
>>>
>>> I agree, wholeheartedly.
>>>
>>> My general advice to those who are required to produce a p-value for a
>>> particular fixed-effects term in a mixed-effects model is to use a
>>> likelihood ratio test. ?Fit the model including that term using
>>> maximum likelihood (i.e. REML = FALSE), fit it again without the term
>>> and compare the results using anova.
>>>
>>> The likelihood ratio statistic will be compared to a chi-squared
>>> distribution to get a p-value and this process is somewhat suspect
>>> when the degrees of freedom would be small. ?However, so many other
>>> things could be going wrong when you are fitting complex models to few
>>> observations that this may be the least of your worries.
>>>
>>> I appreciate that for Ben and others in fields like ecology the need
>>> to incorporate many different possible terms in models for
>>> comparatively small data sets may be inevitable. ?But it is also
>>> inevitable that the precision of the information one can extract from
>>> such small data sets is low. ?Reducing such analysis to a set of
>>> p-values for various terms and treating these p-values as if they were
>>> precisely determined is an oversimplification, even when journal
>>> editors insist on such an oversimplification.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Sent from my mobile device
>>
>> Raldo
>>
>



-- 
Raldo
-------------- next part --------------
Site	Soil	Patch 	Treat	Plant	Year	Counts	N	G
N	N	1	C	O	one	31	0	0
N	N	1	C	O	three	10	0	0
N	N	1	C	O	two	6	0	0
N	N	2	C	O	one	25	0	0
N	N	2	C	O	three	1	0	0
N	N	2	C	O	two	2	0	0
N	N	3	C	O	one	22	0	0
N	N	3	C	O	three	1	0	0
N	N	3	C	O	two	2	0	0
N	N	4	C	O	one	38	0	0
N	N	4	C	O	three	2	0	0
N	N	4	C	O	two	8	0	0
N	N	5	C	O	one	7	0	0
N	N	5	C	O	three	0	0	0
N	N	5	C	O	two	5	0	0
N	N	6	C	O	one	19	0	0
N	N	6	C	O	three	1	0	0
N	N	6	C	O	two	1	0	0
N	N	7	C	O	one	10	0	0
N	N	7	C	O	three	0	0	0
N	N	7	C	O	two	6	0	0
N	N	8	C	O	one	13	0	0
N	N	8	C	O	three	1	0	0
N	N	8	C	O	two	2	0	0
N	N	9	C	O	one	25	0	0
N	N	9	C	O	three	4	0	0
N	N	9	C	O	two	1	0	0
N	N	10	C	O	one	51	0	0
N	N	10	C	O	three	0	0	0
N	N	10	C	O	two	3	0	0
N	N	11	C	O	one	21	0	0
N	N	11	C	O	three	0	0	0
N	N	11	C	O	two	0	0	0
N	N	12	C	O	one	19	0	0
N	N	12	C	O	three	2	0	0
N	N	12	C	O	two	4	0	0
N	N	13	C	O	one	18	0	0
N	N	13	C	O	three	0	0	0
N	N	13	C	O	two	2	0	0
N	N	14	C	O	one	34	0	0
N	N	14	C	O	three	0	0	0
N	N	14	C	O	two	0	0	0
N	N	15	C	O	one	28	0	0
N	N	15	C	O	three	2	0	0
N	N	15	C	O	two	0	0	0
N	N	16	C	O	one	38	0	0
N	N	16	C	O	three	8	0	0
N	N	16	C	O	two	8	0	0
N	N	17	C	O	one	39	0	0
N	N	17	C	O	three	1	0	0
N	N	17	C	O	two	7	0	0
N	N	18	C	O	one	39	0	0
N	N	18	C	O	three	1	0	0
N	N	18	C	O	two	5	0	0
N	N	19	C	O	one	8	0	0
N	N	19	C	O	three	3	0	0
N	N	19	C	O	two	2	0	0
N	N	20	C	O	one	38	0	0
N	N	20	C	O	three	1	0	0
N	N	20	C	O	two	4	0	0
B	O	1	C	O	one	52	0	0
B	O	1	C	O	three	0	0	0
B	O	1	C	O	two	4	0	0
B	O	2	C	O	one	8	0	0
B	O	2	C	O	three	0	0	0
B	O	2	C	O	two	0	0	0
B	O	3	C	O	one	6	0	0
B	O	3	C	O	three	5	0	0
B	O	3	C	O	two	7	0	0
B	O	4	C	O	one	41	0	0
B	O	4	C	O	three	0	0	0
B	O	4	C	O	two	1	0	0
B	O	5	C	O	one	21	0	0
B	O	5	C	O	three	2	0	0
B	O	5	C	O	two	9	0	0
B	O	6	C	O	one	25	0	0
B	O	6	C	O	three	1	0	0
B	O	6	C	O	two	10	0	0
B	O	7	C	O	one	5	0	0
B	O	7	C	O	three	0	0	0
B	O	7	C	O	two	0	0	0
B	O	8	C	O	one	5	0	0
B	O	8	C	O	three	9	0	0
B	O	8	C	O	two	10	0	0
B	O	9	C	O	one	26	0	0
B	O	9	C	O	three	0	0	0
B	O	9	C	O	two	1	0	0
B	O	10	C	O	one	3	0	0
B	O	10	C	O	three	0	0	0
B	O	10	C	O	two	7	0	0
B	O	11	C	O	one	5	0	0
B	O	11	C	O	three	2	0	0
B	O	11	C	O	two	7	0	0
B	O	12	C	O	one	2	0	0
B	O	12	C	O	three	3	0	0
B	O	12	C	O	two	12	0	0
B	O	13	C	O	one	19	0	0
B	O	13	C	O	three	0	0	0
B	O	13	C	O	two	5	0	0
B	O	14	C	O	one	28	0	0
B	O	14	C	O	three	7	0	0
B	O	14	C	O	two	13	0	0
B	O	15	C	O	one	3	0	0
B	O	15	C	O	three	0	0	0
B	O	15	C	O	two	0	0	0
B	O	16	C	O	one	30	0	0
B	O	16	C	O	three	1	0	0
B	O	16	C	O	two	10	0	0
B	O	17	C	O	one	28	0	0
B	O	17	C	O	three	1	0	0
B	O	17	C	O	two	5	0	0
B	O	18	C	O	one	21	0	0
B	O	18	C	O	three	4	0	0
B	O	18	C	O	two	6	0	0
B	O	19	C	O	one	21	0	0
B	O	19	C	O	three	1	0	0
B	O	19	C	O	two	7	0	0
B	O	20	C	O	one	0	0	0
B	O	20	C	O	three	0	0	0
B	O	20	C	O	two	0	0	0
F	O	2	C	O	one	51	0	0
F	O	2	C	O	three	2	0	0
F	O	2	C	O	two	4	0	0
F	O	3	C	O	one	84	0	0
F	O	3	C	O	three	0	0	0
F	O	3	C	O	two	0	0	0
F	O	4	C	O	one	35	0	0
F	O	4	C	O	three	0	0	0
F	O	4	C	O	two	0	0	0
F	O	5	C	O	one	74	0	0
F	O	5	C	O	three	3	0	0
F	O	5	C	O	two	1	0	0
F	O	6	C	O	one	43	0	0
F	O	6	C	O	three	0	0	0
F	O	6	C	O	two	1	0	0
F	O	7	C	O	one	40	0	0
F	O	7	C	O	three	0	0	0
F	O	7	C	O	two	2	0	0
F	O	8	C	O	one	2	0	0
F	O	8	C	O	three	0	0	0
F	O	8	C	O	two	0	0	0
F	O	9	C	O	one	13	0	0
F	O	9	C	O	three	0	0	0
F	O	9	C	O	two	0	0	0
F	O	10	C	O	one	7	0	0
F	O	10	C	O	three	0	0	0
F	O	10	C	O	two	0	0	0
F	O	11	C	O	one	37	0	0
F	O	11	C	O	three	3	0	0
F	O	11	C	O	two	3	0	0
F	O	12	C	O	one	8	0	0
F	O	12	C	O	three	0	0	0
F	O	12	C	O	two	1	0	0
F	O	13	C	O	one	29	0	0
F	O	13	C	O	three	0	0	0
F	O	13	C	O	two	2	0	0
F	O	14	C	O	one	19	0	0
F	O	14	C	O	three	0	0	0
F	O	14	C	O	two	0	0	0
F	O	15	C	O	one	16	0	0
F	O	15	C	O	three	2	0	0
F	O	15	C	O	two	0	0	0
F	O	16	C	O	one	23	0	0
F	O	16	C	O	three	0	0	0
F	O	16	C	O	two	0	0	0
F	O	17	C	O	one	23	0	0
F	O	17	C	O	three	0	0	0
F	O	17	C	O	two	0	0	0
F	O	18	C	O	one	39	0	0
F	O	18	C	O	three	7	0	0
F	O	18	C	O	two	10	0	0
F	O	19	C	O	one	20	0	0
F	O	19	C	O	three	1	0	0
F	O	19	C	O	two	11	0	0
F	O	20	C	O	one	3	0	0
F	O	20	C	O	three	0	0	0
F	O	20	C	O	two	1	0	0
P	O	1	C	O	one	20	0	0
P	O	1	C	O	three	0	0	0
P	O	1	C	O	two	2	0	0
P	O	2	C	O	one	13	0	0
P	O	2	C	O	three	0	0	0
P	O	2	C	O	two	0	0	0
P	O	4	C	O	one	12	0	0
P	O	4	C	O	three	0	0	0
P	O	4	C	O	two	2	0	0
P	O	5	C	O	one	20	0	0
P	O	5	C	O	three	1	0	0
P	O	5	C	O	two	4	0	0
P	O	6	C	O	one	15	0	0
P	O	6	C	O	three	0	0	0
P	O	6	C	O	two	0	0	0
P	O	7	C	O	one	11	0	0
P	O	7	C	O	three	0	0	0
P	O	7	C	O	two	0	0	0
P	O	8	C	O	one	14	0	0
P	O	8	C	O	three	0	0	0
P	O	8	C	O	two	3	0	0
P	O	9	C	O	one	14	0	0
P	O	9	C	O	three	0	0	0
P	O	9	C	O	two	2	0	0
P	O	10	C	O	one	2	0	0
P	O	10	C	O	three	0	0	0
P	O	10	C	O	two	1	0	0
P	O	11	C	O	one	0	0	0
P	O	11	C	O	three	0	0	0
P	O	11	C	O	two	0	0	0
P	O	12	C	O	one	2	0	0
P	O	12	C	O	three	0	0	0
P	O	12	C	O	two	2	0	0
P	O	13	C	O	one	0	0	0
P	O	13	C	O	three	0	0	0
P	O	13	C	O	two	0	0	0
P	O	14	C	O	one	0	0	0
P	O	14	C	O	three	0	0	0
P	O	14	C	O	two	2	0	0
P	O	15	C	O	one	0	0	0
P	O	15	C	O	three	0	0	0
P	O	15	C	O	two	0	0	0
P	O	16	C	O	one	1	0	0
P	O	16	C	O	three	0	0	0
P	O	16	C	O	two	0	0	0
P	O	17	C	O	one	24	0	0
P	O	17	C	O	three	0	0	0
P	O	17	C	O	two	10	0	0
P	O	18	C	O	one	10	0	0
P	O	18	C	O	three	0	0	0
P	O	18	C	O	two	0	0	0
P	O	19	C	O	one	19	0	0
P	O	19	C	O	three	0	0	0
P	O	19	C	O	two	0	0	0
P	O	20	C	O	one	0	0	0
P	O	20	C	O	three	0	0	0
P	O	20	C	O	two	0	0	0
N	N	1	G	O	one	13	0	1
N	N	1	G	O	three	1	0	1
N	N	1	G	O	two	3	0	1
N	N	2	G	O	one	50	0	1
N	N	2	G	O	three	1	0	1
N	N	2	G	O	two	4	0	1
N	N	3	G	O	one	14	0	1
N	N	3	G	O	three	2	0	1
N	N	3	G	O	two	5	0	1
N	N	4	G	O	one	15	0	1
N	N	4	G	O	three	0	0	1
N	N	4	G	O	two	0	0	1
N	N	5	G	O	one	36	0	1
N	N	5	G	O	three	1	0	1
N	N	5	G	O	two	22	0	1
N	N	6	G	O	one	56	0	1
N	N	6	G	O	three	1	0	1
N	N	6	G	O	two	2	0	1
N	N	7	G	O	one	15	0	1
N	N	7	G	O	three	0	0	1
N	N	7	G	O	two	10	0	1
N	N	8	G	O	one	47	0	1
N	N	8	G	O	three	1	0	1
N	N	8	G	O	two	1	0	1
N	N	9	G	O	one	26	0	1
N	N	9	G	O	three	2	0	1
N	N	9	G	O	two	2	0	1
N	N	10	G	O	one	61	0	1
N	N	10	G	O	three	2	0	1
N	N	10	G	O	two	3	0	1
N	N	11	G	O	one	46	0	1
N	N	11	G	O	three	3	0	1
N	N	11	G	O	two	9	0	1
N	N	12	G	O	one	32	0	1
N	N	12	G	O	three	2	0	1
N	N	12	G	O	two	2	0	1
N	N	13	G	O	one	10	0	1
N	N	13	G	O	three	0	0	1
N	N	13	G	O	two	6	0	1
N	N	14	G	O	one	37	0	1
N	N	14	G	O	three	1	0	1
N	N	14	G	O	two	3	0	1
N	N	15	G	O	one	36	0	1
N	N	15	G	O	three	3	0	1
N	N	15	G	O	two	6	0	1
N	N	16	G	O	one	79	0	1
N	N	16	G	O	three	10	0	1
N	N	16	G	O	two	29	0	1
N	N	17	G	O	one	53	0	1
N	N	17	G	O	three	4	0	1
N	N	17	G	O	two	9	0	1
N	N	18	G	O	one	45	0	1
N	N	18	G	O	three	1	0	1
N	N	18	G	O	two	5	0	1
N	N	19	G	O	one	13	0	1
N	N	19	G	O	three	4	0	1
N	N	19	G	O	two	13	0	1
N	N	20	G	O	one	54	0	1
N	N	20	G	O	three	4	0	1
N	N	20	G	O	two	4	0	1
B	O	1	G	O	one	31	0	1
B	O	1	G	O	three	4	0	1
B	O	1	G	O	two	7	0	1
B	O	2	G	O	one	31	0	1
B	O	2	G	O	three	0	0	1
B	O	2	G	O	two	3	0	1
B	O	3	G	O	one	12	0	1
B	O	3	G	O	three	4	0	1
B	O	3	G	O	two	1	0	1
B	O	4	G	O	one	13	0	1
B	O	4	G	O	three	1	0	1
B	O	4	G	O	two	0	0	1
B	O	5	G	O	one	39	0	1
B	O	5	G	O	three	2	0	1
B	O	5	G	O	two	26	0	1
B	O	6	G	O	one	0	0	1
B	O	6	G	O	three	0	0	1
B	O	6	G	O	two	0	0	1
B	O	7	G	O	one	12	0	1
B	O	7	G	O	three	9	0	1
B	O	7	G	O	two	3	0	1
B	O	8	G	O	one	17	0	1
B	O	8	G	O	three	1	0	1
B	O	8	G	O	two	13	0	1
B	O	9	G	O	one	19	0	1
B	O	9	G	O	three	0	0	1
B	O	9	G	O	two	2	0	1
B	O	10	G	O	one	7	0	1
B	O	10	G	O	three	1	0	1
B	O	10	G	O	two	14	0	1
B	O	11	G	O	one	4	0	1
B	O	11	G	O	three	0	0	1
B	O	11	G	O	two	3	0	1
B	O	12	G	O	one	2	0	1
B	O	12	G	O	three	1	0	1
B	O	12	G	O	two	6	0	1
B	O	13	G	O	one	6	0	1
B	O	13	G	O	three	0	0	1
B	O	13	G	O	two	4	0	1
B	O	14	G	O	one	47	0	1
B	O	14	G	O	three	0	0	1
B	O	14	G	O	two	2	0	1
B	O	15	G	O	one	5	0	1
B	O	15	G	O	three	0	0	1
B	O	15	G	O	two	0	0	1
B	O	16	G	O	one	14	0	1
B	O	16	G	O	three	0	0	1
B	O	16	G	O	two	3	0	1
B	O	17	G	O	one	22	0	1
B	O	17	G	O	three	3	0	1
B	O	17	G	O	two	7	0	1
B	O	18	G	O	one	22	0	1
B	O	18	G	O	three	1	0	1
B	O	18	G	O	two	4	0	1
B	O	19	G	O	one	7	0	1
B	O	19	G	O	three	0	0	1
B	O	19	G	O	two	0	0	1
B	O	20	G	O	one	28	0	1
B	O	20	G	O	three	0	0	1
B	O	20	G	O	two	1	0	1
F	O	2	G	O	one	65	0	1
F	O	2	G	O	three	0	0	1
F	O	2	G	O	two	1	0	1
F	O	3	G	O	one	61	0	1
F	O	3	G	O	three	1	0	1
F	O	3	G	O	two	0	0	1
F	O	4	G	O	one	54	0	1
F	O	4	G	O	three	0	0	1
F	O	4	G	O	two	0	0	1
F	O	5	G	O	one	48	0	1
F	O	5	G	O	three	0	0	1
F	O	5	G	O	two	2	0	1
F	O	6	G	O	one	37	0	1
F	O	6	G	O	three	0	0	1
F	O	6	G	O	two	0	0	1
F	O	7	G	O	one	1	0	1
F	O	7	G	O	three	0	0	1
F	O	7	G	O	two	0	0	1
F	O	8	G	O	one	12	0	1
F	O	8	G	O	three	0	0	1
F	O	8	G	O	two	0	0	1
F	O	9	G	O	one	22	0	1
F	O	9	G	O	three	0	0	1
F	O	9	G	O	two	0	0	1
F	O	10	G	O	one	15	0	1
F	O	10	G	O	three	0	0	1
F	O	10	G	O	two	0	0	1
F	O	11	G	O	one	6	0	1
F	O	11	G	O	three	0	0	1
F	O	11	G	O	two	0	0	1
F	O	12	G	O	one	29	0	1
F	O	12	G	O	three	0	0	1
F	O	12	G	O	two	0	0	1
F	O	13	G	O	one	32	0	1
F	O	13	G	O	three	10	0	1
F	O	13	G	O	two	22	0	1
F	O	14	G	O	one	8	0	1
F	O	14	G	O	three	1	0	1
F	O	14	G	O	two	0	0	1
F	O	15	G	O	one	11	0	1
F	O	15	G	O	three	0	0	1
F	O	15	G	O	two	0	0	1
F	O	16	G	O	one	14	0	1
F	O	16	G	O	three	0	0	1
F	O	16	G	O	two	0	0	1
F	O	17	G	O	one	45	0	1
F	O	17	G	O	three	0	0	1
F	O	17	G	O	two	6	0	1
F	O	18	G	O	one	32	0	1
F	O	18	G	O	three	1	0	1
F	O	18	G	O	two	3	0	1
F	O	19	G	O	one	24	0	1
F	O	19	G	O	three	0	0	1
F	O	19	G	O	two	2	0	1
F	O	20	G	O	one	14	0	1
F	O	20	G	O	three	0	0	1
F	O	20	G	O	two	5	0	1
P	O	1	G	O	one	11	0	1
P	O	1	G	O	three	0	0	1
P	O	1	G	O	two	1	0	1
P	O	2	G	O	one	21	0	1
P	O	2	G	O	three	0	0	1
P	O	2	G	O	two	0	0	1
P	O	4	G	O	one	14	0	1
P	O	4	G	O	three	0	0	1
P	O	4	G	O	two	0	0	1
P	O	5	G	O	one	14	0	1
P	O	5	G	O	three	0	0	1
P	O	5	G	O	two	0	0	1
P	O	6	G	O	one	30	0	1
P	O	6	G	O	three	0	0	1
P	O	6	G	O	two	0	0	1
P	O	7	G	O	one	15	0	1
P	O	7	G	O	three	0	0	1
P	O	7	G	O	two	0	0	1
P	O	8	G	O	one	25	0	1
P	O	8	G	O	three	0	0	1
P	O	8	G	O	two	3	0	1
P	O	9	G	O	one	3	0	1
P	O	9	G	O	three	0	0	1
P	O	9	G	O	two	0	0	1
P	O	10	G	O	one	1	0	1
P	O	10	G	O	three	0	0	1
P	O	10	G	O	two	12	0	1
P	O	11	G	O	one	5	0	1
P	O	11	G	O	three	0	0	1
P	O	11	G	O	two	3	0	1
P	O	12	G	O	one	4	0	1
P	O	12	G	O	three	0	0	1
P	O	12	G	O	two	1	0	1
P	O	13	G	O	one	0	0	1
P	O	13	G	O	three	0	0	1
P	O	13	G	O	two	0	0	1
P	O	14	G	O	one	7	0	1
P	O	14	G	O	three	0	0	1
P	O	14	G	O	two	3	0	1
P	O	15	G	O	one	0	0	1
P	O	15	G	O	three	0	0	1
P	O	15	G	O	two	0	0	1
P	O	16	G	O	one	46	0	1
P	O	16	G	O	three	0	0	1
P	O	16	G	O	two	0	0	1
P	O	17	G	O	one	0	0	1
P	O	17	G	O	three	0	0	1
P	O	17	G	O	two	1	0	1
P	O	18	G	O	one	33	0	1
P	O	18	G	O	three	0	0	1
P	O	18	G	O	two	1	0	1
P	O	19	G	O	one	30	0	1
P	O	19	G	O	three	1	0	1
P	O	19	G	O	two	4	0	1
P	O	20	G	O	one	10	0	1
P	O	20	G	O	three	0	0	1
P	O	20	G	O	two	1	0	1
N	N	1	N	O	one	0	1	0
N	N	1	N	O	three	12	1	0
N	N	1	N	O	two	9	1	0
N	N	2	N	O	one	34	1	0
N	N	2	N	O	three	4	1	0
N	N	2	N	O	two	7	1	0
N	N	3	N	O	one	48	1	0
N	N	3	N	O	three	4	1	0
N	N	3	N	O	two	14	1	0
N	N	4	N	O	one	31	1	0
N	N	4	N	O	three	0	1	0
N	N	4	N	O	two	1	1	0
N	N	5	N	O	one	47	1	0
N	N	5	N	O	three	3	1	0
N	N	5	N	O	two	15	1	0
N	N	6	N	O	one	37	1	0
N	N	6	N	O	three	6	1	0
N	N	6	N	O	two	13	1	0
N	N	7	N	O	one	77	1	0
N	N	7	N	O	three	3	1	0
N	N	7	N	O	two	8	1	0
N	N	8	N	O	one	52	1	0
N	N	8	N	O	three	5	1	0
N	N	8	N	O	two	4	1	0
N	N	9	N	O	one	17	1	0
N	N	9	N	O	three	0	1	0
N	N	9	N	O	two	0	1	0
N	N	10	N	O	one	68	1	0
N	N	10	N	O	three	1	1	0
N	N	10	N	O	two	2	1	0
N	N	11	N	O	one	47	1	0
N	N	11	N	O	three	3	1	0
N	N	11	N	O	two	4	1	0
N	N	12	N	O	one	40	1	0
N	N	12	N	O	three	4	1	0
N	N	12	N	O	two	5	1	0
N	N	13	N	O	one	37	1	0
N	N	13	N	O	three	0	1	0
N	N	13	N	O	two	0	1	0
N	N	14	N	O	one	34	1	0
N	N	14	N	O	three	6	1	0
N	N	14	N	O	two	7	1	0
N	N	15	N	O	one	31	1	0
N	N	15	N	O	three	0	1	0
N	N	15	N	O	two	4	1	0
N	N	16	N	O	one	44	1	0
N	N	16	N	O	three	5	1	0
N	N	16	N	O	two	9	1	0
N	N	17	N	O	one	46	1	0
N	N	17	N	O	three	1	1	0
N	N	17	N	O	two	1	1	0
N	N	18	N	O	one	56	1	0
N	N	18	N	O	three	4	1	0
N	N	18	N	O	two	4	1	0
N	N	19	N	O	one	39	1	0
N	N	19	N	O	three	5	1	0
N	N	19	N	O	two	6	1	0
N	N	20	N	O	one	45	1	0
N	N	20	N	O	three	4	1	0
N	N	20	N	O	two	9	1	0
B	O	1	N	O	one	26	1	0
B	O	1	N	O	three	0	1	0
B	O	1	N	O	two	14	1	0
B	O	2	N	O	one	40	1	0
B	O	2	N	O	three	5	1	0
B	O	2	N	O	two	5	1	0
B	O	3	N	O	one	12	1	0
B	O	3	N	O	three	4	1	0
B	O	3	N	O	two	2	1	0
B	O	4	N	O	one	18	1	0
B	O	4	N	O	three	2	1	0
B	O	4	N	O	two	0	1	0
B	O	5	N	O	one	3	1	0
B	O	5	N	O	three	0	1	0
B	O	5	N	O	two	1	1	0
B	O	6	N	O	one	14	1	0
B	O	6	N	O	three	0	1	0
B	O	6	N	O	two	9	1	0
B	O	7	N	O	one	15	1	0
B	O	7	N	O	three	0	1	0
B	O	7	N	O	two	8	1	0
B	O	8	N	O	one	2	1	0
B	O	8	N	O	three	4	1	0
B	O	8	N	O	two	5	1	0
B	O	9	N	O	one	30	1	0
B	O	9	N	O	three	7	1	0
B	O	9	N	O	two	17	1	0
B	O	10	N	O	one	17	1	0
B	O	10	N	O	three	1	1	0
B	O	10	N	O	two	7	1	0
B	O	11	N	O	one	13	1	0
B	O	11	N	O	three	1	1	0
B	O	11	N	O	two	5	1	0
B	O	12	N	O	one	5	1	0
B	O	12	N	O	three	1	1	0
B	O	12	N	O	two	6	1	0
B	O	13	N	O	one	20	1	0
B	O	13	N	O	three	0	1	0
B	O	13	N	O	two	2	1	0
B	O	14	N	O	one	24	1	0
B	O	14	N	O	three	1	1	0
B	O	14	N	O	two	0	1	0
B	O	15	N	O	one	7	1	0
B	O	15	N	O	three	0	1	0
B	O	15	N	O	two	0	1	0
B	O	16	N	O	one	0	1	0
B	O	16	N	O	three	0	1	0
B	O	16	N	O	two	0	1	0
B	O	17	N	O	one	42	1	0
B	O	17	N	O	three	0	1	0
B	O	17	N	O	two	4	1	0
B	O	18	N	O	one	20	1	0
B	O	18	N	O	three	0	1	0
B	O	18	N	O	two	9	1	0
B	O	19	N	O	one	16	1	0
B	O	19	N	O	three	0	1	0
B	O	19	N	O	two	3	1	0
B	O	20	N	O	one	23	1	0
B	O	20	N	O	three	2	1	0
B	O	20	N	O	two	3	1	0
F	O	2	N	O	one	45	1	0
F	O	2	N	O	three	1	1	0
F	O	2	N	O	two	3	1	0
F	O	3	N	O	one	0	1	0
F	O	3	N	O	three	0	1	0
F	O	3	N	O	two	2	1	0
F	O	4	N	O	one	16	1	0
F	O	4	N	O	three	0	1	0
F	O	4	N	O	two	0	1	0
F	O	5	N	O	one	34	1	0
F	O	5	N	O	three	1	1	0
F	O	5	N	O	two	2	1	0
F	O	6	N	O	one	18	1	0
F	O	6	N	O	three	0	1	0
F	O	6	N	O	two	5	1	0
F	O	7	N	O	one	17	1	0
F	O	7	N	O	three	1	1	0
F	O	7	N	O	two	7	1	0
F	O	8	N	O	one	35	1	0
F	O	8	N	O	three	1	1	0
F	O	8	N	O	two	2	1	0
F	O	9	N	O	one	16	1	0
F	O	9	N	O	three	0	1	0
F	O	9	N	O	two	1	1	0
F	O	10	N	O	one	1	1	0
F	O	10	N	O	three	0	1	0
F	O	10	N	O	two	0	1	0
F	O	11	N	O	one	1	1	0
F	O	11	N	O	three	1	1	0
F	O	11	N	O	two	2	1	0
F	O	12	N	O	one	34	1	0
F	O	12	N	O	three	3	1	0
F	O	12	N	O	two	0	1	0
F	O	13	N	O	one	39	1	0
F	O	13	N	O	three	2	1	0
F	O	13	N	O	two	8	1	0
F	O	14	N	O	one	3	1	0
F	O	14	N	O	three	0	1	0
F	O	14	N	O	two	1	1	0
F	O	15	N	O	one	5	1	0
F	O	15	N	O	three	0	1	0
F	O	15	N	O	two	0	1	0
F	O	16	N	O	one	23	1	0
F	O	16	N	O	three	0	1	0
F	O	16	N	O	two	1	1	0
F	O	17	N	O	one	15	1	0
F	O	17	N	O	three	0	1	0
F	O	17	N	O	two	10	1	0
F	O	18	N	O	one	13	1	0
F	O	18	N	O	three	3	1	0
F	O	18	N	O	two	12	1	0
F	O	19	N	O	one	5	1	0
F	O	19	N	O	three	0	1	0
F	O	19	N	O	two	0	1	0
F	O	20	N	O	one	0	1	0
F	O	20	N	O	three	0	1	0
F	O	20	N	O	two	0	1	0
P	O	1	N	O	one	21	1	0
P	O	1	N	O	three	0	1	0
P	O	1	N	O	two	1	1	0
P	O	2	N	O	one	2	1	0
P	O	2	N	O	three	0	1	0
P	O	2	N	O	two	0	1	0
P	O	4	N	O	one	1	1	0
P	O	4	N	O	three	0	1	0
P	O	4	N	O	two	1	1	0
P	O	5	N	O	one	19	1	0
P	O	5	N	O	three	0	1	0
P	O	5	N	O	two	3	1	0
P	O	6	N	O	one	9	1	0
P	O	6	N	O	three	0	1	0
P	O	6	N	O	two	0	1	0
P	O	7	N	O	one	7	1	0
P	O	7	N	O	three	0	1	0
P	O	7	N	O	two	0	1	0
P	O	8	N	O	one	7	1	0
P	O	8	N	O	three	0	1	0
P	O	8	N	O	two	0	1	0
P	O	9	N	O	one	21	1	0
P	O	9	N	O	three	1	1	0
P	O	9	N	O	two	6	1	0
P	O	10	N	O	one	9	1	0
P	O	10	N	O	three	0	1	0
P	O	10	N	O	two	1	1	0
P	O	11	N	O	one	3	1	0
P	O	11	N	O	three	0	1	0
P	O	11	N	O	two	0	1	0
P	O	12	N	O	one	1	1	0
P	O	12	N	O	three	0	1	0
P	O	12	N	O	two	0	1	0
P	O	13	N	O	one	0	1	0
P	O	13	N	O	three	0	1	0
P	O	13	N	O	two	0	1	0
P	O	14	N	O	one	0	1	0
P	O	14	N	O	three	1	1	0
P	O	14	N	O	two	1	1	0
P	O	15	N	O	one	2	1	0
P	O	15	N	O	three	0	1	0
P	O	15	N	O	two	0	1	0
P	O	16	N	O	one	0	1	0
P	O	16	N	O	three	0	1	0
P	O	16	N	O	two	0	1	0
P	O	17	N	O	one	19	1	0
P	O	17	N	O	three	0	1	0
P	O	17	N	O	two	2	1	0
P	O	18	N	O	one	9	1	0
P	O	18	N	O	three	0	1	0
P	O	18	N	O	two	0	1	0
P	O	19	N	O	one	41	1	0
P	O	19	N	O	three	0	1	0
P	O	19	N	O	two	3	1	0
P	O	20	N	O	one	9	1	0
P	O	20	N	O	three	0	1	0
P	O	20	N	O	two	0	1	0
N	N	1	NG 	O	one	17	1	1
N	N	1	NG 	O	three	7	1	1
N	N	1	NG 	O	two	0	1	1
N	N	2	NG 	O	one	16	1	1
N	N	2	NG 	O	three	3	1	1
N	N	2	NG 	O	two	4	1	1
N	N	3	NG 	O	one	7	1	1
N	N	3	NG 	O	three	0	1	1
N	N	3	NG 	O	two	4	1	1
N	N	4	NG 	O	one	26	1	1
N	N	4	NG 	O	three	0	1	1
N	N	4	NG 	O	two	5	1	1
N	N	5	NG 	O	one	0	1	1
N	N	5	NG 	O	three	0	1	1
N	N	5	NG 	O	two	13	1	1
N	N	6	NG 	O	one	59	1	1
N	N	6	NG 	O	three	4	1	1
N	N	6	NG 	O	two	12	1	1
N	N	7	NG 	O	one	68	1	1
N	N	7	NG 	O	three	7	1	1
N	N	7	NG 	O	two	6	1	1
N	N	8	NG 	O	one	42	1	1
N	N	8	NG 	O	three	6	1	1
N	N	8	NG 	O	two	0	1	1
N	N	9	NG 	O	one	22	1	1
N	N	9	NG 	O	three	1	1	1
N	N	9	NG 	O	two	8	1	1
N	N	10	NG 	O	one	15	1	1
N	N	10	NG 	O	three	1	1	1
N	N	10	NG 	O	two	12	1	1
N	N	11	NG 	O	one	56	1	1
N	N	11	NG 	O	three	5	1	1
N	N	11	NG 	O	two	5	1	1
N	N	12	NG 	O	one	21	1	1
N	N	12	NG 	O	three	3	1	1
N	N	12	NG 	O	two	7	1	1
N	N	13	NG 	O	one	45	1	1
N	N	13	NG 	O	three	0	1	1
N	N	13	NG 	O	two	1	1	1
N	N	14	NG 	O	one	30	1	1
N	N	14	NG 	O	three	8	1	1
N	N	14	NG 	O	two	7	1	1
N	N	15	NG 	O	one	21	1	1
N	N	15	NG 	O	three	1	1	1
N	N	15	NG 	O	two	2	1	1
N	N	16	NG 	O	one	49	1	1
N	N	16	NG 	O	three	5	1	1
N	N	16	NG 	O	two	13	1	1
N	N	17	NG 	O	one	41	1	1
N	N	17	NG 	O	three	0	1	1
N	N	17	NG 	O	two	10	1	1
N	N	18	NG 	O	one	5	1	1
N	N	18	NG 	O	three	0	1	1
N	N	18	NG 	O	two	4	1	1
N	N	19	NG 	O	one	42	1	1
N	N	19	NG 	O	three	3	1	1
N	N	19	NG 	O	two	4	1	1
N	N	20	NG 	O	one	17	1	1
N	N	20	NG 	O	three	0	1	1
N	N	20	NG 	O	two	0	1	1
B	O	1	NG 	O	one	44	1	1
B	O	1	NG 	O	three	1	1	1
B	O	1	NG 	O	two	4	1	1
B	O	2	NG 	O	one	36	1	1
B	O	2	NG 	O	three	6	1	1
B	O	2	NG 	O	two	6	1	1
B	O	3	NG 	O	one	14	1	1
B	O	3	NG 	O	three	5	1	1
B	O	3	NG 	O	two	4	1	1
B	O	4	NG 	O	one	0	1	1
B	O	4	NG 	O	three	2	1	1
B	O	4	NG 	O	two	5	1	1
B	O	5	NG 	O	one	72	1	1
B	O	5	NG 	O	three	2	1	1
B	O	5	NG 	O	two	3	1	1
B	O	6	NG 	O	one	39	1	1
B	O	6	NG 	O	three	0	1	1
B	O	6	NG 	O	two	18	1	1
B	O	7	NG 	O	one	14	1	1
B	O	7	NG 	O	three	0	1	1
B	O	7	NG 	O	two	9	1	1
B	O	8	NG 	O	one	7	1	1
B	O	8	NG 	O	three	1	1	1
B	O	8	NG 	O	two	1	1	1
B	O	9	NG 	O	one	17	1	1
B	O	9	NG 	O	three	3	1	1
B	O	9	NG 	O	two	4	1	1
B	O	10	NG 	O	one	43	1	1
B	O	10	NG 	O	three	0	1	1
B	O	10	NG 	O	two	0	1	1
B	O	11	NG 	O	one	1	1	1
B	O	11	NG 	O	three	0	1	1
B	O	11	NG 	O	two	0	1	1
B	O	12	NG 	O	one	1	1	1
B	O	12	NG 	O	three	1	1	1
B	O	12	NG 	O	two	2	1	1
B	O	13	NG 	O	one	14	1	1
B	O	13	NG 	O	three	0	1	1
B	O	13	NG 	O	two	0	1	1
B	O	14	NG 	O	one	3	1	1
B	O	14	NG 	O	three	0	1	1
B	O	14	NG 	O	two	0	1	1
B	O	15	NG 	O	one	10	1	1
B	O	15	NG 	O	three	4	1	1
B	O	15	NG 	O	two	9	1	1
B	O	16	NG 	O	one	2	1	1
B	O	16	NG 	O	three	0	1	1
B	O	16	NG 	O	two	0	1	1
B	O	17	NG 	O	one	26	1	1
B	O	17	NG 	O	three	0	1	1
B	O	17	NG 	O	two	3	1	1
B	O	18	NG 	O	one	18	1	1
B	O	18	NG 	O	three	1	1	1
B	O	18	NG 	O	two	3	1	1
B	O	19	NG 	O	one	22	1	1
B	O	19	NG 	O	three	1	1	1
B	O	19	NG 	O	two	2	1	1
B	O	20	NG 	O	one	15	1	1
B	O	20	NG 	O	three	6	1	1
B	O	20	NG 	O	two	11	1	1
F	O	2	NG 	O	one	64	1	1
F	O	2	NG 	O	three	4	1	1
F	O	2	NG 	O	two	11	1	1
F	O	3	NG 	O	one	26	1	1
F	O	3	NG 	O	three	0	1	1
F	O	3	NG 	O	two	1	1	1
F	O	4	NG 	O	one	34	1	1
F	O	4	NG 	O	three	4	1	1
F	O	4	NG 	O	two	6	1	1
F	O	5	NG 	O	one	16	1	1
F	O	5	NG 	O	three	0	1	1
F	O	5	NG 	O	two	3	1	1
F	O	6	NG 	O	one	7	1	1
F	O	6	NG 	O	three	0	1	1
F	O	6	NG 	O	two	0	1	1
F	O	7	NG 	O	one	20	1	1
F	O	7	NG 	O	three	0	1	1
F	O	7	NG 	O	two	0	1	1
F	O	8	NG 	O	one	20	1	1
F	O	8	NG 	O	three	0	1	1
F	O	8	NG 	O	two	1	1	1
F	O	9	NG 	O	one	29	1	1
F	O	9	NG 	O	three	0	1	1
F	O	9	NG 	O	two	0	1	1
F	O	10	NG 	O	one	0	1	1
F	O	10	NG 	O	three	0	1	1
F	O	10	NG 	O	two	0	1	1
F	O	11	NG 	O	one	4	1	1
F	O	11	NG 	O	three	1	1	1
F	O	11	NG 	O	two	3	1	1
F	O	12	NG 	O	one	7	1	1
F	O	12	NG 	O	three	0	1	1
F	O	12	NG 	O	two	0	1	1
F	O	13	NG 	O	one	3	1	1
F	O	13	NG 	O	three	0	1	1
F	O	13	NG 	O	two	1	1	1
F	O	14	NG 	O	one	4	1	1
F	O	14	NG 	O	three	1	1	1
F	O	14	NG 	O	two	0	1	1
F	O	15	NG 	O	one	7	1	1
F	O	15	NG 	O	three	0	1	1
F	O	15	NG 	O	two	0	1	1
F	O	16	NG 	O	one	4	1	1
F	O	16	NG 	O	three	0	1	1
F	O	16	NG 	O	two	0	1	1
F	O	17	NG 	O	one	34	1	1
F	O	17	NG 	O	three	3	1	1
F	O	17	NG 	O	two	6	1	1
F	O	18	NG 	O	one	11	1	1
F	O	18	NG 	O	three	2	1	1
F	O	18	NG 	O	two	10	1	1
F	O	19	NG 	O	one	14	1	1
F	O	19	NG 	O	three	2	1	1
F	O	19	NG 	O	two	7	1	1
F	O	20	NG 	O	one	0	1	1
F	O	20	NG 	O	three	0	1	1
F	O	20	NG 	O	two	0	1	1
P	O	1	NG 	O	one	0	1	1
P	O	1	NG 	O	three	0	1	1
P	O	1	NG 	O	two	0	1	1
P	O	2	NG 	O	one	9	1	1
P	O	2	NG 	O	three	0	1	1
P	O	2	NG 	O	two	1	1	1
P	O	4	NG 	O	one	12	1	1
P	O	4	NG 	O	three	1	1	1
P	O	4	NG 	O	two	2	1	1
P	O	5	NG 	O	one	12	1	1
P	O	5	NG 	O	three	1	1	1
P	O	5	NG 	O	two	1	1	1
P	O	6	NG 	O	one	20	1	1
P	O	6	NG 	O	three	0	1	1
P	O	6	NG 	O	two	0	1	1
P	O	7	NG 	O	one	10	1	1
P	O	7	NG 	O	three	0	1	1
P	O	7	NG 	O	two	0	1	1
P	O	8	NG 	O	one	7	1	1
P	O	8	NG 	O	three	0	1	1
P	O	8	NG 	O	two	1	1	1
P	O	9	NG 	O	one	5	1	1
P	O	9	NG 	O	three	0	1	1
P	O	9	NG 	O	two	2	1	1
P	O	10	NG 	O	one	8	1	1
P	O	10	NG 	O	three	0	1	1
P	O	10	NG 	O	two	6	1	1
P	O	11	NG 	O	one	0	1	1
P	O	11	NG 	O	three	0	1	1
P	O	11	NG 	O	two	0	1	1
P	O	12	NG 	O	one	0	1	1
P	O	12	NG 	O	three	0	1	1
P	O	12	NG 	O	two	1	1	1
P	O	13	NG 	O	one	0	1	1
P	O	13	NG 	O	three	0	1	1
P	O	13	NG 	O	two	0	1	1
P	O	14	NG 	O	one	2	1	1
P	O	14	NG 	O	three	0	1	1
P	O	14	NG 	O	two	0	1	1
P	O	15	NG 	O	one	0	1	1
P	O	15	NG 	O	three	0	1	1
P	O	15	NG 	O	two	0	1	1
P	O	16	NG 	O	one	0	1	1
P	O	16	NG 	O	three	0	1	1
P	O	16	NG 	O	two	0	1	1
P	O	17	NG 	O	one	18	1	1
P	O	17	NG 	O	three	0	1	1
P	O	17	NG 	O	two	0	1	1
P	O	18	NG 	O	one	1	1	1
P	O	18	NG 	O	three	0	1	1
P	O	18	NG 	O	two	0	1	1
P	O	19	NG 	O	one	9	1	1
P	O	19	NG 	O	three	1	1	1
P	O	19	NG 	O	two	3	1	1
P	O	20	NG 	O	one	5	1	1
P	O	20	NG 	O	three	0	1	1
P	O	20	NG 	O	two	0	1	1

