From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Jul  1 13:57:47 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 1 Jul 2019 11:57:47 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature - GLMMadaptive
 0.6-0
Message-ID: <47630061-43ae-dd24-b009-243730040dc4@erasmusmc.nl>

Dear R mixed-model users,

A new version of GLMMadaptive (0.6-0) has been rolled out on CRAN.

Summary: GLMMadaptive fits mixed effects models using adaptive
Gaussian quadrature to approximate the integrals over the random
effects, allowing also for user-specified models.

Website: https://drizopoulos.github.io/GLMMadaptive/

New features:

- Mixed models for ordinal grouped/clustered outcomes using the 
continuation ratio model, with forward and backward formulation. A 
worked example can be found in the online vignette: 
https://drizopoulos.github.io/GLMMadaptive/articles/Ordinal_Mixed_Models.html

- The new function VIF() calculates variance inflation factors for mixed 
models fitted in the package.

- New family object unit.lindley() for fitting mixed models for bounded 
outcomes; an alternative to the Beta mixed model.

- Faster implementation of the numerical integration algorithm.

As always, any kind of feedback is more than welcome.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From @d@1000 @end|ng |rom c@m@@c@uk  Tue Jul  2 00:34:25 2019
From: @d@1000 @end|ng |rom c@m@@c@uk (S.D. Silver)
Date: Mon, 01 Jul 2019 15:34:25 -0700
Subject: [R-sig-ME] lme4
Message-ID: <cf1c89359668eb324ae8e3f8ad1c51ef@cam.ac.uk>

I am working with an r code procedure for a ARFIMA mutilevel model that 
estimates a
linear mixed model fit by REMLP['lmermod']. I have now been asked to 
compare the model's results with alternatives that include ARFIMA-LDV. 
The only output diagnostics that the code provides in addition to 
parameter estimates is shown below :

      " REML criterion at convergence: 1694929 Scaled residuals:
      Min 1Q Median 3Q Max -3.4407 -0.7361 0.0482 0.7791 2.9853

      Random effects: Groups Name Variance Std.Dev.  time
      (Intercept) 42.5 6.519 Residual 1229.0 35.057 Number of
      obs: 170217, groups: time, 363"

I understand that REML is most directly about estimatingvariance 
components, but is it meaningful to consider it
  as a measure of fit in comparing nested models. Here the alternatives 
are LDV and an MLM that is not fractionally differenced.

Given the difference in estimation methodology, I do not think it is 
feasible to compare 'lmermod' with alternatives in OLS.Do any comparable 
model variants for comparison in the estimation procedure of lme4 come 
to mind ?

Would be grateful for any observations that you could provide.

Steven


From bbo|ker @end|ng |rom gm@||@com  Tue Jul  2 13:30:04 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 2 Jul 2019 07:30:04 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <cf1c89359668eb324ae8e3f8ad1c51ef@cam.ac.uk>
References: <cf1c89359668eb324ae8e3f8ad1c51ef@cam.ac.uk>
Message-ID: <b3e538f5-3d8e-eef5-c608-4a1b660d7494@gmail.com>


  I'm not sure I understand all the details of your modeling framework,
but in general it's dangerous to compare REML for models with differing
fixed effects (which would probably? also include models with different
types of differencing).  It might help if you provided some more
background (what is REMLP,  is 'lmermod' a function or a package, what
is LDV, ... ?)

 cheers
   Ben Bolker

On 2019-07-01 6:34 p.m., S.D. Silver wrote:
> I am working with an r code procedure for a ARFIMA mutilevel model that
> estimates a
> linear mixed model fit by REMLP['lmermod']. I have now been asked to
> compare the model's results with alternatives that include ARFIMA-LDV.
> The only output diagnostics that the code provides in addition to
> parameter estimates is shown below :
> 
> ???? " REML criterion at convergence: 1694929 Scaled residuals:
> ???? Min 1Q Median 3Q Max -3.4407 -0.7361 0.0482 0.7791 2.9853
> 
> ???? Random effects: Groups Name Variance Std.Dev.? time
> ???? (Intercept) 42.5 6.519 Residual 1229.0 35.057 Number of
> ???? obs: 170217, groups: time, 363"
> 
> I understand that REML is most directly about estimatingvariance
> components, but is it meaningful to consider it
> ?as a measure of fit in comparing nested models. Here the alternatives
> are LDV and an MLM that is not fractionally differenced.
> 
> Given the difference in estimation methodology, I do not think it is
> feasible to compare 'lmermod' with alternatives in OLS.Do any comparable
> model variants for comparison in the estimation procedure of lme4 come
> to mind ?
> 
> Would be grateful for any observations that you could provide.
> 
> Steven
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Jul  3 01:55:05 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 2 Jul 2019 19:55:05 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <246c1fd7c63a97f4dbad6f8bed32b951@cam.ac.uk>
References: <cf1c89359668eb324ae8e3f8ad1c51ef@cam.ac.uk>
 <b3e538f5-3d8e-eef5-c608-4a1b660d7494@gmail.com>
 <246c1fd7c63a97f4dbad6f8bed32b951@cam.ac.uk>
Message-ID: <aa1466d8-1015-bf6b-2a91-6317a8c29235@gmail.com>


  Please keep r-sig-mixed-models in the Cc: list ...
  Brief comments below.

On 2019-07-02 6:33 p.m., S.D. Silver wrote:
> On 2019-07-02 04:30, Ben Bolker wrote:
>> I'm not sure I understand all the details of your modeling framework,
>> but in general it's dangerous to compare REML for models with differing
>> fixed effects (which would probably? also include models with different
>> types of differencing).? It might help if you provided some more
>> background (what is REMLP,? is 'lmermod' a function or a package, what
>> is LDV, ... ?)
>>
>> ?cheers
>> ?? Ben Bolker
>>
>> On 2019-07-01 6:34 p.m., S.D. Silver wrote:
>>> I am working with an r code procedure for a ARFIMA mutilevel model that
>>> estimates a
>>> linear mixed model fit by REMLP['lmermod']. I have now been asked to
>>> compare the model's results with alternatives that include ARFIMA-LDV.
>>> The only output diagnostics that the code provides in addition to
>>> parameter estimates is shown below :
>>>
>>> ???? " REML criterion at convergence: 1694929 Scaled residuals:
>>> ???? Min 1Q Median 3Q Max -3.4407 -0.7361 0.0482 0.7791 2.9853
>>>
>>> ???? Random effects: Groups Name Variance Std.Dev.? time
>>> ???? (Intercept) 42.5 6.519 Residual 1229.0 35.057 Number of
>>> ???? obs: 170217, groups: time, 363"
>>>
>>> I understand that REML is most directly about estimatingvariance
>>> components, but is it meaningful to consider it
>>> ?as a measure of fit in comparing nested models. Here the alternatives
>>> are LDV and an MLM that is not fractionally differenced.
>>>
>>> Given the difference in estimation methodology, I do not think it is
>>> feasible to compare 'lmermod' with alternatives in OLS.Do any comparable
>>> model variants for comparison in the estimation procedure of lme4 come
>>> to mind ?
>>>
>>> Would be grateful for any observations that you could provide.
>>>
>>> Steven
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Ben,
> ARFIMA-MLM is a multi-level Arfima model. You can review the package at
> https://pwkraft.github.io/resources/articles/ArfimaMLM-documentation.pdf.
> In the messaget that I posted, REMLP should not had the P. That is a
> typographical error. lmermod is basically a linear function for a mixed
> Model in R. LDV is a model with a lagged dependent variable. Our
> challenge here is to comply with a reviewer request to compare the
> results of our empirical estimation in ARFIMA-MLM to alternatives. I am
> more familiar with models in which we could use mean square error or its
> square root as a measure of fit and have post-estimation diagnostics.
> The output that ARFIMA-MLM provides only includes REML as summary
> statistics. Among alternative estimation procedures, MLM and MLM-LDV do
> not use fractional differencing. The ARFIMA results used lme4 and should
> generate whatever options are available in the R estimation procedure
> for lmer. I understand that REML is essentially a summary statistic that
> is most suitable for estimating the variance component in a random
> effects model.
> 
> My inquiry is really in two parts. First, is there a meaning full
> comparison across estimation models with an implementation in lmer.
> Second, what can be a suitable exercise with REML in variance
> decomposition in lmer?
> 

   The topic of model comparison/goodness-of-fit metrics for multilevel
models is a bit of a quagmire. The (googlable) GLMM FAQ gives some
suggestions for computing R^2 values for multilevel models, but there's
no simple one-size-fits-all answer -- and it will probably get even more
delicate if you try to extend to encompass more different model
structures.  My advice would be that if there is some concrete goal you
are trying to achieve (e.g. one-step-ahead forecasting) and you can come
up with a simple way to quantify your success, that will be the way to
compare the different approaches ...

  cheers
    Ben Bolker


From je@u@@|r|@@ @end|ng |rom d|t@|e  Wed Jul  3 14:39:54 2019
From: je@u@@|r|@@ @end|ng |rom d|t@|e (Jesus Maria Frias Celayeta)
Date: Wed, 3 Jul 2019 13:39:54 +0100
Subject: [R-sig-ME] Simulation of nlme models
Message-ID: <CAErBVpPfx2+eUkp1wV7_p1J2+2m8ugKFzL9HUDOxd5AyfxYFCA@mail.gmail.com>

Hi all,

I've observe a behaviour of predict for 2 level nlme objects that is a bit
unexpected.
If we want to make a level 1 prediction for a 2 level nlme with newdata I
get NA
The toy example (I've got other models that haven't worked either)
library(nlme)
fm1 <- nlme(current ~ A + B * cos(w * voltage + pi/4),
            data = Wafer,
            fixed = list(A ~ voltage + I(voltage^2), B + w ~ 1),
            random = list(Wafer = pdDiag(list(A ~ voltage + I(voltage^2),
                                              B + w ~ 1)),
                          Site = pdDiag(list(A ~
                                               voltage+I(voltage^2),
                                             B ~ 1))),
            start = c(-4.255, 5.622, 1.258,
                      -0.09555, 4.5679))
summary(predict(fm1,newdata=Wafer,level=1))

I'm trying to make simulations using nlme objects and if someone had a hint
on how to develop simulations from random effect distributions using nlme
objects. In my case I'm trying to assess effect of variability (my random
effects) and uncertainty on the prediction of the model.

I've found some examples of bootstrapping but they seem to work only in
perfectly balanced data (same units in all level 1, same number of samples
within level 2 cases).

https://stats.stackexchange.com/questions/232928/non-linear-mixed-model-nlme-with-nested-random-effect-do-not-know-how-to-incl

Any hint will be appreciated!

regards,

Jesus


-- 
[image: turn on images] <https://www.tudublin.ie/>

Jesus Maria Frias Celayeta

Professor and Academic Leader ESHI

City Campus
________________________________________

? +353 1 402 5410  ? +353 87 9697289  ? tudublin.ie

OT Baile ?tha Cliath - Environmental Sustainability and Health Institute,
Grangegorman Campus, D07 H6K8, Ireland

-- 


*This email originated from?TU?Dublin. If you received this email in 
error, please delete it from your system. Please note that if you are not 
the named addressee, disclosing, copying, distributing or taking any action
based on the contents of this email or attachments is prohibited.?*******


*Is ? OT Baile ?tha Cliath a th?inig an r?omhphost seo. M? fuair t? an 
r?omhphost seo tr? earr?id, scrios de do ch?ras ? le do thoil. Tabhair ar 
aird, mura t? an seola? ainmnithe, go bhfuil dianchosc ar aon nochtadh, aon 
ch?ipe?il, aon d?ileadh n? ar aon ghn?omh a dh?anfar bunaithe ar an ?bhar 
at? sa r?omhphost n? sna hiat?in seo.*

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Tue Jul  9 15:49:08 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Tue, 9 Jul 2019 15:49:08 +0200
Subject: [R-sig-ME] Question about non-significant interactions
Message-ID: <CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>

Dear all,


I have more of a theoretical than practical question for you. The model I
am using has two IVs, group (3 levels) and task (2 levels), and a
categorical DV (correct versus incorrect), hence logistic regression.
Random effects for subjects and items, as well as slopes for group by item
and task by subject.

I am interested in the effect of belonging any of three groups, the levels
of the group IV, in order to test some a priori predictions. The bayesian
wrapper is to help the model converge.

Here is the output:

> summary(paper2analysis1)
Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : Participant ~ wishart(df = 4.5, scale = Inf, posterior.scale =
cov, common.scale = TRUE)
Prior dev  : 6.9466

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
 group | item)
   Data: data
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  3857.8   3957.2  -1913.9   3827.8     5570

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.0196 -0.3744 -0.2312 -0.1368  6.9534

Random effects:
 Groups      Name        Variance Std.Dev. Corr
 item        (Intercept) 1.1266   1.0614
             groupL2     0.1311   0.3620   -0.12
             groupNS     0.2029   0.4504   -0.31  0.17
 Participant (Intercept) 0.7582   0.8708
             taskpriming 1.2163   1.1029   -0.77
Number of obs: 5585, groups:  item, 219; Participant, 46

Fixed effects:
                    Estimate Std. Error z value Pr(>|z|)
(Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
taskpriming          1.30911    0.37367   3.503 0.000459 ***
groupL2             -0.04042    0.38322  -0.105 0.916005
groupNS             -1.01144    0.36607  -2.763 0.005727 **
taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) tskprm gropL2 gropNS tsk:L2
taskpriming -0.733
groupL2     -0.660  0.482
groupNS     -0.693  0.507  0.509
tskprmng:L2  0.499 -0.632 -0.755 -0.386
tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508

The model was then subjected to car::Anova for ANOVA type III analysis with
the following output:

> car::Anova(paper2analysis1, type = "III")
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: correctness
              Chisq Df Pr(>Chisq)
(Intercept) 77.4344  1  < 2.2e-16 ***
task        12.2737  1  0.0004594 ***
group        9.9237  2  0.0070000 **
task:group   0.0391  2  0.9806462
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I am not sure how to interpret the non-significant interaction in this
case. Does this mean that, although simple effects exist at group level
within one particular task or at task level within one particular group, I
lack sufficient power to conclude those effects are real? If I look at the
simple effects, I do indeed find such effects but am not sure how to
interpret them against the lack of a main interaction. At a practical
level, the interaction, rather than the main effects, is the most important
part of the analysis.

Thank you in advance for any advice.

Francesco





Best,

Frank

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jul  9 23:03:34 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 9 Jul 2019 21:03:34 +0000
Subject: [R-sig-ME] Question about non-significant interactions
In-Reply-To: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>

Dear Francesco,

I didn't entirely follow your question and I expect that to answer it, it would be necessary to know more about what your research entails. As you imply, this seems to be more a statistics question than an R question. It's also not clear to me what function you used to fit the mixed-effects logistic regression.

But I did notice that you're apparently using Anova() for type-III tests with the default contr.treatment() coding for factors. The main-effect tests that result are not sensible. As it says in ?Anova:

"Warning
Be careful of type-III tests: For a traditional multifactor ANOVA model with interactions, for example, these tests will normally only be sensible when using contrasts that, for different terms, are orthogonal in the row-basis of the model, such as those produced by contr.sum, contr.poly, or contr.helmert, but not by the default contr.treatment. In a model that contains factors, numeric covariates, and interactions, main-effect tests for factors will be for differences over the origin. In contrast (pun intended), type-II tests are invariant with respect to (full-rank) contrast coding. If you don't understand this issue, then you probably shouldn't use Anova for type-III tests."

I hope that this is of some help,
 John
-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Francesco Romano [fbromano77 at gmail.com]
Sent: July 9, 2019 9:49 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question about non-significant interactions

Dear all,


I have more of a theoretical than practical question for you. The model I
am using has two IVs, group (3 levels) and task (2 levels), and a
categorical DV (correct versus incorrect), hence logistic regression.
Random effects for subjects and items, as well as slopes for group by item
and task by subject.

I am interested in the effect of belonging any of three groups, the levels
of the group IV, in order to test some a priori predictions. The bayesian
wrapper is to help the model converge.

Here is the output:

> summary(paper2analysis1)
Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : Participant ~ wishart(df = 4.5, scale = Inf, posterior.scale =
cov, common.scale = TRUE)
Prior dev  : 6.9466

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['bglmerMod']
 Family: binomial  ( logit )
Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
 group | item)
   Data: data
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  3857.8   3957.2  -1913.9   3827.8     5570

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.0196 -0.3744 -0.2312 -0.1368  6.9534

Random effects:
 Groups      Name        Variance Std.Dev. Corr
 item        (Intercept) 1.1266   1.0614
             groupL2     0.1311   0.3620   -0.12
             groupNS     0.2029   0.4504   -0.31  0.17
 Participant (Intercept) 0.7582   0.8708
             taskpriming 1.2163   1.1029   -0.77
Number of obs: 5585, groups:  item, 219; Participant, 46

Fixed effects:
                    Estimate Std. Error z value Pr(>|z|)
(Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
taskpriming          1.30911    0.37367   3.503 0.000459 ***
groupL2             -0.04042    0.38322  -0.105 0.916005
groupNS             -1.01144    0.36607  -2.763 0.005727 **
taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) tskprm gropL2 gropNS tsk:L2
taskpriming -0.733
groupL2     -0.660  0.482
groupNS     -0.693  0.507  0.509
tskprmng:L2  0.499 -0.632 -0.755 -0.386
tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508

The model was then subjected to car::Anova for ANOVA type III analysis with
the following output:

> car::Anova(paper2analysis1, type = "III")
Analysis of Deviance Table (Type III Wald chisquare tests)

Response: correctness
              Chisq Df Pr(>Chisq)
(Intercept) 77.4344  1  < 2.2e-16 ***
task        12.2737  1  0.0004594 ***
group        9.9237  2  0.0070000 **
task:group   0.0391  2  0.9806462
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I am not sure how to interpret the non-significant interaction in this
case. Does this mean that, although simple effects exist at group level
within one particular task or at task level within one particular group, I
lack sufficient power to conclude those effects are real? If I look at the
simple effects, I do indeed find such effects but am not sure how to
interpret them against the lack of a main interaction. At a practical
level, the interaction, rather than the main effects, is the most important
part of the analysis.

Thank you in advance for any advice.

Francesco





Best,

Frank

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |brom@no77 @end|ng |rom gm@||@com  Tue Jul  9 23:24:41 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Tue, 9 Jul 2019 23:24:41 +0200
Subject: [R-sig-ME] Fwd:  Question about non-significant interactions
In-Reply-To: <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
Message-ID: <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>

---------- Forwarded message ---------
From: Francesco Romano <fbromano77 at gmail.com>
Date: Tue, Jul 9, 2019 at 11:24 PM
Subject: Re: [R-sig-ME] Question about non-significant interactions
To: Fox, John <jfox at mcmaster.ca>


Dear John,

Thanks for the reply. One of my research entails examining the relationship
between 3 groups of speakers, the 3 levels of the group categorical
variable previously mentioned, and two tasks. One prediction is that one
group will perform better than other groups on one test but not the other.

I fit a maximal model using the bglmr function as shown previously, then
used car::Anova to determine main effects. My understanding from previous
interaction with you precisely here on r-sig-me is that the function works
as a form of shortcut to the traditional way of model-fitting/ reduction
via the function anova() comparing models, eliminating terms one at a time.

I hope this is clearer now and yes, the question is more of a statistical
one than an R one, even though I suspect the mixed-effect aspect of the
regression may be relevant to answering it.

Frank

 Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Francesco,
>
> I didn't entirely follow your question and I expect that to answer it, it
> would be necessary to know more about what your research entails. As you
> imply, this seems to be more a statistics question than an R question. It's
> also not clear to me what function you used to fit the mixed-effects
> logistic regression.
>
> But I did notice that you're apparently using Anova() for type-III tests
> with the default contr.treatment() coding for factors. The main-effect
> tests that result are not sensible. As it says in ?Anova:
>
> "Warning
> Be careful of type-III tests: For a traditional multifactor ANOVA model
> with interactions, for example, these tests will normally only be sensible
> when using contrasts that, for different terms, are orthogonal in the
> row-basis of the model, such as those produced by contr.sum, contr.poly, or
> contr.helmert, but not by the default contr.treatment. In a model that
> contains factors, numeric covariates, and interactions, main-effect tests
> for factors will be for differences over the origin. In contrast (pun
> intended), type-II tests are invariant with respect to (full-rank) contrast
> coding. If you don't understand this issue, then you probably shouldn't use
> Anova for type-III tests."
>
> I hope that this is of some help,
>  John
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
>
>
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Francesco Romano [fbromano77 at gmail.com]
> Sent: July 9, 2019 9:49 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Question about non-significant interactions
>
> Dear all,
>
>
> I have more of a theoretical than practical question for you. The model I
> am using has two IVs, group (3 levels) and task (2 levels), and a
> categorical DV (correct versus incorrect), hence logistic regression.
> Random effects for subjects and items, as well as slopes for group by item
> and task by subject.
>
> I am interested in the effect of belonging any of three groups, the levels
> of the group IV, in order to test some a priori predictions. The bayesian
> wrapper is to help the model converge.
>
> Here is the output:
>
> > summary(paper2analysis1)
> Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
>            : Participant ~ wishart(df = 4.5, scale = Inf, posterior.scale =
> cov, common.scale = TRUE)
> Prior dev  : 6.9466
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['bglmerMod']
>  Family: binomial  ( logit )
> Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
>  group | item)
>    Data: data
> Control: glmerControl(optimizer = "bobyqa")
>
>      AIC      BIC   logLik deviance df.resid
>   3857.8   3957.2  -1913.9   3827.8     5570
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.0196 -0.3744 -0.2312 -0.1368  6.9534
>
> Random effects:
>  Groups      Name        Variance Std.Dev. Corr
>  item        (Intercept) 1.1266   1.0614
>              groupL2     0.1311   0.3620   -0.12
>              groupNS     0.2029   0.4504   -0.31  0.17
>  Participant (Intercept) 0.7582   0.8708
>              taskpriming 1.2163   1.1029   -0.77
> Number of obs: 5585, groups:  item, 219; Participant, 46
>
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> taskpriming          1.30911    0.37367   3.503 0.000459 ***
> groupL2             -0.04042    0.38322  -0.105 0.916005
> groupNS             -1.01144    0.36607  -2.763 0.005727 **
> taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) tskprm gropL2 gropNS tsk:L2
> taskpriming -0.733
> groupL2     -0.660  0.482
> groupNS     -0.693  0.507  0.509
> tskprmng:L2  0.499 -0.632 -0.755 -0.386
> tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
>
> The model was then subjected to car::Anova for ANOVA type III analysis with
> the following output:
>
> > car::Anova(paper2analysis1, type = "III")
> Analysis of Deviance Table (Type III Wald chisquare tests)
>
> Response: correctness
>               Chisq Df Pr(>Chisq)
> (Intercept) 77.4344  1  < 2.2e-16 ***
> task        12.2737  1  0.0004594 ***
> group        9.9237  2  0.0070000 **
> task:group   0.0391  2  0.9806462
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> I am not sure how to interpret the non-significant interaction in this
> case. Does this mean that, although simple effects exist at group level
> within one particular task or at task level within one particular group, I
> lack sufficient power to conclude those effects are real? If I look at the
> simple effects, I do indeed find such effects but am not sure how to
> interpret them against the lack of a main interaction. At a practical
> level, the interaction, rather than the main effects, is the most important
> part of the analysis.
>
> Thank you in advance for any advice.
>
> Francesco
>
>
>
>
>
> Best,
>
> Frank
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Inviato da Gmail Mobile
-- 
Inviato da Gmail Mobile

	[[alternative HTML version deleted]]


From jonn@t|on@ @end|ng |rom gm@||@com  Wed Jul 10 04:38:01 2019
From: jonn@t|on@ @end|ng |rom gm@||@com (jonnations)
Date: Tue, 9 Jul 2019 22:38:01 -0400
Subject: [R-sig-ME] Modeling group-level effects with unequal #s of
 "subgroups"
Message-ID: <CAHta4sPAMaNytr99QEfXFENw_zMv=zGQ_OSVZhZFOYCePZq7zA@mail.gmail.com>

Hi list,

I am working on what may be a simple problem, but I can?t quite wrap my
head around it. I have spent time searching for a solution to a problem
like this, but I must not be using the correct terminology in my searches.

I am trying to construct a simple linear model with one response, one
predictor, and a group level factor (3 islands in this case). The hard part
is that one of the 3 ?islands? is composed of multiple smaller islands.
Here is a small fake data set:

size <- c(5,6,4,5,3,5,6,6,4,3,2)
age <- c(5,10,2,5,10,3,10,3,3,10,3)
island <- c("A", "A", "B", "B", "B", "C", "C", "C", "C", "C" , "C")
sub-island <- c(NA, NA, NA, NA, NA, "C1", "C1" , "C1", "C2", "C2", "C2")
df_test <- data.frame(size, age, island, sub-island)

Writing a simple model such as
`size ~ 1 + age + (age | island)`
ignores the hierarchical structure of group C, which is important in my
case. However, modeling
`size ~ 1 + age + (age | island) + (age | sub-island)`
would not work as islands A and B do not have this sub-structure. One
alternative may be to assign the other "sub-island" groups to single groups
(i.e. "A1 for all "A's", etc) but I'm not sure if this is appropriate or
not.

If anyone provide some useful information on how to construct this model I
would be very grateful. I am used to modeling in brms, which uses basically
the same syntax as lme4. Alternatively, if anyone could tell me what this
type of data structure is called, then I could better search for options on
my own.

Thank you for helping this beginner,
Jon

-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab <https://esselstyn.github.io/>
Museum of Natural Sciences <https://www.lsu.edu/mns/>
Louisiana State University

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jul 10 08:51:42 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 10 Jul 2019 08:51:42 +0200
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
Message-ID: <CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>

Dear Francesco,

To answer your question, you should convert your hypothesis in a set of
linear contrasts and test those.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 9 jul. 2019 om 23:25 schreef Francesco Romano <fbromano77 at gmail.com>:

> ---------- Forwarded message ---------
> From: Francesco Romano <fbromano77 at gmail.com>
> Date: Tue, Jul 9, 2019 at 11:24 PM
> Subject: Re: [R-sig-ME] Question about non-significant interactions
> To: Fox, John <jfox at mcmaster.ca>
>
>
> Dear John,
>
> Thanks for the reply. One of my research entails examining the relationship
> between 3 groups of speakers, the 3 levels of the group categorical
> variable previously mentioned, and two tasks. One prediction is that one
> group will perform better than other groups on one test but not the other.
>
> I fit a maximal model using the bglmr function as shown previously, then
> used car::Anova to determine main effects. My understanding from previous
> interaction with you precisely here on r-sig-me is that the function works
> as a form of shortcut to the traditional way of model-fitting/ reduction
> via the function anova() comparing models, eliminating terms one at a time.
>
> I hope this is clearer now and yes, the question is more of a statistical
> one than an R one, even though I suspect the mixed-effect aspect of the
> regression may be relevant to answering it.
>
> Frank
>
>  Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:
>
> > Dear Francesco,
> >
> > I didn't entirely follow your question and I expect that to answer it, it
> > would be necessary to know more about what your research entails. As you
> > imply, this seems to be more a statistics question than an R question.
> It's
> > also not clear to me what function you used to fit the mixed-effects
> > logistic regression.
> >
> > But I did notice that you're apparently using Anova() for type-III tests
> > with the default contr.treatment() coding for factors. The main-effect
> > tests that result are not sensible. As it says in ?Anova:
> >
> > "Warning
> > Be careful of type-III tests: For a traditional multifactor ANOVA model
> > with interactions, for example, these tests will normally only be
> sensible
> > when using contrasts that, for different terms, are orthogonal in the
> > row-basis of the model, such as those produced by contr.sum, contr.poly,
> or
> > contr.helmert, but not by the default contr.treatment. In a model that
> > contains factors, numeric covariates, and interactions, main-effect tests
> > for factors will be for differences over the origin. In contrast (pun
> > intended), type-II tests are invariant with respect to (full-rank)
> contrast
> > coding. If you don't understand this issue, then you probably shouldn't
> use
> > Anova for type-III tests."
> >
> > I hope that this is of some help,
> >  John
> > -----------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > web: socserv.mcmaster.ca/jfox
> >
> >
> > ________________________________________
> > From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> > behalf of Francesco Romano [fbromano77 at gmail.com]
> > Sent: July 9, 2019 9:49 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Question about non-significant interactions
> >
> > Dear all,
> >
> >
> > I have more of a theoretical than practical question for you. The model I
> > am using has two IVs, group (3 levels) and task (2 levels), and a
> > categorical DV (correct versus incorrect), hence logistic regression.
> > Random effects for subjects and items, as well as slopes for group by
> item
> > and task by subject.
> >
> > I am interested in the effect of belonging any of three groups, the
> levels
> > of the group IV, in order to test some a priori predictions. The bayesian
> > wrapper is to help the model converge.
> >
> > Here is the output:
> >
> > > summary(paper2analysis1)
> > Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
> > common.scale = TRUE)
> >            : Participant ~ wishart(df = 4.5, scale = Inf,
> posterior.scale =
> > cov, common.scale = TRUE)
> > Prior dev  : 6.9466
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['bglmerMod']
> >  Family: binomial  ( logit )
> > Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> >  group | item)
> >    Data: data
> > Control: glmerControl(optimizer = "bobyqa")
> >
> >      AIC      BIC   logLik deviance df.resid
> >   3857.8   3957.2  -1913.9   3827.8     5570
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -2.0196 -0.3744 -0.2312 -0.1368  6.9534
> >
> > Random effects:
> >  Groups      Name        Variance Std.Dev. Corr
> >  item        (Intercept) 1.1266   1.0614
> >              groupL2     0.1311   0.3620   -0.12
> >              groupNS     0.2029   0.4504   -0.31  0.17
> >  Participant (Intercept) 0.7582   0.8708
> >              taskpriming 1.2163   1.1029   -0.77
> > Number of obs: 5585, groups:  item, 219; Participant, 46
> >
> > Fixed effects:
> >                     Estimate Std. Error z value Pr(>|z|)
> > (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> > taskpriming          1.30911    0.37367   3.503 0.000459 ***
> > groupL2             -0.04042    0.38322  -0.105 0.916005
> > groupNS             -1.01144    0.36607  -2.763 0.005727 **
> > taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> > taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) tskprm gropL2 gropNS tsk:L2
> > taskpriming -0.733
> > groupL2     -0.660  0.482
> > groupNS     -0.693  0.507  0.509
> > tskprmng:L2  0.499 -0.632 -0.755 -0.386
> > tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
> >
> > The model was then subjected to car::Anova for ANOVA type III analysis
> with
> > the following output:
> >
> > > car::Anova(paper2analysis1, type = "III")
> > Analysis of Deviance Table (Type III Wald chisquare tests)
> >
> > Response: correctness
> >               Chisq Df Pr(>Chisq)
> > (Intercept) 77.4344  1  < 2.2e-16 ***
> > task        12.2737  1  0.0004594 ***
> > group        9.9237  2  0.0070000 **
> > task:group   0.0391  2  0.9806462
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > I am not sure how to interpret the non-significant interaction in this
> > case. Does this mean that, although simple effects exist at group level
> > within one particular task or at task level within one particular group,
> I
> > lack sufficient power to conclude those effects are real? If I look at
> the
> > simple effects, I do indeed find such effects but am not sure how to
> > interpret them against the lack of a main interaction. At a practical
> > level, the interaction, rather than the main effects, is the most
> important
> > part of the analysis.
> >
> > Thank you in advance for any advice.
> >
> > Francesco
> >
> >
> >
> >
> >
> > Best,
> >
> > Frank
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> Inviato da Gmail Mobile
> --
> Inviato da Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @hm@dr215 m@iii@g oii tpg@com@@u  Wed Jul 10 10:44:22 2019
From: @hm@dr215 m@iii@g oii tpg@com@@u (@hm@dr215 m@iii@g oii tpg@com@@u)
Date: Wed, 10 Jul 2019 18:44:22 +1000
Subject: [R-sig-ME] Creating a for loop for a mixed-effects model with
 covariates
Message-ID: <000001d536fb$ad1dcc00$07596400$@tpg.com.au>

Hi

 

This is a repeated measures data, and I would like to use a mixed-effects
model to run this. The model includes; independent variables (e.g. ADRB2),
groups (GID), Time, and covariates (e.g. ADRB2_pre) and IDs for the repeated
measures (see below, the dataset). I have 59 variables (independent
variables) with 59 covariates (one for each independent variable). The
covariates are pre_treatment values. 

I am trying to use a "for loop" to run this for 59 variables and covariates
(pre-treatment values). There are two variables that will change in each
model in the loop (see below), how can I make a loop to different these two?


e.g. 

1) ADRB2: if this could be [i]; 2) ADRB2_pre (pre_treatment): is a covariate
(i+1) for variable ADRB2, not sure how this should be looped? 

 

These two variables are listed next to each other (i & i+1) in the
spreadsheet, how I can loop the second one (i+1) as a covariate in the
model? I then need to move to other variables (59 of them) in a loop, and so
on..
Below is a subset of my data, I have 6 groups with 4 subjects within each
group.

Your help would be greatly appreciated. 

I looked at the examples on the web, none of those that I found is similar
to what I intend to do. I was able to make a simple loop for the independent
variable, not for the covariates; and didn't work for 59 variables.

# This is my codes for a simple model

dat <- read.csv("ct_data.csv", header = TRUE, sep=",", na.strings = NA)

# exclude Time 0 form the dataset

dat1 <- subset(dat,   Time >0 , select=1:121) 

 

# factors

dat1$GID <- factor(dat1$GID); dat1$Time <- factor(dat1$Time)

 

library(nlme); 

#Mixed-effects model 

model <- lme(ADRB2 ~ GID + Time + ADRB2_pre, data = dat, random = ~ 1 | ID) 

summary(model)


Repeats

Time

Groups

Independent var_1

Covariate_var1

Independent var_2

Covariate_var2


ID

Time

GID

ADRB2

ADRB2_pre

ACE

ACE_pre


1

0

0

21.58

21.58

21.58

21.58


2

0

0

20.05

20.05

20.05

20.05


3

0

0

21.49

21.49

21.49

21.49


4

0

0

22.08

22.08

22.08

22.08


5

0

1

21.31

21.31

21.31

21.31


6

0

1

20.92

20.92

20.92

20.92


7

0

1

21.21

21.21

21.21

21.21


8

0

1

21.54

21.54

21.54

21.54


9

0

2

20.07

20.07

20.07

20.07


10

0

2

20.66

20.66

20.66

20.66


11

0

2

21.46

21.46

21.46

21.46


12

0

2

21.81

21.81

21.81

21.81


13

0

3

20.08

20.08

20.08

20.08


14

0

3

21.27

21.27

21.27

21.27


15

0

3

21.94

21.94

21.94

21.94


16

0

3

20.8

20.8

20.8

20.8


17

0

4

21.1

21.1

21.1

21.1


18

0

4

20.33

20.33

10.54

10.54


19

0

4

21.55

21.55

21.55

21.55


20

0

4

21.28

21.28

21.28

21.28


21

0

5

20.54

20.54

20.54

20.54


22

0

5

20.69

20.69

20.69

20.69


23

0

5

20.87

20.87

20.87

20.87


24

0

5

22.02

22.02

22.02

22.02


1

1

0

21.56

21.58

21.56

21.58


2

1

0

20.12

20.05

20.12

20.05


3

1

0

21.71

21.49

21.71

21.49


4

1

0

20.77

22.08

20.77

22.08


5

1

1

21.1

21.31

21.1

21.31


6

1

1

21.09

20.92

21.09

20.92


7

1

1

21.05

21.21

21.05

21.21


8

1

1

21.4

21.54

21.4

21.54


9

1

2

19.89

20.07

19.89

20.07


10

1

2

20.93

20.66

20.93

20.66


11

1

2

21.72

21.46

21.72

21.46


12

1

2

21.11

21.81

21.11

21.81


13

1

3

22.1

20.08

22.1

20.08


14

1

3

21.14

21.27

21.14

21.27


15

1

3

20.7

21.94

20.7

21.94


16

1

3

20.98

20.8

20.98

20.8


17

1

4

20.75

21.1

20.75

21.1


18

1

4

20.88

20.33

20.88

10.54


19

1

4

21.19

21.55

21.19

21.55


20

1

4

20.48

21.28

20.48

21.28


21

1

5

20.55

20.54

20.55

20.54


22

1

5

21.77

20.69

21.77

20.69


23

1

5

21.2

20.87

21.2

20.87


24

1

5

20.12

22.02

20.12

22.02


1

2

0

22.45

21.58

22.45

21.58


2

2

0

17.83

20.05

17.83

20.05


3

2

0

21.26

21.49

21.26

21.49


4

2

0

20.69

22.08

20.69

22.08


5

2

1

21.73

21.31

21.73

21.31


6

2

1

22.16

20.92

22.16

20.92


7

2

1

20.85

21.21

20.85

21.21


8

2

1

21.58

21.54

21.58

21.54


9

2

2

22.34

20.07

22.34

20.07


10

2

2

20.91

20.66

20.91

20.66


11

2

2

20.22

21.46

20.22

21.46


12

2

2

21.24

21.81

21.24

21.81


13

2

3

21.18

20.08

21.18

20.08


14

2

3

21.74

21.27

21.74

21.27


15

2

3

20.8

21.94

20.8

21.94


16

2

3

21.71

20.8

11.16

20.8


17

2

4

21.6

21.1

21.6

21.1


18

2

4

19.06

20.33

8.98

10.54


19

2

4

21.26

21.55

21.26

21.55


20

2

4

21.87

21.28

21.87

21.28


21

2

5

20.82

20.54

20.82

20.54


22

2

5

21.1

20.69

21.1

20.69


23

2

5

21.09

20.87

21.09

20.87


24

2

5

20.03

22.02

20.03

22.02

 

 

 


	[[alternative HTML version deleted]]


From p|erce@1 @end|ng |rom m@u@edu  Wed Jul 10 14:14:44 2019
From: p|erce@1 @end|ng |rom m@u@edu (Pierce, Steven)
Date: Wed, 10 Jul 2019 12:14:44 +0000
Subject: [R-sig-ME] Modeling group-level effects with unequal #s of
 "subgroups"
In-Reply-To: <CAHta4sPAMaNytr99QEfXFENw_zMv=zGQ_OSVZhZFOYCePZq7zA@mail.gmail.com>
References: <CAHta4sPAMaNytr99QEfXFENw_zMv=zGQ_OSVZhZFOYCePZq7zA@mail.gmail.com>
Message-ID: <MN2PR12MB392067CB10FFCB21C5A74A7881F00@MN2PR12MB3920.namprd12.prod.outlook.com>

Jon,

You might want to search for literature on "partially clustered" or "partially nested" models. Here's one example. 

Baldwin, S. A., Bauer, D. J., Stice, E., & Rohde, P. (2011). Evaluating models for partially clustered designs. Psychological Methods, 16(2), 149-165. doi:10.1037/a0023464

Steven J. Pierce, Ph.D.
Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: jonnations <jonnations at gmail.com> 
Sent: Tuesday, July 9, 2019 10:38 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Modeling group-level effects with unequal #s of "subgroups"

Hi list,

I am working on what may be a simple problem, but I can?t quite wrap my
head around it. I have spent time searching for a solution to a problem
like this, but I must not be using the correct terminology in my searches.

I am trying to construct a simple linear model with one response, one
predictor, and a group level factor (3 islands in this case). The hard part
is that one of the 3 ?islands? is composed of multiple smaller islands.
Here is a small fake data set:

size <- c(5,6,4,5,3,5,6,6,4,3,2)
age <- c(5,10,2,5,10,3,10,3,3,10,3)
island <- c("A", "A", "B", "B", "B", "C", "C", "C", "C", "C" , "C")
sub-island <- c(NA, NA, NA, NA, NA, "C1", "C1" , "C1", "C2", "C2", "C2")
df_test <- data.frame(size, age, island, sub-island)

Writing a simple model such as
`size ~ 1 + age + (age | island)`
ignores the hierarchical structure of group C, which is important in my
case. However, modeling
`size ~ 1 + age + (age | island) + (age | sub-island)`
would not work as islands A and B do not have this sub-structure. One
alternative may be to assign the other "sub-island" groups to single groups
(i.e. "A1 for all "A's", etc) but I'm not sure if this is appropriate or
not.

If anyone provide some useful information on how to construct this model I
would be very grateful. I am used to modeling in brms, which uses basically
the same syntax as lme4. Alternatively, if anyone could tell me what this
type of data structure is called, then I could better search for options on
my own.

Thank you for helping this beginner,
Jon

-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab <https://urldefense.proofpoint.com/v2/url?u=https-3A__esselstyn.github.io_&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=T7Dok4zc8W-_7zIU6FFE-Tuk8De5yMztwyM3PZF9FeY&s=qFG6aLHJdCC8ygWe69jNZHm9v7ZTY83jLcRk3m5FusM&e= >
Museum of Natural Sciences <https://urldefense.proofpoint.com/v2/url?u=https-3A__www.lsu.edu_mns_&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=T7Dok4zc8W-_7zIU6FFE-Tuk8De5yMztwyM3PZF9FeY&s=VOT7rzKKbHKPIaUTVs5NT6k5jlsnl5ZoKKOcm7FMzpQ&e= >
Louisiana State University

	[[alternative HTML version deleted]]



From j|ox @end|ng |rom mcm@@ter@c@  Wed Jul 10 15:43:05 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 10 Jul 2019 13:43:05 +0000
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <18770_1562741530_x6A6q9EY004297_CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>,
 <18770_1562741530_x6A6q9EY004297_CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>

Dear Francesco and Thierry,

To elaborate slightly on Thierry's suggestion and also to address some other points:

(1) You (Francesco) could use the linearHypothesis() function in the car package to test more specific hypotheses. It would probably be easier to formulate such hypotheses if you fit an equivalent cell-mean model, defining a factor with levels for the 9 = 3*3 combinations of levels of your two factors. 

(2) The type-III tests produced by Anova() still aren't sensible. Did you look at the material from ?Anova that I included in my previous response?

(3) You say that Anova() uses "a form of shortcut to the traditional way of model-fitting/ reduction via the function anova() comparing models." That's not quite true in general, because what Anova() does depends on the model class and the type of test statistic selected. It's true that for a mixed-effects model, Anova() produces Wald tests rather than likelihood-ratio tests. Anova() doesn't have a "bglmerMod" method, and so I assume that the "merMod" method is inherited or that the default method is being used.

Best,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on behalf of Thierry Onkelinx via R-sig-mixed-models [r-sig-mixed-models at r-project.org]
Sent: July 10, 2019 2:51 AM
To: Francesco Romano
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Fwd: Question about non-significant interactions

Dear Francesco,

To answer your question, you should convert your hypothesis in a set of
linear contrasts and test those.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 9 jul. 2019 om 23:25 schreef Francesco Romano <fbromano77 at gmail.com>:

> ---------- Forwarded message ---------
> From: Francesco Romano <fbromano77 at gmail.com>
> Date: Tue, Jul 9, 2019 at 11:24 PM
> Subject: Re: [R-sig-ME] Question about non-significant interactions
> To: Fox, John <jfox at mcmaster.ca>
>
>
> Dear John,
>
> Thanks for the reply. One of my research entails examining the relationship
> between 3 groups of speakers, the 3 levels of the group categorical
> variable previously mentioned, and two tasks. One prediction is that one
> group will perform better than other groups on one test but not the other.
>
> I fit a maximal model using the bglmr function as shown previously, then
> used car::Anova to determine main effects. My understanding from previous
> interaction with you precisely here on r-sig-me is that the function works
> as a form of shortcut to the traditional way of model-fitting/ reduction
> via the function anova() comparing models, eliminating terms one at a time.
>
> I hope this is clearer now and yes, the question is more of a statistical
> one than an R one, even though I suspect the mixed-effect aspect of the
> regression may be relevant to answering it.
>
> Frank
>
>  Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:
>
> > Dear Francesco,
> >
> > I didn't entirely follow your question and I expect that to answer it, it
> > would be necessary to know more about what your research entails. As you
> > imply, this seems to be more a statistics question than an R question.
> It's
> > also not clear to me what function you used to fit the mixed-effects
> > logistic regression.
> >
> > But I did notice that you're apparently using Anova() for type-III tests
> > with the default contr.treatment() coding for factors. The main-effect
> > tests that result are not sensible. As it says in ?Anova:
> >
> > "Warning
> > Be careful of type-III tests: For a traditional multifactor ANOVA model
> > with interactions, for example, these tests will normally only be
> sensible
> > when using contrasts that, for different terms, are orthogonal in the
> > row-basis of the model, such as those produced by contr.sum, contr.poly,
> or
> > contr.helmert, but not by the default contr.treatment. In a model that
> > contains factors, numeric covariates, and interactions, main-effect tests
> > for factors will be for differences over the origin. In contrast (pun
> > intended), type-II tests are invariant with respect to (full-rank)
> contrast
> > coding. If you don't understand this issue, then you probably shouldn't
> use
> > Anova for type-III tests."
> >
> > I hope that this is of some help,
> >  John
> > -----------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > web: socserv.mcmaster.ca/jfox
> >
> >
> > ________________________________________
> > From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> > behalf of Francesco Romano [fbromano77 at gmail.com]
> > Sent: July 9, 2019 9:49 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Question about non-significant interactions
> >
> > Dear all,
> >
> >
> > I have more of a theoretical than practical question for you. The model I
> > am using has two IVs, group (3 levels) and task (2 levels), and a
> > categorical DV (correct versus incorrect), hence logistic regression.
> > Random effects for subjects and items, as well as slopes for group by
> item
> > and task by subject.
> >
> > I am interested in the effect of belonging any of three groups, the
> levels
> > of the group IV, in order to test some a priori predictions. The bayesian
> > wrapper is to help the model converge.
> >
> > Here is the output:
> >
> > > summary(paper2analysis1)
> > Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
> > common.scale = TRUE)
> >            : Participant ~ wishart(df = 4.5, scale = Inf,
> posterior.scale =
> > cov, common.scale = TRUE)
> > Prior dev  : 6.9466
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['bglmerMod']
> >  Family: binomial  ( logit )
> > Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> >  group | item)
> >    Data: data
> > Control: glmerControl(optimizer = "bobyqa")
> >
> >      AIC      BIC   logLik deviance df.resid
> >   3857.8   3957.2  -1913.9   3827.8     5570
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -2.0196 -0.3744 -0.2312 -0.1368  6.9534
> >
> > Random effects:
> >  Groups      Name        Variance Std.Dev. Corr
> >  item        (Intercept) 1.1266   1.0614
> >              groupL2     0.1311   0.3620   -0.12
> >              groupNS     0.2029   0.4504   -0.31  0.17
> >  Participant (Intercept) 0.7582   0.8708
> >              taskpriming 1.2163   1.1029   -0.77
> > Number of obs: 5585, groups:  item, 219; Participant, 46
> >
> > Fixed effects:
> >                     Estimate Std. Error z value Pr(>|z|)
> > (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> > taskpriming          1.30911    0.37367   3.503 0.000459 ***
> > groupL2             -0.04042    0.38322  -0.105 0.916005
> > groupNS             -1.01144    0.36607  -2.763 0.005727 **
> > taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> > taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> >             (Intr) tskprm gropL2 gropNS tsk:L2
> > taskpriming -0.733
> > groupL2     -0.660  0.482
> > groupNS     -0.693  0.507  0.509
> > tskprmng:L2  0.499 -0.632 -0.755 -0.386
> > tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
> >
> > The model was then subjected to car::Anova for ANOVA type III analysis
> with
> > the following output:
> >
> > > car::Anova(paper2analysis1, type = "III")
> > Analysis of Deviance Table (Type III Wald chisquare tests)
> >
> > Response: correctness
> >               Chisq Df Pr(>Chisq)
> > (Intercept) 77.4344  1  < 2.2e-16 ***
> > task        12.2737  1  0.0004594 ***
> > group        9.9237  2  0.0070000 **
> > task:group   0.0391  2  0.9806462
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > I am not sure how to interpret the non-significant interaction in this
> > case. Does this mean that, although simple effects exist at group level
> > within one particular task or at task level within one particular group,
> I
> > lack sufficient power to conclude those effects are real? If I look at
> the
> > simple effects, I do indeed find such effects but am not sure how to
> > interpret them against the lack of a main interaction. At a practical
> > level, the interaction, rather than the main effects, is the most
> important
> > part of the analysis.
> >
> > Thank you in advance for any advice.
> >
> > Francesco
> >
> >
> >
> >
> >
> > Best,
> >
> > Frank
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> Inviato da Gmail Mobile
> --
> Inviato da Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |ex@|ucero @end|ng |rom gm@||@com  Wed Jul 10 16:23:51 2019
From: |ex@|ucero @end|ng |rom gm@||@com (=?UTF-8?Q?Ch=C3=A9_Lucero?=)
Date: Wed, 10 Jul 2019 10:23:51 -0400
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
 <18770_1562741530_x6A6q9EY004297_CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAJOWFj9=-iLKwJTH84D5GfB1KabTNPts-6GRx6QG6LYVaQfQcQ@mail.gmail.com>

Francesco,

To answer the question you originally asked as I understand it: the
interaction test would be telling you whether the difference you find
between tasks varies between groups. The result of the interaction test is
not information about whether differences between tasks (or differences
between groups) are legitimate. It's telling you if the result of comparing
the tasks varied depending on which group you're comparing the task results
in. The interaction test in telling you that you did not observe the
pairwise difference between your tasks varying between different groups of
subjects significantly.

HTH,

-Ch?

On Wed, Jul 10, 2019 at 9:43 AM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Francesco and Thierry,
>
> To elaborate slightly on Thierry's suggestion and also to address some
> other points:
>
> (1) You (Francesco) could use the linearHypothesis() function in the car
> package to test more specific hypotheses. It would probably be easier to
> formulate such hypotheses if you fit an equivalent cell-mean model,
> defining a factor with levels for the 9 = 3*3 combinations of levels of
> your two factors.
>
> (2) The type-III tests produced by Anova() still aren't sensible. Did you
> look at the material from ?Anova that I included in my previous response?
>
> (3) You say that Anova() uses "a form of shortcut to the traditional way
> of model-fitting/ reduction via the function anova() comparing models."
> That's not quite true in general, because what Anova() does depends on the
> model class and the type of test statistic selected. It's true that for a
> mixed-effects model, Anova() produces Wald tests rather than
> likelihood-ratio tests. Anova() doesn't have a "bglmerMod" method, and so I
> assume that the "merMod" method is inherited or that the default method is
> being used.
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
>
>
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Thierry Onkelinx via R-sig-mixed-models [
> r-sig-mixed-models at r-project.org]
> Sent: July 10, 2019 2:51 AM
> To: Francesco Romano
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Fwd: Question about non-significant interactions
>
> Dear Francesco,
>
> To answer your question, you should convert your hypothesis in a set of
> linear contrasts and test those.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 9 jul. 2019 om 23:25 schreef Francesco Romano <fbromano77 at gmail.com
> >:
>
> > ---------- Forwarded message ---------
> > From: Francesco Romano <fbromano77 at gmail.com>
> > Date: Tue, Jul 9, 2019 at 11:24 PM
> > Subject: Re: [R-sig-ME] Question about non-significant interactions
> > To: Fox, John <jfox at mcmaster.ca>
> >
> >
> > Dear John,
> >
> > Thanks for the reply. One of my research entails examining the
> relationship
> > between 3 groups of speakers, the 3 levels of the group categorical
> > variable previously mentioned, and two tasks. One prediction is that one
> > group will perform better than other groups on one test but not the
> other.
> >
> > I fit a maximal model using the bglmr function as shown previously, then
> > used car::Anova to determine main effects. My understanding from previous
> > interaction with you precisely here on r-sig-me is that the function
> works
> > as a form of shortcut to the traditional way of model-fitting/ reduction
> > via the function anova() comparing models, eliminating terms one at a
> time.
> >
> > I hope this is clearer now and yes, the question is more of a statistical
> > one than an R one, even though I suspect the mixed-effect aspect of the
> > regression may be relevant to answering it.
> >
> > Frank
> >
> >  Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:
> >
> > > Dear Francesco,
> > >
> > > I didn't entirely follow your question and I expect that to answer it,
> it
> > > would be necessary to know more about what your research entails. As
> you
> > > imply, this seems to be more a statistics question than an R question.
> > It's
> > > also not clear to me what function you used to fit the mixed-effects
> > > logistic regression.
> > >
> > > But I did notice that you're apparently using Anova() for type-III
> tests
> > > with the default contr.treatment() coding for factors. The main-effect
> > > tests that result are not sensible. As it says in ?Anova:
> > >
> > > "Warning
> > > Be careful of type-III tests: For a traditional multifactor ANOVA model
> > > with interactions, for example, these tests will normally only be
> > sensible
> > > when using contrasts that, for different terms, are orthogonal in the
> > > row-basis of the model, such as those produced by contr.sum,
> contr.poly,
> > or
> > > contr.helmert, but not by the default contr.treatment. In a model that
> > > contains factors, numeric covariates, and interactions, main-effect
> tests
> > > for factors will be for differences over the origin. In contrast (pun
> > > intended), type-II tests are invariant with respect to (full-rank)
> > contrast
> > > coding. If you don't understand this issue, then you probably shouldn't
> > use
> > > Anova for type-III tests."
> > >
> > > I hope that this is of some help,
> > >  John
> > > -----------------------------
> > > John Fox, Professor Emeritus
> > > McMaster University
> > > Hamilton, Ontario
> > > Canada L8S 4M4
> > > web: socserv.mcmaster.ca/jfox
> > >
> > >
> > > ________________________________________
> > > From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> > > behalf of Francesco Romano [fbromano77 at gmail.com]
> > > Sent: July 9, 2019 9:49 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Question about non-significant interactions
> > >
> > > Dear all,
> > >
> > >
> > > I have more of a theoretical than practical question for you. The
> model I
> > > am using has two IVs, group (3 levels) and task (2 levels), and a
> > > categorical DV (correct versus incorrect), hence logistic regression.
> > > Random effects for subjects and items, as well as slopes for group by
> > item
> > > and task by subject.
> > >
> > > I am interested in the effect of belonging any of three groups, the
> > levels
> > > of the group IV, in order to test some a priori predictions. The
> bayesian
> > > wrapper is to help the model converge.
> > >
> > > Here is the output:
> > >
> > > > summary(paper2analysis1)
> > > Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale =
> cov,
> > > common.scale = TRUE)
> > >            : Participant ~ wishart(df = 4.5, scale = Inf,
> > posterior.scale =
> > > cov, common.scale = TRUE)
> > > Prior dev  : 6.9466
> > >
> > > Generalized linear mixed model fit by maximum likelihood (Laplace
> > > Approximation) ['bglmerMod']
> > >  Family: binomial  ( logit )
> > > Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> > >  group | item)
> > >    Data: data
> > > Control: glmerControl(optimizer = "bobyqa")
> > >
> > >      AIC      BIC   logLik deviance df.resid
> > >   3857.8   3957.2  -1913.9   3827.8     5570
> > >
> > > Scaled residuals:
> > >     Min      1Q  Median      3Q     Max
> > > -2.0196 -0.3744 -0.2312 -0.1368  6.9534
> > >
> > > Random effects:
> > >  Groups      Name        Variance Std.Dev. Corr
> > >  item        (Intercept) 1.1266   1.0614
> > >              groupL2     0.1311   0.3620   -0.12
> > >              groupNS     0.2029   0.4504   -0.31  0.17
> > >  Participant (Intercept) 0.7582   0.8708
> > >              taskpriming 1.2163   1.1029   -0.77
> > > Number of obs: 5585, groups:  item, 219; Participant, 46
> > >
> > > Fixed effects:
> > >                     Estimate Std. Error z value Pr(>|z|)
> > > (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> > > taskpriming          1.30911    0.37367   3.503 0.000459 ***
> > > groupL2             -0.04042    0.38322  -0.105 0.916005
> > > groupNS             -1.01144    0.36607  -2.763 0.005727 **
> > > taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> > > taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> > > ---
> > > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >             (Intr) tskprm gropL2 gropNS tsk:L2
> > > taskpriming -0.733
> > > groupL2     -0.660  0.482
> > > groupNS     -0.693  0.507  0.509
> > > tskprmng:L2  0.499 -0.632 -0.755 -0.386
> > > tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
> > >
> > > The model was then subjected to car::Anova for ANOVA type III analysis
> > with
> > > the following output:
> > >
> > > > car::Anova(paper2analysis1, type = "III")
> > > Analysis of Deviance Table (Type III Wald chisquare tests)
> > >
> > > Response: correctness
> > >               Chisq Df Pr(>Chisq)
> > > (Intercept) 77.4344  1  < 2.2e-16 ***
> > > task        12.2737  1  0.0004594 ***
> > > group        9.9237  2  0.0070000 **
> > > task:group   0.0391  2  0.9806462
> > > ---
> > > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > I am not sure how to interpret the non-significant interaction in this
> > > case. Does this mean that, although simple effects exist at group level
> > > within one particular task or at task level within one particular
> group,
> > I
> > > lack sufficient power to conclude those effects are real? If I look at
> > the
> > > simple effects, I do indeed find such effects but am not sure how to
> > > interpret them against the lack of a main interaction. At a practical
> > > level, the interaction, rather than the main effects, is the most
> > important
> > > part of the analysis.
> > >
> > > Thank you in advance for any advice.
> > >
> > > Francesco
> > >
> > >
> > >
> > >
> > >
> > > Best,
> > >
> > > Frank
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > --
> > Inviato da Gmail Mobile
> > --
> > Inviato da Gmail Mobile
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 

PhD Student
Experience and Cognition Lab
Department of Human Development
Cornell University
Martha Van Rensselaer Hall
Ithaca, NY 14853
acl249 at cornell.edu
http://casasanto.com/chelucero/

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Wed Jul 10 21:24:49 2019
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Wed, 10 Jul 2019 20:24:49 +0100
Subject: [R-sig-ME] Under what conditions does it make sense to fit random
 intercepts for an interaction, but not the main effects?
Message-ID: <CA+3TTkOG5sUJzcM21uWee3bt=j-YDApai9QvcDzR7vKL2nt0iw@mail.gmail.com>

I am actually re-posting an old question from Cross Validated that I am
interested in, but has not received any answers:
https://stats.stackexchange.com/questions/402641/under-what-conditions-does-it-make-sense-to-fit-random-intercepts-for-an-interac


I am aware that when specifying the random structure for one factor (B)
nested within another factor (A), we can use:

(1|A) + (1|A:B)

I am trying to understand section 2.3.1 in the online book chapter 2 by
Douglas Bates: http://lme4.r-forge.r-project.org/book/Ch2.pdf
which is using the InstEval dataset, which is an evaluation of lecturers by
students at the Swiss Federal Institute for Technology?Zurich (ETH?Zurich):

> str(InstEval)
'data.frame': 73421 obs. of 7 variables:
$ s : Factor w/ 2972 levels "1","2","3","4",..: 1 1 1 1 2 2 3 3 3 ..
$ d : Factor w/ 1128 levels "1","6","7","8",..: 525 560 832 1068 6..
$ studage: Ord.factor w/ 4 levels "2"<"4"<"6"<"8": 1 1 1 1 1 1 1 1 1 1 ..
$ lectage: Ord.factor w/ 6 levels "1"<"2"<"3"<"4"<..: 2 1 2 2 1 1 1 1 1..
$ service: Factor w/ 2 levels "0","1": 1 2 1 2 1 1 2 1 1 1 ...
$ dept : Factor w/ 14 levels "15","5","10",..: 14 5 14 12 2 2 13 3 3 ..
$ y : int 5 2 5 3 2 4 4 5 5 4 ...
Factor s designates the student and d the instructor. The dept factor is
the department for the course and service indicates whether the course was
a service course taught to students from other departments. Thus these data
are partially crossed.

The model fitted in the text is:

fm4 <- lmer(y ~ 1 + (1|s) + (1|d) + (1|dept:service), InstEval, REML=0)

My question is: why is the interaction fitted as a random intercept without
(or instead of) the main effect also being fitted in this case, and in
general: when would we fit random effects for an interaction but not for
either of the main effects ? These are not nested factors, so I guess that
has something to do with it, but why is dept not specified as a random
intercept instead ? The text goes on to say

We could pursue other mixed-effects models here, such as using the dept
factor and not the dept:service interaction to define random effects, but
we will revisit these data in the next chapter and follow up on some of
these variations there.

However, as far as I know, there is no Chapter 3 !!!!

	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Thu Jul 11 07:07:47 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Thu, 11 Jul 2019 05:07:47 +0000
Subject: [R-sig-ME] 
 Under what conditions does it make sense to fit random
 intercepts for an interaction, but not the main effects?
In-Reply-To: <CA+3TTkOG5sUJzcM21uWee3bt=j-YDApai9QvcDzR7vKL2nt0iw@mail.gmail.com>
References: <CA+3TTkOG5sUJzcM21uWee3bt=j-YDApai9QvcDzR7vKL2nt0iw@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED85622@EXCH-RX03.erasmusmc.nl>

I think this has to do with what is the definition of your grouping variable. In your example with factor A and factor B, say that A is the subject and B the eye of the subject. The specification

(1 | A) + (1 | A:B)

says that measurements within the subject are correlated because they share the same random effect (1 | A), and measurements within the same eye of the same subject are even more correlated because they share the extra random effect (1 | A:B).

But lets say that you wanted to assume that only measurements within the same eye are correlated, but measurements on the same subject but from different eyes would be uncorrelated. Then I think you would only need the (1 | A:B) term.

Best,
Dimitris

- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

From: Robert Long <longrob604 at gmail.com<mailto:longrob604 at gmail.com>>
Date: Wednesday, 10 Jul 2019, 9:31 PM
To: R-mixed models mailing list <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] Under what conditions does it make sense to fit random intercepts for an interaction, but not the main effects?

I am actually re-posting an old question from Cross Validated that I am
interested in, but has not received any answers:
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F402641%2Funder-what-conditions-does-it-make-sense-to-fit-random-intercepts-for-an-interac&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Ca4269991564645e1ec7208d7056d40af%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C636983839105430563&amp;sdata=M17Svnw81914SpUhAkAXXPJODg23JWOYRBHDTYrdKoM%3D&amp;reserved=0


I am aware that when specifying the random structure for one factor (B)
nested within another factor (A), we can use:

(1|A) + (1|A:B)

I am trying to understand section 2.3.1 in the online book chapter 2 by
Douglas Bates: https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Flme4.r-forge.r-project.org%2Fbook%2FCh2.pdf&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Ca4269991564645e1ec7208d7056d40af%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C636983839105430563&amp;sdata=CVZnCWSuNSTLvRan0xvraRmXLX6qSL%2FPELUWPVg0GRc%3D&amp;reserved=0
which is using the InstEval dataset, which is an evaluation of lecturers by
students at the Swiss Federal Institute for Technology?Zurich (ETH?Zurich):

> str(InstEval)
'data.frame': 73421 obs. of 7 variables:
$ s : Factor w/ 2972 levels "1","2","3","4",..: 1 1 1 1 2 2 3 3 3 ..
$ d : Factor w/ 1128 levels "1","6","7","8",..: 525 560 832 1068 6..
$ studage: Ord.factor w/ 4 levels "2"<"4"<"6"<"8": 1 1 1 1 1 1 1 1 1 1 ..
$ lectage: Ord.factor w/ 6 levels "1"<"2"<"3"<"4"<..: 2 1 2 2 1 1 1 1 1..
$ service: Factor w/ 2 levels "0","1": 1 2 1 2 1 1 2 1 1 1 ...
$ dept : Factor w/ 14 levels "15","5","10",..: 14 5 14 12 2 2 13 3 3 ..
$ y : int 5 2 5 3 2 4 4 5 5 4 ...
Factor s designates the student and d the instructor. The dept factor is
the department for the course and service indicates whether the course was
a service course taught to students from other departments. Thus these data
are partially crossed.

The model fitted in the text is:

fm4 <- lmer(y ~ 1 + (1|s) + (1|d) + (1|dept:service), InstEval, REML=0)

My question is: why is the interaction fitted as a random intercept without
(or instead of) the main effect also being fitted in this case, and in
general: when would we fit random effects for an interaction but not for
either of the main effects ? These are not nested factors, so I guess that
has something to do with it, but why is dept not specified as a random
intercept instead ? The text goes on to say

We could pursue other mixed-effects models here, such as using the dept
factor and not the dept:service interaction to define random effects, but
we will revisit these data in the next chapter and follow up on some of
these variations there.

However, as far as I know, there is no Chapter 3 !!!!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Ca4269991564645e1ec7208d7056d40af%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C636983839105430563&amp;sdata=W7xUPKX9BFLUlXBtGVKt4JbpDCnshCe62054%2FkB6oeg%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Thu Jul 11 09:50:09 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Thu, 11 Jul 2019 09:50:09 +0200
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
 <18770_1562741530_x6A6q9EY004297_CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CABX-QoGoyvz=9zSg3=GYzJKMR8QCHQSVQPF54cF+nJz4=N+Row@mail.gmail.com>

Dear John (and others),

I think I have solved this issue, if my understanding of the stats is
correct.

First, wIth regards to (2), yes, I have taken that into account. I recoded
my factors as contr.sum, ran the Anova again (with and without the bayesian
wrapper), to find that results did not change. I also tried the other ways,
namely via the mixed function, which allows you to use mixed-effect models,
automatically recodes your factors to contr.sum, and uses LRT, and the
traditional anova function with lihelihood ratio tests comparing two models
at a time. In all cases, I never get a significant interaction but always
get a main effect for both fixed effects. By the way, regarding your (3),
our original contact a few years back was a query of mine trying to find a
shortcut to traditional likelihood ratio testing comparing models that
would also allow random effects, hence your suggestion to use your
car::Anova, which for the record, I love.

As far as my understanding of the results goes, but feel free to chime in
if you disagree, there is no main interaction because the simple effects
that I find (i.e. the pairwise comparisons) are the same across the two
tests. To simplify things a bit, in my GJT test, the first level of the
task factor, I find the following relationships between groups HL = L2, L1
> HL, and L1 > L2, where HL, L1, and L2 are the three levels of the group
factor, and = is just shorthand for no significant difference. The
relationships are exactly the same at the other level of the task factor,
namely priming, Same goes for the relationship between tasks at each level
of the group variable: every group is significantly more likely to score
correctly on the GJT than the priming task. I take these to explain why the
main interaction turns out not to be statistically significant.

Best,

Frank


On Wed, Jul 10, 2019 at 3:43 PM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Francesco and Thierry,
>
> To elaborate slightly on Thierry's suggestion and also to address some
> other points:
>
> (1) You (Francesco) could use the linearHypothesis() function in the car
> package to test more specific hypotheses. It would probably be easier to
> formulate such hypotheses if you fit an equivalent cell-mean model,
> defining a factor with levels for the 9 = 3*3 combinations of levels of
> your two factors.
>
> (2) The type-III tests produced by Anova() still aren't sensible. Did you
> look at the material from ?Anova that I included in my previous response?
>
> (3) You say that Anova() uses "a form of shortcut to the traditional way
> of model-fitting/ reduction via the function anova() comparing models."
> That's not quite true in general, because what Anova() does depends on the
> model class and the type of test statistic selected. It's true that for a
> mixed-effects model, Anova() produces Wald tests rather than
> likelihood-ratio tests. Anova() doesn't have a "bglmerMod" method, and so I
> assume that the "merMod" method is inherited or that the default method is
> being used.
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
>
>
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Thierry Onkelinx via R-sig-mixed-models [
> r-sig-mixed-models at r-project.org]
> Sent: July 10, 2019 2:51 AM
> To: Francesco Romano
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Fwd: Question about non-significant interactions
>
> Dear Francesco,
>
> To answer your question, you should convert your hypothesis in a set of
> linear contrasts and test those.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 9 jul. 2019 om 23:25 schreef Francesco Romano <fbromano77 at gmail.com
> >:
>
> > ---------- Forwarded message ---------
> > From: Francesco Romano <fbromano77 at gmail.com>
> > Date: Tue, Jul 9, 2019 at 11:24 PM
> > Subject: Re: [R-sig-ME] Question about non-significant interactions
> > To: Fox, John <jfox at mcmaster.ca>
> >
> >
> > Dear John,
> >
> > Thanks for the reply. One of my research entails examining the
> relationship
> > between 3 groups of speakers, the 3 levels of the group categorical
> > variable previously mentioned, and two tasks. One prediction is that one
> > group will perform better than other groups on one test but not the
> other.
> >
> > I fit a maximal model using the bglmr function as shown previously, then
> > used car::Anova to determine main effects. My understanding from previous
> > interaction with you precisely here on r-sig-me is that the function
> works
> > as a form of shortcut to the traditional way of model-fitting/ reduction
> > via the function anova() comparing models, eliminating terms one at a
> time.
> >
> > I hope this is clearer now and yes, the question is more of a statistical
> > one than an R one, even though I suspect the mixed-effect aspect of the
> > regression may be relevant to answering it.
> >
> > Frank
> >
> >  Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:
> >
> > > Dear Francesco,
> > >
> > > I didn't entirely follow your question and I expect that to answer it,
> it
> > > would be necessary to know more about what your research entails. As
> you
> > > imply, this seems to be more a statistics question than an R question.
> > It's
> > > also not clear to me what function you used to fit the mixed-effects
> > > logistic regression.
> > >
> > > But I did notice that you're apparently using Anova() for type-III
> tests
> > > with the default contr.treatment() coding for factors. The main-effect
> > > tests that result are not sensible. As it says in ?Anova:
> > >
> > > "Warning
> > > Be careful of type-III tests: For a traditional multifactor ANOVA model
> > > with interactions, for example, these tests will normally only be
> > sensible
> > > when using contrasts that, for different terms, are orthogonal in the
> > > row-basis of the model, such as those produced by contr.sum,
> contr.poly,
> > or
> > > contr.helmert, but not by the default contr.treatment. In a model that
> > > contains factors, numeric covariates, and interactions, main-effect
> tests
> > > for factors will be for differences over the origin. In contrast (pun
> > > intended), type-II tests are invariant with respect to (full-rank)
> > contrast
> > > coding. If you don't understand this issue, then you probably shouldn't
> > use
> > > Anova for type-III tests."
> > >
> > > I hope that this is of some help,
> > >  John
> > > -----------------------------
> > > John Fox, Professor Emeritus
> > > McMaster University
> > > Hamilton, Ontario
> > > Canada L8S 4M4
> > > web: socserv.mcmaster.ca/jfox
> > >
> > >
> > > ________________________________________
> > > From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> > > behalf of Francesco Romano [fbromano77 at gmail.com]
> > > Sent: July 9, 2019 9:49 AM
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Question about non-significant interactions
> > >
> > > Dear all,
> > >
> > >
> > > I have more of a theoretical than practical question for you. The
> model I
> > > am using has two IVs, group (3 levels) and task (2 levels), and a
> > > categorical DV (correct versus incorrect), hence logistic regression.
> > > Random effects for subjects and items, as well as slopes for group by
> > item
> > > and task by subject.
> > >
> > > I am interested in the effect of belonging any of three groups, the
> > levels
> > > of the group IV, in order to test some a priori predictions. The
> bayesian
> > > wrapper is to help the model converge.
> > >
> > > Here is the output:
> > >
> > > > summary(paper2analysis1)
> > > Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale =
> cov,
> > > common.scale = TRUE)
> > >            : Participant ~ wishart(df = 4.5, scale = Inf,
> > posterior.scale =
> > > cov, common.scale = TRUE)
> > > Prior dev  : 6.9466
> > >
> > > Generalized linear mixed model fit by maximum likelihood (Laplace
> > > Approximation) ['bglmerMod']
> > >  Family: binomial  ( logit )
> > > Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> > >  group | item)
> > >    Data: data
> > > Control: glmerControl(optimizer = "bobyqa")
> > >
> > >      AIC      BIC   logLik deviance df.resid
> > >   3857.8   3957.2  -1913.9   3827.8     5570
> > >
> > > Scaled residuals:
> > >     Min      1Q  Median      3Q     Max
> > > -2.0196 -0.3744 -0.2312 -0.1368  6.9534
> > >
> > > Random effects:
> > >  Groups      Name        Variance Std.Dev. Corr
> > >  item        (Intercept) 1.1266   1.0614
> > >              groupL2     0.1311   0.3620   -0.12
> > >              groupNS     0.2029   0.4504   -0.31  0.17
> > >  Participant (Intercept) 0.7582   0.8708
> > >              taskpriming 1.2163   1.1029   -0.77
> > > Number of obs: 5585, groups:  item, 219; Participant, 46
> > >
> > > Fixed effects:
> > >                     Estimate Std. Error z value Pr(>|z|)
> > > (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> > > taskpriming          1.30911    0.37367   3.503 0.000459 ***
> > > groupL2             -0.04042    0.38322  -0.105 0.916005
> > > groupNS             -1.01144    0.36607  -2.763 0.005727 **
> > > taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> > > taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> > > ---
> > > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >             (Intr) tskprm gropL2 gropNS tsk:L2
> > > taskpriming -0.733
> > > groupL2     -0.660  0.482
> > > groupNS     -0.693  0.507  0.509
> > > tskprmng:L2  0.499 -0.632 -0.755 -0.386
> > > tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
> > >
> > > The model was then subjected to car::Anova for ANOVA type III analysis
> > with
> > > the following output:
> > >
> > > > car::Anova(paper2analysis1, type = "III")
> > > Analysis of Deviance Table (Type III Wald chisquare tests)
> > >
> > > Response: correctness
> > >               Chisq Df Pr(>Chisq)
> > > (Intercept) 77.4344  1  < 2.2e-16 ***
> > > task        12.2737  1  0.0004594 ***
> > > group        9.9237  2  0.0070000 **
> > > task:group   0.0391  2  0.9806462
> > > ---
> > > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > I am not sure how to interpret the non-significant interaction in this
> > > case. Does this mean that, although simple effects exist at group level
> > > within one particular task or at task level within one particular
> group,
> > I
> > > lack sufficient power to conclude those effects are real? If I look at
> > the
> > > simple effects, I do indeed find such effects but am not sure how to
> > > interpret them against the lack of a main interaction. At a practical
> > > level, the interaction, rather than the main effects, is the most
> > important
> > > part of the analysis.
> > >
> > > Thank you in advance for any advice.
> > >
> > > Francesco
> > >
> > >
> > >
> > >
> > >
> > > Best,
> > >
> > > Frank
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > --
> > Inviato da Gmail Mobile
> > --
> > Inviato da Gmail Mobile
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jul 11 11:32:59 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 11 Jul 2019 09:32:59 +0000
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <CABX-QoGoyvz=9zSg3=GYzJKMR8QCHQSVQPF54cF+nJz4=N+Row@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
 <18770_1562741530_x6A6q9EY004297_CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C4A5CB@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoGoyvz=9zSg3=GYzJKMR8QCHQSVQPF54cF+nJz4=N+Row@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836C4B43F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Francesco,

> -----Original Message-----
> From: Francesco Romano [mailto:fbromano77 at gmail.com]
> Sent: Thursday, July 11, 2019 9:50 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Thierry Onkelinx <thierry.onkelinx at inbo.be>; r-sig-mixed-models at r-
> project.org
> Subject: Re: [R-sig-ME] Fwd: Question about non-significant interactions
> 
> Dear John (and others),
> 
> I think I have solved this issue, if my understanding of the stats is correct.
> 
> First, wIth regards to (2), yes, I have taken that into account. I recoded my
> factors as contr.sum, ran the Anova again (with and without the bayesian
> wrapper), to find that results did not change.

The tests for the interaction should be identical but it would be odd if the type-III tests for the main effects didn't change at least slightly when you changed the contrast coding from contr.treatment() to contr.sum().

> I also tried the other ways,
> namely via the mixed function, which allows you to use mixed-effect models,
> automatically recodes your factors to contr.sum, and uses LRT, and the
> traditional anova function with lihelihood ratio tests comparing two models
> at a time. In all cases, I never get a significant interaction but always get a
> main effect for both fixed effects. By the way, regarding your (3), our original
> contact a few years back was a query of mine trying to find a shortcut to
> traditional likelihood ratio testing comparing models that would also allow
> random effects, hence your suggestion to use your car::Anova, which for the
> record, I love.

Thank you.

> 
> As far as my understanding of the results goes, but feel free to chime in if you
> disagree, there is no main interaction because the simple effects that I find
> (i.e. the pairwise comparisons) are the same across the two tests. To simplify
> things a bit, in my GJT test, the first level of the task factor, I find the following
> relationships between groups HL = L2, L1 > HL, and L1 > L2, where HL, L1, and
> L2 are the three levels of the group factor, and = is just shorthand for no
> significant difference. The relationships are exactly the same at the other level
> of the task factor, namely priming, Same goes for the relationship between
> tasks at each level of the group variable: every group is significantly more
> likely to score correctly on the GJT than the priming task. I take these to
> explain why the main interaction turns out not to be statistically significant.

If the simple effects of group are identical across the levels of task, then of course there is no interaction between group and task. If the simple effects are similar, then you probably won't detect an interaction unless, e.g., you have a lot of data. But to treat "no significant difference" as indicative of equality (even heuristically) could certainly lead to apparently paradoxical results, although that hasn't happened in your case.

Best,
 John

> 
> Best,
> 
> 
> Frank
> 
> 
> On Wed, Jul 10, 2019 at 3:43 PM Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Francesco and Thierry,
> 
> 	To elaborate slightly on Thierry's suggestion and also to address some
> other points:
> 
> 	(1) You (Francesco) could use the linearHypothesis() function in the
> car package to test more specific hypotheses. It would probably be easier to
> formulate such hypotheses if you fit an equivalent cell-mean model, defining a
> factor with levels for the 9 = 3*3 combinations of levels of your two factors.
> 
> 	(2) The type-III tests produced by Anova() still aren't sensible. Did you
> look at the material from ?Anova that I included in my previous response?
> 
> 	(3) You say that Anova() uses "a form of shortcut to the traditional
> way of model-fitting/ reduction via the function anova() comparing models."
> That's not quite true in general, because what Anova() does depends on the
> model class and the type of test statistic selected. It's true that for a mixed-
> effects model, Anova() produces Wald tests rather than likelihood-ratio tests.
> Anova() doesn't have a "bglmerMod" method, and so I assume that the
> "merMod" method is inherited or that the default method is being used.
> 
> 	Best,
> 	 John
> 
> 	-----------------------------
> 	John Fox, Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario
> 	Canada L8S 4M4
> 	web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> 
> 
> 	________________________________________
> 	From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-
> project.org <mailto:r-sig-mixed-models-bounces at r-project.org> ] on behalf of
> Thierry Onkelinx via R-sig-mixed-models [r-sig-mixed-models at r-project.org
> <mailto:r-sig-mixed-models at r-project.org> ]
> 	Sent: July 10, 2019 2:51 AM
> 	To: Francesco Romano
> 	Cc: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-
> project.org>
> 	Subject: Re: [R-sig-ME] Fwd: Question about non-significant
> interactions
> 
> 	Dear Francesco,
> 
> 	To answer your question, you should convert your hypothesis in a set
> of
> 	linear contrasts and test those.
> 
> 	Best regards,
> 
> 	ir. Thierry Onkelinx
> 	Statisticus / Statistician
> 
> 	Vlaamse Overheid / Government of Flanders
> 	INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH
> INSTITUTE FOR NATURE AND
> 	FOREST
> 	Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> 	thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> 	Havenlaan 88 bus 73, 1000 Brussel
> 	www.inbo.be <http://www.inbo.be>
> 
> 	///////////////////////////////////////////////////////////////////////////
> ////////////////
> 	To call in the statistician after the experiment is done may be no more
> 	than asking him to perform a post-mortem examination: he may be
> able to say
> 	what the experiment died of. ~ Sir Ronald Aylmer Fisher
> 	The plural of anecdote is not data. ~ Roger Brinner
> 	The combination of some data and an aching desire for an answer
> does not
> 	ensure that a reasonable answer can be extracted from a given body
> of data.
> 	~ John Tukey
> 	///////////////////////////////////////////////////////////////////////////
> ////////////////
> 
> 	<https://www.inbo.be>
> 
> 
> 	Op di 9 jul. 2019 om 23:25 schreef Francesco Romano
> <fbromano77 at gmail.com <mailto:fbromano77 at gmail.com> >:
> 
> 	> ---------- Forwarded message ---------
> 	> From: Francesco Romano <fbromano77 at gmail.com
> <mailto:fbromano77 at gmail.com> >
> 	> Date: Tue, Jul 9, 2019 at 11:24 PM
> 	> Subject: Re: [R-sig-ME] Question about non-significant interactions
> 	> To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> 	>
> 	>
> 	> Dear John,
> 	>
> 	> Thanks for the reply. One of my research entails examining the
> relationship
> 	> between 3 groups of speakers, the 3 levels of the group categorical
> 	> variable previously mentioned, and two tasks. One prediction is that
> one
> 	> group will perform better than other groups on one test but not the
> other.
> 	>
> 	> I fit a maximal model using the bglmr function as shown previously,
> then
> 	> used car::Anova to determine main effects. My understanding from
> previous
> 	> interaction with you precisely here on r-sig-me is that the function
> works
> 	> as a form of shortcut to the traditional way of model-fitting/
> reduction
> 	> via the function anova() comparing models, eliminating terms one at
> a time.
> 	>
> 	> I hope this is clearer now and yes, the question is more of a
> statistical
> 	> one than an R one, even though I suspect the mixed-effect aspect of
> the
> 	> regression may be relevant to answering it.
> 	>
> 	> Frank
> 	>
> 	>  Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 	>
> 	> > Dear Francesco,
> 	> >
> 	> > I didn't entirely follow your question and I expect that to answer it,
> it
> 	> > would be necessary to know more about what your research
> entails. As you
> 	> > imply, this seems to be more a statistics question than an R
> question.
> 	> It's
> 	> > also not clear to me what function you used to fit the mixed-
> effects
> 	> > logistic regression.
> 	> >
> 	> > But I did notice that you're apparently using Anova() for type-III
> tests
> 	> > with the default contr.treatment() coding for factors. The main-
> effect
> 	> > tests that result are not sensible. As it says in ?Anova:
> 	> >
> 	> > "Warning
> 	> > Be careful of type-III tests: For a traditional multifactor ANOVA
> model
> 	> > with interactions, for example, these tests will normally only be
> 	> sensible
> 	> > when using contrasts that, for different terms, are orthogonal in
> the
> 	> > row-basis of the model, such as those produced by contr.sum,
> contr.poly,
> 	> or
> 	> > contr.helmert, but not by the default contr.treatment. In a model
> that
> 	> > contains factors, numeric covariates, and interactions, main-effect
> tests
> 	> > for factors will be for differences over the origin. In contrast (pun
> 	> > intended), type-II tests are invariant with respect to (full-rank)
> 	> contrast
> 	> > coding. If you don't understand this issue, then you probably
> shouldn't
> 	> use
> 	> > Anova for type-III tests."
> 	> >
> 	> > I hope that this is of some help,
> 	> >  John
> 	> > -----------------------------
> 	> > John Fox, Professor Emeritus
> 	> > McMaster University
> 	> > Hamilton, Ontario
> 	> > Canada L8S 4M4
> 	> > web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> 	> >
> 	> >
> 	> > ________________________________________
> 	> > From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-
> project.org <mailto:r-sig-mixed-models-bounces at r-project.org> ] on
> 	> > behalf of Francesco Romano [fbromano77 at gmail.com
> <mailto:fbromano77 at gmail.com> ]
> 	> > Sent: July 9, 2019 9:49 AM
> 	> > To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-
> models at r-project.org>
> 	> > Subject: [R-sig-ME] Question about non-significant interactions
> 	> >
> 	> > Dear all,
> 	> >
> 	> >
> 	> > I have more of a theoretical than practical question for you. The
> model I
> 	> > am using has two IVs, group (3 levels) and task (2 levels), and a
> 	> > categorical DV (correct versus incorrect), hence logistic regression.
> 	> > Random effects for subjects and items, as well as slopes for group
> by
> 	> item
> 	> > and task by subject.
> 	> >
> 	> > I am interested in the effect of belonging any of three groups, the
> 	> levels
> 	> > of the group IV, in order to test some a priori predictions. The
> bayesian
> 	> > wrapper is to help the model converge.
> 	> >
> 	> > Here is the output:
> 	> >
> 	> > > summary(paper2analysis1)
> 	> > Cov prior  : item ~ wishart(df = 5.5, scale = Inf, posterior.scale =
> cov,
> 	> > common.scale = TRUE)
> 	> >            : Participant ~ wishart(df = 4.5, scale = Inf,
> 	> posterior.scale =
> 	> > cov, common.scale = TRUE)
> 	> > Prior dev  : 6.9466
> 	> >
> 	> > Generalized linear mixed model fit by maximum likelihood
> (Laplace
> 	> > Approximation) ['bglmerMod']
> 	> >  Family: binomial  ( logit )
> 	> > Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> 	> >  group | item)
> 	> >    Data: data
> 	> > Control: glmerControl(optimizer = "bobyqa")
> 	> >
> 	> >      AIC      BIC   logLik deviance df.resid
> 	> >   3857.8   3957.2  -1913.9   3827.8     5570
> 	> >
> 	> > Scaled residuals:
> 	> >     Min      1Q  Median      3Q     Max
> 	> > -2.0196 -0.3744 -0.2312 -0.1368  6.9534
> 	> >
> 	> > Random effects:
> 	> >  Groups      Name        Variance Std.Dev. Corr
> 	> >  item        (Intercept) 1.1266   1.0614
> 	> >              groupL2     0.1311   0.3620   -0.12
> 	> >              groupNS     0.2029   0.4504   -0.31  0.17
> 	> >  Participant (Intercept) 0.7582   0.8708
> 	> >              taskpriming 1.2163   1.1029   -0.77
> 	> > Number of obs: 5585, groups:  item, 219; Participant, 46
> 	> >
> 	> > Fixed effects:
> 	> >                     Estimate Std. Error z value Pr(>|z|)
> 	> > (Intercept)         -2.49187    0.28318  -8.800  < 2e-16 ***
> 	> > taskpriming          1.30911    0.37367   3.503 0.000459 ***
> 	> > groupL2             -0.04042    0.38322  -0.105 0.916005
> 	> > groupNS             -1.01144    0.36607  -2.763 0.005727 **
> 	> > taskpriming:groupL2  0.04305    0.48693   0.088 0.929544
> 	> > taskpriming:groupNS -0.04942    0.46034  -0.107 0.914506
> 	> > ---
> 	> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 	> >
> 	> > Correlation of Fixed Effects:
> 	> >             (Intr) tskprm gropL2 gropNS tsk:L2
> 	> > taskpriming -0.733
> 	> > groupL2     -0.660  0.482
> 	> > groupNS     -0.693  0.507  0.509
> 	> > tskprmng:L2  0.499 -0.632 -0.755 -0.386
> 	> > tskprmng:NS  0.530 -0.676 -0.390 -0.750  0.508
> 	> >
> 	> > The model was then subjected to car::Anova for ANOVA type III
> analysis
> 	> with
> 	> > the following output:
> 	> >
> 	> > > car::Anova(paper2analysis1, type = "III")
> 	> > Analysis of Deviance Table (Type III Wald chisquare tests)
> 	> >
> 	> > Response: correctness
> 	> >               Chisq Df Pr(>Chisq)
> 	> > (Intercept) 77.4344  1  < 2.2e-16 ***
> 	> > task        12.2737  1  0.0004594 ***
> 	> > group        9.9237  2  0.0070000 **
> 	> > task:group   0.0391  2  0.9806462
> 	> > ---
> 	> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 	> >
> 	> > I am not sure how to interpret the non-significant interaction in
> this
> 	> > case. Does this mean that, although simple effects exist at group
> level
> 	> > within one particular task or at task level within one particular
> group,
> 	> I
> 	> > lack sufficient power to conclude those effects are real? If I look at
> 	> the
> 	> > simple effects, I do indeed find such effects but am not sure how to
> 	> > interpret them against the lack of a main interaction. At a practical
> 	> > level, the interaction, rather than the main effects, is the most
> 	> important
> 	> > part of the analysis.
> 	> >
> 	> > Thank you in advance for any advice.
> 	> >
> 	> > Francesco
> 	> >
> 	> >
> 	> >
> 	> >
> 	> >
> 	> > Best,
> 	> >
> 	> > Frank
> 	> >
> 	> >         [[alternative HTML version deleted]]
> 	> >
> 	> > _______________________________________________
> 	> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-
> models at r-project.org>  mailing list
> 	> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 	> >
> 	> --
> 	> Inviato da Gmail Mobile
> 	> --
> 	> Inviato da Gmail Mobile
> 	>
> 	>         [[alternative HTML version deleted]]
> 	>
> 	> _______________________________________________
> 	> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-
> project.org>  mailing list
> 	> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 	>
> 
> 	        [[alternative HTML version deleted]]
> 
> 	_______________________________________________
> 	R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-
> project.org>  mailing list
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From L@R@E|||ott @end|ng |rom exeter@@c@uk  Thu Jul 11 13:03:31 2019
From: L@R@E|||ott @end|ng |rom exeter@@c@uk (Elliott, Lewis)
Date: Thu, 11 Jul 2019 11:03:31 +0000
Subject: [R-sig-ME] Pooling results from lme4 models with weights
Message-ID: <LO2P265MB11170F224ADB3DBCEA6E0EBC80F30@LO2P265MB1117.GBRP265.PROD.OUTLOOK.COM>

Hi all,

I have a series of multiply imputed datasets created with the MICE package. With these, I want to run mixed models which include weights using lme4, and pool the results across the multiply imputed datasets using Rubin's correction.

The MICE with() function pools fixed effects nicely, but does not appear to pool random effects. The mertools package has functions for pooling fixed and random effects but cannot handle models including weights. Does anyone know of a package or function which can pool fixed and random effects parts of lme4 models AND handle weights?

Many thanks,

Lewis Elliott


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Thu Jul 11 23:45:00 2019
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Thu, 11 Jul 2019 17:45:00 -0400
Subject: [R-sig-ME] Negative binomial GLMM model/variables selection based
 in marginal R2 and conditional R2
Message-ID: <f896ed95-0023-a990-7031-e02ee507f500@yahoo.com.br>

Dear R-Mixed-Models Members,

 ?????? ?????? I've like to chose my negative binomial GLMM better 
model/variables based in marginal R2 (variance explained by the fixed 
factor(s)) and conditional R2 (variance explained by both the fixed and 
random factors), but some times I have a great dissimilarities in this 
values, if I have gain in the conditional R2, my marginal R2 is poor and 
vice-versa (I make a little exercise by changes in the position on fixed 
and random effects in the models). In my example:

*A) Model 1 - Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat) - balance 
values between marginal and conditional R2*

R2m R2c

delta 0.4282151 0.5203953

lognormal 0.5090799 0.6186677

trigamma 0.3153259 0.3832049


Generalized linear mixed model fit by maximum likelihood (Laplace 
Approximation) ['glmerMod']

Family: Negative Binomial(0.9207)?? ( log )

Formula: Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat)

 ???? Data: d3

 ???????? AIC?????????? BIC???? logLik deviance df.resid

 ????4500.6???? 4521.9?? -2245.3???? 4490.6?????????? 519

Scaled residuals:

Min?????????? 1Q?? Median?????????? 3Q???????? Max

-0.9413 -0.7254 -0.4113?? 0.5294?? 7.2853

Random effects:

Groups Name?????????????? Variance Std.Dev.

Trat???? (Intercept) 0.2176 ????0.4664

Number of obs: 524, groups:?? Trat, 4

Fixed effects:

 ?????????????????????????? Estimate Std. Error z value Pr(>|z|)

(Intercept)?? 0.2847245?? 0.2913635???? 0.977 0.328

Inf_YST???????? -0.0016482?? 0.0003483?? -4.732 2.22e-06 ***

Age_months???? 0.3144764?? 0.0183616?? 17.127?? < 2e-16 ***

---

Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1

Correlation of Fixed Effects:

 ???????????????????? (Intr) In_YST

Inf_YST???????? 0.171

Age_months -0.558 -0.532

convergence code: 0

Model failed to converge with max|grad| = 0.00631137 (tol = 0.001, 
component 1)

Model is nearly unidentifiable: very large eigenvalue

- Rescale variables?

Model is nearly unidentifiable: large eigenvalue ratio

- Rescale variables?


*B) Model 2 -?? Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months) - a better 
conditional but poor marginal R2*

R2m R2c

delta???????? 0.1626844 0.7257397

lognormal 0.1725712 0.7698453

trigamma?? 0.1489258 0.6643626


Generalized linear mixed model fit by maximum likelihood (Laplace 
Approximation) ['glmerMod']

Family: Negative Binomial(1.8431)?? ( log )

Formula: Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months)

 ???? Data: d3

 ???????? AIC?????????? BIC logLik deviance df.resid

 ????4121.5???? 4151.4 -2053.8???? 4107.5?????????? 517

Scaled residuals:

Min?????????? 1Q?? Median?????????? 3Q???????? Max

-1.2776 -0.6703 -0.1486?? 0.3279?? 5.4019

Random effects:

Groups Name?????????????? Variance Std.Dev.

Age_months (Intercept) 1.172?????? 1.083

Number of obs: 524, groups:?? Age_months, 4

Fixed effects:

Estimate Std. Error z value Pr(>|z|)

(Intercept)???????????????? 3.4859551 0.5492043???? 6.347 2.19e-10 ***

Inf_YST???????????????????????? 0.0005702 0.0002864???? 1.991???? 0.0465 *

TratC1-Insecticide -1.1081610 0.1012478 -10.945?? < 2e-16 ***

TratC2-Control???????? -0.7859302 0.1058146?? -7.427 1.11e-13 ***

TratC2-Insecticide -1.3833545 0.1041882 -13.277?? < 2e-16 ***

---

Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1

Correlation of Fixed Effects:

 ?????????????????????? (Intr) In_YST TrC1-I TrC2-C

Inf_YST???????? -0.122

TrtC1-Insct -0.103 0.189

TrtC2-Cntrl -0.104 0.265?? 0.436

TrtC2-Insct -0.097 0.221?? 0.424?? 0.504

convergence code: 0

Model failed to converge with max|grad| = 0.00398879 (tol = 0.001, 
component 1)

Model is nearly unidentifiable: very large eigenvalue

- Rescale variables?

Model is nearly unidentifiable: large eigenvalue ratio

- Rescale variables?


And my questions are:

1) Marginal R2 is a good metric for identify a bad fixed effect choose 
in my models B? Despite a better conditional R2 comparing of conditional 
R2 in my model A.

2) If I'm sure about my fixed and random effects, it is better a final 
model with high values in both R2 or I choose based in the high value in 
conditional R2?


Thanks in advanced,


Alexandre


-- 
======================================================================
Alexandre dos Santos
Prote????o Florestal
IFMT - Instituto Federal de Educa????o, Ci??ncia e Tecnologia de Mato Grosso
Campus C??ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C??ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================


	[[alternative HTML version deleted]]


From @|ec@t|e| @end|ng |rom gm@||@com  Sat Jul 13 17:02:20 2019
From: @|ec@t|e| @end|ng |rom gm@||@com (Alejandro Catalina)
Date: Sat, 13 Jul 2019 18:02:20 +0300
Subject: [R-sig-ME] Fitting multi-response mixed effects models with lmer
In-Reply-To: <03e564c9-54be-4041-bae3-265c40a42d6a@Spark>
References: <03e564c9-54be-4041-bae3-265c40a42d6a@Spark>
Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7@Spark>

Dear all,

I found myself trying to fit a multi-response model with lmer the other day and today I learned that it is indeed not implemented. Is there anyone looking on that direction or does anyone have any pointers or suggestions? I guess I can iteratively fit one model for each response but I?m guessing that would be much slower. Furthermore, I would need to later combine all the models into a single object for my specific requirements. This is the issue I opened on lme4?s GitHub:

	Hi,
I am trying to solve the following formula with?lmer:
cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
which works fine for standard?lm?models without the group terms, but it fails when I have the mixed effects terms with the following error:
Error in initializePtr() : updateMu: Size mismatch
If this is not the right place to post this issue please tell me, I appreciate any pointers forward.

Thank you all,

Best,
Alejandro

	[[alternative HTML version deleted]]


From jonn@t|on@ @end|ng |rom gm@||@com  Sun Jul 14 16:32:31 2019
From: jonn@t|on@ @end|ng |rom gm@||@com (jonnations)
Date: Sun, 14 Jul 2019 07:32:31 -0700
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
In-Reply-To: <mailman.17680.5.1563098402.28274.r-sig-mixed-models@r-project.org>
References: <mailman.17680.5.1563098402.28274.r-sig-mixed-models@r-project.org>
Message-ID: <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>

Hi Alejandro,

This is easy to do in brms, if you?re willing to explore Bayesian options.
There is a nice vignette (brms multivariate) that covers this exact thing.

Jon

On Sun, Jul 14, 2019 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Fitting multi-response mixed effects models with lmer
>       (Alejandro Catalina)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 13 Jul 2019 18:02:20 +0300
> From: Alejandro Catalina <alecatfel at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fitting multi-response mixed effects models with
>         lmer
> Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
> Content-Type: text/plain; charset="utf-8"
>
> Dear all,
>
> I found myself trying to fit a multi-response model with lmer the other
> day and today I learned that it is indeed not implemented. Is there anyone
> looking on that direction or does anyone have any pointers or suggestions?
> I guess I can iteratively fit one model for each response but I?m guessing
> that would be much slower. Furthermore, I would need to later combine all
> the models into a single object for my specific requirements. This is the
> issue I opened on lme4?s GitHub:
>
>         Hi,
> I am trying to solve the following formula with lmer:
> cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
> which works fine for standard lm models without the group terms, but it
> fails when I have the mixed effects terms with the following error:
> Error in initializePtr() : updateMu: Size mismatch
> If this is not the right place to post this issue please tell me, I
> appreciate any pointers forward.
>
> Thank you all,
>
> Best,
> Alejandro
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 151, Issue 10
> ***************************************************

-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab <https://esselstyn.github.io/>
Museum of Natural Sciences <https://www.lsu.edu/mns/>
Louisiana State University

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul 14 22:07:43 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 14 Jul 2019 16:07:43 -0400
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
In-Reply-To: <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>
References: <mailman.17680.5.1563098402.28274.r-sig-mixed-models@r-project.org>
 <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>
Message-ID: <CABghstS6gyd41-jOeEU4QGoW+G7M7uOjg9LiAcQm2dh65RW-AA@mail.gmail.com>

 It isn't terribly hard to roll your own: this is untested but should
get you started.

   respvars <- c("y.1","y.2","y.3")
   fits <- vector("list", 3)
   names(fits) <- respvars
   fits[[1]] <- lmer(y.1 ~ u + (u | floor_id) + (u | county_id),
data=your_data))
   for (i in 2:3) {
           fits[[i]] <- refit(fits[[1]], your_data[[respvars[i]]]
       }
  }

On Sun, Jul 14, 2019 at 10:33 AM jonnations <jonnations at gmail.com> wrote:
>
> Hi Alejandro,
>
> This is easy to do in brms, if you?re willing to explore Bayesian options.
> There is a nice vignette (brms multivariate) that covers this exact thing.
>
> Jon
>
> On Sun, Jul 14, 2019 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
> wrote:
>
> > Send R-sig-mixed-models mailing list submissions to
> >         r-sig-mixed-models at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help' to
> >         r-sig-mixed-models-request at r-project.org
> >
> > You can reach the person managing the list at
> >         r-sig-mixed-models-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> >
> >
> > Today's Topics:
> >
> >    1. Fitting multi-response mixed effects models with lmer
> >       (Alejandro Catalina)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Sat, 13 Jul 2019 18:02:20 +0300
> > From: Alejandro Catalina <alecatfel at gmail.com>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Fitting multi-response mixed effects models with
> >         lmer
> > Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
> > Content-Type: text/plain; charset="utf-8"
> >
> > Dear all,
> >
> > I found myself trying to fit a multi-response model with lmer the other
> > day and today I learned that it is indeed not implemented. Is there anyone
> > looking on that direction or does anyone have any pointers or suggestions?
> > I guess I can iteratively fit one model for each response but I?m guessing
> > that would be much slower. Furthermore, I would need to later combine all
> > the models into a single object for my specific requirements. This is the
> > issue I opened on lme4?s GitHub:
> >
> >         Hi,
> > I am trying to solve the following formula with lmer:
> > cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
> > which works fine for standard lm models without the group terms, but it
> > fails when I have the mixed effects terms with the following error:
> > Error in initializePtr() : updateMu: Size mismatch
> > If this is not the right place to post this issue please tell me, I
> > appreciate any pointers forward.
> >
> > Thank you all,
> >
> > Best,
> > Alejandro
> >
> >         [[alternative HTML version deleted]]
> >
> >
> >
> >
> > ------------------------------
> >
> > Subject: Digest Footer
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 151, Issue 10
> > ***************************************************
>
> --
> Jonathan A. Nations
> PhD Candidate
> Esselstyn Lab <https://esselstyn.github.io/>
> Museum of Natural Sciences <https://www.lsu.edu/mns/>
> Louisiana State University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |@n@dwork|n @end|ng |rom gm@||@com  Sun Jul 14 22:36:57 2019
From: |@n@dwork|n @end|ng |rom gm@||@com (Ian Dworkin)
Date: Sun, 14 Jul 2019 16:36:57 -0400
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
In-Reply-To: <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>
References: <mailman.17680.5.1563098402.28274.r-sig-mixed-models@r-project.org>
 <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>
Message-ID: <CAGudrj=ZLPGV1BUweqHKA-MVHYY90CVuSNH7d+b4ZkDi9RbWmQ@mail.gmail.com>

Alejandro,

 Ben B. and I taught some examples of "tricking" lmer for multivariate
response models, see here
https://mac-theobio.github.io/QMEE/MultivariateMixed.html

Cheers
Ian

On Sun, 14 Jul 2019 at 10:33, jonnations <jonnations at gmail.com> wrote:

> Hi Alejandro,
>
> This is easy to do in brms, if you?re willing to explore Bayesian options.
> There is a nice vignette (brms multivariate) that covers this exact thing.
>
> Jon
>
> On Sun, Jul 14, 2019 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
> wrote:
>
> > Send R-sig-mixed-models mailing list submissions to
> >         r-sig-mixed-models at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help' to
> >         r-sig-mixed-models-request at r-project.org
> >
> > You can reach the person managing the list at
> >         r-sig-mixed-models-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> >
> >
> > Today's Topics:
> >
> >    1. Fitting multi-response mixed effects models with lmer
> >       (Alejandro Catalina)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Sat, 13 Jul 2019 18:02:20 +0300
> > From: Alejandro Catalina <alecatfel at gmail.com>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Fitting multi-response mixed effects models with
> >         lmer
> > Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
> > Content-Type: text/plain; charset="utf-8"
> >
> > Dear all,
> >
> > I found myself trying to fit a multi-response model with lmer the other
> > day and today I learned that it is indeed not implemented. Is there
> anyone
> > looking on that direction or does anyone have any pointers or
> suggestions?
> > I guess I can iteratively fit one model for each response but I?m
> guessing
> > that would be much slower. Furthermore, I would need to later combine all
> > the models into a single object for my specific requirements. This is the
> > issue I opened on lme4?s GitHub:
> >
> >         Hi,
> > I am trying to solve the following formula with lmer:
> > cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
> > which works fine for standard lm models without the group terms, but it
> > fails when I have the mixed effects terms with the following error:
> > Error in initializePtr() : updateMu: Size mismatch
> > If this is not the right place to post this issue please tell me, I
> > appreciate any pointers forward.
> >
> > Thank you all,
> >
> > Best,
> > Alejandro
> >
> >         [[alternative HTML version deleted]]
> >
> >
> >
> >
> > ------------------------------
> >
> > Subject: Digest Footer
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 151, Issue 10
> > ***************************************************
>
> --
> Jonathan A. Nations
> PhD Candidate
> Esselstyn Lab <https://esselstyn.github.io/>
> Museum of Natural Sciences <https://www.lsu.edu/mns/>
> Louisiana State University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Ian Dworkin
Department of Biology
McMaster University
Office phone 905 525 9140 ext. 21775
Lab phone 905 525 9140 ext. 20076
dworkin at mcmaster.ca

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jul 14 23:03:56 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 14 Jul 2019 17:03:56 -0400
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
In-Reply-To: <CAGudrj=ZLPGV1BUweqHKA-MVHYY90CVuSNH7d+b4ZkDi9RbWmQ@mail.gmail.com>
References: <mailman.17680.5.1563098402.28274.r-sig-mixed-models@r-project.org>
 <CAHta4sPog9ROWa=FaJfon+HYsKYEp3OdSmaLFs2qM9X63gzyrw@mail.gmail.com>
 <CAGudrj=ZLPGV1BUweqHKA-MVHYY90CVuSNH7d+b4ZkDi9RbWmQ@mail.gmail.com>
Message-ID: <17f9f18e-f957-2a50-d878-929e1deedb86@gmail.com>


  I thought Alejandro was interested in fitting these responses as
*independent* outcomes (since he says below "I can iteratively fit one
model for each response but I?m guessing that would be much slower"; I
think the loop using refit() every time after the first would be
reasonably fast - I certainly don't see a super-easy way to do it faster
...)

On 2019-07-14 4:36 p.m., Ian Dworkin wrote:
> Alejandro,
> 
>  Ben B. and I taught some examples of "tricking" lmer for multivariate
> response models, see here
> https://mac-theobio.github.io/QMEE/MultivariateMixed.html
> 
> Cheers
> Ian
> 
> On Sun, 14 Jul 2019 at 10:33, jonnations <jonnations at gmail.com> wrote:
> 
>> Hi Alejandro,
>>
>> This is easy to do in brms, if you?re willing to explore Bayesian options.
>> There is a nice vignette (brms multivariate) that covers this exact thing.
>>
>> Jon
>>
>> On Sun, Jul 14, 2019 at 3:01 AM <r-sig-mixed-models-request at r-project.org>
>> wrote:
>>
>>> Send R-sig-mixed-models mailing list submissions to
>>>         r-sig-mixed-models at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> or, via email, send a message with subject or body 'help' to
>>>         r-sig-mixed-models-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>>         r-sig-mixed-models-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of R-sig-mixed-models digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>    1. Fitting multi-response mixed effects models with lmer
>>>       (Alejandro Catalina)
>>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Sat, 13 Jul 2019 18:02:20 +0300
>>> From: Alejandro Catalina <alecatfel at gmail.com>
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] Fitting multi-response mixed effects models with
>>>         lmer
>>> Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
>>> Content-Type: text/plain; charset="utf-8"
>>>
>>> Dear all,
>>>
>>> I found myself trying to fit a multi-response model with lmer the other
>>> day and today I learned that it is indeed not implemented. Is there
>> anyone
>>> looking on that direction or does anyone have any pointers or
>> suggestions?
>>> I guess I can iteratively fit one model for each response but I?m
>> guessing
>>> that would be much slower. Furthermore, I would need to later combine all
>>> the models into a single object for my specific requirements. This is the
>>> issue I opened on lme4?s GitHub:
>>>
>>>         Hi,
>>> I am trying to solve the following formula with lmer:
>>> cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
>>> which works fine for standard lm models without the group terms, but it
>>> fails when I have the mixed effects terms with the following error:
>>> Error in initializePtr() : updateMu: Size mismatch
>>> If this is not the right place to post this issue please tell me, I
>>> appreciate any pointers forward.
>>>
>>> Thank you all,
>>>
>>> Best,
>>> Alejandro
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Subject: Digest Footer
>>>
>>> _______________________________________________
>>> R-sig-mixed-models mailing list
>>> R-sig-mixed-models at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> ------------------------------
>>>
>>> End of R-sig-mixed-models Digest, Vol 151, Issue 10
>>> ***************************************************
>>
>> --
>> Jonathan A. Nations
>> PhD Candidate
>> Esselstyn Lab <https://esselstyn.github.io/>
>> Museum of Natural Sciences <https://www.lsu.edu/mns/>
>> Louisiana State University
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>


From hou@|@y @end|ng |rom gm@||@com  Sun Jul 14 12:23:50 2019
From: hou@|@y @end|ng |rom gm@||@com (Tom Houslay)
Date: Sun, 14 Jul 2019 11:23:50 +0100
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
Message-ID: <CAErKyRrgU4FJMXXpEX2mg+HCYndi8uGEewiUHnU9tgxNOAqu4w@mail.gmail.com>

Hi Alejandro,

There are a few packages in R that you can use for multi-response mixed
models, such as MCMCglmm, brms, and wrappers for Stan, as well as ASreml-R
(if you have an ASreml licence). ASreml is the only one of those that uses
REML, while the others are Bayesian.

I have some tutorials on fitting these types of models in MCMCglmm and
ASreml-R here in case they are useful:

https://tomhouslay.com/tutorials/

Cheers,

Tom



>
> Date: Sat, 13 Jul 2019 18:02:20 +0300
> From: Alejandro Catalina <alecatfel at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Fitting multi-response mixed effects models with
>         lmer
> Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
> Content-Type: text/plain; charset="utf-8"
>
> Dear all,
>
> I found myself trying to fit a multi-response model with lmer the other
> day and today I learned that it is indeed not implemented. Is there anyone
> looking on that direction or does anyone have any pointers or suggestions?
> I guess I can iteratively fit one model for each response but I?m guessing
> that would be much slower. Furthermore, I would need to later combine all
> the models into a single object for my specific requirements. This is the
> issue I opened on lme4?s GitHub:
>
>         Hi,
> I am trying to solve the following formula with lmer:
> cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
> which works fine for standard lm models without the group terms, but it
> fails when I have the mixed effects terms with the following error:
> Error in initializePtr() : updateMu: Size mismatch
> If this is not the right place to post this issue please tell me, I
> appreciate any pointers forward.
>
> Thank you all,
>
> Best,
> Alejandro
>
>

	[[alternative HTML version deleted]]


From @|ec@t|e| @end|ng |rom gm@||@com  Sun Jul 14 12:27:34 2019
From: @|ec@t|e| @end|ng |rom gm@||@com (Alejandro Catalina)
Date: Sun, 14 Jul 2019 13:27:34 +0300
Subject: [R-sig-ME] 
 Fitting multi-response mixed effects models with lmer
In-Reply-To: <CAErKyRrgU4FJMXXpEX2mg+HCYndi8uGEewiUHnU9tgxNOAqu4w@mail.gmail.com>
References: <CAErKyRrgU4FJMXXpEX2mg+HCYndi8uGEewiUHnU9tgxNOAqu4w@mail.gmail.com>
Message-ID: <638111aa-8862-4830-a7ec-d3bbbeffd260@Spark>

Hi Tom,

First of all, thank you for the response,

Yes, I do know about Stan, but given that I only need a maximum likelihood estimator, using Stan seemed a bit too heavy. I will take a look to your tutorials nonetheless and to ASreml.

Best,
Alejandro
On 14 Jul 2019, 13:24 +0300, Tom Houslay <houslay at gmail.com>, wrote:
> Hi Alejandro,
>
> There are a few packages in R that you can use for multi-response mixed models, such as MCMCglmm, brms, and wrappers for Stan, as well as ASreml-R (if you have an ASreml licence). ASreml is the only one of those that uses REML, while the others are Bayesian.
>
> I have some tutorials on fitting these types of models in MCMCglmm and ASreml-R here in case they are useful:
>
> https://tomhouslay.com/tutorials/
>
> Cheers,
>
> Tom
>
>
> > >
> > >
> > > Date: Sat, 13 Jul 2019 18:02:20 +0300
> > > From: Alejandro Catalina <alecatfel at gmail.com>
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Fitting multi-response mixed effects models with
> > > ? ? ? ? lmer
> > > Message-ID: <e44b3683-1a88-45f8-8dc8-1c07595c0dd7 at Spark>
> > > Content-Type: text/plain; charset="utf-8"
> > >
> > > Dear all,
> > >
> > > I found myself trying to fit a multi-response model with lmer the other day and today I learned that it is indeed not implemented. Is there anyone looking on that direction or does anyone have any pointers or suggestions? I guess I can iteratively fit one model for each response but I?m guessing that would be much slower. Furthermore, I would need to later combine all the models into a single object for my specific requirements. This is the issue I opened on lme4?s GitHub:
> > >
> > > ? ? ? ? Hi,
> > > I am trying to solve the following formula with?lmer:
> > > cbind(y.1, y.2, y.3) ~ u + (u | floor_id) + (u | county_id)
> > > which works fine for standard?lm?models without the group terms, but it fails when I have the mixed effects terms with the following error:
> > > Error in initializePtr() : updateMu: Size mismatch
> > > If this is not the right place to post this issue please tell me, I appreciate any pointers forward.
> > >
> > > Thank you all,
> > >
> > > Best,
> > > Alejandro
> > >
> > >

	[[alternative HTML version deleted]]


From h@nk@@teven@ @end|ng |rom m|@m|oh@edu  Sun Jul 14 13:36:36 2019
From: h@nk@@teven@ @end|ng |rom m|@m|oh@edu (Stevens, Hank)
Date: Sun, 14 Jul 2019 07:36:36 -0400
Subject: [R-sig-ME] pairwise combinations of subjects
Message-ID: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>

I was hoping someone might point to information or examples of this type of
problem.

I sometimes encounter data that are derived from interactions between all
pairwise interactions of subjects (e.g., subject a vs. subject b, subject a
vs. subject c, subject b vs. subject c). The response is the result of the
interaction between subjects, and observations are likely to show
correlations within subject. We are interested in the relation between a
fixed effect predictor and the response, and not the effects of subject per
se. For instance,

subj_1   subj_2 . pred  resp
  a        b       1      5
  a        c       1.1 .  4
  b        c       2.5 .  1

where the subj 1 and subj 2 are all the same individuals, but are paired
with a different partner. It seems as though this might be crossed random
effects of subj_1 and subj_2. E.g.,
lmer( resp ~ pred + (1|subj1) + (1|subj2) )

This seems like a design that might be common in breeding....

Many thanks for your thoughts and leads.

Hank Stevens

A more thorough worked example:

library(lme4)
df <- expand.grid(gl())
n <- 5
l <- n*(n-1)/2
x <- data.frame( matrix(NA, nr=1, nc=2) )
names(x) <- c("sp1", "sp2")

r <- 1
for(i in 1:(n-1)){
  for(j in (i+1):n){
    x[r,1:2] <- c(i,j)
    r <- r+1
  }
}

set.seed(4)
x$y <- (x$sp1 + x$sp2) / (n*2) + runif(l)
set.seed(3)
x$c <- - (x$sp1 + x$sp2) / (n*2) + runif(l)

## which design, if any?
summary( lm(y ~ c, data=x))
summary( lmer(y ~ c + (1|sp1) + (1|sp2), data=x))

-- 
*Dr. Hank Stevens*
Lab website <http://blogs.miamioh.edu/stevens-lab/>
PhD Program in Ecology, Evolution, and Environmental Biology
<http://www.cas.muohio.edu/eeeb/index.html>
433 Hughes Hall, Miami University, tel: 513-529-4206

	[[alternative HTML version deleted]]


From beckm089 @end|ng |rom umn@edu  Tue Jul 16 00:10:12 2019
From: beckm089 @end|ng |rom umn@edu (Noelle G. Beckman)
Date: Mon, 15 Jul 2019 16:10:12 -0600
Subject: [R-sig-ME] Mixed model and repeated measures in R
In-Reply-To: <CAJuCY5zf6CXK9-4v=7UJ-TqWQM+KqQBgS7raqGNQ1jXqWC+PZg@mail.gmail.com>
References: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
 <CAJuCY5zf6CXK9-4v=7UJ-TqWQM+KqQBgS7raqGNQ1jXqWC+PZg@mail.gmail.com>
Message-ID: <BCB9E062-BB89-4313-B667-384F03D3950D@umn.edu>

I am currently out of the office until July 5th. I will respond to your email upon my return.

On Jun 17, 2019, at 12:38 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Dear Despina,
> 
> You have complete separation in your dataset. It shows in the output of the
> GCA data. Extreme random intercept variances (SCAN_DATE:ID and ID), extreme
> fixed effect parameters (intercept and Comb_PH_tod).
> 
> Your model is too complex for your data.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op zo 16 jun. 2019 om 21:13 schreef DESPINA MICHAILIDOU <
> de.michailidou at gmail.com>:
> 
> Hi All,
> 
> I am trying to run regression analysis adjusted for repeated measures in R.
> The imaging pathology finding defined as Vert_effect, CA_effect,
> Vert_Intens etc is the outcome variable whereas the clinical symptom
> defined as Comb_PH_tod, Comb_PNP_tod etc, is the predictor variable. Other
> predictor variables that I am using are the daily prednisone use (Pred) and
> the use of immunosuppresive therapy (Immune_Categorical) or not. As the
> prednisone variable is being read as character in R i converted it to
> numeric because it is a number. For example some patients are getting 2 mg
> of prednisone but some others 40 mg. ?I have two subset of diagnoses, ?the
> one is TAK and the second one is GCA. As some patients have either right
> side posterior headache or left side posterior headache or both or none and
> either right side vertebral intensity (imaging study pathology) or left
> side vertebral intensity, or both or none vertebral intensity, for each
> patient I created two rows per subject. The first row represents the right
> sided symptoms and imaging pathology findings and the second row represents
> the left sided symptoms and imaging findings. My repeated measures are the
> side of the symptoms and imaging findings (had to create a separate
> variable for the right and left side symptoms and right and left imaging
> findings that I called it Side and put in there R, L, R, L etc), the ID of
> the patients and the Scan_date visit. Some patients had one scan visit but
> some other patients had multiple scan visits, and that is why I am
> considering scan visit date as a repeated measure. *So this is the code
> that i am using and for the subset of TAK i get this output*
> 
> TAK_data <- subset(Despina, Diagnosis=="TAK")
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod ?+ (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> Error in length(value <- as.numeric(value)) == 1L :
> ?(maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> summary(glmm_Vert_Intes)
> 
> *whereas for the subset of GCA patients there are no issues.*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> Family: binomial ?( logit )
> Formula: Vert_Intes ~ Comb_PH_tod + (1 | ID/SCAN_DATE/Side) + Pred +
> Immune_Catagorical
> ??Data: GCA_data
> 
> ????AIC ?????BIC ??logLik deviance df.resid
> ???87.8 ???113.0 ???-36.9 ????73.8 ?????263
> 
> Scaled residuals:
> ????Min ??????1Q ??Median ??????3Q ?????Max
> -0.98336 -0.00342 -0.00241 -0.00214 ?1.02148
> 
> Random effects:
> Groups ?????????????Name ???????Variance Std.Dev.
> Side:(SCAN_DATE:ID) (Intercept) ??0.00 ???0.00
> SCAN_DATE:ID ???????(Intercept) 528.06 ??22.98
> ID ?????????????????(Intercept) ?18.84 ???4.34
> Number of obs: 270, groups: ?Side:(SCAN_DATE:ID), 270; SCAN_DATE:ID, 135;
> ID, 54
> 
> Fixed effects:
> ???????????????????Estimate Std. Error z value Pr(>|z|)
> (Intercept) ???????-10.63649 ???2.36017 ?-4.507 6.59e-06 ***
> Comb_PH_tod ????????-8.53678 ???4.56601 ?-1.870 ??0.0615 .
> Pred ???????????????-0.02353 ???0.09323 ?-0.252 ??0.8008
> Immune_Catagorical ?-1.41376 ???2.69420 ?-0.525 ??0.5998
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
> ???????????(Intr) Cm_PH_ Pred
> Comb_PH_tod ?0.299
> Pred ???????-0.289 -0.001
> Immn_Ctgrcl -0.520 -0.068 ?0.041
> convergence code: 0
> boundary (singular) fit: see ?isSingular
> 
> *And this is the detailed code that I am using in R*
> install.packages("lme4")
> install.packages("readr")
> 
> library(readr)
> library("lme4")
> 
> setwd("~/Desktop/Despina")
> Despina <- read_csv("Despina.csv")
> as.factor(Despina$ID)
> as.factor(Despina$Diagnosis)
> as.factor(Despina$SCAN_DATE)
> as.factor(Despina$Side)
> as.factor(Despina$Immune_Catagorical)
> as.factor(Despina$LH_today)
> as.factor(Despina$PLH_today)
> as.factor(Despina$Dizz_today)
> as.factor(Despina$P_Diz_today)
> as.factor(Despina$CD_tod)
> as.factor(Despina$Head_today)
> as.factor(Despina$Vertig_today)
> as.factor(Despina$FTH_tod)
> as.factor(Despina$Comb_PH_tod)
> as.factor(Despina$Comb_NP_tod)
> as.factor(Despina$Comb_ANP_tod)
> as.factor(Despina$Comb_PNP_tod)
> as.factor(Despina$CNS_ever)
> as.factor(Despina$ULC_today)
> as.factor(Despina$Vert_effect)
> as.factor(Despina$CA_effect)
> as.factor(Despina$Sub_invol)
> as.factor(Despina$Ax_involv)
> as.factor(Despina$CA_intens)
> as.factor(Despina$Sub_intens)
> as.factor(Despina$Vert_Intes)
> as.factor(Despina$Ax_intens)
> as.factor(Despina$Comb_Vis_L_today)
> Despina$Pred<-as.numeric(as.character(Despina$Pred))
> 
> 
> TAK_data <- subset(Despina, Diagnosis=="TAK")
> 
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod ?+ (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
> 
> GCA_data <- subset(Despina, Diagnosis=="GCA")
> 
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod ?+ (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=GCA_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
> 
> *So my question is why i am getting this error in TAK patients and not in
> GCA patients?*
> Error in length(value <- as.numeric(value)) == 1L :
> ?(maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> 
> Thank you all for your time and consideration in advance.
> 
> Sincerely,
> Despina
> 
> ???????[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative text/enriched version deleted]]


From beckm089 @end|ng |rom umn@edu  Tue Jul 16 00:21:31 2019
From: beckm089 @end|ng |rom umn@edu (Noelle G. Beckman)
Date: Mon, 15 Jul 2019 16:21:31 -0600
Subject: [R-sig-ME] Fwd: Question about non-significant interactions
In-Reply-To: <CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
References: <16931_1562685902_x69FP2qN000508_CABX-QoG4MT_n3as5uibxD=fiGH9-Tqrtn=s5p3jshLx5z-jkbQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836C496FA@FHSDB2D11-2.csu.mcmaster.ca>
 <CABX-QoEY4wS6oxMMPJgVq88sLtbc6xN6kXBXqm2FWbUtDH8t-g@mail.gmail.com>
 <CABX-QoFqCoAUHNsj0s64JWSmo7w_HY7nuauw_7MZ1371OTYZEA@mail.gmail.com>
 <CAJuCY5xNHmpM81qgMWF8YFPnPB32k6yxYC9oTRBwkHMe9SRs1A@mail.gmail.com>
Message-ID: <B89C22E3-3DCB-4D4C-9D8C-AE8735D2AB0E@umn.edu>

I am currently out of the office until July 5th. I will respond to your email upon my return.

On Jul 10, 2019, at 12:51 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Dear Francesco,
> 
> To answer your question, you should convert your hypothesis in a set of
> linear contrasts and test those.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op di 9 jul. 2019 om 23:25 schreef Francesco Romano <fbromano77 at gmail.com>:
> 
> ---------- Forwarded message ---------
> From: Francesco Romano <fbromano77 at gmail.com>
> Date: Tue, Jul 9, 2019 at 11:24 PM
> Subject: Re: [R-sig-ME] Question about non-significant interactions
> To: Fox, John <jfox at mcmaster.ca>
> 
> 
> Dear John,
> 
> Thanks for the reply. One of my research entails examining the relationship
> between 3 groups of speakers, the 3 levels of the group categorical
> variable previously mentioned, and two tasks. One prediction is that one
> group will perform better than other groups on one test but not the other.
> 
> I fit a maximal model using the bglmr function as shown previously, then
> used car::Anova to determine main effects. My understanding from previous
> interaction with you precisely here on r-sig-me is that the function works
> as a form of shortcut to the traditional way of model-fitting/ reduction
> via the function anova() comparing models, eliminating terms one at a time.
> 
> I hope this is clearer now and yes, the question is more of a statistical
> one than an R one, even though I suspect the mixed-effect aspect of the
> regression may be relevant to answering it.
> 
> Frank
> 
> Tue, Jul 9, 2019 at 11:03 PM Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Francesco,
> 
> I didn't entirely follow your question and I expect that to answer it, it
> would be necessary to know more about what your research entails. As you
> imply, this seems to be more a statistics question than an R question.
> It's
> also not clear to me what function you used to fit the mixed-effects
> logistic regression.
> 
> But I did notice that you're apparently using Anova() for type-III tests
> with the default contr.treatment() coding for factors. The main-effect
> tests that result are not sensible. As it says in ?Anova:
> 
> "Warning
> Be careful of type-III tests: For a traditional multifactor ANOVA model
> with interactions, for example, these tests will normally only be
> sensible
> when using contrasts that, for different terms, are orthogonal in the
> row-basis of the model, such as those produced by contr.sum, contr.poly,
> or
> contr.helmert, but not by the default contr.treatment. In a model that
> contains factors, numeric covariates, and interactions, main-effect tests
> for factors will be for differences over the origin. In contrast (pun
> intended), type-II tests are invariant with respect to (full-rank)
> contrast
> coding. If you don't understand this issue, then you probably shouldn't
> use
> Anova for type-III tests."
> 
> I hope that this is of some help,
> John
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
> 
> 
> ________________________________________
> From: R-sig-mixed-models [r-sig-mixed-models-bounces at r-project.org] on
> behalf of Francesco Romano [fbromano77 at gmail.com]
> Sent: July 9, 2019 9:49 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Question about non-significant interactions
> 
> Dear all,
> 
> 
> I have more of a theoretical than practical question for you. The model I
> am using has two IVs, group (3 levels) and task (2 levels), and a
> categorical DV (correct versus incorrect), hence logistic regression.
> Random effects for subjects and items, as well as slopes for group by
> item
> and task by subject.
> 
> I am interested in the effect of belonging any of three groups, the
> levels
> of the group IV, in order to test some a priori predictions. The bayesian
> wrapper is to help the model converge.
> 
> Here is the output:
> 
> summary(paper2analysis1)
> Cov prior ?: item ~ wishart(df = 5.5, scale = Inf, posterior.scale = cov,
> common.scale = TRUE)
> ??????????: Participant ~ wishart(df = 4.5, scale = Inf,
> posterior.scale =
> cov, common.scale = TRUE)
> Prior dev ?: 6.9466
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['bglmerMod']
> Family: binomial ?( logit )
> Formula: correctness ~ task * group + (1 + task | Participant) + (1 +
> group | item)
> ??Data: data
> Control: glmerControl(optimizer = "bobyqa")
> 
> ????AIC ?????BIC ??logLik deviance df.resid
> ?3857.8 ??3957.2 ?-1913.9 ??3827.8 ????5570
> 
> Scaled residuals:
> ???Min ?????1Q ?Median ?????3Q ????Max
> -2.0196 -0.3744 -0.2312 -0.1368 ?6.9534
> 
> Random effects:
> Groups ?????Name ???????Variance Std.Dev. Corr
> item ???????(Intercept) 1.1266 ??1.0614
> ????????????groupL2 ????0.1311 ??0.3620 ??-0.12
> ????????????groupNS ????0.2029 ??0.4504 ??-0.31 ?0.17
> Participant (Intercept) 0.7582 ??0.8708
> ????????????taskpriming 1.2163 ??1.1029 ??-0.77
> Number of obs: 5585, groups: ?item, 219; Participant, 46
> 
> Fixed effects:
> ???????????????????Estimate Std. Error z value Pr(>|z|)
> (Intercept) ????????-2.49187 ???0.28318 ?-8.800 ?< 2e-16 ***
> taskpriming ?????????1.30911 ???0.37367 ??3.503 0.000459 ***
> groupL2 ????????????-0.04042 ???0.38322 ?-0.105 0.916005
> groupNS ????????????-1.01144 ???0.36607 ?-2.763 0.005727 **
> taskpriming:groupL2 ?0.04305 ???0.48693 ??0.088 0.929544
> taskpriming:groupNS -0.04942 ???0.46034 ?-0.107 0.914506
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
> ???????????(Intr) tskprm gropL2 gropNS tsk:L2
> taskpriming -0.733
> groupL2 ????-0.660 ?0.482
> groupNS ????-0.693 ?0.507 ?0.509
> tskprmng:L2 ?0.499 -0.632 -0.755 -0.386
> tskprmng:NS ?0.530 -0.676 -0.390 -0.750 ?0.508
> 
> The model was then subjected to car::Anova for ANOVA type III analysis
> with
> the following output:
> 
> car::Anova(paper2analysis1, type = "III")
> Analysis of Deviance Table (Type III Wald chisquare tests)
> 
> Response: correctness
> ?????????????Chisq Df Pr(>Chisq)
> (Intercept) 77.4344 ?1 ?< 2.2e-16 ***
> task ???????12.2737 ?1 ?0.0004594 ***
> group ???????9.9237 ?2 ?0.0070000 **
> task:group ??0.0391 ?2 ?0.9806462
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> I am not sure how to interpret the non-significant interaction in this
> case. Does this mean that, although simple effects exist at group level
> within one particular task or at task level within one particular group,
> I
> lack sufficient power to conclude those effects are real? If I look at
> the
> simple effects, I do indeed find such effects but am not sure how to
> interpret them against the lack of a main interaction. At a practical
> level, the interaction, rather than the main effects, is the most
> important
> part of the analysis.
> 
> Thank you in advance for any advice.
> 
> Francesco
> 
> 
> 
> 
> 
> Best,
> 
> Frank
> 
> ???????[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> Inviato da Gmail Mobile
> --
> Inviato da Gmail Mobile
> 
> ???????[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative text/enriched version deleted]]


From m|u804 @end|ng |rom @uck|@ndun|@@c@nz  Tue Jul 16 05:15:54 2019
From: m|u804 @end|ng |rom @uck|@ndun|@@c@nz (Mengxia Fu)
Date: Tue, 16 Jul 2019 15:15:54 +1200
Subject: [R-sig-ME] question about emmeans post-hoc analysis
Message-ID: <CAE1+hsqDNHWWTyVkS9e2wHTL9y3yw9osN0qhVCP5Uy16ww9aSA@mail.gmail.com>

Hi list,

I have a question about post-hoc analyses using emmeans function. The model
I am using has four independent variables, pre-test scores, group (4
levels), time (4 levels), and the interaction between group and time. The
dependent variable is post-test scores. I would like to know the
differences between the four groups in terms of their post-test scores at
each time point while controlling for the effects of pre-test scores. My
model is:

*mod<-lmer(posttest scores~pre-test
scores+group+time+group*time+(1|Subject),data=GJT)*

For the post-hoc analyses, I used emmeans. The R code is:

*emmeans(mod, list(pairwise~group|time), adjust="bonferroni")*

My question is: Do the pair-wise comparisons carried out through emmeans
account for the influence of pre-test scores? Because the omnibus test
shows that the effect of pre-test scores is significant, I would like to
exclude the influence of pre-test scores on pair-wise comparisons.

Thank you in advance for any advice.

Best,

Mengxia

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Jul 16 06:27:11 2019
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 16 Jul 2019 04:27:11 +0000
Subject: [R-sig-ME] pairwise combinations of subjects
In-Reply-To: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
References: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4B49F9895@EXCH06S.adqimr.ad.lan>

> I sometimes encounter data that are derived from interactions between all
> pairwise interactions of subjects (e.g., subject a vs. subject b, subject a
> vs. subject c, subject b vs. subject c). The response is the result of the
> interaction between subjects, and observations are likely to show
> correlations within subject. We are interested in the relation between a
> fixed effect predictor and the response, and not the effects of subject per se.
[...]
> This seems like a design that might be common in breeding....

Yes, we fit this flavour of model as SEMs - for example, not exactly the same but just as mechanistically plausible, you have a reciprocal causative pairwise relationship
    ----->
X1      X2
   <-----
|           |
v         v
Y1      Y2

detectable by its effects on total variance (correlated with values of X - so 'ware those variance stabilising transformations ;)), and distribution of the Y's.  The coefficients can be negative, so members of each pair rub each other the wrong way _OR_ if the measurement is say a rating by an external observer, then the ratings may be biased away from each other ("contrast effect"). I don't know how to do this in lme4, but on page 9 of 

https://peerj.com/preprints/3354.pdf

you can see them fitting such a model using the R umx package.

Cheers, David Duffy


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul 16 09:35:48 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 16 Jul 2019 09:35:48 +0200
Subject: [R-sig-ME] pairwise combinations of subjects
In-Reply-To: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
References: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
Message-ID: <CAJuCY5wy9ub5YrSguCM4S9pA-CxAk2OnmOx=mRUjhCKWJCDK-A@mail.gmail.com>

Dear Hank,

Here is a solution using the INLA package. This model has two random
effects with identical estimates for each level.

# make sure that sp1 contains each level
old <- x$sp1[n - 1]
x$sp1[n - 1] <- x$sp2[n - 1]
x$sp2[n - 1] <- old

# fit the model
library(INLA)
m <- inla(y ~ c + f(sp1, model = "iid", n = n) + f(sp2, copy = "sp1"), data
= x)
summary(m)
plot(m)

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 15 jul. 2019 om 15:33 schreef Stevens, Hank <hank.stevens at miamioh.edu
>:

> I was hoping someone might point to information or examples of this type of
> problem.
>
> I sometimes encounter data that are derived from interactions between all
> pairwise interactions of subjects (e.g., subject a vs. subject b, subject a
> vs. subject c, subject b vs. subject c). The response is the result of the
> interaction between subjects, and observations are likely to show
> correlations within subject. We are interested in the relation between a
> fixed effect predictor and the response, and not the effects of subject per
> se. For instance,
>
> subj_1   subj_2 . pred  resp
>   a        b       1      5
>   a        c       1.1 .  4
>   b        c       2.5 .  1
>
> where the subj 1 and subj 2 are all the same individuals, but are paired
> with a different partner. It seems as though this might be crossed random
> effects of subj_1 and subj_2. E.g.,
> lmer( resp ~ pred + (1|subj1) + (1|subj2) )
>
> This seems like a design that might be common in breeding....
>
> Many thanks for your thoughts and leads.
>
> Hank Stevens
>
> A more thorough worked example:
>
> library(lme4)
> df <- expand.grid(gl())
> n <- 5
> l <- n*(n-1)/2
> x <- data.frame( matrix(NA, nr=1, nc=2) )
> names(x) <- c("sp1", "sp2")
>
> r <- 1
> for(i in 1:(n-1)){
>   for(j in (i+1):n){
>     x[r,1:2] <- c(i,j)
>     r <- r+1
>   }
> }
>
> set.seed(4)
> x$y <- (x$sp1 + x$sp2) / (n*2) + runif(l)
> set.seed(3)
> x$c <- - (x$sp1 + x$sp2) / (n*2) + runif(l)
>
> ## which design, if any?
> summary( lm(y ~ c, data=x))
> summary( lmer(y ~ c + (1|sp1) + (1|sp2), data=x))
>
> --
> *Dr. Hank Stevens*
> Lab website <http://blogs.miamioh.edu/stevens-lab/>
> PhD Program in Ecology, Evolution, and Environmental Biology
> <http://www.cas.muohio.edu/eeeb/index.html>
> 433 Hughes Hall, Miami University, tel: 513-529-4206
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From beckm089 @end|ng |rom umn@edu  Tue Jul 16 14:47:09 2019
From: beckm089 @end|ng |rom umn@edu (Noelle G. Beckman)
Date: Tue, 16 Jul 2019 06:47:09 -0600
Subject: [R-sig-ME] pairwise combinations of subjects
In-Reply-To: <CAJuCY5wy9ub5YrSguCM4S9pA-CxAk2OnmOx=mRUjhCKWJCDK-A@mail.gmail.com>
References: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
 <CAJuCY5wy9ub5YrSguCM4S9pA-CxAk2OnmOx=mRUjhCKWJCDK-A@mail.gmail.com>
Message-ID: <FAF3F6E2-726E-4892-B7A8-EBBBA43A25CE@umn.edu>

I am currently out of the office until July 5th. I will respond to your email upon my return.

On Jul 16, 2019, at 1:35 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Dear Hank,
> 
> Here is a solution using the INLA package. This model has two random
> effects with identical estimates for each level.
> 
> # make sure that sp1 contains each level
> old <- x$sp1[n - 1]
> x$sp1[n - 1] <- x$sp2[n - 1]
> x$sp2[n - 1] <- old
> 
> # fit the model
> library(INLA)
> m <- inla(y ~ c + f(sp1, model = "iid", n = n) + f(sp2, copy = "sp1"), data
> = x)
> summary(m)
> plot(m)
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 15 jul. 2019 om 15:33 schreef Stevens, Hank <hank.stevens at miamioh.edu
> :
> 
> I was hoping someone might point to information or examples of this type of
> problem.
> 
> I sometimes encounter data that are derived from interactions between all
> pairwise interactions of subjects (e.g., subject a vs. subject b, subject a
> vs. subject c, subject b vs. subject c). The response is the result of the
> interaction between subjects, and observations are likely to show
> correlations within subject. We are interested in the relation between a
> fixed effect predictor and the response, and not the effects of subject per
> se. For instance,
> 
> subj_1 ??subj_2 . pred ?resp
> ?a ???????b ??????1 ?????5
> ?a ???????c ??????1.1 . ?4
> ?b ???????c ??????2.5 . ?1
> 
> where the subj 1 and subj 2 are all the same individuals, but are paired
> with a different partner. It seems as though this might be crossed random
> effects of subj_1 and subj_2. E.g.,
> lmer( resp ~ pred + (1|subj1) + (1|subj2) )
> 
> This seems like a design that might be common in breeding....
> 
> Many thanks for your thoughts and leads.
> 
> Hank Stevens
> 
> A more thorough worked example:
> 
> library(lme4)
> df <- expand.grid(gl())
> n <- 5
> l <- n*(n-1)/2
> x <- data.frame( matrix(NA, nr=1, nc=2) )
> names(x) <- c("sp1", "sp2")
> 
> r <- 1
> for(i in 1:(n-1)){
> ?for(j in (i+1):n){
> ???x[r,1:2] <- c(i,j)
> ???r <- r+1
> ?}
> }
> 
> set.seed(4)
> x$y <- (x$sp1 + x$sp2) / (n*2) + runif(l)
> set.seed(3)
> x$c <- - (x$sp1 + x$sp2) / (n*2) + runif(l)
> 
> ## which design, if any?
> summary( lm(y ~ c, data=x))
> summary( lmer(y ~ c + (1|sp1) + (1|sp2), data=x))
> 
> --
> *Dr. Hank Stevens*
> Lab website <http://blogs.miamioh.edu/stevens-lab/>
> PhD Program in Ecology, Evolution, and Environmental Biology
> <http://www.cas.muohio.edu/eeeb/index.html>
> 433 Hughes Hall, Miami University, tel: 513-529-4206
> 
> ???????[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative text/enriched version deleted]]


From h@nk@@teven@ @end|ng |rom m|@m|oh@edu  Tue Jul 16 14:36:23 2019
From: h@nk@@teven@ @end|ng |rom m|@m|oh@edu (Stevens, Hank)
Date: Tue, 16 Jul 2019 08:36:23 -0400
Subject: [R-sig-ME] pairwise combinations of subjects
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D4B49F9895@EXCH06S.adqimr.ad.lan>
References: <CALCw2y-pK72xPqGXiC3k=xzSwe5f7R5azM-GqTcYJ0C9U05sYw@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4B49F9895@EXCH06S.adqimr.ad.lan>
Message-ID: <CALCw2y-sP-varffCGkd9_-VU2Q7_OPstGikVnwaR8D7T9NSrZQ@mail.gmail.com>

Thanks David! That looks like a great solution, and a great SEM package. I
plan on spreading the word about umx.
Best,
Hank

On Tue, Jul 16, 2019 at 12:27 AM David Duffy <
David.Duffy at qimrberghofer.edu.au> wrote:

> > I sometimes encounter data that are derived from interactions between all
> > pairwise interactions of subjects (e.g., subject a vs. subject b,
> subject a
> > vs. subject c, subject b vs. subject c). The response is the result of
> the
> > interaction between subjects, and observations are likely to show
> > correlations within subject. We are interested in the relation between a
> > fixed effect predictor and the response, and not the effects of subject
> per se.
> [...]
> > This seems like a design that might be common in breeding....
>
> Yes, we fit this flavour of model as SEMs - for example, not exactly the
> same but just as mechanistically plausible, you have a reciprocal causative
> pairwise relationship
>     ----->
> X1      X2
>    <-----
> |           |
> v         v
> Y1      Y2
>
> detectable by its effects on total variance (correlated with values of X -
> so 'ware those variance stabilising transformations ;)), and distribution
> of the Y's.  The coefficients can be negative, so members of each pair rub
> each other the wrong way _OR_ if the measurement is say a rating by an
> external observer, then the ratings may be biased away from each other
> ("contrast effect"). I don't know how to do this in lme4, but on page 9 of
>
> https://peerj.com/preprints/3354.pdf
>
> you can see them fitting such a model using the R umx package.
>
> Cheers, David Duffy
>


-- 

?Life is a garden, not a road. We enter and exit through the same gate.
Wandering, where we go matters less than what we notice.?
*Dr. Hank Stevens*
Lab website <http://blogs.miamioh.edu/stevens-lab/>
PhD Program in Ecology, Evolution, and Environmental Biology
<http://www.cas.muohio.edu/eeeb/index.html>
My schedule is available by adding stevenmh at miamioh.edu to your Google
Calendar
433 Hughes Hall, Miami University, tel: 513-529-4206

	[[alternative HTML version deleted]]


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Tue Jul 16 17:25:58 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Tue, 16 Jul 2019 15:25:58 +0000
Subject: [R-sig-ME] About modelling time as continuous variable in a
 glmmTMB-based model.
Message-ID: <badb7f3f87dc4fa58934dca016c2a30e@unige.ch>

Dear lists members,

Based on the glmmTMB-based model:

Model 1. Time as a fixed factor:
zipoisson <- glmmTMB(Observations ~ CAP * Time + (1|ID), data=mDATA, ziformula=~ CAP * Time , family=poisson)

A gentle member from this list suggested me to treat time as continuous.  Since I am new with mixed models, I would like to confirm that the new models for this aim are right:

Model 2. Time as continuous variable:
zipoisson <- glmmTMB(Observations ~ CAP * Time + (ID|Time), data=mDATA, ziformula=~ CAP * Time, family=poisson)

Model 3.  Time as continuous, with the dispersion parameter identical for each observation:
zipoisson <- glmmTMB(Observations ~ CAP + (ID|Time), data=mDATA, ziformula=~ 1, family=poisson)


It calls my attention that models 1 and 2 yield the same results. In this way, I wonder whether I did model time properly. Maybe I should introduce the levels of "Time" differently?

current arranging of time data:
Time
  m1
  m2
  m3

Alternative option?
TIme
   1
   2
   3


I thank you in advance for any comment in this regard.

Best regards,


Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Tue Jul 16 22:34:56 2019
From: d@|uedecke @end|ng |rom uke@de (=?UTF-8?Q?Daniel_L=C3=BCdecke?=)
Date: Tue, 16 Jul 2019 22:34:56 +0200
Subject: [R-sig-ME] About modelling time as continuous variable in a
 glmmTMB-based model.
In-Reply-To: <badb7f3f87dc4fa58934dca016c2a30e@unige.ch>
References: <badb7f3f87dc4fa58934dca016c2a30e@unige.ch>
Message-ID: <CANiAikFpgUFJLzxtSJjMUJKss3929_Kp7yF4jCaS3UjUGAK1zA@mail.gmail.com>

Dear Julian,
typically, time varies across groups, so you should model time as random
slope (i.e. switch time and ID in the random effects):

glmmTMB(Observations ~ CAP * Time + (Time | ID), data=mDATA, ziformula=~
CAP * Time, family=poisson)

Best
Daniel


Julian Gaviria Lopez <Julian.GaviriaLopez at unige.ch> schrieb am Di., 16.
Juli 2019, 17:25:

> Dear lists members,
>
> Based on the glmmTMB-based model:
>
> Model 1. Time as a fixed factor:
> zipoisson <- glmmTMB(Observations ~ CAP * Time + (1|ID), data=mDATA,
> ziformula=~ CAP * Time , family=poisson)
>
> A gentle member from this list suggested me to treat time as continuous.
> Since I am new with mixed models, I would like to confirm that the new
> models for this aim are right:
>
> Model 2. Time as continuous variable:
> zipoisson <- glmmTMB(Observations ~ CAP * Time + (ID|Time), data=mDATA,
> ziformula=~ CAP * Time, family=poisson)
>
> Model 3.  Time as continuous, with the dispersion parameter identical for
> each observation:
> zipoisson <- glmmTMB(Observations ~ CAP + (ID|Time), data=mDATA,
> ziformula=~ 1, family=poisson)
>
>
> It calls my attention that models 1 and 2 yield the same results. In this
> way, I wonder whether I did model time properly. Maybe I should introduce
> the levels of "Time" differently?
>
> current arranging of time data:
> Time
>   m1
>   m2
>   m3
>
> Alternative option?
> TIme
>    1
>    2
>    3
>
>
> I thank you in advance for any comment in this regard.
>
> Best regards,
>
>
> Julian Gaviria
> Neurology and Imaging of cognition lab (Labnic)
> University of Geneva. Campus Biotech.
> 9 Chemin des Mines, 1202 Geneva, CH
> Tel: +41 22 379 0380
> Email: Julian.GaviriaLopez at unige.ch
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jul 17 09:46:16 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 17 Jul 2019 09:46:16 +0200
Subject: [R-sig-ME] 
 Negative binomial GLMM model/variables selection based
 in marginal R2 and conditional R2
In-Reply-To: <f896ed95-0023-a990-7031-e02ee507f500@yahoo.com.br>
References: <f896ed95-0023-a990-7031-e02ee507f500@yahoo.com.br>
Message-ID: <CAJuCY5xCpnhEp6L3DuDut0jPc_nay-rtMvtMq-ggrzo_Z3rYjA@mail.gmail.com>

Dear Alexandre,

IMHO the full model of your analysis should be based upon the design of
your study, not on any goodness-of-fit measurement. Having said that, both
random effects variables have only 4 levels. That is too few to get a
descent variance estimation. I'd recommend to consider both as fixed
effects.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 11 jul. 2019 om 23:47 schreef ASANTOS <alexandresantosbr at yahoo.com.br
>:

> Dear R-Mixed-Models Members,
>
>  ?????? ?????? I've like to chose my negative binomial GLMM better
> model/variables based in marginal R2 (variance explained by the fixed
> factor(s)) and conditional R2 (variance explained by both the fixed and
> random factors), but some times I have a great dissimilarities in this
> values, if I have gain in the conditional R2, my marginal R2 is poor and
> vice-versa (I make a little exercise by changes in the position on fixed
> and random effects in the models). In my example:
>
> *A) Model 1 - Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat) - balance
> values between marginal and conditional R2*
>
> R2m R2c
>
> delta 0.4282151 0.5203953
>
> lognormal 0.5090799 0.6186677
>
> trigamma 0.3153259 0.3832049
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>
> Family: Negative Binomial(0.9207)?? ( log )
>
> Formula: Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat)
>
>  ???? Data: d3
>
>  ???????? AIC?????????? BIC???? logLik deviance df.resid
>
>  ????4500.6???? 4521.9?? -2245.3???? 4490.6?????????? 519
>
> Scaled residuals:
>
> Min?????????? 1Q?? Median?????????? 3Q???????? Max
>
> -0.9413 -0.7254 -0.4113?? 0.5294?? 7.2853
>
> Random effects:
>
> Groups Name?????????????? Variance Std.Dev.
>
> Trat???? (Intercept) 0.2176 ????0.4664
>
> Number of obs: 524, groups:?? Trat, 4
>
> Fixed effects:
>
>  ?????????????????????????? Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)?? 0.2847245?? 0.2913635???? 0.977 0.328
>
> Inf_YST???????? -0.0016482?? 0.0003483?? -4.732 2.22e-06 ***
>
> Age_months???? 0.3144764?? 0.0183616?? 17.127?? < 2e-16 ***
>
> ---
>
> Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
> ??? ??? 1
>
> Correlation of Fixed Effects:
>
>  ???????????????????? (Intr) In_YST
>
> Inf_YST???????? 0.171
>
> Age_months -0.558 -0.532
>
> convergence code: 0
>
> Model failed to converge with max|grad| = 0.00631137 (tol = 0.001,
> component 1)
>
> Model is nearly unidentifiable: very large eigenvalue
>
> - Rescale variables?
>
> Model is nearly unidentifiable: large eigenvalue ratio
>
> - Rescale variables?
>
>
> *B) Model 2 -?? Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months) - a better
> conditional but poor marginal R2*
>
> R2m R2c
>
> delta???????? 0.1626844 0.7257397
>
> lognormal 0.1725712 0.7698453
>
> trigamma?? 0.1489258 0.6643626
>
>
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>
> Family: Negative Binomial(1.8431)?? ( log )
>
> Formula: Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months)
>
>  ???? Data: d3
>
>  ???????? AIC?????????? BIC logLik deviance df.resid
>
>  ????4121.5???? 4151.4 -2053.8???? 4107.5?????????? 517
>
> Scaled residuals:
>
> Min?????????? 1Q?? Median?????????? 3Q???????? Max
>
> -1.2776 -0.6703 -0.1486?? 0.3279?? 5.4019
>
> Random effects:
>
> Groups Name?????????????? Variance Std.Dev.
>
> Age_months (Intercept) 1.172?????? 1.083
>
> Number of obs: 524, groups:?? Age_months, 4
>
> Fixed effects:
>
> Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)???????????????? 3.4859551 0.5492043???? 6.347 2.19e-10 ***
>
> Inf_YST???????????????????????? 0.0005702 0.0002864???? 1.991???? 0.0465 *
>
> TratC1-Insecticide -1.1081610 0.1012478 -10.945?? < 2e-16 ***
>
> TratC2-Control???????? -0.7859302 0.1058146?? -7.427 1.11e-13 ***
>
> TratC2-Insecticide -1.3833545 0.1041882 -13.277?? < 2e-16 ***
>
> ---
>
> Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
> ??? ??? 1
>
> Correlation of Fixed Effects:
>
>  ?????????????????????? (Intr) In_YST TrC1-I TrC2-C
>
> Inf_YST???????? -0.122
>
> TrtC1-Insct -0.103 0.189
>
> TrtC2-Cntrl -0.104 0.265?? 0.436
>
> TrtC2-Insct -0.097 0.221?? 0.424?? 0.504
>
> convergence code: 0
>
> Model failed to converge with max|grad| = 0.00398879 (tol = 0.001,
> component 1)
>
> Model is nearly unidentifiable: very large eigenvalue
>
> - Rescale variables?
>
> Model is nearly unidentifiable: large eigenvalue ratio
>
> - Rescale variables?
>
>
> And my questions are:
>
> 1) Marginal R2 is a good metric for identify a bad fixed effect choose
> in my models B? Despite a better conditional R2 comparing of conditional
> R2 in my model A.
>
> 2) If I'm sure about my fixed and random effects, it is better a final
> model with high values in both R2 or I choose based in the high value in
> conditional R2?
>
>
> Thanks in advanced,
>
>
> Alexandre
>
>
> --
> ======================================================================
> Alexandre dos Santos
> Prote????o Florestal
> IFMT - Instituto Federal de Educa????o, Ci??ncia e Tecnologia de Mato
> Grosso
> Campus C??ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C??ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>
>          alexandre.santos at cas.ifmt.edu.br
> Lattes: http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate: www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> ======================================================================
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Wed Jul 17 11:17:33 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Wed, 17 Jul 2019 09:17:33 +0000
Subject: [R-sig-ME] About modelling time as continuous variable in a
 glmmTMB-based model.
In-Reply-To: <CANiAikFpgUFJLzxtSJjMUJKss3929_Kp7yF4jCaS3UjUGAK1zA@mail.gmail.com>
References: <badb7f3f87dc4fa58934dca016c2a30e@unige.ch>,
 <CANiAikFpgUFJLzxtSJjMUJKss3929_Kp7yF4jCaS3UjUGAK1zA@mail.gmail.com>
Message-ID: <d16dad7796ab42aebb7fc94458efb4c0@unige.ch>

Dear Daniel,


Thank you so much for your message. Maybe a brief contextualization might provide a clearer idea about my aims :


Conext:
Data from  50 individuals (ID) encompass 4 brain components (CAP) collected during 2 different conditions. Each condition lasted 5 minutes (split in 1-minute bins: m1, m2, ,m3, m4, m5). The data is arranged like this:

ID
Observations
  CAP
Time
1               3          C1    m1
1               0          C1    m2
1               2          C1    m3
1               0          C1    m4
1               1          C1    m5
?       ?       ?       ?
50              0          C1    m1
?       ?       ?        ?


                 50                                           0              C4       m5
Aim:
Based on the analysis of variance, I aim to find statistical interactions among the CAPs over time (m1... m5). Simultaneously, I want to identify whether any CAP is a better predictor of such variance, for a specific condition. For this reason, I opted for modelling the conditions in two different models.

Model:
zipoisson <- glmmTMB(Observations ~ CAP * Time + (1 | ID), data= mDATA, ziformula=~ CAP * Time , family=poisson)

According to my aims, I do not think that time should be modeled as random slope, but I really would like to hear you opinion (or the one from any other kind expert from the list) after understanding the context of my question.

P.D.  I did run the model as  random slope, such as you suggested, and I deleted the "m" from the "Time" variable,
zipoisson <- glmmTMB(Observations ~ CAP * Time + (Time | ID), data= mDATA, ziformula=~ CAP * Time, family=poisson)

Strikingly, the model did not converge for one of the conditions.


Thanks in advance and best regards.

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch
________________________________
From: Daniel L?decke <d.luedecke at uke.de>
Sent: Tuesday, July 16, 2019 10:34:56 PM
To: Julian Gaviria Lopez
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] About modelling time as continuous variable in a glmmTMB-based model.

Dear Julian,
typically, time varies across groups, so you should model time as random slope (i.e. switch time and ID in the random effects):

glmmTMB(Observations ~ CAP * Time + (Time | ID), data=mDATA, ziformula=~ CAP * Time, family=poisson)

Best
Daniel


Julian Gaviria Lopez <Julian.GaviriaLopez at unige.ch<mailto:Julian.GaviriaLopez at unige.ch>> schrieb am Di., 16. Juli 2019, 17:25:
Dear lists members,

Based on the glmmTMB-based model:

Model 1. Time as a fixed factor:
zipoisson <- glmmTMB(Observations ~ CAP * Time + (1|ID), data=mDATA, ziformula=~ CAP * Time , family=poisson)

A gentle member from this list suggested me to treat time as continuous.  Since I am new with mixed models, I would like to confirm that the new models for this aim are right:

Model 2. Time as continuous variable:
zipoisson <- glmmTMB(Observations ~ CAP * Time + (ID|Time), data=mDATA, ziformula=~ CAP * Time, family=poisson)

Model 3.  Time as continuous, with the dispersion parameter identical for each observation:
zipoisson <- glmmTMB(Observations ~ CAP + (ID|Time), data=mDATA, ziformula=~ 1, family=poisson)


It calls my attention that models 1 and 2 yield the same results. In this way, I wonder whether I did model time properly. Maybe I should introduce the levels of "Time" differently?

current arranging of time data:
Time
  m1
  m2
  m3

Alternative option?
TIme
   1
   2
   3


I thank you in advance for any comment in this regard.

Best regards,


Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch<mailto:Julian.GaviriaLopez at unige.ch>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de<http://www.uke.de/>
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel

________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From m|ck@wu @end|ng |rom m@||@mcg|||@c@  Wed Jul 17 15:46:04 2019
From: m|ck@wu @end|ng |rom m@||@mcg|||@c@ (Gi-Mick Wu)
Date: Wed, 17 Jul 2019 13:46:04 +0000
Subject: [R-sig-ME] 
 mgcv gam/bam model selection with random effects and AR terms
Message-ID: <B4C0A688-8A46-4360-8FB5-4DD8F1AAA975@mail.mcgill.ca>

Dear Mathew,

I was looking for information on model selection for a bam model with an autocorrelation structure and essentially only found your unanswered post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q2/025566.html).

May I ask if you found any solution for this?

Best,
Mick


	[[alternative HTML version deleted]]


From beckm089 @end|ng |rom umn@edu  Wed Jul 17 17:28:13 2019
From: beckm089 @end|ng |rom umn@edu (Noelle G. Beckman)
Date: Wed, 17 Jul 2019 09:28:13 -0600
Subject: [R-sig-ME] 
 Negative binomial GLMM model/variables selection based
 in marginal R2 and conditional R2
In-Reply-To: <CAJuCY5xCpnhEp6L3DuDut0jPc_nay-rtMvtMq-ggrzo_Z3rYjA@mail.gmail.com>
References: <f896ed95-0023-a990-7031-e02ee507f500@yahoo.com.br>
 <CAJuCY5xCpnhEp6L3DuDut0jPc_nay-rtMvtMq-ggrzo_Z3rYjA@mail.gmail.com>
Message-ID: <69766FF9-AB5D-4EE1-BD74-82D55A533869@umn.edu>

I am currently out of the office until July 5th. I will respond to your email upon my return.

On Jul 17, 2019, at 1:46 AM, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Dear Alexandre,
> 
> IMHO the full model of your analysis should be based upon the design of
> your study, not on any goodness-of-fit measurement. Having said that, both
> random effects variables have only 4 levels. That is too few to get a
> descent variance estimation. I'd recommend to consider both as fixed
> effects.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op do 11 jul. 2019 om 23:47 schreef ASANTOS <alexandresantosbr at yahoo.com.br
> :
> 
> Dear R-Mixed-Models Members,
> 
> ?????? ?????? I've like to chose my negative binomial GLMM better
> model/variables based in marginal R2 (variance explained by the fixed
> factor(s)) and conditional R2 (variance explained by both the fixed and
> random factors), but some times I have a great dissimilarities in this
> values, if I have gain in the conditional R2, my marginal R2 is poor and
> vice-versa (I make a little exercise by changes in the position on fixed
> and random effects in the models). In my example:
> 
> *A) Model 1 - Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat) - balance
> values between marginal and conditional R2*
> 
> R2m R2c
> 
> delta 0.4282151 0.5203953
> 
> lognormal 0.5090799 0.6186677
> 
> trigamma 0.3153259 0.3832049
> 
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> 
> Family: Negative Binomial(0.9207)?? ( log )
> 
> Formula: Inf_Leaves ~ Inf_YST + Age_months + (1 | Trat)
> 
> ???? Data: d3
> 
> ???????? AIC?????????? BIC???? logLik deviance df.resid
> 
> ????4500.6???? 4521.9?? -2245.3???? 4490.6?????????? 519
> 
> Scaled residuals:
> 
> Min?????????? 1Q?? Median?????????? 3Q???????? Max
> 
> -0.9413 -0.7254 -0.4113?? 0.5294?? 7.2853
> 
> Random effects:
> 
> Groups Name?????????????? Variance Std.Dev.
> 
> Trat???? (Intercept) 0.2176 ????0.4664
> 
> Number of obs: 524, groups:?? Trat, 4
> 
> Fixed effects:
> 
> ?????????????????????????? Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)?? 0.2847245?? 0.2913635???? 0.977 0.328
> 
> Inf_YST???????? -0.0016482?? 0.0003483?? -4.732 2.22e-06 ***
> 
> Age_months???? 0.3144764?? 0.0183616?? 17.127?? < 2e-16 ***
> 
> ---
> 
> Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
> ??? ??? 1
> 
> Correlation of Fixed Effects:
> 
> ???????????????????? (Intr) In_YST
> 
> Inf_YST???????? 0.171
> 
> Age_months -0.558 -0.532
> 
> convergence code: 0
> 
> Model failed to converge with max|grad| = 0.00631137 (tol = 0.001,
> component 1)
> 
> Model is nearly unidentifiable: very large eigenvalue
> 
> - Rescale variables?
> 
> Model is nearly unidentifiable: large eigenvalue ratio
> 
> - Rescale variables?
> 
> 
> *B) Model 2 -?? Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months) - a better
> conditional but poor marginal R2*
> 
> R2m R2c
> 
> delta???????? 0.1626844 0.7257397
> 
> lognormal 0.1725712 0.7698453
> 
> trigamma?? 0.1489258 0.6643626
> 
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> 
> Family: Negative Binomial(1.8431)?? ( log )
> 
> Formula: Inf_Leaves ~ Inf_YST + Trat + (1 | Age_months)
> 
> ???? Data: d3
> 
> ???????? AIC?????????? BIC logLik deviance df.resid
> 
> ????4121.5???? 4151.4 -2053.8???? 4107.5?????????? 517
> 
> Scaled residuals:
> 
> Min?????????? 1Q?? Median?????????? 3Q???????? Max
> 
> -1.2776 -0.6703 -0.1486?? 0.3279?? 5.4019
> 
> Random effects:
> 
> Groups Name?????????????? Variance Std.Dev.
> 
> Age_months (Intercept) 1.172?????? 1.083
> 
> Number of obs: 524, groups:?? Age_months, 4
> 
> Fixed effects:
> 
> Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)???????????????? 3.4859551 0.5492043???? 6.347 2.19e-10 ***
> 
> Inf_YST???????????????????????? 0.0005702 0.0002864???? 1.991???? 0.0465 *
> 
> TratC1-Insecticide -1.1081610 0.1012478 -10.945?? < 2e-16 ***
> 
> TratC2-Control???????? -0.7859302 0.1058146?? -7.427 1.11e-13 ***
> 
> TratC2-Insecticide -1.3833545 0.1041882 -13.277?? < 2e-16 ***
> 
> ---
> 
> Signif. codes:?? 0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
> ??? ??? 1
> 
> Correlation of Fixed Effects:
> 
> ?????????????????????? (Intr) In_YST TrC1-I TrC2-C
> 
> Inf_YST???????? -0.122
> 
> TrtC1-Insct -0.103 0.189
> 
> TrtC2-Cntrl -0.104 0.265?? 0.436
> 
> TrtC2-Insct -0.097 0.221?? 0.424?? 0.504
> 
> convergence code: 0
> 
> Model failed to converge with max|grad| = 0.00398879 (tol = 0.001,
> component 1)
> 
> Model is nearly unidentifiable: very large eigenvalue
> 
> - Rescale variables?
> 
> Model is nearly unidentifiable: large eigenvalue ratio
> 
> - Rescale variables?
> 
> 
> And my questions are:
> 
> 1) Marginal R2 is a good metric for identify a bad fixed effect choose
> in my models B? Despite a better conditional R2 comparing of conditional
> R2 in my model A.
> 
> 2) If I'm sure about my fixed and random effects, it is better a final
> model with high values in both R2 or I choose based in the high value in
> conditional R2?
> 
> 
> Thanks in advanced,
> 
> 
> Alexandre
> 
> 
> --
> ======================================================================
> Alexandre dos Santos
> Prote????o Florestal
> IFMT - Instituto Federal de Educa????o, Ci??ncia e Tecnologia de Mato
> Grosso
> Campus C??ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C??ceres - MT ?????????????????????CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
> 
> ????????alexandre.santos at cas.ifmt.edu.br
> Lattes: http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate: www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> ======================================================================
> 
> 
> ???????[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative text/enriched version deleted]]


From g@ry@ne|@on @end|ng |rom @t@te@m@@u@  Wed Jul 17 18:54:29 2019
From: g@ry@ne|@on @end|ng |rom @t@te@m@@u@ (Nelson, Gary (FWE ))
Date: Wed, 17 Jul 2019 16:54:29 +0000
Subject: [R-sig-ME] Question concerning nlme
Message-ID: <bd084d8969c147d49ce75c2b7ef0d974@ES-SDC-EMR-03.es.govt.state.ma.us>

I work in the field of fisheries. We sample fish using gears that collect individual in clusters, so any analyses done using such sample have to be corrected for intra-cluster correlation.  This has been shown in many papers in my field.

I am trying to compare growth curves between two sexes using the nlme function. The individuals were collected via cluster sampling.  I have been trying to use the nlme function but am having trouble understanding how to specify the correct formulation.

My growth model is:

vonBert<-deriv(~Linf*(1-exp(-K*(x-t0))),c("Linf","K","t0"),function(x,Linf,K,t0){})

and I created grouped data with cluster as the grouping variable

vbdata<-groupedData(lens~age|cluster,data=catchdata,labels=list(x="age",y="length"))

and the mixed model I have is

vbfull<--nlme(lens~vonBert(age,Linf,K,t0),data=vbdata,fixed=list(Linf~1,K~1,t0~1),random=Linf+K+t0~1,start=c(Linf=c(270),
K=c(0.7),t0=c(0.1)),control=nlmeControl(maxIter=100000,msMaxIter=100000))

My question is how do I incorporate sexes?  I've tried assuming sex is nested within a cluster where
vbdata<-groupedData(lens~age|cluster/sex,data=catchdata,labels=list(x="age",y="length")) but am unsure if this is correct.

Any help would be appreciated.

<>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <><
Gary A. Nelson, Ph. D
Massachusetts Division of Marine Fisheries
Annisquam River Field Station
30 Emerson Avenue
Gloucester, MA 01930
email: gary.nelson @state.ma.us
phone: 978-282-0308 x114


	[[alternative HTML version deleted]]


From @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com  Wed Jul 17 19:15:39 2019
From: @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com (=?UTF-8?Q?Andr=C3=A9_Pardal?=)
Date: Wed, 17 Jul 2019 18:15:39 +0100
Subject: [R-sig-ME] Spatial correlation in glmmTMB
Message-ID: <CAFxBq7xPkguf9KfU_4dcyU2ULyWgKD0wQcN8b1gW_ZhJCjJr3A@mail.gmail.com>

Hello,

I would like to ask for help on how to account for spatial correlation in
glmmTMB package.

According to the help page (
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html),
I need to create a numFactor object grouping coordinates and a dummy
grouping factor.

mydata$pos <- numFactor(mydata$easting, mydata$northing)## spatial
coordinates
mydata$group <- factor(rep(1, nrow(mydata)))## dummy factor

Regarding to the dummy variable, I have 62 locations in my dataframe. The
dummy variable should be 1 for all observations, or go from 1 to 62?
(Actually I have tried both possibilities. First one give me convergence
problems, second one cracks my R).

I have been trying to run the following negative binomial mixed model:

m1 = glmmTMB(density ~ wave_exposure + (1|location) exp(pos + 0|group),
data= mydata, family= nbinom1, ziformula= ~0) ##

I also tried different covariance structures (gau and mat), but no success
so far.

Any ideas or suggestions here?

Thank you in advance!

Andre.

-- 
Visiting PhD student
School of Ocean Sciences
Bangor University
Menai Bridge, Anglesey, UK

	[[alternative HTML version deleted]]


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Wed Jul 17 19:27:44 2019
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Wed, 17 Jul 2019 19:27:44 +0200
Subject: [R-sig-ME] Question concerning nlme
In-Reply-To: <bd084d8969c147d49ce75c2b7ef0d974@ES-SDC-EMR-03.es.govt.state.ma.us>
References: <bd084d8969c147d49ce75c2b7ef0d974@ES-SDC-EMR-03.es.govt.state.ma.us>
Message-ID: <20190717172743.GD8709@info124.pharmacie.univ-paris5.fr>

According to the nlme documentation, fitting different K parameters
for sexes (for instance) should be something like

md <- nlme( lens ~ vonBert( age, Linf, K, t0 ),
            data = vbdata,
	    fixed = list( Linf ~ 1,
	                  K ~ Sexe, # Different mean value
			  t0 ~ 1),
	    random = list( Linf ~ 1,
	                   K ~ Sexe, # Different variance
			   t0 ~ 1 ),
            start = c( Linf = c( 270 ),
	               K    = c( 0.7, 0.7 ),
		       t0   = c(0.1) ),
	    control = nlmeControl( maxIter=100000, msMaxIter=100000)
	  )

if you assume both different mean value (fixed) and variances of the
random effects (random).

Note that, not knowing the context, nesting sex in the cluster seems
strange to me, because if I interpret nesting correctly it would mean
that sex ? female ? or ? male ? means something different in different
clusters (that is, there would be not 2 sexes, but 2 times the number
of clusters different sexes for your fish)...

Hope this will help,

On Wed, Jul 17, 2019 at 04:54:29PM +0000, Nelson, Gary (FWE ) wrote:
? I work in the field of fisheries. We sample fish using gears that collect individual in clusters, so any analyses done using such sample have to be corrected for intra-cluster correlation.  This has been shown in many papers in my field.
? 
? I am trying to compare growth curves between two sexes using the nlme function. The individuals were collected via cluster sampling.  I have been trying to use the nlme function but am having trouble understanding how to specify the correct formulation.
? 
? My growth model is:
? 
? vonBert<-deriv(~Linf*(1-exp(-K*(x-t0))),c("Linf","K","t0"),function(x,Linf,K,t0){})
? 
? and I created grouped data with cluster as the grouping variable
? 
? vbdata<-groupedData(lens~age|cluster,data=catchdata,labels=list(x="age",y="length"))
? 
? and the mixed model I have is
? 
? vbfull<--nlme(lens~vonBert(age,Linf,K,t0),data=vbdata,fixed=list(Linf~1,K~1,t0~1),random=Linf+K+t0~1,start=c(Linf=c(270),
? K=c(0.7),t0=c(0.1)),control=nlmeControl(maxIter=100000,msMaxIter=100000))
? 
? My question is how do I incorporate sexes?  I've tried assuming sex is nested within a cluster where
? vbdata<-groupedData(lens~age|cluster/sex,data=catchdata,labels=list(x="age",y="length")) but am unsure if this is correct.
? 
? Any help would be appreciated.
? 
? <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <>< <><
? Gary A. Nelson, Ph. D
? Massachusetts Division of Marine Fisheries
? Annisquam River Field Station
? 30 Emerson Avenue
? Gloucester, MA 01930
? email: gary.nelson @state.ma.us
? phone: 978-282-0308 x114
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Thu Jul 18 12:33:13 2019
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Thu, 18 Jul 2019 11:33:13 +0100
Subject: [R-sig-ME] Spatial correlation in glmmTMB
In-Reply-To: <mailman.17703.7.1563444001.43692.r-sig-mixed-models@r-project.org>
References: <mailman.17703.7.1563444001.43692.r-sig-mixed-models@r-project.org>
Message-ID: <19fc8e8e-13fc-1303-ec6a-a2f990674ce4@highstat.com>

I suggest trying INLA.

http://www.r-inla.org/


I hope that you have more than 62 observations in total?

Kind regards,

Alain

---------------------------------


Hello,

I would like to ask for help on how to account for spatial correlation in
glmmTMB package.

According to the help page (
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html),
I need to create a numFactor object grouping coordinates and a dummy
grouping factor.

mydata$pos <- numFactor(mydata$easting, mydata$northing)## spatial
coordinates
mydata$group <- factor(rep(1, nrow(mydata)))## dummy factor

Regarding to the dummy variable, I have 62 locations in my dataframe. The
dummy variable should be 1 for all observations, or go from 1 to 62?
(Actually I have tried both possibilities. First one give me convergence
problems, second one cracks my R).

I have been trying to run the following negative binomial mixed model:

m1 = glmmTMB(density ~ wave_exposure + (1|location) exp(pos + 0|group),
data= mydata, family= nbinom1, ziformula= ~0) ##

I also tried different covariance structures (gau and mat), but no success
so far.

Any ideas or suggestions here?

Thank you in advance!

Andre.

-- 
Visiting PhD student
School of Ocean Sciences
Bangor University
Menai Bridge, Anglesey, UK

	[[alternative HTML version deleted]]



***************************************************

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From bbo|ker @end|ng |rom gm@||@com  Thu Jul 18 16:07:32 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 18 Jul 2019 10:07:32 -0400
Subject: [R-sig-ME] Spatial correlation in glmmTMB
In-Reply-To: <19fc8e8e-13fc-1303-ec6a-a2f990674ce4@highstat.com>
References: <mailman.17703.7.1563444001.43692.r-sig-mixed-models@r-project.org>
 <19fc8e8e-13fc-1303-ec6a-a2f990674ce4@highstat.com>
Message-ID: <e21fb275-04b7-e845-3221-7d630b85985d@gmail.com>


  For glmmTMB, if your locations aren't otherwise grouped (e.g. into
distinct sites), then you should use factor(rep(1,62)).  As Alan Zuur
suggests, 62 might be a fairly small sample for estimating spatial
autocorrelation.  If you give us more information about your model (e.g.
post the results of summary(), it might help us diagnose and/or fix your
convergence problems ...

  The mgcv package will also let you fit negative binomial/spatial
models (with a Mat?rn structure, see ?smooth.construct.gp.smooth.spec;
for the random effect, see ?smooth.construct.re.smooth.spec).

On 2019-07-18 6:33 a.m., Highland Statistics Ltd wrote:
> I suggest trying INLA.
> 
> http://www.r-inla.org/
> 
> 
> I hope that you have more than 62 observations in total?
> 
> Kind regards,
> 
> Alain
> 
> ---------------------------------
> 
> 
> Hello,
> 
> I would like to ask for help on how to account for spatial correlation in
> glmmTMB package.
> 
> According to the help page (
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html),
> I need to create a numFactor object grouping coordinates and a dummy
> grouping factor.
> 
> mydata$pos <- numFactor(mydata$easting, mydata$northing)## spatial
> coordinates
> mydata$group <- factor(rep(1, nrow(mydata)))## dummy factor
> 
> Regarding to the dummy variable, I have 62 locations in my dataframe. The
> dummy variable should be 1 for all observations, or go from 1 to 62?
> (Actually I have tried both possibilities. First one give me convergence
> problems, second one cracks my R).
> 
> I have been trying to run the following negative binomial mixed model:
> 
> m1 = glmmTMB(density ~ wave_exposure + (1|location) exp(pos + 0|group),
> data= mydata, family= nbinom1, ziformula= ~0) ##
> 
> I also tried different covariance structures (gau and mat), but no success
> so far.
> 
> Any ideas or suggestions here?
> 
> Thank you in advance!
> 
> Andre.
>


From bbo|ker @end|ng |rom gm@||@com  Thu Jul 18 17:07:27 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 18 Jul 2019 11:07:27 -0400
Subject: [R-sig-ME] 
 mgcv gam/bam model selection with random effects and AR terms
In-Reply-To: <B4C0A688-8A46-4360-8FB5-4DD8F1AAA975@mail.mcgill.ca>
References: <B4C0A688-8A46-4360-8FB5-4DD8F1AAA975@mail.mcgill.ca>
Message-ID: <f5f20123-6be1-b1e2-efb3-46d9388ecfcd@gmail.com>


   I'm not sure of the answer, but in general I'd say if you're
interested in out-of-sample predictive accuracy, you should try to find
something analogous to AIC.  R^2/deviance only tell you how well your
model fits to a specific set of data ...

On 2019-07-17 9:46 a.m., Gi-Mick Wu wrote:
> Dear Mathew,
> 
> I was looking for information on model selection for a bam model with an autocorrelation structure and essentially only found your unanswered post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q2/025566.html).
> 
> May I ask if you found any solution for this?
> 
> Best,
> Mick
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From t|m@co|e @end|ng |rom uc|@@c@uk  Fri Jul 19 00:35:42 2019
From: t|m@co|e @end|ng |rom uc|@@c@uk (Cole, Tim)
Date: Thu, 18 Jul 2019 22:35:42 +0000
Subject: [R-sig-ME] sitar and p=splines
Message-ID: <66EA8DC3-8050-42C5-B4AA-26E5B78B83FE@ucl.ac.uk>

Hi,

My sitar mixed model package fits a natural spline mean curve to growth data, with three subject random effects reflecting random intercept (size), random time intercept (timing) and random time scaling (intensity).

I?m keen to modify the code to fit a penalised or p-spline rather than a b-spline, by including a smoother random effect, but I?m struggling to get the notation right.

Here is code to fit the sitar model using nlme with a b-spline (ns) smoother:

# first create data frame with centred x = age, y = height, id = id
 # install.packages('sitar')
 library(sitar)
  data <- setNames(heights[, 1:3], c('id', 'x', 'y'))
  data$x <- drop(scale(data$x, scale=FALSE))

# fit sitar model with 4 df
  { df <- 4
    knots <- with(data, quantile(x, (1:(df - 1)) / df))
    bounds <- with(data, range(x) + 0.04 * c(-1, 1) * diff(range(x)))
    mat <- matrix(rep(1, df), ncol = 1)
    start <- lm(y ~ splines::ns(x, knots = knots, Bound = bounds), data=data)
    start <- c(coef(start)[c(2:(df + 1), 1)], 0, 0)
    ey <- function(x,s1,s2,s3,s4,a,b,c) {
      x <- (x - b) * exp(c)     # subject-specific location and scale for x
      a + drop((cbind(s1,s2,s3,s4) * splines::ns(x,k=knots,B=bounds))%*%mat)
    }
    sitar1 <- nlme(y ~ ey(x,s1,s2,s3,s4,a,b,c),
         fixed = s1+s2+s3+s4+a+b+c ~ 1,
         random = a+b+c ~ 1 | id,                       ######## random term 1
         data = data, start = start)
  }

  # can fit the same sitar model using sitar package
  sitar2 <- sitar(x, y, id, data, 4)
  all.equal(sitar1, sitar2) # similar though not identical

  # now fit a single p-spline curve to the data using a random effect smoother
  # three p-spline functions from Paul Eilers

  tpower <- function(x, t, p)
    # Truncated p-th power function
    (x - t) ^ p * (x > t)

  bbase <- function(x, xl = min(x), xr = max(x), nseg = 10, deg = 3) {
    # Construct B-spline basis
    dx <- (xr - xl) / nseg
    knots <- seq(xl - deg * dx, xr + deg * dx, by = dx)
    P <- outer(x, knots, tpower, deg)
    n <- dim(P)[2]
    D <- diff(diag(n), diff = deg + 1) / (gamma(deg + 1) * dx ^ deg)
    B <- (-1) ^ (deg + 1) * P %*% t(D)
    B }

  makeZ <- function(x, xl = min(x), xr = max(x), nseg = 10) {
  # Construct smoothing random effect
    B <- bbase(x, xl, xr, nseg)
    D <- diff(diag(ncol(B)), diff = 2)
    Q <- solve(D %*% t(D), D)
    Z <- B %*% t(Q)
    Z
  }

  # creat a one group factor
  data$one <- 1

  # fit p-spline to group one with smoother random effect
  lm1 <- lme(y ~ x, random = list(one = pdIdent(~makeZ(x) - 1)), data = data)      ###### random term 2

  # plot the smooth mean curve for lm1 as points
  with(data, plot(x, fitted(lm1)))
  # and compare with sitar mean curve
  lines(sitar2, 'd', col=2)
  # rather different in shape as sitar adjusts for subject timing and intensity


The key question is how to combine the two approaches, i.e. to include the smooth random effect in sitar by combining these random terms:
  # random = list(one = pdIdent(~makeZ(x) - 1))
  # random = a+b+c ~ 1 | id
They obviously need to be a list, but the correct notation is not obvious.

A second key question is whether the random effect smoother makeZ(x) needs to be updated during the fit, as it depends on x, b and c which are being updated within ey. If it does I don?t think it can be done in nlme.

I?d value people?s thoughts.

Best wishes,
Tim
--
Population Policy and Practice
UCL Great Ormond Street Institute of Child Health,
30 Guilford Street, London WC1N 1EH, UK


	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Jul 20 08:19:55 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 20 Jul 2019 08:19:55 +0200
Subject: [R-sig-ME] 
 mgcv gam/bam model selection with random effects and AR terms
In-Reply-To: <f5f20123-6be1-b1e2-efb3-46d9388ecfcd@gmail.com>
References: <B4C0A688-8A46-4360-8FB5-4DD8F1AAA975@mail.mcgill.ca>
 <f5f20123-6be1-b1e2-efb3-46d9388ecfcd@gmail.com>
Message-ID: <61A81C2B-7347-4953-8500-982AE370B43F@yahoo.fr>

Hi,
According to Kneib & Greven (biometrika 2010)

? the corrected version of the conditional AIC was developed exactly with the goal of allowing for sensible model selection in mixed models. For the marginal AIC we did not find a proper correction, so we would in general not recommend this in its current form. ?

? We have recently developed an R package called cAIC4 (https://cran.r-project.org/web/packages/cAIC4/index.html) that should be a good starting point (also beyond Gaussian mixed effects models). ?

Best
Sacha Varin

Envoy? de mon iPhone

> Le 18 juil. 2019 ? 17:07, Ben Bolker <bbolker at gmail.com> a ?crit :
> 
> 
>   I'm not sure of the answer, but in general I'd say if you're
> interested in out-of-sample predictive accuracy, you should try to find
> something analogous to AIC.  R^2/deviance only tell you how well your
> model fits to a specific set of data ...
> 
>> On 2019-07-17 9:46 a.m., Gi-Mick Wu wrote:
>> Dear Mathew,
>> 
>> I was looking for information on model selection for a bam model with an autocorrelation structure and essentially only found your unanswered post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q2/025566.html).
>> 
>> May I ask if you found any solution for this?
>> 
>> Best,
>> Mick
>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From beckm089 @end|ng |rom umn@edu  Sat Jul 20 17:14:25 2019
From: beckm089 @end|ng |rom umn@edu (Noelle G. Beckman)
Date: Sat, 20 Jul 2019 09:14:25 -0600
Subject: [R-sig-ME] 
 mgcv gam/bam model selection with random effects and AR terms
In-Reply-To: <61A81C2B-7347-4953-8500-982AE370B43F@yahoo.fr>
References: <B4C0A688-8A46-4360-8FB5-4DD8F1AAA975@mail.mcgill.ca>
 <f5f20123-6be1-b1e2-efb3-46d9388ecfcd@gmail.com>
 <61A81C2B-7347-4953-8500-982AE370B43F@yahoo.fr>
Message-ID: <9D619CC1-54D7-4BC7-B9D6-086CC1CD8E46@umn.edu>

I am currently out of the office until July 5th. I will respond to your email upon my return.

On Jul 20, 2019, at 12:19 AM, varin sacha via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

> Hi,
> According to Kneib & Greven (biometrika 2010)
> 
> ? the corrected version of the conditional AIC was developed exactly with the goal of allowing for sensible model selection in mixed models. For the marginal AIC we did not find a proper correction, so we would in general not recommend this in its current form. ?
> 
> ? We have recently developed an R package called cAIC4 (https://cran.r-project.org/web/packages/cAIC4/index.html) that should be a good starting point (also beyond Gaussian mixed effects models). ?
> 
> Best
> Sacha Varin
> 
> Envoy? de mon iPhone
> 
> Le 18 juil. 2019 ? 17:07, Ben Bolker <bbolker at gmail.com> a ?crit :
> 
> 
> ?I'm not sure of the answer, but in general I'd say if you're
> interested in out-of-sample predictive accuracy, you should try to find
> something analogous to AIC. ?R^2/deviance only tell you how well your
> model fits to a specific set of data ...
> 
> On 2019-07-17 9:46 a.m., Gi-Mick Wu wrote:
> Dear Mathew,
> 
> I was looking for information on model selection for a bam model with an autocorrelation structure and essentially only found your unanswered post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q2/025566.html).
> 
> May I ask if you found any solution for this?
> 
> Best,
> Mick
> 
> 
> ??[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative text/enriched version deleted]]


From @r|ve046 @end|ng |rom uott@w@@c@  Wed Jul 17 22:44:52 2019
From: @r|ve046 @end|ng |rom uott@w@@c@ (Stephanie Rivest)
Date: Wed, 17 Jul 2019 13:44:52 -0700
Subject: [R-sig-ME] Scaling Issues
Message-ID: <CAAYeMWEoA47mEteVWUxxZB_qehWLqNvK86_CcTXbC5KFt-0agA@mail.gmail.com>

Hello,

My name is Stephanie Rivest and I've emailed this list in the past asking
questions about glmer models. I'm sorry if this is a repetitive question
that has perhaps been asked in the past, but I have not yet been able to
find an explanation on the web.

I'm using lme4 (glmer.nb) to fit a mixed effects model with the negative
binomial family. I have 173 data points, 8 independent parameters, and 1
random effect. My model is having difficulty converging and I think part of
the problem may be scaling (given the type of warnings that I get). I've
done some research on the subject and have found a couple links (
https://stackoverflow.com/questions/23478792/warning-messages-when-trying-to-run-glmer-in-r
 AND
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html)
discussing what to do. In these web links, B. Bolker suggests the following
code to centre and scale predictors...

B. Bolker's Code:

numcols <- grep("^c\\.",names(df))
dfs <- df
dfs[,numcols] <- scale(dfs[,numcols])
m4 <- update(m1,data=dfs)


My questions is, what is this code doing!? When I look at the new df, it
seems completely identical to the old df, like nothing has changed. And
yet, when I fit the model with the new df, the warnings mostly go away
suggesting that whatever I did seemed to work. I would really like to
understand what is actually going on in the code above. Have all columns
been changed? Or only certain ones? Have scales actually been changed? If
so, in what way? Do they need to be backtransformed in order for me to do
my model interpretation at the end?

Thank you so much for your time,
Stephanie

Stephanie Rivest
Ph.D. Candidate | Candidate au Doctorat
Dept. of Biology | D?p. de Biologie
University of Ottawa | Universit? d'Ottawa

	[[alternative HTML version deleted]]


From @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx  Sun Jul 21 18:17:11 2019
From: @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx (Salvador SANCHEZ COLON)
Date: Sun, 21 Jul 2019 09:17:11 -0700
Subject: [R-sig-ME] Scaling Issues
Message-ID: <HT306LW538U4.F6B7AIMWDKL02@mwweb13oc>

Hi Stephanie,


The base R function "scale" with default arguments (as in this case) first centers the columns in the df (substracting the column's mean from each entry) and then scales each of them by dividing them by its standard deviation.


I think the rest of the code is used only for getting the number of columns (numcols) in the df; assigning the scaled values to a new, updated df (dfs), etc.


I hope this helps. Best regards,


Salvador
?


En Dom, 21 Jul, 2019 en 10:38, Stephanie Rivest <srive046 at uottawa.ca> escribi?:
?

To: r-sig-mixed-models at r-project.org
Hello,

My name is Stephanie Rivest and I've emailed this list in the past asking
questions about glmer models. I'm sorry if this is a repetitive question
that has perhaps been asked in the past, but I have not yet been able to
find an explanation on the web.

I'm using lme4 (glmer.nb) to fit a mixed effects model with the negative
binomial family. I have 173 data points, 8 independent parameters, and 1
random effect. My model is having difficulty converging and I think part of
the problem may be scaling (given the type of warnings that I get). I've
done some research on the subject and have found a couple links (
https://stackoverflow.com/questions/23478792/warning-messages-when-trying-to-run-glmer-in-r
AND
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html)
discussing what to do. In these web links, B. Bolker suggests the following
code to centre and scale predictors...

B. Bolker's Code:

numcols <- grep("^c\\.",names(df))
dfs <- df
dfs[,numcols] <- scale(dfs[,numcols])
m4 <- update(m1,data=dfs)


My questions is, what is this code doing!? When I look at the new df, it
seems completely identical to the old df, like nothing has changed. And
yet, when I fit the model with the new df, the warnings mostly go away
suggesting that whatever I did seemed to work. I would really like to
understand what is actually going on in the code above. Have all columns
been changed? Or only certain ones? Have scales actually been changed? If
so, in what way? Do they need to be backtransformed in order for me to do
my model interpretation at the end?

Thank you so much for your time,
Stephanie

Stephanie Rivest
Ph.D. Candidate | Candidate au Doctorat
Dept. of Biology | D?p. de Biologie
University of Ottawa | Universit? d'Ottawa

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
.
 
	[[alternative HTML version deleted]]


From e||@@@mon@co @end|ng |rom un||r@ch  Mon Jul 22 13:17:22 2019
From: e||@@@mon@co @end|ng |rom un||r@ch (MONACO Elisa)
Date: Mon, 22 Jul 2019 11:17:22 +0000
Subject: [R-sig-ME] keeping both numerically and factor coded factors
Message-ID: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>

Dear list,
looking at the correlation values of my random effects, as well as the fact that my model fails to converge, it makes sense to me to simplify its random structure (while keeping maximal and according to our hp the fixed structure).
One way is to remove correlations, and I know that the || notation works only with numerically coded factors.
As far as I understood, I have two options:
1) use the package afex, putting my model as object of mixed and adding "expand_re=true"
2) use the original factor, by default read as "int"

I want to use the option 2) because with mixed I can't apply the PCA function for random effects to check if my model is over parameterized.

My questions are:
a)    is it true that I can use my factor as it is when read by R, i.e. "int"?
b)    if yes, does it make sense to keep in the model both the factor in the nominal form as fixed effect and the factor in the numerical form as random effect?

Many thanks for your help,

Elisa Monaco | PhD student

	[[alternative HTML version deleted]]


From @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com  Mon Jul 22 13:23:52 2019
From: @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com (=?UTF-8?Q?Andr=C3=A9_Pardal?=)
Date: Mon, 22 Jul 2019 12:23:52 +0100
Subject: [R-sig-ME] Spatial correlation in glmmTMB
In-Reply-To: <53767ee8-b590-9c84-481e-4145b13347b8@umontpellier.fr>
References: <CAFxBq7xPkguf9KfU_4dcyU2ULyWgKD0wQcN8b1gW_ZhJCjJr3A@mail.gmail.com>
 <53767ee8-b590-9c84-481e-4145b13347b8@umontpellier.fr>
Message-ID: <CAFxBq7ymUTQ=10Ch1kpRLZDJzx_hcWWb8LbqDepqHDYVVvZsZg@mail.gmail.com>

Hello,

Thank you all for the comments. Actually, there is a misspelling in my
first email and sorry for not explaining properly. I will try below:

I collected data in 62 locations along a large spatial scale (> 500 km).
And I surely have replication inside each location.
First I performed a model selection for identifying the best random
structure than the fixed structure. The final best model is as below.

m1 = glmmTMB(density ~ wave_exposure + (1|subregion/location), data=
mydata, family= nbinom1, ziformula= ~0)

The term (1|subregion/location) is the random effect of subregion and
location (and location is nested in subregion)

When I try to account for spatial correlation a have the following model:

m1.spatial = glmmTMB(density ~ wave_exposure + (1|subregion/location) +
exp(pos +0|group), data= mydata, family= nbinom1, ziformula= ~0)

The term exp(pos +0|group) refers to the spatial correlation. exp =
exponential covariance structure; pos = numFactor putting spatial
coordinates together; group = a dummy factor (mydata$group <- factor(rep(1,
nrow(mydata))))

I already tried to create a jitter for spatial coordinates, since some
packages do not work if the distance between two coordinates is zero.
I also tried changing the dummy factor to be a repetition from 1 to 62
(since I have 62 locations).

Actually, most of times the model not even runs and cracks my R.

Well, I guess I will try spaMM.


Thanks a lot.

Andre.




On Fri, 19 Jul 2019 at 09:47, Francois Rousset <
francois.rousset at umontpellier.fr> wrote:

> Dear Andr?,
>
> I saw your question on R-sig-ME. I am not sure I fully understand syntax
> in "wave_exposure + (1|location) exp(pos + 0|group)" so I hesitate to reply
> through R-sig-ME. However, perhaps you should try the spaMM package by
>
> library("spaMM")
>
> m1 <-  fitme(density ~ wave_exposure + Matern(1|easting+northing), data=
> mydata, family= negbin())
>
> Let me know whether this is useful.
> F.
>
> -------- Message transf?r? --------
> Sujet : [R-sig-ME] Spatial correlation in glmmTMB
> Date : Wed, 17 Jul 2019 18:15:39 +0100
> De : Andr? Pardal <andre.pardal.souza at gmail.com>
> <andre.pardal.souza at gmail.com>
> Pour : r-sig-mixed-models at r-project.org
>
> Hello,
>
> I would like to ask for help on how to account for spatial correlation in
> glmmTMB package.
>
> According to the help page (
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html),
> I need to create a numFactor object grouping coordinates and a dummy
> grouping factor.
>
> mydata$pos <- numFactor(mydata$easting, mydata$northing)## spatial
> coordinates
> mydata$group <- factor(rep(1, nrow(mydata)))## dummy factor
>
> Regarding to the dummy variable, I have 62 locations in my dataframe. The
> dummy variable should be 1 for all observations, or go from 1 to 62?
> (Actually I have tried both possibilities. First one give me convergence
> problems, second one cracks my R).
>
> I have been trying to run the following negative binomial mixed model:
>
> m1 = glmmTMB(density ~ wave_exposure + (1|location) exp(pos + 0|group),
> data= mydata, family= nbinom1, ziformula= ~0) ##
>
> I also tried different covariance structures (gau and mat), but no success
> so far.
>
> Any ideas or suggestions here?
>
> Thank you in advance!
>
> Andre.
>
> --
> Visiting PhD student
> School of Ocean Sciences
> Bangor University
> Menai Bridge, Anglesey, UK
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
M. Sc. Andr? Luiz Pardal-Souza
Doutorando em Evolu??o e Diversidade
Centro de Ci?ncias Naturais e Humanas
Universidade Federal do ABC (UFABC)
Curr?culo Lattes <http://lattes.cnpq.br/6271009643657143>

Visiting PhD student
School of Ocean Sciences
Bangor University
Menai Bridge, Anglesey, UK

	[[alternative HTML version deleted]]


From @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com  Mon Jul 22 13:37:48 2019
From: @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com (=?UTF-8?Q?Andr=C3=A9_Pardal?=)
Date: Mon, 22 Jul 2019 12:37:48 +0100
Subject: [R-sig-ME] Spatial correlation in glmmTMB
In-Reply-To: <CAFxBq7ymUTQ=10Ch1kpRLZDJzx_hcWWb8LbqDepqHDYVVvZsZg@mail.gmail.com>
References: <CAFxBq7xPkguf9KfU_4dcyU2ULyWgKD0wQcN8b1gW_ZhJCjJr3A@mail.gmail.com>
 <53767ee8-b590-9c84-481e-4145b13347b8@umontpellier.fr>
 <CAFxBq7ymUTQ=10Ch1kpRLZDJzx_hcWWb8LbqDepqHDYVVvZsZg@mail.gmail.com>
Message-ID: <CAFxBq7w+r3bdJFqAsHK+oeFHwPKD7E9MFx5rikLjX6vgPN4TXQ@mail.gmail.com>

Sorry, forgot to paste the error i get:

dens.exp = glmmTMB(density_cht ~ wf_log + exp(pos + 0|group2) +
(1|subregion/location), data=density2, REML=T, family = nbinom1,
ziformula=~0) ##full

Warning message:
In fitTMB(TMBStruc) :
Model convergence problem; non-positive-definite Hessian matrix. See
vignette('troubleshooting')
> summary(dens.exp)
Error in solve.default(as.matrix(Qm)): system is computationally singular:
reciprocal condition number = 2.67616e-135

On Mon, 22 Jul 2019 at 12:23, Andr? Pardal <andre.pardal.souza at gmail.com>
wrote:

> Hello,
>
> Thank you all for the comments. Actually, there is a misspelling in my
> first email and sorry for not explaining properly. I will try below:
>
> I collected data in 62 locations along a large spatial scale (> 500 km).
> And I surely have replication inside each location.
> First I performed a model selection for identifying the best random
> structure than the fixed structure. The final best model is as below.
>
> m1 = glmmTMB(density ~ wave_exposure + (1|subregion/location), data=
> mydata, family= nbinom1, ziformula= ~0)
>
> The term (1|subregion/location) is the random effect of subregion and
> location (and location is nested in subregion)
>
> When I try to account for spatial correlation a have the following model:
>
> m1.spatial = glmmTMB(density ~ wave_exposure + (1|subregion/location) +
> exp(pos +0|group), data= mydata, family= nbinom1, ziformula= ~0)
>
> The term exp(pos +0|group) refers to the spatial correlation. exp =
> exponential covariance structure; pos = numFactor putting spatial
> coordinates together; group = a dummy factor (mydata$group <- factor(rep(1,
> nrow(mydata))))
>
> I already tried to create a jitter for spatial coordinates, since some
> packages do not work if the distance between two coordinates is zero.
> I also tried changing the dummy factor to be a repetition from 1 to 62
> (since I have 62 locations).
>
> Actually, most of times the model not even runs and cracks my R.
>
> Well, I guess I will try spaMM.
>
>
> Thanks a lot.
>
> Andre.
>
>
>
>
> On Fri, 19 Jul 2019 at 09:47, Francois Rousset <
> francois.rousset at umontpellier.fr> wrote:
>
>> Dear Andr?,
>>
>> I saw your question on R-sig-ME. I am not sure I fully understand syntax
>> in "wave_exposure + (1|location) exp(pos + 0|group)" so I hesitate to reply
>> through R-sig-ME. However, perhaps you should try the spaMM package by
>>
>> library("spaMM")
>>
>> m1 <-  fitme(density ~ wave_exposure + Matern(1|easting+northing), data=
>> mydata, family= negbin())
>>
>> Let me know whether this is useful.
>> F.
>>
>> -------- Message transf?r? --------
>> Sujet : [R-sig-ME] Spatial correlation in glmmTMB
>> Date : Wed, 17 Jul 2019 18:15:39 +0100
>> De : Andr? Pardal <andre.pardal.souza at gmail.com>
>> <andre.pardal.souza at gmail.com>
>> Pour : r-sig-mixed-models at r-project.org
>>
>> Hello,
>>
>> I would like to ask for help on how to account for spatial correlation in
>> glmmTMB package.
>>
>> According to the help page (
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>> ),
>> I need to create a numFactor object grouping coordinates and a dummy
>> grouping factor.
>>
>> mydata$pos <- numFactor(mydata$easting, mydata$northing)## spatial
>> coordinates
>> mydata$group <- factor(rep(1, nrow(mydata)))## dummy factor
>>
>> Regarding to the dummy variable, I have 62 locations in my dataframe. The
>> dummy variable should be 1 for all observations, or go from 1 to 62?
>> (Actually I have tried both possibilities. First one give me convergence
>> problems, second one cracks my R).
>>
>> I have been trying to run the following negative binomial mixed model:
>>
>> m1 = glmmTMB(density ~ wave_exposure + (1|location) exp(pos + 0|group),
>> data= mydata, family= nbinom1, ziformula= ~0) ##
>>
>> I also tried different covariance structures (gau and mat), but no success
>> so far.
>>
>> Any ideas or suggestions here?
>>
>> Thank you in advance!
>>
>> Andre.
>>
>> --
>> Visiting PhD student
>> School of Ocean Sciences
>> Bangor University
>> Menai Bridge, Anglesey, UK
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> --
> M. Sc. Andr? Luiz Pardal-Souza
> Doutorando em Evolu??o e Diversidade
> Centro de Ci?ncias Naturais e Humanas
> Universidade Federal do ABC (UFABC)
> Curr?culo Lattes <http://lattes.cnpq.br/6271009643657143>
>
> Visiting PhD student
> School of Ocean Sciences
> Bangor University
> Menai Bridge, Anglesey, UK
>


-- 
M. Sc. Andr? Luiz Pardal-Souza
Doutorando em Evolu??o e Diversidade
Centro de Ci?ncias Naturais e Humanas
Universidade Federal do ABC (UFABC)
Curr?culo Lattes <http://lattes.cnpq.br/6271009643657143>

Visiting PhD student
School of Ocean Sciences
B?angor University
Menai Bridge, Anglesey, UK?

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Mon Jul 22 16:24:24 2019
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Mon, 22 Jul 2019 15:24:24 +0100
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
Message-ID: <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>

Dear Elisa

Is this factor a grouping variable (for random intercepts) or a random
slope ? How many levels does it have ? And lease can you give us the full
model formula.



On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
r-sig-mixed-models at r-project.org> wrote:

> Dear list,
> looking at the correlation values of my random effects, as well as the
> fact that my model fails to converge, it makes sense to me to simplify its
> random structure (while keeping maximal and according to our hp the fixed
> structure).
> One way is to remove correlations, and I know that the || notation works
> only with numerically coded factors.
> As far as I understood, I have two options:
> 1) use the package afex, putting my model as object of mixed and adding
> "expand_re=true"
> 2) use the original factor, by default read as "int"
>
> I want to use the option 2) because with mixed I can't apply the PCA
> function for random effects to check if my model is over parameterized.
>
> My questions are:
> a)    is it true that I can use my factor as it is when read by R, i.e.
> "int"?
> b)    if yes, does it make sense to keep in the model both the factor in
> the nominal form as fixed effect and the factor in the numerical form as
> random effect?
>
> Many thanks for your help,
>
> Elisa Monaco | PhD student
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @nge|o@morett| @end|ng |rom m@nche@ter@@c@uk  Mon Jul 22 17:07:45 2019
From: @nge|o@morett| @end|ng |rom m@nche@ter@@c@uk (Angelo Moretti)
Date: Mon, 22 Jul 2019 15:07:45 +0000
Subject: [R-sig-ME] lme4 multivariate
Message-ID: <70228C1D4D5C0141AE9A106936BD56DC973B2512@MBXP11.ds.man.ac.uk>

Hello,
I am writing regarding the R package lme4. My aim is to estimate a bivariate generalised mixed-effect model for binary responses (with logit link function). Does the package allow to do this instead of estimating two separate models? I am trying to do that under ML.
Thank you very much for your help.




	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jul 22 17:56:19 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 22 Jul 2019 11:56:19 -0400
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
Message-ID: <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com>


  Elisa,

  Can you say a little more about what your factor represents?

  It probably *doesn't* make sense to collapse your factor to an integer
for the purpose of allowing a diagonal covariance matrix, unless:

 * it's reasonable to treat the factor levels as sequential values with
equal differences between each successive pair (e.g., time), OR
 * the factor only has two levels anyway

  Another simplifying strategy is to use a compound-symmetric model
(equal correlations among all pairs of levels): if your original model
is (f|g) (where f is a factor and g is your grouping variable), then
(1|g/f) will generate a CS model.

  cheers
    Ben Bolker


On 2019-07-22 10:24 a.m., Robert Long wrote:
> Dear Elisa
> 
> Is this factor a grouping variable (for random intercepts) or a random
> slope ? How many levels does it have ? And lease can you give us the full
> model formula.
> 
> 
> 
> On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> r-sig-mixed-models at r-project.org> wrote:
> 
>> Dear list,
>> looking at the correlation values of my random effects, as well as the
>> fact that my model fails to converge, it makes sense to me to simplify its
>> random structure (while keeping maximal and according to our hp the fixed
>> structure).
>> One way is to remove correlations, and I know that the || notation works
>> only with numerically coded factors.
>> As far as I understood, I have two options:
>> 1) use the package afex, putting my model as object of mixed and adding
>> "expand_re=true"
>> 2) use the original factor, by default read as "int"
>>
>> I want to use the option 2) because with mixed I can't apply the PCA
>> function for random effects to check if my model is over parameterized.
>>
>> My questions are:
>> a)    is it true that I can use my factor as it is when read by R, i.e.
>> "int"?
>> b)    if yes, does it make sense to keep in the model both the factor in
>> the nominal form as fixed effect and the factor in the numerical form as
>> random effect?
>>
>> Many thanks for your help,
>>
>> Elisa Monaco | PhD student
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Jul 22 18:01:40 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 22 Jul 2019 16:01:40 +0000
Subject: [R-sig-ME] lme4 multivariate
In-Reply-To: <70228C1D4D5C0141AE9A106936BD56DC973B2512@MBXP11.ds.man.ac.uk>
References: <70228C1D4D5C0141AE9A106936BD56DC973B2512@MBXP11.ds.man.ac.uk>
Message-ID: <3a16e1cffdce40829e7f4cd2424ecd12@erasmusmc.nl>

You could the put the two outcomes one underneath the other, create a factor variable denoting the outcome, and interactions of this factor with the fixed and random effects you want to include.

Best,
Dimitris


From: Angelo Moretti <angelo.moretti at manchester.ac.uk<mailto:angelo.moretti at manchester.ac.uk>>
Date: Monday, 22 Jul 2019, 18:08
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] lme4 multivariate

Hello,
I am writing regarding the R package lme4. My aim is to estimate a bivariate generalised mixed-effect model for binary responses (with logit link function). Does the package allow to do this instead of estimating two separate models? I am trying to do that under ML.
Thank you very much for your help.




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C85a37960ee95419e5fe608d70eb66b71%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C636994048951660335&amp;sdata=VZnnHz6pkV5EujoGzi%2BXeFm4hfBhtJW%2FjHQIgE6Rkzs%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From dc@n@rte @end|ng |rom u||@edu  Mon Jul 22 23:29:36 2019
From: dc@n@rte @end|ng |rom u||@edu (Canarte Gutierrez,Climaco D)
Date: Mon, 22 Jul 2019 21:29:36 +0000
Subject: [R-sig-ME] MIxed Effects Logistic Regression error "rank deficient"
 #534
Message-ID: <184D3286-595B-4355-802C-28293DD0B055@ufl.edu>

Hello

I am running mixed effects logistic regression that is throwing the following error: "fixed-effect model matrix is rank deficient so dropping 1 column / coefficient"

This model is the full random-intercept model with all level-1 and level-2 predictors (20 IVs in total.. yeah is a big one) . I did not have this error when gradually adding level-1 and level-2 predictors.

After changing one categorically variable I recently created with its former version, the full-random intercept did not show the ?rank error?, but the b estimates and p-values changed.

Does anyone have an idea what's going on? Should I disregard the results of the model with the "rank deficient"  error "?

Thanks

David Ca?arte
Ph.D. Candidate
Department of Sociology
and Criminology
University of Florida
dcanarte at ufl.edu<mailto:dcanarte at ufl.edu>




	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Jul 23 13:46:09 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 23 Jul 2019 13:46:09 +0200
Subject: [R-sig-ME] 
 MIxed Effects Logistic Regression error "rank deficient" #534
In-Reply-To: <184D3286-595B-4355-802C-28293DD0B055@ufl.edu>
References: <184D3286-595B-4355-802C-28293DD0B055@ufl.edu>
Message-ID: <c56484f4-8534-0755-5e37-71e2b131286b@mpi.nl>

Rank deficiency here means that not all all combinations of all
(fixed-effects) predictors appear in the data and so the model matrix is
incomplete (not full rank) and not all coefficients / fixed effects can
be estimated. If you have a design where you expect this, this is not a
problem. But if all combinations should be present, then this suggests
that your data are not what you think they are. Maybe double check that
you didn't accidentally change the data somehow or incorrectly code a
categorical variable?

Phillip

On 22/7/19 11:29 pm, Canarte Gutierrez,Climaco D wrote:
> Hello
> 
> I am running mixed effects logistic regression that is throwing the following error: "fixed-effect model matrix is rank deficient so dropping 1 column / coefficient"
> 
> This model is the full random-intercept model with all level-1 and level-2 predictors (20 IVs in total.. yeah is a big one) . I did not have this error when gradually adding level-1 and level-2 predictors.
> 
> After changing one categorically variable I recently created with its former version, the full-random intercept did not show the ?rank error?, but the b estimates and p-values changed.
> 
> Does anyone have an idea what's going on? Should I disregard the results of the model with the "rank deficient"  error "?
> 
> Thanks
> 
> David Ca?arte
> Ph.D. Candidate
> Department of Sociology
> and Criminology
> University of Florida
> dcanarte at ufl.edu<mailto:dcanarte at ufl.edu>
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Jul 24 07:56:19 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Wed, 24 Jul 2019 05:56:19 +0000
Subject: [R-sig-ME] New cvGEE package for validating predictions from GEEs
Message-ID: <1a2f37b43e0a4a558c0a7523970e1a0b@erasmusmc.nl>

Dear R mixed model users,

I?d like to announce the release of my new R package cvGEE (https://cran.r-project.org/package=cvGEE) that validates (using repeated cross-validation) predictions from generalized estimating equations using proper scoring rules. It can be used to compare nested and non-nested GEEs, such as to compare GEEs with the same mean structure but different working correlation matrices.

You may find more information and examples in the dedicated website:

https://drizopoulos.github.io/cvGEE/

and vignette

https://drizopoulos.github.io/cvGEE/articles/Scoring_Rules_GEE.html

The package currently works with geeglm objects returned by the geepack but there are plans to extend it to other GEE-solvers packages. Additional future plans include functions for calibration plots.

As always, any kind of feedback is more than welcome.

Best,
Dimitris

- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

	[[alternative HTML version deleted]]


From e||@@@mon@co @end|ng |rom un||r@ch  Wed Jul 24 10:01:09 2019
From: e||@@@mon@co @end|ng |rom un||r@ch (MONACO Elisa)
Date: Wed, 24 Jul 2019 08:01:09 +0000
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>,
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com>
Message-ID: <1563955273507.838@unifr.ch>

Dear all, 
many thanks for your answers and sorry for not providing the details.

My experiment is a 2X2X4 within subject design, with all three factors being categorical: L=Language of the stimuli (2 levels), V= type of the stimuli (2 levels), D= delay of brain stimulation (4 levels). My dependent variable is the amplitude of a physiological measure.

I thought to build my maximal mixed model in which all the factors are crossed within subjects and only D is crossed within items (items are the same, repeated at different delays of stimulation):

lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata, control=lmerControl(optCtrl=list(maxfun=1e6)))

So, to answer @Robert Long: my factor D I was referring to is a random slope, with4 levels

to answer at Ben Bolker:
indeed I don't think that my factor D falls in the 2 cases you mentioned, because:
 a) the differences between each level is not the same for each level (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time, we expect the effect to be present at one or more latencies depending on L;
b) the factor has more than two levels.

According to all of this, I should go for a CS model, right?
I'm a newbie in this field, so can you please give me some indications of what can I read about it or some indications to understand how to handle this (especially if I want to reduce gradually the random structure of the subjects part, see modelreduced2)/?

modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (1|items/D), data=mydata, control=lmerControl(optCtrl=list(maxfun=1e6)))

modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) + (1|items/D), data=mydata, control=lmerControl(optCtrl=list(maxfun=1e6)))


Another point: is this semplification indipendent of which type of contrast I set for D (I'll set sum contrast for V and L, but I'm still reasoning on what is the best for D)?
  
Thank you in advance for this big help and please tell me if you need further clarifications or code.

 Elisa Monaco | PhD student
________________________________________
De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de la part de Ben Bolker <bbolker at gmail.com>
Envoy? : lundi 22 juillet 2019 17:56
? : r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors

  Elisa,

  Can you say a little more about what your factor represents?

  It probably *doesn't* make sense to collapse your factor to an integer
for the purpose of allowing a diagonal covariance matrix, unless:

 * it's reasonable to treat the factor levels as sequential values with
equal differences between each successive pair (e.g., time), OR
 * the factor only has two levels anyway

  Another simplifying strategy is to use a compound-symmetric model
(equal correlations among all pairs of levels): if your original model
is (f|g) (where f is a factor and g is your grouping variable), then
(1|g/f) will generate a CS model.

  cheers
    Ben Bolker


On 2019-07-22 10:24 a.m., Robert Long wrote:
> Dear Elisa
>
> Is this factor a grouping variable (for random intercepts) or a random
> slope ? How many levels does it have ? And lease can you give us the full
> model formula.
>
>
>
> On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> r-sig-mixed-models at r-project.org> wrote:
>
>> Dear list,
>> looking at the correlation values of my random effects, as well as the
>> fact that my model fails to converge, it makes sense to me to simplify its
>> random structure (while keeping maximal and according to our hp the fixed
>> structure).
>> One way is to remove correlations, and I know that the || notation works
>> only with numerically coded factors.
>> As far as I understood, I have two options:
>> 1) use the package afex, putting my model as object of mixed and adding
>> "expand_re=true"
>> 2) use the original factor, by default read as "int"
>>
>> I want to use the option 2) because with mixed I can't apply the PCA
>> function for random effects to check if my model is over parameterized.
>>
>> My questions are:
>> a)    is it true that I can use my factor as it is when read by R, i.e.
>> "int"?
>> b)    if yes, does it make sense to keep in the model both the factor in
>> the nominal form as fixed effect and the factor in the numerical form as
>> random effect?
>>
>> Many thanks for your help,
>>
>> Elisa Monaco | PhD student
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |ongrob604 @end|ng |rom gm@||@com  Wed Jul 24 10:33:16 2019
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Wed, 24 Jul 2019 09:33:16 +0100
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <1563955273507.838@unifr.ch>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
Message-ID: <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>

It is quite possible that such a complex random structure will not be
supported by the data.

In your initial email you mentioned correlations between random effects.
However, since the model did not converge, there is no point in
intetpreting them. Moreover, to force them to be uncorrelated is possibly
making unrealistic constraints on the model.

Why do seek such a complex random structure ? If you are following the
advice by Barr et al (2013) to "keep it maximal", this is often very poor
advice, as noted by Bates et al (2015), Bates being the primary author of
the lme4 package:

https://arxiv.org/pdf/1506.04967








On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:

> Dear all,
> many thanks for your answers and sorry for not providing the details.
>
> My experiment is a 2X2X4 within subject design, with all three factors
> being categorical: L=Language of the stimuli (2 levels), V= type of the
> stimuli (2 levels), D= delay of brain stimulation (4 levels). My dependent
> variable is the amplitude of a physiological measure.
>
> I thought to build my maximal mixed model in which all the factors are
> crossed within subjects and only D is crossed within items (items are the
> same, repeated at different delays of stimulation):
>
> lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata,
> control=lmerControl(optCtrl=list(maxfun=1e6)))
>
> So, to answer @Robert Long: my factor D I was referring to is a random
> slope, with4 levels
>
> to answer at Ben Bolker:
> indeed I don't think that my factor D falls in the 2 cases you mentioned,
> because:
>  a) the differences between each level is not the same for each level
> (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time, we
> expect the effect to be present at one or more latencies depending on L;
> b) the factor has more than two levels.
>
> According to all of this, I should go for a CS model, right?
> I'm a newbie in this field, so can you please give me some indications of
> what can I read about it or some indications to understand how to handle
> this (especially if I want to reduce gradually the random structure of the
> subjects part, see modelreduced2)/?
>
> modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (1|items/D),
> data=mydata, control=lmerControl(optCtrl=list(maxfun=1e6)))
>
> modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) + (1|items/D),
> data=mydata, control=lmerControl(optCtrl=list(maxfun=1e6)))
>
>
> Another point: is this semplification indipendent of which type of
> contrast I set for D (I'll set sum contrast for V and L, but I'm still
> reasoning on what is the best for D)?
>
> Thank you in advance for this big help and please tell me if you need
> further clarifications or code.
>
>  Elisa Monaco | PhD student
> ________________________________________
> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de la
> part de Ben Bolker <bbolker at gmail.com>
> Envoy? : lundi 22 juillet 2019 17:56
> ? : r-sig-mixed-models at r-project.org
> Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
>
>   Elisa,
>
>   Can you say a little more about what your factor represents?
>
>   It probably *doesn't* make sense to collapse your factor to an integer
> for the purpose of allowing a diagonal covariance matrix, unless:
>
>  * it's reasonable to treat the factor levels as sequential values with
> equal differences between each successive pair (e.g., time), OR
>  * the factor only has two levels anyway
>
>   Another simplifying strategy is to use a compound-symmetric model
> (equal correlations among all pairs of levels): if your original model
> is (f|g) (where f is a factor and g is your grouping variable), then
> (1|g/f) will generate a CS model.
>
>   cheers
>     Ben Bolker
>
>
> On 2019-07-22 10:24 a.m., Robert Long wrote:
> > Dear Elisa
> >
> > Is this factor a grouping variable (for random intercepts) or a random
> > slope ? How many levels does it have ? And lease can you give us the full
> > model formula.
> >
> >
> >
> > On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> > r-sig-mixed-models at r-project.org> wrote:
> >
> >> Dear list,
> >> looking at the correlation values of my random effects, as well as the
> >> fact that my model fails to converge, it makes sense to me to simplify
> its
> >> random structure (while keeping maximal and according to our hp the
> fixed
> >> structure).
> >> One way is to remove correlations, and I know that the || notation works
> >> only with numerically coded factors.
> >> As far as I understood, I have two options:
> >> 1) use the package afex, putting my model as object of mixed and adding
> >> "expand_re=true"
> >> 2) use the original factor, by default read as "int"
> >>
> >> I want to use the option 2) because with mixed I can't apply the PCA
> >> function for random effects to check if my model is over parameterized.
> >>
> >> My questions are:
> >> a)    is it true that I can use my factor as it is when read by R, i.e.
> >> "int"?
> >> b)    if yes, does it make sense to keep in the model both the factor in
> >> the nominal form as fixed effect and the factor in the numerical form as
> >> random effect?
> >>
> >> Many thanks for your help,
> >>
> >> Elisa Monaco | PhD student
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|th|n@@@m@v@rghe@e @end|ng |rom emory@edu  Tue Jul 30 04:03:58 2019
From: j|th|n@@@m@v@rghe@e @end|ng |rom emory@edu (Varghese, Jithin Sam)
Date: Tue, 30 Jul 2019 02:03:58 +0000
Subject: [R-sig-ME] Question on Contextual Effects
Message-ID: <BYAPR05MB408850AE82285CB2080B88A9B2DC0@BYAPR05MB4088.namprd05.prod.outlook.com>

Hi everyone,

We are working on a project to model 3 separate cross-sectional surveys (i.e., 3 independent samples). Each survey has the following hierarchical data structure:
L3 - states (~20)
L2 -villages  (~X)
L1 - Individuals (~55,000 total)

We are interested in estimating the association between  a contextual variable measured at the state-level (normally distributed) and an outcome measured at the individual-level (dichotomous) in the pooled data set.  Is there any guidance on the advisable number of contextual variables that could be accommodated in the logistic MLM model?

Thanks a lot for the help in advance.

Regards,
Jithin Sam Varghese
Emory University


________________________________

This e-mail message (including any attachments) is for t...{{dropped:14}}


From g@59||j @end|ng |rom mytum@de  Tue Jul 30 16:33:37 2019
From: g@59||j @end|ng |rom mytum@de (Cueva, Jorge)
Date: Tue, 30 Jul 2019 14:33:37 +0000
Subject: [R-sig-ME] glmer.nb - interaction interpretation
Message-ID: <2d6c6f0b6b714682bc8085bb5863901d@mytum.de>

Dear all
I hope to get support for interpreting a model. First, I am assessing the natural regeneration in a dry forest. The design has 12 clusters and each cluster includes 3 open and 3 fenced plots (a total of 36 open plots and 36 fenced plots), the open plots are separate from the excluded plots by only 20 meters. I want to know if livestock grazing affects the abundance of regeneration, for this we collected excrements of animals, but a single sample of excrements affects both the open and the fence plot.

Of all the models tested, the best was:
glmer.nb(Ind ~ 1 + Equine * Treat + SPrec + Cattle + (1|Cluster), data = BaseOb2, family=poisson, verbose=FALSE, glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))

Ind = number of individuals
Equine = weight of equines excrements (horses + donkeys)
Treat = treatment (open and exclusion plots)
SPrec = seasonal precipitation
Cattle = weight of cattle excrements
Cluster = cluster was used as random predictor because the samples were nested in the cluster.

My issue is when I want to interpret the effect of the predictors. Here are the results

Fixed effects:
                                              Estimate              Std. Error             z value                  Pr(>|z|)
(Intercept)                          3.170153             0.246584             12.856                  < 2e-16 ***
Equine                                 0.926521             0.233079             3.975                     7.03e-05 ***
Treatopen                          -0.009898            0.068965             -0.144                   0.885875
SPrec                                    0.390747             0.078133             5.001                     5.70e-07 ***
Cattle                                   -0.365988            0.184748             -1.981                   0.047589 *
Equine:Treatopen            -0.989678            0.274040             -3.611                   0.000305 ***

It can be seen that the independent effect of Equine is significantly positive and that of Treatopen non-significantly negative. Interpretation of these would be easy, but my issue is the Equine:Treatopen interaction. Why is the effect of Equine first positive and then in the interaction negative? What does that mean?

Very grateful in advance.

Jorge Cueva Ortiz
PhD Candidate
Technical University of Munich
01631327886


	[[alternative HTML version deleted]]


From @|ngm@nn @end|ng |rom gm@||@com  Tue Jul 30 20:05:47 2019
From: @|ngm@nn @end|ng |rom gm@||@com (Henrik Singmann)
Date: Tue, 30 Jul 2019 19:05:47 +0100
Subject: [R-sig-ME] Question on Contextual Effects
In-Reply-To: <BYAPR05MB408850AE82285CB2080B88A9B2DC0@BYAPR05MB4088.namprd05.prod.outlook.com>
References: <BYAPR05MB408850AE82285CB2080B88A9B2DC0@BYAPR05MB4088.namprd05.prod.outlook.com>
Message-ID: <CA+rDMK+jaKFUFzJS_xHonw7xT-8n+XEDn=wonRn5yGFnfQC7sw@mail.gmail.com>

Dear Jithin Sam,

I think that with only 20 states with roughly 20 different values for each
contextual variable, that number (i.e., 20) is probably your relevant
sample size. And if I remember that correctly, the rule of thumb is that
you need 20 data points for each parameter in a linear model, so I guess
this applies here to. So I would say much more than 1 contextual variable
is probably not advisable in one model. You can of course run multiple
models each with different contextual variables, but a joint model sounds
somewhat questionable.

I know that sounds crazy given your enormous amount of data, but the only
thing this many data allows you to do, is to estimate the probability of a
success (i.e., the binomial parameter) in each state very precisely. But
then your main interest is in the inference performed at the state level so
it has to be seen in that context.

Please note that this explanation ignores the fact that estimating
parameters in a binomial model is usually more complicated than in a linear
model.

Please note that I am not a statistician, so I am happy to be corrected by
someone more knowledgeable. But in my experience with such models, the
number of levels at the highest level seems to be the relevant number in
such cases.

Best,
Henrik



Am Di., 30. Juli 2019 um 14:59 Uhr schrieb Varghese, Jithin Sam <
jithin.sam.varghese at emory.edu>:

> Hi everyone,
>
> We are working on a project to model 3 separate cross-sectional surveys
> (i.e., 3 independent samples). Each survey has the following hierarchical
> data structure:
> L3 - states (~20)
> L2 -villages  (~X)
> L1 - Individuals (~55,000 total)
>
> We are interested in estimating the association between  a contextual
> variable measured at the state-level (normally distributed) and an outcome
> measured at the individual-level (dichotomous) in the pooled data set.  Is
> there any guidance on the advisable number of contextual variables that
> could be accommodated in the logistic MLM model?
>
> Thanks a lot for the help in advance.
>
> Regards,
> Jithin Sam Varghese
> Emory University
>
>
> ________________________________
>
> This e-mail message (including any attachments) is for...{{dropped:17}}


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jul 30 22:15:57 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 30 Jul 2019 20:15:57 +0000
Subject: [R-sig-ME] glmer.nb - interaction interpretation
In-Reply-To: <25056_1564508182_x6UHaKEO023599_2d6c6f0b6b714682bc8085bb5863901d@mytum.de>
References: <25056_1564508182_x6UHaKEO023599_2d6c6f0b6b714682bc8085bb5863901d@mytum.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836C82EAE@FHSDB2D11-2.csu.mcmaster.ca>

Dear Jorge,

You might try the predictorEffects() function in the effects package to visualize the interaction. In particular, and as a start, plot(predictorEffects(mod)), where mod is the model you wish to examine.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Cueva, Jorge
> Sent: Tuesday, July 30, 2019 10:34 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer.nb - interaction interpretation
> 
> Dear all
> I hope to get support for interpreting a model. First, I am assessing the natural
> regeneration in a dry forest. The design has 12 clusters and each cluster
> includes 3 open and 3 fenced plots (a total of 36 open plots and 36 fenced
> plots), the open plots are separate from the excluded plots by only 20 meters.
> I want to know if livestock grazing affects the abundance of regeneration, for
> this we collected excrements of animals, but a single sample of excrements
> affects both the open and the fence plot.
> 
> Of all the models tested, the best was:
> glmer.nb(Ind ~ 1 + Equine * Treat + SPrec + Cattle + (1|Cluster), data =
> BaseOb2, family=poisson, verbose=FALSE, glmerControl(optimizer="bobyqa",
> optCtrl = list(maxfun = 2e5)))
> 
> Ind = number of individuals
> Equine = weight of equines excrements (horses + donkeys) Treat = treatment
> (open and exclusion plots) SPrec = seasonal precipitation Cattle = weight of
> cattle excrements Cluster = cluster was used as random predictor because the
> samples were nested in the cluster.
> 
> My issue is when I want to interpret the effect of the predictors. Here are the
> results
> 
> Fixed effects:
>                                               Estimate              Std. Error             z value
> Pr(>|z|)
> (Intercept)                          3.170153             0.246584             12.856                  <
> 2e-16 ***
> Equine                                 0.926521             0.233079             3.975
> 7.03e-05 ***
> Treatopen                          -0.009898            0.068965             -0.144
> 0.885875
> SPrec                                    0.390747             0.078133             5.001
> 5.70e-07 ***
> Cattle                                   -0.365988            0.184748             -1.981
> 0.047589 *
> Equine:Treatopen            -0.989678            0.274040             -3.611
> 0.000305 ***
> 
> It can be seen that the independent effect of Equine is significantly positive
> and that of Treatopen non-significantly negative. Interpretation of these
> would be easy, but my issue is the Equine:Treatopen interaction. Why is the
> effect of Equine first positive and then in the interaction negative? What does
> that mean?
> 
> Very grateful in advance.
> 
> Jorge Cueva Ortiz
> PhD Candidate
> Technical University of Munich
> 01631327886
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From e||@@@mon@co @end|ng |rom un||r@ch  Wed Jul 31 10:14:15 2019
From: e||@@@mon@co @end|ng |rom un||r@ch (MONACO Elisa)
Date: Wed, 31 Jul 2019 08:14:15 +0000
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
Message-ID: <75315dab4f4646f4b22df160f2a9622a@svw-exmb1.unifr.ch>

Thank you,

Robert Long, I think we are claiming the same idea: the maximal model is too complex (overparameterized and with a degenerate/singular solution) and I want to reduce the random structure, following the steps suggested by Bates et al.. Am I correct?
However one of these steps it's indeed "forcing to zero the correlation parameters" and check the good fit of the consequent model. Therefore my question on how to arrange my D factor in the random structure.

I still don't know how to handle CS model suggested by Bolker ((1|g/f)) and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any suggestions would be much appreciated!

Elisa Monaco  


-----Message d'origine-----
De?: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la part de Robert Long
Envoy??: mercredi, 24 juillet 2019 10:33
??: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Objet?: Re: [R-sig-ME] keeping both numerically and factor coded factors

It is quite possible that such a complex random structure will not be supported by the data.

In your initial email you mentioned correlations between random effects.
However, since the model did not converge, there is no point in intetpreting them. Moreover, to force them to be uncorrelated is possibly making unrealistic constraints on the model.

Why do seek such a complex random structure ? If you are following the advice by Barr et al (2013) to "keep it maximal", this is often very poor advice, as noted by Bates et al (2015), Bates being the primary author of the lme4 package:

https://arxiv.org/pdf/1506.04967








On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:

> Dear all,
> many thanks for your answers and sorry for not providing the details.
>
> My experiment is a 2X2X4 within subject design, with all three factors 
> being categorical: L=Language of the stimuli (2 levels), V= type of 
> the stimuli (2 levels), D= delay of brain stimulation (4 levels). My 
> dependent variable is the amplitude of a physiological measure.
>
> I thought to build my maximal mixed model in which all the factors are 
> crossed within subjects and only D is crossed within items (items are 
> the same, repeated at different delays of stimulation):
>
> lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata,
> control=lmerControl(optCtrl=list(maxfun=1e6)))
>
> So, to answer @Robert Long: my factor D I was referring to is a random 
> slope, with4 levels
>
> to answer at Ben Bolker:
> indeed I don't think that my factor D falls in the 2 cases you 
> mentioned,
> because:
>  a) the differences between each level is not the same for each level
> (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time, 
> we expect the effect to be present at one or more latencies depending 
> on L;
> b) the factor has more than two levels.
>
> According to all of this, I should go for a CS model, right?
> I'm a newbie in this field, so can you please give me some indications 
> of what can I read about it or some indications to understand how to 
> handle this (especially if I want to reduce gradually the random 
> structure of the subjects part, see modelreduced2)/?
>
> modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + 
> (1|items/D), data=mydata, 
> control=lmerControl(optCtrl=list(maxfun=1e6)))
>
> modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) + 
> (1|items/D), data=mydata, 
> control=lmerControl(optCtrl=list(maxfun=1e6)))
>
>
> Another point: is this semplification indipendent of which type of 
> contrast I set for D (I'll set sum contrast for V and L, but I'm still 
> reasoning on what is the best for D)?
>
> Thank you in advance for this big help and please tell me if you need 
> further clarifications or code.
>
>  Elisa Monaco | PhD student
> ________________________________________
> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de 
> la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet 
> 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] 
> keeping both numerically and factor coded factors
>
>   Elisa,
>
>   Can you say a little more about what your factor represents?
>
>   It probably *doesn't* make sense to collapse your factor to an 
> integer for the purpose of allowing a diagonal covariance matrix, unless:
>
>  * it's reasonable to treat the factor levels as sequential values 
> with equal differences between each successive pair (e.g., time), OR
>  * the factor only has two levels anyway
>
>   Another simplifying strategy is to use a compound-symmetric model 
> (equal correlations among all pairs of levels): if your original model 
> is (f|g) (where f is a factor and g is your grouping variable), then
> (1|g/f) will generate a CS model.
>
>   cheers
>     Ben Bolker
>
>
> On 2019-07-22 10:24 a.m., Robert Long wrote:
> > Dear Elisa
> >
> > Is this factor a grouping variable (for random intercepts) or a 
> > random slope ? How many levels does it have ? And lease can you give 
> > us the full model formula.
> >
> >
> >
> > On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, < 
> > r-sig-mixed-models at r-project.org> wrote:
> >
> >> Dear list,
> >> looking at the correlation values of my random effects, as well as 
> >> the fact that my model fails to converge, it makes sense to me to 
> >> simplify
> its
> >> random structure (while keeping maximal and according to our hp the
> fixed
> >> structure).
> >> One way is to remove correlations, and I know that the || notation 
> >> works only with numerically coded factors.
> >> As far as I understood, I have two options:
> >> 1) use the package afex, putting my model as object of mixed and 
> >> adding "expand_re=true"
> >> 2) use the original factor, by default read as "int"
> >>
> >> I want to use the option 2) because with mixed I can't apply the 
> >> PCA function for random effects to check if my model is over parameterized.
> >>
> >> My questions are:
> >> a)    is it true that I can use my factor as it is when read by R, i.e.
> >> "int"?
> >> b)    if yes, does it make sense to keep in the model both the factor in
> >> the nominal form as fixed effect and the factor in the numerical 
> >> form as random effect?
> >>
> >> Many thanks for your help,
> >>
> >> Elisa Monaco | PhD student
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Wed Jul 31 11:10:20 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Wed, 31 Jul 2019 11:10:20 +0200
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <de2921ea99d045e9ba21a95a57b3bacb@MSX-L104.msx.ad.zih.tu-dresden.de>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
 <de2921ea99d045e9ba21a95a57b3bacb@MSX-L104.msx.ad.zih.tu-dresden.de>
Message-ID: <CAHr4Dyf4sU-rsgP=aFrWcVP2SsV5ShGKSj5KUyREU0phYKvmEg@mail.gmail.com>

Dear Elisa,

if you just want use the RePsychLing::rePCA() function on objects
return by the afex::mixed() function, you can simply set the *return*
argument of the mixed() function to "merMod". This will work, but -
somewhat counter-intuitively - make the mixed() function return an
object of class lmerModLmerTest as mixed(), by default, uses
lmerTest::lmer() for its calculations.
If you really need a merMod object, then you need to set
afex_options(lmer_function = "lme4") before calling mixed().

library("afex")
library("RePsychLing")

d <- lme4::sleepstudy
d$Days <- cut(d$Days, breaks = 2, labels = c("first_half", "second_half"))

set_sum_contrasts()

# optional: make mixed() return a merMod object
# afex_options(lmer_function = "lme4")

m1 <- mixed(formula = Reaction ~ Days + (Days || Subject),
                     data = d,
                     expand_re = TRUE,
                     return = "merMod")

summary(rePCA(m1))

Best regards,
Maarten

On Wed, Jul 31, 2019 at 10:14 AM MONACO Elisa via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
>


On Wed, Jul 31, 2019 at 10:14 AM MONACO Elisa via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
>
> Thank you,
>
> Robert Long, I think we are claiming the same idea: the maximal model is too complex (overparameterized and with a degenerate/singular solution) and I want to reduce the random structure, following the steps suggested by Bates et al.. Am I correct?
> However one of these steps it's indeed "forcing to zero the correlation parameters" and check the good fit of the consequent model. Therefore my question on how to arrange my D factor in the random structure.
>
> I still don't know how to handle CS model suggested by Bolker ((1|g/f)) and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any suggestions would be much appreciated!
>
> Elisa Monaco
>
>
> -----Message d'origine-----
> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la part de Robert Long
> Envoy? : mercredi, 24 juillet 2019 10:33
> ? : R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
>
> It is quite possible that such a complex random structure will not be supported by the data.
>
> In your initial email you mentioned correlations between random effects.
> However, since the model did not converge, there is no point in intetpreting them. Moreover, to force them to be uncorrelated is possibly making unrealistic constraints on the model.
>
> Why do seek such a complex random structure ? If you are following the advice by Barr et al (2013) to "keep it maximal", this is often very poor advice, as noted by Bates et al (2015), Bates being the primary author of the lme4 package:
>
> https://arxiv.org/pdf/1506.04967
>
>
>
>
>
>
>
>
> On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
>
> > Dear all,
> > many thanks for your answers and sorry for not providing the details.
> >
> > My experiment is a 2X2X4 within subject design, with all three factors
> > being categorical: L=Language of the stimuli (2 levels), V= type of
> > the stimuli (2 levels), D= delay of brain stimulation (4 levels). My
> > dependent variable is the amplitude of a physiological measure.
> >
> > I thought to build my maximal mixed model in which all the factors are
> > crossed within subjects and only D is crossed within items (items are
> > the same, repeated at different delays of stimulation):
> >
> > lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> > So, to answer @Robert Long: my factor D I was referring to is a random
> > slope, with4 levels
> >
> > to answer at Ben Bolker:
> > indeed I don't think that my factor D falls in the 2 cases you
> > mentioned,
> > because:
> >  a) the differences between each level is not the same for each level
> > (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time,
> > we expect the effect to be present at one or more latencies depending
> > on L;
> > b) the factor has more than two levels.
> >
> > According to all of this, I should go for a CS model, right?
> > I'm a newbie in this field, so can you please give me some indications
> > of what can I read about it or some indications to understand how to
> > handle this (especially if I want to reduce gradually the random
> > structure of the subjects part, see modelreduced2)/?
> >
> > modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) +
> > (1|items/D), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> > modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) +
> > (1|items/D), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> >
> > Another point: is this semplification indipendent of which type of
> > contrast I set for D (I'll set sum contrast for V and L, but I'm still
> > reasoning on what is the best for D)?
> >
> > Thank you in advance for this big help and please tell me if you need
> > further clarifications or code.
> >
> >  Elisa Monaco | PhD student
> > ________________________________________
> > De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de
> > la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet
> > 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME]
> > keeping both numerically and factor coded factors
> >
> >   Elisa,
> >
> >   Can you say a little more about what your factor represents?
> >
> >   It probably *doesn't* make sense to collapse your factor to an
> > integer for the purpose of allowing a diagonal covariance matrix, unless:
> >
> >  * it's reasonable to treat the factor levels as sequential values
> > with equal differences between each successive pair (e.g., time), OR
> >  * the factor only has two levels anyway
> >
> >   Another simplifying strategy is to use a compound-symmetric model
> > (equal correlations among all pairs of levels): if your original model
> > is (f|g) (where f is a factor and g is your grouping variable), then
> > (1|g/f) will generate a CS model.
> >
> >   cheers
> >     Ben Bolker
> >
> >
> > On 2019-07-22 10:24 a.m., Robert Long wrote:
> > > Dear Elisa
> > >
> > > Is this factor a grouping variable (for random intercepts) or a
> > > random slope ? How many levels does it have ? And lease can you give
> > > us the full model formula.
> > >
> > >
> > >
> > > On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> > > r-sig-mixed-models at r-project.org> wrote:
> > >
> > >> Dear list,
> > >> looking at the correlation values of my random effects, as well as
> > >> the fact that my model fails to converge, it makes sense to me to
> > >> simplify
> > its
> > >> random structure (while keeping maximal and according to our hp the
> > fixed
> > >> structure).
> > >> One way is to remove correlations, and I know that the || notation
> > >> works only with numerically coded factors.
> > >> As far as I understood, I have two options:
> > >> 1) use the package afex, putting my model as object of mixed and
> > >> adding "expand_re=true"
> > >> 2) use the original factor, by default read as "int"
> > >>
> > >> I want to use the option 2) because with mixed I can't apply the
> > >> PCA function for random effects to check if my model is over parameterized.
> > >>
> > >> My questions are:
> > >> a)    is it true that I can use my factor as it is when read by R, i.e.
> > >> "int"?
> > >> b)    if yes, does it make sense to keep in the model both the factor in
> > >> the nominal form as fixed effect and the factor in the numerical
> > >> form as random effect?
> > >>
> > >> Many thanks for your help,
> > >>
> > >> Elisa Monaco | PhD student
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Wed Jul 31 12:04:18 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Wed, 31 Jul 2019 12:04:18 +0200
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <CAHr4Dyf4sU-rsgP=aFrWcVP2SsV5ShGKSj5KUyREU0phYKvmEg@mail.gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
 <de2921ea99d045e9ba21a95a57b3bacb@MSX-L104.msx.ad.zih.tu-dresden.de>
 <CAHr4Dyf4sU-rsgP=aFrWcVP2SsV5ShGKSj5KUyREU0phYKvmEg@mail.gmail.com>
Message-ID: <CAHr4DydbhNEZkvPG46R6TEmAo8-SZqwy7p0ZdSPWXenQXSmNnQ@mail.gmail.com>

Following up on my last mail (sorry, I was in a rush earlier today):

As you noted, for lme4::lmer() the double-bar syntax || works as
expected only after converting factor-based to vector-valued
random-effects structures, i.e., after converting factors to numeric
covariates.
There are several ways to do this conversion and the mixed() function
is certainly one of them. Note, however, that the standard formula
syntax of mixed() doesn't allow the user to drop higher-order random
effect terms before lower-order random effect terms by which I mean
dropping randomly varying slopes (e.g. by participant) for
interactions before random slopes for main effects. An alternative
would be to manually create the numeric covariates from the model
matrix. If you are interested in this option, then this [1] RPub by
Reinhold Kliegl explains how you can do this.

[1] https://rpubs.com/Reinhold/22193

Best regards,
Maarten

On Wed, Jul 31, 2019 at 11:10 AM Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
> Dear Elisa,
>
> if you just want use the RePsychLing::rePCA() function on objects
> return by the afex::mixed() function, you can simply set the *return*
> argument of the mixed() function to "merMod". This will work, but -
> somewhat counter-intuitively - make the mixed() function return an
> object of class lmerModLmerTest as mixed(), by default, uses
> lmerTest::lmer() for its calculations.
> If you really need a merMod object, then you need to set
> afex_options(lmer_function = "lme4") before calling mixed().
>
> library("afex")
> library("RePsychLing")
>
> d <- lme4::sleepstudy
> d$Days <- cut(d$Days, breaks = 2, labels = c("first_half", "second_half"))
>
> set_sum_contrasts()
>
> # optional: make mixed() return a merMod object
> # afex_options(lmer_function = "lme4")
>
> m1 <- mixed(formula = Reaction ~ Days + (Days || Subject),
>                      data = d,
>                      expand_re = TRUE,
>                      return = "merMod")
>
> summary(rePCA(m1))
>
> Best regards,
> Maarten
>
> On Wed, Jul 31, 2019 at 10:14 AM MONACO Elisa via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org> wrote:
> >
>
>
> On Wed, Jul 31, 2019 at 10:14 AM MONACO Elisa via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org> wrote:
> >
> > Thank you,
> >
> > Robert Long, I think we are claiming the same idea: the maximal model is too complex (overparameterized and with a degenerate/singular solution) and I want to reduce the random structure, following the steps suggested by Bates et al.. Am I correct?
> > However one of these steps it's indeed "forcing to zero the correlation parameters" and check the good fit of the consequent model. Therefore my question on how to arrange my D factor in the random structure.
> >
> > I still don't know how to handle CS model suggested by Bolker ((1|g/f)) and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any suggestions would be much appreciated!
> >
> > Elisa Monaco
> >
> >
> > -----Message d'origine-----
> > De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la part de Robert Long
> > Envoy? : mercredi, 24 juillet 2019 10:33
> > ? : R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> > Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
> >
> > It is quite possible that such a complex random structure will not be supported by the data.
> >
> > In your initial email you mentioned correlations between random effects.
> > However, since the model did not converge, there is no point in intetpreting them. Moreover, to force them to be uncorrelated is possibly making unrealistic constraints on the model.
> >
> > Why do seek such a complex random structure ? If you are following the advice by Barr et al (2013) to "keep it maximal", this is often very poor advice, as noted by Bates et al (2015), Bates being the primary author of the lme4 package:
> >
> > https://arxiv.org/pdf/1506.04967
> >
> >
> >
> >
> >
> >
> >
> >
> > On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
> >
> > > Dear all,
> > > many thanks for your answers and sorry for not providing the details.
> > >
> > > My experiment is a 2X2X4 within subject design, with all three factors
> > > being categorical: L=Language of the stimuli (2 levels), V= type of
> > > the stimuli (2 levels), D= delay of brain stimulation (4 levels). My
> > > dependent variable is the amplitude of a physiological measure.
> > >
> > > I thought to build my maximal mixed model in which all the factors are
> > > crossed within subjects and only D is crossed within items (items are
> > > the same, repeated at different delays of stimulation):
> > >
> > > lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata,
> > > control=lmerControl(optCtrl=list(maxfun=1e6)))
> > >
> > > So, to answer @Robert Long: my factor D I was referring to is a random
> > > slope, with4 levels
> > >
> > > to answer at Ben Bolker:
> > > indeed I don't think that my factor D falls in the 2 cases you
> > > mentioned,
> > > because:
> > >  a) the differences between each level is not the same for each level
> > > (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time,
> > > we expect the effect to be present at one or more latencies depending
> > > on L;
> > > b) the factor has more than two levels.
> > >
> > > According to all of this, I should go for a CS model, right?
> > > I'm a newbie in this field, so can you please give me some indications
> > > of what can I read about it or some indications to understand how to
> > > handle this (especially if I want to reduce gradually the random
> > > structure of the subjects part, see modelreduced2)/?
> > >
> > > modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) +
> > > (1|items/D), data=mydata,
> > > control=lmerControl(optCtrl=list(maxfun=1e6)))
> > >
> > > modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) +
> > > (1|items/D), data=mydata,
> > > control=lmerControl(optCtrl=list(maxfun=1e6)))
> > >
> > >
> > > Another point: is this semplification indipendent of which type of
> > > contrast I set for D (I'll set sum contrast for V and L, but I'm still
> > > reasoning on what is the best for D)?
> > >
> > > Thank you in advance for this big help and please tell me if you need
> > > further clarifications or code.
> > >
> > >  Elisa Monaco | PhD student
> > > ________________________________________
> > > De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de
> > > la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet
> > > 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME]
> > > keeping both numerically and factor coded factors
> > >
> > >   Elisa,
> > >
> > >   Can you say a little more about what your factor represents?
> > >
> > >   It probably *doesn't* make sense to collapse your factor to an
> > > integer for the purpose of allowing a diagonal covariance matrix, unless:
> > >
> > >  * it's reasonable to treat the factor levels as sequential values
> > > with equal differences between each successive pair (e.g., time), OR
> > >  * the factor only has two levels anyway
> > >
> > >   Another simplifying strategy is to use a compound-symmetric model
> > > (equal correlations among all pairs of levels): if your original model
> > > is (f|g) (where f is a factor and g is your grouping variable), then
> > > (1|g/f) will generate a CS model.
> > >
> > >   cheers
> > >     Ben Bolker
> > >
> > >
> > > On 2019-07-22 10:24 a.m., Robert Long wrote:
> > > > Dear Elisa
> > > >
> > > > Is this factor a grouping variable (for random intercepts) or a
> > > > random slope ? How many levels does it have ? And lease can you give
> > > > us the full model formula.
> > > >
> > > >
> > > >
> > > > On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> > > > r-sig-mixed-models at r-project.org> wrote:
> > > >
> > > >> Dear list,
> > > >> looking at the correlation values of my random effects, as well as
> > > >> the fact that my model fails to converge, it makes sense to me to
> > > >> simplify
> > > its
> > > >> random structure (while keeping maximal and according to our hp the
> > > fixed
> > > >> structure).
> > > >> One way is to remove correlations, and I know that the || notation
> > > >> works only with numerically coded factors.
> > > >> As far as I understood, I have two options:
> > > >> 1) use the package afex, putting my model as object of mixed and
> > > >> adding "expand_re=true"
> > > >> 2) use the original factor, by default read as "int"
> > > >>
> > > >> I want to use the option 2) because with mixed I can't apply the
> > > >> PCA function for random effects to check if my model is over parameterized.
> > > >>
> > > >> My questions are:
> > > >> a)    is it true that I can use my factor as it is when read by R, i.e.
> > > >> "int"?
> > > >> b)    if yes, does it make sense to keep in the model both the factor in
> > > >> the nominal form as fixed effect and the factor in the numerical
> > > >> form as random effect?
> > > >>
> > > >> Many thanks for your help,
> > > >>
> > > >> Elisa Monaco | PhD student
> > > >>
> > > >>         [[alternative HTML version deleted]]
> > > >>
> > > >> _______________________________________________
> > > >> R-sig-mixed-models at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >>
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From g@59||j @end|ng |rom mytum@de  Wed Jul 31 14:10:34 2019
From: g@59||j @end|ng |rom mytum@de (Cueva, Jorge)
Date: Wed, 31 Jul 2019 12:10:34 +0000
Subject: [R-sig-ME] glmer.nb - interaction interpretation
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836C82EAE@FHSDB2D11-2.csu.mcmaster.ca>
References: <25056_1564508182_x6UHaKEO023599_2d6c6f0b6b714682bc8085bb5863901d@mytum.de>
 <ACD1644AA6C67E4FBD0C350625508EC836C82EAE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <161b2587a20d4c2db3fd8072f49e016c@mytum.de>

Dear John thank you so much for your support. I got the chart, it looks nice and the interpretation is easier!

Greetings

Jorge Cueva Ortiz

-----Original Message-----
From: Fox, John <jfox at mcmaster.ca> 
Sent: Tuesday, July 30, 2019 22:16
To: Cueva, Jorge <ga59lij at mytum.de>; r-sig-mixed-models at r-project.org
Subject: RE: glmer.nb - interaction interpretation

Dear Jorge,

You might try the predictorEffects() function in the effects package to visualize the interaction. In particular, and as a start, plot(predictorEffects(mod)), where mod is the model you wish to examine.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Cueva, Jorge
> Sent: Tuesday, July 30, 2019 10:34 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmer.nb - interaction interpretation
> 
> Dear all
> I hope to get support for interpreting a model. First, I am assessing 
> the natural regeneration in a dry forest. The design has 12 clusters 
> and each cluster includes 3 open and 3 fenced plots (a total of 36 
> open plots and 36 fenced plots), the open plots are separate from the excluded plots by only 20 meters.
> I want to know if livestock grazing affects the abundance of 
> regeneration, for this we collected excrements of animals, but a 
> single sample of excrements affects both the open and the fence plot.
> 
> Of all the models tested, the best was:
> glmer.nb(Ind ~ 1 + Equine * Treat + SPrec + Cattle + (1|Cluster), data 
> = BaseOb2, family=poisson, verbose=FALSE, 
> glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)))
> 
> Ind = number of individuals
> Equine = weight of equines excrements (horses + donkeys) Treat = 
> treatment (open and exclusion plots) SPrec = seasonal precipitation 
> Cattle = weight of cattle excrements Cluster = cluster was used as 
> random predictor because the samples were nested in the cluster.
> 
> My issue is when I want to interpret the effect of the predictors. 
> Here are the results
> 
> Fixed effects:
>                                               Estimate              Std. Error             z value
> Pr(>|z|)
> (Intercept)                          3.170153             0.246584             12.856                  <
> 2e-16 ***
> Equine                                 0.926521             0.233079             3.975
> 7.03e-05 ***
> Treatopen                          -0.009898            0.068965             -0.144
> 0.885875
> SPrec                                    0.390747             0.078133             5.001
> 5.70e-07 ***
> Cattle                                   -0.365988            0.184748             -1.981
> 0.047589 *
> Equine:Treatopen            -0.989678            0.274040             -3.611
> 0.000305 ***
> 
> It can be seen that the independent effect of Equine is significantly 
> positive and that of Treatopen non-significantly negative. 
> Interpretation of these would be easy, but my issue is the 
> Equine:Treatopen interaction. Why is the effect of Equine first 
> positive and then in the interaction negative? What does that mean?
> 
> Very grateful in advance.
> 
> Jorge Cueva Ortiz
> PhD Candidate
> Technical University of Munich
> 01631327886
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |ongrob604 @end|ng |rom gm@||@com  Thu Aug  1 16:02:31 2019
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Thu, 1 Aug 2019 15:02:31 +0100
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <75315dab4f4646f4b22df160f2a9622a@svw-exmb1.unifr.ch>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
 <75315dab4f4646f4b22df160f2a9622a@svw-exmb1.unifr.ch>
Message-ID: <CA+3TTkPHnPjKdFGuNq2bfKLZoj9Xx_Pyt86CyVSSWCB2nb5zJg@mail.gmail.com>

Dear Elisa,

Yes, one of the possible steps is to force correlations to zero, but then
you are imposing (possibly unreasonable) constraints at the cost of trying
to make the model converge. It is a highly questionable procedure to remove
something or impose constraints purely to cause a model to converge. Random
variables that arise in nature as part of the same data generating process
are rarely uncorrelated. It may be that the correlations are small and
/can/ reasonably be set to zero, but you should investigate whether this is
reasonable first.

Removing random slopes is usually a good way to proceed.

If you can't make progress this way you could try the rstanarm package
which provides a drop in replacement for lmer and will fit the model using
a Bayesian approach. Then, the convergence diagnostics should provide a
better way to solve the problem. It may be that one or more of the variance
components and/or correlations between them are close to zero, in which
case you can remove them from the random structure.


On Wed, 31 Jul 2019, 09:14 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:

> Thank you,
>
> Robert Long, I think we are claiming the same idea: the maximal model is
> too complex (overparameterized and with a degenerate/singular solution) and
> I want to reduce the random structure, following the steps suggested by
> Bates et al.. Am I correct?
> However one of these steps it's indeed "forcing to zero the correlation
> parameters" and check the good fit of the consequent model. Therefore my
> question on how to arrange my D factor in the random structure.
>
> I still don't know how to handle CS model suggested by Bolker ((1|g/f))
> and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any
> suggestions would be much appreciated!
>
> Elisa Monaco
>
>
> -----Message d'origine-----
> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la
> part de Robert Long
> Envoy? : mercredi, 24 juillet 2019 10:33
> ? : R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
>
> It is quite possible that such a complex random structure will not be
> supported by the data.
>
> In your initial email you mentioned correlations between random effects.
> However, since the model did not converge, there is no point in
> intetpreting them. Moreover, to force them to be uncorrelated is possibly
> making unrealistic constraints on the model.
>
> Why do seek such a complex random structure ? If you are following the
> advice by Barr et al (2013) to "keep it maximal", this is often very poor
> advice, as noted by Bates et al (2015), Bates being the primary author of
> the lme4 package:
>
> https://arxiv.org/pdf/1506.04967
>
>
>
>
>
>
>
>
> On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
>
> > Dear all,
> > many thanks for your answers and sorry for not providing the details.
> >
> > My experiment is a 2X2X4 within subject design, with all three factors
> > being categorical: L=Language of the stimuli (2 levels), V= type of
> > the stimuli (2 levels), D= delay of brain stimulation (4 levels). My
> > dependent variable is the amplitude of a physiological measure.
> >
> > I thought to build my maximal mixed model in which all the factors are
> > crossed within subjects and only D is crossed within items (items are
> > the same, repeated at different delays of stimulation):
> >
> > lmer(MEPzed ~ L * V * D + (L*V*D|subjects) + (D|items), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> > So, to answer @Robert Long: my factor D I was referring to is a random
> > slope, with4 levels
> >
> > to answer at Ben Bolker:
> > indeed I don't think that my factor D falls in the 2 cases you
> > mentioned,
> > because:
> >  a) the differences between each level is not the same for each level
> > (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time,
> > we expect the effect to be present at one or more latencies depending
> > on L;
> > b) the factor has more than two levels.
> >
> > According to all of this, I should go for a CS model, right?
> > I'm a newbie in this field, so can you please give me some indications
> > of what can I read about it or some indications to understand how to
> > handle this (especially if I want to reduce gradually the random
> > structure of the subjects part, see modelreduced2)/?
> >
> > modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) +
> > (1|items/D), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> > modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) +
> > (1|items/D), data=mydata,
> > control=lmerControl(optCtrl=list(maxfun=1e6)))
> >
> >
> > Another point: is this semplification indipendent of which type of
> > contrast I set for D (I'll set sum contrast for V and L, but I'm still
> > reasoning on what is the best for D)?
> >
> > Thank you in advance for this big help and please tell me if you need
> > further clarifications or code.
> >
> >  Elisa Monaco | PhD student
> > ________________________________________
> > De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de
> > la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet
> > 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME]
> > keeping both numerically and factor coded factors
> >
> >   Elisa,
> >
> >   Can you say a little more about what your factor represents?
> >
> >   It probably *doesn't* make sense to collapse your factor to an
> > integer for the purpose of allowing a diagonal covariance matrix, unless:
> >
> >  * it's reasonable to treat the factor levels as sequential values
> > with equal differences between each successive pair (e.g., time), OR
> >  * the factor only has two levels anyway
> >
> >   Another simplifying strategy is to use a compound-symmetric model
> > (equal correlations among all pairs of levels): if your original model
> > is (f|g) (where f is a factor and g is your grouping variable), then
> > (1|g/f) will generate a CS model.
> >
> >   cheers
> >     Ben Bolker
> >
> >
> > On 2019-07-22 10:24 a.m., Robert Long wrote:
> > > Dear Elisa
> > >
> > > Is this factor a grouping variable (for random intercepts) or a
> > > random slope ? How many levels does it have ? And lease can you give
> > > us the full model formula.
> > >
> > >
> > >
> > > On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
> > > r-sig-mixed-models at r-project.org> wrote:
> > >
> > >> Dear list,
> > >> looking at the correlation values of my random effects, as well as
> > >> the fact that my model fails to converge, it makes sense to me to
> > >> simplify
> > its
> > >> random structure (while keeping maximal and according to our hp the
> > fixed
> > >> structure).
> > >> One way is to remove correlations, and I know that the || notation
> > >> works only with numerically coded factors.
> > >> As far as I understood, I have two options:
> > >> 1) use the package afex, putting my model as object of mixed and
> > >> adding "expand_re=true"
> > >> 2) use the original factor, by default read as "int"
> > >>
> > >> I want to use the option 2) because with mixed I can't apply the
> > >> PCA function for random effects to check if my model is over
> parameterized.
> > >>
> > >> My questions are:
> > >> a)    is it true that I can use my factor as it is when read by R,
> i.e.
> > >> "int"?
> > >> b)    if yes, does it make sense to keep in the model both the factor
> in
> > >> the nominal form as fixed effect and the factor in the numerical
> > >> form as random effect?
> > >>
> > >> Many thanks for your help,
> > >>
> > >> Elisa Monaco | PhD student
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ben@95472 @end|ng |rom gm@||@com  Thu Aug  1 16:47:11 2019
From: ben@95472 @end|ng |rom gm@||@com (Ben Adams)
Date: Thu, 1 Aug 2019 16:47:11 +0200
Subject: [R-sig-ME] specify random effects in lme4
Message-ID: <CADJrNxSLdm4h2oQv6SiFz5h=2_scSpSaFX2zy+z=5yUd_1P_Eg@mail.gmail.com>

I would like to ask for your help in specifying the random effects of a
model I have been working on in lme4. I have data from a field survey. The
objective of the study is to relate wing size (respond variable) with
habitat (exploratory variable, categorical variable with 2 levels). We
performed a paired design by sampling 50 individuals of 3 species in a
simple habitat and the same 3 species (n=50 again) in a complex habitat in
a region. We replicated that in 20 regions. I am both interested in the
species specific effects and community effects. For running the analyses
per species is this model correct?

modela<-lmer(Wingsize~Habitat+(1|Region))

For community wise effects is this model correct?

modelb<-lmer(Wingsize~Habitat+(1|Region/Habitat/Species))

For a schematic check this
https://stats.stackexchange.com/questions/419693/specify-random-effects-in-lme4


Thank you in advance,


Ben

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Aug  1 19:38:02 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 1 Aug 2019 13:38:02 -0400
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <CA+3TTkPHnPjKdFGuNq2bfKLZoj9Xx_Pyt86CyVSSWCB2nb5zJg@mail.gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
 <75315dab4f4646f4b22df160f2a9622a@svw-exmb1.unifr.ch>
 <CA+3TTkPHnPjKdFGuNq2bfKLZoj9Xx_Pyt86CyVSSWCB2nb5zJg@mail.gmail.com>
Message-ID: <6309ff2b-e173-8989-8041-8b0957ec66ba@gmail.com>


  I generally agree with Robert's point of view - I don't *necessarily*
object to removing correlations, but you have to think carefully about
what it means.

  As to the question of "how should I put more than one factor into a
compound symmetric model"?: suppose you want to make (L*V*D|subjects)
compound symmetric.  You (unfortunately) have a variety of choices.  If
you really want all CS interactions represented, I think you need the
equivalent of (1|subjects/(L+V+D)^2) (which probably won't work as
written, i.e.

 (1|subjects) +
 (1|subjects:L) + (1|subjects:V) + (1|subjects:D) +
 (1|subjects:L:V) + (1|subjects:V:D) + (1|subjects:D:L)

(if you included the (1|subjects:L:V:D) term it would be redundant with
the residual error term).  This is getting complex again -- 7 parameters
(still much better than (L*V*D|subjects), which gives you (16*17)/2 =
136 parameters to estimate) ...

  I'm not sure rstanarm will solve your problems.  That is, I don't see
how the convergence diagnostics that rstanarm gives you are going to be
much more useful than lme4's in deciding how to simplify the problem.
On the other hand, rstanarm offers a big advantage in allowing you to
set priors to keep the solutions to the fitted problem more realistic -
it also integrates over the uncertainty in a useful way.

  [Robert: sorry if I missed or misconstrued something in your answer.
Could you be a little more specific in how you would use rstanarm's
output & diagnostics to help solve this kind of problem?]

 Ben Bolker



On 2019-08-01 10:02 a.m., Robert Long wrote:
> Dear Elisa,
> 
> Yes, one of the possible steps is to force correlations to zero, but then
> you are imposing (possibly unreasonable) constraints at the cost of trying
> to make the model converge. It is a highly questionable procedure to remove
> something or impose constraints purely to cause a model to converge. Random
> variables that arise in nature as part of the same data generating process
> are rarely uncorrelated. It may be that the correlations are small and
> /can/ reasonably be set to zero, but you should investigate whether this is
> reasonable first.
> 
> Removing random slopes is usually a good way to proceed.
> 
> If you can't make progress this way you could try the rstanarm package
> which provides a drop in replacement for lmer and will fit the model using
> a Bayesian approach. Then, the convergence diagnostics should provide a
> better way to solve the problem. It may be that one or more of the variance
> components and/or correlations between them are close to zero, in which
> case you can remove them from the random structure.
> 
> 
> On Wed, 31 Jul 2019, 09:14 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
> 
>> Thank you,
>>
>> Robert Long, I think we are claiming the same idea: the maximal model is
>> too complex (overparameterized and with a degenerate/singular solution) and
>> I want to reduce the random structure, following the steps suggested by
>> Bates et al.. Am I correct?
>> However one of these steps it's indeed "forcing to zero the correlation
>> parameters" and check the good fit of the consequent model. Therefore my
>> question on how to arrange my D factor in the random structure.
>>
>> I still don't know how to handle CS model suggested by Bolker ((1|g/f))
>> and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any
>> suggestions would be much appreciated!
>>
>> Elisa Monaco
>>
>>
>> -----Message d'origine-----
>> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la
>> part de Robert Long
>> Envoy? : mercredi, 24 juillet 2019 10:33
>> ? : R-mixed models mailing list <r-sig-mixed-models at r-project.org>
>> Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
>>
>> It is quite possible that such a complex random structure will not be
>> supported by the data.
>>
>> In your initial email you mentioned correlations between random effects.
>> However, since the model did not converge, there is no point in
>> intetpreting them. Moreover, to force them to be uncorrelated is possibly
>> making unrealistic constraints on the model.
>>
>> Why do seek such a complex random structure ? If you are following the
>> advice by Barr et al (2013) to "keep it maximal", this is often very poor
>> advice, as noted by Bates et al (2015), Bates being the primary author of
>> the lme4 package:
>>
>> https://arxiv.org/pdf/1506.04967
>>
>>
>>
>>
>>
>>
>>
>>
>> On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
>>
>>> Dear all,
>>> many thanks for your answers and sorry for not providing the details.
>>>
>>> My experiment is a 2X2X4 within subject design, with all three factors
>>> being categorical: L=Language of the stimuli (2 levels), V= type of
>>> the stimuli (2 levels), D= delay of brain stimulation (4 levels). My
>>> dependent variable is the amplitude of a physiological measure.
>>>
>>> I thought to build my maximal mixed model in which all the factors are
>>> crossed within subjects and only D is crossed within items (items are
>>> the same, repeated at different delays of stimulation):
>>>
>>> lmer(MEPzed ~ L * V * D  + (D|items), data=mydata,
>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>
>>> So, to answer @Robert Long: my factor D I was referring to is a random
>>> slope, with4 levels
>>>
>>> to answer at Ben Bolker:
>>> indeed I don't think that my factor D falls in the 2 cases you
>>> mentioned,
>>> because:
>>>  a) the differences between each level is not the same for each level
>>> (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time,
>>> we expect the effect to be present at one or more latencies depending
>>> on L;
>>> b) the factor has more than two levels.
>>>
>>> According to all of this, I should go for a CS model, right?
>>> I'm a newbie in this field, so can you please give me some indications
>>> of what can I read about it or some indications to understand how to
>>> handle this (especially if I want to reduce gradually the random
>>> structure of the subjects part, see modelreduced2)/?
>>>
>>> modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) +
>>> (1|items/D), data=mydata,
>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>
>>> modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) +
>>> (1|items/D), data=mydata,
>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>
>>>
>>> Another point: is this semplification indipendent of which type of
>>> contrast I set for D (I'll set sum contrast for V and L, but I'm still
>>> reasoning on what is the best for D)?
>>>
>>> Thank you in advance for this big help and please tell me if you need
>>> further clarifications or code.
>>>
>>>  Elisa Monaco | PhD student
>>> ________________________________________
>>> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de
>>> la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet
>>> 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME]
>>> keeping both numerically and factor coded factors
>>>
>>>   Elisa,
>>>
>>>   Can you say a little more about what your factor represents?
>>>
>>>   It probably *doesn't* make sense to collapse your factor to an
>>> integer for the purpose of allowing a diagonal covariance matrix, unless:
>>>
>>>  * it's reasonable to treat the factor levels as sequential values
>>> with equal differences between each successive pair (e.g., time), OR
>>>  * the factor only has two levels anyway
>>>
>>>   Another simplifying strategy is to use a compound-symmetric model
>>> (equal correlations among all pairs of levels): if your original model
>>> is (f|g) (where f is a factor and g is your grouping variable), then
>>> (1|g/f) will generate a CS model.
>>>
>>>   cheers
>>>     Ben Bolker
>>>
>>>
>>> On 2019-07-22 10:24 a.m., Robert Long wrote:
>>>> Dear Elisa
>>>>
>>>> Is this factor a grouping variable (for random intercepts) or a
>>>> random slope ? How many levels does it have ? And lease can you give
>>>> us the full model formula.
>>>>
>>>>
>>>>
>>>> On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
>>>> r-sig-mixed-models at r-project.org> wrote:
>>>>
>>>>> Dear list,
>>>>> looking at the correlation values of my random effects, as well as
>>>>> the fact that my model fails to converge, it makes sense to me to
>>>>> simplify
>>> its
>>>>> random structure (while keeping maximal and according to our hp the
>>> fixed
>>>>> structure).
>>>>> One way is to remove correlations, and I know that the || notation
>>>>> works only with numerically coded factors.
>>>>> As far as I understood, I have two options:
>>>>> 1) use the package afex, putting my model as object of mixed and
>>>>> adding "expand_re=true"
>>>>> 2) use the original factor, by default read as "int"
>>>>>
>>>>> I want to use the option 2) because with mixed I can't apply the
>>>>> PCA function for random effects to check if my model is over
>> parameterized.
>>>>>
>>>>> My questions are:
>>>>> a)    is it true that I can use my factor as it is when read by R,
>> i.e.
>>>>> "int"?
>>>>> b)    if yes, does it make sense to keep in the model both the factor
>> in
>>>>> the nominal form as fixed effect and the factor in the numerical
>>>>> form as random effect?
>>>>>
>>>>> Many thanks for your help,
>>>>>
>>>>> Elisa Monaco | PhD student
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Aug  2 13:47:27 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 2 Aug 2019 13:47:27 +0200
Subject: [R-sig-ME] keeping both numerically and factor coded factors
In-Reply-To: <6309ff2b-e173-8989-8041-8b0957ec66ba@gmail.com>
References: <1d0761b907e54fc1b565d9b9b202dbe1@svw-exmb1.unifr.ch>
 <CA+3TTkO=HiAi-4h892zV7dDQumtfEZS513LJ4Z1CPVwUM0-Luw@mail.gmail.com>
 <3d6964c5-f24a-63f7-bb86-c2d056901ed6@gmail.com> <1563955273507.838@unifr.ch>
 <CA+3TTkO13Lhoir8k9eawn0WaiG5eoJ3kkf1mn1zpHPcxnx7Ajw@mail.gmail.com>
 <75315dab4f4646f4b22df160f2a9622a@svw-exmb1.unifr.ch>
 <CA+3TTkPHnPjKdFGuNq2bfKLZoj9Xx_Pyt86CyVSSWCB2nb5zJg@mail.gmail.com>
 <6309ff2b-e173-8989-8041-8b0957ec66ba@gmail.com>
Message-ID: <81eb6fce-cf38-2fbd-a8d3-4e0b64202c5e@mpi.nl>

John Kruschke has a recent blog post highlighting how removing
correlations can drastically change your model.

http://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html

Again, I'm with everybody else here: I'm not opposed to "removing"
correlations per se, but you should be aware of what it means in terms
of your model, estimates, and interpretation.

Phillip

On 1/8/19 7:38 pm, Ben Bolker wrote:
> 
>   I generally agree with Robert's point of view - I don't *necessarily*
> object to removing correlations, but you have to think carefully about
> what it means.
> 
>   As to the question of "how should I put more than one factor into a
> compound symmetric model"?: suppose you want to make (L*V*D|subjects)
> compound symmetric.  You (unfortunately) have a variety of choices.  If
> you really want all CS interactions represented, I think you need the
> equivalent of (1|subjects/(L+V+D)^2) (which probably won't work as
> written, i.e.
> 
>  (1|subjects) +
>  (1|subjects:L) + (1|subjects:V) + (1|subjects:D) +
>  (1|subjects:L:V) + (1|subjects:V:D) + (1|subjects:D:L)
> 
> (if you included the (1|subjects:L:V:D) term it would be redundant with
> the residual error term).  This is getting complex again -- 7 parameters
> (still much better than (L*V*D|subjects), which gives you (16*17)/2 =
> 136 parameters to estimate) ...
> 
>   I'm not sure rstanarm will solve your problems.  That is, I don't see
> how the convergence diagnostics that rstanarm gives you are going to be
> much more useful than lme4's in deciding how to simplify the problem.
> On the other hand, rstanarm offers a big advantage in allowing you to
> set priors to keep the solutions to the fitted problem more realistic -
> it also integrates over the uncertainty in a useful way.
> 
>   [Robert: sorry if I missed or misconstrued something in your answer.
> Could you be a little more specific in how you would use rstanarm's
> output & diagnostics to help solve this kind of problem?]
> 
>  Ben Bolker
> 
> 
> 
> On 2019-08-01 10:02 a.m., Robert Long wrote:
>> Dear Elisa,
>>
>> Yes, one of the possible steps is to force correlations to zero, but then
>> you are imposing (possibly unreasonable) constraints at the cost of trying
>> to make the model converge. It is a highly questionable procedure to remove
>> something or impose constraints purely to cause a model to converge. Random
>> variables that arise in nature as part of the same data generating process
>> are rarely uncorrelated. It may be that the correlations are small and
>> /can/ reasonably be set to zero, but you should investigate whether this is
>> reasonable first.
>>
>> Removing random slopes is usually a good way to proceed.
>>
>> If you can't make progress this way you could try the rstanarm package
>> which provides a drop in replacement for lmer and will fit the model using
>> a Bayesian approach. Then, the convergence diagnostics should provide a
>> better way to solve the problem. It may be that one or more of the variance
>> components and/or correlations between them are close to zero, in which
>> case you can remove them from the random structure.
>>
>>
>> On Wed, 31 Jul 2019, 09:14 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
>>
>>> Thank you,
>>>
>>> Robert Long, I think we are claiming the same idea: the maximal model is
>>> too complex (overparameterized and with a degenerate/singular solution) and
>>> I want to reduce the random structure, following the steps suggested by
>>> Bates et al.. Am I correct?
>>> However one of these steps it's indeed "forcing to zero the correlation
>>> parameters" and check the good fit of the consequent model. Therefore my
>>> question on how to arrange my D factor in the random structure.
>>>
>>> I still don't know how to handle CS model suggested by Bolker ((1|g/f))
>>> and how to integrate more factors in that structure ((f1*f2|g/f3)?) ... any
>>> suggestions would be much appreciated!
>>>
>>> Elisa Monaco
>>>
>>>
>>> -----Message d'origine-----
>>> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> De la
>>> part de Robert Long
>>> Envoy? : mercredi, 24 juillet 2019 10:33
>>> ? : R-mixed models mailing list <r-sig-mixed-models at r-project.org>
>>> Objet : Re: [R-sig-ME] keeping both numerically and factor coded factors
>>>
>>> It is quite possible that such a complex random structure will not be
>>> supported by the data.
>>>
>>> In your initial email you mentioned correlations between random effects.
>>> However, since the model did not converge, there is no point in
>>> intetpreting them. Moreover, to force them to be uncorrelated is possibly
>>> making unrealistic constraints on the model.
>>>
>>> Why do seek such a complex random structure ? If you are following the
>>> advice by Barr et al (2013) to "keep it maximal", this is often very poor
>>> advice, as noted by Bates et al (2015), Bates being the primary author of
>>> the lme4 package:
>>>
>>> https://arxiv.org/pdf/1506.04967
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Wed, 24 Jul 2019, 09:01 MONACO Elisa, <elisa.monaco at unifr.ch> wrote:
>>>
>>>> Dear all,
>>>> many thanks for your answers and sorry for not providing the details.
>>>>
>>>> My experiment is a 2X2X4 within subject design, with all three factors
>>>> being categorical: L=Language of the stimuli (2 levels), V= type of
>>>> the stimuli (2 levels), D= delay of brain stimulation (4 levels). My
>>>> dependent variable is the amplitude of a physiological measure.
>>>>
>>>> I thought to build my maximal mixed model in which all the factors are
>>>> crossed within subjects and only D is crossed within items (items are
>>>> the same, repeated at different delays of stimulation):
>>>>
>>>> lmer(MEPzed ~ L * V * D  + (D|items), data=mydata,
>>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>>
>>>> So, to answer @Robert Long: my factor D I was referring to is a random
>>>> slope, with4 levels
>>>>
>>>> to answer at Ben Bolker:
>>>> indeed I don't think that my factor D falls in the 2 cases you
>>>> mentioned,
>>>> because:
>>>>  a) the differences between each level is not the same for each level
>>>> (150ms-75ms-75ms-150ms) and we don't expect en effect ordered in time,
>>>> we expect the effect to be present at one or more latencies depending
>>>> on L;
>>>> b) the factor has more than two levels.
>>>>
>>>> According to all of this, I should go for a CS model, right?
>>>> I'm a newbie in this field, so can you please give me some indications
>>>> of what can I read about it or some indications to understand how to
>>>> handle this (especially if I want to reduce gradually the random
>>>> structure of the subjects part, see modelreduced2)/?
>>>>
>>>> modelreduced1: lmer(MEPzed ~ L * V * D + (L*V*D|subjects) +
>>>> (1|items/D), data=mydata,
>>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>>
>>>> modelreduced2: lmer(MEPzed ~ L * V * D + (L*V|subjects/D) +
>>>> (1|items/D), data=mydata,
>>>> control=lmerControl(optCtrl=list(maxfun=1e6)))
>>>>
>>>>
>>>> Another point: is this semplification indipendent of which type of
>>>> contrast I set for D (I'll set sum contrast for V and L, but I'm still
>>>> reasoning on what is the best for D)?
>>>>
>>>> Thank you in advance for this big help and please tell me if you need
>>>> further clarifications or code.
>>>>
>>>>  Elisa Monaco | PhD student
>>>> ________________________________________
>>>> De : R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> de
>>>> la part de Ben Bolker <bbolker at gmail.com> Envoy? : lundi 22 juillet
>>>> 2019 17:56 ? : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME]
>>>> keeping both numerically and factor coded factors
>>>>
>>>>   Elisa,
>>>>
>>>>   Can you say a little more about what your factor represents?
>>>>
>>>>   It probably *doesn't* make sense to collapse your factor to an
>>>> integer for the purpose of allowing a diagonal covariance matrix, unless:
>>>>
>>>>  * it's reasonable to treat the factor levels as sequential values
>>>> with equal differences between each successive pair (e.g., time), OR
>>>>  * the factor only has two levels anyway
>>>>
>>>>   Another simplifying strategy is to use a compound-symmetric model
>>>> (equal correlations among all pairs of levels): if your original model
>>>> is (f|g) (where f is a factor and g is your grouping variable), then
>>>> (1|g/f) will generate a CS model.
>>>>
>>>>   cheers
>>>>     Ben Bolker
>>>>
>>>>
>>>> On 2019-07-22 10:24 a.m., Robert Long wrote:
>>>>> Dear Elisa
>>>>>
>>>>> Is this factor a grouping variable (for random intercepts) or a
>>>>> random slope ? How many levels does it have ? And lease can you give
>>>>> us the full model formula.
>>>>>
>>>>>
>>>>>
>>>>> On Mon, 22 Jul 2019, 12:17 MONACO Elisa via R-sig-mixed-models, <
>>>>> r-sig-mixed-models at r-project.org> wrote:
>>>>>
>>>>>> Dear list,
>>>>>> looking at the correlation values of my random effects, as well as
>>>>>> the fact that my model fails to converge, it makes sense to me to
>>>>>> simplify
>>>> its
>>>>>> random structure (while keeping maximal and according to our hp the
>>>> fixed
>>>>>> structure).
>>>>>> One way is to remove correlations, and I know that the || notation
>>>>>> works only with numerically coded factors.
>>>>>> As far as I understood, I have two options:
>>>>>> 1) use the package afex, putting my model as object of mixed and
>>>>>> adding "expand_re=true"
>>>>>> 2) use the original factor, by default read as "int"
>>>>>>
>>>>>> I want to use the option 2) because with mixed I can't apply the
>>>>>> PCA function for random effects to check if my model is over
>>> parameterized.
>>>>>>
>>>>>> My questions are:
>>>>>> a)    is it true that I can use my factor as it is when read by R,
>>> i.e.
>>>>>> "int"?
>>>>>> b)    if yes, does it make sense to keep in the model both the factor
>>> in
>>>>>> the nominal form as fixed effect and the factor in the numerical
>>>>>> form as random effect?
>>>>>>
>>>>>> Many thanks for your help,
>>>>>>
>>>>>> Elisa Monaco | PhD student
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  4 11:00:55 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 4 Aug 2019 21:00:55 +1200
Subject: [R-sig-ME] "General" (non-Bernoulli) binomial models in
 GLMMadaptive.
Message-ID: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>


I am just now launching forth into the use of the GLMMadaptive package.

As far as I can discern, from reading the help for mixed_model() and the 
vignette GLMMadaptive_basics, the package can only fit *Bernoulli* 
models in the binomial() family.  Is my reading correct?  Will more 
general binomial models be added in the future?

The only way that I can see as of the present, to fit a general model, 
is to replicated each row of the relevant data frame "nsucc"  and 
"nfail" times (where "nsucc" and "nfail" are the respective numbers of 
successes and failures corresponding to the given row).  The y-value 
corresponding to each of the "nsucc" replicates would be 1 and that 
corresponding to each of the "nfail" replicates would be 0.

While this strategy is, I guess, perfectly do-able, it seems to me to be 
somewhat wasteful and could lead to a data frame of unwieldy size if the 
numbers of trials in the original data were at all large.

My other thought was to take y to be the *proportion* of successes and 
set a weights argument equal to the number of trials (as one can 
apparently do with glm() --- I've never actually tried this!).  However 
it seems that mixed_model() does not have a "weights" argument.

Advice gratefully received.

cheers,

Rolf

Added in press ( :-) ): I have just discovered that mixed_model() in the 
"development version" of GLMMadaptive, on github, *does* have a weights 
argument. I shall now install the development version and experiment.

I would however still appreciate comments and advice.  E.g. will the 
weights argument in mixed_model() work in the way that I am hoping?  Is 
this the recommended approach to fitting a "general" binomial model?

Thanks.

R.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Sun Aug  4 12:10:33 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Sun, 4 Aug 2019 10:10:33 +0000
Subject: [R-sig-ME] "General" (non-Bernoulli) binomial models in
 GLMMadaptive.
In-Reply-To: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>
References: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>
Message-ID: <5204eb5dff0a42dab6b5aee87f6b129e@erasmusmc.nl>

The current CRAN version of GLMMadaptive should work for binomial data. For example, this run in my machine:

library("GLMMadaptive")
library("lme4")
system.time(fm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
             data = cbpp, family = binomial, nAGQ = 21))

system.time(gm1 <- mixed_model(cbind(incidence, size - incidence) ~ period, random = ~ 1 | herd,
                   data = cbpp, family = binomial(), nAGQ = 21))


summary(fm1)
summary(gm1)

Best,
Dimitris


-----Original Message-----
From: Rolf Turner <r.turner at auckland.ac.nz> 
Sent: Sunday, August 4, 2019 11:01 AM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: "General" (non-Bernoulli) binomial models in GLMMadaptive.


I am just now launching forth into the use of the GLMMadaptive package.

As far as I can discern, from reading the help for mixed_model() and the vignette GLMMadaptive_basics, the package can only fit *Bernoulli* models in the binomial() family.  Is my reading correct?  Will more general binomial models be added in the future?

The only way that I can see as of the present, to fit a general model, is to replicated each row of the relevant data frame "nsucc"  and "nfail" times (where "nsucc" and "nfail" are the respective numbers of successes and failures corresponding to the given row).  The y-value corresponding to each of the "nsucc" replicates would be 1 and that corresponding to each of the "nfail" replicates would be 0.

While this strategy is, I guess, perfectly do-able, it seems to me to be somewhat wasteful and could lead to a data frame of unwieldy size if the numbers of trials in the original data were at all large.

My other thought was to take y to be the *proportion* of successes and set a weights argument equal to the number of trials (as one can apparently do with glm() --- I've never actually tried this!).  However it seems that mixed_model() does not have a "weights" argument.

Advice gratefully received.

cheers,

Rolf

Added in press ( :-) ): I have just discovered that mixed_model() in the "development version" of GLMMadaptive, on github, *does* have a weights argument. I shall now install the development version and experiment.

I would however still appreciate comments and advice.  E.g. will the weights argument in mixed_model() work in the way that I am hoping?  Is this the recommended approach to fitting a "general" binomial model?

Thanks.

R.

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  4 13:16:10 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 4 Aug 2019 23:16:10 +1200
Subject: [R-sig-ME] "General" (non-Bernoulli) binomial models in
 GLMMadaptive.
In-Reply-To: <5204eb5dff0a42dab6b5aee87f6b129e@erasmusmc.nl>
References: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>
 <5204eb5dff0a42dab6b5aee87f6b129e@erasmusmc.nl>
Message-ID: <12e22c2c-ccfe-ac40-e17b-ee9785835e45@auckland.ac.nz>


On 4/08/19 10:10 PM, D. Rizopoulos wrote:

> The current CRAN version of GLMMadaptive should work for binomial data.
> For example, this run in my machine:
> 
> library("GLMMadaptive")
> library("lme4")
> system.time(fm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>               data = cbpp, family = binomial, nAGQ = 21))
> 
> system.time(gm1 <- mixed_model(cbind(incidence, size - incidence) ~ period, random = ~ 1 | herd,
>                     data = cbpp, family = binomial(), nAGQ = 21))
> 
> 
> summary(fm1)
> summary(gm1)

Thanks very much for this.  And whew! That's a relief, since neither of 
my proposed work-arounds seems to work worth a damn.

May I just ask a quick (said he, optimistically) follow-up question? 
Can you provide a rationale for the choice of nAGQ = 21?  (If this would 
require a lengthy discourse, don't worry about it.)

cheers,

Rolf

P.S.  I gather, from an off-list OOO response that I received, that
you are on a conference/vacation trip.  My apologies for pestering you 
under these circumstances. I hope that you are having an enjoyable time.

R.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Sun Aug  4 14:28:11 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Sun, 4 Aug 2019 12:28:11 +0000
Subject: [R-sig-ME] "General" (non-Bernoulli) binomial models in
 GLMMadaptive.
In-Reply-To: <12e22c2c-ccfe-ac40-e17b-ee9785835e45@auckland.ac.nz>
References: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>
 <5204eb5dff0a42dab6b5aee87f6b129e@erasmusmc.nl>,
 <12e22c2c-ccfe-ac40-e17b-ee9785835e45@auckland.ac.nz>
Message-ID: <240fbc491de548c7b4abd2395842c8aa@erasmusmc.nl>

In general, the more quadrature points you use the better the approximation of the log-likelihood at the expense of computational time. The order of the approximation is improved every two quadrature points you add. Hence, you start at 1 (equivalent to Laplace approximation), and you go 3, 5, etc.

For more info check Section 5.3 of my course notes (http://www.drizopoulos.com/courses/EMC/CE08.pdf), and also this thesis: https://macsphere.mcmaster.ca/handle/11375/17272

Best,
Dimitris

From: Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>
Date: Sunday, 04 Aug 2019, 2:16 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: "General" (non-Bernoulli) binomial models in GLMMadaptive.


On 4/08/19 10:10 PM, D. Rizopoulos wrote:

> The current CRAN version of GLMMadaptive should work for binomial data.
> For example, this run in my machine:
>
> library("GLMMadaptive")
> library("lme4")
> system.time(fm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>               data = cbpp, family = binomial, nAGQ = 21))
>
> system.time(gm1 <- mixed_model(cbind(incidence, size - incidence) ~ period, random = ~ 1 | herd,
>                     data = cbpp, family = binomial(), nAGQ = 21))
>
>
> summary(fm1)
> summary(gm1)

Thanks very much for this.  And whew! That's a relief, since neither of
my proposed work-arounds seems to work worth a damn.

May I just ask a quick (said he, optimistically) follow-up question?
Can you provide a rationale for the choice of nAGQ = 21?  (If this would
require a lengthy discourse, don't worry about it.)

cheers,

Rolf

P.S.  I gather, from an off-list OOO response that I received, that
you are on a conference/vacation trip.  My apologies for pestering you
under these circumstances. I hope that you are having an enjoyable time.

R.

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  4 23:53:37 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 5 Aug 2019 09:53:37 +1200
Subject: [R-sig-ME] "General" (non-Bernoulli) binomial models in
 GLMMadaptive.
In-Reply-To: <240fbc491de548c7b4abd2395842c8aa@erasmusmc.nl>
References: <43f2096c-ac05-f7ce-124c-d7027d5da630@auckland.ac.nz>
 <5204eb5dff0a42dab6b5aee87f6b129e@erasmusmc.nl>
 <12e22c2c-ccfe-ac40-e17b-ee9785835e45@auckland.ac.nz>
 <240fbc491de548c7b4abd2395842c8aa@erasmusmc.nl>
Message-ID: <838fcc20-7e02-7423-2697-077e9cb5bfc7@auckland.ac.nz>


On 5/08/19 12:28 AM, D. Rizopoulos wrote:

> In general, the more quadrature points you use the better the 
> approximation of the log-likelihood at the expense of computational 
> time. The order of the approximation is improved every two quadrature 
> points you add. Hence, you start at 1 (equivalent to Laplace 
> approximation), and you go 3, 5, etc.
> 
> For more info check Section 5.3 of my course notes 
> (http://www.drizopoulos.com/courses/EMC/CE08.pdf), and also this thesis: 
> https://macsphere.mcmaster.ca/handle/11375/17272

That's clear and succinct!  Thanks very much.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Mon Aug  5 10:57:06 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Mon, 5 Aug 2019 10:57:06 +0200
Subject: [R-sig-ME] glmer: order of variables drastically influences SE
Message-ID: <CAENiVe-QGijHYwKkigYWDM3ShHTAoyaWzDmjYCV31GUOpyFe5A@mail.gmail.com>

Hello everyone,

Could anyone explain to me how the order of variables in the glmer function
could affect the standard error of the estimates? The difference is drastic
in my case (see the two model outputs at the bottom of the email)...
The data I used comes from a 3 way factorial experiment (tillage,
N=nitrogen, CC=cover crop species) on which an additional covariate was
measured (dry_bio_cover_m2).
My main objective is to identify the drivers of weed biomass in different
cover crop.
I came across the situation doing the following:

*1. fitting full model*
mod_full_CC=glmer(dry_bio_weeds_m2+0.001~block+year+scale(dry_bio_cover_m2)*tillage*N*CC+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="nloptwrap",optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")),data=biomassCC_wo_C)

*2. identifying the most parcimonious model*
dred_CC=dredge(mod_full_CC,rank="AICc",fixed=c("block","year"))

The most parcimonious model resulting from dredge (i.e. get.models(dred_CC,
1)[[1]] ) was:
dry_bio_weeds_m2 + 0.001 ~ *CC + N + scale(dry_bio_cover_m2) +  tillage +
block + year *+
    (1 | block:tillage) + (1 | block:tillage:N) + (1 | block:tillage:N:CC)
+ (1 | block:year) + (1 | block:year:tillage) + (1 | block:year:tillage:N)
+ (1 | block:year:tillage:N:CC) +
   * CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
scale(dry_bio_cover_m2):tillage*

If I refit this model in a different (more logical) order with the same
variables, as followed,
dry_bio_weeds_m2 + 0.001 ~* block + year + scale(dry_bio_cover_m2) +
tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2) +
tillage:scale(dry_bio_cover_m2)* +
(1 | block:tillage) + (1 | block:tillage:N) + (1 | block:tillage:N:CC) + (1
| block:year) + (1 | block:year:tillage) + (1 | block:year:tillage:N) + (1
|  block:year:tillage:N:CC)
I obtain similar estimates but drastically different SE, which of course
impacts post-hoc analysis.


The condition number of both models is also slightly different (12.1 for
the model with the variables in the order returned by dredge and 14.3 for
the model with the "logical" order), although no severe collinearity was
detected.



Model with variables fitted in the order given by dredge:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: gaussian  ( sqrt )
Formula: dry_bio_weeds_m2 + 0.001 ~ CC + N + scale(dry_bio_cover_m2) +
     tillage + block + year + (1 | block:tillage) + (1 |
block:tillage:N) +
    (1 | block:tillage:N:CC) + (1 | block:year) + (1 |
block:year:tillage) +      (1 | block:year:tillage:N) + (1 |
block:year:tillage:N:CC) +
    CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
scale(dry_bio_cover_m2):tillage
   Data: biomassCC_wo_C
Control: glmerControl(optimizer = "nloptwrap", optCtrl =
list(algorithm = "NLOPT_LN_NELDERMEAD"))

     AIC      BIC   logLik deviance df.resid
  6294.5   6416.4  -3116.2   6232.5      347

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.7837 -0.5006 -0.0011  0.5075  4.7593

Random effects:
 Groups                  Name        Variance  Std.Dev.
 block:year:tillage:N:CC (Intercept) 3.061e+04 1.750e+02
 block:tillage:N:CC      (Intercept) 2.162e-05 4.650e-03
 block:year:tillage:N    (Intercept) 2.645e-05 5.143e-03
 block:tillage:N         (Intercept) 2.125e+01 4.610e+00
 block:year:tillage      (Intercept) 4.656e-03 6.823e-02
 block:year              (Intercept) 3.848e+02 1.962e+01
 block:tillage           (Intercept) 4.204e-04 2.050e-02
 Residual                            4.505e+03 6.712e+01
Number of obs: 378, groups:
block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
block:year, 8; block:tillage, 8

Fixed effects:
                                   Estimate Std. Error   t value Pr(>|z|)
(Intercept)                       13.829033   0.001353 10219.154  < 2e-16 ***
CCVv                              -0.064097   0.001353   -47.367  < 2e-16 ***
CCTs                               0.059189   0.001353    43.739  < 2e-16 ***
N.L                                5.506568   0.001310  4202.646  < 2e-16 ***
N.Q                               -0.387064   0.001310  -295.407  < 2e-16 ***
N.C                               -0.123713   0.001310   -94.417  < 2e-16 ***
scale(dry_bio_cover_m2)           -3.096732   0.001309 -2366.243  < 2e-16 ***
tillageRT                         -0.034498   0.001310   -26.329  < 2e-16 ***
blockR2                           -1.369223   0.464429    -2.948   0.0032 **
blockR3                           -0.897212   0.001353  -663.006  < 2e-16 ***
blockR4                            0.536253   0.464366     1.155   0.2482
year2014                           0.484093   0.350696     1.380   0.1675
CCVv:N.L                          -3.795768   0.652249    -5.820 5.90e-09 ***
CCTs:N.L                          -3.760854   0.652139    -5.767 8.07e-09 ***
CCVv:N.Q                          -0.630917   0.652215    -0.967   0.3334
CCTs:N.Q                          -0.258428   0.652139    -0.396   0.6919
CCVv:N.C                           0.857098   0.652113     1.314   0.1887
CCTs:N.C                           0.273846   0.652088     0.420   0.6745
CCVv:scale(dry_bio_cover_m2)      -2.834524   0.001310 -2163.350  < 2e-16 ***
CCTs:scale(dry_bio_cover_m2)      -2.564852   0.001401 -1831.105  < 2e-16 ***
CCVv:tillageRT                     4.446872   0.001401  3174.709  < 2e-16 ***
CCTs:tillageRT                     2.758362   0.001401  1969.252  < 2e-16 ***
scale(dry_bio_cover_m2):tillageRT  2.022118   0.001310  1543.318  < 2e-16 ***








Model with variables fitted in "logical" order:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: gaussian  ( sqrt )
Formula: dry_bio_weeds_m2 + 0.001 ~ block + year + scale(dry_bio_cover_m2) +
    tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2)
+      tillage:scale(dry_bio_cover_m2) + (1 | block:tillage) + (1 |
    block:tillage:N) + (1 | block:tillage:N:CC) + (1 | block:year) +
   (1 | block:year:tillage) + (1 | block:year:tillage:N) + (1 |
    block:year:tillage:N:CC)
   Data: biomassCC_wo_C
Control: glmerControl(optimizer = "nloptwrap", optCtrl =
list(algorithm = "NLOPT_LN_NELDERMEAD"))

     AIC      BIC   logLik deviance df.resid
  6294.5   6416.4  -3116.2   6232.5      347

Scaled residuals:
    Min      1Q  Median      3Q     Max
-4.7838 -0.5009 -0.0011  0.5075  4.7594

Random effects:
 Groups                  Name        Variance  Std.Dev.
 block:year:tillage:N:CC (Intercept) 3.061e+04 1.749e+02
 block:tillage:N:CC      (Intercept) 2.141e-05 4.627e-03
 block:year:tillage:N    (Intercept) 2.605e-05 5.104e-03
 block:tillage:N         (Intercept) 2.106e+01 4.589e+00
 block:year:tillage      (Intercept) 4.487e-03 6.699e-02
 block:year              (Intercept) 3.822e+02 1.955e+01
 block:tillage           (Intercept) 4.228e-04 2.056e-02
 Residual                            4.504e+03 6.711e+01
Number of obs: 378, groups:
block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
block:year, 8; block:tillage, 8

Fixed effects:
                                  Estimate Std. Error t value Pr(>|z|)
(Intercept)                       13.82995   42.86352   0.323  0.74696
blockR2                           -1.36672   40.78008  -0.034  0.97326
blockR3                           -0.89843   40.78048  -0.022  0.98242
blockR4                            0.53355   40.77879   0.013  0.98956
year2014                           0.48290   28.79334   0.017  0.98662
scale(dry_bio_cover_m2)           -3.09673    0.81313  -3.808  0.00014 ***
tillageRT                         -0.03537   43.77607  -0.001  0.99936
N.L                                5.50829   43.77552   0.126  0.89987
N.Q                               -0.38899   43.77300  -0.009  0.99291
N.C                               -0.12513   43.77337  -0.003  0.99772
CCVv                              -0.06447   43.74925  -0.001  0.99882
CCTs                               0.05444   43.75387   0.001  0.99901
N.L:CCVv                          -3.79754   61.86354  -0.061  0.95105
N.Q:CCVv                          -0.62820   61.86055  -0.010  0.99190
N.C:CCVv                           0.86704   61.85967   0.014  0.98882
N.L:CCTs                          -3.76680   61.86056  -0.061  0.95145
N.Q:CCTs                          -0.25653   61.85857  -0.004  0.99669
N.C:CCTs                           0.27781   61.85861   0.004  0.99642
tillageRT:CCVv                     4.44671   61.86316   0.072  0.94270
tillageRT:CCTs                     2.75968   61.86792   0.045  0.96442
scale(dry_bio_cover_m2):CCVv      -2.83780    0.93223  -3.044  0.00233 **
scale(dry_bio_cover_m2):CCTs      -2.56887    1.32152  -1.944  0.05191 .
scale(dry_bio_cover_m2):tillageRT  2.02139    0.85983   2.351  0.01873 *


I can share the data if need be. Thank you very much for your help.

Sincerely,

Guillaume ADEUX

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Aug  5 21:26:02 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 5 Aug 2019 15:26:02 -0400
Subject: [R-sig-ME] glmer: order of variables drastically influences SE
In-Reply-To: <CAENiVe-QGijHYwKkigYWDM3ShHTAoyaWzDmjYCV31GUOpyFe5A@mail.gmail.com>
References: <CAENiVe-QGijHYwKkigYWDM3ShHTAoyaWzDmjYCV31GUOpyFe5A@mail.gmail.com>
Message-ID: <e6634850-dcb1-53a8-d726-e5a535883731@gmail.com>


  Similar problems have come up before:

https://github.com/lme4/lme4/issues/449

  It would be great to have data to look at (best of all would be
posting it somewhere and linking to it as a comment in the issue/URL
listed above ...

On 2019-08-05 4:57 a.m., Guillaume Adeux wrote:
> Hello everyone,
> 
> Could anyone explain to me how the order of variables in the glmer function
> could affect the standard error of the estimates? The difference is drastic
> in my case (see the two model outputs at the bottom of the email)...
> The data I used comes from a 3 way factorial experiment (tillage,
> N=nitrogen, CC=cover crop species) on which an additional covariate was
> measured (dry_bio_cover_m2).
> My main objective is to identify the drivers of weed biomass in different
> cover crop.
> I came across the situation doing the following:
> 
> *1. fitting full model*
> mod_full_CC=glmer(dry_bio_weeds_m2+0.001~block+year+scale(dry_bio_cover_m2)*tillage*N*CC+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="nloptwrap",optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")),data=biomassCC_wo_C)
> 
> *2. identifying the most parcimonious model*
> dred_CC=dredge(mod_full_CC,rank="AICc",fixed=c("block","year"))
> 
> The most parcimonious model resulting from dredge (i.e. get.models(dred_CC,
> 1)[[1]] ) was:
> dry_bio_weeds_m2 + 0.001 ~ *CC + N + scale(dry_bio_cover_m2) +  tillage +
> block + year *+
>     (1 | block:tillage) + (1 | block:tillage:N) + (1 | block:tillage:N:CC)
> + (1 | block:year) + (1 | block:year:tillage) + (1 | block:year:tillage:N)
> + (1 | block:year:tillage:N:CC) +
>    * CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
> scale(dry_bio_cover_m2):tillage*
> 
> If I refit this model in a different (more logical) order with the same
> variables, as followed,
> dry_bio_weeds_m2 + 0.001 ~* block + year + scale(dry_bio_cover_m2) +
> tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2) +
> tillage:scale(dry_bio_cover_m2)* +
> (1 | block:tillage) + (1 | block:tillage:N) + (1 | block:tillage:N:CC) + (1
> | block:year) + (1 | block:year:tillage) + (1 | block:year:tillage:N) + (1
> |  block:year:tillage:N:CC)
> I obtain similar estimates but drastically different SE, which of course
> impacts post-hoc analysis.
> 
> 
> The condition number of both models is also slightly different (12.1 for
> the model with the variables in the order returned by dredge and 14.3 for
> the model with the "logical" order), although no severe collinearity was
> detected.
> 
> 
> 
> Model with variables fitted in the order given by dredge:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: gaussian  ( sqrt )
> Formula: dry_bio_weeds_m2 + 0.001 ~ CC + N + scale(dry_bio_cover_m2) +
>      tillage + block + year + (1 | block:tillage) + (1 |
> block:tillage:N) +
>     (1 | block:tillage:N:CC) + (1 | block:year) + (1 |
> block:year:tillage) +      (1 | block:year:tillage:N) + (1 |
> block:year:tillage:N:CC) +
>     CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
> scale(dry_bio_cover_m2):tillage
>    Data: biomassCC_wo_C
> Control: glmerControl(optimizer = "nloptwrap", optCtrl =
> list(algorithm = "NLOPT_LN_NELDERMEAD"))
> 
>      AIC      BIC   logLik deviance df.resid
>   6294.5   6416.4  -3116.2   6232.5      347
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.7837 -0.5006 -0.0011  0.5075  4.7593
> 
> Random effects:
>  Groups                  Name        Variance  Std.Dev.
>  block:year:tillage:N:CC (Intercept) 3.061e+04 1.750e+02
>  block:tillage:N:CC      (Intercept) 2.162e-05 4.650e-03
>  block:year:tillage:N    (Intercept) 2.645e-05 5.143e-03
>  block:tillage:N         (Intercept) 2.125e+01 4.610e+00
>  block:year:tillage      (Intercept) 4.656e-03 6.823e-02
>  block:year              (Intercept) 3.848e+02 1.962e+01
>  block:tillage           (Intercept) 4.204e-04 2.050e-02
>  Residual                            4.505e+03 6.712e+01
> Number of obs: 378, groups:
> block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
> block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
> block:year, 8; block:tillage, 8
> 
> Fixed effects:
>                                    Estimate Std. Error   t value Pr(>|z|)
> (Intercept)                       13.829033   0.001353 10219.154  < 2e-16 ***
> CCVv                              -0.064097   0.001353   -47.367  < 2e-16 ***
> CCTs                               0.059189   0.001353    43.739  < 2e-16 ***
> N.L                                5.506568   0.001310  4202.646  < 2e-16 ***
> N.Q                               -0.387064   0.001310  -295.407  < 2e-16 ***
> N.C                               -0.123713   0.001310   -94.417  < 2e-16 ***
> scale(dry_bio_cover_m2)           -3.096732   0.001309 -2366.243  < 2e-16 ***
> tillageRT                         -0.034498   0.001310   -26.329  < 2e-16 ***
> blockR2                           -1.369223   0.464429    -2.948   0.0032 **
> blockR3                           -0.897212   0.001353  -663.006  < 2e-16 ***
> blockR4                            0.536253   0.464366     1.155   0.2482
> year2014                           0.484093   0.350696     1.380   0.1675
> CCVv:N.L                          -3.795768   0.652249    -5.820 5.90e-09 ***
> CCTs:N.L                          -3.760854   0.652139    -5.767 8.07e-09 ***
> CCVv:N.Q                          -0.630917   0.652215    -0.967   0.3334
> CCTs:N.Q                          -0.258428   0.652139    -0.396   0.6919
> CCVv:N.C                           0.857098   0.652113     1.314   0.1887
> CCTs:N.C                           0.273846   0.652088     0.420   0.6745
> CCVv:scale(dry_bio_cover_m2)      -2.834524   0.001310 -2163.350  < 2e-16 ***
> CCTs:scale(dry_bio_cover_m2)      -2.564852   0.001401 -1831.105  < 2e-16 ***
> CCVv:tillageRT                     4.446872   0.001401  3174.709  < 2e-16 ***
> CCTs:tillageRT                     2.758362   0.001401  1969.252  < 2e-16 ***
> scale(dry_bio_cover_m2):tillageRT  2.022118   0.001310  1543.318  < 2e-16 ***
> 
> 
> 
> 
> 
> 
> 
> 
> Model with variables fitted in "logical" order:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: gaussian  ( sqrt )
> Formula: dry_bio_weeds_m2 + 0.001 ~ block + year + scale(dry_bio_cover_m2) +
>     tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2)
> +      tillage:scale(dry_bio_cover_m2) + (1 | block:tillage) + (1 |
>     block:tillage:N) + (1 | block:tillage:N:CC) + (1 | block:year) +
>    (1 | block:year:tillage) + (1 | block:year:tillage:N) + (1 |
>     block:year:tillage:N:CC)
>    Data: biomassCC_wo_C
> Control: glmerControl(optimizer = "nloptwrap", optCtrl =
> list(algorithm = "NLOPT_LN_NELDERMEAD"))
> 
>      AIC      BIC   logLik deviance df.resid
>   6294.5   6416.4  -3116.2   6232.5      347
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -4.7838 -0.5009 -0.0011  0.5075  4.7594
> 
> Random effects:
>  Groups                  Name        Variance  Std.Dev.
>  block:year:tillage:N:CC (Intercept) 3.061e+04 1.749e+02
>  block:tillage:N:CC      (Intercept) 2.141e-05 4.627e-03
>  block:year:tillage:N    (Intercept) 2.605e-05 5.104e-03
>  block:tillage:N         (Intercept) 2.106e+01 4.589e+00
>  block:year:tillage      (Intercept) 4.487e-03 6.699e-02
>  block:year              (Intercept) 3.822e+02 1.955e+01
>  block:tillage           (Intercept) 4.228e-04 2.056e-02
>  Residual                            4.504e+03 6.711e+01
> Number of obs: 378, groups:
> block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
> block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
> block:year, 8; block:tillage, 8
> 
> Fixed effects:
>                                   Estimate Std. Error t value Pr(>|z|)
> (Intercept)                       13.82995   42.86352   0.323  0.74696
> blockR2                           -1.36672   40.78008  -0.034  0.97326
> blockR3                           -0.89843   40.78048  -0.022  0.98242
> blockR4                            0.53355   40.77879   0.013  0.98956
> year2014                           0.48290   28.79334   0.017  0.98662
> scale(dry_bio_cover_m2)           -3.09673    0.81313  -3.808  0.00014 ***
> tillageRT                         -0.03537   43.77607  -0.001  0.99936
> N.L                                5.50829   43.77552   0.126  0.89987
> N.Q                               -0.38899   43.77300  -0.009  0.99291
> N.C                               -0.12513   43.77337  -0.003  0.99772
> CCVv                              -0.06447   43.74925  -0.001  0.99882
> CCTs                               0.05444   43.75387   0.001  0.99901
> N.L:CCVv                          -3.79754   61.86354  -0.061  0.95105
> N.Q:CCVv                          -0.62820   61.86055  -0.010  0.99190
> N.C:CCVv                           0.86704   61.85967   0.014  0.98882
> N.L:CCTs                          -3.76680   61.86056  -0.061  0.95145
> N.Q:CCTs                          -0.25653   61.85857  -0.004  0.99669
> N.C:CCTs                           0.27781   61.85861   0.004  0.99642
> tillageRT:CCVv                     4.44671   61.86316   0.072  0.94270
> tillageRT:CCTs                     2.75968   61.86792   0.045  0.96442
> scale(dry_bio_cover_m2):CCVv      -2.83780    0.93223  -3.044  0.00233 **
> scale(dry_bio_cover_m2):CCTs      -2.56887    1.32152  -1.944  0.05191 .
> scale(dry_bio_cover_m2):tillageRT  2.02139    0.85983   2.351  0.01873 *
> 
> 
> I can share the data if need be. Thank you very much for your help.
> 
> Sincerely,
> 
> Guillaume ADEUX
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Tue Aug  6 09:33:18 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Tue, 6 Aug 2019 09:33:18 +0200
Subject: [R-sig-ME] glmer: order of variables drastically influences SE
In-Reply-To: <e6634850-dcb1-53a8-d726-e5a535883731@gmail.com>
References: <CAENiVe-QGijHYwKkigYWDM3ShHTAoyaWzDmjYCV31GUOpyFe5A@mail.gmail.com>
 <e6634850-dcb1-53a8-d726-e5a535883731@gmail.com>
Message-ID: <CAENiVe9ddg2PjBWUrJLO-hu6kb_WqoJc3YG7s5C==YNyy4v5hQ@mail.gmail.com>

Hi Ben,

Thanks for your answer and the link.

I posted the data on figshare and linked it to my comment on the GitHub
issue.

Don't hesitate if you need more information.

Sincerely,

Guillaume ADEUX

Le lun. 5 ao?t 2019 ? 21:26, Ben Bolker <bbolker at gmail.com> a ?crit :

>
>   Similar problems have come up before:
>
> https://github.com/lme4/lme4/issues/449
>
>   It would be great to have data to look at (best of all would be
> posting it somewhere and linking to it as a comment in the issue/URL
> listed above ...
>
> On 2019-08-05 4:57 a.m., Guillaume Adeux wrote:
> > Hello everyone,
> >
> > Could anyone explain to me how the order of variables in the glmer
> function
> > could affect the standard error of the estimates? The difference is
> drastic
> > in my case (see the two model outputs at the bottom of the email)...
> > The data I used comes from a 3 way factorial experiment (tillage,
> > N=nitrogen, CC=cover crop species) on which an additional covariate was
> > measured (dry_bio_cover_m2).
> > My main objective is to identify the drivers of weed biomass in different
> > cover crop.
> > I came across the situation doing the following:
> >
> > *1. fitting full model*
> >
> mod_full_CC=glmer(dry_bio_weeds_m2+0.001~block+year+scale(dry_bio_cover_m2)*tillage*N*CC+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="nloptwrap",optCtrl=list(algorithm="NLOPT_LN_NELDERMEAD")),data=biomassCC_wo_C)
> >
> > *2. identifying the most parcimonious model*
> > dred_CC=dredge(mod_full_CC,rank="AICc",fixed=c("block","year"))
> >
> > The most parcimonious model resulting from dredge (i.e.
> get.models(dred_CC,
> > 1)[[1]] ) was:
> > dry_bio_weeds_m2 + 0.001 ~ *CC + N + scale(dry_bio_cover_m2) +  tillage +
> > block + year *+
> >     (1 | block:tillage) + (1 | block:tillage:N) + (1 |
> block:tillage:N:CC)
> > + (1 | block:year) + (1 | block:year:tillage) + (1 |
> block:year:tillage:N)
> > + (1 | block:year:tillage:N:CC) +
> >    * CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
> > scale(dry_bio_cover_m2):tillage*
> >
> > If I refit this model in a different (more logical) order with the same
> > variables, as followed,
> > dry_bio_weeds_m2 + 0.001 ~* block + year + scale(dry_bio_cover_m2) +
> > tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2) +
> > tillage:scale(dry_bio_cover_m2)* +
> > (1 | block:tillage) + (1 | block:tillage:N) + (1 | block:tillage:N:CC) +
> (1
> > | block:year) + (1 | block:year:tillage) + (1 | block:year:tillage:N) +
> (1
> > |  block:year:tillage:N:CC)
> > I obtain similar estimates but drastically different SE, which of course
> > impacts post-hoc analysis.
> >
> >
> > The condition number of both models is also slightly different (12.1 for
> > the model with the variables in the order returned by dredge and 14.3 for
> > the model with the "logical" order), although no severe collinearity was
> > detected.
> >
> >
> >
> > Model with variables fitted in the order given by dredge:
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: gaussian  ( sqrt )
> > Formula: dry_bio_weeds_m2 + 0.001 ~ CC + N + scale(dry_bio_cover_m2) +
> >      tillage + block + year + (1 | block:tillage) + (1 |
> > block:tillage:N) +
> >     (1 | block:tillage:N:CC) + (1 | block:year) + (1 |
> > block:year:tillage) +      (1 | block:year:tillage:N) + (1 |
> > block:year:tillage:N:CC) +
> >     CC:N + CC:scale(dry_bio_cover_m2) + CC:tillage +
> > scale(dry_bio_cover_m2):tillage
> >    Data: biomassCC_wo_C
> > Control: glmerControl(optimizer = "nloptwrap", optCtrl =
> > list(algorithm = "NLOPT_LN_NELDERMEAD"))
> >
> >      AIC      BIC   logLik deviance df.resid
> >   6294.5   6416.4  -3116.2   6232.5      347
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -4.7837 -0.5006 -0.0011  0.5075  4.7593
> >
> > Random effects:
> >  Groups                  Name        Variance  Std.Dev.
> >  block:year:tillage:N:CC (Intercept) 3.061e+04 1.750e+02
> >  block:tillage:N:CC      (Intercept) 2.162e-05 4.650e-03
> >  block:year:tillage:N    (Intercept) 2.645e-05 5.143e-03
> >  block:tillage:N         (Intercept) 2.125e+01 4.610e+00
> >  block:year:tillage      (Intercept) 4.656e-03 6.823e-02
> >  block:year              (Intercept) 3.848e+02 1.962e+01
> >  block:tillage           (Intercept) 4.204e-04 2.050e-02
> >  Residual                            4.505e+03 6.712e+01
> > Number of obs: 378, groups:
> > block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
> > block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
> > block:year, 8; block:tillage, 8
> >
> > Fixed effects:
> >                                    Estimate Std. Error   t value Pr(>|z|)
> > (Intercept)                       13.829033   0.001353 10219.154  <
> 2e-16 ***
> > CCVv                              -0.064097   0.001353   -47.367  <
> 2e-16 ***
> > CCTs                               0.059189   0.001353    43.739  <
> 2e-16 ***
> > N.L                                5.506568   0.001310  4202.646  <
> 2e-16 ***
> > N.Q                               -0.387064   0.001310  -295.407  <
> 2e-16 ***
> > N.C                               -0.123713   0.001310   -94.417  <
> 2e-16 ***
> > scale(dry_bio_cover_m2)           -3.096732   0.001309 -2366.243  <
> 2e-16 ***
> > tillageRT                         -0.034498   0.001310   -26.329  <
> 2e-16 ***
> > blockR2                           -1.369223   0.464429    -2.948
>  0.0032 **
> > blockR3                           -0.897212   0.001353  -663.006  <
> 2e-16 ***
> > blockR4                            0.536253   0.464366     1.155   0.2482
> > year2014                           0.484093   0.350696     1.380   0.1675
> > CCVv:N.L                          -3.795768   0.652249    -5.820
> 5.90e-09 ***
> > CCTs:N.L                          -3.760854   0.652139    -5.767
> 8.07e-09 ***
> > CCVv:N.Q                          -0.630917   0.652215    -0.967   0.3334
> > CCTs:N.Q                          -0.258428   0.652139    -0.396   0.6919
> > CCVv:N.C                           0.857098   0.652113     1.314   0.1887
> > CCTs:N.C                           0.273846   0.652088     0.420   0.6745
> > CCVv:scale(dry_bio_cover_m2)      -2.834524   0.001310 -2163.350  <
> 2e-16 ***
> > CCTs:scale(dry_bio_cover_m2)      -2.564852   0.001401 -1831.105  <
> 2e-16 ***
> > CCVv:tillageRT                     4.446872   0.001401  3174.709  <
> 2e-16 ***
> > CCTs:tillageRT                     2.758362   0.001401  1969.252  <
> 2e-16 ***
> > scale(dry_bio_cover_m2):tillageRT  2.022118   0.001310  1543.318  <
> 2e-16 ***
> >
> >
> >
> >
> >
> >
> >
> >
> > Model with variables fitted in "logical" order:
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: gaussian  ( sqrt )
> > Formula: dry_bio_weeds_m2 + 0.001 ~ block + year +
> scale(dry_bio_cover_m2) +
> >     tillage + N + CC + CC:N + CC:tillage + CC:scale(dry_bio_cover_m2)
> > +      tillage:scale(dry_bio_cover_m2) + (1 | block:tillage) + (1 |
> >     block:tillage:N) + (1 | block:tillage:N:CC) + (1 | block:year) +
> >    (1 | block:year:tillage) + (1 | block:year:tillage:N) + (1 |
> >     block:year:tillage:N:CC)
> >    Data: biomassCC_wo_C
> > Control: glmerControl(optimizer = "nloptwrap", optCtrl =
> > list(algorithm = "NLOPT_LN_NELDERMEAD"))
> >
> >      AIC      BIC   logLik deviance df.resid
> >   6294.5   6416.4  -3116.2   6232.5      347
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -4.7838 -0.5009 -0.0011  0.5075  4.7594
> >
> > Random effects:
> >  Groups                  Name        Variance  Std.Dev.
> >  block:year:tillage:N:CC (Intercept) 3.061e+04 1.749e+02
> >  block:tillage:N:CC      (Intercept) 2.141e-05 4.627e-03
> >  block:year:tillage:N    (Intercept) 2.605e-05 5.104e-03
> >  block:tillage:N         (Intercept) 2.106e+01 4.589e+00
> >  block:year:tillage      (Intercept) 4.487e-03 6.699e-02
> >  block:year              (Intercept) 3.822e+02 1.955e+01
> >  block:tillage           (Intercept) 4.228e-04 2.056e-02
> >  Residual                            4.504e+03 6.711e+01
> > Number of obs: 378, groups:
> > block:year:tillage:N:CC, 192; block:tillage:N:CC, 96;
> > block:year:tillage:N, 64; block:tillage:N, 32; block:year:tillage, 16;
> > block:year, 8; block:tillage, 8
> >
> > Fixed effects:
> >                                   Estimate Std. Error t value Pr(>|z|)
> > (Intercept)                       13.82995   42.86352   0.323  0.74696
> > blockR2                           -1.36672   40.78008  -0.034  0.97326
> > blockR3                           -0.89843   40.78048  -0.022  0.98242
> > blockR4                            0.53355   40.77879   0.013  0.98956
> > year2014                           0.48290   28.79334   0.017  0.98662
> > scale(dry_bio_cover_m2)           -3.09673    0.81313  -3.808  0.00014
> ***
> > tillageRT                         -0.03537   43.77607  -0.001  0.99936
> > N.L                                5.50829   43.77552   0.126  0.89987
> > N.Q                               -0.38899   43.77300  -0.009  0.99291
> > N.C                               -0.12513   43.77337  -0.003  0.99772
> > CCVv                              -0.06447   43.74925  -0.001  0.99882
> > CCTs                               0.05444   43.75387   0.001  0.99901
> > N.L:CCVv                          -3.79754   61.86354  -0.061  0.95105
> > N.Q:CCVv                          -0.62820   61.86055  -0.010  0.99190
> > N.C:CCVv                           0.86704   61.85967   0.014  0.98882
> > N.L:CCTs                          -3.76680   61.86056  -0.061  0.95145
> > N.Q:CCTs                          -0.25653   61.85857  -0.004  0.99669
> > N.C:CCTs                           0.27781   61.85861   0.004  0.99642
> > tillageRT:CCVv                     4.44671   61.86316   0.072  0.94270
> > tillageRT:CCTs                     2.75968   61.86792   0.045  0.96442
> > scale(dry_bio_cover_m2):CCVv      -2.83780    0.93223  -3.044  0.00233 **
> > scale(dry_bio_cover_m2):CCTs      -2.56887    1.32152  -1.944  0.05191 .
> > scale(dry_bio_cover_m2):tillageRT  2.02139    0.85983   2.351  0.01873 *
> >
> >
> > I can share the data if need be. Thank you very much for your help.
> >
> > Sincerely,
> >
> > Guillaume ADEUX
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Aug  8 15:06:50 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 8 Aug 2019 15:06:50 +0200
Subject: [R-sig-ME] allFit fails after removing object with starting values
 for model parameters from workspace
Message-ID: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>

Dear lmer-experts,

if I refit a fitted model with all available optimizers AFTER
removing the object which contains the starting values for the
parameters of the model as in

theta <- c(1, 0.01, 0.2)
fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
            start = theta)
rm(theta)
allFit(fm, verbose = FALSE)

none of the optimizers succeeds:

original model:
Reaction ~ Days + (Days | Subject)
optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw, optimx.L-BFGS-B, 
nloptwrap.NLOPT_LN_N...
7 optimizer(s) failed
differences in negative log-likelihoods:
max= -Inf ; std dev= NA
Warning messages:
1: In min(nllvec) : no non-missing arguments to min; returning Inf
2: In max(nllvec - min(nllvec)) :
   no non-missing arguments to max; returning -Inf


If I don't remove theta from my workspace everything works fine.
Is there a workaround for this - from my perspective - unwanted
behaviour? (I have situations where allFit is used in a different
environment from the one wherein the model was fit, e.g., after
fitting the model the object which contains the fit is saved and
later loaded in another R-session to be processed by allFit.)
I could, of course, save theta everytime as well ... Any ideas?

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Aug  8 15:10:44 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 8 Aug 2019 15:10:44 +0200
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
References: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
Message-ID: <ceedaa5c-bb9e-c8db-633a-c9314a3fcbfa@math.uni-giessen.de>

I forgot to mention that I use lme4_1.1-21.9001
and
R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 08.08.2019 um 15:06 schrieb Gerrit Eichner:
> Dear lmer-experts,
> 
> if I refit a fitted model with all available optimizers AFTER
> removing the object which contains the starting values for the
> parameters of the model as in
> 
> theta <- c(1, 0.01, 0.2)
> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>  ?????????? start = theta)
> rm(theta)
> allFit(fm, verbose = FALSE)
> 
> none of the optimizers succeeds:
> 
> original model:
> Reaction ~ Days + (Days | Subject)
> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw, optimx.L-BFGS-B, 
> nloptwrap.NLOPT_LN_N...
> 7 optimizer(s) failed
> differences in negative log-likelihoods:
> max= -Inf ; std dev= NA
> Warning messages:
> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
> 2: In max(nllvec - min(nllvec)) :
>  ? no non-missing arguments to max; returning -Inf
> 
> 
> If I don't remove theta from my workspace everything works fine.
> Is there a workaround for this - from my perspective - unwanted
> behaviour? (I have situations where allFit is used in a different
> environment from the one wherein the model was fit, e.g., after
> fitting the model the object which contains the fit is saved and
> later loaded in another R-session to be processed by allFit.)
> I could, of course, save theta everytime as well ... Any ideas?
> 
>  ?Best regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Aug  8 15:26:30 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 8 Aug 2019 09:26:30 -0400
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
References: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
Message-ID: <87d6a72d-ff55-45e1-c3b6-1cf815372078@gmail.com>


  This is not surprising, as allFit() uses update(), which tries to
re-evaluate the function ... at the very least allFit needs a
documentation update with that hint ... (I also notice at a glance that
the allFit docs seem to be incomplete anyway).

  If you say more about your workflow we might be able to find a way to
help.  (If your workflow is this simple then the answer would be "well
then don't delete theta" ...)

  cheers
    Ben Bolker


On 2019-08-08 9:06 a.m., Gerrit Eichner wrote:
> Dear lmer-experts,
> 
> if I refit a fitted model with all available optimizers AFTER
> removing the object which contains the starting values for the
> parameters of the model as in
> 
> theta <- c(1, 0.01, 0.2)
> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
> ?????????? start = theta)
> rm(theta)
> allFit(fm, verbose = FALSE)
> 
> none of the optimizers succeeds:
> 
> original model:
> Reaction ~ Days + (Days | Subject)
> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw, optimx.L-BFGS-B,
> nloptwrap.NLOPT_LN_N...
> 7 optimizer(s) failed
> differences in negative log-likelihoods:
> max= -Inf ; std dev= NA
> Warning messages:
> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
> 2: In max(nllvec - min(nllvec)) :
> ? no non-missing arguments to max; returning -Inf
> 
> 
> If I don't remove theta from my workspace everything works fine.
> Is there a workaround for this - from my perspective - unwanted
> behaviour? (I have situations where allFit is used in a different
> environment from the one wherein the model was fit, e.g., after
> fitting the model the object which contains the fit is saved and
> later loaded in another R-session to be processed by allFit.)
> I could, of course, save theta everytime as well ... Any ideas?
> 
> ?Best regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Aug  8 15:41:06 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 8 Aug 2019 15:41:06 +0200
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <87d6a72d-ff55-45e1-c3b6-1cf815372078@gmail.com>
References: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
 <87d6a72d-ff55-45e1-c3b6-1cf815372078@gmail.com>
Message-ID: <b20b92b4-0621-71f8-2008-354e4cb6ba56@math.uni-giessen.de>

Thx a lot, Ben, for the fast reply which clearly explains the
cause of my problem. I've just found a solution which works for
me (and which is not as simple as "don't delete theta" ;-) ):
I "hardwire" theta's value into the function call:

theta <- c(1, 0.01, 0.2)
fm <- eval(bquote(
    lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
         start = .(theta))
    ))

rm(theta)
allFit(fm, verbose = FALSE)


Works like a "charm", at least in my current workflow. :-)

  Thanks once more  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 08.08.2019 um 15:26 schrieb Ben Bolker:
> 
>    This is not surprising, as allFit() uses update(), which tries to
> re-evaluate the function ... at the very least allFit needs a
> documentation update with that hint ... (I also notice at a glance that
> the allFit docs seem to be incomplete anyway).
> 
>    If you say more about your workflow we might be able to find a way to
> help.  (If your workflow is this simple then the answer would be "well
> then don't delete theta" ...)
> 
>    cheers
>      Ben Bolker
> 
> 
> On 2019-08-08 9:06 a.m., Gerrit Eichner wrote:
>> Dear lmer-experts,
>>
>> if I refit a fitted model with all available optimizers AFTER
>> removing the object which contains the starting values for the
>> parameters of the model as in
>>
>> theta <- c(1, 0.01, 0.2)
>> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>>  ?????????? start = theta)
>> rm(theta)
>> allFit(fm, verbose = FALSE)
>>
>> none of the optimizers succeeds:
>>
>> original model:
>> Reaction ~ Days + (Days | Subject)
>> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw, optimx.L-BFGS-B,
>> nloptwrap.NLOPT_LN_N...
>> 7 optimizer(s) failed
>> differences in negative log-likelihoods:
>> max= -Inf ; std dev= NA
>> Warning messages:
>> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
>> 2: In max(nllvec - min(nllvec)) :
>>  ? no non-missing arguments to max; returning -Inf
>>
>>
>> If I don't remove theta from my workspace everything works fine.
>> Is there a workaround for this - from my perspective - unwanted
>> behaviour? (I have situations where allFit is used in a different
>> environment from the one wherein the model was fit, e.g., after
>> fitting the model the object which contains the fit is saved and
>> later loaded in another R-session to be processed by allFit.)
>> I could, of course, save theta everytime as well ... Any ideas?
>>
>>  ?Best regards? --? Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug 12 11:40:17 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 12 Aug 2019 21:40:17 +1200
Subject: [R-sig-ME] Results from vcov() in lme4.
Message-ID: <9f1fe98a-8858-6cb5-4985-861abc2e8e66@auckland.ac.nz>


I am rather puzzled by the results of applying vcov() to (binomial) 
models fitted by glmer().  The linear predictor in the models is of the form

      alpha_i + beta_i * x + <random effects>

where "i" corresponds to "treatment group" and x is numeric.  There are 
six treatment groups so the covariance matrix returned by vcov() is
12 x 12.

When I fit the model with nAGQ = 0 in the call to glmer() the resulting 
matrix is quite sparse --- there is non-zero covariance only between 
parameter estimates corresponding to the same value of "i" (i.e. to the 
same treatment group).  In other words, under the appropriate ordering 
of the estimated parameters, the covariance matrix is block diagonal, 
with six 2 x 2 blocks.

When I fit the model with nAGQ set equal to 1, the resulting covariance 
matrix is non-sparse; all entries are non-zero.  (The entries outside of 
the "block diagonal structure" are, I suppose, "relatively" small --- 
they range from -0.0145 to 0.0010 --- but are well away from being 
"approximately zero".)

I would like a better understanding of the reason for the difference.  I 
was under the impression that setting nAGQ = 0 gives a somewhat 
quick-and-dirty fit of the model; less accurate and reliable than with
nAGQ = 1.  Why does setting nAGQ = 0 (apparently) cause the covariance 
between parameter estimates corresponding to different treatment groups 
to be *exactly* zero?

If I remember my childhood teaching correctly, in a *linear* model, such 
covariances would indeed be exactly zero, so one might expect 
"approximately" zero in the generalised linear model setting.  But why 
should setting nAGQ = 0 result in a covariance matrix which is "just 
like" one from the linear model setting?

I guess it doesn't really matter a damn, but I'd like to understand what 
is going on, at least "in rough intuitive terms".

Can anyone enlighten me?

Thanks.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Aug 12 11:50:33 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 12 Aug 2019 11:50:33 +0200
Subject: [R-sig-ME] Results from vcov() in lme4.
In-Reply-To: <9f1fe98a-8858-6cb5-4985-861abc2e8e66@auckland.ac.nz>
References: <9f1fe98a-8858-6cb5-4985-861abc2e8e66@auckland.ac.nz>
Message-ID: <a9899f98-2128-58cc-a1f6-5219d5cb52f2@mpi.nl>

The MixedModels.jl documentation has the technical answer as to what's
going on:

> The distinction between the "fast" and "slow" algorithms in the MixedModels package (nAGQ=0 or nAGQ=1 in lme4) is whether the fixed-effects parameters, ?, are optimized in PIRLS or in the nonlinear optimizer. 

My suspicion is that not doing joint optimization (i.e. estimating FE
and RE separately as in nAGQ=0) leads to the parameter space not being
explored as efficiently so you still closer to the starting values.

For GLMM this matters because of the way the fixed effects are
conditional on the RE. This was discussed a bit on the list a while
back: GLMMadaptive, if I recall correctly, can produce both conditional
and marginal (population-level) effect estimates for binomial models.
For LMM, the conditional and marginal estimates work out to be the same
thing, so you can ignore / marginalize out the fixed effects before
using the non-linear optimizer to solve the RE.

My explanation is surely infelicitous in some way, so more knowledgeable
people please correct me!

Phillip

On 12/8/19 11:40 am, Rolf Turner wrote:
> 
> I am rather puzzled by the results of applying vcov() to (binomial)
> models fitted by glmer().? The linear predictor in the models is of the
> form
> 
> ???? alpha_i + beta_i * x + <random effects>
> 
> where "i" corresponds to "treatment group" and x is numeric.? There are
> six treatment groups so the covariance matrix returned by vcov() is
> 12 x 12.
> 
> When I fit the model with nAGQ = 0 in the call to glmer() the resulting
> matrix is quite sparse --- there is non-zero covariance only between
> parameter estimates corresponding to the same value of "i" (i.e. to the
> same treatment group).? In other words, under the appropriate ordering
> of the estimated parameters, the covariance matrix is block diagonal,
> with six 2 x 2 blocks.
> 
> When I fit the model with nAGQ set equal to 1, the resulting covariance
> matrix is non-sparse; all entries are non-zero.? (The entries outside of
> the "block diagonal structure" are, I suppose, "relatively" small ---
> they range from -0.0145 to 0.0010 --- but are well away from being
> "approximately zero".)
> 
> I would like a better understanding of the reason for the difference.? I
> was under the impression that setting nAGQ = 0 gives a somewhat
> quick-and-dirty fit of the model; less accurate and reliable than with
> nAGQ = 1.? Why does setting nAGQ = 0 (apparently) cause the covariance
> between parameter estimates corresponding to different treatment groups
> to be *exactly* zero?
> 
> If I remember my childhood teaching correctly, in a *linear* model, such
> covariances would indeed be exactly zero, so one might expect
> "approximately" zero in the generalised linear model setting.? But why
> should setting nAGQ = 0 result in a covariance matrix which is "just
> like" one from the linear model setting?
> 
> I guess it doesn't really matter a damn, but I'd like to understand what
> is going on, at least "in rough intuitive terms".
> 
> Can anyone enlighten me?
> 
> Thanks.
> 
> cheers,
> 
> Rolf Turner
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Aug 14 13:06:32 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 14 Aug 2019 23:06:32 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
 <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
 <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
Message-ID: <7c96e7fe-e05e-aed3-31a4-3d83a33769a2@auckland.ac.nz>


Dear Prof. Rizopoulos,

I hope that this gets through to you on your travels and that I am not 
disrupting the even tenor of your ways *too* badly. :-)

I am *finally* getting back to my efforts to calculate the log 
likelihood of a new ("validation") set of data on the basis of a model 
fitted to a different ("training") set of data.

You suggested a procedure for doing this using the mixed_model() 
function from the GLMMadaptive package.  After a bit of running-in time, 
getting to know the mixed_model() function, I (finally!) set about 
trying to follow your advice.

On 29/04/19 4:25 PM, D. Rizopoulos wrote:

> If you want you could give a try to the GLMMadaptive package that 
> implements the adaptive Gaussian quadrature for a vector of random 
> effects (e.g., intercepts and slopes as in your case), and from which 
> you get the log-likelihood in two steps, e.g.,
> 
> library(GLMMadaptive)
> # the log-likelihood at the initial values
> fm <- mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose 
> | Rep,
>  ? data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, 
> iter_qN_outer = 0)
> logLik(fm)

I am a bit mystified by the "iter_EM = 0" and "iter_qN_outer = 0" in the 
foregoing.  I presume that they really shouldn't be there, but belong 
only in the next step.  But I could be completely out to lunch here, 
since I don't know what I'm doing at all!

I presume that "Ts" should be the "training set" of data.

> # the log-likelihood at user-specified values
> gm <- ?mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ 
> Dose | Rep,
>  ? data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, 
> iter_qN_outer = 0,
>  ? initial_values = list(beta = <put_your_fixed_effects_here>, D = 
> <put_the_RE_cov_matrix_here>))
> logLik(gm)

I presume (yet again!) the "Ts" in the foregoing should be "VS", the new
"validation" set of data.  If not, then I'm *really* not understanding 
anything that is going on here.

What I am conjecturing is that the foregoing code "fits" a model to the
"validation" data without actually doing any fitting.  I.e. it just 
"stays at the starting values" (since it does no iterations) thereby 
getting the same model as that encompassed by "fm".  If this is not what 
the code is doing, can you please explain what it *is* doing?

For "beta" in the initial_values list I used fixef(fm) and for "D" I 
used fm$D.  If this isn't right, then I need more instruction.

Anyhow:  I put all this together in a script ("demo.txt") which is 
attached, along with a demonstration data set X.txt.

If these file are save into your working directory you should be able to
source("demo.txt") and see what I saw:

> Error in if (use.names && nt[i] == nc[i]) dQuote(nt[i]) else i : 
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred 

I presume (am I presumptuous or what?) that the warnings are not too 
much to worry about, but the error flummoxes me.  Clearly I've got 
something wrong, but I have insufficient insight to see what it is.

Can you (or possibly someone else) enlighten me?

Thanks.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190814/ad202abb/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: X.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190814/ad202abb/attachment-0001.txt>

From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Aug 14 20:04:14 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Wed, 14 Aug 2019 18:04:14 +0000
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <7c96e7fe-e05e-aed3-31a4-3d83a33769a2@auckland.ac.nz>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
 <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
 <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
 <7c96e7fe-e05e-aed3-31a4-3d83a33769a2@auckland.ac.nz>
Message-ID: <11d9dd2e289644698665b76e3ddb689d@erasmusmc.nl>

Dear Rolf,

The optimization behind mixed_model() is a hybrid that starts with EM and then switches to quasi-Newton. When you set the control arguments "iter_EM = 0" and "iter_qN_outer = 0" specify that neither EM nor quasi-Newton iterations are used. Hence, you only calculate the log-likelihood value (and the rest of the components) only for the initial values.

The reason why you received the error message is because in the list you provide to the initial_values argument of mixed_model() should be a named list. The name for the fixed effects coefficients is "betas" not "beta" - see the online help file for more info. I had also made this mistake in my untested code you quoted below. If you make this change, it should work (at least it does in my machine).

Best,
Dimitris


-----Original Message-----
From: Rolf Turner <r.turner at auckland.ac.nz> 
Sent: Wednesday, August 14, 2019 1:07 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Cross-validated likelihood, cont.


Dear Prof. Rizopoulos,

I hope that this gets through to you on your travels and that I am not disrupting the even tenor of your ways *too* badly. :-)

I am *finally* getting back to my efforts to calculate the log likelihood of a new ("validation") set of data on the basis of a model fitted to a different ("training") set of data.

You suggested a procedure for doing this using the mixed_model() function from the GLMMadaptive package.  After a bit of running-in time, getting to know the mixed_model() function, I (finally!) set about trying to follow your advice.

On 29/04/19 4:25 PM, D. Rizopoulos wrote:

> If you want you could give a try to the GLMMadaptive package that 
> implements the adaptive Gaussian quadrature for a vector of random 
> effects (e.g., intercepts and slopes as in your case), and from which 
> you get the log-likelihood in two steps, e.g.,
> 
> library(GLMMadaptive)
> # the log-likelihood at the initial values fm <- 
> mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose
> | Rep,
>  ? data = Ts, family = binomial(link = 'cloglog'), iter_EM = 0, 
> iter_qN_outer = 0)
> logLik(fm)

I am a bit mystified by the "iter_EM = 0" and "iter_qN_outer = 0" in the foregoing.  I presume that they really shouldn't be there, but belong only in the next step.  But I could be completely out to lunch here, since I don't know what I'm doing at all!

I presume that "Ts" should be the "training set" of data.

> # the log-likelihood at user-specified values gm <- ?
> mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose | 
> Rep,
>  ? data = Ts, family = binomial(link = 'cloglog'), iter_EM = 0, 
> iter_qN_outer = 0,
>  ? initial_values = list(beta = <put_your_fixed_effects_here>, D =
> <put_the_RE_cov_matrix_here>))
> logLik(gm)

I presume (yet again!) the "Ts" in the foregoing should be "VS", the new "validation" set of data.  If not, then I'm *really* not understanding anything that is going on here.

What I am conjecturing is that the foregoing code "fits" a model to the "validation" data without actually doing any fitting.  I.e. it just "stays at the starting values" (since it does no iterations) thereby getting the same model as that encompassed by "fm".  If this is not what the code is doing, can you please explain what it *is* doing?

For "beta" in the initial_values list I used fixef(fm) and for "D" I used fm$D.  If this isn't right, then I need more instruction.

Anyhow:  I put all this together in a script ("demo.txt") which is attached, along with a demonstration data set X.txt.

If these file are save into your working directory you should be able to
source("demo.txt") and see what I saw:

> Error in if (use.names && nt[i] == nc[i]) dQuote(nt[i]) else i : 
>   missing value where TRUE/FALSE needed In addition: Warning messages:
> 1: glm.fit: fitted probabilities numerically 0 or 1 occurred
> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred

I presume (am I presumptuous or what?) that the warnings are not too much to worry about, but the error flummoxes me.  Clearly I've got something wrong, but I have insufficient insight to see what it is.

Can you (or possibly someone else) enlighten me?

Thanks.

cheers,

Rolf

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Aug 15 01:04:27 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 15 Aug 2019 11:04:27 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <11d9dd2e289644698665b76e3ddb689d@erasmusmc.nl>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
 <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
 <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
 <7c96e7fe-e05e-aed3-31a4-3d83a33769a2@auckland.ac.nz>
 <11d9dd2e289644698665b76e3ddb689d@erasmusmc.nl>
Message-ID: <833af102-1976-97ec-0649-6c83f83f21e1@auckland.ac.nz>


On 15/08/19 6:04 AM, D. Rizopoulos wrote:

> Dear Rolf,
> 
> The optimization behind mixed_model() is a hybrid that starts with EM
> and then switches to quasi-Newton. When you set the control arguments
> "iter_EM = 0" and "iter_qN_outer = 0" specify that neither EM nor
> quasi-Newton iterations are used. Hence, you only calculate the
> log-likelihood value (and the rest of the components) only for the
> initial values.
> 
> The reason why you received the error message is because in the list
> you provide to the initial_values argument of mixed_model() should be
> a named list. The name for the fixed effects coefficients is "betas"
> not "beta" - see the online help file for more info. I had also made
> this mistake in my untested code you quoted below. If you make this
> change, it should work (at least it does in my machine).

Yesssss! That worked!!!  Thank you.  And thank you for confirming that 
my understanding of what is going on was basically correct.

What a difference an "s" makes!  Especially when one hasn't a clue what 
one is doing. :-( Of course this could be held up as another instance of 
RTFM!  Now that I *look* at the help for mixed_model() I see that it 
clearly states that the components of "initial_values" are named 
*"betas"*, "D" and "phis".

I was feeling so all-at-sea that I never considered looking for such a 
simple solution to the problem.

Thanks again.

cheers,

Rolf

P.S.  (The following is mostly aimed at Ben Bolker.)

I thought I'd compare the log likelihood from mixed_model() with that 
from glmer().  So I did:

library(lme4)
g.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
                  data=TS,family=binomial(link="cloglog"),nAGQ=0)
coefs   <- unlist(getME(g.trn,c("theta","beta")))
newdev  <- update(g.trn, data=VS, devFunOnly=TRUE,
                   control=glmerControl(check.nobs.vs.nRE="ignore"))
ll <- -0.5*newdev(coefs)
print(ll)

This *worked* previously.  However after the "newdev <-" it now makes 
the comment:

> fixed-effect model matrix is rank deficient so dropping 1 column / coefficient

and then after "newdev(coefs) it throws an error:

> (15!=3)
> Error in pp$setTheta(theta) : theta size mismatch

I thought that the dropped coefficient might be the problem, so I 
replaced coefs by coefs[-15] but then the error simply changes to:

> (14!=3)
> Error in pp$setTheta(theta) : theta size mismatch

Indeed 15!=3 (no shit, Sherlock!) and likewise 14!=3.  But why *3*???

If I do

chk <- update(g.trn,data=VS)
coefs.chk <- unlist(getME(chk,c("theta","beta")))

I get coefs.chk to be a vector of length 14 (which seems to line up,
names-wise, with coefs) so 14 seems to be the "right answer".  Where 
does 3 come in?

Previously adding the argument

     "control=glmerControl(check.nobs.vs.nRE="ignore")"

to the call to update() (on Ben's advice) fixed the problems that I was 
having.  No longer is this the case.

What has changed?  Is there any way I can get this to work?

R.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From v@@t@vr|n|de@ @end|ng |rom uc|@@c@uk  Tue Aug  6 11:43:34 2019
From: v@@t@vr|n|de@ @end|ng |rom uc|@@c@uk (Stavrinides, Vasilis)
Date: Tue, 6 Aug 2019 09:43:34 +0000
Subject: [R-sig-ME] MCMCglmm priors for ordinal response
Message-ID: <EB6D01FF-0E3D-4EB5-BA68-5E8272B68AB9@ucl.ac.uk>

Dear all,
I am having some trouble understanding how to use priors for a GLMM where the response variable is ordinal (a scale from 1-6) and the explanatory variables are a mixture of factor and continuous variables. I have found a few posts on how to fix certain parameters in the ?prior? argument of the MCMCglmm function, but it is not still very clear in my head. Also, if there is poor chain convergence that cannot be fixed by increasing the iteration number, changing the prior seems the next logical step, but I cannot understand how to make an educated guess of what the change should be. Could anyone please provide some valuable insight?
Thank you and apologies if this is a slightly simple issue ? I am relatively inexperienced in this field.
Best
Vasilis Stavrinides

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Aug 16 22:00:38 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 17 Aug 2019 08:00:38 +1200
Subject: [R-sig-ME] Anyone there?
Message-ID: <7aacb1dd-ee58-5d40-e8fe-fe3fb7b56021@auckland.ac.nz>


This list has gone completely silent for the last few days --- which is 
unusual.  More to the point ( :-) ) no-one has answered the question I 
asked on 15 August (in respect of calculating cross validated log 
likelihood using glmer() for comparison with the value obtained from the 
mixed_model() function from GLMMadaptive).  And I'm kind of desperate 
for an answer.

Previously I was able to do the calculation with glmer(), following 
advice from Ben Bolker, but the calculation has (weirdly) stopped working.

The posting referred to was actually a CC of a message sent to D. 
Rizopoulos.  Did it get through to the list?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 16 22:43:35 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 16 Aug 2019 13:43:35 -0700
Subject: [R-sig-ME] Anyone there?
In-Reply-To: <7aacb1dd-ee58-5d40-e8fe-fe3fb7b56021@auckland.ac.nz>
References: <7aacb1dd-ee58-5d40-e8fe-fe3fb7b56021@auckland.ac.nz>
Message-ID: <FB4C7EF9-B99D-4E6B-823B-F097904665C9@dcn.davis.ca.us>

I saw three emails in that thread. I am not competent to discuss the content though... I suspect the heavy hitters are on vacation or your enthusiastic reply to Dr R gave them an excuse to drop it.

On August 16, 2019 1:00:38 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>This list has gone completely silent for the last few days --- which is
>
>unusual.  More to the point ( :-) ) no-one has answered the question I 
>asked on 15 August (in respect of calculating cross validated log 
>likelihood using glmer() for comparison with the value obtained from
>the 
>mixed_model() function from GLMMadaptive).  And I'm kind of desperate 
>for an answer.
>
>Previously I was able to do the calculation with glmer(), following 
>advice from Ben Bolker, but the calculation has (weirdly) stopped
>working.
>
>The posting referred to was actually a CC of a message sent to D. 
>Rizopoulos.  Did it get through to the list?
>
>cheers,
>
>Rolf Turner

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 17 01:55:11 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 17 Aug 2019 11:55:11 +1200
Subject: [R-sig-ME] Cross validated log likelihood, redux.
Message-ID: <1d0c21a3-687d-a008-3e13-3ff0c4ef8409@auckland.ac.nz>


My apologies for continuing to pester the list with questions about this 
issue, but I urgently need an answer to my most recent question.

That question was contained in a postscript to a reply to D. Rizopoulos, 
and thereby may have been overlooked.  Consequently I am re-posting this 
question.  (Again I apologise for taking up bandwidth.)

In summary, the situation is as follows:

* I am trying to calculate the log likelihood of a "new" data set on the 
basis of a model fitted to a different data set.

* Ben Bolker showed me how to do this using glmer() (from the lme4 
package) and after some to-ing and fro-ing I got his recipe to work.

* Dimitris Rizopoulis also showed me how to do this using the 
mixed_model() function from the GLMMadaptive package.  Again, after much 
delay and after more to-ing and fro-ing, I got Prof. Rizopoulis's advice 
to work.

* I then wanted to cross-check the value obtained from mixed_model() 
with that obtained from glmer(), so I re-ran the glmer() based code.
Lo and behold, that code threw an error (where it had not before done so).

I would really like to be able to use both methods (i.e. that based on 
mixed_model() and that based on glmer()).  So I would like to figure out 
what is going wrong --- or what I am doing wrong --- in the case of the 
glmer() approach.

I have attached a source-able script demo.glmer.txt to demonstrate what 
happens, and have also attached the (simulated) data set X.txt which the 
script uses.

If you place demo.glmer.txt and X.txt in your working directory and
source("demo.glmer.txt") you will get the following message and error 
message:

> fixed-effect model matrix is rank deficient so dropping 1 column / coefficient
> (15!=3)
> Error in pp$setTheta(theta) : theta size mismatch

As I said in my (possibly overlooked) postscript in a previous posting 
on this issue:

This code *worked* previously!!!

I thought that the dropped coefficient might be the problem, so in the 
demo script I replaced coefs by coefs[-15] but then the error simply 
changes to:

 > (14!=3)
 > Error in pp$setTheta(theta) : theta size mismatch

Indeed 15!=3 (no shit, Sherlock!) and likewise 14!=3.  But why *3*???

If I do

chk <- update(g.trn,data=VS)
coefs.chk <- unlist(getME(chk,c("theta","beta")))

I get coefs.chk to be a vector of length 14 (which seems to line up,
names-wise, with coefs as produced by the script) so 14 seems to be the 
"right answer".  Where does 3 come in?

Initially (way back when) I got an error *something* like this, but then
Ben Bolker advised me to add the argument

     "control=glmerControl(check.nobs.vs.nRE="ignore")"

to the call to update() and that fixed the problem that I was having. 
But the fix no longer seems to be "operative". :-)

What has changed?  Is there any way I can get this to work?

Thanks for any pearls of wisdom.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.glmer.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190817/d7e8d4a9/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: X.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190817/d7e8d4a9/attachment-0001.txt>

From bbo|ker @end|ng |rom gm@||@com  Sat Aug 17 03:43:04 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 16 Aug 2019 21:43:04 -0400
Subject: [R-sig-ME] Cross validated log likelihood, redux.
In-Reply-To: <1d0c21a3-687d-a008-3e13-3ff0c4ef8409@auckland.ac.nz>
References: <1d0c21a3-687d-a008-3e13-3ff0c4ef8409@auckland.ac.nz>
Message-ID: <49ca3ee2-4d98-aab5-b542-df24dc8c5d80@gmail.com>


  Hmmm. The proximal problem is that the updated deviance function
thinks it needs coefficients for all of the parameters (theta = 3 +
beta=12), not just the theta parameters.

  It's not obvious to me (I know this might be code I wrote in the first
place!) why you're trying to pass the full theta+beta coefficient vector
to a model defined with nAGQ=0 (which estimates the beta coefficients as
part of the penalized weighted resid sum of squares (pwrss)
computation).  Can you explain/remind us of the reason for the mismatch
here?

  cheers
    Ben Bolker


On 2019-08-16 7:55 p.m., Rolf Turner wrote:
> 
> My apologies for continuing to pester the list with questions about this
> issue, but I urgently need an answer to my most recent question.
> 
> That question was contained in a postscript to a reply to D. Rizopoulos,
> and thereby may have been overlooked.? Consequently I am re-posting this
> question.? (Again I apologise for taking up bandwidth.)
> 
> In summary, the situation is as follows:
> 
> * I am trying to calculate the log likelihood of a "new" data set on the
> basis of a model fitted to a different data set.
> 
> * Ben Bolker showed me how to do this using glmer() (from the lme4
> package) and after some to-ing and fro-ing I got his recipe to work.
> 
> * Dimitris Rizopoulis also showed me how to do this using the
> mixed_model() function from the GLMMadaptive package.? Again, after much
> delay and after more to-ing and fro-ing, I got Prof. Rizopoulis's advice
> to work.
> 
> * I then wanted to cross-check the value obtained from mixed_model()
> with that obtained from glmer(), so I re-ran the glmer() based code.
> Lo and behold, that code threw an error (where it had not before done so).
> 
> I would really like to be able to use both methods (i.e. that based on
> mixed_model() and that based on glmer()).? So I would like to figure out
> what is going wrong --- or what I am doing wrong --- in the case of the
> glmer() approach.
> 
> I have attached a source-able script demo.glmer.txt to demonstrate what
> happens, and have also attached the (simulated) data set X.txt which the
> script uses.
> 
> If you place demo.glmer.txt and X.txt in your working directory and
> source("demo.glmer.txt") you will get the following message and error
> message:
> 
>> fixed-effect model matrix is rank deficient so dropping 1 column /
>> coefficient
>> (15!=3)
>> Error in pp$setTheta(theta) : theta size mismatch
> 
> As I said in my (possibly overlooked) postscript in a previous posting
> on this issue:
> 
> This code *worked* previously!!!
> 
> I thought that the dropped coefficient might be the problem, so in the
> demo script I replaced coefs by coefs[-15] but then the error simply
> changes to:
> 
>> (14!=3)
>> Error in pp$setTheta(theta) : theta size mismatch
> 
> Indeed 15!=3 (no shit, Sherlock!) and likewise 14!=3.? But why *3*???
> 
> If I do
> 
> chk <- update(g.trn,data=VS)
> coefs.chk <- unlist(getME(chk,c("theta","beta")))
> 
> I get coefs.chk to be a vector of length 14 (which seems to line up,
> names-wise, with coefs as produced by the script) so 14 seems to be the
> "right answer".? Where does 3 come in?
> 
> Initially (way back when) I got an error *something* like this, but then
> Ben Bolker advised me to add the argument
> 
> ??? "control=glmerControl(check.nobs.vs.nRE="ignore")"
> 
> to the call to update() and that fixed the problem that I was having.
> But the fix no longer seems to be "operative". :-)
> 
> What has changed?? Is there any way I can get this to work?
> 
> Thanks for any pearls of wisdom.
> 
> cheers,
> 
> Rolf Turner
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 17 07:08:23 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 17 Aug 2019 17:08:23 +1200
Subject: [R-sig-ME] [FORGED] Re:  Cross validated log likelihood, redux.
In-Reply-To: <49ca3ee2-4d98-aab5-b542-df24dc8c5d80@gmail.com>
References: <1d0c21a3-687d-a008-3e13-3ff0c4ef8409@auckland.ac.nz>
 <49ca3ee2-4d98-aab5-b542-df24dc8c5d80@gmail.com>
Message-ID: <3ef7052a-46f6-1f98-9c57-cbaf15cc4622@auckland.ac.nz>


Hi Ben.  Thanks for getting back to me on this.

On 17/08/19 1:43 PM, Ben Bolker wrote:
> 
>    Hmmm. The proximal problem is that the updated deviance function
> thinks it needs coefficients for all of the parameters (theta = 3 +
> beta=12), not just the theta parameters.
> 
>    It's not obvious to me (I know this might be code I wrote in the first
> place!) why you're trying to pass the full theta+beta coefficient vector
> to a model defined with nAGQ=0 (which estimates the beta coefficients as
> part of the penalized weighted resid sum of squares (pwrss)
> computation).  Can you explain/remind us of the reason for the mismatch
> here?

The short answer is, I haven't got a clue.  (Or perhaps, to put it 
differently, that I'm clueless. :-) )

Basically I have just been (mindlessly) following instructions from your 
very good self.  Initially (20 April 2019) you said:

>  Here is an **inefficient** method for computing the likelihood
> 
>    coefs <- unlist(getME(fit,c("theta","beta"))
>    newdev <- update(fit, data=VS, devFunOnly=TRUE)
>    newdev(coefs)

I tried that, and it didn't work.  (Errors were thrown.) Then you 
updated the recipe (on 26 April 2019):

> coefs   <- unlist(getME(f.trn,"theta"))
> newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
>                   control=glmerControl(check.nobs.vs.nRE="ignore"))
> newdev(coefs)
having remarked that there were *two* issues.  (One issue involved the 
specification of "coefs", the other involved having to "override some 
checking that glmer does".)

In my implementation of the code to do a cross-check with the results 
from mixed_model() I neglected to take cognizance of the first issue. 
I.e. I left the assignment of "coefs" as:

> coefs <- unlist(getME(fit,c("theta","beta"))
whereas I should have changed it to

> coefs   <- unlist(getME(f.trn,"theta"))

i.e. leaving out the "beta" term.  Duhhhh!!!

Having corrected my error I find that the code now works as before.  Not 
surprisingly.

Thank you for asking for an explanation of what I was doing, which 
prompted me to go back over the story with the result that I spotted the 
botch-up that I had made.

(It's very difficult to spot errors when you are flying intellectually 
blind.)

Bottom line:  the harmony of the universe now seems to have been 
essentially restored. :-)

Thanks again.

cheers,

Rolf

P. S.  In case anyone is interested, the log likelihood of the 
"validation" data set that I get from mixed_model() in the example that 
I provided is -35.26048.

That from glmer() is -21.37535.

I guess that one can say that they are "in the same ball park".

Since I have no real understanding of the underlying intricacies, I have 
no idea what the implications of the difference between the two answers 
might be.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Aug 19 13:00:46 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Aug 2019 13:00:46 +0200
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
Message-ID: <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>

Dear Helmut,

The mixed models list is more suitable for this kind of question. I'm
forwarding it to that list. Please send any follow-up to that list instead
of the general R help list.

If I understand correctly, you'll need a different variance term for both
treatments (the within subject for T and R). I don't think you can do that
with lmer(). However, you can with nlme::lme() by using the weights
argument. The model does not converge on my machine.

library(nlme)
model2 <- lme(log(PK) ~ period + sequence + treatment , random = ~
treatment | subject, data = data, weights = varIdent(~treatment))

Another option is to go Bayesian with the INLA package (r-inla.org). Note
that the data needs some preparing. And the summary returns the precision
(1/var).

data$lPK_T <- ifelse(data$treatment == "T", log(data$PK), NA)
data$lPK_R <- ifelse(data$treatment == "R", log(data$PK), NA)
data$subject_T <- as.integer(data$subject)
n_subject <- max(data$subject_T)
data$subject_R <- ifelse(data$treatment == "R", data$subject_T + n_subject,
NA)
data$subject_T[data$treatment == "R"] <- NA

library(INLA)
model3 <- inla(
  cbind(lPK_T, lPK_R) ~ period + sequence + treatment +
    f(subject_T, model = "iid2d", n = 2 * n_subject) +
    f(subject_R, copy = "subject_T"),
  data = data,
  family = c("gaussian", "gaussian")
)
summary(model3)

Fixed effects:
                mean     sd 0.025quant 0.5quant 0.975quant    mode kld
(Intercept)   7.6501 0.1529     7.3492   7.6501     7.9507  7.6501   0
period2       0.0423 0.0729    -0.1011   0.0423     0.1854  0.0423   0
period3       0.0057 0.0613    -0.1148   0.0057     0.1262  0.0057   0
period4       0.0718 0.0731    -0.0718   0.0718     0.2153  0.0718   0
sequenceTRTR -0.0218 0.1960    -0.4076  -0.0218     0.3636 -0.0217   0
treatmentT    0.1462 0.0597     0.0288   0.1462     0.2636  0.1462   0

Random effects:
Name  Model
 subject_T   IID2D model
subject_R   Copy

Model hyperparameters:
                                             mean     sd 0.025quant
0.5quant 0.975quant   mode
Precision for the Gaussian observations    9.4943 1.4716     6.8915
9.3972    12.6699 9.2192
Precision for the Gaussian observations[2] 5.7145 0.8390     4.2257
5.6602     7.5228 5.5594
Precision for subject_T (component 1)      1.4670 0.2541     1.0265
1.4471     2.0243 1.4092
Precision for subject_T (component 2)      1.3545 0.2436     0.9350
1.3345     1.8913 1.2962
Rho1:2 for subject_T                       0.9176 0.0236     0.8631
0.9205     0.9551 0.9261

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 aug. 2019 om 12:29 schreef Helmut Sch?tz <helmut.schuetz at bebac.at>:

> Dear all,
>
> I?m struggling to set up a model required for the FDA (haha, and the
> Chinese agency). The closest I could get given at the end (which matches
> the one preferred by other regulatory agencies worldwide). The FDA is
> happy with R but "close" is not close /enough/.
>
> Don't hit me. I'm well aware of the community's attitudes towards SAS.
> I'm not a SASian myself (software agnostic) but that's not related to
> SAS; one could set up this model in other (commercial...) software as well.
>
> The FDA?s model allows different subject effects for each treatment
> (i.e., a subject-by-treatment interaction), and therefore, has 5
> variance terms:
>    1. within subject for T
>    2. within subject for R
>    3. between subject for T
>    4. between subject for R
>    5. covariance for between subject Test and Reference
> The last three are combined to give the subject ? formulation
> interaction variance component.
>
> The code provides a lot of significant digits only for comparison.
>
> # FDA 2001 (APPENDIX E)
> # https://www.fda.gov/media/70958/download
> # FDA 2011 (p. 8)
> #
>
> https://www.accessdata.fda.gov/drugsatfda_docs/psg/Progesterone_caps_19781_RC02-11.pdf
> ###############################################
> # PROC MIXED;                                 #
> # CLASSES SEQ SUBJ PER TRT;                   #
> # MODEL Y = SEQ PER TRT/ DDFM = SATTERTH;     #
> # RANDOM TRT/TYPE = FA0(2) SUB = SUBJ G;      #
> # REPEATED/GRP=TRT SUB = SUBJ;                #
> # ESTIMATE 'T vs. R' TRT 1 -1/CL ALPHA = 0.1; #
> ###############################################
> # Example data set (EMA)
> #
>
> https://www.ema.europa.eu/en/documents/other/31-annex-ii-statistical-analysis-bioequivalence-study-example-data-set_en.pdf
> library(RCurl)
> library(lme4)
> library(emmeans)
> url  <- getURL("https://bebac.at/downloads/ds01.csv")
> data <- read.csv(text = url, colClasses=c(rep("factor", 4), "numeric"))
> mod  <- lmer(log(PK) ~ period + sequence + treatment + (1|subject),
>                         data = data)
> res1 <- test(pairs(emmeans(mod, ~ treatment, mode = "satterth"),
>                     reverse = TRUE), delta = log(0.8))
> res2 <- confint(emmeans(mod, pairwise ~ treatment, mode = "satterth"),
>                  level = 0.9)
> # Workaround at the end because of lexical order
> #   I tried relevel(data$treatment, ref = "R") /before/ the model
> #   However, is not observed by confint(...)
> cat(paste0("\nEMA Example data set 1",
>             "\nAnalysis of log-transformed data",
>             "\nSatterthwaite\u2019s degrees of freedom, 90% CI",
>             "\n\n  SAS 9.4, Phoenix/WinNonlin 8.1",
>             "\n                   mean         SE       df p.value",
>             "\n    R      :  7.6704296 0.10396421  74.762420",
>             "\n    T      :  7.8158939 0.09860609  74.926384",
>             "\n    T vs. R:  0.1454643 0.04650124 207.734958 0.00201129",
>             "\n                     PE  lower.CL  upper.CL",
>             "\n    antilog:  1.1565764 1.0710440 1.2489393",
>             "\n\n  lmer (lme 1.1-21), emmeans 1.4",
>             "\n                   mean         SE       df p.value",
>             "\n    R      :  ", sprintf("%.7f %.8f  %3.6f",
>                                         res2$emmeans$emmean[1],
>                                         res2$emmeans$SE[1],
>                                         res2$emmeans$df[1]),
>             "\n    T      :  ", sprintf("%.7f %.8f  %3.6f",
>                                         res2$emmeans$emmean[2],
>                                         res2$emmeans$SE[2],
>                                         res2$emmeans$df[2]),
>             "\n    T vs. R:  ", sprintf("%.7f %.8f %3.6f %.8f",
>                                         res1$estimate, res1$SE, res1$df,
>                                         res1$p.value),
>             "\n                     PE  lower.CL  upper.CL",
>             "\n    antilog:  ", sprintf("%.7f %.7f %.7f",
> exp(-res2$contrasts$estimate),
> exp(-res2$contrasts$upper.CL),
> exp(-res2$contrasts$lower.CL)), "\n"))
>
> Cheers,
> Helmut
>
> --
> Ing. Helmut Sch?tz
> BEBAC ? Consultancy Services for
> W https://bebac.at/
> C https://bebac.at/Contact.htm
> F https://forum.bebac.at/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Aug 19 14:13:22 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Aug 2019 14:13:22 +0200
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <ba552167-7c6e-3339-8827-ba389d29740c@bebac.at>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
 <ba552167-7c6e-3339-8827-ba389d29740c@bebac.at>
Message-ID: <CAJuCY5yXThWCDDHei_ABeSquBmLAyfeD=HmT7n-ZvOKhpeEiLQ@mail.gmail.com>

Please do check all parameters. I recall that SAS and R use a different
style of dummy coding factor variable.

If that is not the case, please write the full equation for the SAS model.
The language of mathematics is the best way to clearly describe a model and
thus to compare models.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 aug. 2019 om 13:30 schreef Helmut Sch?tz <helmut.schuetz at bebac.at>:

> Dear Thierry,
>
> amazing!
> However, the PE obtained by exp(summary(model3)$fixed["treatmentT",
> "mean"]) is with 1.157428 even more off from the /desired/ 1.1565764
> than lmer?s 1.1572982.
>
> Best,
> Helmut
>
> --
> Ing. Helmut Sch?tz
> BEBAC ? Consultancy Services for
> Bioequivalence and Bioavailability Studies
> Neubaugasse 36/11
> 1070 Vienna, Austria
> W https://bebac.at/
> C https://bebac.at/Contact.htm
> F https://forum.bebac.at/
>
>
>

	[[alternative HTML version deleted]]


From he|mut@@chuetz @end|ng |rom beb@c@@t  Mon Aug 19 14:41:16 2019
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Mon, 19 Aug 2019 14:41:16 +0200
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <CAJuCY5yXThWCDDHei_ABeSquBmLAyfeD=HmT7n-ZvOKhpeEiLQ@mail.gmail.com>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
 <ba552167-7c6e-3339-8827-ba389d29740c@bebac.at>
 <CAJuCY5yXThWCDDHei_ABeSquBmLAyfeD=HmT7n-ZvOKhpeEiLQ@mail.gmail.com>
Message-ID: <29251076-d355-f8b5-4c0b-64962374910f@bebac.at>

Dear Thierry,

Thierry Onkelinx wrote on 2019-08-19 14:13:
> Please do check all parameters. I recall that SAS and R use a 
> different style of dummy coding factor variable.

I?m not a SASian. Hence, I can?t tell. In R factors specified as 
characters are handled in lexical order and internally coded as integers 
starting with 1.

> If that is not?the case, please write the full equation for the SAS 
> model. The language of mathematics is the best way to clearly describe 
> a model and thus to compare models.

Agree.
Unfortunately the SAS code is all the FDA gives. I think everything is 
clear except the covariance structure given by FA0(2).
See 
https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect019.htm#statug.mixed.mixedrandomtypefa0 
Table 56.13
Sorry, beyond me.

Best regards,
Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
W https://bebac.at/
C https://bebac.at/Contact.htm
F https://forum.bebac.at/


From he|mut@@chuetz @end|ng |rom beb@c@@t  Mon Aug 19 13:30:31 2019
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Mon, 19 Aug 2019 13:30:31 +0200
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
Message-ID: <ba552167-7c6e-3339-8827-ba389d29740c@bebac.at>

Dear Thierry,

amazing!
However, the PE obtained by exp(summary(model3)$fixed["treatmentT", 
"mean"]) is with 1.157428 even more off from the /desired/ 1.1565764 
than lmer?s 1.1572982.

Best,
Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
W https://bebac.at/
C https://bebac.at/Contact.htm
F https://forum.bebac.at/


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 19 16:47:02 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Aug 2019 10:47:02 -0400
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <29251076-d355-f8b5-4c0b-64962374910f@bebac.at>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
 <ba552167-7c6e-3339-8827-ba389d29740c@bebac.at>
 <CAJuCY5yXThWCDDHei_ABeSquBmLAyfeD=HmT7n-ZvOKhpeEiLQ@mail.gmail.com>
 <29251076-d355-f8b5-4c0b-64962374910f@bebac.at>
Message-ID: <3a5a2383-ec00-0c7e-78f5-8a88f2bb4052@gmail.com>

  [It's helpful to keep the full content of the thread included ...]

The SAS documentation says:

You can also use TYPE=FA0(2) here to request a estimate that is
constrained to be nonnegative definite.

  This suggests to me that the model specified is probably singular
(variances equal to zero or correlation equal to +/- 1).  (What do SAS
etc. say if you ask them to report random effect var-cov matrices?)

  It is possible to hack lmer to get term-specific residual variances,
*if* you know in advance which residual variance is the smallest (since
this is done by adding an additional variance term, which must be positive).

  glmmTMB can do term-specific residual variances as well, but isn't as
happy with singular fits.

  nlme takes a lot of iterations to think it's converged because (like
glmmTMB) it's fitting the variance-covariance matrix on a log-Cholesky
scale, which means that it is basically trying to optimize to an
infinite parameter value -- it stops when things look "flat enough".

My results (still had to hack the sign of the effect ...)

         estimate  std.error       PE
glmmTMB 0.1454574 0.04609280 1.156568
nlme    0.1466579 0.04673533 1.157958
lmer    0.1454644 0.04650146 1.156577
SAS     0.1454643 0.04650124 1.156576

  I agree that nlme does worst, but I'm a little alarmed that someone at
the FDA is quibbling over a 0.2% difference [all.equal(1.158,1.156)] in
a numerical computation that has a SE that's about 33% of its mean ...

====
library(RCurl)
library(lme4)
library(nlme)
library(glmmTMB)
library(emmeans)
library(broom.mixed)
url  <- getURL("https://bebac.at/downloads/ds01.csv")
data <- read.csv(text = url, colClasses=c(rep("factor", 4), "numeric"))
options(contrasts=c("contr.SAS","contr.poly"))
##     ?contr.SAS? is a wrapper for contr.treatment that sets the base
##     level to be the last level of the factor.  The coefficients
##     produced when using these contrasts should be equivalent to those
##     produced by many (but not all) SAS procedures.
mod1 <- glmmTMB(log(PK) ~ period + sequence + treatment +
(treatment|subject),
              disp=~treatment-1,
              data = data)

mod2 <- lme(log(PK) ~ period + sequence + treatment ,
            random = ~ treatment | subject, data = data,
            weights = varIdent(~treatment),
            control=lmeControl(maxIter=10000, msMaxIter=10000,
                               msMaxEval=10000))

data$obs <- factor(seq(nrow(data)))
mod3 <- lmer(log(PK) ~ period + sequence + treatment + (treatment|subject) +
                 (dummy(treatment,"R")+0|obs),
             data=data,
             control=lmerControl(check.nobs.vs.nlev="ignore"))

modList <- list(glmmTMB=mod1, nlme=mod2, lmer=mod3)
ff <- function(x) {
    res <- subset(tidy(x, effect="fixed"), term=="treatmentR",
                  select=c(estimate,std.error))
    ## hack sign
    res$estimate <- -res$estimate
    return(as.data.frame(res))
}
res <- do.call(rbind,c(lapply(modList, ff),
                       list(SAS=data.frame(estimate=0.1454643,
                                           std.error=0.04650124))))
res$PE <- exp(res$estimate)
lapply(modList,logLik)


On 2019-08-19 8:41 a.m., Helmut Sch?tz wrote:
> Dear Thierry,
> 
> Thierry Onkelinx wrote on 2019-08-19 14:13:
>> Please do check all parameters. I recall that SAS and R use a
>> different style of dummy coding factor variable.
> 
> I?m not a SASian. Hence, I can?t tell. In R factors specified as
> characters are handled in lexical order and internally coded as integers
> starting with 1.
> 
>> If that is not?the case, please write the full equation for the SAS
>> model. The language of mathematics is the best way to clearly describe
>> a model and thus to compare models.
> 
> Agree.
> Unfortunately the SAS code is all the FDA gives. I think everything is
> clear except the covariance structure given by FA0(2).
> See
> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect019.htm#statug.mixed.mixedrandomtypefa0
> Table 56.13
> Sorry, beyond me.

> Best regards,
> Helmut
>


From he|mut@@chuetz @end|ng |rom beb@c@@t  Mon Aug 19 16:00:45 2019
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Mon, 19 Aug 2019 16:00:45 +0200
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
Message-ID: <0d7a35e7-826e-61d0-7c3c-71cf913130aa@bebac.at>

Dear Thierry,

Thierry Onkelinx wrote on 2019-08-19 13:00:

> [?] The model does not converge on my machine.
>
> library(nlme)
> model2 <- lme(log(PK) ~ period + sequence + treatment , random = ~ 
> treatment | subject, data = data, weights = varIdent(~treatment))

Switching the optimizer from the default "nlminb" to the old one "optim" 
did.

mod? <- lme(log(PK) ~ period + sequence + treatment,
 ????????????????????? random = ~ treatment | subject,
 ????????????????????? data = data, weights = varIdent(~ treatment),
 ????????????????????? method = "REML", na.action = na.exclude,
 ????????????????????? control = list(opt = "optim"))

Now I get a CI of 1.0710967-1.2518824 which is slightly more 
conservative than 1.0710440-1.2489393.

A small step for a man but a giant leap for mankind.Of course, requires 
a lot of testing to check whether this is /always/ the case.

All the best,
Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
W https://bebac.at/
C https://bebac.at/Contact.htm
F https://forum.bebac.at/


	[[alternative HTML version deleted]]


From tu|98250 @end|ng |rom temp|e@edu  Mon Aug 19 20:36:12 2019
From: tu|98250 @end|ng |rom temp|e@edu (Daniel P Moriarity)
Date: Mon, 19 Aug 2019 14:36:12 -0400
Subject: [R-sig-ME] Extracting Lv 1 and Lv 2 residuals: lmer
Message-ID: <CAH9nZDq9d5HLm5qJ3DGK5v-Sv-7kH4kB_s6fMhpwD8_1sDk55A@mail.gmail.com>

Good afternoon,

I e-mailed one of the authors of the residuals function (see below) and
they said that they could not remember but suggested e-mailing this mailing
list. Any help would be appreciated!

"I am attempting to extract the Lv 1 and Lv 2 from an lmer model using the
below syntax, but no matter what I change the "level" to, the resulting
objects are identical. Do either of you have the time to specify how to
change this specifier to extract Lv1 and Lv2 residuals? Thank you.

model1 <- CRP_Dep_Model2 <-lmer(Y ~ X+C+(1|ID), data = Data)

residuals(model1, level = 0:1)

https://astrostatistics.psu.edu/su07/R/html/nlme/html/residuals.lme.html "

My best,
Daniel

Doctoral Student, Clinical Area
Mood and Cognition Lab
Department of Psychology
Temple University
1701 North 13th Street
Philadelphia, PA 19122
daniel.moriarity at temple.edu <hannah.frank at temple.edu>

*WARNING: This e-mail may contain material that is confidential and is for
the sole use of the intended recipient.  If you are not the intended
recipient, please contact the sender and delete all copies.  There are no
guarantees that electronic communications are secure and protected.*

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 19 20:46:10 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Aug 2019 14:46:10 -0400
Subject: [R-sig-ME] [R] linear mixed model required for the U.S. FDA
In-Reply-To: <0d7a35e7-826e-61d0-7c3c-71cf913130aa@bebac.at>
References: <418f92dc-6a0c-04b5-dee7-0eb38cf4191b@bebac.at>
 <CAJuCY5y_vQmH74+=LbbKWp4VqYFLriA98fpintZ_PAayDdBpoQ@mail.gmail.com>
 <0d7a35e7-826e-61d0-7c3c-71cf913130aa@bebac.at>
Message-ID: <5d67e79b-1d83-cde3-c932-a187b55968dc@gmail.com>



On 2019-08-19 10:00 a.m., Helmut Sch?tz wrote:
> Dear Thierry,
> 
> Thierry Onkelinx wrote on 2019-08-19 13:00:
> 
>> [?] The model does not converge on my machine.
>>
>> library(nlme)
>> model2 <- lme(log(PK) ~ period + sequence + treatment , random = ~ 
>> treatment | subject, data = data, weights = varIdent(~treatment))
> 
> Switching the optimizer from the default "nlminb" to the old one "optim" 
> did.
> 
> mod? <- lme(log(PK) ~ period + sequence + treatment,
>  ????????????????????? random = ~ treatment | subject,
>  ????????????????????? data = data, weights = varIdent(~ treatment),
>  ????????????????????? method = "REML", na.action = na.exclude,
>  ????????????????????? control = list(opt = "optim"))
> 
> Now I get a CI of 1.0710967-1.2518824 which is slightly more 
> conservative than 1.0710440-1.2489393.

  This is certainly worth pursuing, but again I want to point out that
these are *barely* different in quantitative terms -- a difference of
0.2% in the upper CI (and note that CI boundaries are inherently *more*
uncertain than the point estimates themselves).  I wouldn't be at all
surprised if small changes in the underlying computational platform
(operating system, compiler, etc.) could make differences this big.

  It would be good to know what level of match is really required.  It's
unlikely that you're going to be able to get an *exact* match to the
floating-point results that SAS gives.  It would also be worth checking
the log-likelihood/REML criterion for each fit -- what happens if lme4
is getting a slightly *better* fit than SAS?  (Also note that the
difference between Wald and profile CIs is about the same magnitude as
the numerical differences you're seeing between packages.)

  "The man with two watches never knows what time it is."

> 
> A small step for a man but a giant leap for mankind.Of course, requires 
> a lot of testing to check whether this is /always/ the case.
> 
> All the best,
> Helmut
>


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 19 21:10:06 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Aug 2019 15:10:06 -0400
Subject: [R-sig-ME] Extracting Lv 1 and Lv 2 residuals: lmer
In-Reply-To: <CAH9nZDq9d5HLm5qJ3DGK5v-Sv-7kH4kB_s6fMhpwD8_1sDk55A@mail.gmail.com>
References: <CAH9nZDq9d5HLm5qJ3DGK5v-Sv-7kH4kB_s6fMhpwD8_1sDk55A@mail.gmail.com>
Message-ID: <a53de67f-3117-d74e-9d33-1315e6f2ab02@gmail.com>




On 2019-08-19 2:36 p.m., Daniel P Moriarity wrote:
> Good afternoon,
> 
> I e-mailed one of the authors of the residuals function (see below) and
> they said that they could not remember but suggested e-mailing this mailing
> list. Any help would be appreciated!


  The URL below points to the help page for the lme function from the
nlme package - which is not the same as the lmer function in the lme4
package.

  individual-level residuals: residuals(model1)
  population-level residuals:  Data$Y - predict(model1, re.form=~0)


> 
> "I am attempting to extract the Lv 1 and Lv 2 from an lmer model using the
> below syntax, but no matter what I change the "level" to, the resulting
> objects are identical. Do either of you have the time to specify how to
> change this specifier to extract Lv1 and Lv2 residuals? Thank you.
> 
> model1 <- CRP_Dep_Model2 <-lmer(Y ~ X+C+(1|ID), data = Data)
> 
> residuals(model1, level = 0:1)
> 
> https://astrostatistics.psu.edu/su07/R/html/nlme/html/residuals.lme.html "
> 
> My best,
> Daniel
> 
> Doctoral Student, Clinical Area
> Mood and Cognition Lab
> Department of Psychology
> Temple University
> 1701 North 13th Street
> Philadelphia, PA 19122
> daniel.moriarity at temple.edu <hannah.frank at temple.edu>
> 
> *WARNING: This e-mail may contain material that is confidential and is for
> the sole use of the intended recipient.  If you are not the intended
> recipient, please contact the sender and delete all copies.  There are no
> guarantees that electronic communications are secure and protected.*
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thom@@merk||ng00 @end|ng |rom gm@||@com  Thu Aug 22 12:10:33 2019
From: thom@@merk||ng00 @end|ng |rom gm@||@com (Thomas MERKLING)
Date: Thu, 22 Aug 2019 12:10:33 +0200
Subject: [R-sig-ME] separate variance-covariance matrix for each level of
 grouping variable
Message-ID: <CAK3fCjrp6kM7=GEggsFnp27xLq90pKV33Wrzs9U2iM5voJZ_yw@mail.gmail.com>

Hi all,

I'm interested in modeling a separate variance-covariance matrix for
different levels of a factor variable. I have a SAS example (using the
epilepsy from the brms package as an example):

proc mixed data = epilepsy method = reml;
                  class patient Trt;
                  model count = Trt /s ddfm = satterth;
                 random int zAge / type = un subject=patient group=Trt;
run;

The gr argument in the brms package seems to enable to do that too, as the
group-level effects correspond to a random intercept and slope and a
covariance between the two estimated separately for each level of the Trt
variable.

fit3 <- brm(count ~ Trt + (zAge|gr(patient, by = Trt)), data = epilepsy)

Group-Level Effects:
~patient (Number of levels: 59)
                              Estimate Est.Error l-95% CI u-95% CI
Eff.Sample Rhat
sd(Intercept:Trt0)                7.86      1.41     5.39    10.91
1071 1.00
sd(zAge:Trt0)                     4.14      2.62     0.25     9.97
 546 1.00
sd(Intercept:Trt1)                9.23      1.96     5.37    13.31
 691 1.00
sd(zAge:Trt1)                     7.60      2.24     3.92    12.54
 586 1.01
cor(Intercept:Trt0,zAge:Trt0)     0.57      0.42    -0.60     0.99
1252 1.00
cor(Intercept:Trt1,zAge:Trt1)    -0.85      0.15    -1.00    -0.45
 594 1.00

How do I need to specify the random effect part of the model in lme4 or
glmmTMB to get the same results?

I have tried: fit4 <- glmmTMB(count ~ Trt + (0 + Trt*zAge | patient), data
= epilepsy)
but it seems to calculate correlations between each pair of random
intercept and slope and not only within a factor level.

Random effects:

Conditional model:
 Groups   Name      Variance  Std.Dev.    Corr
 patient    Trt0           56.221   7.498
                Trt1          103.601  10.178    -0.92
                  zAge       15.793   3.974       0.94 -0.97
            Trt1:zAge        6.443   2.538       0.78 -0.92  0.80
 Residual                   32.211   5.675

Thanks in advance for your help,
Thomas

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Aug 22 15:44:03 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 22 Aug 2019 09:44:03 -0400
Subject: [R-sig-ME] 
 separate variance-covariance matrix for each level of
 grouping variable
In-Reply-To: <CAK3fCjrp6kM7=GEggsFnp27xLq90pKV33Wrzs9U2iM5voJZ_yw@mail.gmail.com>
References: <CAK3fCjrp6kM7=GEggsFnp27xLq90pKV33Wrzs9U2iM5voJZ_yw@mail.gmail.com>
Message-ID: <2c94057f-7473-e008-2f17-9b85e638d8db@gmail.com>

count ~ Trt + (0 + dummy(Trt, "Trt0"):zAge | patient) +
              (0 + dummy(Trt, "Trt1"):zAge | patient)

might work in either glmmTMB or lme4.  The dummy() function (which is in
the lme4 package, you may need to load it even if you're using glmmTMB)
is 'sugar' for creating a numeric dummy variable.  An interaction with a
numeric variable corresponds to multiplying the interacting term by the
variable, so (for example) the first term is zero except for
observations in Trt0.

  This hack gets awkward if you have lots of groups (although you can
always construct the formula programmatically).

   In lme4 you may have to use lmerControl() to override some of the
checks that there aren't too many random-effects levels.

  Ben Bolker


From thom@@merk||ng00 @end|ng |rom gm@||@com  Fri Aug 23 13:44:51 2019
From: thom@@merk||ng00 @end|ng |rom gm@||@com (Thomas MERKLING)
Date: Fri, 23 Aug 2019 13:44:51 +0200
Subject: [R-sig-ME] 
 separate variance-covariance matrix for each level of
 grouping variable
In-Reply-To: <mailman.17769.7.1566554402.25347.r-sig-mixed-models@r-project.org>
References: <mailman.17769.7.1566554402.25347.r-sig-mixed-models@r-project.org>
Message-ID: <CAK3fCjpC5o6jJ3NeTU1C5EvhLjsZZ9+d3i2XjTNfbroodsHBqg@mail.gmail.com>

Thanks Ben for your reply,

I used:

glmmTMB(count ~ Trt + (0 + dummy(Trt, "0") + dummy(Trt, "0"):zAge |
patient) + (0 + dummy(Trt, "1") + dummy(Trt, "1"):zAge | patient), data =
epilepsy)

which gave me similar SDs for the random intercepts and slopes as the brms
output but the correlations were 1 and -1 (see below) which is quite
different from the brms output (0.56 and -0.84).
Given that the correlations were exactly 1 and -1, I'm wondering if it is
the exact same fit as brms (count ~ Trt + (zAge|gr(patient, by = Trt)),
data = epilepsy), or if something differs in how the covariances are
estimated ?

Thomas

Conditional model:
 Groups    Name                     Variance   Std.Dev.   Corr
 patient   dummy(Trt, "0")         57.57        7.588
           dummy(Trt, "0"):zAge    11.60        3.405   1.00
 patient.1 dummy(Trt, "1")        103.60     10.178
           dummy(Trt, "1"):zAge    38.37        6.194   -1.00
 Residual                                   32.21    5.676


>
> count ~ Trt + (0 + dummy(Trt, "Trt0"):zAge | patient) +
>               (0 + dummy(Trt, "Trt1"):zAge | patient)
>
> might work in either glmmTMB or lme4.  The dummy() function (which is in
> the lme4 package, you may need to load it even if you're using glmmTMB)
> is 'sugar' for creating a numeric dummy variable.  An interaction with a
> numeric variable corresponds to multiplying the interacting term by the
> variable, so (for example) the first term is zero except for
> observations in Trt0.
>
>   This hack gets awkward if you have lots of groups (although you can
> always construct the formula programmatically).
>
>    In lme4 you may have to use lmerControl() to override some of the
> checks that there aren't too many random-effects levels.
>
>   Ben Bolker
>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Aug 23 15:51:51 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 23 Aug 2019 09:51:51 -0400
Subject: [R-sig-ME] 
 separate variance-covariance matrix for each level of
 grouping variable
In-Reply-To: <CAK3fCjpC5o6jJ3NeTU1C5EvhLjsZZ9+d3i2XjTNfbroodsHBqg@mail.gmail.com>
References: <mailman.17769.7.1566554402.25347.r-sig-mixed-models@r-project.org>
 <CAK3fCjpC5o6jJ3NeTU1C5EvhLjsZZ9+d3i2XjTNfbroodsHBqg@mail.gmail.com>
Message-ID: <3d21e6e4-4909-9934-0bfb-6623d2cfeaed@gmail.com>


  The most obvious differences are that brms (a) imposes priors on all
parameters and (b) computes the point estimate by taking the posterior
mean (maybe median? I'm not sure) rather than the value with the highest
likelihood.

There are some good answers about MLE vs Bayesian answers here:

https://stats.stackexchange.com/questions/401349/maximum-likelihood-parameters-deviate-from-posterior-distributions/401356#401356

  To explore this further you could (1) try out the blme package, which
allows for priors (not necessarily the same as those used in brms
through) and finds MAP (maximum a posteriori) estimates; (2) look at the
likelihood profile for the confidence intervals, and/or their posterior
distributions, which should show you that they're very flat [in which
case it's easy to get a large difference between the MLE and the
posterior mean due to the combination of priors and mode vs mean])

On 2019-08-23 7:44 a.m., Thomas MERKLING wrote:
> Thanks Ben for your reply,
> 
> I used:
> 
> glmmTMB(count ~ Trt + (0 + dummy(Trt, "0") + dummy(Trt, "0"):zAge |
> patient) + (0 + dummy(Trt, "1") + dummy(Trt, "1"):zAge | patient), data =
> epilepsy)
> 
> which gave me similar SDs for the random intercepts and slopes as the brms
> output but the correlations were 1 and -1 (see below) which is quite
> different from the brms output (0.56 and -0.84).
> Given that the correlations were exactly 1 and -1, I'm wondering if it is
> the exact same fit as brms (count ~ Trt + (zAge|gr(patient, by = Trt)),
> data = epilepsy), or if something differs in how the covariances are
> estimated ?
> 
> Thomas
> 
> Conditional model:
>  Groups    Name                     Variance   Std.Dev.   Corr
>  patient   dummy(Trt, "0")         57.57        7.588
>            dummy(Trt, "0"):zAge    11.60        3.405   1.00
>  patient.1 dummy(Trt, "1")        103.60     10.178
>            dummy(Trt, "1"):zAge    38.37        6.194   -1.00
>  Residual                                   32.21    5.676
> 
> 
>>
>> count ~ Trt + (0 + dummy(Trt, "Trt0"):zAge | patient) +
>>               (0 + dummy(Trt, "Trt1"):zAge | patient)
>>
>> might work in either glmmTMB or lme4.  The dummy() function (which is in
>> the lme4 package, you may need to load it even if you're using glmmTMB)
>> is 'sugar' for creating a numeric dummy variable.  An interaction with a
>> numeric variable corresponds to multiplying the interacting term by the
>> variable, so (for example) the first term is zero except for
>> observations in Trt0.
>>
>>   This hack gets awkward if you have lots of groups (although you can
>> always construct the formula programmatically).
>>
>>    In lme4 you may have to use lmerControl() to override some of the
>> checks that there aren't too many random-effects levels.
>>
>>   Ben Bolker
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From to@tm@nnk@th@r|n@ @end|ng |rom gm@||@com  Sat Aug 24 11:08:27 2019
From: to@tm@nnk@th@r|n@ @end|ng |rom gm@||@com (Katharina Tostmann)
Date: Sat, 24 Aug 2019 11:08:27 +0200
Subject: [R-sig-ME] Testing assumption multilevel analysis
Message-ID: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>

Hello together,

I'm calculating a multi-level analysis in R. However, I do not understand
how to test the model assumptions. In my second hypothesis I also have a
mediation with, whereby I also have no idea how to test the model
assumptions.
Can anyone help here? Thank you and best regards

Katharina

	[[alternative HTML version deleted]]


From v|ncent@n@don @end|ng |rom et@mt|@c@  Thu Aug 22 18:16:54 2019
From: v|ncent@n@don @end|ng |rom et@mt|@c@ (Nadon, Vincent)
Date: Thu, 22 Aug 2019 12:16:54 -0400
Subject: [R-sig-ME] Multivariate Mixed Models using LME4 and glmmTMB
Message-ID: <287110bb2a9527a48fb74d633eb2d748@groupoffice.critias.etsmtl.ca>

Dear Ben,

To follow-up on our discussion on stack overflow [1].?Thanks for all
your help.?

When you say?## I'm not quite sure how you're getting away without
## this ...?
in?:


## parameters (chosen rather arbitrarily) np 

Links:
------
[1]
https://stackoverflow.com/questions/57526362/lme4-for-multivariate-mixed-models-never-end-up-converging-finishing-executing/57560547?noredirect=1#comment101590609_57560547

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Mon Aug 26 12:05:41 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Mon, 26 Aug 2019 12:05:41 +0200
Subject: [R-sig-ME] Main effects dilemma in logistic regression
In-Reply-To: <CABX-QoHbLQVUafQcbvK3gk0s8CpsLZO5PdyG55NWqf=PA3Tbtg@mail.gmail.com>
References: <CABX-QoHbLQVUafQcbvK3gk0s8CpsLZO5PdyG55NWqf=PA3Tbtg@mail.gmail.com>
Message-ID: <CABX-QoH-KpS77q0pFyckFuyj56w-W4J54vS9o78rq3hYfkCmsg@mail.gmail.com>

Dear all,


Apologies for cross-posting if you are also part of R-ling-lang.
I am struggling to understand my results and would appreciate some advice
on a matter that has more to do with understanding logistic regression
outputs in R than actual issues with ME.

I have modelled a binomial mixed effects regression via glmer with two IVs,
a Task factor with two levels (AJT, priming) and a Proficiency continuous
predictor centered on its mean (proficiency). The DV is correct versus
incorrect response on the two tests. Participants and items are added as
random effects along with a slope of task by participants.

The main effects analysis of the model


*correctness ~ task * cent_Proficiency + (1 + task | Participant) +  (1 |
item)*

is as follows


> car::Anova(profmodL2)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: correctness
                        Chisq Df Pr(>Chisq)
task                  17.1340  1  3.483e-05 ***
cent_Proficiency       0.2377  1   0.625868
task:cent_Proficiency  7.6260  1   0.005753 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


What I am interested in is the relationship between the continuous
predictor and each level of task. As far as I understand, the main
interaction here is irrelevant to my query since what I am really after is
understanding is whether each increase in unit for proficiency results in
statistically significant log odd increase or decrease on each task. Thus,
I investigating simple effects of proficiency at each of the two levels of
the task factor.

Simple effect analysis yields:

> summary(profmodL2)
Cov prior  : item ~ wishart(df = 3.5, scale = Inf, posterior.scale = cov,
common.scale = TRUE)
           : Participant ~ wishart(df = 4.5, scale = Inf, posterior.scale =
cov, common.scale = TRUE)
Prior dev  : 2.2697

Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [bglmerMod]
 Family: binomial  ( logit )
Formula:
correctness ~ task * cent_Proficiency + (1 + task | Participant) +
    (1 | item)
   Data: prodataL2
Control: glmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid
  1288.2   1331.0   -636.1   1272.2     1547

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.6314 -0.4378 -0.2570 -0.1624  4.8020

Random effects:
 Groups      Name        Variance Std.Dev. Corr
 item        (Intercept) 1.0547   1.0270
 Participant (Intercept) 0.5403   0.7350
             taskpriming 0.7617   0.8728   -0.70
Number of obs: 1555, groups:  item, 219; Participant, 13

Fixed effects:
                             Estimate Std. Error z value Pr(>|z|)
(Intercept)                  -2.58787    0.27034  -9.573  < 2e-16 ***
taskpriming                   1.47193    0.33943   4.336 1.45e-05 ***
cent_Proficiency             -0.06246    0.02659  -2.349  0.01884 *
taskpriming:cent_Proficiency  0.08935    0.03235   2.762  0.00575 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) tskprm cnt_Pr
taskpriming -0.685
cnt_Prfcncy  0.123 -0.087
tskprmng:_P -0.107  0.076 -0.730

Interpreting the coefficient for cent_Proficiency, it looks like the log
odds of a correct response decrease by .06, signalled by the - sign, when
the task is the AJT (default level), for each unit increase in proficiency.
This effect is mildly significant at the p <.05 level.

Here is the dilemma. If I graph the results I obtain the plot in attachment
where the probability in the AJT of a correct answer (coded as 1) is
actually the other way around, that is directly proportional to proficiency.

The R script for the ggplot is taken from the last page of the VCD package,
reported here for convenience in its original:

> ggplot(Donner, aes(age, survived, color = sex)) +

+ geom_point(position = position_jitter(height = 0.02, width = 0)) +

+ stat_smooth(method = "glm", family = binomial, formula = y ~ x,

+ alpha = 0.2, size=2, aes(fill = sex))


What am I to make of this?

Best,

Francesco

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plotL22.pdf
Type: application/pdf
Size: 104806 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190826/19c0e45c/attachment-0001.pdf>

From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Aug 26 14:14:16 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 26 Aug 2019 14:14:16 +0200
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
Message-ID: <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>

This is a rather open-ended request -- you're more likely to get helpful
advice if you're a bit more specific. For example, which model
assumptions do you want to test in particular? What do your data look
like? Which assumptions do you think your data might violate? Why do you
want to explicitly test assumptions? (e.g. Are you worried about
inflated Type-I error? Often it's better to worry less about assumptions
per se and instead focus on "does my model capture the relevant aspects
of my data?")

Phillip

On 24/8/19 11:08 am, Katharina Tostmann wrote:
> Hello together,
> 
> I'm calculating a multi-level analysis in R. However, I do not understand
> how to test the model assumptions. In my second hypothesis I also have a
> mediation with, whereby I also have no idea how to test the model
> assumptions.
> Can anyone help here? Thank you and best regards
> 
> Katharina
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 26 15:41:56 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 26 Aug 2019 09:41:56 -0400
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
 <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
Message-ID: <bf26a182-dab0-fdb3-061e-38f8d84bf816@gmail.com>


  Most of the assumptions of mixed/multivel/hierarchical are inherited
from the standard (generalized) linear modeling assumptions, and at
least the graphical diagnostics are done in the same way (residual vs
fitted plot, scale-location plot, Q-Q plots of residuals, influence
plots).  The main additional assumptions have to do with the group-level
effects, which are typically assumed to be normally distributed.
Typically people use "caterpillar plots" (plots of the BLUPS/conditional
modes for each group, sorted, with error bars based on the conditional
variances) to evaluate these distributional assumptions.

  There are some worked examples of mixed models (in ecology) at
https://bbolker.github.io/mixedmodels-misc/ecostats_chap.html

  Giving more context (as Phillip Alday suggests) would be a good idea.
 In particular, different research fields may emphasize different
criteria more or less.

On 2019-08-26 8:14 a.m., Phillip Alday wrote:
> This is a rather open-ended request -- you're more likely to get helpful
> advice if you're a bit more specific. For example, which model
> assumptions do you want to test in particular? What do your data look
> like? Which assumptions do you think your data might violate? Why do you
> want to explicitly test assumptions? (e.g. Are you worried about
> inflated Type-I error? Often it's better to worry less about assumptions
> per se and instead focus on "does my model capture the relevant aspects
> of my data?")
> 
> Phillip
> 
> On 24/8/19 11:08 am, Katharina Tostmann wrote:
>> Hello together,
>>
>> I'm calculating a multi-level analysis in R. However, I do not understand
>> how to test the model assumptions. In my second hypothesis I also have a
>> mediation with, whereby I also have no idea how to test the model
>> assumptions.
>> Can anyone help here? Thank you and best regards
>>
>> Katharina
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Aug 26 17:35:00 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 26 Aug 2019 17:35:00 +0200
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <CADAgCbwzxueLFWqNW1TS9MD5qbqp6C1F9avWDJakURcjT7QhVw@mail.gmail.com>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
 <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
 <CADAgCbwzxueLFWqNW1TS9MD5qbqp6C1F9avWDJakURcjT7QhVw@mail.gmail.com>
Message-ID: <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>

Please keep the list in CC.

As Ben Bolker mentioned in his reply: for most things, the assumptions
carry over from the non-mixed case and the graphical diagnostics are
done the same way. I would in general avoid explicit statistical tests
of model assumptions (e.g. various tests of normality) because, like all
tests, they have failure modes (especially related to sensitivity and
specificity) and don't actually tell you what any potential violation of
assumptions is doing to your statistical procedure.

For multicollinearity, there is one additional diagnostic that lme4
gives you in its summary output, namely the correlation of fixed
effects. The exact meaning of this is perhaps a little technical
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001941.html),
but in practical terms a high correlation suggests that there may be
multicollinearity. Multicollinearity also tends to show itself in
inflated standard errors (in the fixed effects), much as it does for
standard linear regression.

Regarding independence of errors: I find that to be an assumption that
is often best checked by knowing something about your data generating
process. For example, there may be some autocorrelation in the errors
between observations due to the way data are collected.

Best,
Phillip

On 26/8/19 2:23 pm, Katharina Tostmann wrote:
> Hello Phillip,
> 
> Yes, I know it is a very big question about the assumptions in general.
> At this time I got a little information about linearity, normal
> distibution and variance homogenity. But what ist about
> mulitcollinearity and independency? Do you have any idea to check this
> in a multilevel context?
> 
> Thank you in advance.
> 
> 
> best regards from Germany
> 
> Katharina
> 
> Am Mo., 26. Aug. 2019 um 14:14?Uhr schrieb Phillip Alday
> <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>>:
> 
>     This is a rather open-ended request -- you're more likely to get helpful
>     advice if you're a bit more specific. For example, which model
>     assumptions do you want to test in particular? What do your data look
>     like? Which assumptions do you think your data might violate? Why do you
>     want to explicitly test assumptions? (e.g. Are you worried about
>     inflated Type-I error? Often it's better to worry less about assumptions
>     per se and instead focus on "does my model capture the relevant aspects
>     of my data?")
> 
>     Phillip
> 
>     On 24/8/19 11:08 am, Katharina Tostmann wrote:
>     > Hello together,
>     >
>     > I'm calculating a multi-level analysis in R. However, I do not
>     understand
>     > how to test the model assumptions. In my second hypothesis I also
>     have a
>     > mediation with, whereby I also have no idea how to test the model
>     > assumptions.
>     > Can anyone help here? Thank you and best regards
>     >
>     > Katharina
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From bbo|ker @end|ng |rom gm@||@com  Mon Aug 26 18:23:23 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 26 Aug 2019 12:23:23 -0400
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
 <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
 <CADAgCbwzxueLFWqNW1TS9MD5qbqp6C1F9avWDJakURcjT7QhVw@mail.gmail.com>
 <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>
Message-ID: <da1543e1-7582-350d-7b25-3693e851f013@gmail.com>


  Carrying on (in case it's useful to future readers):

  - I'll go a little bit further than Phillip and point out that
independence of errors is difficult to test *at all* without further
information (e.g. spatial and temporal structure).  If you do have
spatial/temporal structure you can try computing autocorrelation
functions (e.g. using lme() and ACF())
  - lack of multicollinearity is *not* an assumption of multilevel
analysis.  It is a potential problem (in that it makes inference and
prediction harder), but not a violation of the assumptions.  I like this
paper:

Graham, Michael H. ?Confronting Multicollinearity in Ecological Multiple
Regression.? Ecology 84, no. 11 (2003): 2809?15.
https://doi.org/10.1890/02-3114.



On 2019-08-26 11:35 a.m., Phillip Alday wrote:
> Please keep the list in CC.
> 
> As Ben Bolker mentioned in his reply: for most things, the assumptions
> carry over from the non-mixed case and the graphical diagnostics are
> done the same way. I would in general avoid explicit statistical tests
> of model assumptions (e.g. various tests of normality) because, like all
> tests, they have failure modes (especially related to sensitivity and
> specificity) and don't actually tell you what any potential violation of
> assumptions is doing to your statistical procedure.
> 
> For multicollinearity, there is one additional diagnostic that lme4
> gives you in its summary output, namely the correlation of fixed
> effects. The exact meaning of this is perhaps a little technical
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001941.html),
> but in practical terms a high correlation suggests that there may be
> multicollinearity. Multicollinearity also tends to show itself in
> inflated standard errors (in the fixed effects), much as it does for
> standard linear regression.
> 
> Regarding independence of errors: I find that to be an assumption that
> is often best checked by knowing something about your data generating
> process. For example, there may be some autocorrelation in the errors
> between observations due to the way data are collected.
> 
> Best,
> Phillip
> 
> On 26/8/19 2:23 pm, Katharina Tostmann wrote:
>> Hello Phillip,
>>
>> Yes, I know it is a very big question about the assumptions in general.
>> At this time I got a little information about linearity, normal
>> distibution and variance homogenity. But what ist about
>> mulitcollinearity and independency? Do you have any idea to check this
>> in a multilevel context?
>>
>> Thank you in advance.
>>
>>
>> best regards from Germany
>>
>> Katharina
>>
>> Am Mo., 26. Aug. 2019 um 14:14?Uhr schrieb Phillip Alday
>> <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>>:
>>
>>     This is a rather open-ended request -- you're more likely to get helpful
>>     advice if you're a bit more specific. For example, which model
>>     assumptions do you want to test in particular? What do your data look
>>     like? Which assumptions do you think your data might violate? Why do you
>>     want to explicitly test assumptions? (e.g. Are you worried about
>>     inflated Type-I error? Often it's better to worry less about assumptions
>>     per se and instead focus on "does my model capture the relevant aspects
>>     of my data?")
>>
>>     Phillip
>>
>>     On 24/8/19 11:08 am, Katharina Tostmann wrote:
>>     > Hello together,
>>     >
>>     > I'm calculating a multi-level analysis in R. However, I do not
>>     understand
>>     > how to test the model assumptions. In my second hypothesis I also
>>     have a
>>     > mediation with, whereby I also have no idea how to test the model
>>     > assumptions.
>>     > Can anyone help here? Thank you and best regards
>>     >
>>     > Katharina
>>     >
>>     >? ? ? ?[[alternative HTML version deleted]]
>>     >
>>     > _______________________________________________
>>     > R-sig-mixed-models at r-project.org
>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>     >
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Mon Aug 26 18:43:31 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Mon, 26 Aug 2019 16:43:31 +0000
Subject: [R-sig-ME] 
 Multiple comparisons and post hoc tests on glmmTMB model,
 with the multcomp package.
Message-ID: <22976dc0f8dc4c77ab07771aa5da2ab7@unige.ch>

Hi,


I have the next model:

zipoisson <- glmmTMB(Observations ~ CAP * Condition + (1|ID), data=mDATA, ziformula=~ CAP * Condition , family=poisson)

Which result is:
 Family: nbinom1  ( log )
Formula:          Observations ~ CAP * Condition + (1 | ID)
Zero inflation:                ~CAP * Condition
Data: mDATA
     AIC      BIC   logLik deviance df.resid
  4798.4   4979.5  -2365.2   4730.4     1486

Random effects:
Conditional model:
 Groups Name        Variance Std.Dev.
 ID     (Intercept) 0.003643 0.06036
Number of obs: 1520, groups:  ID, 19

Overdispersion parameter for nbinom1 family (): 0.681

Conditional model:
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)             1.09079    0.11695   9.327  < 2e-16 ***
CAPinsC5               -1.03221    0.32151  -3.210  0.00133 **
CAPpreC1               -0.10200    0.17408  -0.586  0.55794
CAPpreC5               -0.50219    0.21082  -2.382  0.01722 *
Conditionaff           -0.17668    0.17403  -1.015  0.31000
Conditionneu           -0.12073    0.18997  -0.636  0.52509
Conditionpneu          -0.25180    0.19119  -1.317  0.18784
CAPinsC5:Conditionaff   1.17944    0.36350   3.245  0.00118 **
CAPpreC1:Conditionaff   0.40988    0.23992   1.708  0.08756 .
CAPpreC5:Conditionaff   0.33029    0.29746   1.110  0.26685
CAPinsC5:Conditionneu   0.75961    0.39673   1.915  0.05553 .
CAPpreC1:Conditionneu  -0.05464    0.27420  -0.199  0.84205
CAPpreC5:Conditionneu   0.57299    0.28324   2.023  0.04308 *
CAPinsC5:Conditionpneu  1.01513    0.42694   2.378  0.01742 *
CAPpreC1:Conditionpneu  0.14104    0.27380   0.515  0.60647
CAPpreC5:Conditionpneu  0.22652    0.33243   0.681  0.49562
---

I want to apply the Multiple comparisons and post hoc tests proposed in:
https://cran.r-project.org/web/packages/glmmTMB/vignettes/model_evaluation.html#mumin
but it is not clear to me what stands for "components" and "period"


Thanks in advance for any input.

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Aug 26 18:57:11 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 26 Aug 2019 16:57:11 +0000
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <29910_1566836622_x7QGNf5n026354_da1543e1-7582-350d-7b25-3693e851f013@gmail.com>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
 <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
 <CADAgCbwzxueLFWqNW1TS9MD5qbqp6C1F9avWDJakURcjT7QhVw@mail.gmail.com>
 <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>
 <29910_1566836622_x7QGNf5n026354_da1543e1-7582-350d-7b25-3693e851f013@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836CDFEB2@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben et al.,

Chiming in a bit late, there's some discussion of various diagnostics (nonlinearity, unusual data, collinearity) for mixed-effects models in Ch. 8 of Fox and Weisberg, An R Companion to Applied Regression, 3rd Ed. (Sage, 2019).

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Monday, August 26, 2019 12:23 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Testing assumption multilevel analysis
> 
> 
>   Carrying on (in case it's useful to future readers):
> 
>   - I'll go a little bit further than Phillip and point out that
> independence of errors is difficult to test *at all* without further
> information (e.g. spatial and temporal structure).  If you do have
> spatial/temporal structure you can try computing autocorrelation functions
> (e.g. using lme() and ACF())
>   - lack of multicollinearity is *not* an assumption of multilevel
> analysis.  It is a potential problem (in that it makes inference and
> prediction harder), but not a violation of the assumptions.  I like this
> paper:
> 
> Graham, Michael H. ?Confronting Multicollinearity in Ecological Multiple
> Regression.? Ecology 84, no. 11 (2003): 2809?15.
> https://doi.org/10.1890/02-3114.
> 
> 
> 
> On 2019-08-26 11:35 a.m., Phillip Alday wrote:
> > Please keep the list in CC.
> >
> > As Ben Bolker mentioned in his reply: for most things, the assumptions
> > carry over from the non-mixed case and the graphical diagnostics are
> > done the same way. I would in general avoid explicit statistical tests
> > of model assumptions (e.g. various tests of normality) because, like
> > all tests, they have failure modes (especially related to sensitivity
> > and
> > specificity) and don't actually tell you what any potential violation
> > of assumptions is doing to your statistical procedure.
> >
> > For multicollinearity, there is one additional diagnostic that lme4
> > gives you in its summary output, namely the correlation of fixed
> > effects. The exact meaning of this is perhaps a little technical
> > (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001941.html)
> > , but in practical terms a high correlation suggests that there may be
> > multicollinearity. Multicollinearity also tends to show itself in
> > inflated standard errors (in the fixed effects), much as it does for
> > standard linear regression.
> >
> > Regarding independence of errors: I find that to be an assumption that
> > is often best checked by knowing something about your data generating
> > process. For example, there may be some autocorrelation in the errors
> > between observations due to the way data are collected.
> >
> > Best,
> > Phillip
> >
> > On 26/8/19 2:23 pm, Katharina Tostmann wrote:
> >> Hello Phillip,
> >>
> >> Yes, I know it is a very big question about the assumptions in general.
> >> At this time I got a little information about linearity, normal
> >> distibution and variance homogenity. But what ist about
> >> mulitcollinearity and independency? Do you have any idea to check
> >> this in a multilevel context?
> >>
> >> Thank you in advance.
> >>
> >>
> >> best regards from Germany
> >>
> >> Katharina
> >>
> >> Am Mo., 26. Aug. 2019 um 14:14?Uhr schrieb Phillip Alday
> >> <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>>:
> >>
> >>     This is a rather open-ended request -- you're more likely to get
> helpful
> >>     advice if you're a bit more specific. For example, which model
> >>     assumptions do you want to test in particular? What do your data
> look
> >>     like? Which assumptions do you think your data might violate? Why
> do you
> >>     want to explicitly test assumptions? (e.g. Are you worried about
> >>     inflated Type-I error? Often it's better to worry less about
> assumptions
> >>     per se and instead focus on "does my model capture the relevant
> aspects
> >>     of my data?")
> >>
> >>     Phillip
> >>
> >>     On 24/8/19 11:08 am, Katharina Tostmann wrote:
> >>     > Hello together,
> >>     >
> >>     > I'm calculating a multi-level analysis in R. However, I do not
> >>     understand
> >>     > how to test the model assumptions. In my second hypothesis I also
> >>     have a
> >>     > mediation with, whereby I also have no idea how to test the model
> >>     > assumptions.
> >>     > Can anyone help here? Thank you and best regards
> >>     >
> >>     > Katharina
> >>     >
> >>     >? ? ? ?[[alternative HTML version deleted]]
> >>     >
> >>     > _______________________________________________
> >>     > R-sig-mixed-models at r-project.org
> >>     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>     >
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Tue Aug 27 12:01:01 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Tue, 27 Aug 2019 10:01:01 +0000
Subject: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
 model
Message-ID: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>

Hello,


I have the next model:

> zipoisson2  <- glmmTMB(Observations ~ CAP * Condition + (1|ID), contrasts=list(CAP="contr.sum",Condition="contr.sum"), data=mDATA, ziformula=~ 1 , family=poisson)


Plotting the effects ("effects" package), I obtain:

(ae <- allEffects(zipoisson2))

model: Observations ~ CAP * Condition
 CAP*Condition effect
        Condition
CAP        aapaff      aff      neu     pneu
  apreC3 3.222636 2.731724 2.777021 2.573694
  insC5  1.406698 3.173030 2.104875 1.420336
  preC1  2.883115 3.641252 2.541221 2.635991
  preC5  2.184075 2.310564 3.137734 1.995430

plot(ae)
Error in UseMethod("droplevels") :
  no applicable method for 'droplevels' applied to an object of class "character"

Question 1: Has anyone encountered the same issue? Any hint to solve it?

Question 2: Maybe is there any other package works better with glmmTMB model

Thanks in advance for any hint about it.

Julian,

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Tue Aug 27 14:01:42 2019
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Tue, 27 Aug 2019 14:01:42 +0200
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
Message-ID: <000001d55ccf$30b7df80$92279e80$@uke.de>

Dear Katharina,

in addition to what has already been said, may I point out to the
"performance" package, which might be helpful to check your model
assumptions and how your model performs in general. You can find an overview
of functions here:
https://easystats.github.io/performance/reference/index.html

Regarding visual inspection, if you also install the "see" package, most of
the results of functions from "performance" can also be plotted, see
examples here:
https://easystats.github.io/see/articles/performance.html

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
Auftrag von Katharina Tostmann
Gesendet: Samstag, 24. August 2019 11:08
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Testing assumption multilevel analysis

Hello together,

I'm calculating a multi-level analysis in R. However, I do not understand
how to test the model assumptions. In my second hypothesis I also have a
mediation with, whereby I also have no idea how to test the model
assumptions.
Can anyone help here? Thank you and best regards

Katharina

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From d@|uedecke @end|ng |rom uke@de  Tue Aug 27 14:06:58 2019
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Tue, 27 Aug 2019 14:06:58 +0200
Subject: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
 model
In-Reply-To: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>
References: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>
Message-ID: <000101d55ccf$ed7fa990$c87efcb0$@uke.de>

Dear Julian,

without a reproducible example, it's a bit difficult to guess how to solve
your issue. Is one of your predictors of class "character" and should
probably be coerced to factor before you fit your model?

Else, you could also try the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), where you have three functions:
ggpredict(), ggeffect() and ggemmeans(), each calling the related functions
"predict()", "effects::effect()" or "emmeans::emmeans()" internally to
compute marginal effects. There is a plot() method as well, based on ggplot2
(see examples here
https://strengejacke.github.io/ggeffects/articles/introduction_plotcustomize
.html or here
https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.ht
ml). 

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
Auftrag von Julian Gaviria Lopez
Gesendet: Dienstag, 27. August 2019 12:01
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
model

Hello,


I have the next model:

> zipoisson2  <- glmmTMB(Observations ~ CAP * Condition + (1|ID), 
> contrasts=list(CAP="contr.sum",Condition="contr.sum"), data=mDATA, 
> ziformula=~ 1 , family=poisson)


Plotting the effects ("effects" package), I obtain:

(ae <- allEffects(zipoisson2))

model: Observations ~ CAP * Condition
 CAP*Condition effect
        Condition
CAP        aapaff      aff      neu     pneu
  apreC3 3.222636 2.731724 2.777021 2.573694
  insC5  1.406698 3.173030 2.104875 1.420336
  preC1  2.883115 3.641252 2.541221 2.635991
  preC5  2.184075 2.310564 3.137734 1.995430

plot(ae)
Error in UseMethod("droplevels") :
  no applicable method for 'droplevels' applied to an object of class
"character"

Question 1: Has anyone encountered the same issue? Any hint to solve it?

Question 2: Maybe is there any other package works better with glmmTMB model

Thanks in advance for any hint about it.

Julian,

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From bbo|ker @end|ng |rom gm@||@com  Tue Aug 27 15:31:33 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 27 Aug 2019 09:31:33 -0400
Subject: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
 model
In-Reply-To: <000101d55ccf$ed7fa990$c87efcb0$@uke.de>
References: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>
 <000101d55ccf$ed7fa990$c87efcb0$@uke.de>
Message-ID: <c6503eaf-939b-bcd2-59af-5088f960cb3d@gmail.com>


  Yes, quite weird as effects:::plot.eff (the relevant method) appears
to check that variables are factors every time it tries to applies
droplevels().  A reproducible example would be great (although
technically maybe not this list's problem, as it's not clear it's
directly mixed-model-related?)

On 2019-08-27 8:06 a.m., Daniel L?decke wrote:
> Dear Julian,
> 
> without a reproducible example, it's a bit difficult to guess how to solve
> your issue. Is one of your predictors of class "character" and should
> probably be coerced to factor before you fit your model?
> 
> Else, you could also try the "ggeffects" package
> (https://strengejacke.github.io/ggeffects/), where you have three functions:
> ggpredict(), ggeffect() and ggemmeans(), each calling the related functions
> "predict()", "effects::effect()" or "emmeans::emmeans()" internally to
> compute marginal effects. There is a plot() method as well, based on ggplot2
> (see examples here
> https://strengejacke.github.io/ggeffects/articles/introduction_plotcustomize
> .html or here
> https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.ht
> ml). 
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
> Auftrag von Julian Gaviria Lopez
> Gesendet: Dienstag, 27. August 2019 12:01
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
> model
> 
> Hello,
> 
> 
> I have the next model:
> 
>> zipoisson2  <- glmmTMB(Observations ~ CAP * Condition + (1|ID), 
>> contrasts=list(CAP="contr.sum",Condition="contr.sum"), data=mDATA, 
>> ziformula=~ 1 , family=poisson)
> 
> 
> Plotting the effects ("effects" package), I obtain:
> 
> (ae <- allEffects(zipoisson2))
> 
> model: Observations ~ CAP * Condition
>  CAP*Condition effect
>         Condition
> CAP        aapaff      aff      neu     pneu
>   apreC3 3.222636 2.731724 2.777021 2.573694
>   insC5  1.406698 3.173030 2.104875 1.420336
>   preC1  2.883115 3.641252 2.541221 2.635991
>   preC5  2.184075 2.310564 3.137734 1.995430
> 
> plot(ae)
> Error in UseMethod("droplevels") :
>   no applicable method for 'droplevels' applied to an object of class
> "character"
> 
> Question 1: Has anyone encountered the same issue? Any hint to solve it?
> 
> Question 2: Maybe is there any other package works better with glmmTMB model
> 
> Thanks in advance for any hint about it.
> 
> Julian,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j|ox @end|ng |rom mcm@@ter@c@  Tue Aug 27 15:57:56 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 27 Aug 2019 13:57:56 +0000
Subject: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
 model
In-Reply-To: <23907_1566912715_x7RDVr3J027535_c6503eaf-939b-bcd2-59af-5088f960cb3d@gmail.com>
References: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>
 <000101d55ccf$ed7fa990$c87efcb0$@uke.de>
 <23907_1566912715_x7RDVr3J027535_c6503eaf-939b-bcd2-59af-5088f960cb3d@gmail.com>
Message-ID: <F52DF599-6AB5-4122-8FFF-76E888D9FBEC@mcmaster.ca>


Dear Ben, Daniel, and Julian,

A reproducible example would have been nice, but it's easy to create one:

-------- snip ---------

> library("glmmTMB")
> example("glmmTMB")

. . .

> library("effects")
Loading required package: carData
lattice theme set by effectsTheme()
See ?effectsTheme for details.
> ef <- Effect("sd", m0) # sd is character
> plot(ef) # error
Error in UseMethod("droplevels") : 
  no applicable method for 'droplevels' applied to an object of class "character"
> 
> dat$sd <- as.factor(dat$sd)
> mf0 <- update(m0)
> ef0 <- Effect("sd", mf0)
> plot(ef0) # works

And as Ben suggests, the problem isn't unique to glmmTMB models.

The temporary fix, as in the example above, is to change the character predictor to a factor. That shouldn't be necessary: Until the current version, Effect() didn't accommodate character predictors. Now that it does, plot.eff() should work with them too and it doesn't. I'll investigate the bug and fix it.

Best,
 John


  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Aug 27, 2019, at 9:31 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
>  Yes, quite weird as effects:::plot.eff (the relevant method) appears
> to check that variables are factors every time it tries to applies
> droplevels().  A reproducible example would be great (although
> technically maybe not this list's problem, as it's not clear it's
> directly mixed-model-related?)
> 
> On 2019-08-27 8:06 a.m., Daniel L?decke wrote:
>> Dear Julian,
>> 
>> without a reproducible example, it's a bit difficult to guess how to solve
>> your issue. Is one of your predictors of class "character" and should
>> probably be coerced to factor before you fit your model?
>> 
>> Else, you could also try the "ggeffects" package
>> (https://strengejacke.github.io/ggeffects/), where you have three functions:
>> ggpredict(), ggeffect() and ggemmeans(), each calling the related functions
>> "predict()", "effects::effect()" or "emmeans::emmeans()" internally to
>> compute marginal effects. There is a plot() method as well, based on ggplot2
>> (see examples here
>> https://strengejacke.github.io/ggeffects/articles/introduction_plotcustomize
>> .html or here
>> https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.ht
>> ml). 
>> 
>> Best
>> Daniel
>> 
>> -----Urspr?ngliche Nachricht-----
>> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
>> Auftrag von Julian Gaviria Lopez
>> Gesendet: Dienstag, 27. August 2019 12:01
>> An: r-sig-mixed-models at r-project.org
>> Betreff: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
>> model
>> 
>> Hello,
>> 
>> 
>> I have the next model:
>> 
>>> zipoisson2  <- glmmTMB(Observations ~ CAP * Condition + (1|ID), 
>>> contrasts=list(CAP="contr.sum",Condition="contr.sum"), data=mDATA, 
>>> ziformula=~ 1 , family=poisson)
>> 
>> 
>> Plotting the effects ("effects" package), I obtain:
>> 
>> (ae <- allEffects(zipoisson2))
>> 
>> model: Observations ~ CAP * Condition
>> CAP*Condition effect
>>        Condition
>> CAP        aapaff      aff      neu     pneu
>>  apreC3 3.222636 2.731724 2.777021 2.573694
>>  insC5  1.406698 3.173030 2.104875 1.420336
>>  preC1  2.883115 3.641252 2.541221 2.635991
>>  preC5  2.184075 2.310564 3.137734 1.995430
>> 
>> plot(ae)
>> Error in UseMethod("droplevels") :
>>  no applicable method for 'droplevels' applied to an object of class
>> "character"
>> 
>> Question 1: Has anyone encountered the same issue? Any hint to solve it?
>> 
>> Question 2: Maybe is there any other package works better with glmmTMB model
>> 
>> Thanks in advance for any hint about it.
>> 
>> Julian,
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> --
>> 
>> _____________________________________________________________________
>> 
>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>> _____________________________________________________________________
>> 
>> SAVE PAPER - THINK BEFORE PRINTING
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|ox @end|ng |rom mcm@@ter@c@  Tue Aug 27 17:24:34 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 27 Aug 2019 15:24:34 +0000
Subject: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
 model
In-Reply-To: <567_1566914296_x7RDwEAm014685_F52DF599-6AB5-4122-8FFF-76E888D9FBEC@mcmaster.ca>
References: <a24714a4ea174aed87f735bfa785b2d3@unige.ch>
 <000101d55ccf$ed7fa990$c87efcb0$@uke.de>
 <23907_1566912715_x7RDVr3J027535_c6503eaf-939b-bcd2-59af-5088f960cb3d@gmail.com>
 <567_1566914296_x7RDwEAm014685_F52DF599-6AB5-4122-8FFF-76E888D9FBEC@mcmaster.ca>
Message-ID: <8828B4E7-DEBA-419A-BC90-50F09441408A@mcmaster.ca>

Dear Ben, Daniel, and Julian,

This bug is now fixed in version 4.1-2 of the effects package on R-Forge. 

Waiting a day to give R-Forge a chance to rebuild the package, you should be able to install it from there via install.packages("effects", repos="http://R-Forge.R-project.org"). 

I'll submit the updated package to CRAN soon.

Best,
 John

> On Aug 27, 2019, at 9:57 AM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> 
> Dear Ben, Daniel, and Julian,
> 
> A reproducible example would have been nice, but it's easy to create one:
> 
> -------- snip ---------
> 
>> library("glmmTMB")
>> example("glmmTMB")
> 
> . . .
> 
>> library("effects")
> Loading required package: carData
> lattice theme set by effectsTheme()
> See ?effectsTheme for details.
>> ef <- Effect("sd", m0) # sd is character
>> plot(ef) # error
> Error in UseMethod("droplevels") : 
>  no applicable method for 'droplevels' applied to an object of class "character"
>> 
>> dat$sd <- as.factor(dat$sd)
>> mf0 <- update(m0)
>> ef0 <- Effect("sd", mf0)
>> plot(ef0) # works
> 
> And as Ben suggests, the problem isn't unique to glmmTMB models.
> 
> The temporary fix, as in the example above, is to change the character predictor to a factor. That shouldn't be necessary: Until the current version, Effect() didn't accommodate character predictors. Now that it does, plot.eff() should work with them too and it doesn't. I'll investigate the bug and fix it.
> 
> Best,
> John
> 
> 
>  -------------------------------------------------
>  John Fox, Professor Emeritus
>  McMaster University
>  Hamilton, Ontario, Canada
>  Web: http::/socserv.mcmaster.ca/jfox
> 
>> On Aug 27, 2019, at 9:31 AM, Ben Bolker <bbolker at gmail.com> wrote:
>> 
>> 
>> Yes, quite weird as effects:::plot.eff (the relevant method) appears
>> to check that variables are factors every time it tries to applies
>> droplevels().  A reproducible example would be great (although
>> technically maybe not this list's problem, as it's not clear it's
>> directly mixed-model-related?)
>> 
>> On 2019-08-27 8:06 a.m., Daniel L?decke wrote:
>>> Dear Julian,
>>> 
>>> without a reproducible example, it's a bit difficult to guess how to solve
>>> your issue. Is one of your predictors of class "character" and should
>>> probably be coerced to factor before you fit your model?
>>> 
>>> Else, you could also try the "ggeffects" package
>>> (https://strengejacke.github.io/ggeffects/), where you have three functions:
>>> ggpredict(), ggeffect() and ggemmeans(), each calling the related functions
>>> "predict()", "effects::effect()" or "emmeans::emmeans()" internally to
>>> compute marginal effects. There is a plot() method as well, based on ggplot2
>>> (see examples here
>>> https://strengejacke.github.io/ggeffects/articles/introduction_plotcustomize
>>> .html or here
>>> https://strengejacke.github.io/ggeffects/articles/introduction_plotmethod.ht
>>> ml). 
>>> 
>>> Best
>>> Daniel
>>> 
>>> -----Urspr?ngliche Nachricht-----
>>> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
>>> Auftrag von Julian Gaviria Lopez
>>> Gesendet: Dienstag, 27. August 2019 12:01
>>> An: r-sig-mixed-models at r-project.org
>>> Betreff: [R-sig-ME] Plotting post-fitting inference effects in a glmmTMB
>>> model
>>> 
>>> Hello,
>>> 
>>> 
>>> I have the next model:
>>> 
>>>> zipoisson2  <- glmmTMB(Observations ~ CAP * Condition + (1|ID), 
>>>> contrasts=list(CAP="contr.sum",Condition="contr.sum"), data=mDATA, 
>>>> ziformula=~ 1 , family=poisson)
>>> 
>>> 
>>> Plotting the effects ("effects" package), I obtain:
>>> 
>>> (ae <- allEffects(zipoisson2))
>>> 
>>> model: Observations ~ CAP * Condition
>>> CAP*Condition effect
>>>       Condition
>>> CAP        aapaff      aff      neu     pneu
>>> apreC3 3.222636 2.731724 2.777021 2.573694
>>> insC5  1.406698 3.173030 2.104875 1.420336
>>> preC1  2.883115 3.641252 2.541221 2.635991
>>> preC5  2.184075 2.310564 3.137734 1.995430
>>> 
>>> plot(ae)
>>> Error in UseMethod("droplevels") :
>>> no applicable method for 'droplevels' applied to an object of class
>>> "character"
>>> 
>>> Question 1: Has anyone encountered the same issue? Any hint to solve it?
>>> 
>>> Question 2: Maybe is there any other package works better with glmmTMB model
>>> 
>>> Thanks in advance for any hint about it.
>>> 
>>> Julian,
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> --
>>> 
>>> _____________________________________________________________________
>>> 
>>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
>>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>>> _____________________________________________________________________
>>> 
>>> SAVE PAPER - THINK BEFORE PRINTING
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From to@tm@nnk@th@r|n@ @end|ng |rom gm@||@com  Tue Aug 27 09:26:01 2019
From: to@tm@nnk@th@r|n@ @end|ng |rom gm@||@com (Katharina Tostmann)
Date: Tue, 27 Aug 2019 09:26:01 +0200
Subject: [R-sig-ME] Testing assumption multilevel analysis
In-Reply-To: <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>
References: <CADAgCby4eFKs5tVZOM00hW-Zr3ZOAqta75EFdQTgq=Nfo8wG4A@mail.gmail.com>
 <01eb4dc4-4ab1-db14-6f1b-d7049da0df02@mpi.nl>
 <CADAgCbwzxueLFWqNW1TS9MD5qbqp6C1F9avWDJakURcjT7QhVw@mail.gmail.com>
 <8a855ebe-a753-93eb-d19d-e21e2d35afc0@mpi.nl>
Message-ID: <CADAgCbwWbJvmm4MZb_nyMwDDgpx7Q6HNa9GrDz+kAn6rnPxMHA@mail.gmail.com>

Hello Phillip,

thank you very much for our helpful response!

Now I feel much better to handle with the assumptions in my multilevel
analysis!


Best regards

Katharina

Am Mo., 26. Aug. 2019 um 17:35 Uhr schrieb Phillip Alday <
phillip.alday at mpi.nl>:

> Please keep the list in CC.
>
> As Ben Bolker mentioned in his reply: for most things, the assumptions
> carry over from the non-mixed case and the graphical diagnostics are
> done the same way. I would in general avoid explicit statistical tests
> of model assumptions (e.g. various tests of normality) because, like all
> tests, they have failure modes (especially related to sensitivity and
> specificity) and don't actually tell you what any potential violation of
> assumptions is doing to your statistical procedure.
>
> For multicollinearity, there is one additional diagnostic that lme4
> gives you in its summary output, namely the correlation of fixed
> effects. The exact meaning of this is perhaps a little technical
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001941.html),
> but in practical terms a high correlation suggests that there may be
> multicollinearity. Multicollinearity also tends to show itself in
> inflated standard errors (in the fixed effects), much as it does for
> standard linear regression.
>
> Regarding independence of errors: I find that to be an assumption that
> is often best checked by knowing something about your data generating
> process. For example, there may be some autocorrelation in the errors
> between observations due to the way data are collected.
>
> Best,
> Phillip
>
> On 26/8/19 2:23 pm, Katharina Tostmann wrote:
> > Hello Phillip,
> >
> > Yes, I know it is a very big question about the assumptions in general.
> > At this time I got a little information about linearity, normal
> > distibution and variance homogenity. But what ist about
> > mulitcollinearity and independency? Do you have any idea to check this
> > in a multilevel context?
> >
> > Thank you in advance.
> >
> >
> > best regards from Germany
> >
> > Katharina
> >
> > Am Mo., 26. Aug. 2019 um 14:14 Uhr schrieb Phillip Alday
> > <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>>:
> >
> >     This is a rather open-ended request -- you're more likely to get
> helpful
> >     advice if you're a bit more specific. For example, which model
> >     assumptions do you want to test in particular? What do your data look
> >     like? Which assumptions do you think your data might violate? Why do
> you
> >     want to explicitly test assumptions? (e.g. Are you worried about
> >     inflated Type-I error? Often it's better to worry less about
> assumptions
> >     per se and instead focus on "does my model capture the relevant
> aspects
> >     of my data?")
> >
> >     Phillip
> >
> >     On 24/8/19 11:08 am, Katharina Tostmann wrote:
> >     > Hello together,
> >     >
> >     > I'm calculating a multi-level analysis in R. However, I do not
> >     understand
> >     > how to test the model assumptions. In my second hypothesis I also
> >     have a
> >     > mediation with, whereby I also have no idea how to test the model
> >     > assumptions.
> >     > Can anyone help here? Thank you and best regards
> >     >
> >     > Katharina
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
>

	[[alternative HTML version deleted]]


From |@nn@014 @end|ng |rom umn@edu  Tue Aug 27 21:52:33 2019
From: |@nn@014 @end|ng |rom umn@edu (Fabiola Iannarilli)
Date: Tue, 27 Aug 2019 14:52:33 -0500
Subject: [R-sig-ME] help with false convergence warning;
 sparse 1s in binary data
Message-ID: <CAJXAS09w8HKV0trUDCN5ii7wEB8WyOCfVPUcZfSNP6+dhSjWuA@mail.gmail.com>

Hi all!

I am using glmmTMB to model a set of time series of binary responses
collected at ~30 sites.  The probability of success fluctuates diurnally,
is likely to vary across sites, and I expect the data may also exhibit
short-term (serial) dependence.  Thus, I am including
sin(2*pi*time/(24*60)) and cos(2*pi*time/(24*60)) as fixed effects, a
random intercept for each site, and a within-site random effect that
follows an AR1 structure . The dataset is quite large (~2,200,000 records),
so I am initially exploring models fit to only a subset of the data
(~190,000 records).

> mod_1min <- glmmTMB(y ~ sin(2*pi*time/(24*60)) + cos(2*pi*time/(24*60)) +
(1|id) + ar1(as.factor(time) + 0 | id), data=y_1min, family=
binomial(link="logit"), ziformula = ~0)



Warning message:

In fitTMB(TMBStruc) :

  Model convergence problem; false convergence (8). See
vignette('troubleshooting')



> summary(mod_1min)

 Family: binomial  ( logit )

Formula:

y ~ sin(2 * pi * time/(24 * 60)) + cos(2 * pi * time/(24 * 60)) +

    (1 | id) + ar1(as.factor(time) + 0 | id)

Data: y_1min



     AIC      BIC   logLik deviance df.resid

   224.0    278.5   -106.0    212.0    64803



Random effects:



Conditional model:

 Groups Name                 Variance  Std.Dev. Corr

 id     (Intercept)          7.908e-02  0.2812

 id.1   as.factor(time)16999 4.084e+03 63.9073  0.33 (ar1)

Number of obs: 64809, groups:  id, 9



Conditional model:

                             Estimate Std. Error z value Pr(>|z|)

(Intercept)                  -19.4483     1.9487  -9.980   <2e-16 ***

sin(2 * pi * time/(24 * 60))  -0.1585     1.3361  -0.119    0.906

cos(2 * pi * time/(24 * 60))   0.2468     1.4576   0.169    0.866

---

Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
??? ??? 1



glmmTMB gives a warning about false convergence. My guess is that this is
due to the low number of 1s in the data, which results in a flat likehood
and very low estimate for the intercept. My questions are:

1)      Is there a way to verify that the sparseness of 1s (and the
intercept) is the actual problem? If so, can I trust the inference for the
fixed effects parameters?

2)      My research questions also focus on evaluating the presence of
autocorrelation in the response.  I?m concerned that the variance
parameters are not well identified. Can I trust the estimate of the
autocorrelation parameter? Is there an alternative way to specify the model
that might improve convergence?

3)      Is it possible that a different optimizer or different Hessian
approximation might help? I tried the solution described at
https://github.com/glmmTMB/glmmTMB/issues/482, but it also gives a warning:

?45: In par[-random] <- par.fixed:   number of items to replace is not a
multiple of replacement length?

4)      Following the suggestion on this thread
https://github.com/glmmTMB/glmmTMB/issues/386, I am also running the same
model using INLA (given the dataset size, I am afraid MCMC will be too
computationally demanding), but there the problem is what priors to use.  I
am also running into memory allocation problems.

I would appreciate any suggestions you may have.

Best,

Fabiola



<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Aug 28 00:07:09 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 27 Aug 2019 18:07:09 -0400
Subject: [R-sig-ME] help with false convergence warning;
 sparse 1s in binary data
In-Reply-To: <CAJXAS09w8HKV0trUDCN5ii7wEB8WyOCfVPUcZfSNP6+dhSjWuA@mail.gmail.com>
References: <CAJXAS09w8HKV0trUDCN5ii7wEB8WyOCfVPUcZfSNP6+dhSjWuA@mail.gmail.com>
Message-ID: <27735d2d-ac2d-91ba-77a8-db2dc86b0e28@gmail.com>


  I'm not sure whether the troubleshooting vignette in the CRAN version
is entirely up to date. Here's what it says about this warning at
https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/troubleshooting.rmd
:

----
It's usually hard to diagnose the source of this warning (this [Stack
Overflow
answer](https://stackoverflow.com/questions/40039114/r-nlminb-what-does-false-convergence-actually-mean)
explains a bit more about what it means). Reasonable methods for making
sure your model is OK are:

- restart the model at the estimated fitted values
- try using a different optimizer, e.g.
`control=glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS"))`

and see if the results are sufficiently similar to the original fit.

---

  There are a few fishy-looking things about this fit:

 the intercept is tiny (plogis(-19) = 5 x 10^(-9), implying a
ridiculously small baseline probability)

  the std dev associated with the AR1 term (63) looks ridiculously
large, unless there's some scaling I'm forgetting/not thinking about.

  Are there a lot of all-zero groups?  In principle these *should* be
"shrinkable", but they tend to cause weird-looking conditional mode
distributions.

  What is your actual fraction of 1s?

  I'm not sure how issue #482 helps: that's a different warning
(non-positive definite Hessian), isn't it?

   Other than trying different starting values and optimizers and seeing
how the results compare, I don't have a lot of solutions.  Regularizing
priors are probably a good idea (which recommends INLA, if it's fast
enough for you) -- have been thinking about implementing the option in
glmmTMB but haven't gotten there yet.
  The gold standard for figuring out whether the results are reliable is
to simulate similar cases with *known* parameters and seeing whether
glmmTMB tends to get the right answers to the focal questions even when
some non-focal parameters are wonky ...

  Ben Bolker



On 2019-08-27 3:52 p.m., Fabiola Iannarilli wrote:
> Hi all!
> 
> I am using glmmTMB to model a set of time series of binary responses
> collected at ~30 sites.  The probability of success fluctuates diurnally,
> is likely to vary across sites, and I expect the data may also exhibit
> short-term (serial) dependence.  Thus, I am including
> sin(2*pi*time/(24*60)) and cos(2*pi*time/(24*60)) as fixed effects, a
> random intercept for each site, and a within-site random effect that
> follows an AR1 structure . The dataset is quite large (~2,200,000 records),
> so I am initially exploring models fit to only a subset of the data
> (~190,000 records).
> 
>> mod_1min <- glmmTMB(y ~ sin(2*pi*time/(24*60)) + cos(2*pi*time/(24*60)) +
> (1|id) + ar1(as.factor(time) + 0 | id), data=y_1min, family=
> binomial(link="logit"), ziformula = ~0)
> 
> 
> 
> Warning message:
> 
> In fitTMB(TMBStruc) :
> 
>   Model convergence problem; false convergence (8). See
> vignette('troubleshooting')
> 
> 
> 
>> summary(mod_1min)
> 
>  Family: binomial  ( logit )
> 
> Formula:
> 
> y ~ sin(2 * pi * time/(24 * 60)) + cos(2 * pi * time/(24 * 60)) +
> 
>     (1 | id) + ar1(as.factor(time) + 0 | id)
> 
> Data: y_1min
> 
> 
> 
>      AIC      BIC   logLik deviance df.resid
> 
>    224.0    278.5   -106.0    212.0    64803
> 
> 
> 
> Random effects:
> 
> 
> 
> Conditional model:
> 
>  Groups Name                 Variance  Std.Dev. Corr
> 
>  id     (Intercept)          7.908e-02  0.2812
> 
>  id.1   as.factor(time)16999 4.084e+03 63.9073  0.33 (ar1)
> 
> Number of obs: 64809, groups:  id, 9
> 
> 
> 
> Conditional model:
> 
>                              Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)                  -19.4483     1.9487  -9.980   <2e-16 ***
> 
> sin(2 * pi * time/(24 * 60))  -0.1585     1.3361  -0.119    0.906
> 
> cos(2 * pi * time/(24 * 60))   0.2468     1.4576   0.169    0.866
> 
> ---
> 
> Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1
> ??? ??? 1
> 
> 
> 
> glmmTMB gives a warning about false convergence. My guess is that this is
> due to the low number of 1s in the data, which results in a flat likehood
> and very low estimate for the intercept. My questions are:
> 
> 1)      Is there a way to verify that the sparseness of 1s (and the
> intercept) is the actual problem? If so, can I trust the inference for the
> fixed effects parameters?
> 
> 2)      My research questions also focus on evaluating the presence of
> autocorrelation in the response.  I?m concerned that the variance
> parameters are not well identified. Can I trust the estimate of the
> autocorrelation parameter? Is there an alternative way to specify the model
> that might improve convergence?
> 
> 3)      Is it possible that a different optimizer or different Hessian
> approximation might help? I tried the solution described at
> https://github.com/glmmTMB/glmmTMB/issues/482, but it also gives a warning:
> 
> ?45: In par[-random] <- par.fixed:   number of items to replace is not a
> multiple of replacement length?
> 
> 4)      Following the suggestion on this thread
> https://github.com/glmmTMB/glmmTMB/issues/386, I am also running the same
> model using INLA (given the dataset size, I am afraid MCMC will be too
> computationally demanding), but there the problem is what priors to use.  I
> am also running into memory allocation problems.
> 
> I would appreciate any suggestions you may have.
> 
> Best,
> 
> Fabiola
> 
> 
> 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From the@bretter@em@|| @end|ng |rom gm@||@com  Fri Aug 30 20:10:22 2019
From: the@bretter@em@|| @end|ng |rom gm@||@com (Brett Feltmate)
Date: Fri, 30 Aug 2019 15:10:22 -0300
Subject: [R-sig-ME] Replicating type III anova tests for glmer/GLMM
Message-ID: <FA1C9B18-B390-40BF-BF44-D21677F0442C@gmail.com>

Hi Henrik,

I'm fairly new to mixed modelling, and I have a question regarding the output of afex::mixed() vs. glmer(), or more specifically the results of ANOVAs performed on them...

I'm modelling accuracy data in a within-Ss design with three factors, using afex I specify:

m1 <- afex::mixed( accuracy ~ x * y * z + ( 1 | subj ), method = 'LRT', family = binomial, data = dat)

and (eventually) using car:

m2 <- lme4::glmer( accuracy ~ x * y * z + ( 1 | subj ) , family = binomial, data = dat)

(I guess that bit was redundant...)

I get a discrepancy wherein if I run:

afex::nice(m1)

The effect of 'x' is reported as significant, but for:

afex::set_sum_contrasts()
car::Anova(m2)

The effect of 'x' doesn't even approached significance (according to the Chisq test)

Do the Chi-Square tests reported in both methods reflect the same thing? That is, the effect of 'x' on accuracy? Or are one of these methods testing something different?

Thank you,

Brett

From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Sep  2 12:31:43 2019
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Mon, 2 Sep 2019 12:31:43 +0200
Subject: [R-sig-ME] Course: Introduction to regression models with spatial
 and temporal correlation using R-INLA
Message-ID: <73f043a3-860c-938d-7dff-6f97addb8321@highstat.com>

We would like to announce the following 3 statistics courses.

Course: Introduction to regression models with spatial and temporal 
correlation using R-INLA

Location: Canada and The Netherlands


Where and when:

1. Introduction to regression models with spatial and temporal 
correlation using R-INLA. NIOZ, Texel, The Netherlands. 23-27 September 
2019

2. Introduction to regression models with spatial and spatial-temporal 
correlation using R-INLA. Burlington (close to Toronto), ON, Canada. 28 
October - 1 November 2019


Course website: http://highstat.com/index.php/courses-upcoming



Kind regards,


Alain Zuur


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Tue Sep  3 13:42:24 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Tue, 3 Sep 2019 13:42:24 +0200
Subject: [R-sig-ME] Discrepancy between STATISTICA results and lmer and lme
Message-ID: <CAHzBVpKpjHgZeo-qVU0rSHRsp0KrKxs72=v8+wT3mEuyBkUQvw@mail.gmail.com>

Morning,
I am running a linear mixed model withrepeated measures using lmer and I
have found that results are the same whe I use lme or aov with repeated
measure. However, are slightly different for STATISTICA software. I guess
is something related with the estimation method or any kind of correction
but I would like to now the reason and I am not able to find it.
Anybody knows or have any recommended reading at this respect?
Thanks in advance

With lmer from package lme4
lmer5 <- lmer(Mean ~ Trtmnt*sp*Period + (1|ExpID), data =
Data[Period%in%c("Before","early peak","late peak"),])
anova(lmer5)
Analysis of Variance Table
                 Df Sum Sq Mean Sq  F value
Trtmnt            2   2.80   1.398   0.6762
sp                2 592.64 296.319 143.3659
Period            2   6.28   3.141   1.5195
Trtmnt:sp         4  12.70   3.176   1.5366
Trtmnt:Period     4  41.99  10.499   5.0795
sp:Period         4   4.61   1.151   0.5571
Trtmnt:sp:Period  8  13.83   1.729   0.8364

With lme from package nlme
lme5 <- lme( Mean ~ Trtmnt*sp*Period, data =
Data[Period%in%c("Before","early peak","late peak"),], random = ~
1|factor(ExpID))
anova(lme5)
                 numDF denDF  F-value p-value
(Intercept)          1   122 5739.446  <.0001
Trtmnt               2    61    0.676  0.5123
sp                   2    61  143.366  <.0001
Period               2   122    1.519  0.2229
Trtmnt:sp            4    61    1.537  0.2029
Trtmnt:Period        4   122    5.079  0.0008
sp:Period            4   122    0.557  0.6942
Trtmnt:sp:Period     8   122    0.836  0.5724

With STATISTICA
 Effect Repeated Measures Analysis of Variance (Lab
coinfection_averages_BM.sta)
Sigma-restricted parameterization
Effective hypothesis decomposition; Std. Error of Estimate: 2.4177
  SS Degr. of MS F p
Intercept 395317,0 1 395317,0 5173,785 0,000000
Trtmnt 169,0 2 84,5 1,106 0,337542
sp 18404,8 2 9202,4 120,438 0,000000
Trtmnt*sp 469,6 4 117,4 1,537 0,202864
Error 4660,9 61 76,4

PERIOD 3,8 2 1,9 0,923 0,399914
PERIOD*Trtmnt 42,5 4 10,6 5,146 0,000726
PERIOD*sp 3,6 4 0,9 0,440 0,779813
PERIOD*Trtmnt*sp 13,8 8 1,7 0,836 0,572377
Error 252,2 122 2,1

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom uc@d@edu  Tue Sep  3 21:33:39 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Tue, 3 Sep 2019 19:33:39 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
Message-ID: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>

I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.

I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)

Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).

I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")

Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.

First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).

I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:

```
Error in getOptfun(optimizer) :
  optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
```

Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
optCtrl = list(method = "nlminb?,
maxit=10000,
iter.max=10000,
eval.max=10000,
lower = c(0,0,0),
upper = c(Inf,10,1)))

and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\

```
Warning messages:
1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
```

I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.

I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.

I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.

Thanks!



231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
"0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
"0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
"0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
"0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
"0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
"0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
"0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
"0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
"0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
"0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
"0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
"0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
"0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
"0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
"0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
"0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
"0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
"0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
"0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
"0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
"0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
"0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
), COUNTY = c("autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "la paz county", "la paz county",
"la paz county", "la paz county", "la paz county", "la paz county",
"la paz county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04012",
"04012", "04012", "04012", "04012", "04012", "04012", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "St. Johns Unified District",
"St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
"St. Johns Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring Schools",
"Mammoth Spring Schools", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "Bryant Public Schools", "Bryant Public Schools",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District"), EXPENDITURE_PER_STUDENT = c(5.2927293064877,
5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
-800L), class = c("tbl_df", "tbl", "data.frame"))


	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Sep  4 09:54:11 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 4 Sep 2019 09:54:11 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
Message-ID: <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>

Dear James,

Your mail contains only a part of the dput() output. Given the size of your
data, I suggest that you place it somewhere online and send us a link to
the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu>:

> I posted my question at Stack Overflow, where it didn?t get much of a
> response, and I was pointed in this direction by Ben Bolker. I?m happy to
> send the whole dataset to anyone who wants but thought that it would be
> presumptuous to include an enormous dput() here.
>
> I?m looking at the effects of education spending per school district on
> crime rate (FBI crime data/UCR) within the cities and towns those school
> districts serve over a fifteen year period. The DV now has 203,410
> observations of city/town crime data over those fifteen years. (I use that
> figure with some reticence, because there are so many moving parts and
> things to account for, but having employed over 100 datasets and hours
> passing through the code again, I think that figure is correct.)
>
> Cities are technically crossed with school district, in that one city
> might attend multiple school districts. This means that one city could have
> multiple values for expenditure per student. School districts, however,
> also overlap with counties. As if things weren?t complicated enough, cities
> are mostly nested within county (though there are cities that exist in two
> counties, but it?s not often, and it?s usually by a small amount). Given
> that each city/town has a distinct PLACE_ID, my understanding is that this
> could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or
> (1|STATE/COUNTY_ID/PLACE_ID).
>
> I?m pretty familiar with mixed-effect models, and I?ve looked through
> clear and informative posts such as this one:
> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified.
> I believe things would remain sane to include school district
> (full_district_id) as another crossed effect, as below:
> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) +
> (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control
> = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> total.years, na.action = "na.omit")
>
> Variables (not included in this model, to keep things null and simple) are
> centered and logged: pop per city, pop.dens per city, year, unemployment
> rate per county, proportion children living in poverty per school district,
> per capita income per county, difference in those who voted democrat in
> presidential elections per county, log enforcement per city/town, centered
> expenditure per student/ 1000 (per school district). PLACE_ID corresponds
> to cities and towns, COUNTY_ID to counties, full_district_id to school
> districts, and state.
>
> First, if I try to run the full model, using UCSD?s supercomputer, I get
> the error that the job was killed, presumably because it got to a point
> where it consumed too much ram (I think 125mb).
>
> I then tried to create a small subsection of data with arrange(STATE,
> COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through
> Delaware), so that I have 26,599 values. If I run this null model with the
> above code, I get the following error:
>
> ```
> Error in getOptfun(optimizer) :
>   optimizer function must use (at least) formal parameters ?fn?, ?par?,
> ?lower?, ?control?
> ```
>
> Then I tried with the optimx, with these configurations: control =
> glmerControl(optimizer = "optimx?,
> optCtrl = list(method = "nlminb?,
> maxit=10000,
> iter.max=10000,
> eval.max=10000,
> lower = c(0,0,0),
> upper = c(Inf,10,1)))
>
> and I received the following warning?since this is a null model, there
> aren?t any variables to really rescale.\
>
> ```
> Warning messages:
> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001,
> component 1)
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> ```
>
> I then tried more values (to 92,486, through Missouri). First, I tried the
> optimizer nloptr, and then I tried the optimix. I still received the same
> above errors.
>
> I?ve checked and rechecked everything, so I wanted to solicit advice,
> either for where I might be going wrong, or for what I could do to resolve
> these error messages.
>
> I?ve provided a brief snippet of the data below (randomly pulling a number
> of cities within counties of Arkansas, Arizona, and Alabama, as a dput.
>
> Thanks!
>
>
>
> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
> ), COUNTY = c("autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "la paz county", "la paz county",
> "la paz county", "la paz county", "la paz county", "la paz county",
> "la paz county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County
> School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "St. Johns Unified District",
> "St. Johns Unified District", "St. Johns Unified District", "St. Johns
> Unified District",
> "St. Johns Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Tombstone Unified
> District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca
> Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman
> Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Pima Unified District", "Pima Unified
> District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring
> Schools",
> "Mammoth Spring Schools", "Greene County Technical School District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Sloan-Hendrix School District",
> "Sloan-Hendrix School District", "Sloan-Hendrix School District",
> "Sloan-Hendrix School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "West Memphis School District",
> "West Memphis School District", "West Memphis School District",
> "West Memphis School District", "West Memphis School District",
> "West Memphis School District", "Bryant Public Schools", "Bryant Public
> Schools",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bryant Public Schools", "Bryant Public
> Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District"), EXPENDITURE_PER_STUDENT =
> c(5.2927293064877,
> 5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
> 7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
> 7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
> 7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
> 5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
> 7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
> 7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
> 7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
> 9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
> 6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
> 9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
> 8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
> 8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
> 6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
> 9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> 8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> 8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
> 8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> 8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> 7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
> 9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
> 8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
> 8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
> 8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
> 7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
> 6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
> 9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
> 6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
> 7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
> 8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
> 9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
> 8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
> 7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
> 9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
> 6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
> 7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
> 7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
> 7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
> 4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
> 5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
> 6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
> 10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
> 6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
> 7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
> 8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
> 7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
> 7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
> 7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
> 6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
> 8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
> 7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
> 8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
> 7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
> 8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
> 9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
> 8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
> 8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
> 7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
> 9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
> 10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
> 7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
> 8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
> 7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
> 11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
> 9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
> 5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
> 6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
> 7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
> 5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
> 6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
> 7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
> 7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
> 7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
> 7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
> 5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
> 7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
> 7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
> 5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
> 7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
> 6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
> 4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> 4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
> 5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
> 6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
> 6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
> 6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
> 6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> 7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
> 10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
> 9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
> 6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
> 6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
> 8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
> 12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
> 10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
> 12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> 9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
> 10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
> 10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
> 12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
> 12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
> 12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
> 12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
> 8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
> 8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
> 9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
> 10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
> 9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
> 10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
> 11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> 11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
> 8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
> 9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
> 10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
> 10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
> 10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
> 10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
> 8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
> 9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
> 9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
> 6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
> 7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
> 8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
> 8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
> 7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
> 8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
> 7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
> 8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
> 10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
> 10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
> 9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
> 8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
> 7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
> 7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
> 7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
> 7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
> 7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
> 7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
> 7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
> 8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
> 8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
> 8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
> 8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
> 8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
> 8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
> 7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
> 7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
> 6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
> 8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
> 11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
> 8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
> 8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
> 9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
> 9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> 11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
> 9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
> 10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
> 10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
> 7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
> 8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
> 6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
> 8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
> 7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
> -800L), class = c("tbl_df", "tbl", "data.frame"))
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hou@|@y @end|ng |rom gm@||@com  Wed Sep  4 13:02:27 2019
From: hou@|@y @end|ng |rom gm@||@com (Tom Houslay)
Date: Wed, 4 Sep 2019 12:02:27 +0100
Subject: [R-sig-ME] MCMCglmm predict failing with more than one fixed effect
Message-ID: <CAErKyRoz9pKiXLoWX32bifthDPwyBDC8CoPOOD2RL38jdGHPpg@mail.gmail.com>

Hi all,

Hoping someone can help me with this issue, even (especially?) if I'm
just being an idiot. I had been using predict.MCMCglmm with new data
successfully until recently (I think coinciding with updating R and
various packages), and now if I have more than one fixed effect in a
model then it fails when supplying any newdata. The error message is:

Error in predict.MCMCglmm(mcmc_ss_2, newdata = as.data.frame(df_ss_pred_2)) :
  model for newdata has fixed effects absent from the original model

I've tried a load of different ways of building the data to predict
from, but nothing seems to work.

Code below for a reproducible example (requires MCMCglmm and the
'sleepstudy' data from lme4). I'm running R 3.6.1 and MCMCglmm 2.29.

Thanks!

Tom


# Basic model of sleepstudy with 1 fixed effect and simple random intercept
mcmc_ss_1 <- MCMCglmm(Reaction ~ Days,
                      random =~ Subject,
                      data = sleepstudy)

summary(mcmc_ss_1)

# Predicts fine on original data
predict(mcmc_ss_1)

# Create data on which to predict
df_ss_pred <- data.frame(Days = 0:9,
                         Subject = 350,
                         Reaction = 0)

# This prediction works
predict(mcmc_ss_1,
        newdata = df_ss_pred)

# Create new data frame with fake additional column
sleepstudy_2 <- cbind(sleepstudy,
                      extra = rnorm(nrow(sleepstudy)))

# Run model with additional fixed effect
mcmc_ss_2 <- MCMCglmm(Reaction ~ Days + extra,
                      random =~ Subject,
                      data = sleepstudy_2)

summary(mcmc_ss_2)

# Predict works fine from original data
predict(mcmc_ss_2)

# Create data frame on which to predict,
#  as before but now with new column added
df_ss_pred_2 <- as.data.frame(expand.grid(Reaction = 0,
                                          Days = 0:9,
                                          Subject = 350,
                                          extra = mean(sleepstudy_2$extra)))

# Prediction fails
predict(mcmc_ss_2,
        newdata = df_ss_pred_2)

# Check model formula
mcmc_ss_2$Fixed$formula

# Check variable names in data frame
str(sleepstudy_2)

# Check variable names in new data frame
str(df_ss_pred_2)


From j@de@ @end|ng |rom uc@d@edu  Sun Sep  8 07:40:28 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Sun, 8 Sep 2019 05:40:28 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
Message-ID: <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>

Okay, sorry for the delay; I was waiting to hear back from a couple people at the census regarding a question on school district info in the dataset.

I?ve  uploaded the dataset as a zip and an xs:
https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing

There is one important thing to note, here, which is that there is more city overlap between counties than I thought. The easiest way to explain this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID, year), you should get 107,515; however, with distinct(PLACE_ID, year), you?ll only get 99,832. So essentially, there are ~8000 times that a city will overlap in two counties (this likely includes the same city repeating this overlap every year?though it all depends on what years the city/town police department reports crime to the FBI). I can figure out the respective populations in each of the two counties where the city overlaps. It?s a bit of leg work, but it is possible. Still, it seems that it would not be principled to include the city/town in both counties because there would be the assumption that the crime occurring in each corresponding county is tied solely to population. Still, I left in all cities/towns overlapping with two counties, in case you have some ideas about how a mixed-model might be used to account for these (I don?t think a crossed-effect structure would do it). So pretty much any city with duplicate values where that value lies within the same county should be counted (these are just separate school districts), but any city with duplicate values where one of those values happens to be in another county, yet the school district is still the same, shouldn't be counted; unless, of course, there is a way for mixed-modeling in lme4 to account for that (PLACE_ID will be the same, but COUNTY_ID will be different, but full_district_id will be the same). Does that make sense? I'll soon send an email to the group with more clarification.

Use IDs vs names. I included names for reference, but city/towns might not always be recorded exactly the same, so IDs are the safer bet.

I have tried lmer?originally, my intention was to preserve counts of zero crime (whether it?s weariness or sanity that has changed my view, the difference between one and zero doesn?t seem so important anymore. I get the boundary (singular) warning (if a warning is what it can be called). No doubt there are many here that know more than me, but my understanding of this message is that it mostly warns against overfitting. To me, controlling for time through a fixed effect and as a random slope seems warranted?different cities/towns have different rates of change in crime from year to year.

I still think fitting with glmer would be ideal, but I also lack an understanding of the nuances on the backend with regard to how the two functions differ. It seems that lmer is faster and more efficient in modeling, though I?m not sure why?mathematically or programmatically?that?s the case. If you can point me to an explanation, I?d appreciate that.

Thanks much for your messages and your help.

James


On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Your mail contains only a part of the dput() output. Given the size of your data, I suggest that you place it somewhere online and send us a link to the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.

I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)

Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).

I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")

Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.

First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).

I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:

```
Error in getOptfun(optimizer) :
  optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
```

Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
optCtrl = list(method = "nlminb?,
maxit=10000,
iter.max=10000,
eval.max=10000,
lower = c(0,0,0),
upper = c(Inf,10,1)))

and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\

```
Warning messages:
1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
```

I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.

I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.

I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.

Thanks!



231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
"0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
"0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
"0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
"0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
"0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
"0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
"0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
"0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
"0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
"0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
"0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
"0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
"0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
"0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
"0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
"0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
"0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
"0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
"0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
"0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
"0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
"0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
), COUNTY = c("autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "la paz county", "la paz county",
"la paz county", "la paz county", "la paz county", "la paz county",
"la paz county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04012",
"04012", "04012", "04012", "04012", "04012", "04012", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "St. Johns Unified District",
"St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
"St. Johns Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring Schools",
"Mammoth Spring Schools", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "Bryant Public Schools", "Bryant Public Schools",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District"), EXPENDITURE_PER_STUDENT = c(5.2927293064877,
5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
-800L), class = c("tbl_df", "tbl", "data.frame"))


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From b@te@ @end|ng |rom @t@t@w|@c@edu  Sun Sep  8 19:19:47 2019
From: b@te@ @end|ng |rom @t@t@w|@c@edu (Douglas Bates)
Date: Sun, 8 Sep 2019 19:19:47 +0200
Subject: [R-sig-ME] Crime and school expenditure data
Message-ID: <CAO7JsnTQRG2A_0fvnjrfWDCffF0-JD+khoSB42Cq6fnxh6tsWw@mail.gmail.com>

James,

Do you have any idea why the year 2004 has such a large mean CRIME_TOTAL
relative to the other years?

julia> by(totalYears, :yrfac, :CRIME_TOTAL => mean)
15?2 DataFrame
? Row ? yrfac        ? CRIME_TOTAL_mean ?
?     ? Categorical? ? Float64          ?
?????????????????????????????????????????
? 1   ? 2003         ? 3168.28          ?
? 2   ? 2004         ? 6368.35          ?
? 3   ? 2005         ? 2943.62          ?
? 4   ? 2006         ? 2879.6           ?
? 5   ? 2007         ? 2703.79          ?
? 6   ? 2008         ? 2673.72          ?
? 7   ? 2009         ? 2540.67          ?
? 8   ? 2010         ? 2388.7           ?
? 9   ? 2011         ? 2302.99          ?
? 10  ? 2012         ? 2194.78          ?
? 11  ? 2013         ? 2151.79          ?
? 12  ? 2014         ? 2000.15          ?
? 13  ? 2015         ? 2049.1           ?
? 14  ? 2016         ? 2089.87          ?
? 15  ? 2017         ? 2076.56          ?

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Sep  9 11:58:15 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 9 Sep 2019 11:58:15 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
Message-ID: <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>

Dear James,

Since all ID's are unique, you can rely on the implicit nesting of random
effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) +
(1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).

There is a huge overlap between PLACE_ID and full_district_id. The model
will have a hard time separating both effects. Especially since you have
the same random slope.

You should also center the year variable. Now your model is estimating the
random intercept at year 0.

So in terms of basic model I would

- drop either PLACE_ID or full_district_id
- center year
- add year to the fixed effects or add it as a separate random intercept

Furthermore, I'm not sure it the Poisson distribution is the most relevant
distribution for your response. I've seen a case were the Poisson
distribution failed. The response was an area in hectares rounded to an
integer value. The model fitted well with a Gamma distribution.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu>:

> Okay, sorry for the delay; I was waiting to hear back from a couple people
> at the census regarding a question on school district info in the dataset.
>
> I?ve  uploaded the dataset as a zip and an xs:
>
> https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
>
> https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing
>
> There is one important thing to note, here, which is that there is more
> city overlap between counties than I thought. The easiest way to explain
> this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID,
> year), you should get 107,515; however, with distinct(PLACE_ID, year),
> you?ll only get 99,832. So essentially, there are ~8000 times that a city
> will overlap in two counties (this likely includes the same city repeating
> this overlap every year?though it all depends on what years the city/town
> police department reports crime to the FBI). I can figure out the
> respective populations in each of the two counties where the city overlaps.
> It?s a bit of leg work, but it is possible. Still, it seems that it would
> not be principled to include the city/town in both counties because there
> would be the assumption that the crime occurring in each corresponding
> county is tied solely to population. Still, I left in all cities/towns
> overlapping with two counties, in case you have some ideas about how a
> mixed-model might be used to account for these (I don?t think a
> crossed-effect structure would do it). So pretty much any city with
> duplicate values where that value lies within the same county should be
> counted (these are just separate school districts), but any city with
> duplicate values where one of those values happens to be in another county,
> yet the school district is still the same, shouldn't be counted; unless, of
> course, there is a way for mixed-modeling in lme4 to account for that
> (PLACE_ID will be the same, but COUNTY_ID will be different, but
> full_district_id will be the same). Does that make sense? I'll soon send an
> email to the group with more clarification.
>
> Use IDs vs names. I included names for reference, but city/towns might not
> always be recorded exactly the same, so IDs are the safer bet.
>
> I have tried lmer?originally, my intention was to preserve counts of zero
> crime (whether it?s weariness or sanity that has changed my view, the
> difference between one and zero doesn?t seem so important anymore. I get
> the boundary (singular) warning (if a warning is what it can be called). No
> doubt there are many here that know more than me, but my understanding of
> this message is that it mostly warns against overfitting. To me,
> controlling for time through a fixed effect and as a random slope seems
> warranted?different cities/towns have different rates of change in crime
> from year to year.
>
> I still think fitting with glmer would be ideal, but I also lack an
> understanding of the nuances on the backend with regard to how the two
> functions differ. It seems that lmer is faster and more efficient in
> modeling, though I?m not sure why?mathematically or programmatically?that?s
> the case. If you can point me to an explanation, I?d appreciate that.
>
> Thanks much for your messages and your help.
>
> James
>
>
> On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear James,
>
> Your mail contains only a part of the dput() output. Given the size of
> your data, I suggest that you place it somewhere online and send us a link
> to the data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be/>
>
>
> Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu>:
>
>> I posted my question at Stack Overflow, where it didn?t get much of a
>> response, and I was pointed in this direction by Ben Bolker. I?m happy to
>> send the whole dataset to anyone who wants but thought that it would be
>> presumptuous to include an enormous dput() here.
>>
>> I?m looking at the effects of education spending per school district on
>> crime rate (FBI crime data/UCR) within the cities and towns those school
>> districts serve over a fifteen year period. The DV now has 203,410
>> observations of city/town crime data over those fifteen years. (I use that
>> figure with some reticence, because there are so many moving parts and
>> things to account for, but having employed over 100 datasets and hours
>> passing through the code again, I think that figure is correct.)
>>
>> Cities are technically crossed with school district, in that one city
>> might attend multiple school districts. This means that one city could have
>> multiple values for expenditure per student. School districts, however,
>> also overlap with counties. As if things weren?t complicated enough, cities
>> are mostly nested within county (though there are cities that exist in two
>> counties, but it?s not often, and it?s usually by a small amount). Given
>> that each city/town has a distinct PLACE_ID, my understanding is that this
>> could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or
>> (1|STATE/COUNTY_ID/PLACE_ID).
>>
>> I?m pretty familiar with mixed-effect models, and I?ve looked through
>> clear and informative posts such as this one:
>> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified.
>> I believe things would remain sane to include school district
>> (full_district_id) as another crossed effect, as below:
>> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) +
>> (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control
>> = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
>> total.years, na.action = "na.omit")
>>
>> Variables (not included in this model, to keep things null and simple)
>> are centered and logged: pop per city, pop.dens per city, year,
>> unemployment rate per county, proportion children living in poverty per
>> school district, per capita income per county, difference in those who
>> voted democrat in presidential elections per county, log enforcement per
>> city/town, centered expenditure per student/ 1000 (per school district).
>> PLACE_ID corresponds to cities and towns, COUNTY_ID to counties,
>> full_district_id to school districts, and state.
>>
>> First, if I try to run the full model, using UCSD?s supercomputer, I get
>> the error that the job was killed, presumably because it got to a point
>> where it consumed too much ram (I think 125mb).
>>
>> I then tried to create a small subsection of data with arrange(STATE,
>> COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through
>> Delaware), so that I have 26,599 values. If I run this null model with the
>> above code, I get the following error:
>>
>> ```
>> Error in getOptfun(optimizer) :
>>   optimizer function must use (at least) formal parameters ?fn?, ?par?,
>> ?lower?, ?control?
>> ```
>>
>> Then I tried with the optimx, with these configurations: control =
>> glmerControl(optimizer = "optimx?,
>> optCtrl = list(method = "nlminb?,
>> maxit=10000,
>> iter.max=10000,
>> eval.max=10000,
>> lower = c(0,0,0),
>> upper = c(Inf,10,1)))
>>
>> and I received the following warning?since this is a null model, there
>> aren?t any variables to really rescale.\
>>
>> ```
>> Warning messages:
>> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower =
>> lower,  :
>>   unrecognized control elements named ?lower?, ?upper? ignored
>> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower =
>> lower,  :
>>   unrecognized control elements named ?lower?, ?upper? ignored
>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001,
>> component 1)
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?
>> ```
>>
>> I then tried more values (to 92,486, through Missouri). First, I tried
>> the optimizer nloptr, and then I tried the optimix. I still received the
>> same above errors.
>>
>> I?ve checked and rechecked everything, so I wanted to solicit advice,
>> either for where I might be going wrong, or for what I could do to resolve
>> these error messages.
>>
>> I?ve provided a brief snippet of the data below (randomly pulling a
>> number of cities within counties of Arkansas, Arizona, and Alabama, as a
>> dput.
>>
>> Thanks!
>>
>>
>>
>> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
>> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
>> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
>> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
>> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
>> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
>> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
>> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
>> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
>> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
>> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
>> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
>> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
>> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
>> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
>> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
>> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
>> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
>> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
>> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
>> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
>> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
>> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
>> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
>> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
>> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
>> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
>> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
>> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
>> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
>> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
>> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
>> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
>> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
>> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
>> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
>> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
>> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
>> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
>> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
>> ), COUNTY = c("autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "coconino county", "coconino
>> county",
>> "coconino county", "coconino county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "greenlee county", "greenlee county", "greenlee county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>> county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>> county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>> county",
>> "greenlee county", "greenlee county", "la paz county", "la paz county",
>> "la paz county", "la paz county", "la paz county", "la paz county",
>> "la paz county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "randolph county", "randolph county", "randolph county", "randolph
>> county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
>> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
>> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
>> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
>> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
>> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga
>> County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "St. Johns Unified District",
>> "St. Johns Unified District", "St. Johns Unified District", "St. Johns
>> Unified District",
>> "St. Johns Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>> District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>> District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>> District",
>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
>> District",
>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
>> District",
>> "Douglas Unified District", "Douglas Unified District", "Tombstone
>> Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>> Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>> Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Fort
>> Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>> "Sierra Vista Unified District", "Tombstone Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>> Unified District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>> District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>> District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>> District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>> District",
>> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>> District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>> Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Williams
>> Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams
>> Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams
>> Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams
>> Unified District",
>> "Williams Unified District", "Globe Unified District", "Miami Unified
>> District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified
>> District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified
>> District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified
>> District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified
>> District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified
>> District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified
>> District",
>> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman
>> Unified District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified
>> District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified
>> District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified
>> District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified
>> District",
>> "Miami Unified District", "Payson Unified District", "Payson Unified
>> District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified
>> District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified
>> District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified
>> District",
>> "Payson Unified District", "Pima Unified District", "Pima Unified
>> District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Safford Unified District", "Thatcher Unified
>> District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>> Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>> Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>> Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>> Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>> Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified
>> District",
>> "Thatcher Unified District", "Clifton Unified District", "Morenci Unified
>> District",
>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
>> District",
>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
>> District",
>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
>> District",
>> "Morenci Unified District", "Morenci Unified District", "Clifton Unified
>> District",
>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
>> District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "North Little Rock School District", "Pulaski County Special School
>> District",
>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>> Schools",
>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>> Schools",
>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>> Schools",
>> "Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring
>> Schools",
>> "Mammoth Spring Schools", "Greene County Technical School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Greene County Technical School District", "Greene County Technical
>> School District",
>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>> School District",
>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>> School District",
>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>> School District",
>> "Pocahontas School District", "Sloan-Hendrix School District",
>> "Sloan-Hendrix School District", "Sloan-Hendrix School District",
>> "Sloan-Hendrix School District", "Forrest City School District",
>> "Forrest City School District", "Forrest City School District",
>> "Forrest City School District", "Forrest City School District",
>> "Forrest City School District", "Forrest City School District",
>> "Forrest City School District", "Forrest City School District",
>> "Forrest City School District", "West Memphis School District",
>> "West Memphis School District", "West Memphis School District",
>> "West Memphis School District", "West Memphis School District",
>> "West Memphis School District", "Bryant Public Schools", "Bryant Public
>> Schools",
>> "Bauxite School District", "Benton School District", "Bryant Public
>> Schools",
>> "Harmony Grove School District", "Bauxite School District", "Benton
>> School District",
>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
>> District",
>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>> District",
>> "Bauxite School District", "Benton School District", "Bryant Public
>> Schools",
>> "Harmony Grove School District", "Bauxite School District", "Benton
>> School District",
>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
>> District",
>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>> District",
>> "Bauxite School District", "Benton School District", "Bryant Public
>> Schools",
>> "Harmony Grove School District", "Bauxite School District", "Benton
>> School District",
>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
>> District",
>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>> District",
>> "Bauxite School District", "Benton School District", "Bryant Public
>> Schools",
>> "Harmony Grove School District", "Bauxite School District", "Benton
>> School District",
>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
>> District",
>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>> District",
>> "Bauxite School District", "Benton School District", "Bryant Public
>> Schools",
>> "Harmony Grove School District", "Bryant Public Schools", "Bryant Public
>> Schools",
>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
>> "Fountain Lake School District", "Fountain Lake School District",
>> "Fountain Lake School District", "Fountain Lake School District",
>> "Fountain Lake School District", "Fountain Lake School District",
>> "Fountain Lake School District", "Fountain Lake School District",
>> "Fountain Lake School District", "Fountain Lake School District",
>> "Fountain Lake School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Bryant Public Schools", "Pulaski County Special School District",
>> "Bryant Public Schools", "Pulaski County Special School District",
>> "Bryant Public Schools", "Pulaski County Special School District",
>> "Bryant Public Schools", "Pulaski County Special School District",
>> "Sheridan School District", "Sheridan School District", "Sheridan School
>> District",
>> "Sheridan School District", "Sheridan School District", "Sheridan School
>> District",
>> "Sheridan School District", "Sheridan School District", "Sheridan School
>> District",
>> "Sheridan School District", "Sheridan School District", "Sheridan School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District", "Pulaski County Special School
>> District",
>> "Pulaski County Special School District"), EXPENDITURE_PER_STUDENT =
>> c(5.2927293064877,
>> 5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
>> 7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
>> 7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
>> 7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
>> 5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
>> 7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
>> 7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
>> 7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
>> 9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
>> 8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
>> 6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
>> 9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
>> 8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
>> 8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>> 8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
>> 6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
>> 9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>> 6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
>> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
>> 8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
>> 8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
>> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
>> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>> 9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
>> 8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
>> 8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
>> 7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
>> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
>> 8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>> 8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
>> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
>> 8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
>> 9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
>> 8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
>> 8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
>> 8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
>> 7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
>> 6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
>> 9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
>> 6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
>> 7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
>> 8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
>> 9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
>> 8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
>> 7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
>> 9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
>> 6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
>> 7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
>> 7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
>> 7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
>> 4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
>> 5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
>> 6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
>> 10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
>> 6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
>> 7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
>> 8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
>> 7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
>> 7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
>> 7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
>> 6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
>> 8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
>> 7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
>> 8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
>> 7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
>> 8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
>> 9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
>> 8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
>> 8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
>> 7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
>> 9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
>> 10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
>> 7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
>> 8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
>> 7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
>> 11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
>> 9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
>> 5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
>> 6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
>> 7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
>> 5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
>> 6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
>> 7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
>> 7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
>> 7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
>> 7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
>> 5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
>> 7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
>> 7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
>> 5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
>> 7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
>> 6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
>> 4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
>> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
>> 4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
>> 5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
>> 6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
>> 6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
>> 6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
>> 6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
>> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
>> 7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
>> 10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
>> 9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
>> 6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
>> 6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
>> 8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
>> 12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
>> 10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
>> 12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
>> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
>> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
>> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
>> 9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
>> 10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
>> 10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
>> 12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
>> 12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
>> 12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
>> 12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
>> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>> 10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
>> 8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
>> 8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
>> 9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
>> 10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
>> 9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
>> 10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
>> 11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
>> 11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
>> 8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
>> 9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
>> 10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
>> 10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
>> 10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
>> 10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
>> 8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
>> 9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
>> 9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
>> 6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
>> 7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
>> 8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
>> 8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
>> 7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
>> 8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
>> 7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
>> 8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
>> 10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
>> 10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
>> 9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
>> 8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
>> 7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
>> 7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
>> 7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
>> 7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
>> 7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
>> 7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
>> 7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
>> 8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
>> 8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
>> 8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
>> 8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
>> 8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
>> 8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
>> 7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
>> 7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
>> 6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
>> 8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
>> 11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
>> 8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>> 10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
>> 8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
>> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
>> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
>> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
>> 9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
>> 9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
>> 11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
>> 9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
>> 10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
>> 10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
>> 7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
>> 8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
>> 6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
>> 8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
>> 7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
>> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>> 10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
>> -800L), class = c("tbl_df", "tbl", "data.frame"))
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From kc000001 @end|ng |rom umn@edu  Mon Sep  9 20:35:18 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Mon, 9 Sep 2019 13:35:18 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
Message-ID: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>

Hello R mixed models community,

I am trying to fit a model for a split- split-plot design using lmer. I
know how to do this with aov and ssp.plot function in agricolae, but I need
to use lmer in this case.

I am interested in the response variable biomass of cover crops. I have the
main plots as crops (corn and soybean). The subplot is tillage, which is
randomized within the crops and has 3 levels (conventional-till, no-till,
and strip-till). Within tillage(sub plot), 3 cover crop strategies are
randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
treatments. The whole experiment is replicated 4 times, therefore, total
experimental units equal to 72 units.

Data arranged in a csv file is attached in this email.

Now the analysis part:

I know how to do this using aov/ ssp.plot( agricolae). The code is as
follows:

model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
Same thing with aov:

model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)

For my  analysis using lmer, and lme,  I have the following code:

model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)

model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)

Now my confusion and questions are:
1. I have used crop, tillage, and cover as fixed effects. And only the rep
(block) as random. Is the random effect properly assigned for this design?

2. I have read a lot about crossed and nested design. Crawley and Oehlert
give particular examples about it, but I have trouble understanding if this
design has nested factors or crossed factors.

I would be very relieved to receive feedback with the matter in hand.

Looking forward, and thank  you  a lot,

Sincerely,
Rabin

From chr|@ho|d @end|ng |rom p@yctc@org  Mon Sep  9 20:50:02 2019
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Mon, 9 Sep 2019 19:50:02 +0100 (BST)
Subject: [R-sig-ME] Some very basic questions about modelling
 heteroscedasticity of within subjects variance in repeated measures
 obserational studies
Message-ID: <165672629.3758974.1568055002536.JavaMail.zimbra@psyctc.org>

I'm a psychotherapist not a theoretical nor a professional statistician so apologies if some of these questions are embarrassingly stupid. I have done some searching for pertinent publications and answers but I'm no finding answers, perhaps I may be using entirely the wrong search terms/questions. 

I took a vow over a decade ago to stick with R for all my stats and don't intend to break it.  I'm slowly getting my head around mostly linear mixed models and mostly for changes on continuous measures in therapies mostly from naturalistic datasets from services, but just now also of some non-help-seeking general population samples. So far I've been using lmer from the lme4 package and lme and nlme from the nlme package. As I don't have the resource of colleagues with real skills in this area I've been trying to check my assumptions and analyses by modelling and seeing if analyses of models fit what I expect. Finding the simstudy package recently looks as if it will help with this and replace my otherwise clumsy models. 

My particular interest is in what I'm calling "heteroscedasticity of within subjects variance in repeated measures", I think it could also be called "allowing a random variance term within individuals" or something like that. I have good theoretical and some (quite old but robust looking pre-mixed models) empirical work that suggests that such a random effect may be present in most of my datasets. I know how to model random offsets (centred or not), random slopes and even piecewise random and nonlinear slopes (all of which are realistic in clinical datasets). However, I'm really unclear how I should model a random variance term, if I'm explaining myself clearly. I found some discussion off [ https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling | https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling ] but the only software implementations seemed to refer to MLWin and though I have great respect for MLWin and have used it in the past, I would really like to keep my vow to do everything in R. 

1) Can anyone point me to work within the mixed models tradition that looks as random within subjects variance?
2) Can anyone point me to work using R tools that explores this?

Many thanks in advance to all, and, while I'm here, huge thanks to the people who have written all these tools and so often give incredibly helpful and thoughtful Emails here from which I've learned much of what I do know about his area,

Chris

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Sep  9 21:13:44 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 9 Sep 2019 21:13:44 +0200
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
Message-ID: <CAJuCY5yynw=1igFFaJBk6a-J6C4Rpd0CxQzW+tOGmkFkdCwKiQ@mail.gmail.com>

Dear Rabin,

The mail list has stripped your csv file. Send small files as txt. Or put
the data somewhere online and send the link.

You want to use a random intercept to model the effect of an experimental
unit which is not captured by your fixed effects. E.g. for each combination
of replicate, crop and tillage you have 3 types of cover. So you want a
"tillage" level random intercept to model this. You can do this by
assigning a unique id to each combination of replicate (4), crop (2) and
tillage (3) = 36 subplot. So number your subplots for 1 to 36. With such
unique ids you don't have to worry about (partially) nested or (partially)
crossed effects. See https://www.muscardinus.be/2017/07/lme4-random-effects/

You can do the same thing at the crop level: unique combinations of
replicate (4) and crop (2) = 8 combinations. The problem is that for a
descend estimate of the random effect variance, you need a lot of levels (>
200) see https://www.muscardinus.be/2018/09/number-random-effect-levels/.
If you only want to use random intercept to correct for dependencies within
the data, then you can get a way with a smaller number (>10). In your case,
you have too few replicates to take the replicate and replicate/crop plot
effect into account. So I recommend that you only take the subplots
(replicate/crop/tillage) into account. Note that this effect will take up
any effect at a higher level (replicate/crop) when you don't model that
effect.

I'd go for lmer(biomass~crop*tillage*cover+ (1|subplot),data=data)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


<https://www.inbo.be>


Op ma 9 sep. 2019 om 20:36 schreef Rabin KC <kc000001 at umn.edu>:

> Hello R mixed models community,
>
> I am trying to fit a model for a split- split-plot design using lmer. I
> know how to do this with aov and ssp.plot function in agricolae, but I need
> to use lmer in this case.
>
> I am interested in the response variable biomass of cover crops. I have the
> main plots as crops (corn and soybean). The subplot is tillage, which is
> randomized within the crops and has 3 levels (conventional-till, no-till,
> and strip-till). Within tillage(sub plot), 3 cover crop strategies are
> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
> treatments. The whole experiment is replicated 4 times, therefore, total
> experimental units equal to 72 units.
>
> Data arranged in a csv file is attached in this email.
>
> Now the analysis part:
>
> I know how to do this using aov/ ssp.plot( agricolae). The code is as
> follows:
>
> model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
> Same thing with aov:
>
>
> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>
> For my  analysis using lmer, and lme,  I have the following code:
>
> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>
> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>
> Now my confusion and questions are:
> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
> (block) as random. Is the random effect properly assigned for this design?
>
> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
> give particular examples about it, but I have trouble understanding if this
> design has nested factors or crossed factors.
>
> I would be very relieved to receive feedback with the matter in hand.
>
> Looking forward, and thank  you  a lot,
>
> Sincerely,
> Rabin
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Sep  9 21:25:04 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 9 Sep 2019 21:25:04 +0200
Subject: [R-sig-ME] Some very basic questions about modelling
 heteroscedasticity of within subjects variance in repeated measures
 obserational studies
In-Reply-To: <165672629.3758974.1568055002536.JavaMail.zimbra@psyctc.org>
References: <165672629.3758974.1568055002536.JavaMail.zimbra@psyctc.org>
Message-ID: <CAJuCY5zxySnYWc4KGViEZgxiYxcyMci2aOPZyXLPCYfNUfJTEQ@mail.gmail.com>

Dear Chris,

I think you want each individual to have a different residual variance. You
can do this with lme() using weight = varIdent(~1|individual). Note that
you'll need a lot data for each individual to get sensible results.

There is a chapter on this in Pinheiro and Bates (2000) Mixed-Effects
Models in S and S-PLUS and probably also in Zuur et al (2009) Mixed Effects
Models and Extensions in Ecology with RMixed-Effects Models in S and S-PLUS

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 9 sep. 2019 om 20:54 schreef Chris Evans <chrishold at psyctc.org>:

> I'm a psychotherapist not a theoretical nor a professional statistician so
> apologies if some of these questions are embarrassingly stupid. I have done
> some searching for pertinent publications and answers but I'm no finding
> answers, perhaps I may be using entirely the wrong search terms/questions.
>
> I took a vow over a decade ago to stick with R for all my stats and don't
> intend to break it.  I'm slowly getting my head around mostly linear mixed
> models and mostly for changes on continuous measures in therapies mostly
> from naturalistic datasets from services, but just now also of some
> non-help-seeking general population samples. So far I've been using lmer
> from the lme4 package and lme and nlme from the nlme package. As I don't
> have the resource of colleagues with real skills in this area I've been
> trying to check my assumptions and analyses by modelling and seeing if
> analyses of models fit what I expect. Finding the simstudy package recently
> looks as if it will help with this and replace my otherwise clumsy models.
>
> My particular interest is in what I'm calling "heteroscedasticity of
> within subjects variance in repeated measures", I think it could also be
> called "allowing a random variance term within individuals" or something
> like that. I have good theoretical and some (quite old but robust looking
> pre-mixed models) empirical work that suggests that such a random effect
> may be present in most of my datasets. I know how to model random offsets
> (centred or not), random slopes and even piecewise random and nonlinear
> slopes (all of which are realistic in clinical datasets). However, I'm
> really unclear how I should model a random variance term, if I'm explaining
> myself clearly. I found some discussion off [
> https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling
> |
> https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling
> ] but the only software implementations seemed to refer to
>  MLWin and though I have great respect for MLWin and have used it in the
> past, I would really like to keep my vow to do everything in R.
>
> 1) Can anyone point me to work within the mixed models tradition that
> looks as random within subjects variance?
> 2) Can anyone point me to work using R tools that explores this?
>
> Many thanks in advance to all, and, while I'm here, huge thanks to the
> people who have written all these tools and so often give incredibly
> helpful and thoughtful Emails here from which I've learned much of what I
> do know about his area,
>
> Chris
>
> --
> Chris Evans <chris at psyctc.org> Visiting Professor, University of
> Sheffield <chris.evans at sheffield.ac.uk>
> I do some consultation work for the University of Roehampton <
> chris.evans at roehampton.ac.uk> and other places
> but <chris at psyctc.org> remains my main Email address.  I have a work web
> site at:
>    https://www.psyctc.org/psyctc/
> and a site I manage for CORE and CORE system trust at:
>    http://www.coresystemtrust.org.uk/
> I have "semigrated" to France, see:
>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
> That page will also take you to my blog which started with earlier joys in
> France and Spain!
>
> If you want to book to talk, I am trying to keep that to Thursdays and my
> diary is at:
>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
> Beware: French time, generally an hour ahead of UK.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kc000001 @end|ng |rom umn@edu  Mon Sep  9 21:51:41 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Mon, 9 Sep 2019 14:51:41 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CAJuCY5yynw=1igFFaJBk6a-J6C4Rpd0CxQzW+tOGmkFkdCwKiQ@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <CAJuCY5yynw=1igFFaJBk6a-J6C4Rpd0CxQzW+tOGmkFkdCwKiQ@mail.gmail.com>
Message-ID: <CANdRtHv-YG8UVJWp=+iM8x-QzsbH_ZfZJ7nhM74VJoR3t9ZtYg@mail.gmail.com>

Dear Thierry,

Thank you for your reply.

The link to the file is here
<https://drive.google.com/open?id=1sQ0O6FgT5eOQKlhc_ejzfR_wJbRvLzrY>. You
advised naming the subplots from 1 to 36. But with 4 replicates, 2 crops
and 3 tillage, should not the number of subplots equal to 24? Am I missing
something?
Even if I name the subplots 1 to 36, how should I name the remaining 36
plots (total 72 plots)?

Sorry, my analysis skills are at beginner's level, but I would appreciate
the clarification.

Thank you,
Rabin

On Mon, Sep 9, 2019 at 2:13 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Rabin,
>
> The mail list has stripped your csv file. Send small files as txt. Or put
> the data somewhere online and send the link.
>
> You want to use a random intercept to model the effect of an experimental
> unit which is not captured by your fixed effects. E.g. for each combination
> of replicate, crop and tillage you have 3 types of cover. So you want a
> "tillage" level random intercept to model this. You can do this by
> assigning a unique id to each combination of replicate (4), crop (2) and
> tillage (3) = 36 subplot. So number your subplots for 1 to 36. With such
> unique ids you don't have to worry about (partially) nested or (partially)
> crossed effects. See
> https://www.muscardinus.be/2017/07/lme4-random-effects/
>
> You can do the same thing at the crop level: unique combinations of
> replicate (4) and crop (2) = 8 combinations. The problem is that for a
> descend estimate of the random effect variance, you need a lot of levels (>
> 200) see https://www.muscardinus.be/2018/09/number-random-effect-levels/.
> If you only want to use random intercept to correct for dependencies within
> the data, then you can get a way with a smaller number (>10). In your case,
> you have too few replicates to take the replicate and replicate/crop plot
> effect into account. So I recommend that you only take the subplots
> (replicate/crop/tillage) into account. Note that this effect will take up
> any effect at a higher level (replicate/crop) when you don't model that
> effect.
>
> I'd go for lmer(biomass~crop*tillage*cover+ (1|subplot),data=data)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
> <https://www.inbo.be>
>
>
> Op ma 9 sep. 2019 om 20:36 schreef Rabin KC <kc000001 at umn.edu>:
>
>> Hello R mixed models community,
>>
>> I am trying to fit a model for a split- split-plot design using lmer. I
>> know how to do this with aov and ssp.plot function in agricolae, but I
>> need
>> to use lmer in this case.
>>
>> I am interested in the response variable biomass of cover crops. I have
>> the
>> main plots as crops (corn and soybean). The subplot is tillage, which is
>> randomized within the crops and has 3 levels (conventional-till, no-till,
>> and strip-till). Within tillage(sub plot), 3 cover crop strategies are
>> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
>> treatments. The whole experiment is replicated 4 times, therefore, total
>> experimental units equal to 72 units.
>>
>> Data arranged in a csv file is attached in this email.
>>
>> Now the analysis part:
>>
>> I know how to do this using aov/ ssp.plot( agricolae). The code is as
>> follows:
>>
>> model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
>> Same thing with aov:
>>
>>
>> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>>
>> For my  analysis using lmer, and lme,  I have the following code:
>>
>> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>>
>> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>>
>> Now my confusion and questions are:
>> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
>> (block) as random. Is the random effect properly assigned for this design?
>>
>> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
>> give particular examples about it, but I have trouble understanding if
>> this
>> design has nested factors or crossed factors.
>>
>> I would be very relieved to receive feedback with the matter in hand.
>>
>> Looking forward, and thank  you  a lot,
>>
>> Sincerely,
>> Rabin
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Sep  9 23:21:27 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 9 Sep 2019 17:21:27 -0400
Subject: [R-sig-ME] Some very basic questions about modelling
 heteroscedasticity of within subjects variance in repeated measures
 obserational studies
In-Reply-To: <CAJuCY5zxySnYWc4KGViEZgxiYxcyMci2aOPZyXLPCYfNUfJTEQ@mail.gmail.com>
References: <165672629.3758974.1568055002536.JavaMail.zimbra@psyctc.org>
 <CAJuCY5zxySnYWc4KGViEZgxiYxcyMci2aOPZyXLPCYfNUfJTEQ@mail.gmail.com>
Message-ID: <7cf3b718-6a14-257d-53d7-f412fe85ac5f@gmail.com>


  Yes.  Alternatively with glmmTMB, with dispformula = ~0+individual
(the "0" isn't strictly necessary but gives more interpretable results).
 Or in lme4 with some hacks previously described on this list (no time
to search for it right now ...)

On 2019-09-09 3:25 p.m., Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Chris,
> 
> I think you want each individual to have a different residual variance. You
> can do this with lme() using weight = varIdent(~1|individual). Note that
> you'll need a lot data for each individual to get sensible results.
> 
> There is a chapter on this in Pinheiro and Bates (2000) Mixed-Effects
> Models in S and S-PLUS and probably also in Zuur et al (2009) Mixed Effects
> Models and Extensions in Ecology with RMixed-Effects Models in S and S-PLUS
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 9 sep. 2019 om 20:54 schreef Chris Evans <chrishold at psyctc.org>:
> 
>> I'm a psychotherapist not a theoretical nor a professional statistician so
>> apologies if some of these questions are embarrassingly stupid. I have done
>> some searching for pertinent publications and answers but I'm no finding
>> answers, perhaps I may be using entirely the wrong search terms/questions.
>>
>> I took a vow over a decade ago to stick with R for all my stats and don't
>> intend to break it.  I'm slowly getting my head around mostly linear mixed
>> models and mostly for changes on continuous measures in therapies mostly
>> from naturalistic datasets from services, but just now also of some
>> non-help-seeking general population samples. So far I've been using lmer
>> from the lme4 package and lme and nlme from the nlme package. As I don't
>> have the resource of colleagues with real skills in this area I've been
>> trying to check my assumptions and analyses by modelling and seeing if
>> analyses of models fit what I expect. Finding the simstudy package recently
>> looks as if it will help with this and replace my otherwise clumsy models.
>>
>> My particular interest is in what I'm calling "heteroscedasticity of
>> within subjects variance in repeated measures", I think it could also be
>> called "allowing a random variance term within individuals" or something
>> like that. I have good theoretical and some (quite old but robust looking
>> pre-mixed models) empirical work that suggests that such a random effect
>> may be present in most of my datasets. I know how to model random offsets
>> (centred or not), random slopes and even piecewise random and nonlinear
>> slopes (all of which are realistic in clinical datasets). However, I'm
>> really unclear how I should model a random variance term, if I'm explaining
>> myself clearly. I found some discussion off [
>> https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling
>> |
>> https://www.researchgate.net/post/Is_heteroscedasticity_considered_in_multilevel_random_effects_hierarchical_modeling
>> ] but the only software implementations seemed to refer to
>>  MLWin and though I have great respect for MLWin and have used it in the
>> past, I would really like to keep my vow to do everything in R.
>>
>> 1) Can anyone point me to work within the mixed models tradition that
>> looks as random within subjects variance?
>> 2) Can anyone point me to work using R tools that explores this?
>>
>> Many thanks in advance to all, and, while I'm here, huge thanks to the
>> people who have written all these tools and so often give incredibly
>> helpful and thoughtful Emails here from which I've learned much of what I
>> do know about his area,
>>
>> Chris
>>
>> --
>> Chris Evans <chris at psyctc.org> Visiting Professor, University of
>> Sheffield <chris.evans at sheffield.ac.uk>
>> I do some consultation work for the University of Roehampton <
>> chris.evans at roehampton.ac.uk> and other places
>> but <chris at psyctc.org> remains my main Email address.  I have a work web
>> site at:
>>    https://www.psyctc.org/psyctc/
>> and a site I manage for CORE and CORE system trust at:
>>    http://www.coresystemtrust.org.uk/
>> I have "semigrated" to France, see:
>>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>> That page will also take you to my blog which started with earlier joys in
>> France and Spain!
>>
>> If you want to book to talk, I am trying to keep that to Thursdays and my
>> diary is at:
>>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
>> Beware: French time, generally an hour ahead of UK.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@kot@judo @end|ng |rom m@c@com  Mon Sep  9 23:43:30 2019
From: d@kot@judo @end|ng |rom m@c@com (Peter Claussen)
Date: Mon, 9 Sep 2019 16:43:30 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
Message-ID: <777CDD01-DC7F-4CBB-B99F-2438EBB44D9B@mac.com>



> On Sep 9, 2019, at 1:35 PM, Rabin KC <kc000001 at umn.edu> wrote:
> 
> Hello R mixed models community,
> 
> ?

> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
> 
> For my  analysis using lmer, and lme,  I have the following code:
> 
> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
> 
> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
> 
> Now my confusion and questions are:
> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
> (block) as random. Is the random effect properly assigned for this design?

Simply, no. 

When you have three levels of independent randomization, then your design model has three random effects

Consider the expected output from agricolae. There should be an error term for crop, as randomized within whole blocks, designated Ea. This is the crop x replicate interaction term, and would also be the residual error if you were to analyze these data as a simple RCB of 2 treatments and 4 replicates (averaging biomass over whole plots). The F-test you would use to test the significance of crop would be MS(crop) / Ea, while the F-test for replicate effects would be MS(rep)/Ea.

There will be a second error strata, representing the independent randomization of tillage within whole plots (replicate:crop). That should be labelled Eb. This would also be the residual error of a simple split-plot experiment with crop as whole plot and tillage as subplot treatments (averaging biomass over subplots) and would be represented as rep:crop:tillage. This is the error term to test tillage and crop-tillage interaction.

The final error strata is the independent randomization of cover within crop:tillage subplots, and this will work out to be equivalent to residual error. So, to duplicate the decomposition of the aov from agricolae, we might write the linear model as

lm(biomass ~ crop*tillage*cover + rep +  rep:crop + rep:crop:tillage, data=data)
or, more briefly, as
lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)

That won?t give the correct F-tests, though, so to get aov to perform appropriate tests, we should write

aov(biomass ~ crop*tillage*cover + rep + Error(rep:crop/tillage), data=data)

(not what you?ve written, since we test rep against rep:crop)

This leads to an lmer model of
lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage), data=data)

> 
> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
> give particular examples about it, but I have trouble understanding if this
> design has nested factors or crossed factors.

crop, tillage and cover are all crossed factors, since each possible combination of crop, tillage and cover are included, and you might be interested in the interactions among these factors. Since this is a split-split-plot experiment, the experimental units (rep:crop = whole plot, rep:crop:tillage=subplot, rep:crop:tillage:cover = sub subplot) are nested, and not all combinations of treatments are subject to the same experimental errors.

That?s where the analysis starts to become tricky. If you want to compare treatments that are all applied within same random effects, that is,

Crop A : Tillage A : Cover A vs Crop A : Tillage A : Cover B, 

then the error terms for mean comparisons are simple. Comparisons across strata, like

Crop A : Tillage A : Cover A vs Crop B : Tillage A : Cover A

require estimates of the variances for each level of error, and with only a few observations (Ea (crop:rep) should have only 3 d.f.) you might not get estimates from lmer, and error terms derived from aov might include negative variances. AOV of the linear model (lm) is useful here, in that if any of the F-ratios of the random effects (rep, rep:crop or rep:crop:tillage) are less than 1, then you should expect lmer to produce a variance estimate of effectively 0. I would need to write out the expected means squares for a split-split-plot, though, to justify this statement.

By your email address and the subject matter, I?m guessing you?re in agronomy at the U of M. If so, I can suggest a friendly neighborhood statistician to consult.

Cheers,

Peter Claussen 
(work email Peter at gdmdata.com <mailto:Peter at gdmdata.com>)


	[[alternative HTML version deleted]]


From kc000001 @end|ng |rom umn@edu  Tue Sep 10 01:05:27 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Mon, 9 Sep 2019 18:05:27 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <777CDD01-DC7F-4CBB-B99F-2438EBB44D9B@mac.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <777CDD01-DC7F-4CBB-B99F-2438EBB44D9B@mac.com>
Message-ID: <CANdRtHuiozRc_kJ-Hqc1m_wnGom+rUPQY9FzcJTmv-b2JvAOrQ@mail.gmail.com>

Dear Peter,

Your reply has made my day and very clearly answered the questions I was
asking myself for a few weeks. Thank you for correcting my mistakes as
well.

The lmer() does produce a variance of 0 for random effect (crop: rep). I
now know the term is called boundary (singular) fit. What would be the
correct thing to do in this case? I do have this experiment conducted for 2
years in 2 different locations, which might take care of the precious
degrees of freedom, but again, will add new variables making the model more
complicated.

I ran an Anova II (wald test) and was thinking of doing post hoc analysis
on significant terms. (If this would take care of singularity). Any advice
on that would be greatly appreciated.

And yes, I am in Agronomy in U of M. I will be writing to you in your work
email about the friendly statistician you mentioned!!!!


Best regards,
Rabin

On Mon, Sep 9, 2019 at 4:43 PM Peter Claussen <dakotajudo at mac.com> wrote:

>
>
> On Sep 9, 2019, at 1:35 PM, Rabin KC <kc000001 at umn.edu> wrote:
>
> Hello R mixed models community,
>
> ?
>
>
>
> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>
> For my  analysis using lmer, and lme,  I have the following code:
>
> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>
> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>
> Now my confusion and questions are:
> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
> (block) as random. Is the random effect properly assigned for this design?
>
>
> Simply, no.
>
> When you have three levels of independent randomization, then your design
> model has three random effects
>
> Consider the expected output from agricolae. There should be an error term
> for crop, as randomized within whole blocks, designated Ea. This is the
> crop x replicate interaction term, and would also be the residual error if
> you were to analyze these data as a simple RCB of 2 treatments and 4
> replicates (averaging biomass over whole plots). The F-test you would use
> to test the significance of crop would be MS(crop) / Ea, while the F-test
> for replicate effects would be MS(rep)/Ea.
>
> There will be a second error strata, representing the independent
> randomization of tillage within whole plots (replicate:crop). That should
> be labelled Eb. This would also be the residual error of a simple
> split-plot experiment with crop as whole plot and tillage as subplot
> treatments (averaging biomass over subplots) and would be represented as
> rep:crop:tillage. This is the error term to test tillage and crop-tillage
> interaction.
>
> The final error strata is the independent randomization of cover within
> crop:tillage subplots, and this will work out to be equivalent to residual
> error. So, to duplicate the decomposition of the aov from agricolae, we
> might write the linear model as
>
> lm(biomass ~ crop*tillage*cover + rep +  rep:crop + rep:crop:tillage,
> data=data)
> or, more briefly, as
> lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)
>
> That won?t give the correct F-tests, though, so to get aov to perform
> appropriate tests, we should write
>
> aov(biomass ~ crop*tillage*cover + rep + Error(rep:crop/tillage),
> data=data)
>
> (not what you?ve written, since we test rep against rep:crop)
>
> This leads to an lmer model of
> lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage), data=data)
>
>
> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
> give particular examples about it, but I have trouble understanding if this
> design has nested factors or crossed factors.
>
>
> crop, tillage and cover are all crossed factors, since each possible
> combination of crop, tillage and cover are included, and you might be
> interested in the interactions among these factors. Since this is a
> split-split-plot experiment, the experimental units (rep:crop = whole plot,
> rep:crop:tillage=subplot, rep:crop:tillage:cover = sub subplot) are nested,
> and not all combinations of treatments are subject to the same experimental
> errors.
>
> That?s where the analysis starts to become tricky. If you want to compare
> treatments that are all applied within same random effects, that is,
>
> Crop A : Tillage A : Cover A vs Crop A : Tillage A : Cover B,
>
> then the error terms for mean comparisons are simple. Comparisons across
> strata, like
>
> Crop A : Tillage A : Cover A vs Crop B : Tillage A : Cover A
>
> require estimates of the variances for each level of error, and with only
> a few observations (Ea (crop:rep) should have only 3 d.f.) you might not
> get estimates from lmer, and error terms derived from aov might include
> negative variances. AOV of the linear model (lm) is useful here, in that if
> any of the F-ratios of the random effects (rep, rep:crop or
> rep:crop:tillage) are less than 1, then you should expect lmer to produce a
> variance estimate of effectively 0. I would need to write out the expected
> means squares for a split-split-plot, though, to justify this statement.
>
> By your email address and the subject matter, I?m guessing you?re in
> agronomy at the U of M. If so, I can suggest a friendly neighborhood
> statistician to consult.
>
> Cheers,
>
> Peter Claussen
> (work email Peter at gdmdata.com)
>
>

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom uc@d@edu  Tue Sep 10 08:50:55 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Tue, 10 Sep 2019 06:50:55 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
Message-ID: <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>

Thanks for the comment to center the year variable. I hadn?t thought about that, and I changed my model to incorporate a centered year. Just wondering?would I be right in saying that while centering the year might affect convergence, and the interpretation of the intercept as the average city in an average year, it wouldn?t affect the coefficient estimates?

I have a model where education spending is averaged (when one city attends multiple school districts) to do away with district_id. That model does run. But you?re doubtful that the mixed-effect model could handle the crossed effects given the large overlap of district_id and city? Is there any rule of thumb for when a crossed effects model can be used vs when a variable must be averaged?or is it merely that if it converges then it converges?

I use year as fixed-effect in my non-null model. Your other suggestion is to possibly add year as a random intercept. Wouldn?t these two choices ultimately be looking at different things?

Thanks for the gamma suggestion. Are you suggesting using a gamma distribution in glmer? Does the gamma distribution in glmer default to the Erlang distribution? Would that still have to be as a rate rather than a discrete variable, and in that case, how would that vary from fitting the model in lmer with crime as a rate and getting rid of population as a fixed effect?

Much thanks, Thierry et al.!

James


With regard to Douglas? question, I should?ve replied all, but here was my answer:

Especially in the early ?00s crime was offered as two datasets?one on metropolitan/city areas with population > 10,000 and the other as population < 10,000. For 2004, the only data available is the dataset for cities > 10,000. I?ve contacted the FBI regarding whether they can track down the corresponding <10,000 dataset; they?re looking into it.



On Sep 9, 2019, at 2:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Since all ID's are unique, you can rely on the implicit nesting of random effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) + (1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).

There is a huge overlap between PLACE_ID and full_district_id. The model will have a hard time separating both effects. Especially since you have the same random slope.

You should also center the year variable. Now your model is estimating the random intercept at year 0.

So in terms of basic model I would

- drop either PLACE_ID or full_district_id
- center year
- add year to the fixed effects or add it as a separate random intercept

Furthermore, I'm not sure it the Poisson distribution is the most relevant distribution for your response. I've seen a case were the Poisson distribution failed. The response was an area in hectares rounded to an integer value. The model fitted well with a Gamma distribution.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
Okay, sorry for the delay; I was waiting to hear back from a couple people at the census regarding a question on school district info in the dataset.

I?ve  uploaded the dataset as a zip and an xs:
https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing

There is one important thing to note, here, which is that there is more city overlap between counties than I thought. The easiest way to explain this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID, year), you should get 107,515; however, with distinct(PLACE_ID, year), you?ll only get 99,832. So essentially, there are ~8000 times that a city will overlap in two counties (this likely includes the same city repeating this overlap every year?though it all depends on what years the city/town police department reports crime to the FBI). I can figure out the respective populations in each of the two counties where the city overlaps. It?s a bit of leg work, but it is possible. Still, it seems that it would not be principled to include the city/town in both counties because there would be the assumption that the crime occurring in each corresponding county is tied solely to population. Still, I left in all cities/towns overlapping with two counties, in case you have some ideas about how a mixed-model might be used to account for these (I don?t think a crossed-effect structure would do it). So pretty much any city with duplicate values where that value lies within the same county should be counted (these are just separate school districts), but any city with duplicate values where one of those values happens to be in another county, yet the school district is still the same, shouldn't be counted; unless, of course, there is a way for mixed-modeling in lme4 to account for that (PLACE_ID will be the same, but COUNTY_ID will be different, but full_district_id will be the same). Does that make sense? I'll soon send an email to the group with more clarification.

Use IDs vs names. I included names for reference, but city/towns might not always be recorded exactly the same, so IDs are the safer bet.

I have tried lmer?originally, my intention was to preserve counts of zero crime (whether it?s weariness or sanity that has changed my view, the difference between one and zero doesn?t seem so important anymore. I get the boundary (singular) warning (if a warning is what it can be called). No doubt there are many here that know more than me, but my understanding of this message is that it mostly warns against overfitting. To me, controlling for time through a fixed effect and as a random slope seems warranted?different cities/towns have different rates of change in crime from year to year.

I still think fitting with glmer would be ideal, but I also lack an understanding of the nuances on the backend with regard to how the two functions differ. It seems that lmer is faster and more efficient in modeling, though I?m not sure why?mathematically or programmatically?that?s the case. If you can point me to an explanation, I?d appreciate that.

Thanks much for your messages and your help.

James


On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Your mail contains only a part of the dput() output. Given the size of your data, I suggest that you place it somewhere online and send us a link to the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.

I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)

Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).

I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")

Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.

First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).

I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:

```
Error in getOptfun(optimizer) :
  optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
```

Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
optCtrl = list(method = "nlminb?,
maxit=10000,
iter.max=10000,
eval.max=10000,
lower = c(0,0,0),
upper = c(Inf,10,1)))

and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\

```
Warning messages:
1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
```

I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.

I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.

I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.

Thanks!



231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
"0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
"0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
"0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
"0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
"0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
"0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
"0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
"0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
"0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
"0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
"0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
"0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
"0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
"0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
"0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
"0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
"0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
"0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
"0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
"0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
"0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
"0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
), COUNTY = c("autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "la paz county", "la paz county",
"la paz county", "la paz county", "la paz county", "la paz county",
"la paz county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04012",
"04012", "04012", "04012", "04012", "04012", "04012", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "St. Johns Unified District",
"St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
"St. Johns Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring Schools",
"Mammoth Spring Schools", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "Bryant Public Schools", "Bryant Public Schools",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District"), EXPENDITURE_PER_STUDENT = c(5.2927293064877,
5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
-800L), class = c("tbl_df", "tbl", "data.frame"))


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Tue Sep 10 08:51:40 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Tue, 10 Sep 2019 08:51:40 +0200
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
Message-ID: <CAENiVe--Gixxhk69W8A+8zcMrZM0Bu-UDE9=K43Gb3L0yKH4Qg@mail.gmail.com>

I agree with Peter Claussen.I am a weed ecologist and often deal with these
experimental set-ups.

The correct full intercept model ought to be:
lmer(biomass~block+
crop*tillage*cover+(1|block:crop)+(1|block:crop:tillage)+(1|block:crop:tillage:CC))

Note that block is treated as fixed because 4 levels are not sufficient to
estimate a random effect.

Also note that (1|block:crop:tillage:CC) should only be introduced in the
model if there is pseudoreplication at the elementary plot level, as is
often done.

For appropriate test of effects, look into the {monet} or {afex} package.

For appropriate post-hoc multiple comparisons, look into the {emmeans}
package.

Cheers,

GA2

Le lun. 9 sept. 2019 ? 20:36, Rabin KC <kc000001 at umn.edu> a ?crit :

> Hello R mixed models community,
>
> I am trying to fit a model for a split- split-plot design using lmer. I
> know how to do this with aov and ssp.plot function in agricolae, but I need
> to use lmer in this case.
>
> I am interested in the response variable biomass of cover crops. I have the
> main plots as crops (corn and soybean). The subplot is tillage, which is
> randomized within the crops and has 3 levels (conventional-till, no-till,
> and strip-till). Within tillage(sub plot), 3 cover crop strategies are
> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
> treatments. The whole experiment is replicated 4 times, therefore, total
> experimental units equal to 72 units.
>
> Data arranged in a csv file is attached in this email.
>
> Now the analysis part:
>
> I know how to do this using aov/ ssp.plot( agricolae). The code is as
> follows:
>
> model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
> Same thing with aov:
>
>
> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>
> For my  analysis using lmer, and lme,  I have the following code:
>
> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>
> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>
> Now my confusion and questions are:
> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
> (block) as random. Is the random effect properly assigned for this design?
>
> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
> give particular examples about it, but I have trouble understanding if this
> design has nested factors or crossed factors.
>
> I would be very relieved to receive feedback with the matter in hand.
>
> Looking forward, and thank  you  a lot,
>
> Sincerely,
> Rabin
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kc000001 @end|ng |rom umn@edu  Tue Sep 10 10:39:45 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Tue, 10 Sep 2019 03:39:45 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CAENiVe--Gixxhk69W8A+8zcMrZM0Bu-UDE9=K43Gb3L0yKH4Qg@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <CAENiVe--Gixxhk69W8A+8zcMrZM0Bu-UDE9=K43Gb3L0yKH4Qg@mail.gmail.com>
Message-ID: <CANdRtHtVOKcDEC3uvSCMycdzJUry9MOT2OrfPAvMmw4Kw3GnOw@mail.gmail.com>

Thank you for your suggestion, Guillaume.

However, the model you suggest is overparameterized in my case. I don't
have enough observations to fit the maximal model.

Also regarding blocks as fixed, I would like to make block inferences in a
broad sense. Is there a particular reason that 4 levels are not enough to
be modeled as a random effect? Or is it due to the risk of getting
imprecise treatment estimates as mentioned in this topic below?

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003712.html

I look forward to hearing from you

Rabin

On Tue, Sep 10, 2019 at 1:51 AM Guillaume Adeux <guillaumesimon.a2 at gmail.com>
wrote:

> I agree with Peter Claussen.I am a weed ecologist and often deal with
> these experimental set-ups.
>
> The correct full intercept model ought to be:
> lmer(biomass~block+
> crop*tillage*cover+(1|block:crop)+(1|block:crop:tillage)+(1|block:crop:tillage:CC))
>
> Note that block is treated as fixed because 4 levels are not sufficient to
> estimate a random effect.
>
> Also note that (1|block:crop:tillage:CC) should only be introduced in the
> model if there is pseudoreplication at the elementary plot level, as is
> often done.
>
> For appropriate test of effects, look into the {monet} or {afex} package.
>
> For appropriate post-hoc multiple comparisons, look into the {emmeans}
> package.
>
> Cheers,
>
> GA2
>
> Le lun. 9 sept. 2019 ? 20:36, Rabin KC <kc000001 at umn.edu> a ?crit :
>
>> Hello R mixed models community,
>>
>> I am trying to fit a model for a split- split-plot design using lmer. I
>> know how to do this with aov and ssp.plot function in agricolae, but I
>> need
>> to use lmer in this case.
>>
>> I am interested in the response variable biomass of cover crops. I have
>> the
>> main plots as crops (corn and soybean). The subplot is tillage, which is
>> randomized within the crops and has 3 levels (conventional-till, no-till,
>> and strip-till). Within tillage(sub plot), 3 cover crop strategies are
>> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
>> treatments. The whole experiment is replicated 4 times, therefore, total
>> experimental units equal to 72 units.
>>
>> Data arranged in a csv file is attached in this email.
>>
>> Now the analysis part:
>>
>> I know how to do this using aov/ ssp.plot( agricolae). The code is as
>> follows:
>>
>> model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
>> Same thing with aov:
>>
>>
>> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>>
>> For my  analysis using lmer, and lme,  I have the following code:
>>
>> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>>
>> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>>
>> Now my confusion and questions are:
>> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
>> (block) as random. Is the random effect properly assigned for this design?
>>
>> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
>> give particular examples about it, but I have trouble understanding if
>> this
>> design has nested factors or crossed factors.
>>
>> I would be very relieved to receive feedback with the matter in hand.
>>
>> Looking forward, and thank  you  a lot,
>>
>> Sincerely,
>> Rabin
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Tue Sep 10 10:53:24 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Tue, 10 Sep 2019 10:53:24 +0200
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CANdRtHtVOKcDEC3uvSCMycdzJUry9MOT2OrfPAvMmw4Kw3GnOw@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <CAENiVe--Gixxhk69W8A+8zcMrZM0Bu-UDE9=K43Gb3L0yKH4Qg@mail.gmail.com>
 <CANdRtHtVOKcDEC3uvSCMycdzJUry9MOT2OrfPAvMmw4Kw3GnOw@mail.gmail.com>
Message-ID: <CAENiVe_GrSyZ-riwPA+fmqvC0dZgm-_KuiqyXOAhRhJHUZSBUA@mail.gmail.com>

OK, I will respond in a practical sense with my philosophy (I am not a
statistician), and will let others fill in on a more statistical note.

First of all, there is no real gain in considering block as random, it will
only "cost" you 3 df as fixed, which is not dramatical. Indeed, random
effects are modelled as variance and four points don't seem very reliable
to estimate a variance.

What do you mean by oveparameterized? If it is a singular fit, this just
implies that certain random effects are estimated as 0. I usually tend to
keep everything because I want my model to reflect my experimental set-up.
Note that removing the random effects which are estimated at 0 will not
change any of the fixed effect coefficients or SE. If the model does not
converge, I consider that as more problematic and selection of random
effects might be necessary (drop the one with the lowest variance).
If you overlooked my statement about (1|block:crop:tillage:CC) (i.e. you
introduced it in the model even though you don't have pseudoreplication),
then this might explain it also.

Don't farm naked, plant cover crops,

GA2



Le mar. 10 sept. 2019 ? 10:40, Rabin KC <kc000001 at umn.edu> a ?crit :

> Thank you for your suggestion, Guillaume.
>
> However, the model you suggest is overparameterized in my case. I don't
> have enough observations to fit the maximal model.
>
> Also regarding blocks as fixed, I would like to make block inferences in a
> broad sense. Is there a particular reason that 4 levels are not enough to
> be modeled as a random effect? Or is it due to the risk of getting
> imprecise treatment estimates as mentioned in this topic below?
>
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003712.html
>
> I look forward to hearing from you
>
> Rabin
>
> On Tue, Sep 10, 2019 at 1:51 AM Guillaume Adeux <
> guillaumesimon.a2 at gmail.com> wrote:
>
>> I agree with Peter Claussen.I am a weed ecologist and often deal with
>> these experimental set-ups.
>>
>> The correct full intercept model ought to be:
>> lmer(biomass~block+
>> crop*tillage*cover+(1|block:crop)+(1|block:crop:tillage)+(1|block:crop:tillage:CC))
>>
>> Note that block is treated as fixed because 4 levels are not sufficient
>> to estimate a random effect.
>>
>> Also note that (1|block:crop:tillage:CC) should only be introduced in the
>> model if there is pseudoreplication at the elementary plot level, as is
>> often done.
>>
>> For appropriate test of effects, look into the {monet} or {afex} package.
>>
>> For appropriate post-hoc multiple comparisons, look into the {emmeans}
>> package.
>>
>> Cheers,
>>
>> GA2
>>
>> Le lun. 9 sept. 2019 ? 20:36, Rabin KC <kc000001 at umn.edu> a ?crit :
>>
>>> Hello R mixed models community,
>>>
>>> I am trying to fit a model for a split- split-plot design using lmer. I
>>> know how to do this with aov and ssp.plot function in agricolae, but I
>>> need
>>> to use lmer in this case.
>>>
>>> I am interested in the response variable biomass of cover crops. I have
>>> the
>>> main plots as crops (corn and soybean). The subplot is tillage, which is
>>> randomized within the crops and has 3 levels (conventional-till, no-till,
>>> and strip-till). Within tillage(sub plot), 3 cover crop strategies are
>>> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
>>> treatments. The whole experiment is replicated 4 times, therefore, total
>>> experimental units equal to 72 units.
>>>
>>> Data arranged in a csv file is attached in this email.
>>>
>>> Now the analysis part:
>>>
>>> I know how to do this using aov/ ssp.plot( agricolae). The code is as
>>> follows:
>>>
>>> model<-with(data,ssp.plot(rep,crop,tillage,cover,biomass)).
>>> Same thing with aov:
>>>
>>>
>>> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>>>
>>> For my  analysis using lmer, and lme,  I have the following code:
>>>
>>> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>>>
>>> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>>>
>>> Now my confusion and questions are:
>>> 1. I have used crop, tillage, and cover as fixed effects. And only the
>>> rep
>>> (block) as random. Is the random effect properly assigned for this
>>> design?
>>>
>>> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
>>> give particular examples about it, but I have trouble understanding if
>>> this
>>> design has nested factors or crossed factors.
>>>
>>> I would be very relieved to receive feedback with the matter in hand.
>>>
>>> Looking forward, and thank  you  a lot,
>>>
>>> Sincerely,
>>> Rabin
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Sep 10 14:45:03 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 10 Sep 2019 14:45:03 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
Message-ID: <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>

Dear James,

Not centring year would require a much stronger random intercept. This
makes the model harder to fit. It will change the random intercept variance
and the correlation between random intercept and random slope. In theory it
shouldn't change the estimates for the fixed effects. But if your model is
unstable / doesn't converge, then how certain can you be on those estimates.

I don't know of any rule of thumb about the overlap in partially crosses
designs. If the model doesn't converge then see how you can simplify it.
E.g. if your model has county_id, then you could drop the state_id as the
county will model any effect at state level (if state level is not in the
model).

I wrote a blogpost on using the same variable both as fixed and as random
effect: https://www.muscardinus.be/2017/08/fixed-and-random/ One of the
examples uses year as a random intercept.

We've used the INLA package (r-inla.org) to model the gamma distribution.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 10 sep. 2019 om 08:51 schreef Ades, James <jades at ucsd.edu>:

> Thanks for the comment to center the year variable. I hadn?t thought about
> that, and I changed my model to incorporate a centered year. Just
> wondering?would I be right in saying that while centering the year might
> affect convergence, and the interpretation of the intercept as the average
> city in an average year, it wouldn?t affect the coefficient estimates?
>
> I have a model where education spending is averaged (when one city attends
> multiple school districts) to do away with district_id. That model does
> run. But you?re doubtful that the mixed-effect model could handle the
> crossed effects given the large overlap of district_id and city? Is there
> any rule of thumb for when a crossed effects model can be used vs when a
> variable must be averaged?or is it merely that if it converges then it
> converges?
>
> I use year as fixed-effect in my non-null model. Your other suggestion is
> to possibly add year as a random intercept. Wouldn?t these two choices
> ultimately be looking at different things?
>
> Thanks for the gamma suggestion. Are you suggesting using a gamma
> distribution in glmer? Does the gamma distribution in glmer default to the
> Erlang distribution? Would that still have to be as a rate rather than a
> discrete variable, and in that case, how would that vary from fitting the
> model in lmer with crime as a rate and getting rid of population as a fixed
> effect?
>
> Much thanks, Thierry et al.!
>
> James
>
>
> With regard to Douglas? question, I should?ve replied all, but here was my
> answer:
>
> Especially in the early ?00s crime was offered as two datasets?one on
> metropolitan/city areas with population > 10,000 and the other as
> population < 10,000. For 2004, the only data available is the dataset for
> cities > 10,000. I?ve contacted the FBI regarding whether they can track
> down the corresponding <10,000 dataset; they?re looking into it.
>
>
>
> On Sep 9, 2019, at 2:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear James,
>
> Since all ID's are unique, you can rely on the implicit nesting of random
> effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) +
> (1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).
>
> There is a huge overlap between PLACE_ID and full_district_id. The model
> will have a hard time separating both effects. Especially since you have
> the same random slope.
>
> You should also center the year variable. Now your model is estimating the
> random intercept at year 0.
>
> So in terms of basic model I would
>
> - drop either PLACE_ID or full_district_id
> - center year
> - add year to the fixed effects or add it as a separate random intercept
>
> Furthermore, I'm not sure it the Poisson distribution is the most relevant
> distribution for your response. I've seen a case were the Poisson
> distribution failed. The response was an area in hectares rounded to an
> integer value. The model fitted well with a Gamma distribution.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be/>
>
>
> Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu>:
>
>> Okay, sorry for the delay; I was waiting to hear back from a couple
>> people at the census regarding a question on school district info in the
>> dataset.
>>
>> I?ve  uploaded the dataset as a zip and an xs:
>>
>> https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
>>
>> https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing
>>
>> There is one important thing to note, here, which is that there is more
>> city overlap between counties than I thought. The easiest way to explain
>> this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID,
>> year), you should get 107,515; however, with distinct(PLACE_ID, year),
>> you?ll only get 99,832. So essentially, there are ~8000 times that a city
>> will overlap in two counties (this likely includes the same city repeating
>> this overlap every year?though it all depends on what years the city/town
>> police department reports crime to the FBI). I can figure out the
>> respective populations in each of the two counties where the city overlaps.
>> It?s a bit of leg work, but it is possible. Still, it seems that it would
>> not be principled to include the city/town in both counties because there
>> would be the assumption that the crime occurring in each corresponding
>> county is tied solely to population. Still, I left in all cities/towns
>> overlapping with two counties, in case you have some ideas about how a
>> mixed-model might be used to account for these (I don?t think a
>> crossed-effect structure would do it). So pretty much any city with
>> duplicate values where that value lies within the same county should be
>> counted (these are just separate school districts), but any city with
>> duplicate values where one of those values happens to be in another county,
>> yet the school district is still the same, shouldn't be counted; unless, of
>> course, there is a way for mixed-modeling in lme4 to account for that
>> (PLACE_ID will be the same, but COUNTY_ID will be different, but
>> full_district_id will be the same). Does that make sense? I'll soon send an
>> email to the group with more clarification.
>>
>> Use IDs vs names. I included names for reference, but city/towns might
>> not always be recorded exactly the same, so IDs are the safer bet.
>>
>> I have tried lmer?originally, my intention was to preserve counts of zero
>> crime (whether it?s weariness or sanity that has changed my view, the
>> difference between one and zero doesn?t seem so important anymore. I get
>> the boundary (singular) warning (if a warning is what it can be called). No
>> doubt there are many here that know more than me, but my understanding of
>> this message is that it mostly warns against overfitting. To me,
>> controlling for time through a fixed effect and as a random slope seems
>> warranted?different cities/towns have different rates of change in crime
>> from year to year.
>>
>> I still think fitting with glmer would be ideal, but I also lack an
>> understanding of the nuances on the backend with regard to how the two
>> functions differ. It seems that lmer is faster and more efficient in
>> modeling, though I?m not sure why?mathematically or programmatically?that?s
>> the case. If you can point me to an explanation, I?d appreciate that.
>>
>> Thanks much for your messages and your help.
>>
>> James
>>
>>
>> On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>> Dear James,
>>
>> Your mail contains only a part of the dput() output. Given the size of
>> your data, I suggest that you place it somewhere online and send us a link
>> to the data.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be/>
>>
>>
>> Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu>:
>>
>>> I posted my question at Stack Overflow, where it didn?t get much of a
>>> response, and I was pointed in this direction by Ben Bolker. I?m happy to
>>> send the whole dataset to anyone who wants but thought that it would be
>>> presumptuous to include an enormous dput() here.
>>>
>>> I?m looking at the effects of education spending per school district on
>>> crime rate (FBI crime data/UCR) within the cities and towns those school
>>> districts serve over a fifteen year period. The DV now has 203,410
>>> observations of city/town crime data over those fifteen years. (I use that
>>> figure with some reticence, because there are so many moving parts and
>>> things to account for, but having employed over 100 datasets and hours
>>> passing through the code again, I think that figure is correct.)
>>>
>>> Cities are technically crossed with school district, in that one city
>>> might attend multiple school districts. This means that one city could have
>>> multiple values for expenditure per student. School districts, however,
>>> also overlap with counties. As if things weren?t complicated enough, cities
>>> are mostly nested within county (though there are cities that exist in two
>>> counties, but it?s not often, and it?s usually by a small amount). Given
>>> that each city/town has a distinct PLACE_ID, my understanding is that this
>>> could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or
>>> (1|STATE/COUNTY_ID/PLACE_ID).
>>>
>>> I?m pretty familiar with mixed-effect models, and I?ve looked through
>>> clear and informative posts such as this one:
>>> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified.
>>> I believe things would remain sane to include school district
>>> (full_district_id) as another crossed effect, as below:
>>> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) +
>>> (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control
>>> = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
>>> total.years, na.action = "na.omit")
>>>
>>> Variables (not included in this model, to keep things null and simple)
>>> are centered and logged: pop per city, pop.dens per city, year,
>>> unemployment rate per county, proportion children living in poverty per
>>> school district, per capita income per county, difference in those who
>>> voted democrat in presidential elections per county, log enforcement per
>>> city/town, centered expenditure per student/ 1000 (per school district).
>>> PLACE_ID corresponds to cities and towns, COUNTY_ID to counties,
>>> full_district_id to school districts, and state.
>>>
>>> First, if I try to run the full model, using UCSD?s supercomputer, I get
>>> the error that the job was killed, presumably because it got to a point
>>> where it consumed too much ram (I think 125mb).
>>>
>>> I then tried to create a small subsection of data with arrange(STATE,
>>> COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through
>>> Delaware), so that I have 26,599 values. If I run this null model with the
>>> above code, I get the following error:
>>>
>>> ```
>>> Error in getOptfun(optimizer) :
>>>   optimizer function must use (at least) formal parameters ?fn?, ?par?,
>>> ?lower?, ?control?
>>> ```
>>>
>>> Then I tried with the optimx, with these configurations: control =
>>> glmerControl(optimizer = "optimx?,
>>> optCtrl = list(method = "nlminb?,
>>> maxit=10000,
>>> iter.max=10000,
>>> eval.max=10000,
>>> lower = c(0,0,0),
>>> upper = c(Inf,10,1)))
>>>
>>> and I received the following warning?since this is a null model, there
>>> aren?t any variables to really rescale.\
>>>
>>> ```
>>> Warning messages:
>>> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower =
>>> lower,  :
>>>   unrecognized control elements named ?lower?, ?upper? ignored
>>> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower =
>>> lower,  :
>>>   unrecognized control elements named ?lower?, ?upper? ignored
>>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>>> :
>>>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001,
>>> component 1)
>>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>>> :
>>>   Model is nearly unidentifiable: very large eigenvalue
>>>  - Rescale variables?
>>> ```
>>>
>>> I then tried more values (to 92,486, through Missouri). First, I tried
>>> the optimizer nloptr, and then I tried the optimix. I still received the
>>> same above errors.
>>>
>>> I?ve checked and rechecked everything, so I wanted to solicit advice,
>>> either for where I might be going wrong, or for what I could do to resolve
>>> these error messages.
>>>
>>> I?ve provided a brief snippet of the data below (randomly pulling a
>>> number of cities within counties of Arkansas, Arizona, and Alabama, as a
>>> dput.
>>>
>>> Thanks!
>>>
>>>
>>>
>>> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
>>> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
>>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>>> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
>>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>>> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
>>> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
>>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>>> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
>>> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
>>> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
>>> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
>>> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
>>> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
>>> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
>>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>>> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
>>> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
>>> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
>>> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
>>> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
>>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>>> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
>>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>>> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
>>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>>> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
>>> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
>>> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
>>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
>>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>>> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
>>> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
>>> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
>>> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
>>> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>>> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
>>> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
>>> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
>>> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
>>> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
>>> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
>>> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>>> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>>> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
>>> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
>>> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
>>> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
>>> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
>>> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
>>> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
>>> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
>>> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
>>> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
>>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>>> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
>>> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
>>> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
>>> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
>>> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
>>> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
>>> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
>>> ), COUNTY = c("autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "autauga county", "autauga county", "autauga county", "autauga county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>>> "baldwin county", "baldwin county", "baldwin county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "apache county",
>>> "apache county", "apache county", "apache county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "cochise county", "cochise county", "cochise county", "cochise county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "coconino county", "coconino
>>> county",
>>> "coconino county", "coconino county", "gila county", "gila county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "gila county", "gila county", "gila county", "gila
>>> county",
>>> "gila county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "graham county", "graham county", "graham county",
>>> "graham county", "greenlee county", "greenlee county", "greenlee county",
>>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>>> county",
>>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>>> county",
>>> "greenlee county", "greenlee county", "greenlee county", "greenlee
>>> county",
>>> "greenlee county", "greenlee county", "la paz county", "la paz county",
>>> "la paz county", "la paz county", "la paz county", "la paz county",
>>> "la paz county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "randolph county", "randolph county", "randolph county", "randolph
>>> county",
>>> "st. francis county", "st. francis county", "st. francis county",
>>> "st. francis county", "st. francis county", "st. francis county",
>>> "st. francis county", "st. francis county", "st. francis county",
>>> "st. francis county", "st. francis county", "st. francis county",
>>> "st. francis county", "st. francis county", "st. francis county",
>>> "st. francis county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county", "saline county", "saline county", "saline county",
>>> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
>>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>>> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>>> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
>>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>>> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>>> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>>> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>>> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>>> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
>>> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
>>> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
>>> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>>> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
>>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>>> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
>>> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
>>> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>>> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga
>>> County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Autauga County School District", "Autauga County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Baldwin County School District",
>>> "Baldwin County School District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "St. Johns Unified District",
>>> "St. Johns Unified District", "St. Johns Unified District", "St. Johns
>>> Unified District",
>>> "St. Johns Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Round Valley Unified District", "Round Valley Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Benson Unified School District", "St. David Unified District",
>>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>>> District",
>>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>>> District",
>>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
>>> District",
>>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
>>> District",
>>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
>>> District",
>>> "Douglas Unified District", "Douglas Unified District", "Tombstone
>>> Unified District",
>>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>>> Unified District",
>>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>>> Unified District",
>>> "Tombstone Unified District", "Tombstone Unified District", "Fort
>>> Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>>> "Sierra Vista Unified District", "Tombstone Unified District",
>>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
>>> Unified District",
>>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>>> District",
>>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>>> District",
>>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>>> District",
>>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
>>> District",
>>> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified
>>> District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Fredonia-Moccasin Unified District", "Page Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
>>> Unified District",
>>> "Flagstaff Unified District", "Flagstaff Unified District", "Williams
>>> Unified District",
>>> "Williams Unified District", "Williams Unified District", "Williams
>>> Unified District",
>>> "Williams Unified District", "Williams Unified District", "Williams
>>> Unified District",
>>> "Williams Unified District", "Williams Unified District", "Williams
>>> Unified District",
>>> "Williams Unified District", "Globe Unified District", "Miami Unified
>>> District",
>>> "Globe Unified District", "Miami Unified District", "Globe Unified
>>> District",
>>> "Miami Unified District", "Globe Unified District", "Miami Unified
>>> District",
>>> "Globe Unified District", "Miami Unified District", "Globe Unified
>>> District",
>>> "Miami Unified District", "Globe Unified District", "Miami Unified
>>> District",
>>> "Globe Unified District", "Miami Unified District", "Globe Unified
>>> District",
>>> "Miami Unified District", "Globe Unified District", "Miami Unified
>>> District",
>>> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman
>>> Unified District",
>>> "Miami Unified District", "Miami Unified District", "Miami Unified
>>> District",
>>> "Miami Unified District", "Miami Unified District", "Miami Unified
>>> District",
>>> "Miami Unified District", "Miami Unified District", "Miami Unified
>>> District",
>>> "Miami Unified District", "Miami Unified District", "Miami Unified
>>> District",
>>> "Miami Unified District", "Payson Unified District", "Payson Unified
>>> District",
>>> "Payson Unified District", "Payson Unified District", "Payson Unified
>>> District",
>>> "Payson Unified District", "Payson Unified District", "Payson Unified
>>> District",
>>> "Payson Unified District", "Payson Unified District", "Payson Unified
>>> District",
>>> "Payson Unified District", "Pima Unified District", "Pima Unified
>>> District",
>>> "Pima Unified District", "Pima Unified District", "Pima Unified
>>> District",
>>> "Pima Unified District", "Pima Unified District", "Pima Unified
>>> District",
>>> "Pima Unified District", "Pima Unified District", "Pima Unified
>>> District",
>>> "Pima Unified District", "Safford Unified District", "Thatcher Unified
>>> District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>>> Unified District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>>> Unified District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>>> Unified District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>>> Unified District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Safford Unified District", "Thatcher
>>> Unified District",
>>> "Safford Unified District", "Thatcher Unified District", "Safford
>>> Unified District",
>>> "Thatcher Unified District", "Clifton Unified District", "Morenci
>>> Unified District",
>>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
>>> District",
>>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
>>> District",
>>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
>>> District",
>>> "Morenci Unified District", "Morenci Unified District", "Clifton Unified
>>> District",
>>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
>>> District",
>>> "Parker Unified School District", "Parker Unified School District",
>>> "Parker Unified School District", "Parker Unified School District",
>>> "Parker Unified School District", "Parker Unified School District",
>>> "Parker Unified School District", "Little Rock School District",
>>> "Little Rock School District", "Little Rock School District",
>>> "Little Rock School District", "Little Rock School District",
>>> "Little Rock School District", "Little Rock School District",
>>> "Little Rock School District", "Little Rock School District",
>>> "Little Rock School District", "Little Rock School District",
>>> "Little Rock School District", "Pulaski County Special School District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Little Rock School District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "North Little Rock School District", "Pulaski County Special School
>>> District",
>>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>>> Schools",
>>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>>> Schools",
>>> "Corning Public Schools", "Corning Public Schools", "Corning Public
>>> Schools",
>>> "Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring
>>> Schools",
>>> "Mammoth Spring Schools", "Greene County Technical School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Greene County Technical School District", "Greene County Technical
>>> School District",
>>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>>> School District",
>>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>>> School District",
>>> "Pocahontas School District", "Pocahontas School District", "Pocahontas
>>> School District",
>>> "Pocahontas School District", "Sloan-Hendrix School District",
>>> "Sloan-Hendrix School District", "Sloan-Hendrix School District",
>>> "Sloan-Hendrix School District", "Forrest City School District",
>>> "Forrest City School District", "Forrest City School District",
>>> "Forrest City School District", "Forrest City School District",
>>> "Forrest City School District", "Forrest City School District",
>>> "Forrest City School District", "Forrest City School District",
>>> "Forrest City School District", "West Memphis School District",
>>> "West Memphis School District", "West Memphis School District",
>>> "West Memphis School District", "West Memphis School District",
>>> "West Memphis School District", "Bryant Public Schools", "Bryant Public
>>> Schools",
>>> "Bauxite School District", "Benton School District", "Bryant Public
>>> Schools",
>>> "Harmony Grove School District", "Bauxite School District", "Benton
>>> School District",
>>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite
>>> School District",
>>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>>> District",
>>> "Bauxite School District", "Benton School District", "Bryant Public
>>> Schools",
>>> "Harmony Grove School District", "Bauxite School District", "Benton
>>> School District",
>>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite
>>> School District",
>>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>>> District",
>>> "Bauxite School District", "Benton School District", "Bryant Public
>>> Schools",
>>> "Harmony Grove School District", "Bauxite School District", "Benton
>>> School District",
>>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite
>>> School District",
>>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>>> District",
>>> "Bauxite School District", "Benton School District", "Bryant Public
>>> Schools",
>>> "Harmony Grove School District", "Bauxite School District", "Benton
>>> School District",
>>> "Bryant Public Schools", "Harmony Grove School District", "Bauxite
>>> School District",
>>> "Benton School District", "Bryant Public Schools", "Harmony Grove School
>>> District",
>>> "Bauxite School District", "Benton School District", "Bryant Public
>>> Schools",
>>> "Harmony Grove School District", "Bryant Public Schools", "Bryant Public
>>> Schools",
>>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public
>>> Schools",
>>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public
>>> Schools",
>>> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public
>>> Schools",
>>> "Fountain Lake School District", "Fountain Lake School District",
>>> "Fountain Lake School District", "Fountain Lake School District",
>>> "Fountain Lake School District", "Fountain Lake School District",
>>> "Fountain Lake School District", "Fountain Lake School District",
>>> "Fountain Lake School District", "Fountain Lake School District",
>>> "Fountain Lake School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Bryant Public Schools", "Pulaski County Special School District",
>>> "Bryant Public Schools", "Pulaski County Special School District",
>>> "Bryant Public Schools", "Pulaski County Special School District",
>>> "Bryant Public Schools", "Pulaski County Special School District",
>>> "Sheridan School District", "Sheridan School District", "Sheridan School
>>> District",
>>> "Sheridan School District", "Sheridan School District", "Sheridan School
>>> District",
>>> "Sheridan School District", "Sheridan School District", "Sheridan School
>>> District",
>>> "Sheridan School District", "Sheridan School District", "Sheridan School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District", "Pulaski County Special School
>>> District",
>>> "Pulaski County Special School District"), EXPENDITURE_PER_STUDENT =
>>> c(5.2927293064877,
>>> 5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
>>> 7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
>>> 7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
>>> 7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
>>> 5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
>>> 7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
>>> 7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
>>> 7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
>>> 9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
>>> 8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
>>> 6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
>>> 9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
>>> 8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
>>> 8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
>>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>>> 8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
>>> 6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
>>> 9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>>> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>>> 6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
>>> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
>>> 8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
>>> 8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
>>> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>>> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>>> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
>>> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
>>> 9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
>>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
>>> 8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
>>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>>> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
>>> 8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
>>> 7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
>>> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
>>> 8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
>>> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
>>> 8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
>>> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
>>> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
>>> 8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
>>> 9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
>>> 8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
>>> 8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
>>> 8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
>>> 7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
>>> 6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
>>> 9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
>>> 6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
>>> 7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
>>> 8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
>>> 9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
>>> 8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
>>> 7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
>>> 9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
>>> 6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
>>> 7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
>>> 7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
>>> 7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
>>> 4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
>>> 5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
>>> 6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
>>> 10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
>>> 6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
>>> 7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
>>> 8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
>>> 7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
>>> 7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
>>> 7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
>>> 6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
>>> 8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
>>> 7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
>>> 8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
>>> 7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
>>> 8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
>>> 9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
>>> 8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
>>> 8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
>>> 7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
>>> 9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
>>> 10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
>>> 7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
>>> 8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
>>> 7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
>>> 11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
>>> 9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
>>> 5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
>>> 6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
>>> 7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
>>> 5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
>>> 6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
>>> 7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
>>> 7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
>>> 7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
>>> 7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
>>> 5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
>>> 7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
>>> 7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
>>> 5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
>>> 7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
>>> 6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
>>> 4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
>>> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
>>> 4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
>>> 5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
>>> 6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
>>> 6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
>>> 6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
>>> 6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
>>> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
>>> 7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
>>> 10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
>>> 9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
>>> 6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
>>> 6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
>>> 8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
>>> 12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
>>> 10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
>>> 12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
>>> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
>>> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
>>> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
>>> 9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
>>> 10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
>>> 10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
>>> 12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
>>> 12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
>>> 12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
>>> 12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
>>> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
>>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>>> 10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
>>> 8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
>>> 8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
>>> 9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
>>> 10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
>>> 9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
>>> 10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
>>> 11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
>>> 11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
>>> 8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
>>> 9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
>>> 10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
>>> 10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
>>> 10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
>>> 10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
>>> 8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
>>> 9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
>>> 9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
>>> 6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
>>> 7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
>>> 8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
>>> 8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
>>> 7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
>>> 8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
>>> 7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
>>> 8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
>>> 10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
>>> 10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
>>> 9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
>>> 8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
>>> 7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
>>> 7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
>>> 7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
>>> 7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
>>> 7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
>>> 7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
>>> 7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
>>> 8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
>>> 8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
>>> 8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
>>> 8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
>>> 8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
>>> 8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
>>> 7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
>>> 7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
>>> 6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
>>> 8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
>>> 11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
>>> 8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
>>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>>> 10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
>>> 8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
>>> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
>>> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
>>> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
>>> 9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
>>> 9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
>>> 11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
>>> 9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
>>> 10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
>>> 10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
>>> 7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
>>> 8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
>>> 6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
>>> 8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
>>> 7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
>>> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
>>> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
>>> 10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
>>> -800L), class = c("tbl_df", "tbl", "data.frame"))
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From @|te@@ed@c2 @end|ng |rom gm@||@com  Tue Sep 10 17:56:43 2019
From: @|te@@ed@c2 @end|ng |rom gm@||@com (C. AMAL D. GLELE)
Date: Tue, 10 Sep 2019 15:56:43 +0000
Subject: [R-sig-ME] within_and_between_group_variance
Message-ID: <CANrzCv0p5ddWVdPU0ofwyioDQbc5D=aLhdj077EaCTAjWj154g@mail.gmail.com>

Hello, dear all.
Can somebody,  please, tell me:
among the outputs of a glmm and/or glm, what are:
1) within group variance and it's utility
2) between group variance and it's utility
In advance, many thanks.
Best regards,

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 10 18:01:35 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 10 Sep 2019 12:01:35 -0400
Subject: [R-sig-ME] within_and_between_group_variance
In-Reply-To: <CANrzCv0p5ddWVdPU0ofwyioDQbc5D=aLhdj077EaCTAjWj154g@mail.gmail.com>
References: <CANrzCv0p5ddWVdPU0ofwyioDQbc5D=aLhdj077EaCTAjWj154g@mail.gmail.com>
Message-ID: <CABghstTr7VFohuvMy22Tomxs0u38yNgjaC8cjFw61gC1CV9aHQ@mail.gmail.com>

  Can we have a little more context for the question please? Utility
for what purpose?

  GLMs (generalized linear models) don't have grouping structure at
all, so the terms "within-group" and "between-group" don't really
apply.

  (G)LMMs summarize "among-group variance" as the variances of the
random effects. "Within-group variance" is the residual variance for a
linear mixed model (LMM, i.e. a GLMM with Gaussian response and
identity link), harder to compute for non-LMM GLMMs (but papers e.g.
by Nakagawa and Schielzeth define these components on the way to
estimating R^2 or intra-class correlation values for GLMMs).

On Tue, Sep 10, 2019 at 11:57 AM C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hello, dear all.
> Can somebody,  please, tell me:
> among the outputs of a glmm and/or glm, what are:
> 1) within group variance and it's utility
> 2) between group variance and it's utility
> In advance, many thanks.
> Best regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|te@@ed@c2 @end|ng |rom gm@||@com  Tue Sep 10 18:28:18 2019
From: @|te@@ed@c2 @end|ng |rom gm@||@com (C. AMAL D. GLELE)
Date: Tue, 10 Sep 2019 16:28:18 +0000
Subject: [R-sig-ME] within_and_between_group_variance
In-Reply-To: <CABghstTr7VFohuvMy22Tomxs0u38yNgjaC8cjFw61gC1CV9aHQ@mail.gmail.com>
References: <CANrzCv0p5ddWVdPU0ofwyioDQbc5D=aLhdj077EaCTAjWj154g@mail.gmail.com>
 <CABghstTr7VFohuvMy22Tomxs0u38yNgjaC8cjFw61gC1CV9aHQ@mail.gmail.com>
Message-ID: <CANrzCv0F7i-gGgd0UNYT4wH9DHJX5fbPSgAazjD04099MdOhaQ@mail.gmail.com>

Thank you so much for your reply.
My question is not about a specific context;
about these terms, I've read somethings that were not clear for me ; so
that, I decide to request the help of the list to know more about them.
Thanks, again.
Best,



Le mar. 10 sept. 2019 ? 16:01, Ben Bolker <bbolker at gmail.com> a ?crit :

>   Can we have a little more context for the question please? Utility
> for what purpose?
>
>   GLMs (generalized linear models) don't have grouping structure at
> all, so the terms "within-group" and "between-group" don't really
> apply.
>
>   (G)LMMs summarize "among-group variance" as the variances of the
> random effects. "Within-group variance" is the residual variance for a
> linear mixed model (LMM, i.e. a GLMM with Gaussian response and
> identity link), harder to compute for non-LMM GLMMs (but papers e.g.
> by Nakagawa and Schielzeth define these components on the way to
> estimating R^2 or intra-class correlation values for GLMMs).
>
> On Tue, Sep 10, 2019 at 11:57 AM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> >
> > Hello, dear all.
> > Can somebody,  please, tell me:
> > among the outputs of a glmm and/or glm, what are:
> > 1) within group variance and it's utility
> > 2) between group variance and it's utility
> > In advance, many thanks.
> > Best regards,
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From krzb@r @end|ng |rom protonm@||@ch  Wed Sep 11 16:02:28 2019
From: krzb@r @end|ng |rom protonm@||@ch (Krzysztof Bartoszek)
Date: Wed, 11 Sep 2019 14:02:28 +0000
Subject: [R-sig-ME] Measurement error for mixed models
Message-ID: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>

Dear all,
As far as I managed to see the weights parameter in nlme::lme(), mgcv::gamm(), gamm4::gamm4(), can be used to pass some specific residual variance structure based on nlme's varFunc class. I was wondering if the following variance structure is possible to be obtained from the already implemented instances in varClasses, or I will need to code it myself.

I want the variance of the response for observation i to be of the form v_i^2 = s^2 + s_i^2, where s^2 is a common for all observations unknown variability and s_i^2 is known, individual specific measurement error variance (can be 0).

Thank you
Best wishes
Krzysztof Bartoszek

Sent with ProtonMail Secure Email.
	[[alternative HTML version deleted]]


From HDor@n @end|ng |rom @|r@org  Wed Sep 11 16:46:10 2019
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Wed, 11 Sep 2019 14:46:10 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
Message-ID: <BL0PR05MB4818464156BA00CF610AD21BCAB10@BL0PR05MB4818.namprd05.prod.outlook.com>

This error-in-variables approach is not available in lme. I do have an R-based implementation of this for models with random intercepts. You can find this implementation at:

https://shiny.airast.org/METRICS/

And a complete tutorial is under the Help tab.

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Krzysztof Bartoszek via R-sig-mixed-models
Sent: Wednesday, September 11, 2019 10:02 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Measurement error for mixed models

Dear all,
As far as I managed to see the weights parameter in nlme::lme(), mgcv::gamm(), gamm4::gamm4(), can be used to pass some specific residual variance structure based on nlme's varFunc class. I was wondering if the following variance structure is possible to be obtained from the already implemented instances in varClasses, or I will need to code it myself.

I want the variance of the response for observation i to be of the form v_i^2 = s^2 + s_i^2, where s^2 is a common for all observations unknown variability and s_i^2 is known, individual specific measurement error variance (can be 0).

Thank you
Best wishes
Krzysztof Bartoszek

Sent with ProtonMail Secure Email.
	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From z||@t@erv @end|ng |rom gm@||@com  Wed Sep 11 17:33:06 2019
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Wed, 11 Sep 2019 11:33:06 -0400
Subject: [R-sig-ME] Change mer@call text?
Message-ID: <FABC2502-DFC9-4906-B973-31A713C450C5@gmail.com>

For convenience, I am running separate mixed-effects regressions on variables in a data frame.

In a loop, I issue the following:

	merList[[merSpec$LHS[k]]] = lmerTest::lmer(as.formula(merForm), data=dat, ...)

where merList contains a list of results, merSpec$LHS contains the outcome variable name, and merForm contains the formula for a specific mixed-effects regression.

This works well and provides a convenient way to do bulk analyses (regardless of the dubiety of doing so).

A problem arises in identifying the output because the call slot (@call) in the S4 structure becomes "lmerTest::lmer(as.formula(merForm), data=dat, ...)"

How can I change the output to identify the actual formula used in analysis so it appears in the summary and elsewhere?

Thanks,

From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Sep 11 19:12:16 2019
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 11 Sep 2019 17:12:16 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
Message-ID: <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>

Hi Krzysztof,

This can be done with lme(). Let si2 denote the known variance of observation i. With varFixed(), you can specify that the error variances are known up to a proportionality constant, sigma^2. With lmeControl(sigma=1), you can fix that proportionality constant to 1, so the error variances are equal to s2i. Then add random effects for each row of the dataset. That will be your s^2. So, putting this all together:

dat$id <- 1:nrow(dat)
lme(yi ~ x1 + ..., random = ~ 1 | id, 
    weights = varFixed(~ si2), 
    control = lmeControl(sigma = 1), 
    data = dat)

Interestingly, this is identical to what is done in meta-analysis in the 'random-effects model', where we have known sampling variances for the outcomes and we add a random effect for each row (i.e., study) to the model. You might find this of interest:

http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer

But also read the note at the end -- there is (was?) some issue with lme() when fixing sigma to a constant. Not sure if this has been fixed in the meantime.

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Krzysztof Bartoszek via R-sig-mixed-models
Sent: Wednesday, 11 September, 2019 16:02
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Measurement error for mixed models

Dear all,
As far as I managed to see the weights parameter in nlme::lme(), mgcv::gamm(), gamm4::gamm4(), can be used to pass some specific residual variance structure based on nlme's varFunc class. I was wondering if the following variance structure is possible to be obtained from the already implemented instances in varClasses, or I will need to code it myself.

I want the variance of the response for observation i to be of the form v_i^2 = s^2 + s_i^2, where s^2 is a common for all observations unknown variability and s_i^2 is known, individual specific measurement error variance (can be 0).

Thank you
Best wishes
Krzysztof Bartoszek


From cperk @end|ng |rom terpm@||@umd@edu  Thu Sep 12 20:54:18 2019
From: cperk @end|ng |rom terpm@||@umd@edu (Carrie Perkins)
Date: Thu, 12 Sep 2019 14:54:18 -0400
Subject: [R-sig-ME] Model failed to converge
Message-ID: <CAPtr_T7E2WL=J_P=GHweFfHXS6Bj6VO0zirS_90ah1DQRqY+Lw@mail.gmail.com>

Hi Everyone,

I would like to run a mixed effects model in lmer using data from a
salinity tolerance experiment. The experiment had 4 salinity treatments,
and 3 replicates of 48 plant genotypes were planted in each treatment. This
resulted in a total of 144 individuals per treatment, amounting to a grand
total of 576 individuals in the whole experiment.

I tried to run the following model in R:

lmer_model <- lmer(Y~Treatment+(Treatment|Genotype),data=dataframe)

In the formula above, Y refers to the response variable (in this case leaf
length). Treatment refers to the 4 salinity treatments and Genotype refers
to the 48 genotypes represented in the experiment.

However, this model failed to converge. At first I was worried that I do
not have enough degrees of freedom available.

However, when I calculated degrees of freedom it seemed like this must not
be the problem:

Treatment (fixed effect) degrees of freedom: 4 - 1 = 3

Random effects degrees of freedom:
According to Dr. Bolker's FAQ (
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
)

"each random term in the model with q components counts for q(q+1)/2
parameters ? for example, a term of the form (slope|group) has 3 parameters
(intercept variance, slope variance, correlation between intercept and
slope)".

Per the statement above, I multiplied 3 X 48 Genotypes = 144 df

This amounts to 3 + 144 = 147 degrees of freedom taken up by the
explanatory variables

Since I had 576 individuals in the experiment, I should have 429 error
degrees of freedom left to play with (576 - 147).

Please let me know if I am mistaken in how I calculated the degrees of
freedom, because I find it very confusing to try to calculate degrees of
freedom of the random effects.

Any assistance in figuring out why the model failed to converge would also
be great!

Best,
Carrie

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Sep 12 22:36:53 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 12 Sep 2019 16:36:53 -0400
Subject: [R-sig-ME] Model failed to converge
In-Reply-To: <CAPtr_T7E2WL=J_P=GHweFfHXS6Bj6VO0zirS_90ah1DQRqY+Lw@mail.gmail.com>
References: <CAPtr_T7E2WL=J_P=GHweFfHXS6Bj6VO0zirS_90ah1DQRqY+Lw@mail.gmail.com>
Message-ID: <15c51b62-313d-b4ce-0295-3fe2baf605b6@gmail.com>


  I don't think the degrees of freedom per se is the problem.  At the
genotype level, you are trying to estimate (4*5)/2=10 parameters from 48
genotypes, which seems ambitious although not impossible (a general rule
of thumb is that you want (at least) about 10x as many observations as
parameters at any given level).  However, this is more of an issue for
singularity (see `?lme4::isSingular`) that for convergence warnings
(`?lme4::convergence`, `?lme4::troubleshooting`, `?lme4::allFit`).

 Simplifying the model to

Y~Treatment+(1|Genotype/Treatment)

(i.e., assuming compound symmetry among treatments) might be worth a try.

  Ben Bolker

On 2019-09-12 2:54 p.m., Carrie Perkins wrote:
> Hi Everyone,
> 
> I would like to run a mixed effects model in lmer using data from a
> salinity tolerance experiment. The experiment had 4 salinity treatments,
> and 3 replicates of 48 plant genotypes were planted in each treatment. This
> resulted in a total of 144 individuals per treatment, amounting to a grand
> total of 576 individuals in the whole experiment.
> 
> I tried to run the following model in R:
> 
> lmer_model <- lmer(Y~Treatment+(Treatment|Genotype),data=dataframe)
> 
> In the formula above, Y refers to the response variable (in this case leaf
> length). Treatment refers to the 4 salinity treatments and Genotype refers
> to the 48 genotypes represented in the experiment.
> 
> However, this model failed to converge. At first I was worried that I do
> not have enough degrees of freedom available.
> 
> However, when I calculated degrees of freedom it seemed like this must not
> be the problem:
> 
> Treatment (fixed effect) degrees of freedom: 4 - 1 = 3
> 
> Random effects degrees of freedom:
> According to Dr. Bolker's FAQ (
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
> )
> 
> "each random term in the model with q components counts for q(q+1)/2
> parameters ? for example, a term of the form (slope|group) has 3 parameters
> (intercept variance, slope variance, correlation between intercept and
> slope)".
> 
> Per the statement above, I multiplied 3 X 48 Genotypes = 144 df
> 
> This amounts to 3 + 144 = 147 degrees of freedom taken up by the
> explanatory variables
> 
> Since I had 576 individuals in the experiment, I should have 429 error
> degrees of freedom left to play with (576 - 147).
> 
> Please let me know if I am mistaken in how I calculated the degrees of
> freedom, because I find it very confusing to try to calculate degrees of
> freedom of the random effects.
> 
> Any assistance in figuring out why the model failed to converge would also
> be great!
> 
> Best,
> Carrie
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From krzb@r @end|ng |rom protonm@||@ch  Thu Sep 12 22:45:34 2019
From: krzb@r @end|ng |rom protonm@||@ch (Krzysztof Bartoszek)
Date: Thu, 12 Sep 2019 20:45:34 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
 <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
Message-ID: <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>

Hello!
Thank you Wolfgang, it was really helpful.
It seems that the issue with sigma fixed in nlme::lme() still persists. With nlme_3.1-141 I reran the code by Maciej Beresewicz from https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16975 and obtain the same output of nlme::lme() as he did. Hence, I am using method="ML" as suggested on https://www.jepusto.com/bug-in-nlme-with-fixed-sigma/

However, interestingly one cannot have 0 measurement error for some observations.

library(nlme)
library(mgcv)
library(gamm4)
df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
df_Dummy$id<-as.factor(1:nrow(df_Dummy))
df_Dummy$merror<-rexp(10)
colnames(df_Dummy)[1:2]<-c("x","y")
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML") ## works fine
mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML") ## works fine

df_Dummy$merror[1:4]<-0
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML")
## produces:
## Error in MEestimate(lmeSt, grps) :
##   NA/NaN/Inf in foreign function call (arg 1)
## In addition: Warning messages:
## 1: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 2: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 3: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 4: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation

mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML")
## produces:
## Error in MEestimate(lmeSt, grps) :
##  NA/NaN/Inf in foreign function call (arg 1)
## In addition: Warning messages:
## 1: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 2: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 3: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 4: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation

df_Dummy$merror<-df_Dummy$merror+0.000000001
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML") ## works fine again
mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML") ## works fine again

Also, unfortunately the same mechanism cannot be used in gamm4::gamm4(), if I am not missing something.

gamm4::gamm4(y~x,random= ~(1|id), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian,methof="ML")
## produces:
## Error in model.frame.default(formula = y ~ x, data = df_Dummy, weights = varFixed(~merror),  :
##  variable lengths differ (found for '(weights)')

Best wishes
Krzysztof

??????? Original Message ???????
On Wednesday, September 11, 2019 7:12 PM, Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

&gt; Hi Krzysztof,
&gt;
&gt; This can be done with lme(). Let si2 denote the known variance of observation i. With varFixed(), you can specify that the error variances are known up to a proportionality constant, sigma^2. With lmeControl(sigma=1), you can fix that proportionality constant to 1, so the error variances are equal to s2i. Then add random effects for each row of the dataset. That will be your s^2. So, putting this all together:
&gt;
&gt; dat$id &lt;- 1:nrow(dat)
&gt; lme(yi ~ x1 + ..., random = ~ 1 | id,
&gt; weights = varFixed(~ si2),
&gt; control = lmeControl(sigma = 1),
&gt; data = dat)
&gt;
&gt; Interestingly, this is identical to what is done in meta-analysis in the 'random-effects model', where we have known sampling variances for the outcomes and we add a random effect for each row (i.e., study) to the model. You might find this of interest:
&gt;
&gt; http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
&gt;
&gt; But also read the note at the end -- there is (was?) some issue with lme() when fixing sigma to a constant. Not sure if this has been fixed in the meantime.
&gt;
&gt; Best,
&gt; Wolfgang
&gt;
&gt; -----Original Message-----
&gt; From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Krzysztof Bartoszek via R-sig-mixed-models
&gt; Sent: Wednesday, 11 September, 2019 16:02
&gt; To: r-sig-mixed-models at r-project.org
&gt; Subject: [R-sig-ME] Measurement error for mixed models
&gt;
&gt; Dear all,
&gt; As far as I managed to see the weights parameter in nlme::lme(), mgcv::gamm(), gamm4::gamm4(), can be used to pass some specific residual variance structure based on nlme's varFunc class. I was wondering if the following variance structure is possible to be obtained from the already implemented instances in varClasses, or I will need to code it myself.
&gt;
&gt; I want the variance of the response for observation i to be of the form v_i^2 = s^2 + s_i^2, where s^2 is a common for all observations unknown variability and s_i^2 is known, individual specific measurement error variance (can be 0).
&gt;
&gt; Thank you
&gt; Best wishes
&gt; Krzysztof Bartoszek

</wolfgang.viechtbauer at maastrichtuniversity.nl>


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Thu Sep 12 23:04:00 2019
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Thu, 12 Sep 2019 21:04:00 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
 <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
 <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>
Message-ID: <92656866c17f4f358275a4e222c74d76@UM-MAIL3214.unimaas.nl>

Thanks for the feedback.

For what it's worth, you can fit the model with those 0 variances with metafor:

df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
df_Dummy$id<-as.factor(1:nrow(df_Dummy))
df_Dummy$merror<-rexp(10)
colnames(df_Dummy)[1:2]<-c("x","y")
df_Dummy$merror[1:4]<-0

library(metafor)
rma(y ~ x, merror, data=df_Dummy, method="ML")

This will work as long as the variance component is larger than 0.

Best,
Wolfgang

-----Original Message-----
From: Krzysztof Bartoszek [mailto:krzbar at protonmail.ch] 
Sent: Thursday, 12 September, 2019 22:46
To: Viechtbauer, Wolfgang (SP)
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Measurement error for mixed models

Hello!
Thank you Wolfgang, it was really helpful.
It seems that the issue with sigma fixed in nlme::lme() still persists. With nlme_3.1-141 I reran the code by Maciej Beresewicz from https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16975 and obtain the same output of nlme::lme() as he did. Hence, I am using method="ML" as suggested on https://www.jepusto.com/bug-in-nlme-with-fixed-sigma/

However, interestingly one cannot have 0 measurement error for some observations.

library(nlme)
library(mgcv)
library(gamm4)
df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
df_Dummy$id<-as.factor(1:nrow(df_Dummy))
df_Dummy$merror<-rexp(10)
colnames(df_Dummy)[1:2]<-c("x","y")
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML") ## works fine
mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML") ## works fine

df_Dummy$merror[1:4]<-0
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML")
## produces:
## Error in MEestimate(lmeSt, grps) :
##   NA/NaN/Inf in foreign function call (arg 1)
## In addition: Warning messages:
## 1: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 2: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 3: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation
## 4: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##   NA/NaN function evaluation

mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML")
## produces:
## Error in MEestimate(lmeSt, grps) :
##  NA/NaN/Inf in foreign function call (arg 1)
## In addition: Warning messages:
## 1: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 2: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 3: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation
## 4: In nlminb(c(oldPars), function(lmePars) -logLik(lmeSt, lmePars),  :
##  NA/NaN function evaluation

df_Dummy$merror<-df_Dummy$merror+0.000000001
nlme::lme(y~x,random=~1|id, weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, method="ML") ## works fine again
mgcv::gamm(y~x,random= list(id=~1), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian, method="ML") ## works fine again

Also, unfortunately the same mechanism cannot be used in gamm4::gamm4(), if I am not missing something.

gamm4::gamm4(y~x,random= ~(1|id), weights=varFixed(~merror), control=lmeControl(sigma=1), data=df_Dummy, family=gaussian,methof="ML")
## produces:
## Error in model.frame.default(formula = y ~ x, data = df_Dummy, weights = varFixed(~merror),  :
##  variable lengths differ (found for '(weights)')

Best wishes
Krzysztof

??????? Original Message ???????
On Wednesday, September 11, 2019 7:12 PM, Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

&gt; Hi Krzysztof,
&gt;
&gt; This can be done with lme(). Let si2 denote the known variance of observation i. With varFixed(), you can specify that the error variances are known up to a proportionality constant, sigma^2. With lmeControl(sigma=1), you can fix that proportionality constant to 1, so the error variances are equal to s2i. Then add random effects for each row of the dataset. That will be your s^2. So, putting this all together:
&gt;
&gt; dat$id &lt;- 1:nrow(dat)
&gt; lme(yi ~ x1 + ..., random = ~ 1 | id,
&gt; weights = varFixed(~ si2),
&gt; control = lmeControl(sigma = 1),
&gt; data = dat)
&gt;
&gt; Interestingly, this is identical to what is done in meta-analysis in the 'random-effects model', where we have known sampling variances for the outcomes and we add a random effect for each row (i.e., study) to the model. You might find this of interest:
&gt;
&gt; http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer
&gt;
&gt; But also read the note at the end -- there is (was?) some issue with lme() when fixing sigma to a constant. Not sure if this has been fixed in the meantime.
&gt;
&gt; Best,
&gt; Wolfgang
&gt;
&gt; -----Original Message-----
&gt; From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Krzysztof Bartoszek via R-sig-mixed-models
&gt; Sent: Wednesday, 11 September, 2019 16:02
&gt; To: r-sig-mixed-models at r-project.org
&gt; Subject: [R-sig-ME] Measurement error for mixed models
&gt;
&gt; Dear all,
&gt; As far as I managed to see the weights parameter in nlme::lme(), mgcv::gamm(), gamm4::gamm4(), can be used to pass some specific residual variance structure based on nlme's varFunc class. I was wondering if the following variance structure is possible to be obtained from the already implemented instances in varClasses, or I will need to code it myself.
&gt;
&gt; I want the variance of the response for observation i to be of the form v_i^2 = s^2 + s_i^2, where s^2 is a common for all observations unknown variability and s_i^2 is known, individual specific measurement error variance (can be 0).
&gt;
&gt; Thank you
&gt; Best wishes
&gt; Krzysztof Bartoszek

From kc000001 @end|ng |rom umn@edu  Fri Sep 13 05:48:19 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Thu, 12 Sep 2019 22:48:19 -0500
Subject: [R-sig-ME] Can we analyse combined split plot experiment using
 lmer()?
Message-ID: <CANdRtHuW8TvO+ojspfn3bPdBYGMfeKvLQk-PiE3fu2OA-A4__A@mail.gmail.com>

Hello community,

A few days ago, I posted about using lmer() to analyze a split split-plot
design.
The research design is as such:

I am interested in the response variable biomass of cover crops. I have the
main plots as crops (corn and soybean). The subplot is tillage, which is
randomized within the crops and has 3 levels (conventional-till, no-till,
and strip-till). Within tillage(subplot), 3 cover crop strategies are
randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
treatments. The whole experiment is replicated 4 times, therefore, total
experimental units equal to 72 units.

The experiment is conducted in 2 locations for 2 years, therefore total
units equal to 288.

Now the model (as suggested by Peter Claussen in our community) for the
experiment conducted each year and location is :

model <- lmer (biomass ~ crop*tillage*cover+(1|rep/crop/tillage),
data=data)

The random-effects seem to be the split-plot error terms in the above model.

My question now is:

Now when I combine each year and location, how should I model this
experiment. I am thinking about the following model:

model.all <- lmer (biomass ~location*
crop*tillage*cover+(1|year/rep/crop/tillage), data=data)

Where location is a fixed effect and year is a random effect.

Does this above model actually work? Or should it be like follows:

model.all.1<- lmer (biomass ~ crop*tillage*cover+(1|year)+
(1|rep/crop/tillage), data=data)

Also, I would be very grateful if someone would advise me if the
assumptions of normality and constant variances apply for these lmer models?

Thank you,
Rabin

	[[alternative HTML version deleted]]


From kev|n@m@chu @end|ng |rom duke@edu  Thu Sep 12 20:14:13 2019
From: kev|n@m@chu @end|ng |rom duke@edu (Kevin Chu)
Date: Thu, 12 Sep 2019 18:14:13 +0000
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
Message-ID: <SN6PR05MB430253EBEE1E4D1D021594B9D3B00@SN6PR05MB4302.namprd05.prod.outlook.com>

Hello,

I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly.

These are the data types.

> str(mydata)
'data.frame': 280 obs. of  5 variables:
 $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ...
 $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
 $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
 $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...

Below is the code I used to generated the model.

lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum))

I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached).

My questions:
1) Why do anova and Anova give different results even though I specified type III ANOVA?
2) Why is the Sum Sq equal to 0 in the table produced by anova?

I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data.

Thank you,
Kevin Chu

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Anova_car.png
Type: image/png
Size: 102189 bytes
Desc: Anova_car.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190912/7a584988/attachment-0002.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: anova_stats.png
Type: image/png
Size: 125109 bytes
Desc: anova_stats.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190912/7a584988/attachment-0003.png>

From j@de@ @end|ng |rom uc@d@edu  Fri Sep 13 09:04:06 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Fri, 13 Sep 2019 07:04:06 +0000
Subject: [R-sig-ME] Split-plot experiment with lmer
In-Reply-To: <mailman.17823.460.1568355510.2228.r-sig-mixed-models@r-project.org>
References: <mailman.17823.460.1568355510.2228.r-sig-mixed-models@r-project.org>
Message-ID: <1DFD43D5-B068-45EF-973F-2A0C46E4CBF9@UCSD.edu>

HI Rabin,

From how I see it, if there aren?t multiple measurings throughout the year, then you?d probably want to keep year as a fixed effect. There are only two time points, which I don?t think is enough for a random intercept?since a random intercept is essentially applying a probability distribution to the given variable (anyone correct me if I?m wrong here).

You say that the experiment is conducted four times. Is that four times within the two years? If that is the case, then I?d just make timepoint the variable and do away with years (unless there?s something specifically important to those two years).

The second model you list has year as a crossed effect. This would depend on the structure of your data, whether or not each rep (block) receives a completely new id, or is merely repeated (1,2,3?18,19,20 through 72 vs 1,2,3?17,18 and then 1,2,3?17,18 again). If it?s the latter, then you?d want everything nested within timepoint so?(1 | timepoint/rep/crop/tillage).

Since you have two locations, you?re right to make location a fixed-effect with an interaction. I?d probably think there would be an interaction of time as well, which is why a model with location*timepoint*crop*tillage*cover + (timepoint | rep/crop/tillage), where you control for time as both a fixed effect and a random slope, might be best (I?ve learned from Thierry that centering time as a random slope is also good practice). I?m not too familiar working with fixed effects as random effects as well.

Regarding assumptions of normality, etc., I?d think you?d want to look at your residuals and whether there is any pattern to their distribution or not. If there isn?t a pattern, then you?d be good to go with lmer.

Again, anyone correct me if I?m wrong on any of this.

Good luck!

James


On Sep 12, 2019, at 11:18 PM, r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> wrote:

Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Can we analyse combined split plot experiment using lmer()?
     (Rabin KC)
  2. Using anova vs. Anova for linear mixed model (Kevin Chu)

----------------------------------------------------------------------

Message: 1
Date: Thu, 12 Sep 2019 22:48:19 -0500
From: Rabin KC <kc000001 at umn.edu>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Can we analyse combined split plot experiment
using lmer()?
Message-ID:
<CANdRtHuW8TvO+ojspfn3bPdBYGMfeKvLQk-PiE3fu2OA-A4__A at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello community,

A few days ago, I posted about using lmer() to analyze a split split-plot
design.
The research design is as such:

I am interested in the response variable biomass of cover crops. I have the
main plots as crops (corn and soybean). The subplot is tillage, which is
randomized within the crops and has 3 levels (conventional-till, no-till,
and strip-till). Within tillage(subplot), 3 cover crop strategies are
randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
treatments. The whole experiment is replicated 4 times, therefore, total
experimental units equal to 72 units.

The experiment is conducted in 2 locations for 2 years, therefore total
units equal to 288.

Now the model (as suggested by Peter Claussen in our community) for the
experiment conducted each year and location is :

model <- lmer (biomass ~ crop*tillage*cover+(1|rep/crop/tillage),
data=data)

The random-effects seem to be the split-plot error terms in the above model.

My question now is:

Now when I combine each year and location, how should I model this
experiment. I am thinking about the following model:

model.all <- lmer (biomass ~location*
crop*tillage*cover+(1|year/rep/crop/tillage), data=data)

Where location is a fixed effect and year is a random effect.

Does this above model actually work? Or should it be like follows:

model.all.1<- lmer (biomass ~ crop*tillage*cover+(1|year)+
(1|rep/crop/tillage), data=data)

Also, I would be very grateful if someone would advise me if the
assumptions of normality and constant variances apply for these lmer models?

Thank you,
Rabin

[[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Thu, 12 Sep 2019 18:14:13 +0000
From: Kevin Chu <kevin.m.chu at duke.edu>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
Message-ID:
<SN6PR05MB430253EBEE1E4D1D021594B9D3B00 at SN6PR05MB4302.namprd05.prod.outlook.com>

Content-Type: text/plain; charset="iso-8859-1"

Hello,

I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly.

These are the data types.

str(mydata)
'data.frame': 280 obs. of  5 variables:
$ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
$ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ...
$ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
$ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
$ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...

Below is the code I used to generated the model.

lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum))

I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached).

My questions:
1) Why do anova and Anova give different results even though I specified type III ANOVA?
2) Why is the Sum Sq equal to 0 in the table produced by anova?

I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data.

Thank you,
Kevin Chu

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Anova_car.png
Type: image/png
Size: 102189 bytes
Desc: Anova_car.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190912/7a584988/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: anova_stats.png
Type: image/png
Size: 125109 bytes
Desc: anova_stats.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190912/7a584988/attachment-0001.png>


------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 153, Issue 15
***************************************************


	[[alternative HTML version deleted]]


From krzb@r @end|ng |rom protonm@||@ch  Fri Sep 13 10:30:46 2019
From: krzb@r @end|ng |rom protonm@||@ch (Krzysztof Bartoszek)
Date: Fri, 13 Sep 2019 08:30:46 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <92656866c17f4f358275a4e222c74d76@UM-MAIL3214.unimaas.nl>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
 <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
 <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>
 <92656866c17f4f358275a4e222c74d76@UM-MAIL3214.unimaas.nl>
Message-ID: <dBxMX2XzfQc7mUCxsCyyC_0eQfkBqDHJNPtzIjklngg06fbzc3T0ie_nlGXM3hgasXU2MWgmEffvJAubDxY42gz0I3b8TOxVcz01Gs2X9LI=@protonmail.ch>

Thanks for the code and suggestions. Trying to run the analysis in metafor was on the TODO list. Thank you for saving me the time on figuring out the syntax.
If I may ask for clarification, what do you mean by "the variance component is larger than 0" ?

Best wishes
Krzysztof


??????? Original Message ???????
On Thursday, September 12, 2019 9:04 PM, Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Thanks for the feedback.
>
> For what it's worth, you can fit the model with those 0 variances with metafor:
>
> df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
> df_Dummy$id<-as.factor(1:nrow(df_Dummy))
> df_Dummy$merror<-rexp(10)
> colnames(df_Dummy)[1:2]<-c("x","y")
> df_Dummy$merror[1:4]<-0
>
> library(metafor)
> rma(y ~ x, merror, data=df_Dummy, method="ML")
>
> This will work as long as the variance component is larger than 0.
>
> Best,
> Wolfgang


From krzb@r @end|ng |rom protonm@||@ch  Fri Sep 13 11:00:48 2019
From: krzb@r @end|ng |rom protonm@||@ch (Krzysztof Bartoszek)
Date: Fri, 13 Sep 2019 09:00:48 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <dBxMX2XzfQc7mUCxsCyyC_0eQfkBqDHJNPtzIjklngg06fbzc3T0ie_nlGXM3hgasXU2MWgmEffvJAubDxY42gz0I3b8TOxVcz01Gs2X9LI=@protonmail.ch>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
 <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
 <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>
 <92656866c17f4f358275a4e222c74d76@UM-MAIL3214.unimaas.nl>
 <dBxMX2XzfQc7mUCxsCyyC_0eQfkBqDHJNPtzIjklngg06fbzc3T0ie_nlGXM3hgasXU2MWgmEffvJAubDxY42gz0I3b8TOxVcz01Gs2X9LI=@protonmail.ch>
Message-ID: <_3iUMrpwLaOa27uW8YEBMKvIsaQeHvCJuCkA3WAgT0TBWn4x0BPKe31cWqfzrfDk4AevyyFtnk2TfsjqmDHezty8aVXOGHmDRmpqdtXLD8M=@protonmail.ch>

PS
The below code does not work directly
df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
df_Dummy$id<-as.factor(1:nrow(df_Dummy))
df_Dummy$merror<-rexp(10)
colnames(df_Dummy)[1:2]<-c("x","y")
df_Dummy$merror[1:4]<-0
library(metafor)
rma(y ~ x, merror, data=df_Dummy, method="ML")

## produces
## Error in rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##   Division by zero when computing the inverse variance weights.
## In addition: Warning message:
## In rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##   There are outcomes with non-positive sampling variances.
## Taking as I need for nlme::lme() ang mgcv::gamm()

df_Dummy$merror<-df_Dummy$merror+0.0000000001
rma(y ~ x, merror, data=df_Dummy, method="ML")

## produces
## Error in rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##  Ratio of largest to smallest sampling variance extremely large.
## Cannot obtain stable results.
## and

df_Dummy$merror[1:4]<-0;df_Dummy$merror<-df_Dummy$merror+0.000001
rma(y ~ x, merror, data=df_Dummy, method="ML")

## works, hopefully the bounding away from 0 variance is not too
## large to have an effect on estimation

Krzysztof




??????? Original Message ???????
On Friday, September 13, 2019 8:30 AM, Krzysztof Bartoszek <krzbar at protonmail.ch> wrote:

> Thanks for the code and suggestions. Trying to run the analysis in metafor was on the TODO list. Thank you for saving me the time on figuring out the syntax.
> If I may ask for clarification, what do you mean by "the variance component is larger than 0" ?
>
> Best wishes
> Krzysztof
>
> ??????? Original Message ???????
> On Thursday, September 12, 2019 9:04 PM, Viechtbauer, Wolfgang (SP) wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
>
> > Thanks for the feedback.
> > For what it's worth, you can fit the model with those 0 variances with metafor:
> > df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
> > df_Dummy$id<-as.factor(1:nrow(df_Dummy))
> > df_Dummy$merror<-rexp(10)
> > colnames(df_Dummy)[1:2]<-c("x","y")
> > df_Dummy$merror[1:4]<-0
> > library(metafor)
> > rma(y ~ x, merror, data=df_Dummy, method="ML")
> > This will work as long as the variance component is larger than 0.
> > Best,
> > Wolfgang


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Sep 13 11:15:40 2019
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 13 Sep 2019 09:15:40 +0000
Subject: [R-sig-ME] Measurement error for mixed models
In-Reply-To: <_3iUMrpwLaOa27uW8YEBMKvIsaQeHvCJuCkA3WAgT0TBWn4x0BPKe31cWqfzrfDk4AevyyFtnk2TfsjqmDHezty8aVXOGHmDRmpqdtXLD8M=@protonmail.ch>
References: <DpYVfgBfG-08D93kzSYogOOd0ArvxUJ3wgXgoyu0iE0gzUFWHQG4dZ9wBFFS0kBFjmZ17P28nZq50lWGtHBZAAV-Wkmyoy3DNh0CpLpOoQg=@protonmail.ch>
 <d0f856435b8c4f338b36142929006bb1@UM-MAIL3214.unimaas.nl>
 <ddNnza8wbOr2X2OiVvAgwyWuegwZmyAIqZ2JyRuAMOHOFTBF2ERToW9r86-QsUFsLDDRm5Wwq4wzgWEiOXkIVCXYZ1qdfUwvIdZM8vPv0ss=@protonmail.ch>
 <92656866c17f4f358275a4e222c74d76@UM-MAIL3214.unimaas.nl>
 <dBxMX2XzfQc7mUCxsCyyC_0eQfkBqDHJNPtzIjklngg06fbzc3T0ie_nlGXM3hgasXU2MWgmEffvJAubDxY42gz0I3b8TOxVcz01Gs2X9LI=@protonmail.ch>
 <_3iUMrpwLaOa27uW8YEBMKvIsaQeHvCJuCkA3WAgT0TBWn4x0BPKe31cWqfzrfDk4AevyyFtnk2TfsjqmDHezty8aVXOGHmDRmpqdtXLD8M=@protonmail.ch>
Message-ID: <4c9d750acd88438d8658a881c9e8b034@UM-MAIL3214.unimaas.nl>

I am referring to the variance of the random effect specified via 'random = ~ 1 | id' (in rma(), this gets added by default). You are fitting the model:

y_i = beta0 + beta1 * x_i + u_i + e_i,

where u_i ~ N(0, sigma^2) (or tau^2 in the notation of rma()) and e_i ~ N(0, merror_i), where merror_i is the known measurement variance of the ith observation. If the estimate of sigma^2 is larger than 0, then the marginal variance of y_i is positive, even if merror_i = 0 for some observations. But if sigma^2 is estimated to be 0, then the marginal variance of y_i is 0 for observations where merror_i = 0 and then we are in trouble, because then we get division by zero when computing the MLEs of beta0 and beta1.

Note that the code below *does* work, but whether you can fit the model or not depends on whether the estimate of sigma^2 is larger than 0. If you run it multiple times, sometimes this will be the case and sometimes not.

If you add some small value, say epsilon, to merror_i, then you have merror_i = epsilon for those observations where merror_i = 0 to begin with and merror_i = merror_i + epsilon otherwise. That can be a problem, because the weights given to the observations (when computing the MLEs) can then be very different, especially if the estimate of sigma^2 = 0. In that case, the ratio of max((merror_i + epsilon) / epsilon) may be so extreme that rma() issues a warning (that is what the "Ratio of largest to smallest sampling variance extremely large" warning means). That should be warning, not an error (it used to be an error in earlier version of metafor, but should now only be warning -- so make sure you use the latest version of metafor).

Best,
Wolfgang

-----Original Message-----
From: Krzysztof Bartoszek [mailto:krzbar at protonmail.ch] 
Sent: Friday, 13 September, 2019 11:01
To: Viechtbauer, Wolfgang (SP)
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Measurement error for mixed models

PS
The below code does not work directly
df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
df_Dummy$id<-as.factor(1:nrow(df_Dummy))
df_Dummy$merror<-rexp(10)
colnames(df_Dummy)[1:2]<-c("x","y")
df_Dummy$merror[1:4]<-0
library(metafor)
rma(y ~ x, merror, data=df_Dummy, method="ML")

## produces
## Error in rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##   Division by zero when computing the inverse variance weights.
## In addition: Warning message:
## In rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##   There are outcomes with non-positive sampling variances.
## Taking as I need for nlme::lme() ang mgcv::gamm()

df_Dummy$merror<-df_Dummy$merror+0.0000000001
rma(y ~ x, merror, data=df_Dummy, method="ML")

## produces
## Error in rma(y ~ x, merror, data = df_Dummy, method = "ML") :
##  Ratio of largest to smallest sampling variance extremely large.
## Cannot obtain stable results.
## and

df_Dummy$merror[1:4]<-0;df_Dummy$merror<-df_Dummy$merror+0.000001
rma(y ~ x, merror, data=df_Dummy, method="ML")

## works, hopefully the bounding away from 0 variance is not too
## large to have an effect on estimation

Krzysztof

??????? Original Message ???????
On Friday, September 13, 2019 8:30 AM, Krzysztof Bartoszek <krzbar at protonmail.ch> wrote:

> Thanks for the code and suggestions. Trying to run the analysis in metafor was on the TODO list. Thank you for saving me the time on figuring out the syntax.
> If I may ask for clarification, what do you mean by "the variance component is larger than 0" ?
>
> Best wishes
> Krzysztof
>
> ??????? Original Message ???????
> On Thursday, September 12, 2019 9:04 PM, Viechtbauer, Wolfgang (SP) wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
>
> > Thanks for the feedback.
> > For what it's worth, you can fit the model with those 0 variances with metafor:
> > df_Dummy<-as.data.frame(matrix(rnorm(20),ncol=2,nrow=10))
> > df_Dummy$id<-as.factor(1:nrow(df_Dummy))
> > df_Dummy$merror<-rexp(10)
> > colnames(df_Dummy)[1:2]<-c("x","y")
> > df_Dummy$merror[1:4]<-0
> > library(metafor)
> > rma(y ~ x, merror, data=df_Dummy, method="ML")
> > This will work as long as the variance component is larger than 0.
> > Best,
> > Wolfgang



From j|ox @end|ng |rom mcm@@ter@c@  Fri Sep 13 17:05:22 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 13 Sep 2019 15:05:22 +0000
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
In-Reply-To: <2106_1568355516_x8D6H5Ak009062_SN6PR05MB430253EBEE1E4D1D021594B9D3B00@SN6PR05MB4302.namprd05.prod.outlook.com>
References: <2106_1568355516_x8D6H5Ak009062_SN6PR05MB430253EBEE1E4D1D021594B9D3B00@SN6PR05MB4302.namprd05.prod.outlook.com>
Message-ID: <506BA441-DC50-4EAC-B867-DD05C5395CBC@mcmaster.ca>

Dear Kevin,

It's not entirely clear to me what you did, because as far as I know, the anova() method for merMod objects supplied by the lme4 package doesn't have a type argument and computes sequential ("type-I") tests. (You say that you're using anova() in the stats package, but while stats provides the anova() generic function, the method is coming from someplace else.)

That said, I suspect that the discrepancy is due to the empty cells in the table of the fixed-effects factors. Normally, Anova() will detect the resulting aliased coefficients in the model and report an error, but I believe that lmer() suppresses the aliased coefficients by removing redundant columns of the model matrix. Whatever anova() method you used apparently detected the empty cells directly and printed a warning.

Finally, and particularly in light of the empty cells, I wonder why you want to compute type-III tests.

I hope that this is of some help,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Sep 12, 2019, at 2:14 PM, Kevin Chu <kevin.m.chu at duke.edu> wrote:
> 
> Hello,
> 
> I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly.
> 
> These are the data types.
> 
>> str(mydata)
> 'data.frame': 280 obs. of  5 variables:
> $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ...
> $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
> $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
> $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...
> 
> Below is the code I used to generated the model.
> 
> lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum))
> 
> I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached).
> 
> My questions:
> 1) Why do anova and Anova give different results even though I specified type III ANOVA?
> 2) Why is the Sum Sq equal to 0 in the table produced by anova?
> 
> I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data.
> 
> Thank you,
> Kevin Chu
> <Anova_car.png><anova_stats.png>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Ph||||p@A|d@y @end|ng |rom mp|@n|  Fri Sep 13 17:08:49 2019
From: Ph||||p@A|d@y @end|ng |rom mp|@n| (Alday, Phillip)
Date: Fri, 13 Sep 2019 15:08:49 +0000
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
Message-ID: <ea6c6db8-99ce-44bf-9e99-a62bcf9c8b73@mpi.nl>

Dear Jon, dear Kevin,

I suspect Kevin is using lmerTest and not lme4 directly. lmerTest does have a type argument for anova()  and defaults to the Satterthwaite ddf approximation.

Phillip

Sent from my mobile, please excuse the brevity.
________________________________
Von: "Fox, John" <jfox at mcmaster.ca>
Gesendet: Freitag, 13. September 2019 17:06
An: Kevin Chu
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Using anova vs. Anova for linear mixed model


Dear Kevin,

It's not entirely clear to me what you did, because as far as I know, the anova() method for merMod objects supplied by the lme4 package doesn't have a type argument and computes sequential ("type-I") tests. (You say that you're using anova() in the stats package, but while stats provides the anova() generic function, the method is coming from someplace else.)

That said, I suspect that the discrepancy is due to the empty cells in the table of the fixed-effects factors. Normally, Anova() will detect the resulting aliased coefficients in the model and report an error, but I believe that lmer() suppresses the aliased coefficients by removing redundant columns of the model matrix. Whatever anova() method you used apparently detected the empty cells directly and printed a warning.

Finally, and particularly in light of the empty cells, I wonder why you want to compute type-III tests.

I hope that this is of some help,
John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Sep 12, 2019, at 2:14 PM, Kevin Chu <kevin.m.chu at duke.edu> wrote:
>
> Hello,
>
> I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly.
>
> These are the data types.
>
>> str(mydata)
> 'data.frame': 280 obs. of  5 variables:
> $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ...
> $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
> $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
> $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...
>
> Below is the code I used to generated the model.
>
> lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum))
>
> I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached).
>
> My questions:
> 1) Why do anova and Anova give different results even though I specified type III ANOVA?
> 2) Why is the Sum Sq equal to 0 in the table produced by anova?
>
> I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data.
>
> Thank you,
> Kevin Chu
> <Anova_car.png><anova_stats.png>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Fri Sep 13 18:20:02 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 13 Sep 2019 16:20:02 +0000
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
In-Reply-To: <33B66334-8879-482E-B02D-990A85FAD0FC@duke.edu>
References: <ea6c6db8-99ce-44bf-9e99-a62bcf9c8b73@mpi.nl>
 <33B66334-8879-482E-B02D-990A85FAD0FC@duke.edu>
Message-ID: <5DFD3A44-87A7-4ED2-B531-864CE1B6D92B@mcmaster.ca>

Dear Kevin,

My brief advice is to use "type-II" tests (and to say that "type-I", i.e., sequential, tests are rarely sensible). The different "types" of tests address different hypotheses (unless the data are balanced), and it really isn't a good to do all of them in the same analysis.

The distinctions among the "types" of tests are sufficiently intricate that I'd rather not address them in an email, and the presence of empty cells complicates the matter. Depending on the configuration of empty cells, for example, some interactions might not be estimable and in any event will not be estimable in their entirety. You could do some reading (for example, these issues are addressed in my Applied Regression Analysis and Generalized Linear Models text), but I suggest that you seek competent statistical help, which is surely available locally at Duke. I suspect that there are substantive statistical issues concerning sparsity of data that need to be addressed on a non-mechanical level.

Best,
 John
  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Sep 13, 2019, at 11:53 AM, Kevin Chu <kevin.m.chu at duke.edu> wrote:
> 
> Hello Dr. Alday and Dr. Fox,
> 
> Thank you for your replies. I am indeed using the anova method from lmerTest with the default Satterthwaite method for estimating ddf. 
> 
> I am not a statistics expert (I am a graduate student in electrical and computer engineering), so I do not entirely understand the differences between ANOVA types. I ran the anova method using the three ANOVA types, but I obtained very similar p-values. The part I am suspicious about is that the sum of squares for the STRATEGY factor is exactly equal to 0, which I suspect may be due to the missing cells.
> 
> My question: Do I need to specify any arguments in the anova method so that it can handle missing cells?
> 
> Thank you,
> Kevin
> 
>> On Sep 13, 2019, at 11:08 AM, Alday, Phillip <Phillip.Alday at mpi.nl> wrote:
>> 
>> Dear Jon, dear Kevin, 
>> 
>> I suspect Kevin is using lmerTest and not lme4 directly. lmerTest does have a type argument for anova()  and defaults to the Satterthwaite ddf approximation. 
>> 
>> Phillip 
>> 
>> Sent from my mobile, please excuse the brevity.
>> Von: "Fox, John" <jfox at mcmaster.ca>
>> Gesendet: Freitag, 13. September 2019 17:06
>> An: Kevin Chu
>> Cc: r-sig-mixed-models at r-project.org
>> Betreff: Re: [R-sig-ME] Using anova vs. Anova for linear mixed model 
>> 
>> Dear Kevin, 
>> 
>> It's not entirely clear to me what you did, because as far as I know, the anova() method for merMod objects supplied by the lme4 package doesn't have a type argument and computes sequential ("type-I") tests. (You say that you're using anova() in the stats package, but while stats provides the anova() generic function, the method is coming from someplace else.) 
>> 
>> That said, I suspect that the discrepancy is due to the empty cells in the table of the fixed-effects factors. Normally, Anova() will detect the resulting aliased coefficients in the model and report an error, but I believe that lmer() suppresses the aliased  coefficients by removing redundant columns of the model matrix. Whatever anova() method you used apparently detected the empty cells directly and printed a warning. 
>> 
>> Finally, and particularly in light of the empty cells, I wonder why you want to compute type-III tests. 
>> 
>> I hope that this is of some help, 
>> John 
>> 
>>   ----------------------------- 
>>   John Fox, Professor Emeritus 
>>   McMaster University 
>>   Hamilton, Ontario, Canada 
>>   Web: http::/socserv.mcmaster.ca/jfox 
>> 
>> > On Sep 12, 2019, at 2:14 PM, Kevin Chu <kevin.m.chu at duke.edu> wrote: 
>> > 
>> > Hello, 
>> > 
>> > I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly. 
>> > 
>> > These are the data types. 
>> > 
>> >> str(mydata) 
>> > 'data.frame': 280 obs. of  5 variables: 
>> > $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ... 
>> > $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ... 
>> > $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ... 
>> > $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ... 
>> > $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ... 
>> > 
>> > Below is the code I used to generated the model. 
>> > 
>> > lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum)) 
>> > 
>> > I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached). 
>> > 
>> > My questions: 
>> > 1) Why do anova and Anova give different results even though I specified type III ANOVA? 
>> > 2) Why is the Sum Sq equal to 0 in the table produced by anova? 
>> > 
>> > I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data. 
>> > 
>> > Thank you, 
>> > Kevin Chu 
>> > <Anova_car.png><anova_stats.png>_______________________________________________ 
>> > R-sig-mixed-models at r-project.org mailing list 
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>> 
> 


From jdpoe223 @end|ng |rom gm@||@com  Sat Sep 14 00:33:49 2019
From: jdpoe223 @end|ng |rom gm@||@com (John Poe)
Date: Fri, 13 Sep 2019 18:33:49 -0400
Subject: [R-sig-ME] empirical bayes shrinkage
Message-ID: <CACDpxFCkuTEjW_-8XSkqTbDtV5JTzMT+1TjxSQfWaa2oB0Gc3A@mail.gmail.com>

Hello everyone,

I'm working on a set of lecture notes for my multilevel modeling courses
and I'm trying to track down papers on random effects shrinkage.
Specifically, if you know of anything that contrasts fully bayesian
hierarchical models to empirical bayes shrinkage to unbiased or
unregularized random effects without partial pooling that would be
extremely helpful. Anything on the subject at all would be great though!

Thanks!

	[[alternative HTML version deleted]]


From tu|98250 @end|ng |rom temp|e@edu  Sat Sep 14 05:03:29 2019
From: tu|98250 @end|ng |rom temp|e@edu (Daniel P Moriarity)
Date: Fri, 13 Sep 2019 23:03:29 -0400
Subject: [R-sig-ME] Intercept Variance Components Equal 0- Change Score
Message-ID: <CAH9nZDruY7WaOMObU0whX9QEhAsnrZ+qXxe_snWtXPyn8143RA@mail.gmail.com>

Hello all,

I am revising some MLMs using lmer and a reviewer suggested we use change
scores as our outcome. When I did so, I noticed that the variance
components for the intercept were both 0 (see below) regardless of the
variable I was predicting to (all 6 are now change scores). Any ideas as to
why this might be? The change scores are not person-centered, and we
confirmed that there is between-person variability using the VAR function
(see below the random effects ouput). Thank you.


Random effects:

  Groups   Name        Variance Std.Dev.

ID       (Intercept)  0.00    0.000

Residual             19.46    4.411

Number of obs: 310, groups:  ID, 130


> var(Data_group_by$CDI_Change)
[1] 6.353349


My best,
Daniel

Doctoral Student, Clinical Area
Mood and Cognition Lab
Department of Psychology
Temple University
1701 North 13th Street
Philadelphia, PA 19122
daniel.moriarity at temple.edu <hannah.frank at temple.edu>

*WARNING: This e-mail may contain material that is confidential and is for
the sole use of the intended recipient.  If you are not the intended
recipient, please contact the sender and delete all copies.  There are no
guarantees that electronic communications are secure and protected.*

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 14 11:36:15 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 14 Sep 2019 11:36:15 +0200
Subject: [R-sig-ME] empirical bayes shrinkage
In-Reply-To: <CACDpxFCkuTEjW_-8XSkqTbDtV5JTzMT+1TjxSQfWaa2oB0Gc3A@mail.gmail.com>
References: <CACDpxFCkuTEjW_-8XSkqTbDtV5JTzMT+1TjxSQfWaa2oB0Gc3A@mail.gmail.com>
Message-ID: <0b6181dd-3675-dc0d-5fbe-cdf49e3764c6@mpi.nl>

Have you looked at the PyMC3 documentation?

e.g.

https://docs.pymc.io/notebooks/hierarchical_partial_pooling.html

https://docs.pymc.io/notebooks/multilevel_modeling.html

On 14/09/2019 00:33, John Poe wrote:
> Hello everyone,
>
> I'm working on a set of lecture notes for my multilevel modeling courses
> and I'm trying to track down papers on random effects shrinkage.
> Specifically, if you know of anything that contrasts fully bayesian
> hierarchical models to empirical bayes shrinkage to unbiased or
> unregularized random effects without partial pooling that would be
> extremely helpful. Anything on the subject at all would be great though!
>
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 14 11:49:47 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 14 Sep 2019 11:49:47 +0200
Subject: [R-sig-ME] Intercept Variance Components Equal 0- Change Score
In-Reply-To: <CAH9nZDruY7WaOMObU0whX9QEhAsnrZ+qXxe_snWtXPyn8143RA@mail.gmail.com>
References: <CAH9nZDruY7WaOMObU0whX9QEhAsnrZ+qXxe_snWtXPyn8143RA@mail.gmail.com>
Message-ID: <5af6f2e0-aceb-01ea-c44b-79c3eb97a356@mpi.nl>

Without seeing the rest of your model, it's hard to tell. I suspect you
model is something like:

change_score ~ 1 + some_predictor + (1|ID)

Then you only have a few change_scores by participant and the
by-participant variation is indistinguishable from the residual
variation. Because the random-effect for participant measures the
variation due to participant *beyond* the residual variation, it goes to
zero here.

Phillip

On 14/09/2019 05:03, Daniel P Moriarity wrote:
> Hello all,
>
> I am revising some MLMs using lmer and a reviewer suggested we use change
> scores as our outcome. When I did so, I noticed that the variance
> components for the intercept were both 0 (see below) regardless of the
> variable I was predicting to (all 6 are now change scores). Any ideas as to
> why this might be? The change scores are not person-centered, and we
> confirmed that there is between-person variability using the VAR function
> (see below the random effects ouput). Thank you.
>
>
> Random effects:
>
>   Groups   Name        Variance Std.Dev.
>
> ID       (Intercept)  0.00    0.000
>
> Residual             19.46    4.411
>
> Number of obs: 310, groups:  ID, 130
>
>
>> var(Data_group_by$CDI_Change)
> [1] 6.353349
>
>
> My best,
> Daniel
>
> Doctoral Student, Clinical Area
> Mood and Cognition Lab
> Department of Psychology
> Temple University
> 1701 North 13th Street
> Philadelphia, PA 19122
> daniel.moriarity at temple.edu <hannah.frank at temple.edu>
>
> *WARNING: This e-mail may contain material that is confidential and is for
> the sole use of the intended recipient.  If you are not the intended
> recipient, please contact the sender and delete all copies.  There are no
> guarantees that electronic communications are secure and protected.*
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sat Sep 14 23:41:49 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sat, 14 Sep 2019 21:41:49 +0000
Subject: [R-sig-ME] Trying to understand the syntax of lmer
Message-ID: <BN7PR03MB37305318FC2A8D8B8A3298B3E2B20@BN7PR03MB3730.namprd03.prod.outlook.com>

Colleagues,
I hope you will not mind my asking seven questions, questions designed to allow me to know if my basic understanding of lmer syntax is correct. Below I post code and in the comments 7 questions.?


data(Orthodont,package="nlme")
Orthodont$nsex <- as.numeric(Orthodont$Sex=="Male")
Orthodont$nsexage <- with(Orthodont, nsex*age)

# (1) Is this a model with a random intercept in which, each subject has his, or her own intercept?
lmer(distance ~ age +(1|Subject),data=Orthodont)

# (2) Is this a model with a random slope, where age is the slope, each subject having their own slope?
lmer(distance ~ age + (0+age|Subject), data=Orthodont)

# (3) Is this a model with random intercept, Subject, and random slope age?
# (4) If it is, what is the assumed covariance structure between slope and intercept?
# (5) Is the covariance structure assumed to be unstructured?
# (6) How can I get the estimated covariance between intercept (subject) and slope (age)?
lmer(distance ~ age +(1|Subject)+(0+age|Subject), data=Orthodont)
# (7) The next two models, I believe have a random intercept (a sparate slope for each subject),
# ? ? an age*sex interaction, a random slope (age) for each subject. Are my assumptions correct?
lmer(distance ~ age +Sex+nsexage+(1|Subject)+(0+age|Subject), data=Orthodont)
lmer(distance ~ age +Sex+Sex*age+(1|Subject)+(0+age|Subject), data=Orthodont)

Thank you for your patients with my eight questions.

John



John David Sorkin M.D., Ph.D.

Professor of Medicine

Chief, Biostatistics and Informatics

University of Maryland School of Medicine Division of?Gerontology and Geriatric Medicine

Baltimore VA Medical Center

10 North Greene Street

GRECC (BT/18/GR)

Baltimore, MD 21201-1524

(Phone) 410-605-7119

(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




From bbo|ker @end|ng |rom gm@||@com  Sun Sep 15 00:20:50 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 14 Sep 2019 18:20:50 -0400
Subject: [R-sig-ME] Trying to understand the syntax of lmer
In-Reply-To: <BN7PR03MB37305318FC2A8D8B8A3298B3E2B20@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <BN7PR03MB37305318FC2A8D8B8A3298B3E2B20@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <CABghstTi4SAkaCsP2hksLEPJ5mqiyRQtiRJSNsAox6DF_T_OdQ@mail.gmail.com>

On Sat, Sep 14, 2019 at 5:42 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> Colleagues,
> I hope you will not mind my asking seven questions, questions designed to allow me to know if my basic understanding of lmer syntax is correct. Below I post code and in the comments 7 questions.
>
>
> data(Orthodont,package="nlme")
> Orthodont$nsex <- as.numeric(Orthodont$Sex=="Male")
> Orthodont$nsexage <- with(Orthodont, nsex*age)
>
> # (1) Is this a model with a random intercept in which, each subject has his, or her own intercept?
> lmer(distance ~ age +(1|Subject),data=Orthodont)

 Yes
>
> # (2) Is this a model with a random slope, where age is the slope, each subject having their own slope?
> lmer(distance ~ age + (0+age|Subject), data=Orthodont)

  Yes
>
> # (3) Is this a model with random intercept, Subject, and random slope age?

  I'm confused.  Are you referring to this model

(a) > lmer(distance ~ age +(1|Subject)+(0+age|Subject), data=Orthodont)

or

(b)  lmer(distance ~ age + (age|Subject), data=Orthodont)

  Both models allow varying intercepts and slopes among Subjects.

> # (4) If it is, what is the assumed covariance structure between slope and intercept?

 (a) intercept-slope covariance is constrained to 0
 (b) variance-covariance matrix is positive semi-definite (i.e., both
eigenvalues >=0).  Correlation can be any value between -1 and 1.



> # (5) Is the covariance structure assumed to be unstructured?

 (a) No.
(b) Yes.

> # (6) How can I get the estimated covariance between intercept (subject) and slope (age)?
> lmer(distance ~ age +(1|Subject)+(0+age|Subject), data=Orthodont)

 (a) it's constrained to be zero
 (b) VarCorr(fitted_model)$Subject[1,2]

> # (7) The next two models, I believe have a random intercept (a separate slope for each subject),
> #     an age*sex interaction, a random slope (age) for each subject. Are my assumptions correct?
> lmer(distance ~ age +Sex+nsexage+(1|Subject)+(0+age|Subject), data=Orthodont)
> lmer(distance ~ age +Sex+Sex*age+(1|Subject)+(0+age|Subject), data=Orthodont)

  Yes. In the second model, the fixed effect specification is slightly
redundant.
  distance ~ age*Sex + ... (or ~ Sex*age + ...) will include the main
effects as well as the interaction.
(questions about fixed-effect model specification are not specific to
mixed models, but follow R's general rules as implemented by
model.matrix() ...)

See:

  section 2.2 of Bates et all JSS paper [vignette("lmer",package="lme4")]
 and https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification
(and links therein:
http://www.rensenieuwenhuis.nl/r-sessions-16-multilevel-model-specification-lme4/
and https://rpsychologist.com/r-guide-longitudinal-lme-lmer)

>
> Thank you for your patients with my eight questions.
>
> John
>
>
>
> John David Sorkin M.D., Ph.D.
>
> Professor of Medicine
>
> Chief, Biostatistics and Informatics
>
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>
> Baltimore VA Medical Center
>
> 10 North Greene Street
>
> GRECC (BT/18/GR)
>
> Baltimore, MD 21201-1524
>
> (Phone) 410-605-7119
>
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @pro @end|ng |rom un|me|b@edu@@u  Sat Sep 14 00:41:01 2019
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Fri, 13 Sep 2019 22:41:01 +0000
Subject: [R-sig-ME] empirical bayes shrinkage
In-Reply-To: <CACDpxFCkuTEjW_-8XSkqTbDtV5JTzMT+1TjxSQfWaa2oB0Gc3A@mail.gmail.com>
References: <CACDpxFCkuTEjW_-8XSkqTbDtV5JTzMT+1TjxSQfWaa2oB0Gc3A@mail.gmail.com>
Message-ID: <MEAPR01MB3701F4DD5F414B14D5DF9117E2B30@MEAPR01MB3701.ausprd01.prod.outlook.com>

Geoff Robinson?s ?That BLUP is a good thing? statistical science IIRC should not be missed!

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://cebra.unimelb.edu.au/
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Poe <jdpoe223 at gmail.com>
Sent: Saturday, September 14, 2019 8:33:49 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] empirical bayes shrinkage

Hello everyone,

I'm working on a set of lecture notes for my multilevel modeling courses
and I'm trying to track down papers on random effects shrinkage.
Specifically, if you know of anything that contrasts fully bayesian
hierarchical models to empirical bayes shrinkage to unbiased or
unregularized random effects without partial pooling that would be
extremely helpful. Anything on the subject at all would be great though!

Thanks!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From kev|n@m@chu @end|ng |rom duke@edu  Fri Sep 13 17:53:32 2019
From: kev|n@m@chu @end|ng |rom duke@edu (Kevin Chu)
Date: Fri, 13 Sep 2019 15:53:32 +0000
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
In-Reply-To: <ea6c6db8-99ce-44bf-9e99-a62bcf9c8b73@mpi.nl>
References: <ea6c6db8-99ce-44bf-9e99-a62bcf9c8b73@mpi.nl>
Message-ID: <33B66334-8879-482E-B02D-990A85FAD0FC@duke.edu>

Hello Dr. Alday and Dr. Fox,

Thank you for your replies. I am indeed using the anova method from lmerTest with the default Satterthwaite method for estimating ddf.

I am not a statistics expert (I am a graduate student in electrical and computer engineering), so I do not entirely understand the differences between ANOVA types. I ran the anova method using the three ANOVA types, but I obtained very similar p-values. The part I am suspicious about is that the sum of squares for the STRATEGY factor is exactly equal to 0, which I suspect may be due to the missing cells.

My question: Do I need to specify any arguments in the anova method so that it can handle missing cells?

Thank you,
Kevin

On Sep 13, 2019, at 11:08 AM, Alday, Phillip <Phillip.Alday at mpi.nl<mailto:Phillip.Alday at mpi.nl>> wrote:

Dear Jon, dear Kevin,

I suspect Kevin is using lmerTest and not lme4 directly. lmerTest does have a type argument for anova()  and defaults to the Satterthwaite ddf approximation.

Phillip

Sent from my mobile, please excuse the brevity.
________________________________
Von: "Fox, John" <jfox at mcmaster.ca<mailto:jfox at mcmaster.ca>>
Gesendet: Freitag, 13. September 2019 17:06
An: Kevin Chu
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Using anova vs. Anova for linear mixed model


Dear Kevin,

It's not entirely clear to me what you did, because as far as I know, the anova() method for merMod objects supplied by the lme4 package doesn't have a type argument and computes sequential ("type-I") tests. (You say that you're using anova() in the stats package, but while stats provides the anova() generic function, the method is coming from someplace else.)

That said, I suspect that the discrepancy is due to the empty cells in the table of the fixed-effects factors. Normally, Anova() will detect the resulting aliased coefficients in the model and report an error, but I believe that lmer() suppresses the aliased coefficients by removing redundant columns of the model matrix. Whatever anova() method you used apparently detected the empty cells directly and printed a warning.

Finally, and particularly in light of the empty cells, I wonder why you want to compute type-III tests.

I hope that this is of some help,
John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox<http://socserv.mcmaster.ca/jfox>

> On Sep 12, 2019, at 2:14 PM, Kevin Chu <kevin.m.chu at duke.edu<mailto:kevin.m.chu at duke.edu>> wrote:
>
> Hello,
>
> I built a linear mixed effects model with three fixed factors and one random factor. I want to test for statistical significance of the fixed effects using F-tests from a type III ANOVA table. Since I am using a type III ANOVA, I understand that I need to set the contrasts to contr.sum so that the sums of squares are calculated correctly.
>
> These are the data types.
>
>> str(mydata)
> 'data.frame': 280 obs. of  5 variables:
> $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3 3 ...
> $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
> $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
> $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...
>
> Below is the code I used to generated the model.
>
> lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT), data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum, STRATEGY=contr.sum))
>
> I tried passing lmm through anova from the stats package and Anova from the car package, but I obtained different results (screenshots are attached).
>
> My questions:
> 1) Why do anova and Anova give different results even though I specified type III ANOVA?
> 2) Why is the Sum Sq equal to 0 in the table produced by anova?
>
> I would prefer not to release the data as I plan to publish a paper based on my results, but if it helps I can create dummy data.
>
> Thank you,
> Kevin Chu
> <Anova_car.png><anova_stats.png>_______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwQGaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=NNSxTeokqazWhiWULiCMlOAVTEByVHXdjy6FjXUjiHU&m=F5q1yWIx355pICBP6MYm99qp9soZHkUUIGMG7TCpKec&s=bcz0PLPOIWmpvoOw9D6H5XEozUoZNTPXPwOdjYmGoUc&e=>

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwQGaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=NNSxTeokqazWhiWULiCMlOAVTEByVHXdjy6FjXUjiHU&m=F5q1yWIx355pICBP6MYm99qp9soZHkUUIGMG7TCpKec&s=bcz0PLPOIWmpvoOw9D6H5XEozUoZNTPXPwOdjYmGoUc&e=>


	[[alternative HTML version deleted]]


From @t@n|eychr|@topher1 @end|ng |rom y@hoo@com  Sun Sep 15 15:41:33 2019
From: @t@n|eychr|@topher1 @end|ng |rom y@hoo@com (Christopher Stanley)
Date: Sun, 15 Sep 2019 13:41:33 +0000 (UTC)
Subject: [R-sig-ME] Joint modelling using frailtypack R package
References: <65861359.5043728.1568554893484.ref@mail.yahoo.com>
Message-ID: <65861359.5043728.1568554893484@mail.yahoo.com>

Colleagues,
I am trying to model recurrent events (clinical malaria episodes) jointly with longitudinal outcome (malaria parasites density) and a terminal outcome (loss-to-follow up). For some reason I am unable to have my code run using frailtypack package. Would anyone have an idea what might be going wrong in my code pasted below? Or if anyone has suggestions for a different package which can fit these models ( or just joint models of recurrent events and longitudinal outcome)??
Here's is the code and error message that am getting:*******> joint.model <-trivPenal(Surv(start, stop, clinical_malaria) ~ cluster(studyid) ++? ? ? ? ? ? ? ? ? ?age_yrs + season + gender + pre_netfreq + terminal(ltfu),+? ? ? ? ? ? ? ? ? ?formula.terminalEvent = ~ age_yrs + season,+? ? ? ? ? ? ? ? ? ?smearquant ~ age_yrs + season, data = paper3_recurrent_episode,+? ? ? ? ? ? ? ? ? ?data.Longi = paper3_recurrent_Longi, random = c("1","stop"), id = "studyid",??+? ? ? ? ? ? ? ? ? ?link = "Random-effects", recurrentAG = TRUE, n.knots = 6, kappa=c(0.01, 2))Error in aggregate.data.frame(as.data.frame(x), ...) :?? arguments must have same length*******Thanks for your help in advance.
 Christopher Chikhosi StanleyPhD student - Epidemiology & Biostatistics?University of the WitwatersrandFaculty of Health Science
Wits School of Public Health27 Saint Andrews Road, Parktown 2193

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Sun Sep 15 15:44:59 2019
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Sun, 15 Sep 2019 09:44:59 -0400
Subject: [R-sig-ME] Using anova vs. Anova for linear mixed model
In-Reply-To: <33B66334-8879-482E-B02D-990A85FAD0FC@duke.edu>
References: <ea6c6db8-99ce-44bf-9e99-a62bcf9c8b73@mpi.nl>
 <33B66334-8879-482E-B02D-990A85FAD0FC@duke.edu>
Message-ID: <CANOgrHZMV-SsOKhwM02Y0uCpa43Ee4cntVOmO9Aq=syp45e65w@mail.gmail.com>

You may also want to try "drop1" native to the lme4 package for comparison



On Sun, Sep 15, 2019 at 9:38 AM Kevin Chu <kevin.m.chu at duke.edu> wrote:

> Hello Dr. Alday and Dr. Fox,
>
> Thank you for your replies. I am indeed using the anova method from
> lmerTest with the default Satterthwaite method for estimating ddf.
>
> I am not a statistics expert (I am a graduate student in electrical and
> computer engineering), so I do not entirely understand the differences
> between ANOVA types. I ran the anova method using the three ANOVA types,
> but I obtained very similar p-values. The part I am suspicious about is
> that the sum of squares for the STRATEGY factor is exactly equal to 0,
> which I suspect may be due to the missing cells.
>
> My question: Do I need to specify any arguments in the anova method so
> that it can handle missing cells?
>
> Thank you,
> Kevin
>
> On Sep 13, 2019, at 11:08 AM, Alday, Phillip <Phillip.Alday at mpi.nl<mailto:
> Phillip.Alday at mpi.nl>> wrote:
>
> Dear Jon, dear Kevin,
>
> I suspect Kevin is using lmerTest and not lme4 directly. lmerTest does
> have a type argument for anova()  and defaults to the Satterthwaite ddf
> approximation.
>
> Phillip
>
> Sent from my mobile, please excuse the brevity.
> ________________________________
> Von: "Fox, John" <jfox at mcmaster.ca<mailto:jfox at mcmaster.ca>>
> Gesendet: Freitag, 13. September 2019 17:06
> An: Kevin Chu
> Cc: r-sig-mixed-models at r-project.org<mailto:
> r-sig-mixed-models at r-project.org>
> Betreff: Re: [R-sig-ME] Using anova vs. Anova for linear mixed model
>
>
> Dear Kevin,
>
> It's not entirely clear to me what you did, because as far as I know, the
> anova() method for merMod objects supplied by the lme4 package doesn't have
> a type argument and computes sequential ("type-I") tests. (You say that
> you're using anova() in the stats package, but while stats provides the
> anova() generic function, the method is coming from someplace else.)
>
> That said, I suspect that the discrepancy is due to the empty cells in the
> table of the fixed-effects factors. Normally, Anova() will detect the
> resulting aliased coefficients in the model and report an error, but I
> believe that lmer() suppresses the aliased coefficients by removing
> redundant columns of the model matrix. Whatever anova() method you used
> apparently detected the empty cells directly and printed a warning.
>
> Finally, and particularly in light of the empty cells, I wonder why you
> want to compute type-III tests.
>
> I hope that this is of some help,
> John
>
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox<http://socserv.mcmaster.ca/jfox>
>
> > On Sep 12, 2019, at 2:14 PM, Kevin Chu <kevin.m.chu at duke.edu<mailto:
> kevin.m.chu at duke.edu>> wrote:
> >
> > Hello,
> >
> > I built a linear mixed effects model with three fixed factors and one
> random factor. I want to test for statistical significance of the fixed
> effects using F-tests from a type III ANOVA table. Since I am using a type
> III ANOVA, I understand that I need to set the contrasts to contr.sum so
> that the sums of squares are calculated correctly.
> >
> > These are the data types.
> >
> >> str(mydata)
> > 'data.frame': 280 obs. of  5 variables:
> > $ SUBJECT  : Factor w/ 20 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1
> ...
> > $ CONDITION: Factor w/ 4 levels "anechoic","aula",..: 1 1 1 1 2 2 2 2 3
> 3 ...
> > $ CHANNEL  : Factor w/ 2 levels "0","1": 1 1 2 2 1 1 2 2 1 1 ...
> > $ STRATEGY : Factor w/ 2 levels "0","1": 1 2 1 2 1 2 1 2 1 2 ...
> > $ SCORE    : num  107.4 57 90.1 96.1 -16.4 ...
> >
> > Below is the code I used to generated the model.
> >
> > lmm <- lmer(SCORE ~ CONDITION * CHANNEL * STRATEGY + (1 | SUBJECT),
> data=mydata, contrasts=list(CONDITION=contr.sum, CHANNEL=contr.sum,
> STRATEGY=contr.sum))
> >
> > I tried passing lmm through anova from the stats package and Anova from
> the car package, but I obtained different results (screenshots are
> attached).
> >
> > My questions:
> > 1) Why do anova and Anova give different results even though I specified
> type III ANOVA?
> > 2) Why is the Sum Sq equal to 0 in the table produced by anova?
> >
> > I would prefer not to release the data as I plan to publish a paper
> based on my results, but if it helps I can create dummy data.
> >
> > Thank you,
> > Kevin Chu
> >
> <Anova_car.png><anova_stats.png>_______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwQGaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=NNSxTeokqazWhiWULiCMlOAVTEByVHXdjy6FjXUjiHU&m=F5q1yWIx355pICBP6MYm99qp9soZHkUUIGMG7TCpKec&s=bcz0PLPOIWmpvoOw9D6H5XEozUoZNTPXPwOdjYmGoUc&e=
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwQGaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=NNSxTeokqazWhiWULiCMlOAVTEByVHXdjy6FjXUjiHU&m=F5q1yWIx355pICBP6MYm99qp9soZHkUUIGMG7TCpKec&s=bcz0PLPOIWmpvoOw9D6H5XEozUoZNTPXPwOdjYmGoUc&e=
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom uc@d@edu  Mon Sep 16 05:27:00 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Mon, 16 Sep 2019 03:27:00 +0000
Subject: [R-sig-ME] Dealing with NAs in LMER with longitudinal data (Re
 Crime and Education data)
Message-ID: <ECFC4041-383E-4CED-889C-A1DB1B2B1592@UCSD.edu>

I?ve often heard that mixed-effect lmer/glmer models ?handle? or ?deal? with NA values well, and I?ve become more curious about what this actually means, if it is, indeed, true. What I?ve observed working with mixed-effect models is that na.omit will delete the entire row of observations, and depending on the number of NAs, the AIC might deceptively, dramatically decrease, given that the sample is smaller.

I know that one can also use ?na.pass??maybe this is what I?ve heard in the past with regard to lmer handling NAs well(?)?though I?ve often found that this doesn?t always work, throwing back the error that ```Error in qr.default(X, tol = tol, LAPACK = FALSE) : NA/NaN/Inf in foreign function call (arg 1)```. When it does work, I?m not sure how it works. I looked through the lme4 manual and the ?Fitting Linear Mixed-Effects Models? article, but I couldn?t find anything.

I?d assume that imputation is better practice for handling NAs. Though, specifically referencing my crime/ed analysis (I?ve posted the data here: https://drive.google.com/open?id=1wRwLqCKNfpz5aHtyy5KfY07_RFqWsWv9) this is a bit more difficult, and something I have yet to do. I?ve been reading about it here: https://stefvanbuuren.name/fimd/sec-rastering.html.

In addition, there are instances where data is only offered every five years, or, as is the case with a presidential election, every four years. My ?bandaid? approach for this kind of data pitfall is to stagger the four years, so that the election data counts for the two years preceding and the two years following the election (this is an assumption, but it seems preferable to NAs for three out of four years). 

Still, it seems that weirdness might be accompanying this method. Looking at educational attainment data (averaged over a five-year period) in the dataset, there exists unseemly high correlation between year and the proportion of people in a place and their corresponding educational attainment (some high school, hs diploma, some college, bachelors, MA,etc.); these individual variables have anywhere from a  -.5 to a .6 correlation with year. 

Code for looking at correlations:
```cor.total.years.city <- total.years.city.select%>%select((3), (8:31))%>%na.omit()
cor1 = cor(cor.total.years.city)
corrplot.mixed(cor1, lower.col = "black", number.cex = .7)```

Perhaps I should put these variables into into long format, but I?ve read that sometimes this exacerbates multi-collinearity. (And this wouldn?t solve the correlation strangeness)

To summarize: 
1. If lmer does handle NAs well, how exactly is it doing that? If ?na.pass? fails, then is it handling NAs as any other program?
2. Is imputation (done correctly) better than allowing mixed-effect functions to handle NAs?
3. Any specific resources on imputing longitudinal data?
4. For data offered every four years, is my method of staggering (and filling) this data sufficient? Is there another way I should be thinking about this in lme4? Is this the source of funky correlations between education attainment and year?
5. Should I be using long format here for variables like race (black, white, asian, latino) and education attainment (some high school, hs diploma, some college, bachelors, MA/grad school)

Thanks much!

James

From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Sep 17 06:02:41 2019
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 17 Sep 2019 04:02:41 +0000
Subject: [R-sig-ME] Dealing with NAs in LMER with longitudinal data (Re
 Crime and Education data)
In-Reply-To: <ECFC4041-383E-4CED-889C-A1DB1B2B1592@UCSD.edu>
References: <ECFC4041-383E-4CED-889C-A1DB1B2B1592@UCSD.edu>
Message-ID: <a45a0728e8964c728b982b0d58d1c465@qimrberghofer.edu.au>


> I?ve often heard that mixed-effect lmer/glmer models ?handle? or ?deal? with NA values well, 
> and I?ve become more curious about what this actually means, if it is, indeed, true. What 
> I?ve observed working with mixed-effect models is that na.omit will delete the entire 
> row of observations, and depending on the number of NAs, the AIC might 
> deceptively, dramatically decrease, given that the sample is smaller.

> I know that one can also use ?na.pass?

> I?d assume that imputation is better practice for handling NAs. 

> To summarize:
> 1. If lmer does handle NAs well, how exactly is it doing that? If ?na.pass? fails, 
> then is it handling NAs as any other program?

My limited understanding is that na.pass usually affects just the copy of the data in
the returned object. It won't get around the fact that if you are conditioning on fixed effects, only complete observations must be used. So if you want your AICs to be comparable, you need to have a single dataset that is complete for all the variables you are interested in.

> 2. Is imputation (done correctly) better than allowing mixed-effect functions to handle NAs?

If you have non-ignorable missing data, then these must be included as response variables, so the mixed model can combine the correct likelihoods for each pattern of missingness. I have more experience with a straightforward multivariate formulation for this, so I don't know how or if you can mimic this in the lmer framework. Quite aside from if you want to specify directional paths between such variables - imputation is the cheap and cheerful answer.

> 5. Should I be using long format here for variables like race (black, white, asian, latino) 
> and education attainment (some high school, hs diploma, some college, bachelors, 
> MA/grad school)

I'd of thought so, unless you already have a handle on the causes of any autocorrelation

Hopefully someone more in your area will respond, but in animal breeding genetics, there are mixed models of similar huge longitudinal datasets (people I know in human genetics were great fans of the Journal of Dairy Science ;), and of ASReml).

Cheers, David Duffy.

From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Tue Sep 17 09:26:52 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Tue, 17 Sep 2019 07:26:52 +0000
Subject: [R-sig-ME] Dealing with NAs in LMER with longitudinal data (Re
 Crime and Education data)
In-Reply-To: <a45a0728e8964c728b982b0d58d1c465@qimrberghofer.edu.au>
References: <ECFC4041-383E-4CED-889C-A1DB1B2B1592@UCSD.edu>,
 <a45a0728e8964c728b982b0d58d1c465@qimrberghofer.edu.au>
Message-ID: <90369ecbaac44ebea6adef025d9f5190@erasmusmc.nl>

We should distinguish between missing data in the outcome and missing data in the covariates.

For missing data in the outcome, mixed effects models provide unbiased estimates and valid inferences under the missing completely at random and missing at random missing data mechanisms. No (multiple) imputation of the outcome is required in this case. Only that the model is adequately/flexibly specified with regard to both the fixed- and random-effects structures. For the fixed-effects part in particular you need to include any covariates that potentially relate to the reasons why you have missing data. Finally, if the missing data mechanism is missing not at random, then the mixed model alone is not enough and you will need to jointly model the outcome and the dropout process.

For missing data in the covariates you will need to use multiple imputation. It is important that the whole outcome is included in the imputation step. This is more challenging for example for longitudinal outcomes that are not measured at the same time points for all subjects. There are approaches and R packages to handle these situations.

Best,
Dimitris


From: David Duffy <David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au>>
Date: Tuesday, 17 Sep 2019, 06:03
To: Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>, r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Dealing with NAs in LMER with longitudinal data (Re Crime and Education data)


> I?ve often heard that mixed-effect lmer/glmer models ?handle? or ?deal? with NA values well,
> and I?ve become more curious about what this actually means, if it is, indeed, true. What
> I?ve observed working with mixed-effect models is that na.omit will delete the entire
> row of observations, and depending on the number of NAs, the AIC might
> deceptively, dramatically decrease, given that the sample is smaller.

> I know that one can also use ?na.pass?

> I?d assume that imputation is better practice for handling NAs.

> To summarize:
> 1. If lmer does handle NAs well, how exactly is it doing that? If ?na.pass? fails,
> then is it handling NAs as any other program?

My limited understanding is that na.pass usually affects just the copy of the data in
the returned object. It won't get around the fact that if you are conditioning on fixed effects, only complete observations must be used. So if you want your AICs to be comparable, you need to have a single dataset that is complete for all the variables you are interested in.

> 2. Is imputation (done correctly) better than allowing mixed-effect functions to handle NAs?

If you have non-ignorable missing data, then these must be included as response variables, so the mixed model can combine the correct likelihoods for each pattern of missingness. I have more experience with a straightforward multivariate formulation for this, so I don't know how or if you can mimic this in the lmer framework. Quite aside from if you want to specify directional paths between such variables - imputation is the cheap and cheerful answer.

> 5. Should I be using long format here for variables like race (black, white, asian, latino)
> and education attainment (some high school, hs diploma, some college, bachelors,
> MA/grad school)

I'd of thought so, unless you already have a handle on the causes of any autocorrelation

Hopefully someone more in your area will respond, but in animal breeding genetics, there are mixed models of similar huge longitudinal datasets (people I know in human genetics were great fans of the Journal of Dairy Science ;), and of ASReml).

Cheers, David Duffy.
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C2a138361e3764a450a7908d73b23f0b0%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637042897872673826&amp;sdata=ytckzuyEucwzIAQRYmnZRdzlOO1LBywRjjGUZHwvV5Q%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From d@kot@judo @end|ng |rom m@c@com  Tue Sep 17 17:24:17 2019
From: d@kot@judo @end|ng |rom m@c@com (Peter Claussen)
Date: Tue, 17 Sep 2019 10:24:17 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <CANdRtHuiozRc_kJ-Hqc1m_wnGom+rUPQY9FzcJTmv-b2JvAOrQ@mail.gmail.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <777CDD01-DC7F-4CBB-B99F-2438EBB44D9B@mac.com>
 <CANdRtHuiozRc_kJ-Hqc1m_wnGom+rUPQY9FzcJTmv-b2JvAOrQ@mail.gmail.com>
Message-ID: <A1568553-D5B6-4962-8507-6F72EE846BEC@mac.com>

Rabin,

OK, finally getting back to this.

A couple cases to consider that might be leading to a singular fit. The first should be, I think, the most obvious - you simply do not have enough samples from a random variable to obtain an estimate. If we can assume that your experimental replicates and whole plots sample over comparable spatial heterogeneity, then combining trials will give you more samples from those populations, thus perhaps a better estimate for whole pilot variance terms.

The other is that your analysis model is incorrect for these experiments. 

Remember that one of the assumptions of AOV is that residual errors are independent and identically distributed. This assumption allows us to compute variances from expected mean squares. I would suggest https://dl.sciencesocieties.org/publications/aj/abstracts/81/4/AJ0810040665 <https://dl.sciencesocieties.org/publications/aj/abstracts/81/4/AJ0810040665> for an example of how to write up the expected mean squares. 

We can compute variance components from mean squares, based on their expectations, but these usually dependent on an estimate of residual variance, and when residuals are not i.i.d., I think we get poor estimates of the other variance terms.

To explore this, I considered the data you posted and fit the model

model1 <-lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)
par(mfrow=c(2,2))
plot(model1)

We might need to accept that the residuals are not i.i.d, i particular, that the errors variances are not comparable between corn and soybeans. In lmer, we might attempt to address this with

model1.lmer <- lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage), data=data)
model2.lmer <- lmer(biomass ~ crop*tillage*cover+(crop | rep/crop/tillage), data=data)
plot(model1.lmer)
plot(model2.lmer)

There appears to be some improvement, at least with soybeans. 

You might consider what this suggests about your experimental design and randomization model. The primary plots may have been exchangeable units when either corn or soybean were seeded, but over the course of the season, may no have been exchangeable with regard to cover crop - that is, errors in application or germination may be different when seeding into corn vs soybeans. Perhaps there is an interaction with tillage?

Another issue you might be facing is the assumption of independence. Consider these:

data$wholeplot <- data$crop:data$rep
data$subplot <- data$wholeplot:data$tillage
data$residuals <- residuals(model1)
plot(residuals ~ rep,data=data)
plot(residuals ~ wholeplot,data=data)

There may be a spatial component that introduces correlations among the residuals, making the estimate of residual unreliable. You would need to consider your trial map. It might be possible to model a fixed effect spatial trend and continue with lmer; capturing residual correlations in two dimensions (i.e. AR1 x AR1), as far as I know, is only possible in R using AS-REML.


You most certainly will want to combine experiments, but for this post I?m limiting myself to a simpler discussion of computational options for mixed models in R. 

FWIW,  I presented some options for mixed model analysis of agricultural trials at one of the ASA/CSSA/SSSA meetings - see https://gdmdata.com/media/documents/handouts/2016ASA_RMixedModelsPresentation.pdf <https://gdmdata.com/media/documents/handouts/2016ASA_RMixedModelsPresentation.pdf> . I also gave a presentation on our current approach to spatial modeling - the presentation (https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD_Spatial.pdf <https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD_Spatial.pdf>) doesn?t include R code but there is supplementary material with literate documentation at https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD.zip <https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD.zip> . I left autocorrelated errors out of this presentation because I was unable to find an acceptable solution in lme. 

Cheers




> On Sep 9, 2019, at 6:05 PM, Rabin KC <kc000001 at umn.edu> wrote:
> 
> Dear Peter, 
> 
> Your reply has made my day and very clearly answered the questions I was asking myself for a few weeks. Thank you for correcting my mistakes as well. 
> 
> The lmer() does produce a variance of 0 for random effect (crop: rep). I now know the term is called boundary (singular) fit. What would be the correct thing to do in this case? I do have this experiment conducted for 2 years in 2 different locations, which might take care of the precious degrees of freedom, but again, will add new variables making the model more complicated. 
> 
> I ran an Anova II (wald test) and was thinking of doing post hoc analysis on significant terms. (If this would take care of singularity). Any advice on that would be greatly appreciated.
> 
> And yes, I am in Agronomy in U of M. I will be writing to you in your work email about the friendly statistician you mentioned!!!!
> 
> 
> Best regards, 
> Rabin
> 
> On Mon, Sep 9, 2019 at 4:43 PM Peter Claussen <dakotajudo at mac.com <mailto:dakotajudo at mac.com>> wrote:
> 
> 
>> On Sep 9, 2019, at 1:35 PM, Rabin KC <kc000001 at umn.edu <mailto:kc000001 at umn.edu>> wrote:
>> 
>> Hello R mixed models community,
>> 
>> ?
> 
>> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>> 
>> For my  analysis using lmer, and lme,  I have the following code:
>> 
>> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>> 
>> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>> 
>> Now my confusion and questions are:
>> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
>> (block) as random. Is the random effect properly assigned for this design?
> 
> Simply, no. 
> 
> When you have three levels of independent randomization, then your design model has three random effects
> 
> Consider the expected output from agricolae. There should be an error term for crop, as randomized within whole blocks, designated Ea. This is the crop x replicate interaction term, and would also be the residual error if you were to analyze these data as a simple RCB of 2 treatments and 4 replicates (averaging biomass over whole plots). The F-test you would use to test the significance of crop would be MS(crop) / Ea, while the F-test for replicate effects would be MS(rep)/Ea.
> 
> There will be a second error strata, representing the independent randomization of tillage within whole plots (replicate:crop). That should be labelled Eb. This would also be the residual error of a simple split-plot experiment with crop as whole plot and tillage as subplot treatments (averaging biomass over subplots) and would be represented as rep:crop:tillage. This is the error term to test tillage and crop-tillage interaction.
> 
> The final error strata is the independent randomization of cover within crop:tillage subplots, and this will work out to be equivalent to residual error. So, to duplicate the decomposition of the aov from agricolae, we might write the linear model as
> 
> lm(biomass ~ crop*tillage*cover + rep +  rep:crop + rep:crop:tillage, data=data)
> or, more briefly, as
> lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)
> 
> That won?t give the correct F-tests, though, so to get aov to perform appropriate tests, we should write
> 
> aov(biomass ~ crop*tillage*cover + rep + Error(rep:crop/tillage), data=data)
> 
> (not what you?ve written, since we test rep against rep:crop)
> 
> This leads to an lmer model of
> lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage), data=data)
> 
>> 
>> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
>> give particular examples about it, but I have trouble understanding if this
>> design has nested factors or crossed factors.
> 
> crop, tillage and cover are all crossed factors, since each possible combination of crop, tillage and cover are included, and you might be interested in the interactions among these factors. Since this is a split-split-plot experiment, the experimental units (rep:crop = whole plot, rep:crop:tillage=subplot, rep:crop:tillage:cover = sub subplot) are nested, and not all combinations of treatments are subject to the same experimental errors.
> 
> That?s where the analysis starts to become tricky. If you want to compare treatments that are all applied within same random effects, that is,
> 
> Crop A : Tillage A : Cover A vs Crop A : Tillage A : Cover B, 
> 
> then the error terms for mean comparisons are simple. Comparisons across strata, like
> 
> Crop A : Tillage A : Cover A vs Crop B : Tillage A : Cover A
> 
> require estimates of the variances for each level of error, and with only a few observations (Ea (crop:rep) should have only 3 d.f.) you might not get estimates from lmer, and error terms derived from aov might include negative variances. AOV of the linear model (lm) is useful here, in that if any of the F-ratios of the random effects (rep, rep:crop or rep:crop:tillage) are less than 1, then you should expect lmer to produce a variance estimate of effectively 0. I would need to write out the expected means squares for a split-split-plot, though, to justify this statement.
> 
> By your email address and the subject matter, I?m guessing you?re in agronomy at the U of M. If so, I can suggest a friendly neighborhood statistician to consult.
> 
> Cheers,
> 
> Peter Claussen 
> (work email Peter at gdmdata.com <mailto:Peter at gdmdata.com>)
> 


	[[alternative HTML version deleted]]


From d@kot@judo @end|ng |rom m@c@com  Tue Sep 17 17:44:16 2019
From: d@kot@judo @end|ng |rom m@c@com (Peter Claussen)
Date: Tue, 17 Sep 2019 10:44:16 -0500
Subject: [R-sig-ME] Can we analyse combined split plot experiment using
 lmer()?
In-Reply-To: <CANdRtHuW8TvO+ojspfn3bPdBYGMfeKvLQk-PiE3fu2OA-A4__A@mail.gmail.com>
References: <CANdRtHuW8TvO+ojspfn3bPdBYGMfeKvLQk-PiE3fu2OA-A4__A@mail.gmail.com>
Message-ID: <4DB5C3E7-5BB8-4A88-943C-3633276716CE@mac.com>

Rabin,

Was each combination of year and location and independent experiment? That is, were the main crops seeded independently, for each year and location, or were plantings on exactly the same day, with the same equipment, and using the same varieities?  Was the timing of in-season tillage the same for all locations or years? Were cover crops seeded at exactly the same stages, with the same seed sources and equipment?

Those are things that contribute to experimental error in the split-plot blocking structure. So, for a first pass, I would pool location and year as environment, and compare
lmer (biomass ~ environment*crop*tillage*cover+(1 | rep/crop/tillage), data=data)
lmer (biomass ~ environment*crop*tillage*cover+(environment | rep/crop/tillage), data=data)

The first model assumes homogeneity of experimental error across experiments, the second allows for independent errors, I think. 

If there are interactions between environments and treatments, then you may need to decompose the environments into years and location, and we can in theory assume some correlation among years and among locations, but you don?t really have enough samples to explore that in detail

Cheers,

> On Sep 12, 2019, at 10:48 PM, Rabin KC <kc000001 at umn.edu> wrote:
> 
> Hello community,
> 
> A few days ago, I posted about using lmer() to analyze a split split-plot
> design.
> The research design is as such:
> 
> I am interested in the response variable biomass of cover crops. I have the
> main plots as crops (corn and soybean). The subplot is tillage, which is
> randomized within the crops and has 3 levels (conventional-till, no-till,
> and strip-till). Within tillage(subplot), 3 cover crop strategies are
> randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
> treatments. The whole experiment is replicated 4 times, therefore, total
> experimental units equal to 72 units.
> 
> The experiment is conducted in 2 locations for 2 years, therefore total
> units equal to 288.
> 
> Now the model (as suggested by Peter Claussen in our community) for the
> experiment conducted each year and location is :
> 
> model <- lmer (biomass ~ crop*tillage*cover+(1|rep/crop/tillage),
> data=data)
> 
> The random-effects seem to be the split-plot error terms in the above model.
> 
> My question now is:
> 
> Now when I combine each year and location, how should I model this
> experiment. I am thinking about the following model:
> 
> model.all <- lmer (biomass ~location*
> crop*tillage*cover+(1|year/rep/crop/tillage), data=data)
> 
> Where location is a fixed effect and year is a random effect.
> 
> Does this above model actually work? Or should it be like follows:
> 
> model.all.1<- lmer (biomass ~ crop*tillage*cover+(1|year)+
> (1|rep/crop/tillage), data=data)
> 
> Also, I would be very grateful if someone would advise me if the
> assumptions of normality and constant variances apply for these lmer models?
> 
> Thank you,
> Rabin
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From kc000001 @end|ng |rom umn@edu  Tue Sep 17 17:55:56 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Tue, 17 Sep 2019 10:55:56 -0500
Subject: [R-sig-ME] Understanding and analysing split split design using
 lmer()
In-Reply-To: <A1568553-D5B6-4962-8507-6F72EE846BEC@mac.com>
References: <CANdRtHtUGoDTr9=adfvhtdDv3J=MBpBHunKZkWf2fO1YLED1KQ@mail.gmail.com>
 <777CDD01-DC7F-4CBB-B99F-2438EBB44D9B@mac.com>
 <CANdRtHuiozRc_kJ-Hqc1m_wnGom+rUPQY9FzcJTmv-b2JvAOrQ@mail.gmail.com>
 <A1568553-D5B6-4962-8507-6F72EE846BEC@mac.com>
Message-ID: <CANdRtHvCQ=PQwn-0y+u_oVp=LhveE4f_aRV0ZZKY0C9esqfv_Q@mail.gmail.com>

Dear Peter,

Thank you for your reply.

I was very concerned with the residual plots as you have advised. The
residual plots from the model [model1<- lmer(biomass ~
crop*tillage*cover+(1|rep/crop/tillage), data=data) look extremely
heteroskedastic. There is an outward coning of the residuals. I did a
square root transformation on the response and I feel it helped with the
residuals (no visual pattern of the residuals). As to combine years, just
as you mentioned, crops are rotated over the years. I did find a fine paper
in Soils and tillage research journal who have taken into account the
spatial variability from the rotation. That is what I am working on now,
and thanks for your help and guidance, learning about this is going to be
more fun and easier!

Thank you again,
Rabin

On Tue, Sep 17, 2019 at 10:24 AM Peter Claussen <dakotajudo at mac.com> wrote:

> Rabin,
>
> OK, finally getting back to this.
>
> A couple cases to consider that might be leading to a singular fit. The
> first should be, I think, the most obvious - you simply do not have enough
> samples from a random variable to obtain an estimate. If we can assume that
> your experimental replicates and whole plots sample over comparable spatial
> heterogeneity, then combining trials will give you more samples from those
> populations, thus perhaps a better estimate for whole pilot variance terms.
>
> The other is that your analysis model is incorrect for these experiments.
>
> Remember that one of the assumptions of AOV is that residual errors are
> independent and identically distributed. This assumption allows us to
> compute variances from expected mean squares. I would suggest
> https://dl.sciencesocieties.org/publications/aj/abstracts/81/4/AJ0810040665 for
> an example of how to write up the expected mean squares.
>
> We can compute variance components from mean squares, based on their
> expectations, but these usually dependent on an estimate of residual
> variance, and when residuals are not i.i.d., I think we get poor estimates
> of the other variance terms.
>
> To explore this, I considered the data you posted and fit the model
>
> model1 <-lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)
> par(mfrow=c(2,2))
> plot(model1)
>
> We might need to accept that the residuals are not i.i.d, i particular,
> that the errors variances are not comparable between corn and soybeans. In
> lmer, we might attempt to address this with
>
> model1.lmer <- lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage),
> data=data)
> model2.lmer <- lmer(biomass ~ crop*tillage*cover+(crop |
> rep/crop/tillage), data=data)
> plot(model1.lmer)
> plot(model2.lmer)
>
> There appears to be some improvement, at least with soybeans.
>
> You might consider what this suggests about your experimental design and
> randomization model. The primary plots may have been exchangeable units
> when either corn or soybean were seeded, but over the course of the season,
> may no have been exchangeable with regard to cover crop - that is, errors
> in application or germination may be different when seeding into corn vs
> soybeans. Perhaps there is an interaction with tillage?
>
> Another issue you might be facing is the assumption of independence.
> Consider these:
>
> data$wholeplot <- data$crop:data$rep
> data$subplot <- data$wholeplot:data$tillage
> data$residuals <- residuals(model1)
> plot(residuals ~ rep,data=data)
> plot(residuals ~ wholeplot,data=data)
>
> There may be a spatial component that introduces correlations among the
> residuals, making the estimate of residual unreliable. You would need to
> consider your trial map. It might be possible to model a fixed effect
> spatial trend and continue with lmer; capturing residual correlations in
> two dimensions (i.e. AR1 x AR1), as far as I know, is only possible in R
> using AS-REML.
>
>
> You most certainly will want to combine experiments, but for this post I?m
> limiting myself to a simpler discussion of computational options for mixed
> models in R.
>
> FWIW,  I presented some options for mixed model analysis of agricultural
> trials at one of the ASA/CSSA/SSSA meetings - see
> https://gdmdata.com/media/documents/handouts/2016ASA_RMixedModelsPresentation.pdf .
> I also gave a presentation on our current approach to spatial modeling -
> the presentation (
> https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD_Spatial.pdf)
> doesn?t include R code but there is supplementary material with literate
> documentation at
> https://gdmdata.com/media/documents/handouts/2017ASA_BeyondRCBD.zip . I
> left autocorrelated errors out of this presentation because I was unable to
> find an acceptable solution in lme.
>
> Cheers
>
>
>
>
> On Sep 9, 2019, at 6:05 PM, Rabin KC <kc000001 at umn.edu> wrote:
>
> Dear Peter,
>
> Your reply has made my day and very clearly answered the questions I was
> asking myself for a few weeks. Thank you for correcting my mistakes as
> well.
>
> The lmer() does produce a variance of 0 for random effect (crop: rep). I
> now know the term is called boundary (singular) fit. What would be the
> correct thing to do in this case? I do have this experiment conducted for 2
> years in 2 different locations, which might take care of the precious
> degrees of freedom, but again, will add new variables making the model more
> complicated.
>
> I ran an Anova II (wald test) and was thinking of doing post hoc analysis
> on significant terms. (If this would take care of singularity). Any advice
> on that would be greatly appreciated.
>
> And yes, I am in Agronomy in U of M. I will be writing to you in your work
> email about the friendly statistician you mentioned!!!!
>
>
> Best regards,
> Rabin
>
> On Mon, Sep 9, 2019 at 4:43 PM Peter Claussen <dakotajudo at mac.com> wrote:
>
>>
>>
>> On Sep 9, 2019, at 1:35 PM, Rabin KC <kc000001 at umn.edu> wrote:
>>
>> Hello R mixed models community,
>>
>> ?
>>
>>
>>
>> model1<aov(cover_coverage~rep+crop*tillage*cover+Error(rep/crop/tillage),data=data)
>>
>> For my  analysis using lmer, and lme,  I have the following code:
>>
>> model2<-lmer(biomass~crop*tillage*cover+ (1|rep),data=data)
>>
>> model3<-lme(fixed=biomass~crop*tillage*cover, data=data, random=~1|rep)
>>
>> Now my confusion and questions are:
>> 1. I have used crop, tillage, and cover as fixed effects. And only the rep
>> (block) as random. Is the random effect properly assigned for this design?
>>
>>
>> Simply, no.
>>
>> When you have three levels of independent randomization, then your design
>> model has three random effects
>>
>> Consider the expected output from agricolae. There should be an error
>> term for crop, as randomized within whole blocks, designated Ea. This is
>> the crop x replicate interaction term, and would also be the residual error
>> if you were to analyze these data as a simple RCB of 2 treatments and 4
>> replicates (averaging biomass over whole plots). The F-test you would use
>> to test the significance of crop would be MS(crop) / Ea, while the F-test
>> for replicate effects would be MS(rep)/Ea.
>>
>> There will be a second error strata, representing the independent
>> randomization of tillage within whole plots (replicate:crop). That should
>> be labelled Eb. This would also be the residual error of a simple
>> split-plot experiment with crop as whole plot and tillage as subplot
>> treatments (averaging biomass over subplots) and would be represented as
>> rep:crop:tillage. This is the error term to test tillage and crop-tillage
>> interaction.
>>
>> The final error strata is the independent randomization of cover within
>> crop:tillage subplots, and this will work out to be equivalent to residual
>> error. So, to duplicate the decomposition of the aov from agricolae, we
>> might write the linear model as
>>
>> lm(biomass ~ crop*tillage*cover + rep +  rep:crop + rep:crop:tillage,
>> data=data)
>> or, more briefly, as
>> lm(biomass ~ crop*tillage*cover + rep/crop/tillage,data=data)
>>
>> That won?t give the correct F-tests, though, so to get aov to perform
>> appropriate tests, we should write
>>
>> aov(biomass ~ crop*tillage*cover + rep + Error(rep:crop/tillage),
>> data=data)
>>
>> (not what you?ve written, since we test rep against rep:crop)
>>
>> This leads to an lmer model of
>> lmer(biomass ~ crop*tillage*cover+(1|rep/crop/tillage), data=data)
>>
>>
>> 2. I have read a lot about crossed and nested design. Crawley and Oehlert
>> give particular examples about it, but I have trouble understanding if
>> this
>> design has nested factors or crossed factors.
>>
>>
>> crop, tillage and cover are all crossed factors, since each possible
>> combination of crop, tillage and cover are included, and you might be
>> interested in the interactions among these factors. Since this is a
>> split-split-plot experiment, the experimental units (rep:crop = whole plot,
>> rep:crop:tillage=subplot, rep:crop:tillage:cover = sub subplot) are nested,
>> and not all combinations of treatments are subject to the same experimental
>> errors.
>>
>> That?s where the analysis starts to become tricky. If you want to compare
>> treatments that are all applied within same random effects, that is,
>>
>> Crop A : Tillage A : Cover A vs Crop A : Tillage A : Cover B,
>>
>> then the error terms for mean comparisons are simple. Comparisons across
>> strata, like
>>
>> Crop A : Tillage A : Cover A vs Crop B : Tillage A : Cover A
>>
>> require estimates of the variances for each level of error, and with only
>> a few observations (Ea (crop:rep) should have only 3 d.f.) you might not
>> get estimates from lmer, and error terms derived from aov might include
>> negative variances. AOV of the linear model (lm) is useful here, in that if
>> any of the F-ratios of the random effects (rep, rep:crop or
>> rep:crop:tillage) are less than 1, then you should expect lmer to produce a
>> variance estimate of effectively 0. I would need to write out the expected
>> means squares for a split-split-plot, though, to justify this statement.
>>
>> By your email address and the subject matter, I?m guessing you?re in
>> agronomy at the U of M. If so, I can suggest a friendly neighborhood
>> statistician to consult.
>>
>> Cheers,
>>
>> Peter Claussen
>> (work email Peter at gdmdata.com)
>>
>>
>

	[[alternative HTML version deleted]]


From kc000001 @end|ng |rom umn@edu  Tue Sep 17 18:11:29 2019
From: kc000001 @end|ng |rom umn@edu (Rabin KC)
Date: Tue, 17 Sep 2019 11:11:29 -0500
Subject: [R-sig-ME] Can we analyse combined split plot experiment using
 lmer()?
In-Reply-To: <4DB5C3E7-5BB8-4A88-943C-3633276716CE@mac.com>
References: <CANdRtHuW8TvO+ojspfn3bPdBYGMfeKvLQk-PiE3fu2OA-A4__A@mail.gmail.com>
 <4DB5C3E7-5BB8-4A88-943C-3633276716CE@mac.com>
Message-ID: <CANdRtHurYTO_98WCfRBtL_6DbNAsE+iP6i0YFoHoLbbYjpaS_w@mail.gmail.com>

Dear Peter,

The experiments in each year and location were independent of each other.
The equipment used for planting were different for each location (same
variety). Cover crops were seeded at the physiological maturity of primary
crops in each location, using the same seeding methods.

Thank you,
Rabin

On Tue, Sep 17, 2019 at 10:44 AM Peter Claussen <dakotajudo at mac.com> wrote:

> Rabin,
>
> Was each combination of year and location and independent experiment? That
> is, were the main crops seeded independently, for each year and location,
> or were plantings on exactly the same day, with the same equipment, and
> using the same varieities?  Was the timing of in-season tillage the same
> for all locations or years? Were cover crops seeded at exactly the same
> stages, with the same seed sources and equipment?
>
> Those are things that contribute to experimental error in the split-plot
> blocking structure. So, for a first pass, I would pool location and year as
> environment, and compare
> lmer (biomass ~ environment*crop*tillage*cover+(1 | rep/crop/tillage),
> data=data)
> lmer (biomass ~ environment*crop*tillage*cover+(environment |
> rep/crop/tillage), data=data)
>
> The first model assumes homogeneity of experimental error across
> experiments, the second allows for independent errors, I think.
>
> If there are interactions between environments and treatments, then you
> may need to decompose the environments into years and location, and we can
> in theory assume some correlation among years and among locations, but you
> don?t really have enough samples to explore that in detail
>
> Cheers,
>
> > On Sep 12, 2019, at 10:48 PM, Rabin KC <kc000001 at umn.edu> wrote:
> >
> > Hello community,
> >
> > A few days ago, I posted about using lmer() to analyze a split split-plot
> > design.
> > The research design is as such:
> >
> > I am interested in the response variable biomass of cover crops. I have
> the
> > main plots as crops (corn and soybean). The subplot is tillage, which is
> > randomized within the crops and has 3 levels (conventional-till, no-till,
> > and strip-till). Within tillage(subplot), 3 cover crop strategies are
> > randomly assigned (AR, ARCC, ARCCFR). Therefore 1 rep (block) has 18
> > treatments. The whole experiment is replicated 4 times, therefore, total
> > experimental units equal to 72 units.
> >
> > The experiment is conducted in 2 locations for 2 years, therefore total
> > units equal to 288.
> >
> > Now the model (as suggested by Peter Claussen in our community) for the
> > experiment conducted each year and location is :
> >
> > model <- lmer (biomass ~ crop*tillage*cover+(1|rep/crop/tillage),
> > data=data)
> >
> > The random-effects seem to be the split-plot error terms in the above
> model.
> >
> > My question now is:
> >
> > Now when I combine each year and location, how should I model this
> > experiment. I am thinking about the following model:
> >
> > model.all <- lmer (biomass ~location*
> > crop*tillage*cover+(1|year/rep/crop/tillage), data=data)
> >
> > Where location is a fixed effect and year is a random effect.
> >
> > Does this above model actually work? Or should it be like follows:
> >
> > model.all.1<- lmer (biomass ~ crop*tillage*cover+(1|year)+
> > (1|rep/crop/tillage), data=data)
> >
> > Also, I would be very grateful if someone would advise me if the
> > assumptions of normality and constant variances apply for these lmer
> models?
> >
> > Thank you,
> > Rabin
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Wed Sep 25 13:33:46 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Wed, 25 Sep 2019 13:33:46 +0200
Subject: [R-sig-ME] Export several lme outputs to a single excel file
Message-ID: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>

Dear users,
it is not such an statistical question but how to export results
I fit several *lme* model s and I know how can I export the data to excel,
this way:
lme1 <- lme(Mean ~ x*y, data = Data, random = ~ 1|factor(ID))
anova(lme1)->resultslme1
And to export to excel since keep the data in ordered in rows/columns
write.xlsx( resultslme1  ,"C:/Users/Desktop/resultslme1.xlsx")

What I want to do is to export output from several lme at the same time,
and adding the name/reference of the model. Something like this
lme1
  numDF denDF F.value p.value
(Intercept) 1 78 653,6152 0
x 2 78 0,822612 0,443057
y 2 39 0,479357 0,622781
x:y 4 78 2,593825 0,042787

lme2
  numDF denDF F.value p.value
(Intercept) 1 78 653,6152 0
x 2 78 0,822612 0,443057
y 2 39 0,479357 0,622781
x:y 4 78 2,593825 0,042787


I tried with merge, abind, paste,... but I did not find the solution

Thanks in advance

-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Wed Sep 25 22:55:48 2019
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Wed, 25 Sep 2019 22:55:48 +0200
Subject: [R-sig-ME] Export several lme outputs to a single excel file
In-Reply-To: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>
References: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>
Message-ID: <20190925205548.GF22724@info124.pharmacie.univ-paris5.fr>

Dear Mario,

Since anova( ) results are basically data.frames, a simple way could
be to add a column to identify the model, then row-bind the results.

Something like (using examples in the lme man page)

# First model
fm1 <- lme(distance ~ age, data = Orthodont)
anova( fm1 ) -> r1
r1$Md <- 1

# Second model
fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)
anova( fm2 ) -> r2
r2$Md <- 2

# Bind results
r <- rbind( r1, r2 )

# Export
write.xlsx( r, "your_file.xlsx" )

For more model, can be adapted with do.call( rbind, list_of_results)
and either a for or lapply to generate the additional
columns... Depends on how you obtain your several models.

Best regards,

NB: note that, to avoid duplicate row names, terms with the same name
will be incremented - see the results of the example above.  You can
avoid this by explicely add the term names in the data.frame ---
r1$Terms <- rownames( r1 ) --- and removing the row names of the final
result.


On Wed, Sep 25, 2019 at 01:33:46PM +0200, Mario Garrido wrote:
? Dear users,
? it is not such an statistical question but how to export results
? I fit several *lme* model s and I know how can I export the data to excel,
? this way:
? lme1 <- lme(Mean ~ x*y, data = Data, random = ~ 1|factor(ID))
? anova(lme1)->resultslme1
? And to export to excel since keep the data in ordered in rows/columns
? write.xlsx( resultslme1  ,"C:/Users/Desktop/resultslme1.xlsx")
? 
? What I want to do is to export output from several lme at the same time,
? and adding the name/reference of the model. Something like this
? lme1
?   numDF denDF F.value p.value
? (Intercept) 1 78 653,6152 0
? x 2 78 0,822612 0,443057
? y 2 39 0,479357 0,622781
? x:y 4 78 2,593825 0,042787
? 
? lme2
?   numDF denDF F.value p.value
? (Intercept) 1 78 653,6152 0
? x 2 78 0,822612 0,443057
? y 2 39 0,479357 0,622781
? x:y 4 78 2,593825 0,042787
? 
? 
? I tried with merge, abind, paste,... but I did not find the solution
? 
? Thanks in advance
? 
? -- 
? Mario Garrido Escudero, PhD
? Dr. Hadas Hawlena Lab
? Mitrani Department of Desert Ecology
? Jacob Blaustein Institutes for Desert Research
? Ben-Gurion University of the Negev
? Midreshet Ben-Gurion 84990 ISRAEL
? 
? gaiarrido at gmail.com; gaadio at post.bgu.ac.il
? phone: (+972) 08-659-6854
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From hou@|@y @end|ng |rom gm@||@com  Fri Sep 27 17:11:25 2019
From: hou@|@y @end|ng |rom gm@||@com (Tom Houslay)
Date: Fri, 27 Sep 2019 16:11:25 +0100
Subject: [R-sig-ME] 
 MCMCglmm predict failing with more than one fixed effect
Message-ID: <CAErKyRphAbYo0j5Qivd3E-12UKhaHLMmKNqGXN7mJ=b+BLQUkg@mail.gmail.com>

Hi all,

Just closing the open question I had in case anyone else has had the same
issue using predict.MCMCglmm. Turns out that it didn't seem to like
predicting with a single value in any of the fixed effect terms - so even
if I just want to predict for a single value of something, I just have to
add in another value and then ignore those rows afterwards. I've appended a
little bit to the reproducible code from my last email to show how that's
working (see below).

Cheers

Tom

---

sleepstudy <- lme4::sleepstudy

# Basic model of sleepstudy with 1 fixed effect and simple random intercept
mcmc_ss_1 <- MCMCglmm(Reaction ~ Days,
                      random =~ Subject,
                      data = sleepstudy)

summary(mcmc_ss_1)

# Predicts fine on original data
predict(mcmc_ss_1)

# Create data on which to predict
df_ss_pred <- data.frame(Days = 0:9,
                         Subject = 350,
                         Reaction = 0)

# This prediction works
predict(mcmc_ss_1,
        newdata = df_ss_pred)

# Create new data frame with fake additional column
sleepstudy_2 <- cbind(sleepstudy,
                      extra = rnorm(nrow(sleepstudy)))

# Run model with additional fixed effect
mcmc_ss_2 <- MCMCglmm(Reaction ~ Days + extra,
                      random =~ Subject,
                      data = sleepstudy_2)

summary(mcmc_ss_2)

# Predict works fine from original data
predict(mcmc_ss_2)

# Create data frame on which to predict,
#  as before but now with new column added
df_ss_pred_2 <- as.data.frame(expand.grid(Reaction = 0,
                                          Days = 0:9,
                                          Subject = 350,
                                          extra = mean(sleepstudy_2$extra)))

# Prediction fails
predict(mcmc_ss_2,
        newdata = df_ss_pred_2)

# Check model formula
mcmc_ss_2$Fixed$formula

# Check variable names in data frame
str(sleepstudy_2)

# Check variable names in new data frame
str(df_ss_pred_2)


# Try adding another value for 'extra'
df_ss_pred_3 <- as.data.frame(expand.grid(Reaction = 0,
                                          Days = 0:9,
                                          Subject = 350,
                                          extra =
c(mean(sleepstudy_2$extra),

mean(sleepstudy_2$extra) + sd(sleepstudy_2$extra))))


# Prediction now works!
predict(mcmc_ss_2,
        newdata = df_ss_pred_3)

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom uc@d@edu  Sat Sep 28 01:05:03 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Fri, 27 Sep 2019 23:05:03 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
Message-ID: <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>

I?m confused. So I?ve added race to my current model (see below).

I?ve made race (latino, white, black, asian, two or more races) into percents for each city/town, such that I have five values for each city/town for each year (2003-2017). I?ve gathered the five variables into the one column ?race? and the values containing the percents into another column named ?per_race.?

This is the way that I?ve structured my model to include race:

lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race + (year|PLACE_ID / race) + (1|COUNTY_ID) + (1|STATE), control = lmerControl(optimizer="Nelder_Mead"), na.action = 'na.omit', dat, REML = FALSE)

In the current model, I am only getting one value of race as a regression coefficient ?per_race.? It seems that race would also need to be a fixed effect. How do I restructure my model to receive all five race values as regression coefficients? Would I need to include race as an interaction between per_race and race? ( lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race*race + (year |PLACE_ID/race) + ( 1|COUNTY_ID) + (1| STATE) ) This doesn?t seem right.

I?ve uploaded the data here: https://drive.google.com/file/d/1oKMpjnh2Y-ONvYufcX5MxF6WKMBw58YO/view?usp=sharing

Thanks much!

James



On Sep 10, 2019, at 5:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Not centring year would require a much stronger random intercept. This makes the model harder to fit. It will change the random intercept variance and the correlation between random intercept and random slope. In theory it shouldn't change the estimates for the fixed effects. But if your model is unstable / doesn't converge, then how certain can you be on those estimates.

I don't know of any rule of thumb about the overlap in partially crosses designs. If the model doesn't converge then see how you can simplify it. E.g. if your model has county_id, then you could drop the state_id as the county will model any effect at state level (if state level is not in the model).

I wrote a blogpost on using the same variable both as fixed and as random effect: https://www.muscardinus.be/2017/08/fixed-and-random/ One of the examples uses year as a random intercept.

We've used the INLA package (r-inla.org<http://r-inla.org/>) to model the gamma distribution.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op di 10 sep. 2019 om 08:51 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
Thanks for the comment to center the year variable. I hadn?t thought about that, and I changed my model to incorporate a centered year. Just wondering?would I be right in saying that while centering the year might affect convergence, and the interpretation of the intercept as the average city in an average year, it wouldn?t affect the coefficient estimates?

I have a model where education spending is averaged (when one city attends multiple school districts) to do away with district_id. That model does run. But you?re doubtful that the mixed-effect model could handle the crossed effects given the large overlap of district_id and city? Is there any rule of thumb for when a crossed effects model can be used vs when a variable must be averaged?or is it merely that if it converges then it converges?

I use year as fixed-effect in my non-null model. Your other suggestion is to possibly add year as a random intercept. Wouldn?t these two choices ultimately be looking at different things?

Thanks for the gamma suggestion. Are you suggesting using a gamma distribution in glmer? Does the gamma distribution in glmer default to the Erlang distribution? Would that still have to be as a rate rather than a discrete variable, and in that case, how would that vary from fitting the model in lmer with crime as a rate and getting rid of population as a fixed effect?

Much thanks, Thierry et al.!

James


With regard to Douglas? question, I should?ve replied all, but here was my answer:

Especially in the early ?00s crime was offered as two datasets?one on metropolitan/city areas with population > 10,000 and the other as population < 10,000. For 2004, the only data available is the dataset for cities > 10,000. I?ve contacted the FBI regarding whether they can track down the corresponding <10,000 dataset; they?re looking into it.



On Sep 9, 2019, at 2:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Since all ID's are unique, you can rely on the implicit nesting of random effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) + (1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).

There is a huge overlap between PLACE_ID and full_district_id. The model will have a hard time separating both effects. Especially since you have the same random slope.

You should also center the year variable. Now your model is estimating the random intercept at year 0.

So in terms of basic model I would

- drop either PLACE_ID or full_district_id
- center year
- add year to the fixed effects or add it as a separate random intercept

Furthermore, I'm not sure it the Poisson distribution is the most relevant distribution for your response. I've seen a case were the Poisson distribution failed. The response was an area in hectares rounded to an integer value. The model fitted well with a Gamma distribution.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
Okay, sorry for the delay; I was waiting to hear back from a couple people at the census regarding a question on school district info in the dataset.

I?ve  uploaded the dataset as a zip and an xs:
https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing

There is one important thing to note, here, which is that there is more city overlap between counties than I thought. The easiest way to explain this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID, year), you should get 107,515; however, with distinct(PLACE_ID, year), you?ll only get 99,832. So essentially, there are ~8000 times that a city will overlap in two counties (this likely includes the same city repeating this overlap every year?though it all depends on what years the city/town police department reports crime to the FBI). I can figure out the respective populations in each of the two counties where the city overlaps. It?s a bit of leg work, but it is possible. Still, it seems that it would not be principled to include the city/town in both counties because there would be the assumption that the crime occurring in each corresponding county is tied solely to population. Still, I left in all cities/towns overlapping with two counties, in case you have some ideas about how a mixed-model might be used to account for these (I don?t think a crossed-effect structure would do it). So pretty much any city with duplicate values where that value lies within the same county should be counted (these are just separate school districts), but any city with duplicate values where one of those values happens to be in another county, yet the school district is still the same, shouldn't be counted; unless, of course, there is a way for mixed-modeling in lme4 to account for that (PLACE_ID will be the same, but COUNTY_ID will be different, but full_district_id will be the same). Does that make sense? I'll soon send an email to the group with more clarification.

Use IDs vs names. I included names for reference, but city/towns might not always be recorded exactly the same, so IDs are the safer bet.

I have tried lmer?originally, my intention was to preserve counts of zero crime (whether it?s weariness or sanity that has changed my view, the difference between one and zero doesn?t seem so important anymore. I get the boundary (singular) warning (if a warning is what it can be called). No doubt there are many here that know more than me, but my understanding of this message is that it mostly warns against overfitting. To me, controlling for time through a fixed effect and as a random slope seems warranted?different cities/towns have different rates of change in crime from year to year.

I still think fitting with glmer would be ideal, but I also lack an understanding of the nuances on the backend with regard to how the two functions differ. It seems that lmer is faster and more efficient in modeling, though I?m not sure why?mathematically or programmatically?that?s the case. If you can point me to an explanation, I?d appreciate that.

Thanks much for your messages and your help.

James


On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear James,

Your mail contains only a part of the dput() output. Given the size of your data, I suggest that you place it somewhere online and send us a link to the data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.

I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)

Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).

I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")

Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.

First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).

I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:

```
Error in getOptfun(optimizer) :
  optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
```

Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
optCtrl = list(method = "nlminb?,
maxit=10000,
iter.max=10000,
eval.max=10000,
lower = c(0,0,0),
upper = c(Inf,10,1)))

and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\

```
Warning messages:
1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
```

I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.

I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.

I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.

Thanks!



231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
"0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
"0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
"0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
"0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
"0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
"0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
"0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
"0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
"0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
"0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
"0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
"0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
"0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
"0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
"0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
"0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
"0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
"0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
"0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
"0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
"0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
"0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
), COUNTY = c("autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "la paz county", "la paz county",
"la paz county", "la paz county", "la paz county", "la paz county",
"la paz county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04012",
"04012", "04012", "04012", "04012", "04012", "04012", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "St. Johns Unified District",
"St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
"St. Johns Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring Schools",
"Mammoth Spring Schools", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "Bryant Public Schools", "Bryant Public Schools",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District"), EXPENDITURE_PER_STUDENT = c(5.2927293064877,
5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
-800L), class = c("tbl_df", "tbl", "data.frame"))


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Sep 28 04:14:30 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 27 Sep 2019 22:14:30 -0400
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
Message-ID: <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>

I'm having trouble reading this file - it's 50MB to start with, my
Linux system thinks it's gzipped ("gzip compressed data"), then when I
un-gzip it I get a 100+MB file that it thinks is "data" (which just
means "binary file I don't understand").  Is there any way you can
make a **much smaller** reproducible example for us to inspect??

  I think the answer to your proximal question about per_race is that
you would need five *different* numerical variables, one for each
race-percentage. However, you can't/shouldn't actually use all five,
since they will be multicollinear (since the sum of all five will be 1
or 100 (or however you've scaled the total).

  Also: I wouldn't recommend Nelder-Mead, it's probably the slowest
and least reliable option ...

On Fri, Sep 27, 2019 at 7:05 PM Ades, James <jades at ucsd.edu> wrote:
>
> I?m confused. So I?ve added race to my current model (see below).
>
> I?ve made race (latino, white, black, asian, two or more races) into percents for each city/town, such that I have five values for each city/town for each year (2003-2017). I?ve gathered the five variables into the one column ?race? and the values containing the percents into another column named ?per_race.?
>
> This is the way that I?ve structured my model to include race:
>
> lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race + (year|PLACE_ID / race) + (1|COUNTY_ID) + (1|STATE), control = lmerControl(optimizer="Nelder_Mead"), na.action = 'na.omit', dat, REML = FALSE)
>
> In the current model, I am only getting one value of race as a regression coefficient ?per_race.? It seems that race would also need to be a fixed effect. How do I restructure my model to receive all five race values as regression coefficients? Would I need to include race as an interaction between per_race and race? ( lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race*race + (year |PLACE_ID/race) + ( 1|COUNTY_ID) + (1| STATE) ) This doesn?t seem right.
>
> I?ve uploaded the data here: https://drive.google.com/file/d/1oKMpjnh2Y-ONvYufcX5MxF6WKMBw58YO/view?usp=sharing
>
> Thanks much!
>
> James
>
>
>
> On Sep 10, 2019, at 5:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>
> Dear James,
>
> Not centring year would require a much stronger random intercept. This makes the model harder to fit. It will change the random intercept variance and the correlation between random intercept and random slope. In theory it shouldn't change the estimates for the fixed effects. But if your model is unstable / doesn't converge, then how certain can you be on those estimates.
>
> I don't know of any rule of thumb about the overlap in partially crosses designs. If the model doesn't converge then see how you can simplify it. E.g. if your model has county_id, then you could drop the state_id as the county will model any effect at state level (if state level is not in the model).
>
> I wrote a blogpost on using the same variable both as fixed and as random effect: https://www.muscardinus.be/2017/08/fixed-and-random/ One of the examples uses year as a random intercept.
>
> We've used the INLA package (r-inla.org<http://r-inla.org/>) to model the gamma distribution.
>
> Best regards,
>
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be<http://www.inbo.be/>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>
>
> Op di 10 sep. 2019 om 08:51 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
> Thanks for the comment to center the year variable. I hadn?t thought about that, and I changed my model to incorporate a centered year. Just wondering?would I be right in saying that while centering the year might affect convergence, and the interpretation of the intercept as the average city in an average year, it wouldn?t affect the coefficient estimates?
>
> I have a model where education spending is averaged (when one city attends multiple school districts) to do away with district_id. That model does run. But you?re doubtful that the mixed-effect model could handle the crossed effects given the large overlap of district_id and city? Is there any rule of thumb for when a crossed effects model can be used vs when a variable must be averaged?or is it merely that if it converges then it converges?
>
> I use year as fixed-effect in my non-null model. Your other suggestion is to possibly add year as a random intercept. Wouldn?t these two choices ultimately be looking at different things?
>
> Thanks for the gamma suggestion. Are you suggesting using a gamma distribution in glmer? Does the gamma distribution in glmer default to the Erlang distribution? Would that still have to be as a rate rather than a discrete variable, and in that case, how would that vary from fitting the model in lmer with crime as a rate and getting rid of population as a fixed effect?
>
> Much thanks, Thierry et al.!
>
> James
>
>
> With regard to Douglas? question, I should?ve replied all, but here was my answer:
>
> Especially in the early ?00s crime was offered as two datasets?one on metropolitan/city areas with population > 10,000 and the other as population < 10,000. For 2004, the only data available is the dataset for cities > 10,000. I?ve contacted the FBI regarding whether they can track down the corresponding <10,000 dataset; they?re looking into it.
>
>
>
> On Sep 9, 2019, at 2:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>
> Dear James,
>
> Since all ID's are unique, you can rely on the implicit nesting of random effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) + (1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).
>
> There is a huge overlap between PLACE_ID and full_district_id. The model will have a hard time separating both effects. Especially since you have the same random slope.
>
> You should also center the year variable. Now your model is estimating the random intercept at year 0.
>
> So in terms of basic model I would
>
> - drop either PLACE_ID or full_district_id
> - center year
> - add year to the fixed effects or add it as a separate random intercept
>
> Furthermore, I'm not sure it the Poisson distribution is the most relevant distribution for your response. I've seen a case were the Poisson distribution failed. The response was an area in hectares rounded to an integer value. The model fitted well with a Gamma distribution.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be<http://www.inbo.be/>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>
>
> Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
> Okay, sorry for the delay; I was waiting to hear back from a couple people at the census regarding a question on school district info in the dataset.
>
> I?ve  uploaded the dataset as a zip and an xs:
> https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
> https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing
>
> There is one important thing to note, here, which is that there is more city overlap between counties than I thought. The easiest way to explain this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID, year), you should get 107,515; however, with distinct(PLACE_ID, year), you?ll only get 99,832. So essentially, there are ~8000 times that a city will overlap in two counties (this likely includes the same city repeating this overlap every year?though it all depends on what years the city/town police department reports crime to the FBI). I can figure out the respective populations in each of the two counties where the city overlaps. It?s a bit of leg work, but it is possible. Still, it seems that it would not be principled to include the city/town in both counties because there would be the assumption that the crime occurring in each corresponding county is tied solely to population. Still, I left in all cities/towns overlapping with two counties, in case you have some ideas about how a mixed-model might be used to account for these (I don?t think a crossed-effect structure would do it). So pretty much any city with duplicate values where that value lies within the same county should be counted (these are just separate school districts), but any city with duplicate values where one of those values happens to be in another county, yet the school district is still the same, shouldn't be counted; unless, of course, there is a way for mixed-modeling in lme4 to account for that (PLACE_ID will be the same, but COUNTY_ID will be different, but full_district_id will be the same). Does that make sense? I'll soon send an email to the group with more clarification.
>
> Use IDs vs names. I included names for reference, but city/towns might not always be recorded exactly the same, so IDs are the safer bet.
>
> I have tried lmer?originally, my intention was to preserve counts of zero crime (whether it?s weariness or sanity that has changed my view, the difference between one and zero doesn?t seem so important anymore. I get the boundary (singular) warning (if a warning is what it can be called). No doubt there are many here that know more than me, but my understanding of this message is that it mostly warns against overfitting. To me, controlling for time through a fixed effect and as a random slope seems warranted?different cities/towns have different rates of change in crime from year to year.
>
> I still think fitting with glmer would be ideal, but I also lack an understanding of the nuances on the backend with regard to how the two functions differ. It seems that lmer is faster and more efficient in modeling, though I?m not sure why?mathematically or programmatically?that?s the case. If you can point me to an explanation, I?d appreciate that.
>
> Thanks much for your messages and your help.
>
> James
>
>
> On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>
> Dear James,
>
> Your mail contains only a part of the dput() output. Given the size of your data, I suggest that you place it somewhere online and send us a link to the data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be<http://www.inbo.be/>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>
>
> Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
> I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.
>
> I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)
>
> Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).
>
> I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")
>
> Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.
>
> First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).
>
> I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:
>
> ```
> Error in getOptfun(optimizer) :
>   optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
> ```
>
> Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
> optCtrl = list(method = "nlminb?,
> maxit=10000,
> iter.max=10000,
> eval.max=10000,
> lower = c(0,0,0),
> upper = c(Inf,10,1)))
>
> and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\
>
> ```
> Warning messages:
> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> ```
>
> I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.
>
> I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.
>
> I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.
>
> Thanks!
>
>
>
> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
> ), COUNTY = c("autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "la paz county", "la paz county",
> "la paz county", "la paz county", "la paz county", "la paz county",
> "la paz county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "St. Johns Unified District",
> "St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
> "St. Johns Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
> "Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
> "Williams Unified District", "Williams Unified District", "Williams Unified District",
> "Williams Unified District", "Williams Unified District", "Williams Unified District",
> "Williams Unified District", "Williams Unified District", "Williams Unified District",
> "Williams Unified District", "Globe Unified District", "Miami Unified District",
> "Globe Unified District", "Miami Unified District", "Globe Unified District",
> "Miami Unified District", "Globe Unified District", "Miami Unified District",
> "Globe Unified District", "Miami Unified District", "Globe Unified District",
> "Miami Unified District", "Globe Unified District", "Miami Unified District",
> "Globe Unified District", "Miami Unified District", "Globe Unified District",
> "Miami Unified District", "Globe Unified District", "Miami Unified District",
> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified District",
> "Miami Unified District", "Payson Unified District", "Payson Unified District",
> "Payson Unified District", "Payson Unified District", "Payson Unified District",
> "Payson Unified District", "Payson Unified District", "Payson Unified District",
> "Payson Unified District", "Payson Unified District", "Payson Unified District",
> "Payson Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
> "Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
> "Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School District",
> "North Little Rock School District", "Pulaski County Special School District",
> "North Little Rock School District", "Pulaski County Special School District


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 28 17:09:34 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 28 Sep 2019 17:09:34 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
Message-ID: <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>

Despite the extension, it's not a CSV file, it's RData which R does
actually zip depending on the options you passed -- readRDS() works.

@Ben: there's a null byte in there, which is why your system
(rightfully) though it was a binary data file.

Ben's and Thierry's comments cover all the other issues, I think.

My advice would to be ignore the random effects bit for a little while
and think about how you would structure your fixed effects for a plain
lm() so that you can answer the inferential questions you care about.
After that, I would come back to the random effects. State, county and
place all seem like fine blocking variables, but nesting race within
place really doesn't make sense for you current fixed-effects structure.?

Looking at the dataframe, I also have the strong suspicion that it's not
quite structured how you think it is. Right now, per_race is a single
column, which means you have each observation repeated five times for
each race. (This ties into Ben's second comment.)

Phillip

On 28/09/2019 04:14, Ben Bolker wrote:
> I'm having trouble reading this file - it's 50MB to start with, my
> Linux system thinks it's gzipped ("gzip compressed data"), then when I
> un-gzip it I get a 100+MB file that it thinks is "data" (which just
> means "binary file I don't understand").  Is there any way you can
> make a **much smaller** reproducible example for us to inspect??
>
>   I think the answer to your proximal question about per_race is that
> you would need five *different* numerical variables, one for each
> race-percentage. However, you can't/shouldn't actually use all five,
> since they will be multicollinear (since the sum of all five will be 1
> or 100 (or however you've scaled the total).
>
>   Also: I wouldn't recommend Nelder-Mead, it's probably the slowest
> and least reliable option ...
>
> On Fri, Sep 27, 2019 at 7:05 PM Ades, James <jades at ucsd.edu> wrote:
>> I?m confused. So I?ve added race to my current model (see below).
>>
>> I?ve made race (latino, white, black, asian, two or more races) into percents for each city/town, such that I have five values for each city/town for each year (2003-2017). I?ve gathered the five variables into the one column ?race? and the values containing the percents into another column named ?per_race.?
>>
>> This is the way that I?ve structured my model to include race:
>>
>> lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race + (year|PLACE_ID / race) + (1|COUNTY_ID) + (1|STATE), control = lmerControl(optimizer="Nelder_Mead"), na.action = 'na.omit', dat, REML = FALSE)
>>
>> In the current model, I am only getting one value of race as a regression coefficient ?per_race.? It seems that race would also need to be a fixed effect. How do I restructure my model to receive all five race values as regression coefficients? Would I need to include race as an interaction between per_race and race? ( lmer(log(CRIME_TOTAL + 1) ~ year + cent.log.pop + cent.log.pop.dens + per_race*race + (year |PLACE_ID/race) + ( 1|COUNTY_ID) + (1| STATE) ) This doesn?t seem right.
>>
>> I?ve uploaded the data here: https://drive.google.com/file/d/1oKMpjnh2Y-ONvYufcX5MxF6WKMBw58YO/view?usp=sharing
>>
>> Thanks much!
>>
>> James
>>
>>
>>
>> On Sep 10, 2019, at 5:45 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>>
>> Dear James,
>>
>> Not centring year would require a much stronger random intercept. This makes the model harder to fit. It will change the random intercept variance and the correlation between random intercept and random slope. In theory it shouldn't change the estimates for the fixed effects. But if your model is unstable / doesn't converge, then how certain can you be on those estimates.
>>
>> I don't know of any rule of thumb about the overlap in partially crosses designs. If the model doesn't converge then see how you can simplify it. E.g. if your model has county_id, then you could drop the state_id as the county will model any effect at state level (if state level is not in the model).
>>
>> I wrote a blogpost on using the same variable both as fixed and as random effect: https://www.muscardinus.be/2017/08/fixed-and-random/ One of the examples uses year as a random intercept.
>>
>> We've used the INLA package (r-inla.org<http://r-inla.org/>) to model the gamma distribution.
>>
>> Best regards,
>>
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be<http://www.inbo.be/>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>>
>>
>> Op di 10 sep. 2019 om 08:51 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
>> Thanks for the comment to center the year variable. I hadn?t thought about that, and I changed my model to incorporate a centered year. Just wondering?would I be right in saying that while centering the year might affect convergence, and the interpretation of the intercept as the average city in an average year, it wouldn?t affect the coefficient estimates?
>>
>> I have a model where education spending is averaged (when one city attends multiple school districts) to do away with district_id. That model does run. But you?re doubtful that the mixed-effect model could handle the crossed effects given the large overlap of district_id and city? Is there any rule of thumb for when a crossed effects model can be used vs when a variable must be averaged?or is it merely that if it converges then it converges?
>>
>> I use year as fixed-effect in my non-null model. Your other suggestion is to possibly add year as a random intercept. Wouldn?t these two choices ultimately be looking at different things?
>>
>> Thanks for the gamma suggestion. Are you suggesting using a gamma distribution in glmer? Does the gamma distribution in glmer default to the Erlang distribution? Would that still have to be as a rate rather than a discrete variable, and in that case, how would that vary from fitting the model in lmer with crime as a rate and getting rid of population as a fixed effect?
>>
>> Much thanks, Thierry et al.!
>>
>> James
>>
>>
>> With regard to Douglas? question, I should?ve replied all, but here was my answer:
>>
>> Especially in the early ?00s crime was offered as two datasets?one on metropolitan/city areas with population > 10,000 and the other as population < 10,000. For 2004, the only data available is the dataset for cities > 10,000. I?ve contacted the FBI regarding whether they can track down the corresponding <10,000 dataset; they?re looking into it.
>>
>>
>>
>> On Sep 9, 2019, at 2:58 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>>
>> Dear James,
>>
>> Since all ID's are unique, you can rely on the implicit nesting of random effects. (1|STATE_ID/COUNTY_ID) is equivalent to (1|STATE_ID) + (1|COUNTY_ID) when each COUNTY_ID is unique (not reused among states).
>>
>> There is a huge overlap between PLACE_ID and full_district_id. The model will have a hard time separating both effects. Especially since you have the same random slope.
>>
>> You should also center the year variable. Now your model is estimating the random intercept at year 0.
>>
>> So in terms of basic model I would
>>
>> - drop either PLACE_ID or full_district_id
>> - center year
>> - add year to the fixed effects or add it as a separate random intercept
>>
>> Furthermore, I'm not sure it the Poisson distribution is the most relevant distribution for your response. I've seen a case were the Poisson distribution failed. The response was an area in hectares rounded to an integer value. The model fitted well with a Gamma distribution.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be<http://www.inbo.be/>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>>
>>
>> Op zo 8 sep. 2019 om 07:40 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
>> Okay, sorry for the delay; I was waiting to hear back from a couple people at the census regarding a question on school district info in the dataset.
>>
>> I?ve  uploaded the dataset as a zip and an xs:
>> https://drive.google.com/file/d/1hyJYVg0x_-dIHfZdjWzdRuQS_H365buK/view?usp=sharing
>> https://drive.google.com/file/d/1qKU7vvzsqzrD58lcu6HWlMALwy4mm6RF/view?usp=sharing
>>
>> There is one important thing to note, here, which is that there is more city overlap between counties than I thought. The easiest way to explain this is by checking distinct values: using distinct(PLACE_ID, COUNTY_ID, year), you should get 107,515; however, with distinct(PLACE_ID, year), you?ll only get 99,832. So essentially, there are ~8000 times that a city will overlap in two counties (this likely includes the same city repeating this overlap every year?though it all depends on what years the city/town police department reports crime to the FBI). I can figure out the respective populations in each of the two counties where the city overlaps. It?s a bit of leg work, but it is possible. Still, it seems that it would not be principled to include the city/town in both counties because there would be the assumption that the crime occurring in each corresponding county is tied solely to population. Still, I left in all cities/towns overlapping with two counties, in case you have some ideas about how a mixed-model might be used to account for these (I don?t think a crossed-effect structure would do it). So pretty much any city with duplicate values where that value lies within the same county should be counted (these are just separate school districts), but any city with duplicate values where one of those values happens to be in another county, yet the school district is still the same, shouldn't be counted; unless, of course, there is a way for mixed-modeling in lme4 to account for that (PLACE_ID will be the same, but COUNTY_ID will be different, but full_district_id will be the same). Does that make sense? I'll soon send an email to the group with more clarification.
>>
>> Use IDs vs names. I included names for reference, but city/towns might not always be recorded exactly the same, so IDs are the safer bet.
>>
>> I have tried lmer?originally, my intention was to preserve counts of zero crime (whether it?s weariness or sanity that has changed my view, the difference between one and zero doesn?t seem so important anymore. I get the boundary (singular) warning (if a warning is what it can be called). No doubt there are many here that know more than me, but my understanding of this message is that it mostly warns against overfitting. To me, controlling for time through a fixed effect and as a random slope seems warranted?different cities/towns have different rates of change in crime from year to year.
>>
>> I still think fitting with glmer would be ideal, but I also lack an understanding of the nuances on the backend with regard to how the two functions differ. It seems that lmer is faster and more efficient in modeling, though I?m not sure why?mathematically or programmatically?that?s the case. If you can point me to an explanation, I?d appreciate that.
>>
>> Thanks much for your messages and your help.
>>
>> James
>>
>>
>> On Sep 4, 2019, at 12:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>>
>> Dear James,
>>
>> Your mail contains only a part of the dput() output. Given the size of your data, I suggest that you place it somewhere online and send us a link to the data.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be<http://www.inbo.be/>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> [https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>
>>
>>
>> Op di 3 sep. 2019 om 21:34 schreef Ades, James <jades at ucsd.edu<mailto:jades at ucsd.edu>>:
>> I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.
>>
>> I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)
>>
>> Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).
>>
>> I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
>> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")
>>
>> Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.
>>
>> First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).
>>
>> I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:
>>
>> ```
>> Error in getOptfun(optimizer) :
>>   optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
>> ```
>>
>> Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
>> optCtrl = list(method = "nlminb?,
>> maxit=10000,
>> iter.max=10000,
>> eval.max=10000,
>> lower = c(0,0,0),
>> upper = c(Inf,10,1)))
>>
>> and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\
>>
>> ```
>> Warning messages:
>> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
>>   unrecognized control elements named ?lower?, ?upper? ignored
>> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
>>   unrecognized control elements named ?lower?, ?upper? ignored
>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?
>> ```
>>
>> I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.
>>
>> I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.
>>
>> I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.
>>
>> Thanks!
>>
>>
>>
>> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
>> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
>> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
>> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
>> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
>> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
>> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
>> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
>> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
>> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
>> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
>> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
>> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
>> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
>> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
>> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
>> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
>> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
>> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
>> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
>> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
>> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
>> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
>> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
>> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
>> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
>> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
>> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
>> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
>> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
>> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
>> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
>> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
>> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
>> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
>> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
>> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
>> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
>> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
>> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
>> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
>> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
>> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
>> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
>> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
>> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
>> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
>> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
>> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
>> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
>> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
>> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
>> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
>> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
>> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
>> ), COUNTY = c("autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "autauga county", "autauga county", "autauga county", "autauga county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
>> "baldwin county", "baldwin county", "baldwin county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "apache county",
>> "apache county", "apache county", "apache county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "cochise county", "cochise county", "cochise county", "cochise county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "coconino county", "coconino county",
>> "coconino county", "coconino county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "gila county", "gila county", "gila county", "gila county",
>> "gila county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "graham county", "graham county", "graham county",
>> "graham county", "greenlee county", "greenlee county", "greenlee county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
>> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
>> "greenlee county", "greenlee county", "la paz county", "la paz county",
>> "la paz county", "la paz county", "la paz county", "la paz county",
>> "la paz county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "randolph county", "randolph county", "randolph county", "randolph county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "st. francis county", "st. francis county",
>> "st. francis county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county", "saline county", "saline county", "saline county",
>> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
>> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
>> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
>> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
>> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
>> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
>> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
>> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
>> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
>> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
>> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
>> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
>> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
>> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
>> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
>> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Autauga County School District", "Autauga County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Baldwin County School District",
>> "Baldwin County School District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "St. Johns Unified District",
>> "St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
>> "St. Johns Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Round Valley Unified District", "Round Valley Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Benson Unified School District", "St. David Unified District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
>> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
>> "Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
>> "Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
>> "Sierra Vista Unified District", "Sierra Vista Unified District",
>> "Sierra Vista Unified District", "Tombstone Unified District",
>> "Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
>> "Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
>> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Fredonia-Moccasin Unified District", "Page Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
>> "Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams Unified District",
>> "Williams Unified District", "Williams Unified District", "Williams Unified District",
>> "Williams Unified District", "Globe Unified District", "Miami Unified District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified District",
>> "Globe Unified District", "Miami Unified District", "Globe Unified District",
>> "Miami Unified District", "Globe Unified District", "Miami Unified District",
>> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified District",
>> "Miami Unified District", "Miami Unified District", "Miami Unified District",
>> "Miami Unified District", "Payson Unified District", "Payson Unified District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified District",
>> "Payson Unified District", "Payson Unified District", "Payson Unified District",
>> "Payson Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Pima Unified District", "Pima Unified District",
>> "Pima Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
>> "Safford Unified District", "Thatcher Unified District", "Safford Unified District",
>> "Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
>> "Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
>> "Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
>> "Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Parker Unified School District",
>> "Parker Unified School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Little Rock School District",
>> "Little Rock School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Little Rock School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "Pulaski County Special School District", "Pulaski County Special School District",
>> "North Little Rock School District", "Pulaski County Special School District",
>> "North Little Rock School District", "Pulaski County Special School District
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 28 20:58:12 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 28 Sep 2019 20:58:12 +0200
Subject: [R-sig-ME] specify random effects in lme4
In-Reply-To: <CADJrNxSLdm4h2oQv6SiFz5h=2_scSpSaFX2zy+z=5yUd_1P_Eg@mail.gmail.com>
References: <CADJrNxSLdm4h2oQv6SiFz5h=2_scSpSaFX2zy+z=5yUd_1P_Eg@mail.gmail.com>
Message-ID: <1715d759-7901-f2cb-67b9-692502fdb050@mpi.nl>

The decision to include a variable as a fixed or random effect doesn't
depend on whether or not that variable is a nuisance / control variable.
That's a common but really misleading heuristic.

Random effects estimate variance and estimating the variance of
something with only 3 instances (e.g. species in your design) doesn't
really make that much sense.

For your second model, see Thierry Onkelinx's many comments on this
mailing list about having the same variable as a fixed and random effect
as well as his blog post:
https://www.muscardinus.be/2017/08/fixed-and-random/ .

All that said,  you could run different models by species:

lmer(Wingsize ~ 1 + Habitat + (1|Region)) for each species

Or you could do some fun nesting of the fixed effects and have a single
model that estimates all these effects within each species:

lmer(Wingsize ~ 1 + Species/Habitat + (1|Region))

The model

lmer(Wingsize ~ 1 + Habitat + (1|Region/Species))

which expands to

lmer(Wingsize ~ 1 + Habitat + (1|Region) + (1|Region:Species)

is technically valid model, but it treats the same species occurring in
different regions as being different entities.  Whether or not that's
desirable for your work is something you have to know based on your own
research question and domain-specific knowledge.

The model

lmer(Wingsize~Habitat+(1|Region/Habitat))

expands to

lmer(Wingsize~Habitat+(1|Region) + (1|Region:Habitat))

which actually a special case of

lmer(Wingsize~Habitat+(0 + Habitat|Region)

when the variance-covariance matrix for the random effects is compound
symmetric.

This is rapidly getting into quite advanced applications, but if you
combine the last two Region/Species and Region/Habitat bits, then you
understand a bit more about how the three-level nesting
Region/Habitat/Species will be handled. My tendency would be to leave
habitat on the left-hand side of the | and then think about whether you
want Species/Habitat in the fixed effects or Habitat/Species as a
grouping variable (based on the considerations above).

Best,

Phillip

On 01/08/2019 16:47, Ben Adams wrote:
> I would like to ask for your help in specifying the random effects of a
> model I have been working on in lme4. I have data from a field survey. The
> objective of the study is to relate wing size (respond variable) with
> habitat (exploratory variable, categorical variable with 2 levels). We
> performed a paired design by sampling 50 individuals of 3 species in a
> simple habitat and the same 3 species (n=50 again) in a complex habitat in
> a region. We replicated that in 20 regions. I am both interested in the
> species specific effects and community effects. For running the analyses
> per species is this model correct?
> 
> modela<-lmer(Wingsize~Habitat+(1|Region))
> 
> For community wise effects is this model correct?
> 
> modelb<-lmer(Wingsize~Habitat+(1|Region/Habitat/Species))
> 
> For a schematic check this
> https://stats.stackexchange.com/questions/419693/specify-random-effects-in-lme4
> 
> 
> Thank you in advance,
> 
> 
> Ben
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 28 23:15:00 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 28 Sep 2019 23:15:00 +0200
Subject: [R-sig-ME] convergence: nearly unidentifiable: very large
 eigenvalue-Rescale variables?
In-Reply-To: <CAEA998htbx5j==fKPSJjT6ORWcnttRV47TKWiKq6Ht=WyHgB+Q@mail.gmail.com>
References: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
 <ff376d01-e98b-59eb-dd00-7313b6b7a130@mpi.nl>
 <CAEA998htbx5j==fKPSJjT6ORWcnttRV47TKWiKq6Ht=WyHgB+Q@mail.gmail.com>
Message-ID: <cb97d09c-979f-1c62-cb0e-f0a39a0aaf13@mpi.nl>

Hi Souheyla,

it's been a while, but coming back to your question.

Scaling a variable x works like this:

scale(x) = (x - mean(x)) / sd(x)

In other words, it centers things around zero and then converts the
units to standard deviations on the original scale.

Critically, this is a linear transformation, so it doesn't impact model
fit (for converged models), but it can make it easier for the software
to converge. In other words, scale() won't impact where you do or don't
find significance for converged models. It does impact the
interpretation of the model coefficients so that a coefficient reflects
the impact of a 1 SD change instead of an impact of (in your case) a 1s
change. But that's not a big deal, and if you know the SD and the mean
on the original scale, you can even back transform the coefficient to
the original scale.

You could also think of it like this: whether you measure time in
seconds or milliseconds should have no impact on your inferences, but it
does impact how big the numbers are and thus how easy it is to deal with
them (which is analagous to convergence for the software).  It also
impacts whether 1000 is a big span of time or a little one (analogous to
the interpretation of coefficients above). And indeed this is the case
because converting between seconds and milliseconds is also a linear
transformation.

Note that the logarithm is not a linear transformation and so this
doesn't hold for log transforms.

I'm a bit curious about your span of durations for 'words' -- those
don't all seem like plausible values for me, especially not 0 and 400s.

Phillip

On 18/04/2019 15:22, Souheyla GHEBGHOUB wrote:
> Hi?Phillip,
> 
> Yes. Duration is a predictor for 28 words. So there are 28 values for
> duration, in a range of 0 to 400, e.g. c(0, 10, 0, 320, 8, 35, 2, 400,
> 10, 2, 0..).?
> Yes, I applied log() since its a duration in seconds, but values of 0
> turned to infin values does the model did not recognise.
> I used scale() , though the model converged but it resulted in certain
> negative values for duration, I found that the scaling made the values
> quite close, no much difference between them and I am worried to what
> extent this affects my hypothesis testing that the duration should have
> an effect on DV ? I found no significant effect could this be due to
> scale() function??
> 
> Thank you very much,
> Souheyla
> /
> /
> 
> 
> On Thu, 18 Apr 2019 at 12:40, Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
> 
> 
>     On 18/4/19 1:14 pm, Souheyla GHEBGHOUB wrote:
>     > Hi everyone,
>     >
>     > I have a continuous predictor, duration, of 28 levels but with a large
>     > variance (from 0 to 400).
> 
>     Um, how do you have a continuous predictor with levels? Do you mean that
>     there are only 28 different/unique observed values within that
>     continuous predictor?
> 
>     Did you try applying scale() to duration? Or if duration is a response
>     time, maybe log()?
> 
>     How many subjects do you have? How many words? Are they fully crossed?
> 
>     Best,
>     Phillip
> 
> 
> 
> 
> 
>     This inhibits convergence. I used all techniques
>     > mentioned in this link lme4 convergence warnings: troubleshooting
>     >
>     <https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html>
>     > but
>     > nothing worked : ( ?
>     > Here is my model:
>     >
>     > *mod <- glmer(response~duration + wfpre + sequence + verbalfreq +
>     PoS +
>     > Characters + (1|Subject) + (1|Word), glmerControl(optimizer="bobyqa",
>     > optCtrl = list(maxfun = 2e5)), **data = df, family = 'binomial')*
>     >
>     > Could you please assist me with this?
>     > Thank you
>     > Souheyla
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 28 23:26:54 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 28 Sep 2019 23:26:54 +0200
Subject: [R-sig-ME] Looking for help in moving from a full factorial
 repeated measure anova to a LME model
In-Reply-To: <CANAWZx8_kgAm1O1=8GDKagm+A7veX0tnK8MeamTsJG5J16Vf2w@mail.gmail.com>
References: <CANAWZx8_kgAm1O1=8GDKagm+A7veX0tnK8MeamTsJG5J16Vf2w@mail.gmail.com>
Message-ID: <dfc6d5ee-a8ce-b309-3cd1-b3b08825cc5e@mpi.nl>

Hi Blazej,

sorry for not getting back to you sooner, especially when you actually
had a minimum working example ....

I suspect part of the problem is that anova() in R corresponds to a Type
I ANOVA, while the default in SPSS (if I recall correctly) is Type III.
I personally think Type III isn't terribly sensical and think Type II is
the way to go, but that's another topic. There's a lot of commentary and
explanations on these things. John Fox has posted various things on this
list to that effect, while Bill Venables has an excellent commentary on
the issue ("Exegeses on Linear Models":
https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf )

In practical terms, you need to load the car package and then try

Anova(m, type=2)
or
Anova(m, type=3)

The other thing that could be creating discrepancies is that you only
have a by-subjects intercept and no by-subjects slope. The choice of
random effects structure is a relatively big topic, and there are lots
of different things to read depending on your level of math. There's the
often cited 'Keep it maximal' paper by Barr et al. (2013, J Mem & Lang),
but I have some objections to that. Instead, I would recommend
'Balancing Type I error and power' by Matuschek et al. (2017, JML), or
the arXiv paper 'Parsimonous Mixed Models' (Bates et al.) or the
nextjournal paper 'Complexity in fitting Linear Mixed Models (Bates,
https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models/).

Hope that helps, even a year and a half later ....
Phillip

On 31/05/2018 13:37, Blazej Mrozinski wrote:
> Greetings to all group members,
> 
> I'm having troubles in setting up a linear mixed model for analyzing a
> balanced factorial within-subject design
> 
> I would normally use GLM Repeated Measures in SPSS on aggregated data-
> which is what I already did with current and previous data, but want to
> avoid losing participants due to missing data listwise deletion associated
> with GLM module.
> 
> Otherwise, I'd like everything as in GLM Repeated Measures - that is: all
> main effects and all interactions.
> 
> I understand that to use LME I need to have a raw datafile with separate
> line for each observation (multiple lines per participant). [Preparing such
> data file is not a problem].
> I am, however, unsure about proper syntax to get an equivalent of GLM
> Repeated Measures while using LME4.
> 
> This is some exemplary R code that mimics my real data structure (in raw /
> long format):
> 
> library(AlgDesign) #for generating a factorial design)
> df <-gen.factorial(c(8,2,2,2,2,10), factors = "all",
>                   varNames = c("rep", "A", "B", "C", "D", "Subject"))
> 
> df$rep <- as.numeric(df$rep)
> df$Subject <- as.numeric(df$Subject)
> 
> response <- sample(0:1, 1280, replace=TRUE, prob = c(0.3, 0.7))
> logRT <- rnorm(n=1280, m=7, sd=1)
> 
> df <- cbind(df, response, logRT)
> df$logRT[df$logRT<5 | df$logRT >9] <- NA
> 
> In my usual workflow I'd aggregate logRT over each factor and transpose to
> a wide format resulting in one row per subject to accomodate SPSS needs in
> GLM repeated measure procedure.
> 
> Clearly running
> 
> m <- lmer(logRT ~ A*B*C*D*response + (1|Subject), df)
> anova(m)
> 
> gives very different results from what I can get via SPSS anova and I'm
> guessing problem lies in how I specified the model in lmer call.
> 
> Any help would be greatly appreciated.
> 
> Blazej Mrozinski
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Sep 28 23:35:59 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 28 Sep 2019 23:35:59 +0200
Subject: [R-sig-ME] Specification of random effects structure
In-Reply-To: <02f401d4f5f7$4bd2a410$e377ec30$@uni-wuerzburg.de>
References: <02f401d4f5f7$4bd2a410$e377ec30$@uni-wuerzburg.de>
Message-ID: <9ffa0aaa-aa10-be23-2b2e-4de1dcd261b5@mpi.nl>

I suspect that if you look at the by-participant variance, you will have
seen it go down. The fixed effects term for N is by-participant, so when
it's left out from the model, the variation that it explains would tend
to be associated with the by-participant intercept (for the main effect)
or the by-participant slope (for the interaction).

One and a half minor terminological points>

1. The syntax you used and the models you describe are valid for lme4
but not nlme, so did you mean lmer() instead of lme()?

2. I would avoid the L1 vs L2 distinction here. I find the terminology
confusing and I would describe your design as 'crossed' and not 'nested'
anyway because you could just as well think of participants as being
repetitions of each item as the other way around. There's no need to
think of these things as strictly hierarchical, which is why some
(including me) prefer the terminology "multilevel" instead
"hierarchical" model.

Best,

Phillip

On 18/04/2019 16:59, Thorsten Aichele wrote:
> Dear List,
> 
>  
> 
> I am trying to specify the optimal random effect structure and I am not
> sure, if there's a problem with my understanding of the random effects
> structure, or with my data, or with none of these two.
> 
>  
> 
> Design: 
> 
> -          Two Levels, Repeated measures (L2 = 140 Participants)
> 
> -          Measure of Personality trait 'N' on L2
> 
> -          One experimental factor 'Condition' (on L1)
> 
> -          The control condition contained 12 Items. The experimental
> condition contained another 12 items (Item 1-12 = control group, item 13-24=
> experimental group)
> 
> -          Each participant answered all the items and all conditions. (Each
> item was only answered once)
> 
> -          The experimental comparison was:  funny (experimental condition)
> vs. not funny (control condition)
> 
> -          I have two random factors (participants on Level 2 and items on
> level 1)
> 
> -          Items are nested under condition (as the items in both conditions
> were not the same)
> 
>  
> 
> Now I want to look for a Cross-Level Interaction of the L2 variable
> (personality trait 'N') with the L1 variable 'Condition' (my main
> hypothesis)
> 
>  
> 
> I made the following Random effect structure under the assumption "include
> every possible random slope"
> 
>                                lme(DV ~ 1 + (1 + Condition|participants) +
> (1|Item)  
> 
> [I excluded random slope for N on item, as the model did not converge]
> 
>  
> 
>                                Now I tried to compare this model with a
> model with fixed effects + interaction for 'condition' and 'N'
> 
>                                lme(DV ~ 1 + Condition*N + (1 +
> Condition|participants) + (1|Item)  
> 
>                                                -Fixed effects part showed
> nonsignificant effect for 'condition' and 'N' 
> 
> -Fixed effects part showed a significant interaction effect  Condition:N
> 
> -Fixed effect for intercept was also significant
> 
>  
> 
> Both Models share identical residual variance (1.7450). I have no idea how
> this could be possible. The interaction effect is rather small (-.0247), but
> I doubt, that an interaction effect could become significant without
> explaining any variance.
> 
>  
> 
> I would be thankful if anyone could help me with this problem
> 
>  
> 
> Best,
> 
> Thorsten Aichele
> 
>  
> 
>  
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j@de@ @end|ng |rom uc@d@edu  Sun Sep 29 03:20:44 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Sun, 29 Sep 2019 01:20:44 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
Message-ID: <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>

Thanks, Ben and Philip!

So I think I was conflating having a continuous dependent variable, which could then be broken up into different categories with dummy variables (for instance, if I wanted to look at how wealth affects the distribution of race in an area, I could create a model like lmer(total people ~ race + per capita income + ?) with creating something similar with a fixed factor (which I guess can?t be done).

I did try running the variables independently, which worked, I just thought there was a way to combine races, and then per that logic, thought that since race variables repeated within place (city/town), I could nest it within PLACE_ID. But realized that the percent race as a fixed effect (as an output) didn?t really make sense?hence my confusion. So I guess somewhere in there my logic was afoul.

Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it was actually quicker and more likely to converge. Good to know. I read through the lme4 package details here: https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you recommend then optimx? Or Nloptr/bobyqa? (which I think is the default).

Regarding multicollinearity: is there an article you could send me on dealing with multicollinearity in mixed-effect models? I?ve perused the internet, but haven?t been able to find a great how to and dealing with it, such that you can better parse the effects of different variables (I know that one can use PCA, but that fundamentally alters the process, and isn?t there a way of averaging variables such that you minimize collinearity?).

One thing I?m currently dealing with in my model is that year as a fixed effect is correlated with a district?s spending, such that if I remove year, district spending has a negative effect on crime, but including year as a fixed effect alters the spending regression coefficient to be positive (just north of zero). Though here, specifically, I?m not sure if this is technically collinearity, or if time as a fixed factor is merely controlling, here, for crime change over time, where a model without year as a fixed factor would be looking at the effect of district spending on crime (similar to a model where years are averaged together). Does that make sense? Is that interpretation accurate?

Thanks much!

James


On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>> wrote:

ink the answer to your proximal question about per_race is that
you would need five *different* numerical varia


	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sun Sep 29 12:06:36 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sun, 29 Sep 2019 12:06:36 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
 <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
Message-ID: <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>

The default optimizer in lme4 is the default for a reason. :) While
there's no free lunch or single best optimizer for every situation, the
default was chosen based on our experience about which optimizer works
performs well across a wide range of models and datasets.

Multicollinearity in mixed-effects models works pretty much exactly the
same way as it does in fixed-effects (i.e. regular/not mixed) regression
and so the way it's addressed (converting to PC basis, residualization,
etc.) In your case, you could omit one race and then the remaining races
will be linearly independent, albeit still correlated with another. This
correlation isn't great and will inflate your standard errors, but then
at least your design matrix won't be rank deficient.

Regarding year-spending: Are you using 'correlated' in a strict sense,
e.g. that spending tends to go up year-by-year? Or do just mean that
including spending in the model changes the effect of year? (I think the
latter weakly implies the former, but it's a different perspective.)
Either way, the changing coefficient isn't terribly surprising. In
'human' terms: if you don't have the option of attributing something to
the actual source of variation, but you do have something that is
vaguely related to it, then you will attribute it to that. However, if
you're ever given the chance to attribute it to the actual source, you
will do that and your attribution to the vaguely-related thing will change.

Best,
Phillip

On 29/09/2019 03:20, Ades, James wrote:
> Thanks, Ben and Philip!
> 
> So I think I was conflating having a continuous dependent variable,
> which could then be broken up into different categories with dummy
> variables (for instance, if I wanted to look at how wealth affects the
> distribution of race in an area, I could create a model like lmer(total
> people ~ race + per capita income + ?) with creating something similar
> with a fixed factor (which I guess can?t be done).
> 
> I did try running the variables independently, which worked, I just
> thought there was a way to combine races, and then per that logic,
> thought that since race variables repeated within place (city/town), I
> could nest it within PLACE_ID. But realized that the percent race as a
> fixed effect (as an output) didn?t really make sense?hence my confusion.
> So I guess somewhere in there my logic was afoul.
> 
> Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it
> was actually quicker and more likely to converge. Good to know. I read
> through the lme4 package details here:
> https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you
> recommend then optimx? Or Nloptr/bobyqa? (which I think is the default).
> 
> Regarding multicollinearity: is there an article you could send me on
> dealing with multicollinearity in mixed-effect models? I?ve perused the
> internet, but haven?t been able to find a great how to and dealing with
> it, such that you can better parse the effects of different variables (I
> know that one can use PCA, but that fundamentally alters the process,
> and isn?t there a way of averaging variables such that you minimize
> collinearity?).
> 
> One thing I?m currently dealing with in my model is that year as a fixed
> effect is correlated with a district?s spending, such that if I remove
> year, district spending has a negative effect on crime, but including
> year as a fixed effect alters the spending regression coefficient to be
> positive (just north of zero). Though here, specifically, I?m not sure
> if this is technically collinearity, or if time as a fixed factor is
> merely controlling, here, for crime change over time, where a model
> without year as a fixed factor would be looking at the effect of
> district spending on crime (similar to a model where years are averaged
> together). Does that make sense? Is that interpretation accurate?
> 
> Thanks much!
> 
> James
> 
> 
>> On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>>
>>> ink the answer to your proximal question about per_race is that
>>> you would need five *different* numerical varia
>


